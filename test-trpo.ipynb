{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from garage import wrap_experiment\n",
    "from garage.envs import GymEnv\n",
    "from garage.experiment.deterministic import set_seed\n",
    "from garage.sampler import LocalSampler\n",
    "from garage.torch.algos import TRPO\n",
    "from garage.torch.algos import VPG\n",
    "from garage.torch.policies import GaussianMLPPolicy\n",
    "from garage.torch.value_functions import GaussianMLPValueFunction\n",
    "from garage.trainer import Trainer\n",
    "\n",
    "@wrap_experiment\n",
    "def trpo_pendulum(ctxt=None, seed=1):\n",
    "    \"\"\"Train TRPO with InvertedDoublePendulum-v2 environment.\n",
    "    Args:\n",
    "        ctxt (garage.experiment.ExperimentContext): The experiment\n",
    "            configuration used by Trainer to create the snapshotter.\n",
    "        seed (int): Used to seed the random number generator to produce\n",
    "            determinism.\n",
    "    \"\"\"\n",
    "    set_seed(seed)\n",
    "    env = GymEnv('MountainCarContinuous-v0')\n",
    "\n",
    "    trainer = Trainer(ctxt)\n",
    "\n",
    "    policy = GaussianMLPPolicy(env.spec,\n",
    "                               hidden_sizes=[32, 32],\n",
    "                               hidden_nonlinearity=torch.tanh,\n",
    "                               output_nonlinearity=None)\n",
    "\n",
    "    value_function = GaussianMLPValueFunction(env_spec=env.spec,\n",
    "                                              hidden_sizes=(32, 32),\n",
    "                                              hidden_nonlinearity=torch.tanh,\n",
    "                                              output_nonlinearity=None)\n",
    "\n",
    "    sampler = LocalSampler(agents=policy,\n",
    "                           envs=env,\n",
    "                           max_episode_length=env.spec.max_episode_length)\n",
    "\n",
    "    algo = TRPO(env_spec=env.spec,\n",
    "                policy=policy,\n",
    "                value_function=value_function,\n",
    "                sampler=sampler,\n",
    "                discount=0.99,\n",
    "                center_adv=False)\n",
    "\n",
    "    trainer.setup(algo, env)\n",
    "    trainer.train(n_epochs=500, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-23 10:37:18 | [trpo_pendulum] Logging to d:\\Github\\DRSOM-for-RL\\data/local/experiment/trpo_pendulum_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\lib\\site-packages\\garage\\experiment\\deterministic.py:36: UserWarning: Enabeling deterministic mode in PyTorch can have a performance impact when using GPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-23 10:37:18 | [trpo_pendulum] Obtaining samples...\n",
      "flat loss grads is: \n",
      "tensor([ 1.4506e-01, -6.3618e-03, -9.6141e-05,  ..., -2.9816e-03,\n",
      "         4.6496e-03, -3.1764e-02])\n",
      "G is: \n",
      "tensor([[0.0319, 0.0986],\n",
      "        [0.0986, 0.4065]])\n",
      "eig is:\n",
      "tensor([[0.0075, 0.0000],\n",
      "        [0.4308, 0.0000]])\n",
      "loss before is:\n",
      "tensor(3.4138, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(3.4034, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:19 | [trpo_pendulum] epoch #0 | Saving snapshot...\n",
      "2022-08-23 10:37:19 | [trpo_pendulum] epoch #0 | Saved\n",
      "2022-08-23 10:37:19 | [trpo_pendulum] epoch #0 | Time 1.00 s\n",
      "2022-08-23 10:37:19 | [trpo_pendulum] epoch #0 | EpochTime 1.00 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn    -10.8561\n",
      "Evaluation/AverageReturn             -108.645\n",
      "Evaluation/Iteration                    0\n",
      "Evaluation/MaxReturn                 -103.75\n",
      "Evaluation/MinReturn                 -113.54\n",
      "Evaluation/NumEpisodes                  2\n",
      "Evaluation/StdReturn                    4.89498\n",
      "Evaluation/TerminationRate              0\n",
      "GaussianMLPPolicy/Entropy               1.39514\n",
      "GaussianMLPPolicy/KL                    0.00960769\n",
      "GaussianMLPPolicy/KLBefore              0\n",
      "GaussianMLPPolicy/LossAfter             3.40337\n",
      "GaussianMLPPolicy/LossBefore            3.41378\n",
      "GaussianMLPPolicy/dLoss                 0.010407\n",
      "GaussianMLPValueFunction/LossAfter     12.9548\n",
      "GaussianMLPValueFunction/LossBefore    49.6662\n",
      "GaussianMLPValueFunction/dLoss         36.7114\n",
      "TotalEnvSteps                        1998\n",
      "-----------------------------------  -------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.4034e-01, -7.2821e-03,  1.0487e-04,  ...,  2.8260e-04,\n",
      "         1.8266e-02, -6.5516e-02])\n",
      "G is: \n",
      "tensor([[0.0949, 0.4530],\n",
      "        [0.4530, 3.2948]])\n",
      "eig is:\n",
      "tensor([[0.0321, 0.0000],\n",
      "        [3.3577, 0.0000]])\n",
      "loss before is:\n",
      "tensor(1.3061, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(1.2955, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:20 | [trpo_pendulum] epoch #1 | Saving snapshot...\n",
      "2022-08-23 10:37:20 | [trpo_pendulum] epoch #1 | Saved\n",
      "2022-08-23 10:37:20 | [trpo_pendulum] epoch #1 | Time 2.08 s\n",
      "2022-08-23 10:37:20 | [trpo_pendulum] epoch #1 | EpochTime 1.07 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn    -11.8717\n",
      "Evaluation/AverageReturn             -101.668\n",
      "Evaluation/Iteration                    1\n",
      "Evaluation/MaxReturn                 -100.811\n",
      "Evaluation/MinReturn                 -102.525\n",
      "Evaluation/NumEpisodes                  2\n",
      "Evaluation/StdReturn                    0.856765\n",
      "Evaluation/TerminationRate              0\n",
      "GaussianMLPPolicy/Entropy               1.37277\n",
      "GaussianMLPPolicy/KL                    0.00549847\n",
      "GaussianMLPPolicy/KLBefore              0\n",
      "GaussianMLPPolicy/LossAfter             1.29548\n",
      "GaussianMLPPolicy/LossBefore            1.30608\n",
      "GaussianMLPPolicy/dLoss                 0.0106019\n",
      "GaussianMLPValueFunction/LossAfter      3.46681\n",
      "GaussianMLPValueFunction/LossBefore     8.95755\n",
      "GaussianMLPValueFunction/dLoss          5.49074\n",
      "TotalEnvSteps                        3996\n",
      "-----------------------------------  -------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.2317e-01, -1.5761e-03,  7.7995e-05,  ..., -4.7621e-03,\n",
      "         1.4471e-02, -5.3322e-02])\n",
      "G is: \n",
      "tensor([[0.0328, 0.1787],\n",
      "        [0.1787, 1.3939]])\n",
      "eig is:\n",
      "tensor([[0.0097, 0.0000],\n",
      "        [1.4170, 0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.1151, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.1206, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:21 | [trpo_pendulum] epoch #2 | Saving snapshot...\n",
      "2022-08-23 10:37:21 | [trpo_pendulum] epoch #2 | Saved\n",
      "2022-08-23 10:37:21 | [trpo_pendulum] epoch #2 | Time 3.10 s\n",
      "2022-08-23 10:37:21 | [trpo_pendulum] epoch #2 | EpochTime 1.01 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn     -8.49506\n",
      "Evaluation/AverageReturn              -89.9575\n",
      "Evaluation/Iteration                    2\n",
      "Evaluation/MaxReturn                  -88.6702\n",
      "Evaluation/MinReturn                  -91.2448\n",
      "Evaluation/NumEpisodes                  2\n",
      "Evaluation/StdReturn                    1.2873\n",
      "Evaluation/TerminationRate              0\n",
      "GaussianMLPPolicy/Entropy               1.36438\n",
      "GaussianMLPPolicy/KL                    0.00527914\n",
      "GaussianMLPPolicy/KLBefore              0\n",
      "GaussianMLPPolicy/LossAfter            -0.1206\n",
      "GaussianMLPPolicy/LossBefore           -0.115099\n",
      "GaussianMLPPolicy/dLoss                 0.00550057\n",
      "GaussianMLPValueFunction/LossAfter      2.59192\n",
      "GaussianMLPValueFunction/LossBefore     2.66226\n",
      "GaussianMLPValueFunction/dLoss          0.0703344\n",
      "TotalEnvSteps                        5994\n",
      "-----------------------------------  -------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.5741e-01, -8.0359e-04,  3.6237e-05,  ..., -1.0568e-03,\n",
      "         1.4706e-03,  8.3214e-05])\n",
      "G is: \n",
      "tensor([[0.0250, 0.0502],\n",
      "        [0.0502, 0.1047]])\n",
      "eig is:\n",
      "tensor([[0.0008, 0.0000],\n",
      "        [0.1289, 0.0000]])\n",
      "loss before is:\n",
      "tensor(0.1535, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.1438, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:22 | [trpo_pendulum] epoch #3 | Saving snapshot...\n",
      "2022-08-23 10:37:22 | [trpo_pendulum] epoch #3 | Saved\n",
      "2022-08-23 10:37:22 | [trpo_pendulum] epoch #3 | Time 4.10 s\n",
      "2022-08-23 10:37:22 | [trpo_pendulum] epoch #3 | EpochTime 1.00 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn    -10.1278\n",
      "Evaluation/AverageReturn              -93.5668\n",
      "Evaluation/Iteration                    3\n",
      "Evaluation/MaxReturn                  -87.6105\n",
      "Evaluation/MinReturn                  -99.5232\n",
      "Evaluation/NumEpisodes                  2\n",
      "Evaluation/StdReturn                    5.95638\n",
      "Evaluation/TerminationRate              0\n",
      "GaussianMLPPolicy/Entropy               1.3062\n",
      "GaussianMLPPolicy/KL                    0.00635229\n",
      "GaussianMLPPolicy/KLBefore              0\n",
      "GaussianMLPPolicy/LossAfter             0.143751\n",
      "GaussianMLPPolicy/LossBefore            0.153462\n",
      "GaussianMLPPolicy/dLoss                 0.00971094\n",
      "GaussianMLPValueFunction/LossAfter      2.65853\n",
      "GaussianMLPValueFunction/LossBefore     2.73948\n",
      "GaussianMLPValueFunction/dLoss          0.0809443\n",
      "TotalEnvSteps                        7992\n",
      "-----------------------------------  -------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.3067e-01,  2.8781e-03,  4.9871e-04,  ...,  1.7292e-03,\n",
      "        -1.1897e-04, -1.3570e-02])\n",
      "G is: \n",
      "tensor([[0.0190, 0.0362],\n",
      "        [0.0362, 0.0822]])\n",
      "eig is:\n",
      "tensor([[0.0025, 0.0000],\n",
      "        [0.0987, 0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.1582, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.1656, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:23 | [trpo_pendulum] epoch #4 | Saving snapshot...\n",
      "2022-08-23 10:37:23 | [trpo_pendulum] epoch #4 | Saved\n",
      "2022-08-23 10:37:23 | [trpo_pendulum] epoch #4 | Time 5.19 s\n",
      "2022-08-23 10:37:23 | [trpo_pendulum] epoch #4 | EpochTime 1.08 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn     -8.0509\n",
      "Evaluation/AverageReturn              -83.6893\n",
      "Evaluation/Iteration                    4\n",
      "Evaluation/MaxReturn                  -82.6741\n",
      "Evaluation/MinReturn                  -84.7045\n",
      "Evaluation/NumEpisodes                  2\n",
      "Evaluation/StdReturn                    1.01517\n",
      "Evaluation/TerminationRate              0\n",
      "GaussianMLPPolicy/Entropy               1.28989\n",
      "GaussianMLPPolicy/KL                    0.00626884\n",
      "GaussianMLPPolicy/KLBefore              0\n",
      "GaussianMLPPolicy/LossAfter            -0.165601\n",
      "GaussianMLPPolicy/LossBefore           -0.158239\n",
      "GaussianMLPPolicy/dLoss                 0.00736222\n",
      "GaussianMLPValueFunction/LossAfter      2.67918\n",
      "GaussianMLPValueFunction/LossBefore     3.10281\n",
      "GaussianMLPValueFunction/dLoss          0.423627\n",
      "TotalEnvSteps                        9990\n",
      "-----------------------------------  -------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.0768e-01,  1.2979e-03,  1.5434e-05,  ..., -2.6791e-03,\n",
      "         1.5817e-02, -4.4270e-02])\n",
      "G is: \n",
      "tensor([[0.0768, 0.5656],\n",
      "        [0.5656, 7.3930]])\n",
      "eig is:\n",
      "tensor([[0.0334, 0.0000],\n",
      "        [7.4365, 0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0413, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0573, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:24 | [trpo_pendulum] epoch #5 | Saving snapshot...\n",
      "2022-08-23 10:37:24 | [trpo_pendulum] epoch #5 | Saved\n",
      "2022-08-23 10:37:24 | [trpo_pendulum] epoch #5 | Time 6.20 s\n",
      "2022-08-23 10:37:24 | [trpo_pendulum] epoch #5 | EpochTime 1.01 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -9.26518\n",
      "Evaluation/AverageReturn               -85.2306\n",
      "Evaluation/Iteration                     5\n",
      "Evaluation/MaxReturn                   -83.1431\n",
      "Evaluation/MinReturn                   -87.3181\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     2.08749\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.24904\n",
      "GaussianMLPPolicy/KL                     0.00568646\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0573434\n",
      "GaussianMLPPolicy/LossBefore            -0.0412846\n",
      "GaussianMLPPolicy/dLoss                  0.0160589\n",
      "GaussianMLPValueFunction/LossAfter       2.92091\n",
      "GaussianMLPValueFunction/LossBefore      3.0486\n",
      "GaussianMLPValueFunction/dLoss           0.127682\n",
      "TotalEnvSteps                        11988\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.0627e-01,  7.4199e-04,  1.2539e-05,  ..., -9.1996e-04,\n",
      "         1.0136e-02, -3.1674e-02])\n",
      "G is: \n",
      "tensor([[0.0212, 0.1786],\n",
      "        [0.1786, 2.5913]])\n",
      "eig is:\n",
      "tensor([[0.0089, 0.0000],\n",
      "        [2.6036, 0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.4083, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.4112, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:25 | [trpo_pendulum] epoch #6 | Saving snapshot...\n",
      "2022-08-23 10:37:25 | [trpo_pendulum] epoch #6 | Saved\n",
      "2022-08-23 10:37:25 | [trpo_pendulum] epoch #6 | Time 7.26 s\n",
      "2022-08-23 10:37:25 | [trpo_pendulum] epoch #6 | EpochTime 1.05 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -6.98805\n",
      "Evaluation/AverageReturn               -71.9176\n",
      "Evaluation/Iteration                     6\n",
      "Evaluation/MaxReturn                   -68.6166\n",
      "Evaluation/MinReturn                   -75.2185\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     3.30093\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.23033\n",
      "GaussianMLPPolicy/KL                     0.00616349\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.411202\n",
      "GaussianMLPPolicy/LossBefore            -0.408253\n",
      "GaussianMLPPolicy/dLoss                  0.00294873\n",
      "GaussianMLPValueFunction/LossAfter       2.08272\n",
      "GaussianMLPValueFunction/LossBefore      2.67239\n",
      "GaussianMLPValueFunction/dLoss           0.589674\n",
      "TotalEnvSteps                        13986\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 0.1360,  0.0084,  0.0002,  ..., -0.0222,  0.0348, -0.0645])\n",
      "G is: \n",
      "tensor([[ 0.0744,  1.0267],\n",
      "        [ 1.0267, 17.6666]])\n",
      "eig is:\n",
      "tensor([[1.4679e-02, 0.0000e+00],\n",
      "        [1.7726e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0412, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0526, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:26 | [trpo_pendulum] epoch #7 | Saving snapshot...\n",
      "2022-08-23 10:37:26 | [trpo_pendulum] epoch #7 | Saved\n",
      "2022-08-23 10:37:26 | [trpo_pendulum] epoch #7 | Time 8.18 s\n",
      "2022-08-23 10:37:26 | [trpo_pendulum] epoch #7 | EpochTime 0.92 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -6.18341\n",
      "Evaluation/AverageReturn               -70.6878\n",
      "Evaluation/Iteration                     7\n",
      "Evaluation/MaxReturn                   -70.6583\n",
      "Evaluation/MinReturn                   -70.7172\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.0294764\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.14955\n",
      "GaussianMLPPolicy/KL                     0.00771476\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0526313\n",
      "GaussianMLPPolicy/LossBefore            -0.0412238\n",
      "GaussianMLPPolicy/dLoss                  0.0114076\n",
      "GaussianMLPValueFunction/LossAfter       2.08484\n",
      "GaussianMLPValueFunction/LossBefore      2.12386\n",
      "GaussianMLPValueFunction/dLoss           0.0390272\n",
      "TotalEnvSteps                        15984\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.9691e-02,  3.6194e-03,  6.0060e-05,  ..., -1.7417e-02,\n",
      "         2.5059e-02, -4.5823e-02])\n",
      "G is: \n",
      "tensor([[0.0311, 0.4294],\n",
      "        [0.4294, 7.4784]])\n",
      "eig is:\n",
      "tensor([[6.4712e-03, 0.0000e+00],\n",
      "        [7.5031e+00, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.2925, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.2999, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:27 | [trpo_pendulum] epoch #8 | Saving snapshot...\n",
      "2022-08-23 10:37:27 | [trpo_pendulum] epoch #8 | Saved\n",
      "2022-08-23 10:37:27 | [trpo_pendulum] epoch #8 | Time 9.12 s\n",
      "2022-08-23 10:37:27 | [trpo_pendulum] epoch #8 | EpochTime 0.93 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -6.80442\n",
      "Evaluation/AverageReturn               -62.9695\n",
      "Evaluation/Iteration                     8\n",
      "Evaluation/MaxReturn                   -61.2251\n",
      "Evaluation/MinReturn                   -64.7139\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     1.74438\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.12121\n",
      "GaussianMLPPolicy/KL                     0.00548653\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.299928\n",
      "GaussianMLPPolicy/LossBefore            -0.292456\n",
      "GaussianMLPPolicy/dLoss                  0.00747213\n",
      "GaussianMLPValueFunction/LossAfter       1.66706\n",
      "GaussianMLPValueFunction/LossBefore      1.96635\n",
      "GaussianMLPValueFunction/dLoss           0.299291\n",
      "TotalEnvSteps                        17982\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.4571e-01,  2.6720e-03, -1.2425e-05,  ..., -2.0152e-03,\n",
      "         9.1791e-03, -1.9303e-02])\n",
      "G is: \n",
      "tensor([[0.0260, 0.1629],\n",
      "        [0.1629, 3.1916]])\n",
      "eig is:\n",
      "tensor([[0.0176, 0.0000],\n",
      "        [3.1999, 0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0916, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0995, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:28 | [trpo_pendulum] epoch #9 | Saving snapshot...\n",
      "2022-08-23 10:37:28 | [trpo_pendulum] epoch #9 | Saved\n",
      "2022-08-23 10:37:28 | [trpo_pendulum] epoch #9 | Time 10.09 s\n",
      "2022-08-23 10:37:28 | [trpo_pendulum] epoch #9 | EpochTime 0.96 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -5.59162\n",
      "Evaluation/AverageReturn               -58.47\n",
      "Evaluation/Iteration                     9\n",
      "Evaluation/MaxReturn                   -53.352\n",
      "Evaluation/MinReturn                   -63.5881\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     5.11804\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.06217\n",
      "GaussianMLPPolicy/KL                     0.00593051\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.099497\n",
      "GaussianMLPPolicy/LossBefore            -0.0916207\n",
      "GaussianMLPPolicy/dLoss                  0.00787625\n",
      "GaussianMLPValueFunction/LossAfter       1.88214\n",
      "GaussianMLPValueFunction/LossBefore      1.93667\n",
      "GaussianMLPValueFunction/dLoss           0.0545368\n",
      "TotalEnvSteps                        19980\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 0.0805,  0.0092, -0.0002,  ..., -0.0212,  0.0337, -0.0730])\n",
      "G is: \n",
      "tensor([[ 0.0639,  1.2907],\n",
      "        [ 1.2907, 28.4865]])\n",
      "eig is:\n",
      "tensor([[5.3596e-03, 0.0000e+00],\n",
      "        [2.8545e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.1533, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.1601, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:29 | [trpo_pendulum] epoch #10 | Saving snapshot...\n",
      "2022-08-23 10:37:29 | [trpo_pendulum] epoch #10 | Saved\n",
      "2022-08-23 10:37:29 | [trpo_pendulum] epoch #10 | Time 11.06 s\n",
      "2022-08-23 10:37:29 | [trpo_pendulum] epoch #10 | EpochTime 0.97 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -5.18649\n",
      "Evaluation/AverageReturn               -53.831\n",
      "Evaluation/Iteration                    10\n",
      "Evaluation/MaxReturn                   -53.4116\n",
      "Evaluation/MinReturn                   -54.2504\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.419422\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.0519\n",
      "GaussianMLPPolicy/KL                     0.0066739\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.160051\n",
      "GaussianMLPPolicy/LossBefore            -0.153332\n",
      "GaussianMLPPolicy/dLoss                  0.00671819\n",
      "GaussianMLPValueFunction/LossAfter       1.6409\n",
      "GaussianMLPValueFunction/LossBefore      1.71715\n",
      "GaussianMLPValueFunction/dLoss           0.0762445\n",
      "TotalEnvSteps                        21978\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.9741e-02,  9.8576e-04, -5.6015e-05,  ..., -6.5893e-03,\n",
      "         9.3250e-03, -2.2673e-02])\n",
      "G is: \n",
      "tensor([[0.0137, 0.0848],\n",
      "        [0.0848, 1.1898]])\n",
      "eig is:\n",
      "tensor([[0.0076, 0.0000],\n",
      "        [1.1958, 0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.1451, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.1490, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:30 | [trpo_pendulum] epoch #11 | Saving snapshot...\n",
      "2022-08-23 10:37:30 | [trpo_pendulum] epoch #11 | Saved\n",
      "2022-08-23 10:37:30 | [trpo_pendulum] epoch #11 | Time 12.09 s\n",
      "2022-08-23 10:37:30 | [trpo_pendulum] epoch #11 | EpochTime 1.02 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -5.28123\n",
      "Evaluation/AverageReturn               -49.0465\n",
      "Evaluation/Iteration                    11\n",
      "Evaluation/MaxReturn                   -48.8773\n",
      "Evaluation/MinReturn                   -49.2157\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.169186\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.0287\n",
      "GaussianMLPPolicy/KL                     0.00474701\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.149037\n",
      "GaussianMLPPolicy/LossBefore            -0.145146\n",
      "GaussianMLPPolicy/dLoss                  0.0038915\n",
      "GaussianMLPValueFunction/LossAfter       1.50821\n",
      "GaussianMLPValueFunction/LossBefore      1.58851\n",
      "GaussianMLPValueFunction/dLoss           0.0803012\n",
      "TotalEnvSteps                        23976\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.3543e-02, -2.4772e-04,  1.7832e-05,  ...,  7.5735e-03,\n",
      "        -8.8721e-03,  2.0606e-02])\n",
      "G is: \n",
      "tensor([[0.0117, 0.0656],\n",
      "        [0.0656, 0.8138]])\n",
      "eig is:\n",
      "tensor([[0.0064, 0.0000],\n",
      "        [0.8191, 0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0187, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0222, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:31 | [trpo_pendulum] epoch #12 | Saving snapshot...\n",
      "2022-08-23 10:37:31 | [trpo_pendulum] epoch #12 | Saved\n",
      "2022-08-23 10:37:31 | [trpo_pendulum] epoch #12 | Time 13.05 s\n",
      "2022-08-23 10:37:31 | [trpo_pendulum] epoch #12 | EpochTime 0.96 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -4.97156\n",
      "Evaluation/AverageReturn               -46.9639\n",
      "Evaluation/Iteration                    12\n",
      "Evaluation/MaxReturn                   -46.2729\n",
      "Evaluation/MinReturn                   -47.6549\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.690988\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.991793\n",
      "GaussianMLPPolicy/KL                     0.00852013\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0221783\n",
      "GaussianMLPPolicy/LossBefore            -0.0187478\n",
      "GaussianMLPPolicy/dLoss                  0.00343051\n",
      "GaussianMLPValueFunction/LossAfter       1.44543\n",
      "GaussianMLPValueFunction/LossBefore      1.48709\n",
      "GaussianMLPValueFunction/dLoss           0.0416512\n",
      "TotalEnvSteps                        25974\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 0.0711, -0.0040, -0.0002,  ...,  0.0098, -0.0107,  0.0295])\n",
      "G is: \n",
      "tensor([[0.0119, 0.1443],\n",
      "        [0.1443, 2.6510]])\n",
      "eig is:\n",
      "tensor([[0.0041, 0.0000],\n",
      "        [2.6588, 0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0737, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0744, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:32 | [trpo_pendulum] epoch #13 | Saving snapshot...\n",
      "2022-08-23 10:37:32 | [trpo_pendulum] epoch #13 | Saved\n",
      "2022-08-23 10:37:32 | [trpo_pendulum] epoch #13 | Time 14.02 s\n",
      "2022-08-23 10:37:32 | [trpo_pendulum] epoch #13 | EpochTime 0.97 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -4.31098\n",
      "Evaluation/AverageReturn               -44.4243\n",
      "Evaluation/Iteration                    13\n",
      "Evaluation/MaxReturn                   -43.7455\n",
      "Evaluation/MinReturn                   -45.1031\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.678812\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.979525\n",
      "GaussianMLPPolicy/KL                     0.00618918\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0743996\n",
      "GaussianMLPPolicy/LossBefore            -0.0736815\n",
      "GaussianMLPPolicy/dLoss                  0.000718102\n",
      "GaussianMLPValueFunction/LossAfter       1.36682\n",
      "GaussianMLPValueFunction/LossBefore      1.392\n",
      "GaussianMLPValueFunction/dLoss           0.0251802\n",
      "TotalEnvSteps                        27972\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.8810e-02, -9.5602e-04, -9.1222e-06,  ...,  6.3799e-03,\n",
      "        -8.5610e-03,  1.3022e-02])\n",
      "G is: \n",
      "tensor([[0.0069, 0.0477],\n",
      "        [0.0477, 0.7705]])\n",
      "eig is:\n",
      "tensor([[0.0039, 0.0000],\n",
      "        [0.7734, 0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0449, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0470, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:33 | [trpo_pendulum] epoch #14 | Saving snapshot...\n",
      "2022-08-23 10:37:33 | [trpo_pendulum] epoch #14 | Saved\n",
      "2022-08-23 10:37:33 | [trpo_pendulum] epoch #14 | Time 15.01 s\n",
      "2022-08-23 10:37:33 | [trpo_pendulum] epoch #14 | EpochTime 0.98 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -4.37502\n",
      "Evaluation/AverageReturn               -42.595\n",
      "Evaluation/Iteration                    14\n",
      "Evaluation/MaxReturn                   -42.5212\n",
      "Evaluation/MinReturn                   -42.6687\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.0737716\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.963182\n",
      "GaussianMLPPolicy/KL                     0.00335075\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0470175\n",
      "GaussianMLPPolicy/LossBefore            -0.0449395\n",
      "GaussianMLPPolicy/dLoss                  0.002078\n",
      "GaussianMLPValueFunction/LossAfter       1.34838\n",
      "GaussianMLPValueFunction/LossBefore      1.36338\n",
      "GaussianMLPValueFunction/dLoss           0.0150036\n",
      "TotalEnvSteps                        29970\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.2138e-02, -1.8302e-03,  1.7333e-05,  ...,  2.4000e-03,\n",
      "        -1.2206e-02,  3.2575e-02])\n",
      "G is: \n",
      "tensor([[0.0137, 0.1344],\n",
      "        [0.1344, 2.1544]])\n",
      "eig is:\n",
      "tensor([[0.0053, 0.0000],\n",
      "        [2.1628, 0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0254, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0257, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:34 | [trpo_pendulum] epoch #15 | Saving snapshot...\n",
      "2022-08-23 10:37:34 | [trpo_pendulum] epoch #15 | Saved\n",
      "2022-08-23 10:37:34 | [trpo_pendulum] epoch #15 | Time 16.00 s\n",
      "2022-08-23 10:37:34 | [trpo_pendulum] epoch #15 | EpochTime 0.98 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -4.69227\n",
      "Evaluation/AverageReturn               -41.6703\n",
      "Evaluation/Iteration                    15\n",
      "Evaluation/MaxReturn                   -41.2292\n",
      "Evaluation/MinReturn                   -42.1113\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.441062\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.946036\n",
      "GaussianMLPPolicy/KL                     0.00117773\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0256862\n",
      "GaussianMLPPolicy/LossBefore            -0.0253653\n",
      "GaussianMLPPolicy/dLoss                  0.000320889\n",
      "GaussianMLPValueFunction/LossAfter       1.40075\n",
      "GaussianMLPValueFunction/LossBefore      1.40898\n",
      "GaussianMLPValueFunction/dLoss           0.00822711\n",
      "TotalEnvSteps                        31968\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.7646e-02, -5.3646e-04, -3.4403e-05,  ...,  4.2221e-03,\n",
      "        -5.7474e-03,  1.1350e-02])\n",
      "G is: \n",
      "tensor([[0.0056, 0.0314],\n",
      "        [0.0314, 0.4952]])\n",
      "eig is:\n",
      "tensor([[0.0036, 0.0000],\n",
      "        [0.4972, 0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0396, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0411, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:35 | [trpo_pendulum] epoch #16 | Saving snapshot...\n",
      "2022-08-23 10:37:35 | [trpo_pendulum] epoch #16 | Saved\n",
      "2022-08-23 10:37:35 | [trpo_pendulum] epoch #16 | Time 16.97 s\n",
      "2022-08-23 10:37:35 | [trpo_pendulum] epoch #16 | EpochTime 0.97 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -3.70991\n",
      "Evaluation/AverageReturn               -39.3664\n",
      "Evaluation/Iteration                    16\n",
      "Evaluation/MaxReturn                   -37.9424\n",
      "Evaluation/MinReturn                   -40.7903\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     1.42399\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.907581\n",
      "GaussianMLPPolicy/KL                     0.0094564\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0410555\n",
      "GaussianMLPPolicy/LossBefore            -0.0396074\n",
      "GaussianMLPPolicy/dLoss                  0.00144809\n",
      "GaussianMLPValueFunction/LossAfter       1.30753\n",
      "GaussianMLPValueFunction/LossBefore      1.31967\n",
      "GaussianMLPValueFunction/dLoss           0.0121481\n",
      "TotalEnvSteps                        33966\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.7021e-02,  1.3490e-03, -7.2403e-05,  ...,  1.5783e-02,\n",
      "        -1.6837e-02,  3.7249e-02])\n",
      "G is: \n",
      "tensor([[0.0173, 0.2299],\n",
      "        [0.2299, 4.9343]])\n",
      "eig is:\n",
      "tensor([[0.0066, 0.0000],\n",
      "        [4.9451, 0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0338, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0349, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:36 | [trpo_pendulum] epoch #17 | Saving snapshot...\n",
      "2022-08-23 10:37:36 | [trpo_pendulum] epoch #17 | Saved\n",
      "2022-08-23 10:37:36 | [trpo_pendulum] epoch #17 | Time 17.97 s\n",
      "2022-08-23 10:37:36 | [trpo_pendulum] epoch #17 | EpochTime 0.99 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -4.01228\n",
      "Evaluation/AverageReturn               -38.366\n",
      "Evaluation/Iteration                    17\n",
      "Evaluation/MaxReturn                   -38.1595\n",
      "Evaluation/MinReturn                   -38.5724\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.206464\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.891801\n",
      "GaussianMLPPolicy/KL                     0.00521545\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0349353\n",
      "GaussianMLPPolicy/LossBefore            -0.03376\n",
      "GaussianMLPPolicy/dLoss                  0.00117525\n",
      "GaussianMLPValueFunction/LossAfter       1.32177\n",
      "GaussianMLPValueFunction/LossBefore      1.3337\n",
      "GaussianMLPValueFunction/dLoss           0.0119312\n",
      "TotalEnvSteps                        35964\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.3116e-02,  7.8714e-04,  1.8202e-05,  ...,  1.5893e-02,\n",
      "        -1.2376e-02,  2.6282e-02])\n",
      "G is: \n",
      "tensor([[0.0120, 0.1318],\n",
      "        [0.1318, 2.7570]])\n",
      "eig is:\n",
      "tensor([[0.0057, 0.0000],\n",
      "        [2.7634, 0.0000]])\n",
      "loss before is:\n",
      "tensor(0.1704, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.1635, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:37 | [trpo_pendulum] epoch #18 | Saving snapshot...\n",
      "2022-08-23 10:37:37 | [trpo_pendulum] epoch #18 | Saved\n",
      "2022-08-23 10:37:37 | [trpo_pendulum] epoch #18 | Time 18.99 s\n",
      "2022-08-23 10:37:37 | [trpo_pendulum] epoch #18 | EpochTime 1.02 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -4.41002\n",
      "Evaluation/AverageReturn               -43.3344\n",
      "Evaluation/Iteration                    18\n",
      "Evaluation/MaxReturn                   -43.1843\n",
      "Evaluation/MinReturn                   -43.4845\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.150092\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.8178\n",
      "GaussianMLPPolicy/KL                     0.00845653\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.163524\n",
      "GaussianMLPPolicy/LossBefore             0.170359\n",
      "GaussianMLPPolicy/dLoss                  0.00683449\n",
      "GaussianMLPValueFunction/LossAfter       1.30467\n",
      "GaussianMLPValueFunction/LossBefore      1.39687\n",
      "GaussianMLPValueFunction/dLoss           0.0922076\n",
      "TotalEnvSteps                        37962\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.9880e-02,  4.9333e-03, -1.8231e-05,  ...,  1.6471e-02,\n",
      "        -1.5057e-02,  3.4338e-02])\n",
      "G is: \n",
      "tensor([[1.8127e-02, 7.3482e-01],\n",
      "        [7.3482e-01, 3.4272e+01]])\n",
      "eig is:\n",
      "tensor([[2.3727e-03, 0.0000e+00],\n",
      "        [3.4288e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.2313, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.2315, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:38 | [trpo_pendulum] epoch #19 | Saving snapshot...\n",
      "2022-08-23 10:37:38 | [trpo_pendulum] epoch #19 | Saved\n",
      "2022-08-23 10:37:38 | [trpo_pendulum] epoch #19 | Time 19.93 s\n",
      "2022-08-23 10:37:38 | [trpo_pendulum] epoch #19 | EpochTime 0.94 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -3.85523\n",
      "Evaluation/AverageReturn               -36.1214\n",
      "Evaluation/Iteration                    19\n",
      "Evaluation/MaxReturn                   -34.5997\n",
      "Evaluation/MinReturn                   -37.6431\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     1.52171\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.799482\n",
      "GaussianMLPPolicy/KL                     0.00592494\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.231484\n",
      "GaussianMLPPolicy/LossBefore            -0.231275\n",
      "GaussianMLPPolicy/dLoss                  0.000208259\n",
      "GaussianMLPValueFunction/LossAfter       1.23945\n",
      "GaussianMLPValueFunction/LossBefore      1.45125\n",
      "GaussianMLPValueFunction/dLoss           0.2118\n",
      "TotalEnvSteps                        39960\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.6802e-02,  6.5780e-03,  3.2806e-05,  ...,  2.0998e-02,\n",
      "        -2.1635e-02,  3.3501e-02])\n",
      "G is: \n",
      "tensor([[2.1830e-02, 9.5254e-01],\n",
      "        [9.5254e-01, 4.7124e+01]])\n",
      "eig is:\n",
      "tensor([[2.5787e-03, 0.0000e+00],\n",
      "        [4.7144e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.0523, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0513, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:39 | [trpo_pendulum] epoch #20 | Saving snapshot...\n",
      "2022-08-23 10:37:39 | [trpo_pendulum] epoch #20 | Saved\n",
      "2022-08-23 10:37:39 | [trpo_pendulum] epoch #20 | Time 20.96 s\n",
      "2022-08-23 10:37:39 | [trpo_pendulum] epoch #20 | EpochTime 1.02 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -3.58838\n",
      "Evaluation/AverageReturn               -37.1\n",
      "Evaluation/Iteration                    20\n",
      "Evaluation/MaxReturn                   -37.0452\n",
      "Evaluation/MinReturn                   -37.1548\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.0547651\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.786821\n",
      "GaussianMLPPolicy/KL                     0.00588041\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.0512604\n",
      "GaussianMLPPolicy/LossBefore             0.0522634\n",
      "GaussianMLPPolicy/dLoss                  0.00100302\n",
      "GaussianMLPValueFunction/LossAfter       1.16938\n",
      "GaussianMLPValueFunction/LossBefore      1.19471\n",
      "GaussianMLPValueFunction/dLoss           0.0253297\n",
      "TotalEnvSteps                        41958\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 0.0349,  0.0124,  0.0002,  ...,  0.0299, -0.0303,  0.0502])\n",
      "G is: \n",
      "tensor([[4.2025e-02, 2.1108e+00],\n",
      "        [2.1108e+00, 1.1060e+02]])\n",
      "eig is:\n",
      "tensor([[1.7395e-03, 0.0000e+00],\n",
      "        [1.1064e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0510, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0553, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:40 | [trpo_pendulum] epoch #21 | Saving snapshot...\n",
      "2022-08-23 10:37:40 | [trpo_pendulum] epoch #21 | Saved\n",
      "2022-08-23 10:37:40 | [trpo_pendulum] epoch #21 | Time 21.96 s\n",
      "2022-08-23 10:37:40 | [trpo_pendulum] epoch #21 | EpochTime 1.00 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -3.48463\n",
      "Evaluation/AverageReturn               -35.4419\n",
      "Evaluation/Iteration                    21\n",
      "Evaluation/MaxReturn                   -34.942\n",
      "Evaluation/MinReturn                   -35.9417\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.49988\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.732727\n",
      "GaussianMLPPolicy/KL                     0.00914708\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0552833\n",
      "GaussianMLPPolicy/LossBefore            -0.051047\n",
      "GaussianMLPPolicy/dLoss                  0.00423626\n",
      "GaussianMLPValueFunction/LossAfter       1.17993\n",
      "GaussianMLPValueFunction/LossBefore      1.20555\n",
      "GaussianMLPValueFunction/dLoss           0.0256143\n",
      "TotalEnvSteps                        43956\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 0.1397,  0.1443, -0.0060,  ...,  0.1240, -0.1380,  0.1894])\n",
      "G is: \n",
      "tensor([[1.2883e+00, 1.0242e+02],\n",
      "        [1.0242e+02, 8.9717e+03]])\n",
      "eig is:\n",
      "tensor([[1.1914e-01, 0.0000e+00],\n",
      "        [8.9728e+03, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(1.1501, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(1.1195, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:41 | [trpo_pendulum] epoch #22 | Saving snapshot...\n",
      "2022-08-23 10:37:41 | [trpo_pendulum] epoch #22 | Saved\n",
      "2022-08-23 10:37:41 | [trpo_pendulum] epoch #22 | Time 22.95 s\n",
      "2022-08-23 10:37:41 | [trpo_pendulum] epoch #22 | EpochTime 0.98 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -3.12863\n",
      "Evaluation/AverageReturn               -68.5475\n",
      "Evaluation/Iteration                    22\n",
      "Evaluation/MaxReturn                   -33.8067\n",
      "Evaluation/MinReturn                  -103.288\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                    34.7408\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.707505\n",
      "GaussianMLPPolicy/KL                     0.00788899\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              1.11952\n",
      "GaussianMLPPolicy/LossBefore             1.1501\n",
      "GaussianMLPPolicy/dLoss                  0.0305797\n",
      "GaussianMLPValueFunction/LossAfter      11.0482\n",
      "GaussianMLPValueFunction/LossBefore     22.5534\n",
      "GaussianMLPValueFunction/dLoss          11.5052\n",
      "TotalEnvSteps                        45954\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.6401e-02,  9.4495e-02,  1.0218e-04,  ...,  1.2287e-01,\n",
      "        -1.0688e-01,  1.7653e-01])\n",
      "G is: \n",
      "tensor([[8.2652e-01, 6.6498e+01],\n",
      "        [6.6498e+01, 5.5918e+03]])\n",
      "eig is:\n",
      "tensor([[3.6133e-02, 0.0000e+00],\n",
      "        [5.5926e+03, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.9921, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-1.0063, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:42 | [trpo_pendulum] epoch #23 | Saving snapshot...\n",
      "2022-08-23 10:37:42 | [trpo_pendulum] epoch #23 | Saved\n",
      "2022-08-23 10:37:42 | [trpo_pendulum] epoch #23 | Time 23.95 s\n",
      "2022-08-23 10:37:42 | [trpo_pendulum] epoch #23 | EpochTime 0.99 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -3.24637\n",
      "Evaluation/AverageReturn               -40.526\n",
      "Evaluation/Iteration                    23\n",
      "Evaluation/MaxReturn                   -28.7071\n",
      "Evaluation/MinReturn                   -52.3448\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                    11.8189\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.696688\n",
      "GaussianMLPPolicy/KL                     0.00586281\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -1.00629\n",
      "GaussianMLPPolicy/LossBefore            -0.99206\n",
      "GaussianMLPPolicy/dLoss                  0.0142257\n",
      "GaussianMLPValueFunction/LossAfter       2.63764\n",
      "GaussianMLPValueFunction/LossBefore      5.22527\n",
      "GaussianMLPValueFunction/dLoss           2.58764\n",
      "TotalEnvSteps                        47952\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 0.0072,  0.0549, -0.0003,  ...,  0.0033, -0.0529, -0.0114])\n",
      "G is: \n",
      "tensor([[  0.1441,   2.2691],\n",
      "        [  2.2691, 108.7965]])\n",
      "eig is:\n",
      "tensor([[9.6695e-02, 0.0000e+00],\n",
      "        [1.0884e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.4145, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.4015, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:43 | [trpo_pendulum] epoch #24 | Saving snapshot...\n",
      "2022-08-23 10:37:43 | [trpo_pendulum] epoch #24 | Saved\n",
      "2022-08-23 10:37:43 | [trpo_pendulum] epoch #24 | Time 24.93 s\n",
      "2022-08-23 10:37:43 | [trpo_pendulum] epoch #24 | EpochTime 0.97 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -2.86183\n",
      "Evaluation/AverageReturn               -53.2631\n",
      "Evaluation/Iteration                    24\n",
      "Evaluation/MaxReturn                   -51.9086\n",
      "Evaluation/MinReturn                   -54.6175\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     1.35444\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.694903\n",
      "GaussianMLPPolicy/KL                     0.00655504\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.401485\n",
      "GaussianMLPPolicy/LossBefore             0.414483\n",
      "GaussianMLPPolicy/dLoss                  0.0129984\n",
      "GaussianMLPValueFunction/LossAfter       2.77198\n",
      "GaussianMLPValueFunction/LossBefore      3.35974\n",
      "GaussianMLPValueFunction/dLoss           0.587753\n",
      "TotalEnvSteps                        49950\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 0.0793,  0.0362, -0.0009,  ...,  0.0481, -0.0505,  0.0643])\n",
      "G is: \n",
      "tensor([[1.4680e-01, 1.1074e+01],\n",
      "        [1.1074e+01, 9.4990e+02]])\n",
      "eig is:\n",
      "tensor([[1.7700e-02, 0.0000e+00],\n",
      "        [9.5003e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.3423, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.3533, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:44 | [trpo_pendulum] epoch #25 | Saving snapshot...\n",
      "2022-08-23 10:37:44 | [trpo_pendulum] epoch #25 | Saved\n",
      "2022-08-23 10:37:44 | [trpo_pendulum] epoch #25 | Time 25.89 s\n",
      "2022-08-23 10:37:44 | [trpo_pendulum] epoch #25 | EpochTime 0.95 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn      -2.37921\n",
      "Evaluation/AverageReturn               -43.9367\n",
      "Evaluation/Iteration                    25\n",
      "Evaluation/MaxReturn                   -41.3754\n",
      "Evaluation/MinReturn                   -46.498\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     2.56127\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.650084\n",
      "GaussianMLPPolicy/KL                     0.0078909\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.353314\n",
      "GaussianMLPPolicy/LossBefore            -0.34234\n",
      "GaussianMLPPolicy/dLoss                  0.0109742\n",
      "GaussianMLPValueFunction/LossAfter       1.96218\n",
      "GaussianMLPValueFunction/LossBefore      2.20713\n",
      "GaussianMLPValueFunction/dLoss           0.244955\n",
      "TotalEnvSteps                        51948\n",
      "-----------------------------------  -------------\n",
      "flat loss grads is: \n",
      "tensor([ 0.0766, -0.0073, -0.0007,  ..., -0.0197,  0.0143, -0.0273])\n",
      "G is: \n",
      "tensor([[2.1895e-02, 1.6025e+00],\n",
      "        [1.6025e+00, 1.5831e+02]])\n",
      "eig is:\n",
      "tensor([[5.6763e-03, 0.0000e+00],\n",
      "        [1.5833e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.6935, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.7008, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:45 | [trpo_pendulum] epoch #26 | Saving snapshot...\n",
      "2022-08-23 10:37:45 | [trpo_pendulum] epoch #26 | Saved\n",
      "2022-08-23 10:37:45 | [trpo_pendulum] epoch #26 | Time 26.89 s\n",
      "2022-08-23 10:37:45 | [trpo_pendulum] epoch #26 | EpochTime 1.00 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -2.06704\n",
      "Evaluation/AverageReturn               -24.1301\n",
      "Evaluation/Iteration                    26\n",
      "Evaluation/MaxReturn                   -23.3211\n",
      "Evaluation/MinReturn                   -24.9392\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.809076\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.574768\n",
      "GaussianMLPPolicy/KL                     0.00948643\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.700807\n",
      "GaussianMLPPolicy/LossBefore            -0.693467\n",
      "GaussianMLPPolicy/dLoss                  0.00733978\n",
      "GaussianMLPValueFunction/LossAfter       1.26432\n",
      "GaussianMLPValueFunction/LossBefore      2.41655\n",
      "GaussianMLPValueFunction/dLoss           1.15223\n",
      "TotalEnvSteps                        53946\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.0570e-02,  3.3940e-03,  3.6485e-05,  ...,  2.6388e-02,\n",
      "        -1.8141e-02,  3.1791e-02])\n",
      "G is: \n",
      "tensor([[1.6161e-02, 1.2362e+00],\n",
      "        [1.2362e+00, 1.0012e+02]])\n",
      "eig is:\n",
      "tensor([[9.0027e-04, 0.0000e+00],\n",
      "        [1.0014e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.1205, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.1211, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:46 | [trpo_pendulum] epoch #27 | Saving snapshot...\n",
      "2022-08-23 10:37:46 | [trpo_pendulum] epoch #27 | Saved\n",
      "2022-08-23 10:37:46 | [trpo_pendulum] epoch #27 | Time 27.91 s\n",
      "2022-08-23 10:37:46 | [trpo_pendulum] epoch #27 | EpochTime 1.02 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -2.13361\n",
      "Evaluation/AverageReturn               -20.6274\n",
      "Evaluation/Iteration                    27\n",
      "Evaluation/MaxReturn                   -20.529\n",
      "Evaluation/MinReturn                   -20.7259\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.0984662\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.526024\n",
      "GaussianMLPPolicy/KL                     0.00722389\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.121127\n",
      "GaussianMLPPolicy/LossBefore            -0.120459\n",
      "GaussianMLPPolicy/dLoss                  0.000668392\n",
      "GaussianMLPValueFunction/LossAfter       1.21005\n",
      "GaussianMLPValueFunction/LossBefore      1.25827\n",
      "GaussianMLPValueFunction/dLoss           0.0482206\n",
      "TotalEnvSteps                        55944\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.4733e-02,  1.4027e-02,  3.3481e-05,  ...,  3.4384e-02,\n",
      "        -2.8399e-02,  4.0469e-02])\n",
      "G is: \n",
      "tensor([[3.5041e-02, 3.0010e+00],\n",
      "        [3.0010e+00, 2.8567e+02]])\n",
      "eig is:\n",
      "tensor([[3.5095e-03, 0.0000e+00],\n",
      "        [2.8570e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.1713, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.1665, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:47 | [trpo_pendulum] epoch #28 | Saving snapshot...\n",
      "2022-08-23 10:37:47 | [trpo_pendulum] epoch #28 | Saved\n",
      "2022-08-23 10:37:47 | [trpo_pendulum] epoch #28 | Time 28.90 s\n",
      "2022-08-23 10:37:47 | [trpo_pendulum] epoch #28 | EpochTime 0.98 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -2.11883\n",
      "Evaluation/AverageReturn               -25.8707\n",
      "Evaluation/Iteration                    28\n",
      "Evaluation/MaxReturn                   -19.6724\n",
      "Evaluation/MinReturn                   -32.0691\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     6.19837\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.47793\n",
      "GaussianMLPPolicy/KL                     0.00773468\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.166513\n",
      "GaussianMLPPolicy/LossBefore             0.1713\n",
      "GaussianMLPPolicy/dLoss                  0.00478749\n",
      "GaussianMLPValueFunction/LossAfter       1.40963\n",
      "GaussianMLPValueFunction/LossBefore      1.50987\n",
      "GaussianMLPValueFunction/dLoss           0.100247\n",
      "TotalEnvSteps                        57942\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 0.0409,  0.0021,  0.0001,  ...,  0.0043, -0.0059,  0.0049])\n",
      "G is: \n",
      "tensor([[2.8786e-03, 9.1478e-02],\n",
      "        [9.1478e-02, 8.9037e+00]])\n",
      "eig is:\n",
      "tensor([[1.9379e-03, 0.0000e+00],\n",
      "        [8.9046e+00, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.1717, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.1767, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:48 | [trpo_pendulum] epoch #29 | Saving snapshot...\n",
      "2022-08-23 10:37:48 | [trpo_pendulum] epoch #29 | Saved\n",
      "2022-08-23 10:37:48 | [trpo_pendulum] epoch #29 | Time 29.86 s\n",
      "2022-08-23 10:37:48 | [trpo_pendulum] epoch #29 | EpochTime 0.95 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -1.72198\n",
      "Evaluation/AverageReturn               -20.7262\n",
      "Evaluation/Iteration                    29\n",
      "Evaluation/MaxReturn                   -20.2465\n",
      "Evaluation/MinReturn                   -21.2058\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.47967\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.429621\n",
      "GaussianMLPPolicy/KL                     0.00857614\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.176691\n",
      "GaussianMLPPolicy/LossBefore            -0.171727\n",
      "GaussianMLPPolicy/dLoss                  0.00496332\n",
      "GaussianMLPValueFunction/LossAfter       1.18648\n",
      "GaussianMLPValueFunction/LossBefore      1.27342\n",
      "GaussianMLPValueFunction/dLoss           0.0869439\n",
      "TotalEnvSteps                        59940\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 0.0241,  0.0047, -0.0002,  ...,  0.0067, -0.0053,  0.0078])\n",
      "G is: \n",
      "tensor([[2.4865e-03, 1.7133e-01],\n",
      "        [1.7133e-01, 1.8145e+01]])\n",
      "eig is:\n",
      "tensor([[8.6975e-04, 0.0000e+00],\n",
      "        [1.8147e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.1159, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.1172, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:49 | [trpo_pendulum] epoch #30 | Saving snapshot...\n",
      "2022-08-23 10:37:49 | [trpo_pendulum] epoch #30 | Saved\n",
      "2022-08-23 10:37:49 | [trpo_pendulum] epoch #30 | Time 30.95 s\n",
      "2022-08-23 10:37:49 | [trpo_pendulum] epoch #30 | EpochTime 1.09 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -1.76166\n",
      "Evaluation/AverageReturn               -17.446\n",
      "Evaluation/Iteration                    30\n",
      "Evaluation/MaxReturn                   -16.2023\n",
      "Evaluation/MinReturn                   -18.6897\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     1.24371\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.410249\n",
      "GaussianMLPPolicy/KL                     0.00455887\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.117248\n",
      "GaussianMLPPolicy/LossBefore            -0.11594\n",
      "GaussianMLPPolicy/dLoss                  0.00130754\n",
      "GaussianMLPValueFunction/LossAfter       1.15331\n",
      "GaussianMLPValueFunction/LossBefore      1.20704\n",
      "GaussianMLPValueFunction/dLoss           0.0537295\n",
      "TotalEnvSteps                        61938\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 0.0203,  0.0086, -0.0001,  ...,  0.0287, -0.0091,  0.0349])\n",
      "G is: \n",
      "tensor([[1.7535e-02, 1.8208e+00],\n",
      "        [1.8208e+00, 1.9348e+02]])\n",
      "eig is:\n",
      "tensor([[3.9673e-04, 0.0000e+00],\n",
      "        [1.9350e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0490, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0490, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:50 | [trpo_pendulum] epoch #31 | Saving snapshot...\n",
      "2022-08-23 10:37:50 | [trpo_pendulum] epoch #31 | Saved\n",
      "2022-08-23 10:37:50 | [trpo_pendulum] epoch #31 | Time 31.92 s\n",
      "2022-08-23 10:37:50 | [trpo_pendulum] epoch #31 | EpochTime 0.97 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -1.54256\n",
      "Evaluation/AverageReturn               -15.6826\n",
      "Evaluation/Iteration                    31\n",
      "Evaluation/MaxReturn                   -15.3486\n",
      "Evaluation/MinReturn                   -16.0165\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.333968\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.403991\n",
      "GaussianMLPPolicy/KL                     0.000259196\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0490224\n",
      "GaussianMLPPolicy/LossBefore            -0.0490188\n",
      "GaussianMLPPolicy/dLoss                  3.58745e-06\n",
      "GaussianMLPValueFunction/LossAfter       1.12111\n",
      "GaussianMLPValueFunction/LossBefore      1.14867\n",
      "GaussianMLPValueFunction/dLoss           0.027558\n",
      "TotalEnvSteps                        63936\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.8083e-02,  6.7496e-03,  2.6065e-05,  ...,  1.8547e-02,\n",
      "        -9.1086e-03,  2.1724e-02])\n",
      "G is: \n",
      "tensor([[7.2679e-03, 6.3186e-01],\n",
      "        [6.3186e-01, 6.0724e+01]])\n",
      "eig is:\n",
      "tensor([[6.9427e-04, 0.0000e+00],\n",
      "        [6.0730e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.0430, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0430, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:51 | [trpo_pendulum] epoch #32 | Saving snapshot...\n",
      "2022-08-23 10:37:51 | [trpo_pendulum] epoch #32 | Saved\n",
      "2022-08-23 10:37:51 | [trpo_pendulum] epoch #32 | Time 32.98 s\n",
      "2022-08-23 10:37:51 | [trpo_pendulum] epoch #32 | EpochTime 1.06 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -1.53226\n",
      "Evaluation/AverageReturn               -16.9144\n",
      "Evaluation/Iteration                    32\n",
      "Evaluation/MaxReturn                   -16.8\n",
      "Evaluation/MinReturn                   -17.0288\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.114392\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.391484\n",
      "GaussianMLPPolicy/KL                     0.00130081\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.0429658\n",
      "GaussianMLPPolicy/LossBefore             0.0429909\n",
      "GaussianMLPPolicy/dLoss                  2.51196e-05\n",
      "GaussianMLPValueFunction/LossAfter       1.10202\n",
      "GaussianMLPValueFunction/LossBefore      1.13051\n",
      "GaussianMLPValueFunction/dLoss           0.0284904\n",
      "TotalEnvSteps                        65934\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 0.0270,  0.0208, -0.0003,  ...,  0.0482, -0.0265,  0.0565])\n",
      "G is: \n",
      "tensor([[5.8083e-02, 5.8308e+00],\n",
      "        [5.8308e+00, 6.2152e+02]])\n",
      "eig is:\n",
      "tensor([[3.4180e-03, 0.0000e+00],\n",
      "        [6.2157e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.0928, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0909, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:52 | [trpo_pendulum] epoch #33 | Saving snapshot...\n",
      "2022-08-23 10:37:52 | [trpo_pendulum] epoch #33 | Saved\n",
      "2022-08-23 10:37:52 | [trpo_pendulum] epoch #33 | Time 33.96 s\n",
      "2022-08-23 10:37:52 | [trpo_pendulum] epoch #33 | EpochTime 0.97 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -1.65705\n",
      "Evaluation/AverageReturn               -19.9173\n",
      "Evaluation/Iteration                    33\n",
      "Evaluation/MaxReturn                   -16.2186\n",
      "Evaluation/MinReturn                   -23.616\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     3.69872\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.348062\n",
      "GaussianMLPPolicy/KL                     0.00800107\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.0909089\n",
      "GaussianMLPPolicy/LossBefore             0.0927692\n",
      "GaussianMLPPolicy/dLoss                  0.0018603\n",
      "GaussianMLPValueFunction/LossAfter       1.16947\n",
      "GaussianMLPValueFunction/LossBefore      1.21747\n",
      "GaussianMLPValueFunction/dLoss           0.0479996\n",
      "TotalEnvSteps                        67932\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.9049e-02,  8.4225e-03,  7.1108e-05,  ...,  2.9672e-02,\n",
      "        -1.5609e-02,  3.4254e-02])\n",
      "G is: \n",
      "tensor([[1.6514e-02, 1.5296e+00],\n",
      "        [1.5296e+00, 1.5315e+02]])\n",
      "eig is:\n",
      "tensor([[1.2360e-03, 0.0000e+00],\n",
      "        [1.5316e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.1374, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.1385, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:53 | [trpo_pendulum] epoch #34 | Saving snapshot...\n",
      "2022-08-23 10:37:53 | [trpo_pendulum] epoch #34 | Saved\n",
      "2022-08-23 10:37:53 | [trpo_pendulum] epoch #34 | Time 34.96 s\n",
      "2022-08-23 10:37:53 | [trpo_pendulum] epoch #34 | EpochTime 0.99 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -1.55702\n",
      "Evaluation/AverageReturn               -15.8397\n",
      "Evaluation/Iteration                    34\n",
      "Evaluation/MaxReturn                   -15.384\n",
      "Evaluation/MinReturn                   -16.2953\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.455658\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.327904\n",
      "GaussianMLPPolicy/KL                     0.00608511\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.138493\n",
      "GaussianMLPPolicy/LossBefore            -0.137375\n",
      "GaussianMLPPolicy/dLoss                  0.00111797\n",
      "GaussianMLPValueFunction/LossAfter       1.05992\n",
      "GaussianMLPValueFunction/LossBefore      1.14773\n",
      "GaussianMLPValueFunction/dLoss           0.0878071\n",
      "TotalEnvSteps                        69930\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 0.0223,  0.0058, -0.0001,  ...,  0.0146, -0.0078,  0.0169])\n",
      "G is: \n",
      "tensor([[4.7268e-03, 3.8157e-01],\n",
      "        [3.8157e-01, 3.8282e+01]])\n",
      "eig is:\n",
      "tensor([[9.2316e-04, 0.0000e+00],\n",
      "        [3.8286e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.0029, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:54 | [trpo_pendulum] epoch #35 | Saving snapshot...\n",
      "2022-08-23 10:37:54 | [trpo_pendulum] epoch #35 | Saved\n",
      "2022-08-23 10:37:54 | [trpo_pendulum] epoch #35 | Time 35.90 s\n",
      "2022-08-23 10:37:54 | [trpo_pendulum] epoch #35 | EpochTime 0.94 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -1.39572\n",
      "Evaluation/AverageReturn               -15.9875\n",
      "Evaluation/Iteration                    35\n",
      "Evaluation/MaxReturn                   -15.6676\n",
      "Evaluation/MinReturn                   -16.3074\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.319894\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.287284\n",
      "GaussianMLPPolicy/KL                     0.00918092\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.000530124\n",
      "GaussianMLPPolicy/LossBefore             0.00290286\n",
      "GaussianMLPPolicy/dLoss                  0.00237274\n",
      "GaussianMLPValueFunction/LossAfter       1.02286\n",
      "GaussianMLPValueFunction/LossBefore      1.05748\n",
      "GaussianMLPValueFunction/dLoss           0.0346239\n",
      "TotalEnvSteps                        71928\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.4577e-02,  5.8297e-03, -4.6262e-05,  ...,  3.2877e-02,\n",
      "        -4.8052e-03,  4.0466e-02])\n",
      "G is: \n",
      "tensor([[1.8503e-02, 1.8944e+00],\n",
      "        [1.8944e+00, 2.0034e+02]])\n",
      "eig is:\n",
      "tensor([[5.9509e-04, 0.0000e+00],\n",
      "        [2.0036e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.1107, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.1128, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:55 | [trpo_pendulum] epoch #36 | Saving snapshot...\n",
      "2022-08-23 10:37:55 | [trpo_pendulum] epoch #36 | Saved\n",
      "2022-08-23 10:37:55 | [trpo_pendulum] epoch #36 | Time 36.86 s\n",
      "2022-08-23 10:37:55 | [trpo_pendulum] epoch #36 | EpochTime 0.96 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -1.2739\n",
      "Evaluation/AverageReturn               -12.6418\n",
      "Evaluation/Iteration                    36\n",
      "Evaluation/MaxReturn                   -12.4359\n",
      "Evaluation/MinReturn                   -12.8477\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.205901\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.271236\n",
      "GaussianMLPPolicy/KL                     0.00737196\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.112775\n",
      "GaussianMLPPolicy/LossBefore            -0.110674\n",
      "GaussianMLPPolicy/dLoss                  0.00210093\n",
      "GaussianMLPValueFunction/LossAfter       0.961763\n",
      "GaussianMLPValueFunction/LossBefore      1.0472\n",
      "GaussianMLPValueFunction/dLoss           0.0854381\n",
      "TotalEnvSteps                        73926\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.5920e-02,  2.4226e-03,  2.0167e-05,  ...,  1.9657e-02,\n",
      "        -6.2129e-05,  2.3515e-02])\n",
      "G is: \n",
      "tensor([[6.0321e-03, 5.9459e-01],\n",
      "        [5.9459e-01, 6.1312e+01]])\n",
      "eig is:\n",
      "tensor([[2.6703e-04, 0.0000e+00],\n",
      "        [6.1317e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0276, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0289, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:56 | [trpo_pendulum] epoch #37 | Saving snapshot...\n",
      "2022-08-23 10:37:56 | [trpo_pendulum] epoch #37 | Saved\n",
      "2022-08-23 10:37:56 | [trpo_pendulum] epoch #37 | Time 37.85 s\n",
      "2022-08-23 10:37:56 | [trpo_pendulum] epoch #37 | EpochTime 0.99 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -1.27124\n",
      "Evaluation/AverageReturn               -11.8927\n",
      "Evaluation/Iteration                    37\n",
      "Evaluation/MaxReturn                   -11.7608\n",
      "Evaluation/MinReturn                   -12.0245\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.131865\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.233535\n",
      "GaussianMLPPolicy/KL                     0.00542798\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0289067\n",
      "GaussianMLPPolicy/LossBefore            -0.0276054\n",
      "GaussianMLPPolicy/dLoss                  0.00130131\n",
      "GaussianMLPValueFunction/LossAfter       0.907333\n",
      "GaussianMLPValueFunction/LossBefore      0.956381\n",
      "GaussianMLPValueFunction/dLoss           0.0490479\n",
      "TotalEnvSteps                        75924\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 0.0190,  0.0013, -0.0001,  ...,  0.0104,  0.0007,  0.0125])\n",
      "G is: \n",
      "tensor([[2.1367e-03, 2.0923e-01],\n",
      "        [2.0923e-01, 2.4932e+01]])\n",
      "eig is:\n",
      "tensor([[3.8147e-04, 0.0000e+00],\n",
      "        [2.4934e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0165, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0173, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:57 | [trpo_pendulum] epoch #38 | Saving snapshot...\n",
      "2022-08-23 10:37:57 | [trpo_pendulum] epoch #38 | Saved\n",
      "2022-08-23 10:37:57 | [trpo_pendulum] epoch #38 | Time 38.85 s\n",
      "2022-08-23 10:37:57 | [trpo_pendulum] epoch #38 | EpochTime 0.99 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -1.12274\n",
      "Evaluation/AverageReturn               -11.4219\n",
      "Evaluation/Iteration                    38\n",
      "Evaluation/MaxReturn                   -11.0972\n",
      "Evaluation/MinReturn                   -11.7465\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.324648\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.219737\n",
      "GaussianMLPPolicy/KL                     0.00563307\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0172903\n",
      "GaussianMLPPolicy/LossBefore            -0.0165058\n",
      "GaussianMLPPolicy/dLoss                  0.000784533\n",
      "GaussianMLPValueFunction/LossAfter       0.855513\n",
      "GaussianMLPValueFunction/LossBefore      0.906706\n",
      "GaussianMLPValueFunction/dLoss           0.0511932\n",
      "TotalEnvSteps                        77922\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.0240e-02,  1.4934e-03,  2.4041e-06,  ...,  9.1506e-03,\n",
      "        -1.3971e-03,  1.0852e-02])\n",
      "G is: \n",
      "tensor([[1.6967e-03, 1.4688e-01],\n",
      "        [1.4688e-01, 1.6847e+01]])\n",
      "eig is:\n",
      "tensor([[4.1771e-04, 0.0000e+00],\n",
      "        [1.6848e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0552, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0553, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:58 | [trpo_pendulum] epoch #39 | Saving snapshot...\n",
      "2022-08-23 10:37:58 | [trpo_pendulum] epoch #39 | Saved\n",
      "2022-08-23 10:37:58 | [trpo_pendulum] epoch #39 | Time 39.83 s\n",
      "2022-08-23 10:37:58 | [trpo_pendulum] epoch #39 | EpochTime 0.97 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -0.890313\n",
      "Evaluation/AverageReturn                -9.68333\n",
      "Evaluation/Iteration                    39\n",
      "Evaluation/MaxReturn                    -9.56263\n",
      "Evaluation/MinReturn                    -9.80403\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.120699\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.204846\n",
      "GaussianMLPPolicy/KL                     0.00265433\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0552999\n",
      "GaussianMLPPolicy/LossBefore            -0.055196\n",
      "GaussianMLPPolicy/dLoss                  0.000103839\n",
      "GaussianMLPValueFunction/LossAfter       0.798615\n",
      "GaussianMLPValueFunction/LossBefore      0.867623\n",
      "GaussianMLPValueFunction/dLoss           0.0690085\n",
      "TotalEnvSteps                        79920\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.3214e-02,  2.7967e-03,  2.4045e-05,  ...,  1.9342e-02,\n",
      "        -1.4043e-03,  2.3041e-02])\n",
      "G is: \n",
      "tensor([[5.9388e-03, 6.1749e-01],\n",
      "        [6.1749e-01, 7.0593e+01]])\n",
      "eig is:\n",
      "tensor([[5.3406e-04, 0.0000e+00],\n",
      "        [7.0599e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.0026, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0006, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:37:59 | [trpo_pendulum] epoch #40 | Saving snapshot...\n",
      "2022-08-23 10:37:59 | [trpo_pendulum] epoch #40 | Saved\n",
      "2022-08-23 10:37:59 | [trpo_pendulum] epoch #40 | Time 40.85 s\n",
      "2022-08-23 10:37:59 | [trpo_pendulum] epoch #40 | EpochTime 1.02 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -0.933573\n",
      "Evaluation/AverageReturn                -9.73778\n",
      "Evaluation/Iteration                    40\n",
      "Evaluation/MaxReturn                    -9.16395\n",
      "Evaluation/MinReturn                   -10.3116\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.573825\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.149538\n",
      "GaussianMLPPolicy/KL                     0.00911239\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.000637153\n",
      "GaussianMLPPolicy/LossBefore             0.00261578\n",
      "GaussianMLPPolicy/dLoss                  0.00197863\n",
      "GaussianMLPValueFunction/LossAfter       0.747416\n",
      "GaussianMLPValueFunction/LossBefore      0.803113\n",
      "GaussianMLPValueFunction/dLoss           0.0556971\n",
      "TotalEnvSteps                        81918\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.2615e-02,  3.9278e-03,  1.0398e-05,  ...,  1.4178e-02,\n",
      "        -1.7042e-03,  1.7167e-02])\n",
      "G is: \n",
      "tensor([[3.8093e-03, 5.2902e-01],\n",
      "        [5.2902e-01, 7.7703e+01]])\n",
      "eig is:\n",
      "tensor([[2.0599e-04, 0.0000e+00],\n",
      "        [7.7707e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0321, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0334, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:00 | [trpo_pendulum] epoch #41 | Saving snapshot...\n",
      "2022-08-23 10:38:00 | [trpo_pendulum] epoch #41 | Saved\n",
      "2022-08-23 10:38:00 | [trpo_pendulum] epoch #41 | Time 41.85 s\n",
      "2022-08-23 10:38:00 | [trpo_pendulum] epoch #41 | EpochTime 0.99 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -0.811484\n",
      "Evaluation/AverageReturn                -8.74036\n",
      "Evaluation/Iteration                    41\n",
      "Evaluation/MaxReturn                    -8.60884\n",
      "Evaluation/MinReturn                    -8.87187\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.131513\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.0859016\n",
      "GaussianMLPPolicy/KL                     0.00679246\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0333654\n",
      "GaussianMLPPolicy/LossBefore            -0.0321475\n",
      "GaussianMLPPolicy/dLoss                  0.00121789\n",
      "GaussianMLPValueFunction/LossAfter       0.659705\n",
      "GaussianMLPValueFunction/LossBefore      0.730679\n",
      "GaussianMLPValueFunction/dLoss           0.0709744\n",
      "TotalEnvSteps                        83916\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.8668e-03,  1.4237e-03, -2.2321e-05,  ...,  6.1916e-03,\n",
      "        -4.5677e-04,  7.4585e-03])\n",
      "G is: \n",
      "tensor([[7.5418e-04, 1.1620e-01],\n",
      "        [1.1620e-01, 2.0025e+01]])\n",
      "eig is:\n",
      "tensor([[7.8201e-05, 0.0000e+00],\n",
      "        [2.0026e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0421, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0425, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:01 | [trpo_pendulum] epoch #42 | Saving snapshot...\n",
      "2022-08-23 10:38:01 | [trpo_pendulum] epoch #42 | Saved\n",
      "2022-08-23 10:38:01 | [trpo_pendulum] epoch #42 | Time 42.89 s\n",
      "2022-08-23 10:38:01 | [trpo_pendulum] epoch #42 | EpochTime 1.04 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -0.754523\n",
      "Evaluation/AverageReturn                -7.52964\n",
      "Evaluation/Iteration                    42\n",
      "Evaluation/MaxReturn                    -7.36317\n",
      "Evaluation/MinReturn                    -7.69612\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.166475\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.0762758\n",
      "GaussianMLPPolicy/KL                     0.00933621\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.042508\n",
      "GaussianMLPPolicy/LossBefore            -0.0421142\n",
      "GaussianMLPPolicy/dLoss                  0.000393786\n",
      "GaussianMLPValueFunction/LossAfter       0.589045\n",
      "GaussianMLPValueFunction/LossBefore      0.66979\n",
      "GaussianMLPValueFunction/dLoss           0.0807452\n",
      "TotalEnvSteps                        85914\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.2047e-02,  2.2196e-03,  1.0987e-05,  ...,  9.5778e-03,\n",
      "        -1.2617e-03,  1.1451e-02])\n",
      "G is: \n",
      "tensor([[1.7914e-03, 2.8967e-01],\n",
      "        [2.8967e-01, 5.1057e+01]])\n",
      "eig is:\n",
      "tensor([[1.5259e-04, 0.0000e+00],\n",
      "        [5.1059e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0135, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0143, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:02 | [trpo_pendulum] epoch #43 | Saving snapshot...\n",
      "2022-08-23 10:38:02 | [trpo_pendulum] epoch #43 | Saved\n",
      "2022-08-23 10:38:02 | [trpo_pendulum] epoch #43 | Time 43.86 s\n",
      "2022-08-23 10:38:02 | [trpo_pendulum] epoch #43 | EpochTime 0.96 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -0.650263\n",
      "Evaluation/AverageReturn                -7.07724\n",
      "Evaluation/Iteration                    43\n",
      "Evaluation/MaxReturn                    -6.86538\n",
      "Evaluation/MinReturn                    -7.28909\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.211853\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.0224892\n",
      "GaussianMLPPolicy/KL                     0.00589256\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.014315\n",
      "GaussianMLPPolicy/LossBefore            -0.0134533\n",
      "GaussianMLPPolicy/dLoss                  0.00086171\n",
      "GaussianMLPValueFunction/LossAfter       0.518833\n",
      "GaussianMLPValueFunction/LossBefore      0.588884\n",
      "GaussianMLPValueFunction/dLoss           0.0700513\n",
      "TotalEnvSteps                        87912\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.6253e-02,  1.5479e-03,  1.0346e-05,  ...,  3.4773e-03,\n",
      "        -9.3107e-04,  4.1154e-03])\n",
      "G is: \n",
      "tensor([[5.4487e-04, 5.4474e-02],\n",
      "        [5.4474e-02, 1.1127e+01]])\n",
      "eig is:\n",
      "tensor([[2.7752e-04, 0.0000e+00],\n",
      "        [1.1127e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0151, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0164, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:03 | [trpo_pendulum] epoch #44 | Saving snapshot...\n",
      "2022-08-23 10:38:03 | [trpo_pendulum] epoch #44 | Saved\n",
      "2022-08-23 10:38:03 | [trpo_pendulum] epoch #44 | Time 44.85 s\n",
      "2022-08-23 10:38:03 | [trpo_pendulum] epoch #44 | EpochTime 0.98 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -0.589872\n",
      "Evaluation/AverageReturn                -6.38669\n",
      "Evaluation/Iteration                    44\n",
      "Evaluation/MaxReturn                    -6.34343\n",
      "Evaluation/MinReturn                    -6.42995\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.0432596\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy               -0.0494977\n",
      "GaussianMLPPolicy/KL                     0.0081594\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0164472\n",
      "GaussianMLPPolicy/LossBefore            -0.0151173\n",
      "GaussianMLPPolicy/dLoss                  0.00132984\n",
      "GaussianMLPValueFunction/LossAfter       0.449272\n",
      "GaussianMLPValueFunction/LossBefore      0.52092\n",
      "GaussianMLPValueFunction/dLoss           0.071648\n",
      "TotalEnvSteps                        89910\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.4175e-02,  7.9800e-06, -1.0171e-04,  ..., -3.2466e-03,\n",
      "        -1.0064e-03, -3.8865e-03])\n",
      "G is: \n",
      "tensor([[3.7958e-04, 3.3271e-02],\n",
      "        [3.3271e-02, 8.1531e+00]])\n",
      "eig is:\n",
      "tensor([[2.4414e-04, 0.0000e+00],\n",
      "        [8.1533e+00, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0310, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0323, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:04 | [trpo_pendulum] epoch #45 | Saving snapshot...\n",
      "2022-08-23 10:38:04 | [trpo_pendulum] epoch #45 | Saved\n",
      "2022-08-23 10:38:04 | [trpo_pendulum] epoch #45 | Time 45.81 s\n",
      "2022-08-23 10:38:04 | [trpo_pendulum] epoch #45 | EpochTime 0.95 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -0.519679\n",
      "Evaluation/AverageReturn                -5.50255\n",
      "Evaluation/Iteration                    45\n",
      "Evaluation/MaxReturn                    -5.24206\n",
      "Evaluation/MinReturn                    -5.76304\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.260491\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy               -0.0872039\n",
      "GaussianMLPPolicy/KL                     0.00695351\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0322902\n",
      "GaussianMLPPolicy/LossBefore            -0.0310249\n",
      "GaussianMLPPolicy/dLoss                  0.00126536\n",
      "GaussianMLPValueFunction/LossAfter       0.368433\n",
      "GaussianMLPValueFunction/LossBefore      0.451442\n",
      "GaussianMLPValueFunction/dLoss           0.0830097\n",
      "TotalEnvSteps                        91908\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.1291e-02,  8.9048e-04,  5.2483e-05,  ...,  3.3904e-03,\n",
      "        -4.5906e-04,  3.8022e-03])\n",
      "G is: \n",
      "tensor([[3.7181e-04, 7.2035e-02],\n",
      "        [7.2035e-02, 2.1406e+01]])\n",
      "eig is:\n",
      "tensor([[1.2970e-04, 0.0000e+00],\n",
      "        [2.1406e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0224, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0228, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:05 | [trpo_pendulum] epoch #46 | Saving snapshot...\n",
      "2022-08-23 10:38:05 | [trpo_pendulum] epoch #46 | Saved\n",
      "2022-08-23 10:38:05 | [trpo_pendulum] epoch #46 | Time 46.80 s\n",
      "2022-08-23 10:38:05 | [trpo_pendulum] epoch #46 | EpochTime 0.99 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -0.473701\n",
      "Evaluation/AverageReturn                -4.96241\n",
      "Evaluation/Iteration                    46\n",
      "Evaluation/MaxReturn                    -4.81956\n",
      "Evaluation/MinReturn                    -5.10527\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.142856\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy               -0.122022\n",
      "GaussianMLPPolicy/KL                     0.00840575\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.022809\n",
      "GaussianMLPPolicy/LossBefore            -0.0224015\n",
      "GaussianMLPPolicy/dLoss                  0.000407463\n",
      "GaussianMLPValueFunction/LossAfter       0.288954\n",
      "GaussianMLPValueFunction/LossBefore      0.369355\n",
      "GaussianMLPValueFunction/dLoss           0.0804008\n",
      "TotalEnvSteps                        93906\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.9081e-03,  1.4412e-03, -1.0286e-05,  ...,  8.7817e-03,\n",
      "        -2.6199e-04,  1.0101e-02])\n",
      "G is: \n",
      "tensor([[1.4685e-03, 4.1173e-01],\n",
      "        [4.1173e-01, 1.2394e+02]])\n",
      "eig is:\n",
      "tensor([[9.9182e-05, 0.0000e+00],\n",
      "        [1.2394e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0034, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0037, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:06 | [trpo_pendulum] epoch #47 | Saving snapshot...\n",
      "2022-08-23 10:38:06 | [trpo_pendulum] epoch #47 | Saved\n",
      "2022-08-23 10:38:06 | [trpo_pendulum] epoch #47 | Time 47.76 s\n",
      "2022-08-23 10:38:06 | [trpo_pendulum] epoch #47 | EpochTime 0.96 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -0.457425\n",
      "Evaluation/AverageReturn                -4.87561\n",
      "Evaluation/Iteration                    47\n",
      "Evaluation/MaxReturn                    -4.71473\n",
      "Evaluation/MinReturn                    -5.0365\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.160884\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy               -0.133237\n",
      "GaussianMLPPolicy/KL                     0.00614521\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.00372328\n",
      "GaussianMLPPolicy/LossBefore            -0.00342831\n",
      "GaussianMLPPolicy/dLoss                  0.000294978\n",
      "GaussianMLPValueFunction/LossAfter       0.214831\n",
      "GaussianMLPValueFunction/LossBefore      0.289331\n",
      "GaussianMLPValueFunction/dLoss           0.0744997\n",
      "TotalEnvSteps                        95904\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.6532e-03, -1.4181e-03,  1.8408e-05,  ..., -5.6052e-03,\n",
      "         5.2105e-04, -6.3832e-03])\n",
      "G is: \n",
      "tensor([[6.1046e-04, 1.8754e-01],\n",
      "        [1.8754e-01, 5.8566e+01]])\n",
      "eig is:\n",
      "tensor([[7.6294e-06, 0.0000e+00],\n",
      "        [5.8566e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0180, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0180, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:07 | [trpo_pendulum] epoch #48 | Saving snapshot...\n",
      "2022-08-23 10:38:07 | [trpo_pendulum] epoch #48 | Saved\n",
      "2022-08-23 10:38:07 | [trpo_pendulum] epoch #48 | Time 48.79 s\n",
      "2022-08-23 10:38:07 | [trpo_pendulum] epoch #48 | EpochTime 1.03 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -0.415795\n",
      "Evaluation/AverageReturn                -4.4304\n",
      "Evaluation/Iteration                    48\n",
      "Evaluation/MaxReturn                    -4.28723\n",
      "Evaluation/MinReturn                    -4.57357\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.14317\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy               -0.134775\n",
      "GaussianMLPPolicy/KL                     0.000107464\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0180161\n",
      "GaussianMLPPolicy/LossBefore            -0.0180153\n",
      "GaussianMLPPolicy/dLoss                  8.25152e-07\n",
      "GaussianMLPValueFunction/LossAfter       0.125518\n",
      "GaussianMLPValueFunction/LossBefore      0.20807\n",
      "GaussianMLPValueFunction/dLoss           0.0825515\n",
      "TotalEnvSteps                        97902\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.8175e-03,  1.8289e-03,  2.3392e-05,  ...,  9.1576e-03,\n",
      "        -2.7337e-04,  1.0523e-02])\n",
      "G is: \n",
      "tensor([[1.6437e-03, 4.9796e-01],\n",
      "        [4.9796e-01, 1.5827e+02]])\n",
      "eig is:\n",
      "tensor([[9.1553e-05, 0.0000e+00],\n",
      "        [1.5827e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0006, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0009, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:08 | [trpo_pendulum] epoch #49 | Saving snapshot...\n",
      "2022-08-23 10:38:08 | [trpo_pendulum] epoch #49 | Saved\n",
      "2022-08-23 10:38:08 | [trpo_pendulum] epoch #49 | Time 49.75 s\n",
      "2022-08-23 10:38:08 | [trpo_pendulum] epoch #49 | EpochTime 0.96 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -0.432551\n",
      "Evaluation/AverageReturn                -4.51509\n",
      "Evaluation/Iteration                    49\n",
      "Evaluation/MaxReturn                    -4.08122\n",
      "Evaluation/MinReturn                    -4.94895\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.433865\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy               -0.140455\n",
      "GaussianMLPPolicy/KL                     0.0097902\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.000880456\n",
      "GaussianMLPPolicy/LossBefore            -0.000614306\n",
      "GaussianMLPPolicy/dLoss                  0.00026615\n",
      "GaussianMLPValueFunction/LossAfter       0.0625575\n",
      "GaussianMLPValueFunction/LossBefore      0.136609\n",
      "GaussianMLPValueFunction/dLoss           0.0740519\n",
      "TotalEnvSteps                        99900\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.0522e-03,  4.2377e-04, -4.8717e-05,  ...,  2.2674e-03,\n",
      "        -9.7769e-05,  2.6155e-03])\n",
      "G is: \n",
      "tensor([[1.7353e-04, 2.8789e-02],\n",
      "        [2.8789e-02, 8.9901e+00]])\n",
      "eig is:\n",
      "tensor([[8.2016e-05, 0.0000e+00],\n",
      "        [8.9902e+00, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.0016, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0015, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:09 | [trpo_pendulum] epoch #50 | Saving snapshot...\n",
      "2022-08-23 10:38:09 | [trpo_pendulum] epoch #50 | Saved\n",
      "2022-08-23 10:38:09 | [trpo_pendulum] epoch #50 | Time 50.74 s\n",
      "2022-08-23 10:38:09 | [trpo_pendulum] epoch #50 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.42076\n",
      "Evaluation/AverageReturn                 -4.4967\n",
      "Evaluation/Iteration                     50\n",
      "Evaluation/MaxReturn                     -4.42571\n",
      "Evaluation/MinReturn                     -4.56768\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0709847\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.168952\n",
      "GaussianMLPPolicy/KL                      0.00960033\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00148563\n",
      "GaussianMLPPolicy/LossBefore              0.00156479\n",
      "GaussianMLPPolicy/dLoss                   7.91674e-05\n",
      "GaussianMLPValueFunction/LossAfter       -0.00945115\n",
      "GaussianMLPValueFunction/LossBefore       0.0629687\n",
      "GaussianMLPValueFunction/dLoss            0.0724198\n",
      "TotalEnvSteps                        101898\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.8064e-03,  9.8700e-04, -6.9177e-05,  ...,  6.1815e-03,\n",
      "         3.4626e-04,  7.2733e-03])\n",
      "G is: \n",
      "tensor([[6.8339e-04, 2.0637e-01],\n",
      "        [2.0637e-01, 7.0477e+01]])\n",
      "eig is:\n",
      "tensor([[8.3923e-05, 0.0000e+00],\n",
      "        [7.0478e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.0275, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0271, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:10 | [trpo_pendulum] epoch #51 | Saving snapshot...\n",
      "2022-08-23 10:38:10 | [trpo_pendulum] epoch #51 | Saved\n",
      "2022-08-23 10:38:10 | [trpo_pendulum] epoch #51 | Time 51.74 s\n",
      "2022-08-23 10:38:10 | [trpo_pendulum] epoch #51 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.480542\n",
      "Evaluation/AverageReturn                 -5.39107\n",
      "Evaluation/Iteration                     51\n",
      "Evaluation/MaxReturn                     -5.20279\n",
      "Evaluation/MinReturn                     -5.57935\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.188279\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.195438\n",
      "GaussianMLPPolicy/KL                      0.00477541\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.0270706\n",
      "GaussianMLPPolicy/LossBefore              0.0275132\n",
      "GaussianMLPPolicy/dLoss                   0.000442533\n",
      "GaussianMLPValueFunction/LossAfter       -0.0762171\n",
      "GaussianMLPValueFunction/LossBefore       0.0163655\n",
      "GaussianMLPValueFunction/dLoss            0.0925826\n",
      "TotalEnvSteps                        103896\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.1748e-03, -1.8303e-03, -3.5102e-05,  ..., -8.4428e-03,\n",
      "         4.6241e-04, -9.7903e-03])\n",
      "G is: \n",
      "tensor([[1.4927e-03, 5.0402e-01],\n",
      "        [5.0402e-01, 1.7852e+02]])\n",
      "eig is:\n",
      "tensor([[6.1035e-05, 0.0000e+00],\n",
      "        [1.7852e+02, 0.0000e+00]])\n",
      "2022-08-23 10:38:11 | [trpo_pendulum] epoch #52 | Line search condition violated. Rejecting the step!\n",
      "2022-08-23 10:38:11 | [trpo_pendulum] epoch #52 | Violated because loss not improving\n",
      "2022-08-23 10:38:11 | [trpo_pendulum] epoch #52 | Saving snapshot...\n",
      "2022-08-23 10:38:11 | [trpo_pendulum] epoch #52 | Saved\n",
      "2022-08-23 10:38:11 | [trpo_pendulum] epoch #52 | Time 52.74 s\n",
      "2022-08-23 10:38:11 | [trpo_pendulum] epoch #52 | EpochTime 1.00 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn       -0.38038\n",
      "Evaluation/AverageReturn                 -4.01732\n",
      "Evaluation/Iteration                     52\n",
      "Evaluation/MaxReturn                     -3.78754\n",
      "Evaluation/MinReturn                     -4.24711\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.229784\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.195438\n",
      "GaussianMLPPolicy/KL                      0\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0481897\n",
      "GaussianMLPPolicy/LossBefore             -0.0481897\n",
      "GaussianMLPPolicy/dLoss                   0\n",
      "GaussianMLPValueFunction/LossAfter       -0.168774\n",
      "GaussianMLPValueFunction/LossBefore      -0.0201908\n",
      "GaussianMLPValueFunction/dLoss            0.148584\n",
      "TotalEnvSteps                        105894\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.0561e-03, -2.3329e-03,  4.7880e-05,  ..., -4.4621e-03,\n",
      "         1.1333e-03, -5.1255e-03])\n",
      "G is: \n",
      "tensor([[6.4263e-04, 1.7836e-01],\n",
      "        [1.7836e-01, 6.3398e+01]])\n",
      "eig is:\n",
      "tensor([[1.4114e-04, 0.0000e+00],\n",
      "        [6.3398e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.0093, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0092, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:12 | [trpo_pendulum] epoch #53 | Saving snapshot...\n",
      "2022-08-23 10:38:12 | [trpo_pendulum] epoch #53 | Saved\n",
      "2022-08-23 10:38:12 | [trpo_pendulum] epoch #53 | Time 53.74 s\n",
      "2022-08-23 10:38:12 | [trpo_pendulum] epoch #53 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.432485\n",
      "Evaluation/AverageReturn                 -4.26465\n",
      "Evaluation/Iteration                     53\n",
      "Evaluation/MaxReturn                     -4.08955\n",
      "Evaluation/MinReturn                     -4.43975\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.175103\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.210836\n",
      "GaussianMLPPolicy/KL                      0.00997805\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00924988\n",
      "GaussianMLPPolicy/LossBefore              0.00932942\n",
      "GaussianMLPPolicy/dLoss                   7.95405e-05\n",
      "GaussianMLPValueFunction/LossAfter       -0.244568\n",
      "GaussianMLPValueFunction/LossBefore      -0.16689\n",
      "GaussianMLPValueFunction/dLoss            0.0776779\n",
      "TotalEnvSteps                        107892\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.5628e-03, -2.4989e-03, -8.0082e-06,  ..., -6.0834e-03,\n",
      "         1.5701e-03, -6.9841e-03])\n",
      "G is: \n",
      "tensor([[9.2663e-04, 3.1132e-01],\n",
      "        [3.1132e-01, 1.1496e+02]])\n",
      "eig is:\n",
      "tensor([[7.6294e-05, 0.0000e+00],\n",
      "        [1.1496e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0146, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0147, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:13 | [trpo_pendulum] epoch #54 | Saving snapshot...\n",
      "2022-08-23 10:38:13 | [trpo_pendulum] epoch #54 | Saved\n",
      "2022-08-23 10:38:13 | [trpo_pendulum] epoch #54 | Time 54.72 s\n",
      "2022-08-23 10:38:13 | [trpo_pendulum] epoch #54 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.363119\n",
      "Evaluation/AverageReturn                 -3.89404\n",
      "Evaluation/Iteration                     54\n",
      "Evaluation/MaxReturn                     -3.78634\n",
      "Evaluation/MinReturn                     -4.00175\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.107705\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.212979\n",
      "GaussianMLPPolicy/KL                      0.000597267\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0146522\n",
      "GaussianMLPPolicy/LossBefore             -0.0146419\n",
      "GaussianMLPPolicy/dLoss                   1.03032e-05\n",
      "GaussianMLPValueFunction/LossAfter       -0.324099\n",
      "GaussianMLPValueFunction/LossBefore      -0.240141\n",
      "GaussianMLPValueFunction/dLoss            0.0839581\n",
      "TotalEnvSteps                        109890\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.9716e-03, -1.4938e-03, -3.1181e-05,  ..., -8.3521e-03,\n",
      "         1.2685e-03, -9.6433e-03])\n",
      "G is: \n",
      "tensor([[1.3628e-03, 5.0212e-01],\n",
      "        [5.0212e-01, 1.9236e+02]])\n",
      "eig is:\n",
      "tensor([[6.1035e-05, 0.0000e+00],\n",
      "        [1.9236e+02, 0.0000e+00]])\n",
      "2022-08-23 10:38:14 | [trpo_pendulum] epoch #55 | Line search condition violated. Rejecting the step!\n",
      "2022-08-23 10:38:14 | [trpo_pendulum] epoch #55 | Violated because loss not improving\n",
      "2022-08-23 10:38:14 | [trpo_pendulum] epoch #55 | Saving snapshot...\n",
      "2022-08-23 10:38:14 | [trpo_pendulum] epoch #55 | Saved\n",
      "2022-08-23 10:38:14 | [trpo_pendulum] epoch #55 | Time 55.71 s\n",
      "2022-08-23 10:38:14 | [trpo_pendulum] epoch #55 | EpochTime 0.99 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn       -0.371802\n",
      "Evaluation/AverageReturn                 -4.15517\n",
      "Evaluation/Iteration                     55\n",
      "Evaluation/MaxReturn                     -4.05151\n",
      "Evaluation/MinReturn                     -4.25884\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.103661\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.212979\n",
      "GaussianMLPPolicy/KL                      0\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00668783\n",
      "GaussianMLPPolicy/LossBefore              0.00668783\n",
      "GaussianMLPPolicy/dLoss                   0\n",
      "GaussianMLPValueFunction/LossAfter       -0.388605\n",
      "GaussianMLPValueFunction/LossBefore      -0.315678\n",
      "GaussianMLPValueFunction/dLoss            0.0729272\n",
      "TotalEnvSteps                        111888\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.9819e-03, -3.8407e-03, -2.6493e-05,  ..., -1.5519e-02,\n",
      "         3.0176e-03, -1.7866e-02])\n",
      "G is: \n",
      "tensor([[4.8036e-03, 1.8319e+00],\n",
      "        [1.8319e+00, 7.0387e+02]])\n",
      "eig is:\n",
      "tensor([[6.1035e-05, 0.0000e+00],\n",
      "        [7.0387e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.0211, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0210, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:15 | [trpo_pendulum] epoch #56 | Saving snapshot...\n",
      "2022-08-23 10:38:15 | [trpo_pendulum] epoch #56 | Saved\n",
      "2022-08-23 10:38:15 | [trpo_pendulum] epoch #56 | Time 56.82 s\n",
      "2022-08-23 10:38:15 | [trpo_pendulum] epoch #56 | EpochTime 1.10 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.462011\n",
      "Evaluation/AverageReturn                 -4.64029\n",
      "Evaluation/Iteration                     56\n",
      "Evaluation/MaxReturn                     -4.49684\n",
      "Evaluation/MinReturn                     -4.78374\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.143451\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.225688\n",
      "GaussianMLPPolicy/KL                      0.00217009\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.02105\n",
      "GaussianMLPPolicy/LossBefore              0.0210556\n",
      "GaussianMLPPolicy/dLoss                   5.65872e-06\n",
      "GaussianMLPValueFunction/LossAfter       -0.445319\n",
      "GaussianMLPValueFunction/LossBefore      -0.351601\n",
      "GaussianMLPValueFunction/dLoss            0.0937189\n",
      "TotalEnvSteps                        113886\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 0.0075, -0.0038, -0.0002,  ..., -0.0087,  0.0016, -0.0099])\n",
      "G is: \n",
      "tensor([[2.0373e-03, 7.3146e-01],\n",
      "        [7.3146e-01, 2.8544e+02]])\n",
      "eig is:\n",
      "tensor([[1.8311e-04, 0.0000e+00],\n",
      "        [2.8545e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0090, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0093, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:16 | [trpo_pendulum] epoch #57 | Saving snapshot...\n",
      "2022-08-23 10:38:16 | [trpo_pendulum] epoch #57 | Saved\n",
      "2022-08-23 10:38:16 | [trpo_pendulum] epoch #57 | Time 57.73 s\n",
      "2022-08-23 10:38:16 | [trpo_pendulum] epoch #57 | EpochTime 0.91 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.42258\n",
      "Evaluation/AverageReturn                 -4.47857\n",
      "Evaluation/Iteration                     57\n",
      "Evaluation/MaxReturn                     -3.96652\n",
      "Evaluation/MinReturn                     -4.99063\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.512057\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.25078\n",
      "GaussianMLPPolicy/KL                      0.00899523\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00931444\n",
      "GaussianMLPPolicy/LossBefore             -0.00901289\n",
      "GaussianMLPPolicy/dLoss                   0.000301547\n",
      "GaussianMLPValueFunction/LossAfter       -0.45954\n",
      "GaussianMLPValueFunction/LossBefore      -0.40239\n",
      "GaussianMLPValueFunction/dLoss            0.0571497\n",
      "TotalEnvSteps                        115884\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.8088e-03, -4.3221e-03, -1.9346e-05,  ..., -2.0044e-02,\n",
      "         4.2972e-03, -2.2785e-02])\n",
      "G is: \n",
      "tensor([[7.2701e-03, 2.7309e+00],\n",
      "        [2.7309e+00, 1.0359e+03]])\n",
      "eig is:\n",
      "tensor([[1.2207e-04, 0.0000e+00],\n",
      "        [1.0359e+03, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0148, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0148, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:17 | [trpo_pendulum] epoch #58 | Saving snapshot...\n",
      "2022-08-23 10:38:17 | [trpo_pendulum] epoch #58 | Saved\n",
      "2022-08-23 10:38:17 | [trpo_pendulum] epoch #58 | Time 58.70 s\n",
      "2022-08-23 10:38:17 | [trpo_pendulum] epoch #58 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.407066\n",
      "Evaluation/AverageReturn                 -4.25639\n",
      "Evaluation/Iteration                     58\n",
      "Evaluation/MaxReturn                     -4.21137\n",
      "Evaluation/MinReturn                     -4.30142\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0450261\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.254681\n",
      "GaussianMLPPolicy/KL                      7.15564e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0148084\n",
      "GaussianMLPPolicy/LossBefore             -0.0148075\n",
      "GaussianMLPPolicy/dLoss                   8.56817e-07\n",
      "GaussianMLPValueFunction/LossAfter       -0.546074\n",
      "GaussianMLPValueFunction/LossBefore      -0.470267\n",
      "GaussianMLPValueFunction/dLoss            0.0758075\n",
      "TotalEnvSteps                        117882\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.5471e-03, -2.0695e-03, -4.8846e-05,  ..., -9.2062e-03,\n",
      "         2.2052e-03, -1.0458e-02])\n",
      "G is: \n",
      "tensor([[1.6379e-03, 6.1756e-01],\n",
      "        [6.1756e-01, 2.4168e+02]])\n",
      "eig is:\n",
      "tensor([[6.1035e-05, 0.0000e+00],\n",
      "        [2.4168e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.0051, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0045, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:18 | [trpo_pendulum] epoch #59 | Saving snapshot...\n",
      "2022-08-23 10:38:18 | [trpo_pendulum] epoch #59 | Saved\n",
      "2022-08-23 10:38:18 | [trpo_pendulum] epoch #59 | Time 59.68 s\n",
      "2022-08-23 10:38:18 | [trpo_pendulum] epoch #59 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.410737\n",
      "Evaluation/AverageReturn                 -4.19127\n",
      "Evaluation/Iteration                     59\n",
      "Evaluation/MaxReturn                     -3.91312\n",
      "Evaluation/MinReturn                     -4.46943\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.278157\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.308573\n",
      "GaussianMLPPolicy/KL                      0.0091072\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00449385\n",
      "GaussianMLPPolicy/LossBefore              0.00505769\n",
      "GaussianMLPPolicy/dLoss                   0.000563839\n",
      "GaussianMLPValueFunction/LossAfter       -0.62052\n",
      "GaussianMLPValueFunction/LossBefore      -0.558868\n",
      "GaussianMLPValueFunction/dLoss            0.0616519\n",
      "TotalEnvSteps                        119880\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.2691e-03, -1.0932e-03, -1.8144e-05,  ..., -4.2361e-03,\n",
      "         2.7299e-03, -4.7274e-03])\n",
      "G is: \n",
      "tensor([[3.7573e-04, 1.1125e-01],\n",
      "        [1.1125e-01, 4.1902e+01]])\n",
      "eig is:\n",
      "tensor([[7.6294e-05, 0.0000e+00],\n",
      "        [4.1902e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0054, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0057, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:19 | [trpo_pendulum] epoch #60 | Saving snapshot...\n",
      "2022-08-23 10:38:19 | [trpo_pendulum] epoch #60 | Saved\n",
      "2022-08-23 10:38:19 | [trpo_pendulum] epoch #60 | Time 60.64 s\n",
      "2022-08-23 10:38:19 | [trpo_pendulum] epoch #60 | EpochTime 0.96 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn       -0.405864\n",
      "Evaluation/AverageReturn                 -4.01161\n",
      "Evaluation/Iteration                     60\n",
      "Evaluation/MaxReturn                     -3.85532\n",
      "Evaluation/MinReturn                     -4.16791\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.156294\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.327865\n",
      "GaussianMLPPolicy/KL                      0.00586285\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00569813\n",
      "GaussianMLPPolicy/LossBefore             -0.00535663\n",
      "GaussianMLPPolicy/dLoss                   0.0003415\n",
      "GaussianMLPValueFunction/LossAfter       -0.705383\n",
      "GaussianMLPValueFunction/LossBefore      -0.63457\n",
      "GaussianMLPValueFunction/dLoss            0.0708128\n",
      "TotalEnvSteps                        121878\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.9240e-03, -1.3828e-03, -2.5838e-05,  ..., -1.5488e-02,\n",
      "         2.1001e-03, -1.8026e-02])\n",
      "G is: \n",
      "tensor([[3.7019e-03, 1.3570e+00],\n",
      "        [1.3570e+00, 5.0111e+02]])\n",
      "eig is:\n",
      "tensor([[3.0518e-05, 0.0000e+00],\n",
      "        [5.0111e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0091, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0095, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:20 | [trpo_pendulum] epoch #61 | Saving snapshot...\n",
      "2022-08-23 10:38:20 | [trpo_pendulum] epoch #61 | Saved\n",
      "2022-08-23 10:38:20 | [trpo_pendulum] epoch #61 | Time 61.68 s\n",
      "2022-08-23 10:38:20 | [trpo_pendulum] epoch #61 | EpochTime 1.03 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.383184\n",
      "Evaluation/AverageReturn                 -3.81986\n",
      "Evaluation/Iteration                     61\n",
      "Evaluation/MaxReturn                     -3.78656\n",
      "Evaluation/MinReturn                     -3.85317\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0333022\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.334068\n",
      "GaussianMLPPolicy/KL                      0.00468927\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00950766\n",
      "GaussianMLPPolicy/LossBefore             -0.00909795\n",
      "GaussianMLPPolicy/dLoss                   0.000409712\n",
      "GaussianMLPValueFunction/LossAfter       -0.774677\n",
      "GaussianMLPValueFunction/LossBefore      -0.700452\n",
      "GaussianMLPValueFunction/dLoss            0.0742245\n",
      "TotalEnvSteps                        123876\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.1940e-03, -3.1188e-06,  3.2015e-06,  ..., -1.2204e-03,\n",
      "         2.0298e-05, -1.4378e-03])\n",
      "G is: \n",
      "tensor([[7.9014e-05, 1.0319e-02],\n",
      "        [1.0319e-02, 4.2096e+00]])\n",
      "eig is:\n",
      "tensor([[5.3883e-05, 0.0000e+00],\n",
      "        [4.2096e+00, 0.0000e+00]])\n",
      "2022-08-23 10:38:20 | [trpo_pendulum] epoch #62 | Line search condition violated. Rejecting the step!\n",
      "2022-08-23 10:38:20 | [trpo_pendulum] epoch #62 | Violated because loss not improving\n",
      "2022-08-23 10:38:20 | [trpo_pendulum] epoch #62 | Violated because constraint is violated\n",
      "2022-08-23 10:38:21 | [trpo_pendulum] epoch #62 | Saving snapshot...\n",
      "2022-08-23 10:38:21 | [trpo_pendulum] epoch #62 | Saved\n",
      "2022-08-23 10:38:21 | [trpo_pendulum] epoch #62 | Time 62.70 s\n",
      "2022-08-23 10:38:21 | [trpo_pendulum] epoch #62 | EpochTime 1.01 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn       -0.347879\n",
      "Evaluation/AverageReturn                 -3.53091\n",
      "Evaluation/Iteration                     62\n",
      "Evaluation/MaxReturn                     -3.48891\n",
      "Evaluation/MinReturn                     -3.57292\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0420057\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.334068\n",
      "GaussianMLPPolicy/KL                      0\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0123921\n",
      "GaussianMLPPolicy/LossBefore             -0.0123921\n",
      "GaussianMLPPolicy/dLoss                   0\n",
      "GaussianMLPValueFunction/LossAfter       -0.852013\n",
      "GaussianMLPValueFunction/LossBefore      -0.767708\n",
      "GaussianMLPValueFunction/dLoss            0.0843045\n",
      "TotalEnvSteps                        125874\n",
      "-----------------------------------  --------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.2216e-03, -1.2950e-03, -1.7449e-05,  ..., -1.6149e-02,\n",
      "         4.8098e-03, -1.8609e-02])\n",
      "G is: \n",
      "tensor([[4.2885e-03, 1.7551e+00],\n",
      "        [1.7551e+00, 7.2233e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [722.3331,   0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0011, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0015, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:22 | [trpo_pendulum] epoch #63 | Saving snapshot...\n",
      "2022-08-23 10:38:22 | [trpo_pendulum] epoch #63 | Saved\n",
      "2022-08-23 10:38:22 | [trpo_pendulum] epoch #63 | Time 63.69 s\n",
      "2022-08-23 10:38:22 | [trpo_pendulum] epoch #63 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.344315\n",
      "Evaluation/AverageReturn                 -3.3663\n",
      "Evaluation/Iteration                     63\n",
      "Evaluation/MaxReturn                     -3.30585\n",
      "Evaluation/MinReturn                     -3.42676\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0604543\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.339742\n",
      "GaussianMLPPolicy/KL                      0.00696465\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00153121\n",
      "GaussianMLPPolicy/LossBefore             -0.00105708\n",
      "GaussianMLPPolicy/dLoss                   0.000474126\n",
      "GaussianMLPValueFunction/LossAfter       -0.93208\n",
      "GaussianMLPValueFunction/LossBefore      -0.868117\n",
      "GaussianMLPValueFunction/dLoss            0.0639631\n",
      "TotalEnvSteps                        127872\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.6758e-03, -1.3214e-03, -2.4893e-05,  ..., -1.0618e-02,\n",
      "         3.4083e-03, -1.2076e-02])\n",
      "G is: \n",
      "tensor([[1.8483e-03, 7.4807e-01],\n",
      "        [7.4807e-01, 3.0472e+02]])\n",
      "eig is:\n",
      "tensor([[3.0518e-05, 0.0000e+00],\n",
      "        [3.0472e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0006, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0006, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:23 | [trpo_pendulum] epoch #64 | Saving snapshot...\n",
      "2022-08-23 10:38:23 | [trpo_pendulum] epoch #64 | Saved\n",
      "2022-08-23 10:38:23 | [trpo_pendulum] epoch #64 | Time 64.73 s\n",
      "2022-08-23 10:38:23 | [trpo_pendulum] epoch #64 | EpochTime 1.03 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.301043\n",
      "Evaluation/AverageReturn                 -3.39759\n",
      "Evaluation/Iteration                     64\n",
      "Evaluation/MaxReturn                     -3.3936\n",
      "Evaluation/MinReturn                     -3.40158\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00399283\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.345317\n",
      "GaussianMLPPolicy/KL                      0.000578903\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000579233\n",
      "GaussianMLPPolicy/LossBefore             -0.000572341\n",
      "GaussianMLPPolicy/dLoss                   6.89243e-06\n",
      "GaussianMLPValueFunction/LossAfter       -0.988592\n",
      "GaussianMLPValueFunction/LossBefore      -0.931633\n",
      "GaussianMLPValueFunction/dLoss            0.0569591\n",
      "TotalEnvSteps                        129870\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.9518e-03, -7.7810e-04,  4.6975e-06,  ..., -5.0213e-03,\n",
      "         1.7027e-03, -5.7118e-03])\n",
      "G is: \n",
      "tensor([[4.4542e-04, 1.5383e-01],\n",
      "        [1.5383e-01, 6.0038e+01]])\n",
      "eig is:\n",
      "tensor([[5.3406e-05, 0.0000e+00],\n",
      "        [6.0039e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.0033, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0032, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:24 | [trpo_pendulum] epoch #65 | Saving snapshot...\n",
      "2022-08-23 10:38:24 | [trpo_pendulum] epoch #65 | Saved\n",
      "2022-08-23 10:38:24 | [trpo_pendulum] epoch #65 | Time 65.70 s\n",
      "2022-08-23 10:38:24 | [trpo_pendulum] epoch #65 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.32359\n",
      "Evaluation/AverageReturn                 -3.42599\n",
      "Evaluation/Iteration                     65\n",
      "Evaluation/MaxReturn                     -3.3461\n",
      "Evaluation/MinReturn                     -3.50588\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0798888\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.372448\n",
      "GaussianMLPPolicy/KL                      0.00850081\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00318951\n",
      "GaussianMLPPolicy/LossBefore              0.00329526\n",
      "GaussianMLPPolicy/dLoss                   0.000105753\n",
      "GaussianMLPValueFunction/LossAfter       -1.02521\n",
      "GaussianMLPValueFunction/LossBefore      -0.974658\n",
      "GaussianMLPValueFunction/dLoss            0.0505499\n",
      "TotalEnvSteps                        131868\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.0859e-03, -1.8400e-03, -3.1876e-05,  ..., -1.9288e-02,\n",
      "         6.2341e-03, -2.1940e-02])\n",
      "G is: \n",
      "tensor([[6.1717e-03, 2.7941e+00],\n",
      "        [2.7941e+00, 1.2693e+03]])\n",
      "eig is:\n",
      "tensor([[   0.0000,    0.0000],\n",
      "        [1269.2822,    0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0069, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0069, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:25 | [trpo_pendulum] epoch #66 | Saving snapshot...\n",
      "2022-08-23 10:38:25 | [trpo_pendulum] epoch #66 | Saved\n",
      "2022-08-23 10:38:25 | [trpo_pendulum] epoch #66 | Time 66.68 s\n",
      "2022-08-23 10:38:25 | [trpo_pendulum] epoch #66 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.341625\n",
      "Evaluation/AverageReturn                 -3.5114\n",
      "Evaluation/Iteration                     66\n",
      "Evaluation/MaxReturn                     -3.46752\n",
      "Evaluation/MinReturn                     -3.55527\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0438772\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.387585\n",
      "GaussianMLPPolicy/KL                      0.00225282\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00687822\n",
      "GaussianMLPPolicy/LossBefore              0.00689045\n",
      "GaussianMLPPolicy/dLoss                   1.22329e-05\n",
      "GaussianMLPValueFunction/LossAfter       -1.05802\n",
      "GaussianMLPValueFunction/LossBefore      -1.00023\n",
      "GaussianMLPValueFunction/dLoss            0.0577829\n",
      "TotalEnvSteps                        133866\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.4039e-03, -2.5207e-03, -7.9305e-06,  ..., -2.0178e-02,\n",
      "         1.0215e-02, -2.2678e-02])\n",
      "G is: \n",
      "tensor([[7.1358e-03, 3.6056e+00],\n",
      "        [3.6056e+00, 1.8325e+03]])\n",
      "eig is:\n",
      "tensor([[   0.0000,    0.0000],\n",
      "        [1832.5204,    0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0031, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0031, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:26 | [trpo_pendulum] epoch #67 | Saving snapshot...\n",
      "2022-08-23 10:38:26 | [trpo_pendulum] epoch #67 | Saved\n",
      "2022-08-23 10:38:26 | [trpo_pendulum] epoch #67 | Time 67.66 s\n",
      "2022-08-23 10:38:26 | [trpo_pendulum] epoch #67 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.380706\n",
      "Evaluation/AverageReturn                 -3.66396\n",
      "Evaluation/Iteration                     67\n",
      "Evaluation/MaxReturn                     -3.64681\n",
      "Evaluation/MinReturn                     -3.68112\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0171576\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.425198\n",
      "GaussianMLPPolicy/KL                      0.00387268\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00305831\n",
      "GaussianMLPPolicy/LossBefore              0.00309023\n",
      "GaussianMLPPolicy/dLoss                   3.19125e-05\n",
      "GaussianMLPValueFunction/LossAfter       -0.992399\n",
      "GaussianMLPValueFunction/LossBefore      -0.970668\n",
      "GaussianMLPValueFunction/dLoss            0.0217313\n",
      "TotalEnvSteps                        135864\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.6115e-03, -3.7340e-03, -6.2776e-06,  ..., -2.7099e-02,\n",
      "         1.3147e-02, -3.0544e-02])\n",
      "G is: \n",
      "tensor([[1.2037e-02, 6.2009e+00],\n",
      "        [6.2009e+00, 3.2062e+03]])\n",
      "eig is:\n",
      "tensor([[   0.0000,    0.0000],\n",
      "        [3206.2156,    0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0074, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0082, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:27 | [trpo_pendulum] epoch #68 | Saving snapshot...\n",
      "2022-08-23 10:38:27 | [trpo_pendulum] epoch #68 | Saved\n",
      "2022-08-23 10:38:27 | [trpo_pendulum] epoch #68 | Time 68.61 s\n",
      "2022-08-23 10:38:27 | [trpo_pendulum] epoch #68 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.403837\n",
      "Evaluation/AverageReturn                 -3.53426\n",
      "Evaluation/Iteration                     68\n",
      "Evaluation/MaxReturn                     -3.461\n",
      "Evaluation/MinReturn                     -3.60752\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0732601\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.479253\n",
      "GaussianMLPPolicy/KL                      0.00802657\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00817633\n",
      "GaussianMLPPolicy/LossBefore             -0.00740555\n",
      "GaussianMLPPolicy/dLoss                   0.000770775\n",
      "GaussianMLPValueFunction/LossAfter       -1.02356\n",
      "GaussianMLPValueFunction/LossBefore      -0.975356\n",
      "GaussianMLPValueFunction/dLoss            0.0482084\n",
      "TotalEnvSteps                        137862\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.4792e-03, -1.8980e-03,  9.8472e-06,  ..., -1.5882e-02,\n",
      "         7.6087e-03, -1.8053e-02])\n",
      "G is: \n",
      "tensor([[4.1052e-03, 2.3325e+00],\n",
      "        [2.3325e+00, 1.3352e+03]])\n",
      "eig is:\n",
      "tensor([[1.2207e-04, 0.0000e+00],\n",
      "        [1.3352e+03, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0214, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0219, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:28 | [trpo_pendulum] epoch #69 | Saving snapshot...\n",
      "2022-08-23 10:38:28 | [trpo_pendulum] epoch #69 | Saved\n",
      "2022-08-23 10:38:28 | [trpo_pendulum] epoch #69 | Time 69.60 s\n",
      "2022-08-23 10:38:28 | [trpo_pendulum] epoch #69 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.308535\n",
      "Evaluation/AverageReturn                 -2.93798\n",
      "Evaluation/Iteration                     69\n",
      "Evaluation/MaxReturn                     -2.91366\n",
      "Evaluation/MinReturn                     -2.96229\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0243135\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.509145\n",
      "GaussianMLPPolicy/KL                      0.00935822\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0219073\n",
      "GaussianMLPPolicy/LossBefore             -0.0213956\n",
      "GaussianMLPPolicy/dLoss                   0.000511726\n",
      "GaussianMLPValueFunction/LossAfter       -1.23035\n",
      "GaussianMLPValueFunction/LossBefore      -1.00942\n",
      "GaussianMLPValueFunction/dLoss            0.220932\n",
      "TotalEnvSteps                        139860\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.5996e-03, -3.3916e-03,  1.3960e-05,  ..., -2.1393e-02,\n",
      "         1.0212e-02, -2.4685e-02])\n",
      "G is: \n",
      "tensor([[7.7116e-03, 4.6350e+00],\n",
      "        [4.6350e+00, 2.7981e+03]])\n",
      "eig is:\n",
      "tensor([[   0.0000,    0.0000],\n",
      "        [2798.1519,    0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0049, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0053, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:29 | [trpo_pendulum] epoch #70 | Saving snapshot...\n",
      "2022-08-23 10:38:29 | [trpo_pendulum] epoch #70 | Saved\n",
      "2022-08-23 10:38:29 | [trpo_pendulum] epoch #70 | Time 70.56 s\n",
      "2022-08-23 10:38:29 | [trpo_pendulum] epoch #70 | EpochTime 0.96 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn       -0.252316\n",
      "Evaluation/AverageReturn                 -2.77732\n",
      "Evaluation/Iteration                     70\n",
      "Evaluation/MaxReturn                     -2.74968\n",
      "Evaluation/MinReturn                     -2.80496\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0276409\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.527715\n",
      "GaussianMLPPolicy/KL                      0.00535742\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00526076\n",
      "GaussianMLPPolicy/LossBefore             -0.00494868\n",
      "GaussianMLPPolicy/dLoss                   0.00031208\n",
      "GaussianMLPValueFunction/LossAfter       -1.3338\n",
      "GaussianMLPValueFunction/LossBefore      -1.26823\n",
      "GaussianMLPValueFunction/dLoss            0.0655756\n",
      "TotalEnvSteps                        141858\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.1017e-03, -3.1945e-03, -2.5967e-05,  ..., -1.7480e-02,\n",
      "         8.0416e-03, -2.0658e-02])\n",
      "G is: \n",
      "tensor([[5.8997e-03, 3.8859e+00],\n",
      "        [3.8859e+00, 2.5691e+03]])\n",
      "eig is:\n",
      "tensor([[   0.0000,    0.0000],\n",
      "        [2569.1357,    0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0051, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0055, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:30 | [trpo_pendulum] epoch #71 | Saving snapshot...\n",
      "2022-08-23 10:38:30 | [trpo_pendulum] epoch #71 | Saved\n",
      "2022-08-23 10:38:30 | [trpo_pendulum] epoch #71 | Time 71.54 s\n",
      "2022-08-23 10:38:30 | [trpo_pendulum] epoch #71 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.265033\n",
      "Evaluation/AverageReturn                 -2.63711\n",
      "Evaluation/Iteration                     71\n",
      "Evaluation/MaxReturn                     -2.42565\n",
      "Evaluation/MinReturn                     -2.84856\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.211457\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.534321\n",
      "GaussianMLPPolicy/KL                      0.00518969\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0054613\n",
      "GaussianMLPPolicy/LossBefore             -0.00510702\n",
      "GaussianMLPPolicy/dLoss                   0.000354277\n",
      "GaussianMLPValueFunction/LossAfter       -1.34933\n",
      "GaussianMLPValueFunction/LossBefore      -1.29071\n",
      "GaussianMLPValueFunction/dLoss            0.0586185\n",
      "TotalEnvSteps                        143856\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.9658e-03, -1.3391e-03,  7.8488e-07,  ..., -7.3920e-03,\n",
      "         3.4571e-03, -8.5551e-03])\n",
      "G is: \n",
      "tensor([[9.9807e-04, 6.1300e-01],\n",
      "        [6.1300e-01, 3.8790e+02]])\n",
      "eig is:\n",
      "tensor([[6.1035e-05, 0.0000e+00],\n",
      "        [3.8790e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0089, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0091, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:31 | [trpo_pendulum] epoch #72 | Saving snapshot...\n",
      "2022-08-23 10:38:31 | [trpo_pendulum] epoch #72 | Saved\n",
      "2022-08-23 10:38:31 | [trpo_pendulum] epoch #72 | Time 72.50 s\n",
      "2022-08-23 10:38:31 | [trpo_pendulum] epoch #72 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.243232\n",
      "Evaluation/AverageReturn                 -2.36304\n",
      "Evaluation/Iteration                     72\n",
      "Evaluation/MaxReturn                     -2.19845\n",
      "Evaluation/MinReturn                     -2.52762\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.164583\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.550122\n",
      "GaussianMLPPolicy/KL                      0.00801521\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00913231\n",
      "GaussianMLPPolicy/LossBefore             -0.00891683\n",
      "GaussianMLPPolicy/dLoss                   0.000215479\n",
      "GaussianMLPValueFunction/LossAfter       -1.37758\n",
      "GaussianMLPValueFunction/LossBefore      -1.28955\n",
      "GaussianMLPValueFunction/dLoss            0.0880295\n",
      "TotalEnvSteps                        145854\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.8021e-03, -1.8636e-03, -2.4220e-05,  ..., -1.4210e-02,\n",
      "         6.1700e-03, -1.6369e-02])\n",
      "G is: \n",
      "tensor([[3.3508e-03, 2.0943e+00],\n",
      "        [2.0943e+00, 1.3225e+03]])\n",
      "eig is:\n",
      "tensor([[-1.2207e-04,  0.0000e+00],\n",
      "        [ 1.3225e+03,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-0.0030, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0036, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:32 | [trpo_pendulum] epoch #73 | Saving snapshot...\n",
      "2022-08-23 10:38:32 | [trpo_pendulum] epoch #73 | Saved\n",
      "2022-08-23 10:38:32 | [trpo_pendulum] epoch #73 | Time 73.50 s\n",
      "2022-08-23 10:38:32 | [trpo_pendulum] epoch #73 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.211311\n",
      "Evaluation/AverageReturn                 -2.2001\n",
      "Evaluation/Iteration                     73\n",
      "Evaluation/MaxReturn                     -2.07353\n",
      "Evaluation/MinReturn                     -2.32666\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.126563\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.615136\n",
      "GaussianMLPPolicy/KL                      0.00869554\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00357815\n",
      "GaussianMLPPolicy/LossBefore             -0.00299174\n",
      "GaussianMLPPolicy/dLoss                   0.000586406\n",
      "GaussianMLPValueFunction/LossAfter       -1.40635\n",
      "GaussianMLPValueFunction/LossBefore      -1.37518\n",
      "GaussianMLPValueFunction/dLoss            0.0311694\n",
      "TotalEnvSteps                        147852\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.5109e-03, -7.3951e-04, -4.0262e-06,  ..., -8.2221e-03,\n",
      "         3.5513e-03, -9.4194e-03])\n",
      "G is: \n",
      "tensor([[1.0731e-03, 7.4341e-01],\n",
      "        [7.4341e-01, 5.1818e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [518.1854,   0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0102, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0105, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:33 | [trpo_pendulum] epoch #74 | Saving snapshot...\n",
      "2022-08-23 10:38:33 | [trpo_pendulum] epoch #74 | Saved\n",
      "2022-08-23 10:38:33 | [trpo_pendulum] epoch #74 | Time 74.46 s\n",
      "2022-08-23 10:38:33 | [trpo_pendulum] epoch #74 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.161892\n",
      "Evaluation/AverageReturn                 -1.83808\n",
      "Evaluation/Iteration                     74\n",
      "Evaluation/MaxReturn                     -1.78796\n",
      "Evaluation/MinReturn                     -1.8882\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0501196\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.685005\n",
      "GaussianMLPPolicy/KL                      0.00632544\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0104755\n",
      "GaussianMLPPolicy/LossBefore             -0.0102382\n",
      "GaussianMLPPolicy/dLoss                   0.000237313\n",
      "GaussianMLPValueFunction/LossAfter       -1.62391\n",
      "GaussianMLPValueFunction/LossBefore      -1.48084\n",
      "GaussianMLPValueFunction/dLoss            0.143075\n",
      "TotalEnvSteps                        149850\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.1130e-03,  4.3722e-05,  2.7031e-07,  ...,  2.8098e-03,\n",
      "        -1.1578e-03,  3.2261e-03])\n",
      "G is: \n",
      "tensor([[1.3333e-04, 9.9348e-02],\n",
      "        [9.9348e-02, 7.9804e+01]])\n",
      "eig is:\n",
      "tensor([[7.6294e-06, 0.0000e+00],\n",
      "        [7.9804e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0091, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0091, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:34 | [trpo_pendulum] epoch #75 | Saving snapshot...\n",
      "2022-08-23 10:38:34 | [trpo_pendulum] epoch #75 | Saved\n",
      "2022-08-23 10:38:34 | [trpo_pendulum] epoch #75 | Time 75.47 s\n",
      "2022-08-23 10:38:34 | [trpo_pendulum] epoch #75 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.168632\n",
      "Evaluation/AverageReturn                 -1.57306\n",
      "Evaluation/Iteration                     75\n",
      "Evaluation/MaxReturn                     -1.56929\n",
      "Evaluation/MinReturn                     -1.57684\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00377225\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.699389\n",
      "GaussianMLPPolicy/KL                      0.00406417\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00914727\n",
      "GaussianMLPPolicy/LossBefore             -0.0091335\n",
      "GaussianMLPPolicy/dLoss                   1.37659e-05\n",
      "GaussianMLPValueFunction/LossAfter       -1.73542\n",
      "GaussianMLPValueFunction/LossBefore      -1.58686\n",
      "GaussianMLPValueFunction/dLoss            0.148562\n",
      "TotalEnvSteps                        151848\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.0421e-03,  1.0931e-04,  9.4598e-07,  ...,  1.5235e-03,\n",
      "        -6.2880e-04,  1.7391e-03])\n",
      "G is: \n",
      "tensor([[4.0421e-05, 2.9963e-02],\n",
      "        [2.9963e-02, 2.4753e+01]])\n",
      "eig is:\n",
      "tensor([[3.8147e-06, 0.0000e+00],\n",
      "        [2.4754e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0042, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0043, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:35 | [trpo_pendulum] epoch #76 | Saving snapshot...\n",
      "2022-08-23 10:38:35 | [trpo_pendulum] epoch #76 | Saved\n",
      "2022-08-23 10:38:35 | [trpo_pendulum] epoch #76 | Time 76.43 s\n",
      "2022-08-23 10:38:35 | [trpo_pendulum] epoch #76 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.134656\n",
      "Evaluation/AverageReturn                 -1.4365\n",
      "Evaluation/Iteration                     76\n",
      "Evaluation/MaxReturn                     -1.3635\n",
      "Evaluation/MinReturn                     -1.5095\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0730021\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.777582\n",
      "GaussianMLPPolicy/KL                      0.00705119\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00432842\n",
      "GaussianMLPPolicy/LossBefore             -0.00417793\n",
      "GaussianMLPPolicy/dLoss                   0.000150493\n",
      "GaussianMLPValueFunction/LossAfter       -1.83953\n",
      "GaussianMLPValueFunction/LossBefore      -1.75236\n",
      "GaussianMLPValueFunction/dLoss            0.0871731\n",
      "TotalEnvSteps                        153846\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.3165e-03,  2.9771e-04,  6.9724e-06,  ...,  2.9274e-03,\n",
      "        -1.2235e-03,  3.3472e-03])\n",
      "G is: \n",
      "tensor([[1.4219e-04, 1.3458e-01],\n",
      "        [1.3458e-01, 1.3237e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [132.3737,   0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0052, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0052, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:36 | [trpo_pendulum] epoch #77 | Saving snapshot...\n",
      "2022-08-23 10:38:36 | [trpo_pendulum] epoch #77 | Saved\n",
      "2022-08-23 10:38:36 | [trpo_pendulum] epoch #77 | Time 77.44 s\n",
      "2022-08-23 10:38:36 | [trpo_pendulum] epoch #77 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.125281\n",
      "Evaluation/AverageReturn                 -1.30298\n",
      "Evaluation/Iteration                     77\n",
      "Evaluation/MaxReturn                     -1.28565\n",
      "Evaluation/MinReturn                     -1.3203\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0173262\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.78192\n",
      "GaussianMLPPolicy/KL                      0.00488794\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00524889\n",
      "GaussianMLPPolicy/LossBefore             -0.00519496\n",
      "GaussianMLPPolicy/dLoss                   5.39236e-05\n",
      "GaussianMLPValueFunction/LossAfter       -1.91042\n",
      "GaussianMLPValueFunction/LossBefore      -1.81818\n",
      "GaussianMLPValueFunction/dLoss            0.0922371\n",
      "TotalEnvSteps                        155844\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.3102e-03, -1.0073e-03, -4.0716e-06,  ..., -8.1186e-03,\n",
      "         3.5439e-03, -9.2670e-03])\n",
      "G is: \n",
      "tensor([[1.0421e-03, 1.0097e+00],\n",
      "        [1.0097e+00, 9.8403e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [984.0311,   0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0006, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0008, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:37 | [trpo_pendulum] epoch #78 | Saving snapshot...\n",
      "2022-08-23 10:38:37 | [trpo_pendulum] epoch #78 | Saved\n",
      "2022-08-23 10:38:37 | [trpo_pendulum] epoch #78 | Time 78.40 s\n",
      "2022-08-23 10:38:37 | [trpo_pendulum] epoch #78 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.132438\n",
      "Evaluation/AverageReturn                 -1.35234\n",
      "Evaluation/Iteration                     78\n",
      "Evaluation/MaxReturn                     -1.28811\n",
      "Evaluation/MinReturn                     -1.41658\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0642351\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.856747\n",
      "GaussianMLPPolicy/KL                      0.00736974\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000770443\n",
      "GaussianMLPPolicy/LossBefore             -0.000554503\n",
      "GaussianMLPPolicy/dLoss                   0.000215939\n",
      "GaussianMLPValueFunction/LossAfter       -1.96855\n",
      "GaussianMLPValueFunction/LossBefore      -1.91448\n",
      "GaussianMLPValueFunction/dLoss            0.0540682\n",
      "TotalEnvSteps                        157842\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.8658e-03, -2.5961e-04, -8.5625e-07,  ..., -2.3830e-03,\n",
      "         1.0360e-03, -2.7116e-03])\n",
      "G is: \n",
      "tensor([[9.1452e-05, 9.8575e-02],\n",
      "        [9.8575e-02, 1.1052e+02]])\n",
      "eig is:\n",
      "tensor([[7.6294e-06, 0.0000e+00],\n",
      "        [1.1052e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0080, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0081, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:38 | [trpo_pendulum] epoch #79 | Saving snapshot...\n",
      "2022-08-23 10:38:38 | [trpo_pendulum] epoch #79 | Saved\n",
      "2022-08-23 10:38:38 | [trpo_pendulum] epoch #79 | Time 79.36 s\n",
      "2022-08-23 10:38:38 | [trpo_pendulum] epoch #79 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.10118\n",
      "Evaluation/AverageReturn                 -1.07868\n",
      "Evaluation/Iteration                     79\n",
      "Evaluation/MaxReturn                     -1.07402\n",
      "Evaluation/MinReturn                     -1.08334\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00465895\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.927193\n",
      "GaussianMLPPolicy/KL                      0.00639337\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00812215\n",
      "GaussianMLPPolicy/LossBefore             -0.00797702\n",
      "GaussianMLPPolicy/dLoss                   0.000145122\n",
      "GaussianMLPValueFunction/LossAfter       -2.08257\n",
      "GaussianMLPValueFunction/LossBefore      -1.90444\n",
      "GaussianMLPValueFunction/dLoss            0.178137\n",
      "TotalEnvSteps                        159840\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.2720e-04,  1.5358e-04, -1.4809e-06,  ...,  1.3161e-03,\n",
      "        -5.7446e-04,  1.5019e-03])\n",
      "G is: \n",
      "tensor([[2.7626e-05, 3.4327e-02],\n",
      "        [3.4327e-02, 4.4047e+01]])\n",
      "eig is:\n",
      "tensor([[ 0.0000,  0.0000],\n",
      "        [44.0472,  0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0027, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0027, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:39 | [trpo_pendulum] epoch #80 | Saving snapshot...\n",
      "2022-08-23 10:38:39 | [trpo_pendulum] epoch #80 | Saved\n",
      "2022-08-23 10:38:39 | [trpo_pendulum] epoch #80 | Time 80.37 s\n",
      "2022-08-23 10:38:39 | [trpo_pendulum] epoch #80 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0928094\n",
      "Evaluation/AverageReturn                 -0.952979\n",
      "Evaluation/Iteration                     80\n",
      "Evaluation/MaxReturn                     -0.932087\n",
      "Evaluation/MinReturn                     -0.97387\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0208916\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.931732\n",
      "GaussianMLPPolicy/KL                      0.00218811\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00268431\n",
      "GaussianMLPPolicy/LossBefore             -0.00268148\n",
      "GaussianMLPPolicy/dLoss                   2.82237e-06\n",
      "GaussianMLPValueFunction/LossAfter       -2.21684\n",
      "GaussianMLPValueFunction/LossBefore      -2.12395\n",
      "GaussianMLPValueFunction/dLoss            0.0928936\n",
      "TotalEnvSteps                        161838\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.2406e-03, -1.1212e-04,  1.5610e-06,  ..., -1.5804e-03,\n",
      "         6.4382e-04, -1.8228e-03])\n",
      "G is: \n",
      "tensor([[4.5067e-05, 5.3768e-02],\n",
      "        [5.3768e-02, 7.2205e+01]])\n",
      "eig is:\n",
      "tensor([[7.6294e-06, 0.0000e+00],\n",
      "        [7.2205e+01, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0007, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0009, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:40 | [trpo_pendulum] epoch #81 | Saving snapshot...\n",
      "2022-08-23 10:38:40 | [trpo_pendulum] epoch #81 | Saved\n",
      "2022-08-23 10:38:40 | [trpo_pendulum] epoch #81 | Time 81.47 s\n",
      "2022-08-23 10:38:40 | [trpo_pendulum] epoch #81 | EpochTime 1.10 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0917069\n",
      "Evaluation/AverageReturn                 -0.931578\n",
      "Evaluation/Iteration                     81\n",
      "Evaluation/MaxReturn                     -0.914279\n",
      "Evaluation/MinReturn                     -0.948877\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0172991\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.00927\n",
      "GaussianMLPPolicy/KL                      0.00737253\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00089627\n",
      "GaussianMLPPolicy/LossBefore             -0.000719198\n",
      "GaussianMLPPolicy/dLoss                   0.000177072\n",
      "GaussianMLPValueFunction/LossAfter       -2.21556\n",
      "GaussianMLPValueFunction/LossBefore      -2.16418\n",
      "GaussianMLPValueFunction/dLoss            0.0513797\n",
      "TotalEnvSteps                        163836\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.1368e-03,  1.7344e-04, -4.2634e-06,  ...,  2.9485e-03,\n",
      "        -1.1832e-03,  3.4303e-03])\n",
      "G is: \n",
      "tensor([[1.4745e-04, 2.2833e-01],\n",
      "        [2.2833e-01, 3.6591e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [365.9146,   0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0017, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0019, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:41 | [trpo_pendulum] epoch #82 | Saving snapshot...\n",
      "2022-08-23 10:38:41 | [trpo_pendulum] epoch #82 | Saved\n",
      "2022-08-23 10:38:41 | [trpo_pendulum] epoch #82 | Time 82.49 s\n",
      "2022-08-23 10:38:41 | [trpo_pendulum] epoch #82 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0737675\n",
      "Evaluation/AverageReturn                 -0.837219\n",
      "Evaluation/Iteration                     82\n",
      "Evaluation/MaxReturn                     -0.835281\n",
      "Evaluation/MinReturn                     -0.839157\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0019379\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.09234\n",
      "GaussianMLPPolicy/KL                      0.00970849\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00192915\n",
      "GaussianMLPPolicy/LossBefore             -0.00170668\n",
      "GaussianMLPPolicy/dLoss                   0.000222472\n",
      "GaussianMLPValueFunction/LossAfter       -2.3228\n",
      "GaussianMLPValueFunction/LossBefore      -2.25495\n",
      "GaussianMLPValueFunction/dLoss            0.067848\n",
      "TotalEnvSteps                        165834\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.5495e-03, -2.4755e-04, -4.4844e-07,  ..., -2.8004e-03,\n",
      "         1.1629e-03, -3.2091e-03])\n",
      "G is: \n",
      "tensor([[1.2692e-04, 2.2864e-01],\n",
      "        [2.2864e-01, 4.1979e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [419.7884,   0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0061, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0063, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:42 | [trpo_pendulum] epoch #83 | Saving snapshot...\n",
      "2022-08-23 10:38:42 | [trpo_pendulum] epoch #83 | Saved\n",
      "2022-08-23 10:38:42 | [trpo_pendulum] epoch #83 | Time 83.45 s\n",
      "2022-08-23 10:38:42 | [trpo_pendulum] epoch #83 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0705821\n",
      "Evaluation/AverageReturn                 -0.665858\n",
      "Evaluation/Iteration                     83\n",
      "Evaluation/MaxReturn                     -0.641295\n",
      "Evaluation/MinReturn                     -0.690421\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.024563\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.16987\n",
      "GaussianMLPPolicy/KL                      0.00672993\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00626421\n",
      "GaussianMLPPolicy/LossBefore             -0.00614846\n",
      "GaussianMLPPolicy/dLoss                   0.000115758\n",
      "GaussianMLPValueFunction/LossAfter       -2.43331\n",
      "GaussianMLPValueFunction/LossBefore      -2.24084\n",
      "GaussianMLPValueFunction/dLoss            0.192476\n",
      "TotalEnvSteps                        167832\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.1129e-03, -1.9826e-04,  2.2277e-06,  ..., -2.6776e-03,\n",
      "         1.0989e-03, -3.0809e-03])\n",
      "G is: \n",
      "tensor([[1.1511e-04, 2.4402e-01],\n",
      "        [2.4402e-01, 5.2304e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [523.0395,   0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0005, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0006, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:43 | [trpo_pendulum] epoch #84 | Saving snapshot...\n",
      "2022-08-23 10:38:43 | [trpo_pendulum] epoch #84 | Saved\n",
      "2022-08-23 10:38:43 | [trpo_pendulum] epoch #84 | Time 84.39 s\n",
      "2022-08-23 10:38:43 | [trpo_pendulum] epoch #84 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0573982\n",
      "Evaluation/AverageReturn                 -0.555393\n",
      "Evaluation/Iteration                     84\n",
      "Evaluation/MaxReturn                     -0.554935\n",
      "Evaluation/MinReturn                     -0.55585\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000457456\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.24222\n",
      "GaussianMLPPolicy/KL                      0.00860501\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000571549\n",
      "GaussianMLPPolicy/LossBefore             -0.000477748\n",
      "GaussianMLPPolicy/dLoss                   9.38001e-05\n",
      "GaussianMLPValueFunction/LossAfter       -2.55631\n",
      "GaussianMLPValueFunction/LossBefore      -2.47722\n",
      "GaussianMLPValueFunction/dLoss            0.0790873\n",
      "TotalEnvSteps                        169830\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.8106e-04,  3.2175e-05, -1.2372e-06,  ...,  5.0370e-04,\n",
      "        -2.0432e-04,  5.8395e-04])\n",
      "G is: \n",
      "tensor([[4.4709e-06, 1.0444e-02],\n",
      "        [1.0444e-02, 2.6440e+01]])\n",
      "eig is:\n",
      "tensor([[ 0.0000,  0.0000],\n",
      "        [26.4401,  0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0027, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0027, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:44 | [trpo_pendulum] epoch #85 | Saving snapshot...\n",
      "2022-08-23 10:38:44 | [trpo_pendulum] epoch #85 | Saved\n",
      "2022-08-23 10:38:44 | [trpo_pendulum] epoch #85 | Time 85.36 s\n",
      "2022-08-23 10:38:44 | [trpo_pendulum] epoch #85 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0509821\n",
      "Evaluation/AverageReturn                 -0.485356\n",
      "Evaluation/Iteration                     85\n",
      "Evaluation/MaxReturn                     -0.482222\n",
      "Evaluation/MinReturn                     -0.488491\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00313444\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.31635\n",
      "GaussianMLPPolicy/KL                      0.00662539\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0027444\n",
      "GaussianMLPPolicy/LossBefore             -0.00270489\n",
      "GaussianMLPPolicy/dLoss                   3.95123e-05\n",
      "GaussianMLPValueFunction/LossAfter       -2.68282\n",
      "GaussianMLPValueFunction/LossBefore      -2.56144\n",
      "GaussianMLPValueFunction/dLoss            0.121382\n",
      "TotalEnvSteps                        171828\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.1832e-03, -1.6827e-04, -8.5194e-07,  ..., -1.9008e-03,\n",
      "         7.8885e-04, -2.1781e-03])\n",
      "G is: \n",
      "tensor([[5.8961e-05, 1.6597e-01],\n",
      "        [1.6597e-01, 4.7851e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [478.5072,   0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0029, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0030, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:44 | [trpo_pendulum] epoch #86 | Saving snapshot...\n",
      "2022-08-23 10:38:45 | [trpo_pendulum] epoch #86 | Saved\n",
      "2022-08-23 10:38:45 | [trpo_pendulum] epoch #86 | Time 86.30 s\n",
      "2022-08-23 10:38:45 | [trpo_pendulum] epoch #86 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0384615\n",
      "Evaluation/AverageReturn                 -0.394595\n",
      "Evaluation/Iteration                     86\n",
      "Evaluation/MaxReturn                     -0.387239\n",
      "Evaluation/MinReturn                     -0.40195\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00735574\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.39451\n",
      "GaussianMLPPolicy/KL                      0.0070715\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00295171\n",
      "GaussianMLPPolicy/LossBefore             -0.00286044\n",
      "GaussianMLPPolicy/dLoss                   9.12743e-05\n",
      "GaussianMLPValueFunction/LossAfter       -2.72326\n",
      "GaussianMLPValueFunction/LossBefore      -2.63225\n",
      "GaussianMLPValueFunction/dLoss            0.0910158\n",
      "TotalEnvSteps                        173826\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.1895e-04,  6.7269e-05,  3.4507e-06,  ...,  8.9843e-04,\n",
      "        -3.6685e-04,  1.0295e-03])\n",
      "G is: \n",
      "tensor([[1.3395e-05, 4.2578e-02],\n",
      "        [4.2578e-02, 1.4250e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [142.4989,   0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0025, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0026, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:45 | [trpo_pendulum] epoch #87 | Saving snapshot...\n",
      "2022-08-23 10:38:45 | [trpo_pendulum] epoch #87 | Saved\n",
      "2022-08-23 10:38:45 | [trpo_pendulum] epoch #87 | Time 87.24 s\n",
      "2022-08-23 10:38:45 | [trpo_pendulum] epoch #87 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.034946\n",
      "Evaluation/AverageReturn                 -0.356742\n",
      "Evaluation/Iteration                     87\n",
      "Evaluation/MaxReturn                     -0.354006\n",
      "Evaluation/MinReturn                     -0.359478\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00273576\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.45471\n",
      "GaussianMLPPolicy/KL                      0.00615784\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00259014\n",
      "GaussianMLPPolicy/LossBefore             -0.00254616\n",
      "GaussianMLPPolicy/dLoss                   4.39784e-05\n",
      "GaussianMLPValueFunction/LossAfter       -2.85728\n",
      "GaussianMLPValueFunction/LossBefore      -2.73397\n",
      "GaussianMLPValueFunction/dLoss            0.123307\n",
      "TotalEnvSteps                        175824\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.9107e-04,  1.6228e-04,  2.3428e-06,  ...,  1.7035e-03,\n",
      "        -7.0650e-04,  1.9549e-03])\n",
      "G is: \n",
      "tensor([[4.7000e-05, 1.7956e-01],\n",
      "        [1.7956e-01, 6.8953e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [689.5303,   0.0000]])\n",
      "2022-08-23 10:38:46 | [trpo_pendulum] epoch #88 | Line search condition violated. Rejecting the step!\n",
      "2022-08-23 10:38:46 | [trpo_pendulum] epoch #88 | Violated because loss not improving\n",
      "2022-08-23 10:38:46 | [trpo_pendulum] epoch #88 | Saving snapshot...\n",
      "2022-08-23 10:38:46 | [trpo_pendulum] epoch #88 | Saved\n",
      "2022-08-23 10:38:46 | [trpo_pendulum] epoch #88 | Time 88.24 s\n",
      "2022-08-23 10:38:46 | [trpo_pendulum] epoch #88 | EpochTime 1.00 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0303163\n",
      "Evaluation/AverageReturn                 -0.322409\n",
      "Evaluation/Iteration                     88\n",
      "Evaluation/MaxReturn                     -0.31366\n",
      "Evaluation/MinReturn                     -0.331158\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00874911\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.45471\n",
      "GaussianMLPPolicy/KL                      0\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00255988\n",
      "GaussianMLPPolicy/LossBefore             -0.00255988\n",
      "GaussianMLPPolicy/dLoss                   0\n",
      "GaussianMLPValueFunction/LossAfter       -2.93233\n",
      "GaussianMLPValueFunction/LossBefore      -2.81153\n",
      "GaussianMLPValueFunction/dLoss            0.120806\n",
      "TotalEnvSteps                        177822\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.9410e-04,  1.1950e-04,  2.0677e-07,  ...,  1.1647e-03,\n",
      "        -4.8709e-04,  1.3349e-03])\n",
      "G is: \n",
      "tensor([[2.2686e-05, 8.4062e-02],\n",
      "        [8.4062e-02, 3.2285e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [322.8547,   0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0013, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0012, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:47 | [trpo_pendulum] epoch #89 | Saving snapshot...\n",
      "2022-08-23 10:38:47 | [trpo_pendulum] epoch #89 | Saved\n",
      "2022-08-23 10:38:47 | [trpo_pendulum] epoch #89 | Time 89.20 s\n",
      "2022-08-23 10:38:47 | [trpo_pendulum] epoch #89 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0336237\n",
      "Evaluation/AverageReturn                 -0.329594\n",
      "Evaluation/Iteration                     89\n",
      "Evaluation/MaxReturn                     -0.328593\n",
      "Evaluation/MinReturn                     -0.330595\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00100141\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.53148\n",
      "GaussianMLPPolicy/KL                      0.006528\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00123511\n",
      "GaussianMLPPolicy/LossBefore              0.0013048\n",
      "GaussianMLPPolicy/dLoss                   6.96942e-05\n",
      "GaussianMLPValueFunction/LossAfter       -2.97234\n",
      "GaussianMLPValueFunction/LossBefore      -2.90065\n",
      "GaussianMLPValueFunction/dLoss            0.0716877\n",
      "TotalEnvSteps                        179820\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.4261e-05,  3.6627e-04, -4.5966e-06,  ...,  4.4551e-03,\n",
      "        -1.8410e-03,  5.1085e-03])\n",
      "G is: \n",
      "tensor([[3.2166e-04, 1.4524e+00],\n",
      "        [1.4524e+00, 6.5583e+03]])\n",
      "eig is:\n",
      "tensor([[   0.0000,    0.0000],\n",
      "        [6558.3247,    0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0013, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0013, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:48 | [trpo_pendulum] epoch #90 | Saving snapshot...\n",
      "2022-08-23 10:38:48 | [trpo_pendulum] epoch #90 | Saved\n",
      "2022-08-23 10:38:48 | [trpo_pendulum] epoch #90 | Time 90.14 s\n",
      "2022-08-23 10:38:48 | [trpo_pendulum] epoch #90 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0279958\n",
      "Evaluation/AverageReturn                 -0.295349\n",
      "Evaluation/Iteration                     90\n",
      "Evaluation/MaxReturn                     -0.294485\n",
      "Evaluation/MinReturn                     -0.296213\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00086403\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.53576\n",
      "GaussianMLPPolicy/KL                      0.00037926\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00126543\n",
      "GaussianMLPPolicy/LossBefore              0.00126578\n",
      "GaussianMLPPolicy/dLoss                   3.54485e-07\n",
      "GaussianMLPValueFunction/LossAfter       -3.08002\n",
      "GaussianMLPValueFunction/LossBefore      -3.00534\n",
      "GaussianMLPValueFunction/dLoss            0.0746791\n",
      "TotalEnvSteps                        181818\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.1487e-04,  8.7786e-05,  5.7454e-08,  ...,  1.2555e-03,\n",
      "        -5.1588e-04,  1.4361e-03])\n",
      "G is: \n",
      "tensor([[2.5549e-05, 1.1345e-01],\n",
      "        [1.1345e-01, 5.1130e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [511.3015,   0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0026, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0027, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:49 | [trpo_pendulum] epoch #91 | Saving snapshot...\n",
      "2022-08-23 10:38:49 | [trpo_pendulum] epoch #91 | Saved\n",
      "2022-08-23 10:38:49 | [trpo_pendulum] epoch #91 | Time 91.09 s\n",
      "2022-08-23 10:38:49 | [trpo_pendulum] epoch #91 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0300666\n",
      "Evaluation/AverageReturn                 -0.285015\n",
      "Evaluation/Iteration                     91\n",
      "Evaluation/MaxReturn                     -0.279151\n",
      "Evaluation/MinReturn                     -0.29088\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00586443\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.61252\n",
      "GaussianMLPPolicy/KL                      0.0064365\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.002681\n",
      "GaussianMLPPolicy/LossBefore             -0.00263567\n",
      "GaussianMLPPolicy/dLoss                   4.53356e-05\n",
      "GaussianMLPValueFunction/LossAfter       -3.15702\n",
      "GaussianMLPValueFunction/LossBefore      -2.99201\n",
      "GaussianMLPValueFunction/dLoss            0.165012\n",
      "TotalEnvSteps                        183816\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.4443e-04,  1.1377e-04, -1.9194e-07,  ...,  1.6983e-03,\n",
      "        -6.9559e-04,  1.9457e-03])\n",
      "G is: \n",
      "tensor([[4.6226e-05, 2.4172e-01],\n",
      "        [2.4172e-01, 1.2695e+03]])\n",
      "eig is:\n",
      "tensor([[-1.2207e-04,  0.0000e+00],\n",
      "        [ 1.2695e+03,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-0.0016, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0017, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:50 | [trpo_pendulum] epoch #92 | Saving snapshot...\n",
      "2022-08-23 10:38:50 | [trpo_pendulum] epoch #92 | Saved\n",
      "2022-08-23 10:38:50 | [trpo_pendulum] epoch #92 | Time 92.03 s\n",
      "2022-08-23 10:38:50 | [trpo_pendulum] epoch #92 | EpochTime 0.93 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0215942\n",
      "Evaluation/AverageReturn                 -0.236483\n",
      "Evaluation/Iteration                     92\n",
      "Evaluation/MaxReturn                     -0.231599\n",
      "Evaluation/MinReturn                     -0.241366\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00488397\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.68039\n",
      "GaussianMLPPolicy/KL                      0.00720522\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0016543\n",
      "GaussianMLPPolicy/LossBefore             -0.00161672\n",
      "GaussianMLPPolicy/dLoss                   3.7576e-05\n",
      "GaussianMLPValueFunction/LossAfter       -3.24383\n",
      "GaussianMLPValueFunction/LossBefore      -3.14033\n",
      "GaussianMLPValueFunction/dLoss            0.103501\n",
      "TotalEnvSteps                        185814\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.1719e-04,  5.1053e-05, -5.2248e-07,  ...,  5.6649e-04,\n",
      "        -2.3808e-04,  6.4469e-04])\n",
      "G is: \n",
      "tensor([[5.2546e-06, 3.0278e-02],\n",
      "        [3.0278e-02, 1.8048e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [180.4848,   0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0015, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0015, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:51 | [trpo_pendulum] epoch #93 | Saving snapshot...\n",
      "2022-08-23 10:38:51 | [trpo_pendulum] epoch #93 | Saved\n",
      "2022-08-23 10:38:51 | [trpo_pendulum] epoch #93 | Time 92.99 s\n",
      "2022-08-23 10:38:51 | [trpo_pendulum] epoch #93 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0218787\n",
      "Evaluation/AverageReturn                 -0.215255\n",
      "Evaluation/Iteration                     93\n",
      "Evaluation/MaxReturn                     -0.207527\n",
      "Evaluation/MinReturn                     -0.222982\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00772791\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.77176\n",
      "GaussianMLPPolicy/KL                      0.00961203\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00151652\n",
      "GaussianMLPPolicy/LossBefore             -0.0014768\n",
      "GaussianMLPPolicy/dLoss                   3.97263e-05\n",
      "GaussianMLPValueFunction/LossAfter       -3.34396\n",
      "GaussianMLPValueFunction/LossBefore      -3.2299\n",
      "GaussianMLPValueFunction/dLoss            0.114066\n",
      "TotalEnvSteps                        187812\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.8097e-04, -9.1723e-05,  1.9940e-07,  ..., -1.3418e-03,\n",
      "         5.5345e-04, -1.5313e-03])\n",
      "G is: \n",
      "tensor([[2.8630e-05, 2.0438e-01],\n",
      "        [2.0438e-01, 1.4665e+03]])\n",
      "eig is:\n",
      "tensor([[-1.2207e-04,  0.0000e+00],\n",
      "        [ 1.4665e+03,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-0.0017, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0017, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:52 | [trpo_pendulum] epoch #94 | Saving snapshot...\n",
      "2022-08-23 10:38:52 | [trpo_pendulum] epoch #94 | Saved\n",
      "2022-08-23 10:38:52 | [trpo_pendulum] epoch #94 | Time 93.89 s\n",
      "2022-08-23 10:38:52 | [trpo_pendulum] epoch #94 | EpochTime 0.90 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0159842\n",
      "Evaluation/AverageReturn                 -0.171557\n",
      "Evaluation/Iteration                     94\n",
      "Evaluation/MaxReturn                     -0.168701\n",
      "Evaluation/MinReturn                     -0.174412\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0028558\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.86333\n",
      "GaussianMLPPolicy/KL                      0.00947361\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00171976\n",
      "GaussianMLPPolicy/LossBefore             -0.00168473\n",
      "GaussianMLPPolicy/dLoss                   3.50368e-05\n",
      "GaussianMLPValueFunction/LossAfter       -3.43881\n",
      "GaussianMLPValueFunction/LossBefore      -3.2984\n",
      "GaussianMLPValueFunction/dLoss            0.140412\n",
      "TotalEnvSteps                        189810\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.4575e-04, -7.6797e-05,  2.6974e-07,  ..., -5.2517e-04,\n",
      "         2.3655e-04, -5.7884e-04])\n",
      "G is: \n",
      "tensor([[4.5308e-06, 3.7573e-02],\n",
      "        [3.7573e-02, 3.2370e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [323.7046,   0.0000]])\n",
      "loss before is:\n",
      "tensor(9.1867e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(6.0312e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:53 | [trpo_pendulum] epoch #95 | Saving snapshot...\n",
      "2022-08-23 10:38:53 | [trpo_pendulum] epoch #95 | Saved\n",
      "2022-08-23 10:38:53 | [trpo_pendulum] epoch #95 | Time 94.87 s\n",
      "2022-08-23 10:38:53 | [trpo_pendulum] epoch #95 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0159768\n",
      "Evaluation/AverageReturn                 -0.159386\n",
      "Evaluation/Iteration                     95\n",
      "Evaluation/MaxReturn                     -0.157263\n",
      "Evaluation/MinReturn                     -0.161508\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00212221\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.92414\n",
      "GaussianMLPPolicy/KL                      0.00784985\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               6.03125e-05\n",
      "GaussianMLPPolicy/LossBefore              9.18674e-05\n",
      "GaussianMLPPolicy/dLoss                   3.15549e-05\n",
      "GaussianMLPValueFunction/LossAfter       -3.51521\n",
      "GaussianMLPValueFunction/LossBefore      -3.43843\n",
      "GaussianMLPValueFunction/dLoss            0.0767775\n",
      "TotalEnvSteps                        191808\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.4576e-04, -8.0371e-05, -1.1783e-06,  ..., -1.0405e-03,\n",
      "         4.2875e-04, -1.1891e-03])\n",
      "G is: \n",
      "tensor([[1.7321e-05, 1.6775e-01],\n",
      "        [1.6775e-01, 1.6360e+03]])\n",
      "eig is:\n",
      "tensor([[   0.0000,    0.0000],\n",
      "        [1635.9839,    0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0012, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0012, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:54 | [trpo_pendulum] epoch #96 | Saving snapshot...\n",
      "2022-08-23 10:38:54 | [trpo_pendulum] epoch #96 | Saved\n",
      "2022-08-23 10:38:54 | [trpo_pendulum] epoch #96 | Time 95.85 s\n",
      "2022-08-23 10:38:54 | [trpo_pendulum] epoch #96 | EpochTime 0.98 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0129371\n",
      "Evaluation/AverageReturn                 -0.133763\n",
      "Evaluation/Iteration                     96\n",
      "Evaluation/MaxReturn                     -0.128362\n",
      "Evaluation/MinReturn                     -0.139165\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00540116\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.96931\n",
      "GaussianMLPPolicy/KL                      0.00974007\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00117909\n",
      "GaussianMLPPolicy/LossBefore             -0.00115955\n",
      "GaussianMLPPolicy/dLoss                   1.9538e-05\n",
      "GaussianMLPValueFunction/LossAfter       -3.60758\n",
      "GaussianMLPValueFunction/LossBefore      -3.48906\n",
      "GaussianMLPValueFunction/dLoss            0.118515\n",
      "TotalEnvSteps                        193806\n",
      "-----------------------------------  ---------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.4850e-04,  9.8610e-05,  3.5078e-08,  ...,  1.6022e-03,\n",
      "        -6.5763e-04,  1.8287e-03])\n",
      "G is: \n",
      "tensor([[4.0305e-05, 4.2533e-01],\n",
      "        [4.2533e-01, 4.4953e+03]])\n",
      "eig is:\n",
      "tensor([[   0.0000,    0.0000],\n",
      "        [4495.2539,    0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0008, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0008, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:55 | [trpo_pendulum] epoch #97 | Saving snapshot...\n",
      "2022-08-23 10:38:55 | [trpo_pendulum] epoch #97 | Saved\n",
      "2022-08-23 10:38:55 | [trpo_pendulum] epoch #97 | Time 96.81 s\n",
      "2022-08-23 10:38:55 | [trpo_pendulum] epoch #97 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0119664\n",
      "Evaluation/AverageReturn                 -0.11879\n",
      "Evaluation/Iteration                     97\n",
      "Evaluation/MaxReturn                     -0.11335\n",
      "Evaluation/MinReturn                     -0.12423\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00544005\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.03271\n",
      "GaussianMLPPolicy/KL                      0.00618004\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000774001\n",
      "GaussianMLPPolicy/LossBefore             -0.000754284\n",
      "GaussianMLPPolicy/dLoss                   1.97173e-05\n",
      "GaussianMLPValueFunction/LossAfter       -3.68059\n",
      "GaussianMLPValueFunction/LossBefore      -3.59409\n",
      "GaussianMLPValueFunction/dLoss            0.0864942\n",
      "TotalEnvSteps                        195804\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.4846e-04,  6.8714e-05, -1.4605e-08,  ...,  9.1981e-04,\n",
      "        -3.7999e-04,  1.0497e-03])\n",
      "G is: \n",
      "tensor([[1.3233e-05, 1.5667e-01],\n",
      "        [1.5667e-01, 1.8635e+03]])\n",
      "eig is:\n",
      "tensor([[   0.0000,    0.0000],\n",
      "        [1863.5381,    0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:56 | [trpo_pendulum] epoch #98 | Saving snapshot...\n",
      "2022-08-23 10:38:56 | [trpo_pendulum] epoch #98 | Saved\n",
      "2022-08-23 10:38:56 | [trpo_pendulum] epoch #98 | Time 97.75 s\n",
      "2022-08-23 10:38:56 | [trpo_pendulum] epoch #98 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.012057\n",
      "Evaluation/AverageReturn                 -0.110393\n",
      "Evaluation/Iteration                     98\n",
      "Evaluation/MaxReturn                     -0.10764\n",
      "Evaluation/MinReturn                     -0.113146\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00275286\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.11846\n",
      "GaussianMLPPolicy/KL                      0.00810633\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000237078\n",
      "GaussianMLPPolicy/LossBefore              0.000256214\n",
      "GaussianMLPPolicy/dLoss                   1.91362e-05\n",
      "GaussianMLPValueFunction/LossAfter       -3.76951\n",
      "GaussianMLPValueFunction/LossBefore      -3.69767\n",
      "GaussianMLPValueFunction/dLoss            0.0718369\n",
      "TotalEnvSteps                        197802\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.3288e-04,  8.2841e-06, -1.0742e-06,  ...,  8.6992e-04,\n",
      "        -3.3751e-04,  1.0104e-03])\n",
      "G is: \n",
      "tensor([[1.1853e-05, 1.6630e-01],\n",
      "        [1.6630e-01, 2.3479e+03]])\n",
      "eig is:\n",
      "tensor([[-2.4414e-04,  0.0000e+00],\n",
      "        [ 2.3479e+03,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:57 | [trpo_pendulum] epoch #99 | Saving snapshot...\n",
      "2022-08-23 10:38:57 | [trpo_pendulum] epoch #99 | Saved\n",
      "2022-08-23 10:38:57 | [trpo_pendulum] epoch #99 | Time 98.71 s\n",
      "2022-08-23 10:38:57 | [trpo_pendulum] epoch #99 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00964351\n",
      "Evaluation/AverageReturn                 -0.0927792\n",
      "Evaluation/Iteration                     99\n",
      "Evaluation/MaxReturn                     -0.0917167\n",
      "Evaluation/MinReturn                     -0.0938417\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00106252\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.16468\n",
      "GaussianMLPPolicy/KL                      0.00783564\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000208869\n",
      "GaussianMLPPolicy/LossBefore              0.000229465\n",
      "GaussianMLPPolicy/dLoss                   2.05959e-05\n",
      "GaussianMLPValueFunction/LossAfter       -3.81981\n",
      "GaussianMLPValueFunction/LossBefore      -3.75297\n",
      "GaussianMLPValueFunction/dLoss            0.0668375\n",
      "TotalEnvSteps                        199800\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.3457e-05,  6.7393e-05,  2.3048e-07,  ...,  9.7844e-04,\n",
      "        -4.0154e-04,  1.1179e-03])\n",
      "G is: \n",
      "tensor([[1.4828e-05, 2.2837e-01],\n",
      "        [2.2837e-01, 3.5181e+03]])\n",
      "eig is:\n",
      "tensor([[   0.0000,    0.0000],\n",
      "        [3518.0728,    0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0004, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0004, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:58 | [trpo_pendulum] epoch #100 | Saving snapshot...\n",
      "2022-08-23 10:38:58 | [trpo_pendulum] epoch #100 | Saved\n",
      "2022-08-23 10:38:58 | [trpo_pendulum] epoch #100 | Time 99.67 s\n",
      "2022-08-23 10:38:58 | [trpo_pendulum] epoch #100 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00780249\n",
      "Evaluation/AverageReturn                 -0.0838455\n",
      "Evaluation/Iteration                    100\n",
      "Evaluation/MaxReturn                     -0.081671\n",
      "Evaluation/MinReturn                     -0.08602\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00217446\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.20468\n",
      "GaussianMLPPolicy/KL                      0.00245531\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000443877\n",
      "GaussianMLPPolicy/LossBefore             -0.000440424\n",
      "GaussianMLPPolicy/dLoss                   3.45288e-06\n",
      "GaussianMLPValueFunction/LossAfter       -3.93914\n",
      "GaussianMLPValueFunction/LossBefore      -3.85248\n",
      "GaussianMLPValueFunction/dLoss            0.086664\n",
      "TotalEnvSteps                        201798\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.4449e-04, -1.5950e-04, -2.1175e-06,  ..., -1.8046e-03,\n",
      "         7.5154e-04, -2.0540e-03])\n",
      "G is: \n",
      "tensor([[5.0470e-05, 8.4177e-01],\n",
      "        [8.4177e-01, 1.4048e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [14048.2188,     0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:38:59 | [trpo_pendulum] epoch #101 | Saving snapshot...\n",
      "2022-08-23 10:38:59 | [trpo_pendulum] epoch #101 | Saved\n",
      "2022-08-23 10:38:59 | [trpo_pendulum] epoch #101 | Time 100.62 s\n",
      "2022-08-23 10:38:59 | [trpo_pendulum] epoch #101 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00695582\n",
      "Evaluation/AverageReturn                 -0.0735244\n",
      "Evaluation/Iteration                    101\n",
      "Evaluation/MaxReturn                     -0.0728742\n",
      "Evaluation/MinReturn                     -0.0741746\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000650216\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.25285\n",
      "GaussianMLPPolicy/KL                      0.00610406\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000225766\n",
      "GaussianMLPPolicy/LossBefore              0.000238996\n",
      "GaussianMLPPolicy/dLoss                   1.32307e-05\n",
      "GaussianMLPValueFunction/LossAfter       -3.96918\n",
      "GaussianMLPValueFunction/LossBefore      -3.8966\n",
      "GaussianMLPValueFunction/dLoss            0.0725789\n",
      "TotalEnvSteps                        203796\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.4562e-04,  2.3766e-05, -2.8484e-07,  ...,  3.6853e-04,\n",
      "        -1.5135e-04,  4.2069e-04])\n",
      "G is: \n",
      "tensor([[2.1138e-06, 3.8285e-02],\n",
      "        [3.8285e-02, 7.0044e+02]])\n",
      "eig is:\n",
      "tensor([[6.1035e-05, 0.0000e+00],\n",
      "        [7.0044e+02, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0012, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0012, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:00 | [trpo_pendulum] epoch #102 | Saving snapshot...\n",
      "2022-08-23 10:39:00 | [trpo_pendulum] epoch #102 | Saved\n",
      "2022-08-23 10:39:00 | [trpo_pendulum] epoch #102 | Time 101.57 s\n",
      "2022-08-23 10:39:00 | [trpo_pendulum] epoch #102 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00733126\n",
      "Evaluation/AverageReturn                 -0.0697101\n",
      "Evaluation/Iteration                    102\n",
      "Evaluation/MaxReturn                     -0.0677626\n",
      "Evaluation/MinReturn                     -0.0716576\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00194752\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.32441\n",
      "GaussianMLPPolicy/KL                      0.00543851\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00119533\n",
      "GaussianMLPPolicy/LossBefore             -0.00118527\n",
      "GaussianMLPPolicy/dLoss                   1.00632e-05\n",
      "GaussianMLPValueFunction/LossAfter       -4.09973\n",
      "GaussianMLPValueFunction/LossBefore      -3.90402\n",
      "GaussianMLPValueFunction/dLoss            0.195711\n",
      "TotalEnvSteps                        205794\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.3624e-04,  3.4086e-06, -4.1964e-07,  ..., -1.1773e-04,\n",
      "         4.2924e-05, -1.3695e-04])\n",
      "G is: \n",
      "tensor([[2.3467e-07, 4.5066e-03],\n",
      "        [4.5066e-03, 9.5115e+01]])\n",
      "eig is:\n",
      "tensor([[ 0.0000,  0.0000],\n",
      "        [95.1148,  0.0000]])\n",
      "loss before is:\n",
      "tensor(-8.3539e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-9.3189e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:01 | [trpo_pendulum] epoch #103 | Saving snapshot...\n",
      "2022-08-23 10:39:01 | [trpo_pendulum] epoch #103 | Saved\n",
      "2022-08-23 10:39:01 | [trpo_pendulum] epoch #103 | Time 102.57 s\n",
      "2022-08-23 10:39:01 | [trpo_pendulum] epoch #103 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0064265\n",
      "Evaluation/AverageReturn                 -0.0597753\n",
      "Evaluation/Iteration                    103\n",
      "Evaluation/MaxReturn                     -0.0579983\n",
      "Evaluation/MinReturn                     -0.0615523\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.001777\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.39056\n",
      "GaussianMLPPolicy/KL                      0.00587773\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -9.31894e-05\n",
      "GaussianMLPPolicy/LossBefore             -8.3539e-05\n",
      "GaussianMLPPolicy/dLoss                   9.65039e-06\n",
      "GaussianMLPValueFunction/LossAfter       -4.17804\n",
      "GaussianMLPValueFunction/LossBefore      -4.10227\n",
      "GaussianMLPValueFunction/dLoss            0.0757675\n",
      "TotalEnvSteps                        207792\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.9529e-05,  7.1206e-05,  8.5697e-07,  ...,  1.2135e-03,\n",
      "        -4.9637e-04,  1.3833e-03])\n",
      "G is: \n",
      "tensor([[2.2639e-05, 5.4532e-01],\n",
      "        [5.4532e-01, 1.3140e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [13139.8887,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0005, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0005, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:02 | [trpo_pendulum] epoch #104 | Saving snapshot...\n",
      "2022-08-23 10:39:02 | [trpo_pendulum] epoch #104 | Saved\n",
      "2022-08-23 10:39:02 | [trpo_pendulum] epoch #104 | Time 103.53 s\n",
      "2022-08-23 10:39:02 | [trpo_pendulum] epoch #104 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00518755\n",
      "Evaluation/AverageReturn                 -0.0523314\n",
      "Evaluation/Iteration                    104\n",
      "Evaluation/MaxReturn                     -0.050772\n",
      "Evaluation/MinReturn                     -0.0538908\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0015594\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.42175\n",
      "GaussianMLPPolicy/KL                      0.00757541\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000494263\n",
      "GaussianMLPPolicy/LossBefore             -0.000493822\n",
      "GaussianMLPPolicy/dLoss                   4.4133e-07\n",
      "GaussianMLPValueFunction/LossAfter       -4.24287\n",
      "GaussianMLPValueFunction/LossBefore      -4.16321\n",
      "GaussianMLPValueFunction/dLoss            0.0796652\n",
      "TotalEnvSteps                        209790\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.0617e-04,  1.1950e-04,  1.1042e-07,  ...,  1.5787e-03,\n",
      "        -6.5258e-04,  1.8027e-03])\n",
      "G is: \n",
      "tensor([[3.8791e-05, 1.0029e+00],\n",
      "        [1.0029e+00, 2.5938e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [25937.9648,     0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:03 | [trpo_pendulum] epoch #105 | Saving snapshot...\n",
      "2022-08-23 10:39:03 | [trpo_pendulum] epoch #105 | Saved\n",
      "2022-08-23 10:39:03 | [trpo_pendulum] epoch #105 | Time 104.46 s\n",
      "2022-08-23 10:39:03 | [trpo_pendulum] epoch #105 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0054466\n",
      "Evaluation/AverageReturn                 -0.0561397\n",
      "Evaluation/Iteration                    105\n",
      "Evaluation/MaxReturn                     -0.0552737\n",
      "Evaluation/MinReturn                     -0.0570057\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000865981\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.47911\n",
      "GaussianMLPPolicy/KL                      0.00440301\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000266565\n",
      "GaussianMLPPolicy/LossBefore              0.000274076\n",
      "GaussianMLPPolicy/dLoss                   7.51085e-06\n",
      "GaussianMLPValueFunction/LossAfter       -4.27378\n",
      "GaussianMLPValueFunction/LossBefore      -4.25515\n",
      "GaussianMLPValueFunction/dLoss            0.0186334\n",
      "TotalEnvSteps                        211788\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.1395e-05,  2.3759e-04,  3.0123e-07,  ...,  3.1342e-03,\n",
      "        -1.2956e-03,  3.5789e-03])\n",
      "G is: \n",
      "tensor([[1.5287e-04, 4.4346e+00],\n",
      "        [4.4346e+00, 1.2865e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [128645.5156,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0008, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0008, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:04 | [trpo_pendulum] epoch #106 | Saving snapshot...\n",
      "2022-08-23 10:39:04 | [trpo_pendulum] epoch #106 | Saved\n",
      "2022-08-23 10:39:04 | [trpo_pendulum] epoch #106 | Time 105.54 s\n",
      "2022-08-23 10:39:04 | [trpo_pendulum] epoch #106 | EpochTime 1.07 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00488726\n",
      "Evaluation/AverageReturn                 -0.0478067\n",
      "Evaluation/Iteration                    106\n",
      "Evaluation/MaxReturn                     -0.0458009\n",
      "Evaluation/MinReturn                     -0.0498126\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00200587\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.51253\n",
      "GaussianMLPPolicy/KL                      0.00442174\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000849721\n",
      "GaussianMLPPolicy/LossBefore             -0.000842183\n",
      "GaussianMLPPolicy/dLoss                   7.5383e-06\n",
      "GaussianMLPValueFunction/LossAfter       -4.33914\n",
      "GaussianMLPValueFunction/LossBefore      -4.23949\n",
      "GaussianMLPValueFunction/dLoss            0.0996513\n",
      "TotalEnvSteps                        213786\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.3439e-04, -9.9895e-05,  1.7038e-07,  ..., -1.9297e-03,\n",
      "         7.7880e-04, -2.2158e-03])\n",
      "G is: \n",
      "tensor([[5.7992e-05, 1.7972e+00],\n",
      "        [1.7972e+00, 5.5751e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [55751.1328,     0.0000]])\n",
      "loss before is:\n",
      "tensor(8.4095e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(7.0005e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:05 | [trpo_pendulum] epoch #107 | Saving snapshot...\n",
      "2022-08-23 10:39:05 | [trpo_pendulum] epoch #107 | Saved\n",
      "2022-08-23 10:39:05 | [trpo_pendulum] epoch #107 | Time 106.51 s\n",
      "2022-08-23 10:39:05 | [trpo_pendulum] epoch #107 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00414127\n",
      "Evaluation/AverageReturn                 -0.0449274\n",
      "Evaluation/Iteration                    107\n",
      "Evaluation/MaxReturn                     -0.043183\n",
      "Evaluation/MinReturn                     -0.0466719\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00174444\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.57011\n",
      "GaussianMLPPolicy/KL                      0.00718361\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               7.00048e-05\n",
      "GaussianMLPPolicy/LossBefore              8.40955e-05\n",
      "GaussianMLPPolicy/dLoss                   1.40907e-05\n",
      "GaussianMLPValueFunction/LossAfter       -4.41175\n",
      "GaussianMLPValueFunction/LossBefore      -4.34832\n",
      "GaussianMLPValueFunction/dLoss            0.0634308\n",
      "TotalEnvSteps                        215784\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.4144e-04,  5.2347e-05,  5.2351e-07,  ...,  7.5607e-04,\n",
      "        -3.1087e-04,  8.6343e-04])\n",
      "G is: \n",
      "tensor([[8.9070e-06, 3.0941e-01],\n",
      "        [3.0941e-01, 1.0773e+04]])\n",
      "eig is:\n",
      "tensor([[-9.7656e-04,  0.0000e+00],\n",
      "        [ 1.0773e+04,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-0.0007, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0007, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:06 | [trpo_pendulum] epoch #108 | Saving snapshot...\n",
      "2022-08-23 10:39:06 | [trpo_pendulum] epoch #108 | Saved\n",
      "2022-08-23 10:39:06 | [trpo_pendulum] epoch #108 | Time 107.48 s\n",
      "2022-08-23 10:39:06 | [trpo_pendulum] epoch #108 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00366432\n",
      "Evaluation/AverageReturn                 -0.037964\n",
      "Evaluation/Iteration                    108\n",
      "Evaluation/MaxReturn                     -0.0358011\n",
      "Evaluation/MinReturn                     -0.0401268\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00216284\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.64045\n",
      "GaussianMLPPolicy/KL                      0.00533127\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0006723\n",
      "GaussianMLPPolicy/LossBefore             -0.000662331\n",
      "GaussianMLPPolicy/dLoss                   9.96876e-06\n",
      "GaussianMLPValueFunction/LossAfter       -4.51317\n",
      "GaussianMLPValueFunction/LossBefore      -4.37615\n",
      "GaussianMLPValueFunction/dLoss            0.137013\n",
      "TotalEnvSteps                        217782\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.8767e-06,  2.3763e-04,  2.0275e-07,  ...,  3.2185e-03,\n",
      "        -1.3311e-03,  3.6729e-03])\n",
      "G is: \n",
      "tensor([[1.6122e-04, 6.4648e+00],\n",
      "        [6.4648e+00, 2.5924e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [259239.5000,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0010, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0010, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:07 | [trpo_pendulum] epoch #109 | Saving snapshot...\n",
      "2022-08-23 10:39:07 | [trpo_pendulum] epoch #109 | Saved\n",
      "2022-08-23 10:39:07 | [trpo_pendulum] epoch #109 | Time 108.43 s\n",
      "2022-08-23 10:39:07 | [trpo_pendulum] epoch #109 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00391687\n",
      "Evaluation/AverageReturn                 -0.0362965\n",
      "Evaluation/Iteration                    109\n",
      "Evaluation/MaxReturn                     -0.0360447\n",
      "Evaluation/MinReturn                     -0.0365484\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000251857\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.64607\n",
      "GaussianMLPPolicy/KL                      0.000871038\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000955422\n",
      "GaussianMLPPolicy/LossBefore             -0.000954266\n",
      "GaussianMLPPolicy/dLoss                   1.15525e-06\n",
      "GaussianMLPValueFunction/LossAfter       -4.65842\n",
      "GaussianMLPValueFunction/LossBefore      -4.35114\n",
      "GaussianMLPValueFunction/dLoss            0.307283\n",
      "TotalEnvSteps                        219780\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.9816e-05,  8.8902e-05, -8.5099e-08,  ...,  1.4204e-03,\n",
      "        -5.8642e-04,  1.6184e-03])\n",
      "G is: \n",
      "tensor([[3.1514e-05, 1.2868e+00],\n",
      "        [1.2868e+00, 5.2551e+04]])\n",
      "eig is:\n",
      "tensor([[-3.9062e-03,  0.0000e+00],\n",
      "        [ 5.2551e+04,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:08 | [trpo_pendulum] epoch #110 | Saving snapshot...\n",
      "2022-08-23 10:39:08 | [trpo_pendulum] epoch #110 | Saved\n",
      "2022-08-23 10:39:08 | [trpo_pendulum] epoch #110 | Time 109.38 s\n",
      "2022-08-23 10:39:08 | [trpo_pendulum] epoch #110 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00404361\n",
      "Evaluation/AverageReturn                 -0.0374206\n",
      "Evaluation/Iteration                    110\n",
      "Evaluation/MaxReturn                     -0.0371831\n",
      "Evaluation/MinReturn                     -0.0376581\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000237506\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.68904\n",
      "GaussianMLPPolicy/KL                      0.00253539\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000206152\n",
      "GaussianMLPPolicy/LossBefore              0.000209813\n",
      "GaussianMLPPolicy/dLoss                   3.66115e-06\n",
      "GaussianMLPValueFunction/LossAfter       -4.73287\n",
      "GaussianMLPValueFunction/LossBefore      -4.64444\n",
      "GaussianMLPValueFunction/dLoss            0.0884228\n",
      "TotalEnvSteps                        221778\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.2994e-05,  1.5626e-04, -2.5219e-07,  ...,  2.5172e-03,\n",
      "        -1.0388e-03,  2.8686e-03])\n",
      "G is: \n",
      "tensor([[9.8952e-05, 4.4037e+00],\n",
      "        [4.4037e+00, 1.9599e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [195986.0938,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:09 | [trpo_pendulum] epoch #111 | Saving snapshot...\n",
      "2022-08-23 10:39:09 | [trpo_pendulum] epoch #111 | Saved\n",
      "2022-08-23 10:39:09 | [trpo_pendulum] epoch #111 | Time 110.34 s\n",
      "2022-08-23 10:39:09 | [trpo_pendulum] epoch #111 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00342736\n",
      "Evaluation/AverageReturn                 -0.0313134\n",
      "Evaluation/Iteration                    111\n",
      "Evaluation/MaxReturn                     -0.0302745\n",
      "Evaluation/MinReturn                     -0.0323523\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00103889\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.72677\n",
      "GaussianMLPPolicy/KL                      0.00315018\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000201129\n",
      "GaussianMLPPolicy/LossBefore             -0.000196162\n",
      "GaussianMLPPolicy/dLoss                   4.9669e-06\n",
      "GaussianMLPValueFunction/LossAfter       -4.81472\n",
      "GaussianMLPValueFunction/LossBefore      -4.72353\n",
      "GaussianMLPValueFunction/dLoss            0.0911908\n",
      "TotalEnvSteps                        223776\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.6894e-05,  3.1995e-05, -2.9776e-09,  ...,  5.0853e-04,\n",
      "        -2.1006e-04,  5.7924e-04])\n",
      "G is: \n",
      "tensor([[4.0379e-06, 1.9366e-01],\n",
      "        [1.9366e-01, 9.2915e+03]])\n",
      "eig is:\n",
      "tensor([[-9.7656e-04,  0.0000e+00],\n",
      "        [ 9.2915e+03,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-6.3487e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-6.4501e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:09 | [trpo_pendulum] epoch #112 | Saving snapshot...\n",
      "2022-08-23 10:39:09 | [trpo_pendulum] epoch #112 | Saved\n",
      "2022-08-23 10:39:09 | [trpo_pendulum] epoch #112 | Time 111.28 s\n",
      "2022-08-23 10:39:09 | [trpo_pendulum] epoch #112 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00307602\n",
      "Evaluation/AverageReturn                 -0.0295075\n",
      "Evaluation/Iteration                    112\n",
      "Evaluation/MaxReturn                     -0.028918\n",
      "Evaluation/MinReturn                     -0.0300971\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000589527\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.75193\n",
      "GaussianMLPPolicy/KL                      0.000726164\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.45011e-05\n",
      "GaussianMLPPolicy/LossBefore             -6.34869e-05\n",
      "GaussianMLPPolicy/dLoss                   1.01416e-06\n",
      "GaussianMLPValueFunction/LossAfter       -4.88606\n",
      "GaussianMLPValueFunction/LossBefore      -4.8244\n",
      "GaussianMLPValueFunction/dLoss            0.061667\n",
      "TotalEnvSteps                        225774\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.4157e-05,  1.1484e-04,  3.1475e-07,  ...,  1.8594e-03,\n",
      "        -7.6647e-04,  2.1189e-03])\n",
      "G is: \n",
      "tensor([[5.3963e-05, 2.7221e+00],\n",
      "        [2.7221e+00, 1.3732e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [137317.1094,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:10 | [trpo_pendulum] epoch #113 | Saving snapshot...\n",
      "2022-08-23 10:39:10 | [trpo_pendulum] epoch #113 | Saved\n",
      "2022-08-23 10:39:10 | [trpo_pendulum] epoch #113 | Time 112.23 s\n",
      "2022-08-23 10:39:10 | [trpo_pendulum] epoch #113 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00262441\n",
      "Evaluation/AverageReturn                 -0.0310279\n",
      "Evaluation/Iteration                    113\n",
      "Evaluation/MaxReturn                     -0.0299163\n",
      "Evaluation/MinReturn                     -0.0321395\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0011116\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.78617\n",
      "GaussianMLPPolicy/KL                      0.00210317\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000271673\n",
      "GaussianMLPPolicy/LossBefore              0.000274878\n",
      "GaussianMLPPolicy/dLoss                   3.20523e-06\n",
      "GaussianMLPValueFunction/LossAfter       -4.9294\n",
      "GaussianMLPValueFunction/LossBefore      -4.8266\n",
      "GaussianMLPValueFunction/dLoss            0.102799\n",
      "TotalEnvSteps                        227772\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.6146e-05,  1.6821e-04, -6.6746e-07,  ...,  2.5588e-03,\n",
      "        -1.0603e-03,  2.9133e-03])\n",
      "G is: \n",
      "tensor([[1.0225e-04, 5.5244e+00],\n",
      "        [5.5244e+00, 2.9847e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [298474.8125,      0.0000]])\n",
      "loss before is:\n",
      "tensor(3.5654e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(3.2452e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:11 | [trpo_pendulum] epoch #114 | Saving snapshot...\n",
      "2022-08-23 10:39:11 | [trpo_pendulum] epoch #114 | Saved\n",
      "2022-08-23 10:39:11 | [trpo_pendulum] epoch #114 | Time 113.17 s\n",
      "2022-08-23 10:39:11 | [trpo_pendulum] epoch #114 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00306724\n",
      "Evaluation/AverageReturn                 -0.0300979\n",
      "Evaluation/Iteration                    114\n",
      "Evaluation/MaxReturn                     -0.0281967\n",
      "Evaluation/MinReturn                     -0.0319991\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00190117\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.81067\n",
      "GaussianMLPPolicy/KL                      0.00203886\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               3.24521e-05\n",
      "GaussianMLPPolicy/LossBefore              3.56538e-05\n",
      "GaussianMLPPolicy/dLoss                   3.20172e-06\n",
      "GaussianMLPValueFunction/LossAfter       -4.41329\n",
      "GaussianMLPValueFunction/LossBefore      -4.89659\n",
      "GaussianMLPValueFunction/dLoss           -0.483305\n",
      "TotalEnvSteps                        229770\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.4178e-05,  7.9355e-05,  1.5419e-06,  ...,  1.5430e-03,\n",
      "        -6.2700e-04,  1.7641e-03])\n",
      "G is: \n",
      "tensor([[3.7134e-05, 2.1057e+00],\n",
      "        [2.1057e+00, 1.1944e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [119442.4453,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0014, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0014, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:12 | [trpo_pendulum] epoch #115 | Saving snapshot...\n",
      "2022-08-23 10:39:12 | [trpo_pendulum] epoch #115 | Saved\n",
      "2022-08-23 10:39:12 | [trpo_pendulum] epoch #115 | Time 114.19 s\n",
      "2022-08-23 10:39:12 | [trpo_pendulum] epoch #115 | EpochTime 1.02 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00229488\n",
      "Evaluation/AverageReturn                 -0.025206\n",
      "Evaluation/Iteration                    115\n",
      "Evaluation/MaxReturn                     -0.0240437\n",
      "Evaluation/MinReturn                     -0.0263683\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0011623\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.82805\n",
      "GaussianMLPPolicy/KL                      0.00654677\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00138633\n",
      "GaussianMLPPolicy/LossBefore             -0.00138563\n",
      "GaussianMLPPolicy/dLoss                   6.99423e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.07687\n",
      "GaussianMLPValueFunction/LossBefore      -3.86341\n",
      "GaussianMLPValueFunction/dLoss            1.21346\n",
      "TotalEnvSteps                        231768\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.7084e-05,  4.9436e-05, -2.5680e-07,  ...,  7.1525e-04,\n",
      "        -2.9550e-04,  8.1665e-04])\n",
      "G is: \n",
      "tensor([[8.0464e-06, 4.7489e-01],\n",
      "        [4.7489e-01, 2.8036e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [28035.8633,     0.0000]])\n",
      "loss before is:\n",
      "tensor(4.2954e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(4.1266e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:13 | [trpo_pendulum] epoch #116 | Saving snapshot...\n",
      "2022-08-23 10:39:13 | [trpo_pendulum] epoch #116 | Saved\n",
      "2022-08-23 10:39:13 | [trpo_pendulum] epoch #116 | Time 115.12 s\n",
      "2022-08-23 10:39:13 | [trpo_pendulum] epoch #116 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00263124\n",
      "Evaluation/AverageReturn                 -0.024962\n",
      "Evaluation/Iteration                    116\n",
      "Evaluation/MaxReturn                     -0.0232999\n",
      "Evaluation/MinReturn                     -0.0266242\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00166216\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.85969\n",
      "GaussianMLPPolicy/KL                      0.00118457\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               4.12658e-05\n",
      "GaussianMLPPolicy/LossBefore              4.29542e-05\n",
      "GaussianMLPPolicy/dLoss                   1.68847e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.08085\n",
      "GaussianMLPValueFunction/LossBefore      -5.11262\n",
      "GaussianMLPValueFunction/dLoss           -0.031764\n",
      "TotalEnvSteps                        233766\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-9.0794e-05,  2.4765e-04,  8.3638e-07,  ...,  3.9738e-03,\n",
      "        -1.6275e-03,  4.5471e-03])\n",
      "G is: \n",
      "tensor([[2.4807e-04, 1.5589e+01],\n",
      "        [1.5589e+01, 9.7976e+05]])\n",
      "eig is:\n",
      "tensor([[-6.2500e-02,  0.0000e+00],\n",
      "        [ 9.7976e+05,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(0.0012, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0011, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:14 | [trpo_pendulum] epoch #117 | Saving snapshot...\n",
      "2022-08-23 10:39:14 | [trpo_pendulum] epoch #117 | Saved\n",
      "2022-08-23 10:39:14 | [trpo_pendulum] epoch #117 | Time 116.08 s\n",
      "2022-08-23 10:39:14 | [trpo_pendulum] epoch #117 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00264435\n",
      "Evaluation/AverageReturn                 -0.0286769\n",
      "Evaluation/Iteration                    117\n",
      "Evaluation/MaxReturn                     -0.0283415\n",
      "Evaluation/MinReturn                     -0.0290123\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000335423\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.81458\n",
      "GaussianMLPPolicy/KL                      0.00455205\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00114528\n",
      "GaussianMLPPolicy/LossBefore              0.00115564\n",
      "GaussianMLPPolicy/dLoss                   1.03575e-05\n",
      "GaussianMLPValueFunction/LossAfter       -4.81174\n",
      "GaussianMLPValueFunction/LossBefore      -3.72835\n",
      "GaussianMLPValueFunction/dLoss            1.08339\n",
      "TotalEnvSteps                        235764\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.0632e-05, -1.1215e-04,  1.6102e-06,  ..., -1.3135e-03,\n",
      "         5.5226e-04, -1.4941e-03])\n",
      "G is: \n",
      "tensor([[2.7166e-05, 1.5604e+00],\n",
      "        [1.5604e+00, 8.9645e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [89645.2969,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0007, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0007, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:15 | [trpo_pendulum] epoch #118 | Saving snapshot...\n",
      "2022-08-23 10:39:15 | [trpo_pendulum] epoch #118 | Saved\n",
      "2022-08-23 10:39:15 | [trpo_pendulum] epoch #118 | Time 117.11 s\n",
      "2022-08-23 10:39:15 | [trpo_pendulum] epoch #118 | EpochTime 1.02 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00269796\n",
      "Evaluation/AverageReturn                 -0.0278545\n",
      "Evaluation/Iteration                    118\n",
      "Evaluation/MaxReturn                     -0.0262674\n",
      "Evaluation/MinReturn                     -0.0294415\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00158703\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.83467\n",
      "GaussianMLPPolicy/KL                      0.00899748\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000665992\n",
      "GaussianMLPPolicy/LossBefore             -0.000660849\n",
      "GaussianMLPPolicy/dLoss                   5.14335e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.06684\n",
      "GaussianMLPValueFunction/LossBefore      -4.72056\n",
      "GaussianMLPValueFunction/dLoss            0.346274\n",
      "TotalEnvSteps                        237762\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.7036e-05,  1.3416e-04, -1.0026e-07,  ...,  1.6048e-03,\n",
      "        -6.6752e-04,  1.8335e-03])\n",
      "G is: \n",
      "tensor([[4.0895e-05, 2.4629e+00],\n",
      "        [2.4629e+00, 1.4833e+05]])\n",
      "eig is:\n",
      "tensor([[1.5625e-02, 0.0000e+00],\n",
      "        [1.4833e+05, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:16 | [trpo_pendulum] epoch #119 | Saving snapshot...\n",
      "2022-08-23 10:39:16 | [trpo_pendulum] epoch #119 | Saved\n",
      "2022-08-23 10:39:16 | [trpo_pendulum] epoch #119 | Time 118.05 s\n",
      "2022-08-23 10:39:16 | [trpo_pendulum] epoch #119 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00266216\n",
      "Evaluation/AverageReturn                 -0.0256223\n",
      "Evaluation/Iteration                    119\n",
      "Evaluation/MaxReturn                     -0.0255005\n",
      "Evaluation/MinReturn                     -0.025744\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00012177\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.85294\n",
      "GaussianMLPPolicy/KL                      0.000975568\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000325075\n",
      "GaussianMLPPolicy/LossBefore             -0.000323684\n",
      "GaussianMLPPolicy/dLoss                   1.39044e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.28866\n",
      "GaussianMLPValueFunction/LossBefore      -5.1358\n",
      "GaussianMLPValueFunction/dLoss            0.152861\n",
      "TotalEnvSteps                        239760\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.0697e-05,  1.2108e-04,  9.8725e-08,  ...,  1.4718e-03,\n",
      "        -6.1132e-04,  1.6821e-03])\n",
      "G is: \n",
      "tensor([[3.4389e-05, 2.1477e+00],\n",
      "        [2.1477e+00, 1.3413e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [134130.7969,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:17 | [trpo_pendulum] epoch #120 | Saving snapshot...\n",
      "2022-08-23 10:39:17 | [trpo_pendulum] epoch #120 | Saved\n",
      "2022-08-23 10:39:17 | [trpo_pendulum] epoch #120 | Time 118.99 s\n",
      "2022-08-23 10:39:17 | [trpo_pendulum] epoch #120 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00250578\n",
      "Evaluation/AverageReturn                 -0.0245004\n",
      "Evaluation/Iteration                    120\n",
      "Evaluation/MaxReturn                     -0.0240114\n",
      "Evaluation/MinReturn                     -0.0249894\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000488997\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.87437\n",
      "GaussianMLPPolicy/KL                      0.000989507\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000181665\n",
      "GaussianMLPPolicy/LossBefore              0.000183077\n",
      "GaussianMLPPolicy/dLoss                   1.41183e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.19366\n",
      "GaussianMLPValueFunction/LossBefore      -5.28674\n",
      "GaussianMLPValueFunction/dLoss           -0.0930743\n",
      "TotalEnvSteps                        241758\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-5.9293e-05,  4.4350e-04,  5.4468e-06,  ...,  4.7264e-03,\n",
      "        -1.9788e-03,  5.3853e-03])\n",
      "G is: \n",
      "tensor([[3.5469e-04, 2.3113e+01],\n",
      "        [2.3113e+01, 1.5063e+06]])\n",
      "eig is:\n",
      "tensor([[1.2500e-01, 0.0000e+00],\n",
      "        [1.5063e+06, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.0009, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0009, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:18 | [trpo_pendulum] epoch #121 | Saving snapshot...\n",
      "2022-08-23 10:39:18 | [trpo_pendulum] epoch #121 | Saved\n",
      "2022-08-23 10:39:18 | [trpo_pendulum] epoch #121 | Time 120.02 s\n",
      "2022-08-23 10:39:18 | [trpo_pendulum] epoch #121 | EpochTime 1.02 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00239269\n",
      "Evaluation/AverageReturn                 -0.0294749\n",
      "Evaluation/Iteration                    121\n",
      "Evaluation/MaxReturn                     -0.028107\n",
      "Evaluation/MinReturn                     -0.0308427\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00136787\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.84639\n",
      "GaussianMLPPolicy/KL                      0.00317364\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000858916\n",
      "GaussianMLPPolicy/LossBefore              0.000867037\n",
      "GaussianMLPPolicy/dLoss                   8.12154e-06\n",
      "GaussianMLPValueFunction/LossAfter       -3.7442\n",
      "GaussianMLPValueFunction/LossBefore      -3.30611\n",
      "GaussianMLPValueFunction/dLoss            0.438094\n",
      "TotalEnvSteps                        243756\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.8639e-05,  1.7773e-04, -8.0394e-08,  ...,  1.8922e-03,\n",
      "        -7.9062e-04,  2.1631e-03])\n",
      "G is: \n",
      "tensor([[5.7453e-05, 3.5716e+00],\n",
      "        [3.5716e+00, 2.2203e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [222033.0312,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0004, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0004, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:19 | [trpo_pendulum] epoch #122 | Saving snapshot...\n",
      "2022-08-23 10:39:19 | [trpo_pendulum] epoch #122 | Saved\n",
      "2022-08-23 10:39:19 | [trpo_pendulum] epoch #122 | Time 120.95 s\n",
      "2022-08-23 10:39:19 | [trpo_pendulum] epoch #122 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00236979\n",
      "Evaluation/AverageReturn                 -0.0226357\n",
      "Evaluation/Iteration                    122\n",
      "Evaluation/MaxReturn                     -0.0214677\n",
      "Evaluation/MinReturn                     -0.0238037\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00116803\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.8768\n",
      "GaussianMLPPolicy/KL                      0.00149261\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000434776\n",
      "GaussianMLPPolicy/LossBefore             -0.000432531\n",
      "GaussianMLPPolicy/dLoss                   2.2444e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.23497\n",
      "GaussianMLPValueFunction/LossBefore      -5.09575\n",
      "GaussianMLPValueFunction/dLoss            0.139219\n",
      "TotalEnvSteps                        245754\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.8327e-05,  2.0153e-04, -1.2752e-06,  ...,  2.3122e-03,\n",
      "        -9.6157e-04,  2.6408e-03])\n",
      "G is: \n",
      "tensor([[8.5697e-05, 5.6652e+00],\n",
      "        [5.6652e+00, 3.7454e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [374541.5000,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0009, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0009, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:20 | [trpo_pendulum] epoch #123 | Saving snapshot...\n",
      "2022-08-23 10:39:20 | [trpo_pendulum] epoch #123 | Saved\n",
      "2022-08-23 10:39:20 | [trpo_pendulum] epoch #123 | Time 121.99 s\n",
      "2022-08-23 10:39:20 | [trpo_pendulum] epoch #123 | EpochTime 1.04 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00249266\n",
      "Evaluation/AverageReturn                 -0.0284723\n",
      "Evaluation/Iteration                    123\n",
      "Evaluation/MaxReturn                     -0.0284496\n",
      "Evaluation/MinReturn                     -0.028495\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.26784e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.92216\n",
      "GaussianMLPPolicy/KL                      0.00261722\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000879445\n",
      "GaussianMLPPolicy/LossBefore              0.000882888\n",
      "GaussianMLPPolicy/dLoss                   3.44327e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.28597\n",
      "GaussianMLPValueFunction/LossBefore      -4.30336\n",
      "GaussianMLPValueFunction/dLoss            0.982612\n",
      "TotalEnvSteps                        247752\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.0042e-04,  1.3420e-04,  3.2283e-07,  ...,  1.7890e-03,\n",
      "        -7.3718e-04,  2.0441e-03])\n",
      "G is: \n",
      "tensor([[5.0883e-05, 3.6618e+00],\n",
      "        [3.6618e+00, 2.6358e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [263583.6875,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:21 | [trpo_pendulum] epoch #124 | Saving snapshot...\n",
      "2022-08-23 10:39:21 | [trpo_pendulum] epoch #124 | Saved\n",
      "2022-08-23 10:39:21 | [trpo_pendulum] epoch #124 | Time 122.93 s\n",
      "2022-08-23 10:39:21 | [trpo_pendulum] epoch #124 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00270887\n",
      "Evaluation/AverageReturn                 -0.0322679\n",
      "Evaluation/Iteration                    124\n",
      "Evaluation/MaxReturn                     -0.0314763\n",
      "Evaluation/MinReturn                     -0.0330595\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000791594\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.97868\n",
      "GaussianMLPPolicy/KL                      0.00384466\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000483798\n",
      "GaussianMLPPolicy/LossBefore              0.000489941\n",
      "GaussianMLPPolicy/dLoss                   6.14274e-06\n",
      "GaussianMLPValueFunction/LossAfter       -4.91646\n",
      "GaussianMLPValueFunction/LossBefore      -4.57326\n",
      "GaussianMLPValueFunction/dLoss            0.343203\n",
      "TotalEnvSteps                        249750\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.1807e-05,  3.5695e-05,  1.2223e-07,  ...,  4.3130e-04,\n",
      "        -1.7903e-04,  4.9152e-04])\n",
      "G is: \n",
      "tensor([[2.9601e-06, 2.3866e-01],\n",
      "        [2.3866e-01, 1.9246e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [19246.1270,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0009, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0009, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:22 | [trpo_pendulum] epoch #125 | Saving snapshot...\n",
      "2022-08-23 10:39:22 | [trpo_pendulum] epoch #125 | Saved\n",
      "2022-08-23 10:39:22 | [trpo_pendulum] epoch #125 | Time 123.81 s\n",
      "2022-08-23 10:39:22 | [trpo_pendulum] epoch #125 | EpochTime 0.88 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0020783\n",
      "Evaluation/AverageReturn                 -0.0200885\n",
      "Evaluation/Iteration                    125\n",
      "Evaluation/MaxReturn                     -0.018645\n",
      "Evaluation/MinReturn                     -0.021532\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00144349\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -2.99401\n",
      "GaussianMLPPolicy/KL                      0.00030883\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000928987\n",
      "GaussianMLPPolicy/LossBefore             -0.000928584\n",
      "GaussianMLPPolicy/dLoss                   4.03088e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.42693\n",
      "GaussianMLPValueFunction/LossBefore      -4.32048\n",
      "GaussianMLPValueFunction/dLoss            1.10645\n",
      "TotalEnvSteps                        251748\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.8182e-05,  9.4799e-05, -1.2123e-06,  ...,  1.2169e-03,\n",
      "        -5.0390e-04,  1.3900e-03])\n",
      "G is: \n",
      "tensor([[2.3583e-05, 1.9618e+00],\n",
      "        [1.9618e+00, 1.6321e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [163205.5469,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-3.5333e-06, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-3.6994e-06, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:23 | [trpo_pendulum] epoch #126 | Saving snapshot...\n",
      "2022-08-23 10:39:23 | [trpo_pendulum] epoch #126 | Saved\n",
      "2022-08-23 10:39:23 | [trpo_pendulum] epoch #126 | Time 124.77 s\n",
      "2022-08-23 10:39:23 | [trpo_pendulum] epoch #126 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00207459\n",
      "Evaluation/AverageReturn                 -0.0205377\n",
      "Evaluation/Iteration                    126\n",
      "Evaluation/MaxReturn                     -0.0197627\n",
      "Evaluation/MinReturn                     -0.0213128\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000775053\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.00988\n",
      "GaussianMLPPolicy/KL                      0.00252419\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.69944e-06\n",
      "GaussianMLPPolicy/LossBefore             -3.53333e-06\n",
      "GaussianMLPPolicy/dLoss                   1.66103e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.17313\n",
      "GaussianMLPValueFunction/LossBefore      -5.41794\n",
      "GaussianMLPValueFunction/dLoss           -0.244811\n",
      "TotalEnvSteps                        253746\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.0233e-05,  6.8260e-05, -1.0720e-08,  ...,  9.6050e-04,\n",
      "        -3.9612e-04,  1.0951e-03])\n",
      "G is: \n",
      "tensor([[1.4573e-05, 1.2445e+00],\n",
      "        [1.2445e+00, 1.0628e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [106278.8047,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:24 | [trpo_pendulum] epoch #127 | Saving snapshot...\n",
      "2022-08-23 10:39:24 | [trpo_pendulum] epoch #127 | Saved\n",
      "2022-08-23 10:39:24 | [trpo_pendulum] epoch #127 | Time 125.73 s\n",
      "2022-08-23 10:39:24 | [trpo_pendulum] epoch #127 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00199879\n",
      "Evaluation/AverageReturn                 -0.0190982\n",
      "Evaluation/Iteration                    127\n",
      "Evaluation/MaxReturn                     -0.0182716\n",
      "Evaluation/MinReturn                     -0.0199249\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000826658\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.03704\n",
      "GaussianMLPPolicy/KL                      0.00091559\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00020208\n",
      "GaussianMLPPolicy/LossBefore              0.000203358\n",
      "GaussianMLPPolicy/dLoss                   1.27773e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.57906\n",
      "GaussianMLPValueFunction/LossBefore      -5.45531\n",
      "GaussianMLPValueFunction/dLoss            0.123754\n",
      "TotalEnvSteps                        255744\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-5.5084e-05,  2.6336e-04,  9.7303e-07,  ...,  3.2141e-03,\n",
      "        -1.3389e-03,  3.6498e-03])\n",
      "G is: \n",
      "tensor([[1.6320e-04, 1.4707e+01],\n",
      "        [1.4707e+01, 1.3256e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1325550.7500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0013, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0013, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:25 | [trpo_pendulum] epoch #128 | Saving snapshot...\n",
      "2022-08-23 10:39:25 | [trpo_pendulum] epoch #128 | Saved\n",
      "2022-08-23 10:39:25 | [trpo_pendulum] epoch #128 | Time 126.71 s\n",
      "2022-08-23 10:39:25 | [trpo_pendulum] epoch #128 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00257984\n",
      "Evaluation/AverageReturn                 -0.0313123\n",
      "Evaluation/Iteration                    128\n",
      "Evaluation/MaxReturn                     -0.0301389\n",
      "Evaluation/MinReturn                     -0.0324857\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00117344\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.00459\n",
      "GaussianMLPPolicy/KL                      0.00304898\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00131796\n",
      "GaussianMLPPolicy/LossBefore              0.0013235\n",
      "GaussianMLPPolicy/dLoss                   5.54195e-06\n",
      "GaussianMLPValueFunction/LossAfter       -4.37509\n",
      "GaussianMLPValueFunction/LossBefore      -1.3367\n",
      "GaussianMLPValueFunction/dLoss            3.03839\n",
      "TotalEnvSteps                        257742\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.5862e-05, -2.3205e-04, -4.2115e-06,  ..., -3.4295e-03,\n",
      "         1.4042e-03, -3.9148e-03])\n",
      "G is: \n",
      "tensor([[1.8587e-04, 1.5715e+01],\n",
      "        [1.5715e+01, 1.3288e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [1328843.,       0.]])\n",
      "loss before is:\n",
      "tensor(0.0010, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0009, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:26 | [trpo_pendulum] epoch #129 | Saving snapshot...\n",
      "2022-08-23 10:39:26 | [trpo_pendulum] epoch #129 | Saved\n",
      "2022-08-23 10:39:26 | [trpo_pendulum] epoch #129 | Time 127.64 s\n",
      "2022-08-23 10:39:26 | [trpo_pendulum] epoch #129 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00297461\n",
      "Evaluation/AverageReturn                 -0.0376484\n",
      "Evaluation/Iteration                    129\n",
      "Evaluation/MaxReturn                     -0.0344691\n",
      "Evaluation/MinReturn                     -0.0408278\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00317935\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.05103\n",
      "GaussianMLPPolicy/KL                      0.00918954\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000946786\n",
      "GaussianMLPPolicy/LossBefore              0.00095758\n",
      "GaussianMLPPolicy/dLoss                   1.07943e-05\n",
      "GaussianMLPValueFunction/LossAfter       -4.53215\n",
      "GaussianMLPValueFunction/LossBefore      -2.74805\n",
      "GaussianMLPValueFunction/dLoss            1.7841\n",
      "TotalEnvSteps                        259740\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.7745e-05, -3.5745e-05,  1.2799e-06,  ..., -6.3289e-04,\n",
      "         2.5923e-04, -7.2427e-04])\n",
      "G is: \n",
      "tensor([[6.3077e-06, 5.8310e-01],\n",
      "        [5.8310e-01, 5.3919e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [53918.9688,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0007, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0007, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:27 | [trpo_pendulum] epoch #130 | Saving snapshot...\n",
      "2022-08-23 10:39:27 | [trpo_pendulum] epoch #130 | Saved\n",
      "2022-08-23 10:39:27 | [trpo_pendulum] epoch #130 | Time 128.57 s\n",
      "2022-08-23 10:39:27 | [trpo_pendulum] epoch #130 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00266903\n",
      "Evaluation/AverageReturn                 -0.0284186\n",
      "Evaluation/Iteration                    130\n",
      "Evaluation/MaxReturn                     -0.0268705\n",
      "Evaluation/MinReturn                     -0.0299666\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00154803\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.06708\n",
      "GaussianMLPPolicy/KL                      0.000835017\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000744318\n",
      "GaussianMLPPolicy/LossBefore             -0.000743359\n",
      "GaussianMLPPolicy/dLoss                   9.58855e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.15418\n",
      "GaussianMLPValueFunction/LossBefore      -4.3992\n",
      "GaussianMLPValueFunction/dLoss            0.754981\n",
      "TotalEnvSteps                        261738\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.8033e-05,  9.5606e-05,  8.3826e-07,  ...,  1.4696e-03,\n",
      "        -6.0225e-04,  1.6768e-03])\n",
      "G is: \n",
      "tensor([[3.4060e-05, 3.2594e+00],\n",
      "        [3.2594e+00, 3.1192e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [311922.3125,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0007, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0007, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:28 | [trpo_pendulum] epoch #131 | Saving snapshot...\n",
      "2022-08-23 10:39:28 | [trpo_pendulum] epoch #131 | Saved\n",
      "2022-08-23 10:39:28 | [trpo_pendulum] epoch #131 | Time 129.63 s\n",
      "2022-08-23 10:39:28 | [trpo_pendulum] epoch #131 | EpochTime 1.06 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00224162\n",
      "Evaluation/AverageReturn                 -0.0227409\n",
      "Evaluation/Iteration                    131\n",
      "Evaluation/MaxReturn                     -0.0223685\n",
      "Evaluation/MinReturn                     -0.0231132\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000372373\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.07485\n",
      "GaussianMLPPolicy/KL                      0.000619676\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000705901\n",
      "GaussianMLPPolicy/LossBefore             -0.000705786\n",
      "GaussianMLPPolicy/dLoss                   1.15891e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.46434\n",
      "GaussianMLPValueFunction/LossBefore      -4.71946\n",
      "GaussianMLPValueFunction/dLoss            0.744885\n",
      "TotalEnvSteps                        263736\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.4891e-05,  3.4506e-05, -2.7923e-07,  ...,  5.9875e-04,\n",
      "        -2.4334e-04,  6.8725e-04])\n",
      "G is: \n",
      "tensor([[5.6840e-06, 5.5416e-01],\n",
      "        [5.5416e-01, 5.4052e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [54052.1641,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-1.4756e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-1.5615e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:29 | [trpo_pendulum] epoch #132 | Saving snapshot...\n",
      "2022-08-23 10:39:29 | [trpo_pendulum] epoch #132 | Saved\n",
      "2022-08-23 10:39:29 | [trpo_pendulum] epoch #132 | Time 130.61 s\n",
      "2022-08-23 10:39:29 | [trpo_pendulum] epoch #132 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00201781\n",
      "Evaluation/AverageReturn                 -0.0209137\n",
      "Evaluation/Iteration                    132\n",
      "Evaluation/MaxReturn                     -0.0203705\n",
      "Evaluation/MinReturn                     -0.0214568\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000543151\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.07945\n",
      "GaussianMLPPolicy/KL                      0.000619588\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -1.56152e-05\n",
      "GaussianMLPPolicy/LossBefore             -1.47556e-05\n",
      "GaussianMLPPolicy/dLoss                   8.59576e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.53466\n",
      "GaussianMLPValueFunction/LossBefore      -5.49729\n",
      "GaussianMLPValueFunction/dLoss            0.0373755\n",
      "TotalEnvSteps                        265734\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.3290e-05,  2.6891e-04, -1.7181e-07,  ...,  3.6464e-03,\n",
      "        -1.5050e-03,  4.1604e-03])\n",
      "G is: \n",
      "tensor([[2.1055e-04, 2.0700e+01],\n",
      "        [2.0700e+01, 2.0352e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [2035197.2500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:30 | [trpo_pendulum] epoch #133 | Saving snapshot...\n",
      "2022-08-23 10:39:30 | [trpo_pendulum] epoch #133 | Saved\n",
      "2022-08-23 10:39:30 | [trpo_pendulum] epoch #133 | Time 131.58 s\n",
      "2022-08-23 10:39:30 | [trpo_pendulum] epoch #133 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00232304\n",
      "Evaluation/AverageReturn                 -0.0238002\n",
      "Evaluation/Iteration                    133\n",
      "Evaluation/MaxReturn                     -0.0229732\n",
      "Evaluation/MinReturn                     -0.0246273\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000827065\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.12203\n",
      "GaussianMLPPolicy/KL                      0.00344808\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000317498\n",
      "GaussianMLPPolicy/LossBefore              0.000322844\n",
      "GaussianMLPPolicy/dLoss                   5.34626e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.42943\n",
      "GaussianMLPValueFunction/LossBefore      -5.26352\n",
      "GaussianMLPValueFunction/dLoss            0.165915\n",
      "TotalEnvSteps                        267732\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.7158e-05,  1.7121e-04,  4.1591e-07,  ...,  2.3572e-03,\n",
      "        -9.7160e-04,  2.6899e-03])\n",
      "G is: \n",
      "tensor([[8.7931e-05, 9.4095e+00],\n",
      "        [9.4095e+00, 1.0069e+06]])\n",
      "eig is:\n",
      "tensor([[-6.2500e-02,  0.0000e+00],\n",
      "        [ 1.0069e+06,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:31 | [trpo_pendulum] epoch #134 | Saving snapshot...\n",
      "2022-08-23 10:39:31 | [trpo_pendulum] epoch #134 | Saved\n",
      "2022-08-23 10:39:31 | [trpo_pendulum] epoch #134 | Time 132.52 s\n",
      "2022-08-23 10:39:31 | [trpo_pendulum] epoch #134 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00193306\n",
      "Evaluation/AverageReturn                 -0.0227804\n",
      "Evaluation/Iteration                    134\n",
      "Evaluation/MaxReturn                     -0.0222938\n",
      "Evaluation/MinReturn                     -0.023267\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000486579\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.14056\n",
      "GaussianMLPPolicy/KL                      0.00109362\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000222947\n",
      "GaussianMLPPolicy/LossBefore              0.000224537\n",
      "GaussianMLPPolicy/dLoss                   1.58988e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.45793\n",
      "GaussianMLPValueFunction/LossBefore      -5.3407\n",
      "GaussianMLPValueFunction/dLoss            0.117224\n",
      "TotalEnvSteps                        269730\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.8530e-05,  1.6792e-04, -7.3152e-07,  ...,  2.2616e-03,\n",
      "        -9.3431e-04,  2.5807e-03])\n",
      "G is: \n",
      "tensor([[8.1016e-05, 9.0016e+00],\n",
      "        [9.0016e+00, 1.0002e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1000179.8750,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:32 | [trpo_pendulum] epoch #135 | Saving snapshot...\n",
      "2022-08-23 10:39:32 | [trpo_pendulum] epoch #135 | Saved\n",
      "2022-08-23 10:39:32 | [trpo_pendulum] epoch #135 | Time 133.46 s\n",
      "2022-08-23 10:39:32 | [trpo_pendulum] epoch #135 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00170435\n",
      "Evaluation/AverageReturn                 -0.0181596\n",
      "Evaluation/Iteration                    135\n",
      "Evaluation/MaxReturn                     -0.018094\n",
      "Evaluation/MinReturn                     -0.0182252\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.56194e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.17316\n",
      "GaussianMLPPolicy/KL                      0.00164665\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00028221\n",
      "GaussianMLPPolicy/LossBefore             -0.000279749\n",
      "GaussianMLPPolicy/dLoss                   2.46067e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.18924\n",
      "GaussianMLPValueFunction/LossBefore      -5.43976\n",
      "GaussianMLPValueFunction/dLoss           -0.250523\n",
      "TotalEnvSteps                        271728\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.3420e-05,  7.7729e-05,  1.7853e-08,  ...,  1.0592e-03,\n",
      "        -4.3737e-04,  1.2079e-03])\n",
      "G is: \n",
      "tensor([[1.7739e-05, 2.1012e+00],\n",
      "        [2.1012e+00, 2.4890e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [248903.9375,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:33 | [trpo_pendulum] epoch #136 | Saving snapshot...\n",
      "2022-08-23 10:39:33 | [trpo_pendulum] epoch #136 | Saved\n",
      "2022-08-23 10:39:33 | [trpo_pendulum] epoch #136 | Time 134.39 s\n",
      "2022-08-23 10:39:33 | [trpo_pendulum] epoch #136 | EpochTime 0.92 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00146545\n",
      "Evaluation/AverageReturn                 -0.013763\n",
      "Evaluation/Iteration                    136\n",
      "Evaluation/MaxReturn                     -0.0132565\n",
      "Evaluation/MinReturn                     -0.0142694\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000506428\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.1894\n",
      "GaussianMLPPolicy/KL                      0.00041497\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000106846\n",
      "GaussianMLPPolicy/LossBefore              0.000107426\n",
      "GaussianMLPPolicy/dLoss                   5.79712e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.73597\n",
      "GaussianMLPValueFunction/LossBefore      -5.65947\n",
      "GaussianMLPValueFunction/dLoss            0.0765023\n",
      "TotalEnvSteps                        273726\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.0575e-05,  1.5396e-04, -4.0238e-09,  ...,  2.0934e-03,\n",
      "        -8.6455e-04,  2.3872e-03])\n",
      "G is: \n",
      "tensor([[6.9289e-05, 8.4786e+00],\n",
      "        [8.4786e+00, 1.0375e+06]])\n",
      "eig is:\n",
      "tensor([[-6.2500e-02,  0.0000e+00],\n",
      "        [ 1.0375e+06,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-5.7400e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-5.8242e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:34 | [trpo_pendulum] epoch #137 | Saving snapshot...\n",
      "2022-08-23 10:39:34 | [trpo_pendulum] epoch #137 | Saved\n",
      "2022-08-23 10:39:34 | [trpo_pendulum] epoch #137 | Time 135.33 s\n",
      "2022-08-23 10:39:34 | [trpo_pendulum] epoch #137 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00131444\n",
      "Evaluation/AverageReturn                 -0.0137228\n",
      "Evaluation/Iteration                    137\n",
      "Evaluation/MaxReturn                     -0.0134666\n",
      "Evaluation/MinReturn                     -0.0139789\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000256125\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.19669\n",
      "GaussianMLPPolicy/KL                      0.000594092\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.82417e-05\n",
      "GaussianMLPPolicy/LossBefore             -5.73999e-05\n",
      "GaussianMLPPolicy/dLoss                   8.41832e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.79957\n",
      "GaussianMLPValueFunction/LossBefore      -5.7419\n",
      "GaussianMLPValueFunction/dLoss            0.057663\n",
      "TotalEnvSteps                        275724\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.3991e-05,  4.8069e-05,  2.7428e-07,  ...,  7.0161e-04,\n",
      "        -2.8803e-04,  8.0145e-04])\n",
      "G is: \n",
      "tensor([[7.7809e-06, 9.6596e-01],\n",
      "        [9.6596e-01, 1.1993e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [119931.8203,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:34 | [trpo_pendulum] epoch #138 | Saving snapshot...\n",
      "2022-08-23 10:39:34 | [trpo_pendulum] epoch #138 | Saved\n",
      "2022-08-23 10:39:34 | [trpo_pendulum] epoch #138 | Time 136.29 s\n",
      "2022-08-23 10:39:34 | [trpo_pendulum] epoch #138 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00150099\n",
      "Evaluation/AverageReturn                 -0.0153201\n",
      "Evaluation/Iteration                    138\n",
      "Evaluation/MaxReturn                     -0.0152472\n",
      "Evaluation/MinReturn                     -0.0153931\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.29554e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.21389\n",
      "GaussianMLPPolicy/KL                      0.000396704\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000120666\n",
      "GaussianMLPPolicy/LossBefore              0.000121232\n",
      "GaussianMLPPolicy/dLoss                   5.66535e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.71333\n",
      "GaussianMLPValueFunction/LossBefore      -5.74777\n",
      "GaussianMLPValueFunction/dLoss           -0.0344405\n",
      "TotalEnvSteps                        277722\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.4953e-05,  6.8249e-05, -3.4626e-08,  ...,  9.1896e-04,\n",
      "        -3.7965e-04,  1.0482e-03])\n",
      "G is: \n",
      "tensor([[1.3359e-05, 1.7171e+00],\n",
      "        [1.7171e+00, 2.2072e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [220721.4375,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-1.8779e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-1.9082e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:35 | [trpo_pendulum] epoch #139 | Saving snapshot...\n",
      "2022-08-23 10:39:35 | [trpo_pendulum] epoch #139 | Saved\n",
      "2022-08-23 10:39:35 | [trpo_pendulum] epoch #139 | Time 137.26 s\n",
      "2022-08-23 10:39:35 | [trpo_pendulum] epoch #139 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00123054\n",
      "Evaluation/AverageReturn                 -0.0127182\n",
      "Evaluation/Iteration                    139\n",
      "Evaluation/MaxReturn                     -0.0124338\n",
      "Evaluation/MinReturn                     -0.0130026\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000284397\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.22448\n",
      "GaussianMLPPolicy/KL                      0.000217346\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -1.90819e-05\n",
      "GaussianMLPPolicy/LossBefore             -1.87793e-05\n",
      "GaussianMLPPolicy/dLoss                   3.02582e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.78665\n",
      "GaussianMLPValueFunction/LossBefore      -5.85242\n",
      "GaussianMLPValueFunction/dLoss           -0.0657649\n",
      "TotalEnvSteps                        279720\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.1077e-05,  9.8842e-05, -3.7170e-06,  ...,  1.1535e-03,\n",
      "        -4.8521e-04,  1.3124e-03])\n",
      "G is: \n",
      "tensor([[2.1095e-05, 2.7682e+00],\n",
      "        [2.7682e+00, 3.6335e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [363348.6250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:36 | [trpo_pendulum] epoch #140 | Saving snapshot...\n",
      "2022-08-23 10:39:36 | [trpo_pendulum] epoch #140 | Saved\n",
      "2022-08-23 10:39:36 | [trpo_pendulum] epoch #140 | Time 138.18 s\n",
      "2022-08-23 10:39:36 | [trpo_pendulum] epoch #140 | EpochTime 0.92 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00142586\n",
      "Evaluation/AverageReturn                 -0.0183171\n",
      "Evaluation/Iteration                    140\n",
      "Evaluation/MaxReturn                     -0.0180276\n",
      "Evaluation/MinReturn                     -0.0186066\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000289498\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.21625\n",
      "GaussianMLPPolicy/KL                      0.00539106\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000421433\n",
      "GaussianMLPPolicy/LossBefore              0.000422851\n",
      "GaussianMLPPolicy/dLoss                   1.41739e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.56334\n",
      "GaussianMLPValueFunction/LossBefore      -4.88215\n",
      "GaussianMLPValueFunction/dLoss            0.681184\n",
      "TotalEnvSteps                        281718\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-9.7655e-08,  1.5385e-04, -1.4056e-06,  ...,  2.5226e-03,\n",
      "        -1.0339e-03,  2.8815e-03])\n",
      "G is: \n",
      "tensor([[9.9975e-05, 1.2845e+01],\n",
      "        [1.2845e+01, 1.6506e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1650560.8750,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:37 | [trpo_pendulum] epoch #141 | Saving snapshot...\n",
      "2022-08-23 10:39:37 | [trpo_pendulum] epoch #141 | Saved\n",
      "2022-08-23 10:39:37 | [trpo_pendulum] epoch #141 | Time 139.15 s\n",
      "2022-08-23 10:39:37 | [trpo_pendulum] epoch #141 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00138813\n",
      "Evaluation/AverageReturn                 -0.0160941\n",
      "Evaluation/Iteration                    141\n",
      "Evaluation/MaxReturn                     -0.0160872\n",
      "Evaluation/MinReturn                     -0.016101\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.8592e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.21608\n",
      "GaussianMLPPolicy/KL                      0.00160698\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000329628\n",
      "GaussianMLPPolicy/LossBefore             -0.000328931\n",
      "GaussianMLPPolicy/dLoss                   6.97444e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.83557\n",
      "GaussianMLPValueFunction/LossBefore      -5.449\n",
      "GaussianMLPValueFunction/dLoss            0.386573\n",
      "TotalEnvSteps                        283716\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.2737e-05,  7.8499e-05, -1.6809e-07,  ...,  1.3068e-03,\n",
      "        -5.3732e-04,  1.4875e-03])\n",
      "G is: \n",
      "tensor([[2.6657e-05, 3.4094e+00],\n",
      "        [3.4094e+00, 4.3606e+05]])\n",
      "eig is:\n",
      "tensor([[-3.1250e-02,  0.0000e+00],\n",
      "        [ 4.3606e+05,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:38 | [trpo_pendulum] epoch #142 | Saving snapshot...\n",
      "2022-08-23 10:39:38 | [trpo_pendulum] epoch #142 | Saved\n",
      "2022-08-23 10:39:38 | [trpo_pendulum] epoch #142 | Time 140.07 s\n",
      "2022-08-23 10:39:38 | [trpo_pendulum] epoch #142 | EpochTime 0.91 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00127668\n",
      "Evaluation/AverageReturn                 -0.0139698\n",
      "Evaluation/Iteration                    142\n",
      "Evaluation/MaxReturn                     -0.0138537\n",
      "Evaluation/MinReturn                     -0.0140858\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000116006\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.22532\n",
      "GaussianMLPPolicy/KL                      0.00029112\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00029122\n",
      "GaussianMLPPolicy/LossBefore             -0.000290812\n",
      "GaussianMLPPolicy/dLoss                   4.0821e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.66484\n",
      "GaussianMLPValueFunction/LossBefore      -5.61242\n",
      "GaussianMLPValueFunction/dLoss            0.0524206\n",
      "TotalEnvSteps                        285714\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.7035e-05,  9.0304e-05, -2.9887e-08,  ...,  1.4974e-03,\n",
      "        -6.1582e-04,  1.7039e-03])\n",
      "G is: \n",
      "tensor([[3.4985e-05, 4.5575e+00],\n",
      "        [4.5575e+00, 5.9371e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [593709.1875,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:39 | [trpo_pendulum] epoch #143 | Saving snapshot...\n",
      "2022-08-23 10:39:39 | [trpo_pendulum] epoch #143 | Saved\n",
      "2022-08-23 10:39:39 | [trpo_pendulum] epoch #143 | Time 141.08 s\n",
      "2022-08-23 10:39:39 | [trpo_pendulum] epoch #143 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00135273\n",
      "Evaluation/AverageReturn                 -0.0135406\n",
      "Evaluation/Iteration                    143\n",
      "Evaluation/MaxReturn                     -0.0132252\n",
      "Evaluation/MinReturn                     -0.013856\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000315375\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.23733\n",
      "GaussianMLPPolicy/KL                      0.000409019\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000217142\n",
      "GaussianMLPPolicy/LossBefore              0.000217712\n",
      "GaussianMLPPolicy/dLoss                   5.7026e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.30773\n",
      "GaussianMLPValueFunction/LossBefore      -5.77798\n",
      "GaussianMLPValueFunction/dLoss           -0.470248\n",
      "TotalEnvSteps                        287712\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.9966e-05,  1.2512e-04,  1.3885e-08,  ...,  2.1075e-03,\n",
      "        -8.6577e-04,  2.3989e-03])\n",
      "G is: \n",
      "tensor([[6.9308e-05, 9.2483e+00],\n",
      "        [9.2483e+00, 1.2341e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1234094.3750,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:40 | [trpo_pendulum] epoch #144 | Saving snapshot...\n",
      "2022-08-23 10:39:40 | [trpo_pendulum] epoch #144 | Saved\n",
      "2022-08-23 10:39:40 | [trpo_pendulum] epoch #144 | Time 142.05 s\n",
      "2022-08-23 10:39:40 | [trpo_pendulum] epoch #144 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00138414\n",
      "Evaluation/AverageReturn                 -0.0140177\n",
      "Evaluation/Iteration                    144\n",
      "Evaluation/MaxReturn                     -0.013803\n",
      "Evaluation/MinReturn                     -0.0142325\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000214748\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.26407\n",
      "GaussianMLPPolicy/KL                      0.00121616\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000430709\n",
      "GaussianMLPPolicy/LossBefore              0.000432463\n",
      "GaussianMLPPolicy/dLoss                   1.7545e-06\n",
      "GaussianMLPValueFunction/LossAfter       -6.01043\n",
      "GaussianMLPValueFunction/LossBefore      -5.17452\n",
      "GaussianMLPValueFunction/dLoss            0.835901\n",
      "TotalEnvSteps                        289710\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.0509e-05,  8.6473e-05,  1.3024e-07,  ...,  1.4547e-03,\n",
      "        -5.9741e-04,  1.6558e-03])\n",
      "G is: \n",
      "tensor([[3.3013e-05, 4.6465e+00],\n",
      "        [4.6465e+00, 6.5400e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [653999.5000,      0.0000]])\n",
      "loss before is:\n",
      "tensor(6.9653e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(6.9233e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:41 | [trpo_pendulum] epoch #145 | Saving snapshot...\n",
      "2022-08-23 10:39:41 | [trpo_pendulum] epoch #145 | Saved\n",
      "2022-08-23 10:39:41 | [trpo_pendulum] epoch #145 | Time 142.99 s\n",
      "2022-08-23 10:39:41 | [trpo_pendulum] epoch #145 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00122908\n",
      "Evaluation/AverageReturn                 -0.0124304\n",
      "Evaluation/Iteration                    145\n",
      "Evaluation/MaxReturn                     -0.0121046\n",
      "Evaluation/MinReturn                     -0.0127562\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000325788\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.27214\n",
      "GaussianMLPPolicy/KL                      0.00029362\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               6.92327e-05\n",
      "GaussianMLPPolicy/LossBefore              6.96529e-05\n",
      "GaussianMLPPolicy/dLoss                   4.20187e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.08671\n",
      "GaussianMLPValueFunction/LossBefore      -6.05351\n",
      "GaussianMLPValueFunction/dLoss            0.0331955\n",
      "TotalEnvSteps                        291708\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.8348e-05,  2.8837e-05, -5.0968e-07,  ...,  5.4717e-04,\n",
      "        -2.2344e-04,  6.2514e-04])\n",
      "G is: \n",
      "tensor([[4.6750e-06, 6.6848e-01],\n",
      "        [6.6848e-01, 9.5614e+04]])\n",
      "eig is:\n",
      "tensor([[    0.,     0.],\n",
      "        [95614.,     0.]])\n",
      "loss before is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:42 | [trpo_pendulum] epoch #146 | Saving snapshot...\n",
      "2022-08-23 10:39:42 | [trpo_pendulum] epoch #146 | Saved\n",
      "2022-08-23 10:39:42 | [trpo_pendulum] epoch #146 | Time 143.95 s\n",
      "2022-08-23 10:39:42 | [trpo_pendulum] epoch #146 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00135657\n",
      "Evaluation/AverageReturn                 -0.0151018\n",
      "Evaluation/Iteration                    146\n",
      "Evaluation/MaxReturn                     -0.0149091\n",
      "Evaluation/MinReturn                     -0.0152945\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000192696\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.2925\n",
      "GaussianMLPPolicy/KL                      0.000506333\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00044841\n",
      "GaussianMLPPolicy/LossBefore              0.000449135\n",
      "GaussianMLPPolicy/dLoss                   7.25064e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.29942\n",
      "GaussianMLPValueFunction/LossBefore      -4.69875\n",
      "GaussianMLPValueFunction/dLoss            0.600663\n",
      "TotalEnvSteps                        293706\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-2.8460e-05,  1.0577e-04, -8.7257e-07,  ...,  1.9828e-03,\n",
      "        -8.0971e-04,  2.2631e-03])\n",
      "G is: \n",
      "tensor([[6.1303e-05, 9.1260e+00],\n",
      "        [9.1260e+00, 1.3587e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1358682.7500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:43 | [trpo_pendulum] epoch #147 | Saving snapshot...\n",
      "2022-08-23 10:39:43 | [trpo_pendulum] epoch #147 | Saved\n",
      "2022-08-23 10:39:43 | [trpo_pendulum] epoch #147 | Time 144.93 s\n",
      "2022-08-23 10:39:43 | [trpo_pendulum] epoch #147 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00126988\n",
      "Evaluation/AverageReturn                 -0.0147886\n",
      "Evaluation/Iteration                    147\n",
      "Evaluation/MaxReturn                     -0.0147231\n",
      "Evaluation/MinReturn                     -0.0148542\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.55425e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.27183\n",
      "GaussianMLPPolicy/KL                      0.00103307\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000289497\n",
      "GaussianMLPPolicy/LossBefore             -0.000287752\n",
      "GaussianMLPPolicy/dLoss                   1.74472e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.60145\n",
      "GaussianMLPValueFunction/LossBefore      -5.32409\n",
      "GaussianMLPValueFunction/dLoss            0.277359\n",
      "TotalEnvSteps                        295704\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.9751e-05,  7.3351e-05, -1.3855e-07,  ...,  1.2810e-03,\n",
      "        -5.2586e-04,  1.4582e-03])\n",
      "G is: \n",
      "tensor([[2.5545e-05, 3.6453e+00],\n",
      "        [3.6453e+00, 5.2021e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [520208.3750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:44 | [trpo_pendulum] epoch #148 | Saving snapshot...\n",
      "2022-08-23 10:39:44 | [trpo_pendulum] epoch #148 | Saved\n",
      "2022-08-23 10:39:44 | [trpo_pendulum] epoch #148 | Time 145.96 s\n",
      "2022-08-23 10:39:44 | [trpo_pendulum] epoch #148 | EpochTime 1.02 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00121154\n",
      "Evaluation/AverageReturn                 -0.0109529\n",
      "Evaluation/Iteration                    148\n",
      "Evaluation/MaxReturn                     -0.0105166\n",
      "Evaluation/MinReturn                     -0.0113892\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000436284\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.29329\n",
      "GaussianMLPPolicy/KL                      0.000651298\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000311549\n",
      "GaussianMLPPolicy/LossBefore             -0.000310632\n",
      "GaussianMLPPolicy/dLoss                   9.17586e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.06678\n",
      "GaussianMLPValueFunction/LossBefore      -5.58638\n",
      "GaussianMLPValueFunction/dLoss            0.480395\n",
      "TotalEnvSteps                        297702\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.1596e-06, -3.3533e-05, -6.5538e-08,  ..., -6.5598e-04,\n",
      "         2.6702e-04, -7.4870e-04])\n",
      "G is: \n",
      "tensor([[6.6955e-06, 9.9677e-01],\n",
      "        [9.9677e-01, 1.4840e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [148403.9062,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:45 | [trpo_pendulum] epoch #149 | Saving snapshot...\n",
      "2022-08-23 10:39:45 | [trpo_pendulum] epoch #149 | Saved\n",
      "2022-08-23 10:39:45 | [trpo_pendulum] epoch #149 | Time 146.94 s\n",
      "2022-08-23 10:39:45 | [trpo_pendulum] epoch #149 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00116878\n",
      "Evaluation/AverageReturn                 -0.0122607\n",
      "Evaluation/Iteration                    149\n",
      "Evaluation/MaxReturn                     -0.0112655\n",
      "Evaluation/MinReturn                     -0.013256\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000995206\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.29357\n",
      "GaussianMLPPolicy/KL                      0.000137694\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00031838\n",
      "GaussianMLPPolicy/LossBefore              0.000318576\n",
      "GaussianMLPPolicy/dLoss                   1.9549e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.78256\n",
      "GaussianMLPValueFunction/LossBefore      -5.48555\n",
      "GaussianMLPValueFunction/dLoss            0.297002\n",
      "TotalEnvSteps                        299700\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.8831e-06, -2.9955e-05, -9.5918e-08,  ..., -4.2952e-04,\n",
      "         1.7884e-04, -4.8625e-04])\n",
      "G is: \n",
      "tensor([[2.8707e-06, 4.2765e-01],\n",
      "        [4.2765e-01, 6.3722e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [63722.1406,     0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:46 | [trpo_pendulum] epoch #150 | Saving snapshot...\n",
      "2022-08-23 10:39:46 | [trpo_pendulum] epoch #150 | Saved\n",
      "2022-08-23 10:39:46 | [trpo_pendulum] epoch #150 | Time 147.91 s\n",
      "2022-08-23 10:39:46 | [trpo_pendulum] epoch #150 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00133026\n",
      "Evaluation/AverageReturn                 -0.0137425\n",
      "Evaluation/Iteration                    150\n",
      "Evaluation/MaxReturn                     -0.013535\n",
      "Evaluation/MinReturn                     -0.01395\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000207486\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.29445\n",
      "GaussianMLPPolicy/KL                      8.88769e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000381341\n",
      "GaussianMLPPolicy/LossBefore              0.000381465\n",
      "GaussianMLPPolicy/dLoss                   1.23866e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.93362\n",
      "GaussianMLPValueFunction/LossBefore      -5.05428\n",
      "GaussianMLPValueFunction/dLoss            0.879339\n",
      "TotalEnvSteps                        301698\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.9876e-05, -5.8838e-06, -9.7938e-08,  ..., -1.0985e-04,\n",
      "         4.4774e-05, -1.2517e-04])\n",
      "G is: \n",
      "tensor([[1.8860e-07, 2.8017e-02],\n",
      "        [2.8017e-02, 4.1820e+03]])\n",
      "eig is:\n",
      "tensor([[   0.0000,    0.0000],\n",
      "        [4182.0059,    0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:47 | [trpo_pendulum] epoch #151 | Saving snapshot...\n",
      "2022-08-23 10:39:47 | [trpo_pendulum] epoch #151 | Saved\n",
      "2022-08-23 10:39:47 | [trpo_pendulum] epoch #151 | Time 148.92 s\n",
      "2022-08-23 10:39:47 | [trpo_pendulum] epoch #151 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00120781\n",
      "Evaluation/AverageReturn                 -0.0112304\n",
      "Evaluation/Iteration                    151\n",
      "Evaluation/MaxReturn                     -0.0110382\n",
      "Evaluation/MinReturn                     -0.0114226\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000192207\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.31525\n",
      "GaussianMLPPolicy/KL                      0.000440677\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000275296\n",
      "GaussianMLPPolicy/LossBefore             -0.000274683\n",
      "GaussianMLPPolicy/dLoss                   6.13101e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.13812\n",
      "GaussianMLPValueFunction/LossBefore      -5.69763\n",
      "GaussianMLPValueFunction/dLoss            0.440492\n",
      "TotalEnvSteps                        303696\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.3499e-05, -4.0705e-04,  8.3600e-07,  ..., -7.0297e-03,\n",
      "         2.8878e-03, -8.0006e-03])\n",
      "G is: \n",
      "tensor([[7.6882e-04, 1.1959e+02],\n",
      "        [1.1959e+02, 1.8602e+07]])\n",
      "eig is:\n",
      "tensor([[       0.,        0.],\n",
      "        [18601520.,        0.]])\n",
      "loss before is:\n",
      "tensor(0.0011, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0011, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:48 | [trpo_pendulum] epoch #152 | Saving snapshot...\n",
      "2022-08-23 10:39:48 | [trpo_pendulum] epoch #152 | Saved\n",
      "2022-08-23 10:39:48 | [trpo_pendulum] epoch #152 | Time 149.89 s\n",
      "2022-08-23 10:39:48 | [trpo_pendulum] epoch #152 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00154001\n",
      "Evaluation/AverageReturn                 -0.0188124\n",
      "Evaluation/Iteration                    152\n",
      "Evaluation/MaxReturn                     -0.0182553\n",
      "Evaluation/MinReturn                     -0.0193694\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000557078\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.33958\n",
      "GaussianMLPPolicy/KL                      0.00449399\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00108957\n",
      "GaussianMLPPolicy/LossBefore              0.00109655\n",
      "GaussianMLPPolicy/dLoss                   6.98282e-06\n",
      "GaussianMLPValueFunction/LossAfter       -4.46908\n",
      "GaussianMLPValueFunction/LossBefore       3.96835\n",
      "GaussianMLPValueFunction/dLoss            8.43742\n",
      "TotalEnvSteps                        305694\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.1065e-06,  3.3162e-05, -5.2284e-07,  ...,  6.1814e-04,\n",
      "        -2.5264e-04,  7.0578e-04])\n",
      "G is: \n",
      "tensor([[5.9553e-06, 9.7348e-01],\n",
      "        [9.7348e-01, 1.5914e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [159142.8125,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0005, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0005, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:49 | [trpo_pendulum] epoch #153 | Saving snapshot...\n",
      "2022-08-23 10:39:49 | [trpo_pendulum] epoch #153 | Saved\n",
      "2022-08-23 10:39:49 | [trpo_pendulum] epoch #153 | Time 150.85 s\n",
      "2022-08-23 10:39:49 | [trpo_pendulum] epoch #153 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00145394\n",
      "Evaluation/AverageReturn                 -0.016831\n",
      "Evaluation/Iteration                    153\n",
      "Evaluation/MaxReturn                     -0.0165865\n",
      "Evaluation/MinReturn                     -0.0170755\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000244523\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.34478\n",
      "GaussianMLPPolicy/KL                      0.000105936\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000493188\n",
      "GaussianMLPPolicy/LossBefore             -0.000493027\n",
      "GaussianMLPPolicy/dLoss                   1.61061e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.35499\n",
      "GaussianMLPValueFunction/LossBefore      -4.25602\n",
      "GaussianMLPValueFunction/dLoss            1.09898\n",
      "TotalEnvSteps                        307692\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.6291e-05,  1.0219e-04,  8.1794e-08,  ...,  1.7501e-03,\n",
      "        -7.1896e-04,  1.9912e-03])\n",
      "G is: \n",
      "tensor([[4.7675e-05, 7.8713e+00],\n",
      "        [7.8713e+00, 1.2996e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1299583.7500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0008, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0008, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:50 | [trpo_pendulum] epoch #154 | Saving snapshot...\n",
      "2022-08-23 10:39:50 | [trpo_pendulum] epoch #154 | Saved\n",
      "2022-08-23 10:39:50 | [trpo_pendulum] epoch #154 | Time 151.87 s\n",
      "2022-08-23 10:39:50 | [trpo_pendulum] epoch #154 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00121292\n",
      "Evaluation/AverageReturn                 -0.0112851\n",
      "Evaluation/Iteration                    154\n",
      "Evaluation/MaxReturn                     -0.0111147\n",
      "Evaluation/MinReturn                     -0.0114555\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000170373\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.36285\n",
      "GaussianMLPPolicy/KL                      0.000611111\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000815565\n",
      "GaussianMLPPolicy/LossBefore             -0.000814735\n",
      "GaussianMLPPolicy/dLoss                   8.30041e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.10388\n",
      "GaussianMLPValueFunction/LossBefore      -2.42474\n",
      "GaussianMLPValueFunction/dLoss            3.67914\n",
      "TotalEnvSteps                        309690\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.1873e-06,  1.1850e-04, -2.0481e-08,  ...,  2.0444e-03,\n",
      "        -8.3933e-04,  2.3268e-03])\n",
      "G is: \n",
      "tensor([[6.5063e-05, 1.1137e+01],\n",
      "        [1.1137e+01, 1.9064e+06]])\n",
      "eig is:\n",
      "tensor([[-1.2500e-01,  0.0000e+00],\n",
      "        [ 1.9064e+06,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:51 | [trpo_pendulum] epoch #155 | Saving snapshot...\n",
      "2022-08-23 10:39:51 | [trpo_pendulum] epoch #155 | Saved\n",
      "2022-08-23 10:39:51 | [trpo_pendulum] epoch #155 | Time 152.82 s\n",
      "2022-08-23 10:39:51 | [trpo_pendulum] epoch #155 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0013932\n",
      "Evaluation/AverageReturn                 -0.01302\n",
      "Evaluation/Iteration                    155\n",
      "Evaluation/MaxReturn                     -0.01294\n",
      "Evaluation/MinReturn                     -0.0130999\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.99342e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.36285\n",
      "GaussianMLPPolicy/KL                      0.000366244\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000152275\n",
      "GaussianMLPPolicy/LossBefore              0.000152802\n",
      "GaussianMLPPolicy/dLoss                   5.27012e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.05256\n",
      "GaussianMLPValueFunction/LossBefore      -5.91725\n",
      "GaussianMLPValueFunction/dLoss            0.135307\n",
      "TotalEnvSteps                        311688\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.8457e-05,  1.5673e-04, -2.3462e-07,  ...,  2.5605e-03,\n",
      "        -1.0554e-03,  2.9107e-03])\n",
      "G is: \n",
      "tensor([[1.0206e-04, 1.7471e+01],\n",
      "        [1.7471e+01, 2.9907e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [2990689.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:52 | [trpo_pendulum] epoch #156 | Saving snapshot...\n",
      "2022-08-23 10:39:52 | [trpo_pendulum] epoch #156 | Saved\n",
      "2022-08-23 10:39:52 | [trpo_pendulum] epoch #156 | Time 153.80 s\n",
      "2022-08-23 10:39:52 | [trpo_pendulum] epoch #156 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00128467\n",
      "Evaluation/AverageReturn                 -0.0144631\n",
      "Evaluation/Iteration                    156\n",
      "Evaluation/MaxReturn                     -0.0142986\n",
      "Evaluation/MinReturn                     -0.0146276\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000164484\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.38224\n",
      "GaussianMLPPolicy/KL                      0.000947243\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00028988\n",
      "GaussianMLPPolicy/LossBefore              0.000291294\n",
      "GaussianMLPPolicy/dLoss                   1.4143e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.60781\n",
      "GaussianMLPValueFunction/LossBefore      -5.1749\n",
      "GaussianMLPValueFunction/dLoss            0.432909\n",
      "TotalEnvSteps                        313686\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.8459e-05, -2.3946e-04,  5.7269e-06,  ..., -3.3452e-03,\n",
      "         1.4041e-03, -3.7867e-03])\n",
      "G is: \n",
      "tensor([[1.7428e-04, 3.0993e+01],\n",
      "        [3.0993e+01, 5.5134e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [5513406.,       0.]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:53 | [trpo_pendulum] epoch #157 | Saving snapshot...\n",
      "2022-08-23 10:39:53 | [trpo_pendulum] epoch #157 | Saved\n",
      "2022-08-23 10:39:53 | [trpo_pendulum] epoch #157 | Time 154.89 s\n",
      "2022-08-23 10:39:53 | [trpo_pendulum] epoch #157 | EpochTime 1.09 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00145884\n",
      "Evaluation/AverageReturn                 -0.0183183\n",
      "Evaluation/Iteration                    157\n",
      "Evaluation/MaxReturn                     -0.0183039\n",
      "Evaluation/MinReturn                     -0.0183328\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.44263e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.37533\n",
      "GaussianMLPPolicy/KL                      0.00916547\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000228332\n",
      "GaussianMLPPolicy/LossBefore              0.000237014\n",
      "GaussianMLPPolicy/dLoss                   8.68125e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.05471\n",
      "GaussianMLPValueFunction/LossBefore      -4.52167\n",
      "GaussianMLPValueFunction/dLoss            0.533047\n",
      "TotalEnvSteps                        315684\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-2.6354e-05, -2.0769e-05, -7.2192e-08,  ..., -2.9957e-04,\n",
      "         1.2392e-04, -3.4043e-04])\n",
      "G is: \n",
      "tensor([[1.4036e-06, 2.4688e-01],\n",
      "        [2.4688e-01, 4.3447e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [43446.8828,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0008, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0008, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:54 | [trpo_pendulum] epoch #158 | Saving snapshot...\n",
      "2022-08-23 10:39:54 | [trpo_pendulum] epoch #158 | Saved\n",
      "2022-08-23 10:39:54 | [trpo_pendulum] epoch #158 | Time 155.88 s\n",
      "2022-08-23 10:39:54 | [trpo_pendulum] epoch #158 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00115766\n",
      "Evaluation/AverageReturn                 -0.0115969\n",
      "Evaluation/Iteration                    158\n",
      "Evaluation/MaxReturn                     -0.0109355\n",
      "Evaluation/MinReturn                     -0.0122583\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000661433\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.35575\n",
      "GaussianMLPPolicy/KL                      0.000386094\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000784103\n",
      "GaussianMLPPolicy/LossBefore             -0.000783525\n",
      "GaussianMLPPolicy/dLoss                   5.78526e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.88092\n",
      "GaussianMLPValueFunction/LossBefore      -2.98498\n",
      "GaussianMLPValueFunction/dLoss            2.89594\n",
      "TotalEnvSteps                        317682\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.1158e-05,  1.3715e-04, -7.8337e-08,  ...,  2.0799e-03,\n",
      "        -8.5757e-04,  2.3675e-03])\n",
      "G is: \n",
      "tensor([[6.7608e-05, 1.1435e+01],\n",
      "        [1.1435e+01, 1.9340e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1934001.7500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(3.7903e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(3.7039e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:55 | [trpo_pendulum] epoch #159 | Saving snapshot...\n",
      "2022-08-23 10:39:55 | [trpo_pendulum] epoch #159 | Saved\n",
      "2022-08-23 10:39:55 | [trpo_pendulum] epoch #159 | Time 156.86 s\n",
      "2022-08-23 10:39:55 | [trpo_pendulum] epoch #159 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0011951\n",
      "Evaluation/AverageReturn                 -0.0136712\n",
      "Evaluation/Iteration                    159\n",
      "Evaluation/MaxReturn                     -0.0133128\n",
      "Evaluation/MinReturn                     -0.0140297\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000358482\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.37029\n",
      "GaussianMLPPolicy/KL                      0.000613947\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               3.70386e-05\n",
      "GaussianMLPPolicy/LossBefore              3.79033e-05\n",
      "GaussianMLPPolicy/dLoss                   8.64737e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.03713\n",
      "GaussianMLPValueFunction/LossBefore      -6.00129\n",
      "GaussianMLPValueFunction/dLoss            0.0358434\n",
      "TotalEnvSteps                        319680\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.6089e-05,  1.0674e-04, -1.3311e-08,  ...,  1.6743e-03,\n",
      "        -6.8877e-04,  1.9069e-03])\n",
      "G is: \n",
      "tensor([[4.3804e-05, 7.6289e+00],\n",
      "        [7.6289e+00, 1.3287e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1328655.1250,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:56 | [trpo_pendulum] epoch #160 | Saving snapshot...\n",
      "2022-08-23 10:39:56 | [trpo_pendulum] epoch #160 | Saved\n",
      "2022-08-23 10:39:56 | [trpo_pendulum] epoch #160 | Time 157.81 s\n",
      "2022-08-23 10:39:56 | [trpo_pendulum] epoch #160 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00102105\n",
      "Evaluation/AverageReturn                 -0.0105412\n",
      "Evaluation/Iteration                    160\n",
      "Evaluation/MaxReturn                     -0.0103325\n",
      "Evaluation/MinReturn                     -0.01075\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000208784\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.38248\n",
      "GaussianMLPPolicy/KL                      0.000399557\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000277126\n",
      "GaussianMLPPolicy/LossBefore             -0.000276566\n",
      "GaussianMLPPolicy/dLoss                   5.59812e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.7131\n",
      "GaussianMLPValueFunction/LossBefore      -5.6951\n",
      "GaussianMLPValueFunction/dLoss            0.0180006\n",
      "TotalEnvSteps                        321678\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.7495e-05,  7.8603e-05, -9.1203e-08,  ...,  1.2267e-03,\n",
      "        -5.0487e-04,  1.3972e-03])\n",
      "G is: \n",
      "tensor([[2.3514e-05, 4.1950e+00],\n",
      "        [4.1950e+00, 7.4845e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [748445.1250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:57 | [trpo_pendulum] epoch #161 | Saving snapshot...\n",
      "2022-08-23 10:39:57 | [trpo_pendulum] epoch #161 | Saved\n",
      "2022-08-23 10:39:57 | [trpo_pendulum] epoch #161 | Time 158.82 s\n",
      "2022-08-23 10:39:57 | [trpo_pendulum] epoch #161 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00112652\n",
      "Evaluation/AverageReturn                 -0.0106914\n",
      "Evaluation/Iteration                    161\n",
      "Evaluation/MaxReturn                     -0.0104272\n",
      "Evaluation/MinReturn                     -0.0109555\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000264131\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.40162\n",
      "GaussianMLPPolicy/KL                      0.000505057\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00025706\n",
      "GaussianMLPPolicy/LossBefore             -0.00025635\n",
      "GaussianMLPPolicy/dLoss                   7.09842e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.70715\n",
      "GaussianMLPValueFunction/LossBefore      -5.74584\n",
      "GaussianMLPValueFunction/dLoss           -0.0386982\n",
      "TotalEnvSteps                        323676\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.3696e-05,  7.0080e-05, -2.8124e-07,  ...,  1.0967e-03,\n",
      "        -4.5148e-04,  1.2493e-03])\n",
      "G is: \n",
      "tensor([[1.8790e-05, 3.4822e+00],\n",
      "        [3.4822e+00, 6.4532e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [645315.3750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:58 | [trpo_pendulum] epoch #162 | Saving snapshot...\n",
      "2022-08-23 10:39:58 | [trpo_pendulum] epoch #162 | Saved\n",
      "2022-08-23 10:39:58 | [trpo_pendulum] epoch #162 | Time 159.86 s\n",
      "2022-08-23 10:39:58 | [trpo_pendulum] epoch #162 | EpochTime 1.03 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00104958\n",
      "Evaluation/AverageReturn                 -0.0113501\n",
      "Evaluation/Iteration                    162\n",
      "Evaluation/MaxReturn                     -0.0111718\n",
      "Evaluation/MinReturn                     -0.0115283\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000178218\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.41183\n",
      "GaussianMLPPolicy/KL                      0.00020308\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000125533\n",
      "GaussianMLPPolicy/LossBefore             -0.00012524\n",
      "GaussianMLPPolicy/dLoss                   2.92392e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.71517\n",
      "GaussianMLPValueFunction/LossBefore      -6.03902\n",
      "GaussianMLPValueFunction/dLoss           -0.32385\n",
      "TotalEnvSteps                        325674\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.3737e-05,  6.1323e-05, -6.4617e-07,  ...,  9.9611e-04,\n",
      "        -4.0952e-04,  1.1357e-03])\n",
      "G is: \n",
      "tensor([[1.5496e-05, 2.9296e+00],\n",
      "        [2.9296e+00, 5.5388e+05]])\n",
      "eig is:\n",
      "tensor([[     0.,      0.],\n",
      "        [553878.,      0.]])\n",
      "loss before is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:39:59 | [trpo_pendulum] epoch #163 | Saving snapshot...\n",
      "2022-08-23 10:39:59 | [trpo_pendulum] epoch #163 | Saved\n",
      "2022-08-23 10:39:59 | [trpo_pendulum] epoch #163 | Time 160.83 s\n",
      "2022-08-23 10:39:59 | [trpo_pendulum] epoch #163 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00114589\n",
      "Evaluation/AverageReturn                 -0.0126476\n",
      "Evaluation/Iteration                    163\n",
      "Evaluation/MaxReturn                     -0.0125399\n",
      "Evaluation/MinReturn                     -0.0127554\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00010774\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.42307\n",
      "GaussianMLPPolicy/KL                      0.000218773\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000400489\n",
      "GaussianMLPPolicy/LossBefore              0.000400817\n",
      "GaussianMLPPolicy/dLoss                   3.28233e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.97714\n",
      "GaussianMLPValueFunction/LossBefore      -4.98506\n",
      "GaussianMLPValueFunction/dLoss            0.992085\n",
      "TotalEnvSteps                        327672\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.2589e-05, -4.3472e-05, -1.5865e-07,  ..., -7.0973e-04,\n",
      "         2.9139e-04, -8.0830e-04])\n",
      "G is: \n",
      "tensor([[7.8545e-06, 1.5178e+00],\n",
      "        [1.5178e+00, 2.9331e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [293305.4375,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0004, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0004, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:00 | [trpo_pendulum] epoch #164 | Saving snapshot...\n",
      "2022-08-23 10:40:00 | [trpo_pendulum] epoch #164 | Saved\n",
      "2022-08-23 10:40:00 | [trpo_pendulum] epoch #164 | Time 161.79 s\n",
      "2022-08-23 10:40:00 | [trpo_pendulum] epoch #164 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000961881\n",
      "Evaluation/AverageReturn                 -0.0100909\n",
      "Evaluation/Iteration                    164\n",
      "Evaluation/MaxReturn                     -0.00958476\n",
      "Evaluation/MinReturn                     -0.0105971\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000506163\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.43906\n",
      "GaussianMLPPolicy/KL                      0.000313739\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000382009\n",
      "GaussianMLPPolicy/LossBefore             -0.000381582\n",
      "GaussianMLPPolicy/dLoss                   4.26866e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.11455\n",
      "GaussianMLPValueFunction/LossBefore      -5.26298\n",
      "GaussianMLPValueFunction/dLoss            0.851571\n",
      "TotalEnvSteps                        329670\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.7458e-05, -9.6950e-07, -6.8442e-08,  ...,  2.5463e-05,\n",
      "        -9.3274e-06,  3.0179e-05])\n",
      "G is: \n",
      "tensor([[1.0579e-08, 2.0195e-03],\n",
      "        [2.0195e-03, 4.0296e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [402.9571,   0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:01 | [trpo_pendulum] epoch #165 | Saving snapshot...\n",
      "2022-08-23 10:40:01 | [trpo_pendulum] epoch #165 | Saved\n",
      "2022-08-23 10:40:01 | [trpo_pendulum] epoch #165 | Time 162.71 s\n",
      "2022-08-23 10:40:01 | [trpo_pendulum] epoch #165 | EpochTime 0.92 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000959517\n",
      "Evaluation/AverageReturn                 -0.0104411\n",
      "Evaluation/Iteration                    165\n",
      "Evaluation/MaxReturn                     -0.0102626\n",
      "Evaluation/MinReturn                     -0.0106197\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000178541\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.4516\n",
      "GaussianMLPPolicy/KL                      0.000232788\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000110035\n",
      "GaussianMLPPolicy/LossBefore             -0.000109711\n",
      "GaussianMLPPolicy/dLoss                   3.24952e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.20779\n",
      "GaussianMLPValueFunction/LossBefore      -6.14223\n",
      "GaussianMLPValueFunction/dLoss            0.0655608\n",
      "TotalEnvSteps                        331668\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.5552e-06,  7.8580e-05, -1.7724e-08,  ...,  1.2499e-03,\n",
      "        -5.1450e-04,  1.4227e-03])\n",
      "G is: \n",
      "tensor([[2.4349e-05, 4.9789e+00],\n",
      "        [4.9789e+00, 1.0181e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1018087.7500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(3.7640e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(3.7473e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:02 | [trpo_pendulum] epoch #166 | Saving snapshot...\n",
      "2022-08-23 10:40:02 | [trpo_pendulum] epoch #166 | Saved\n",
      "2022-08-23 10:40:02 | [trpo_pendulum] epoch #166 | Time 163.66 s\n",
      "2022-08-23 10:40:02 | [trpo_pendulum] epoch #166 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000928372\n",
      "Evaluation/AverageReturn                 -0.00947499\n",
      "Evaluation/Iteration                    166\n",
      "Evaluation/MaxReturn                     -0.00941755\n",
      "Evaluation/MinReturn                     -0.00953244\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.74423e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.4516\n",
      "GaussianMLPPolicy/KL                      0.00011767\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               3.74732e-05\n",
      "GaussianMLPPolicy/LossBefore              3.76403e-05\n",
      "GaussianMLPPolicy/dLoss                   1.671e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.30678\n",
      "GaussianMLPValueFunction/LossBefore      -6.26164\n",
      "GaussianMLPValueFunction/dLoss            0.0451412\n",
      "TotalEnvSteps                        333666\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-4.3410e-05,  1.3879e-04,  3.4871e-06,  ...,  9.5828e-04,\n",
      "        -4.2796e-04,  1.0543e-03])\n",
      "G is: \n",
      "tensor([[1.4438e-05, 2.9212e+00],\n",
      "        [2.9212e+00, 5.9713e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [597132.9375,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0009, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0009, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:03 | [trpo_pendulum] epoch #167 | Saving snapshot...\n",
      "2022-08-23 10:40:03 | [trpo_pendulum] epoch #167 | Saved\n",
      "2022-08-23 10:40:03 | [trpo_pendulum] epoch #167 | Time 164.67 s\n",
      "2022-08-23 10:40:03 | [trpo_pendulum] epoch #167 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0014112\n",
      "Evaluation/AverageReturn                 -0.0165307\n",
      "Evaluation/Iteration                    167\n",
      "Evaluation/MaxReturn                     -0.0161825\n",
      "Evaluation/MinReturn                     -0.016879\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000348227\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.4265\n",
      "GaussianMLPPolicy/KL                      0.00326246\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000905335\n",
      "GaussianMLPPolicy/LossBefore              0.000911596\n",
      "GaussianMLPPolicy/dLoss                   6.26122e-06\n",
      "GaussianMLPValueFunction/LossAfter       -4.54956\n",
      "GaussianMLPValueFunction/LossBefore       2.5826\n",
      "GaussianMLPValueFunction/dLoss            7.13216\n",
      "TotalEnvSteps                        335664\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-2.8763e-05,  2.5697e-04,  5.1103e-09,  ...,  3.9687e-03,\n",
      "        -1.6345e-03,  4.5188e-03])\n",
      "G is: \n",
      "tensor([[2.4609e-04, 4.7952e+01],\n",
      "        [4.7952e+01, 9.3439e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [9343946.,       0.]])\n",
      "loss before is:\n",
      "tensor(-0.0009, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0009, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:04 | [trpo_pendulum] epoch #168 | Saving snapshot...\n",
      "2022-08-23 10:40:04 | [trpo_pendulum] epoch #168 | Saved\n",
      "2022-08-23 10:40:04 | [trpo_pendulum] epoch #168 | Time 165.67 s\n",
      "2022-08-23 10:40:04 | [trpo_pendulum] epoch #168 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00087003\n",
      "Evaluation/AverageReturn                 -0.00922675\n",
      "Evaluation/Iteration                    168\n",
      "Evaluation/MaxReturn                     -0.0092069\n",
      "Evaluation/MinReturn                     -0.0092466\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.98484e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.40764\n",
      "GaussianMLPPolicy/KL                      0.00139261\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000853694\n",
      "GaussianMLPPolicy/LossBefore             -0.00085132\n",
      "GaussianMLPPolicy/dLoss                   2.37458e-06\n",
      "GaussianMLPValueFunction/LossAfter       -6.238\n",
      "GaussianMLPValueFunction/LossBefore      -1.22284\n",
      "GaussianMLPValueFunction/dLoss            5.01515\n",
      "TotalEnvSteps                        337662\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.9764e-05, -5.0623e-05, -2.8613e-07,  ..., -4.5621e-04,\n",
      "         1.9733e-04, -5.1008e-04])\n",
      "G is: \n",
      "tensor([[3.2625e-06, 6.1015e-01],\n",
      "        [6.1015e-01, 1.1448e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [114478.5469,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:05 | [trpo_pendulum] epoch #169 | Saving snapshot...\n",
      "2022-08-23 10:40:05 | [trpo_pendulum] epoch #169 | Saved\n",
      "2022-08-23 10:40:05 | [trpo_pendulum] epoch #169 | Time 166.69 s\n",
      "2022-08-23 10:40:05 | [trpo_pendulum] epoch #169 | EpochTime 1.02 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00111333\n",
      "Evaluation/AverageReturn                 -0.0120255\n",
      "Evaluation/Iteration                    169\n",
      "Evaluation/MaxReturn                     -0.0116589\n",
      "Evaluation/MinReturn                     -0.012392\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00036654\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.42102\n",
      "GaussianMLPPolicy/KL                      0.000992099\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000305775\n",
      "GaussianMLPPolicy/LossBefore              0.000307189\n",
      "GaussianMLPPolicy/dLoss                   1.41404e-06\n",
      "GaussianMLPValueFunction/LossAfter       -6.1208\n",
      "GaussianMLPValueFunction/LossBefore      -5.45273\n",
      "GaussianMLPValueFunction/dLoss            0.668071\n",
      "TotalEnvSteps                        339660\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.1952e-05,  8.2906e-05,  2.6304e-07,  ...,  1.3093e-03,\n",
      "        -5.3800e-04,  1.4917e-03])\n",
      "G is: \n",
      "tensor([[2.6763e-05, 5.1542e+00],\n",
      "        [5.1542e+00, 9.9266e+05]])\n",
      "eig is:\n",
      "tensor([[     0.,      0.],\n",
      "        [992662.,      0.]])\n",
      "loss before is:\n",
      "tensor(-8.3295e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-8.3849e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:06 | [trpo_pendulum] epoch #170 | Saving snapshot...\n",
      "2022-08-23 10:40:06 | [trpo_pendulum] epoch #170 | Saved\n",
      "2022-08-23 10:40:06 | [trpo_pendulum] epoch #170 | Time 167.68 s\n",
      "2022-08-23 10:40:06 | [trpo_pendulum] epoch #170 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0010163\n",
      "Evaluation/AverageReturn                 -0.0101243\n",
      "Evaluation/Iteration                    170\n",
      "Evaluation/MaxReturn                     -0.0100423\n",
      "Evaluation/MinReturn                     -0.0102062\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.19779e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.43664\n",
      "GaussianMLPPolicy/KL                      0.000384666\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -8.38491e-05\n",
      "GaussianMLPPolicy/LossBefore             -8.32947e-05\n",
      "GaussianMLPPolicy/dLoss                   5.54392e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.6138\n",
      "GaussianMLPValueFunction/LossBefore      -6.1597\n",
      "GaussianMLPValueFunction/dLoss           -0.545897\n",
      "TotalEnvSteps                        341658\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-2.4742e-05,  3.3124e-05,  2.8990e-07,  ...,  1.6970e-03,\n",
      "        -6.6307e-04,  1.9655e-03])\n",
      "G is: \n",
      "tensor([[4.5088e-05, 8.9334e+00],\n",
      "        [8.9334e+00, 1.7752e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [1775191.,       0.]])\n",
      "loss before is:\n",
      "tensor(0.0007, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0007, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:07 | [trpo_pendulum] epoch #171 | Saving snapshot...\n",
      "2022-08-23 10:40:07 | [trpo_pendulum] epoch #171 | Saved\n",
      "2022-08-23 10:40:07 | [trpo_pendulum] epoch #171 | Time 168.68 s\n",
      "2022-08-23 10:40:07 | [trpo_pendulum] epoch #171 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00121605\n",
      "Evaluation/AverageReturn                 -0.0131632\n",
      "Evaluation/Iteration                    171\n",
      "Evaluation/MaxReturn                     -0.0131349\n",
      "Evaluation/MinReturn                     -0.0131915\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.83091e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.42264\n",
      "GaussianMLPPolicy/KL                      0.00343948\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000659771\n",
      "GaussianMLPPolicy/LossBefore              0.000666335\n",
      "GaussianMLPPolicy/dLoss                   6.56408e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.67847\n",
      "GaussianMLPValueFunction/LossBefore      -2.38788\n",
      "GaussianMLPValueFunction/dLoss            3.29059\n",
      "TotalEnvSteps                        343656\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.8839e-05, -2.2052e-04, -3.1651e-06,  ..., -3.2316e-03,\n",
      "         1.3302e-03, -3.6792e-03])\n",
      "G is: \n",
      "tensor([[1.6312e-04, 3.1507e+01],\n",
      "        [3.1507e+01, 6.0859e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [6085856.,       0.]])\n",
      "loss before is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:08 | [trpo_pendulum] epoch #172 | Saving snapshot...\n",
      "2022-08-23 10:40:08 | [trpo_pendulum] epoch #172 | Saved\n",
      "2022-08-23 10:40:08 | [trpo_pendulum] epoch #172 | Time 169.67 s\n",
      "2022-08-23 10:40:08 | [trpo_pendulum] epoch #172 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00124441\n",
      "Evaluation/AverageReturn                 -0.0156411\n",
      "Evaluation/Iteration                    172\n",
      "Evaluation/MaxReturn                     -0.0149149\n",
      "Evaluation/MinReturn                     -0.0163674\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000726231\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.46422\n",
      "GaussianMLPPolicy/KL                      0.00373811\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000372829\n",
      "GaussianMLPPolicy/LossBefore              0.000377865\n",
      "GaussianMLPPolicy/dLoss                   5.03554e-06\n",
      "GaussianMLPValueFunction/LossAfter       -4.92297\n",
      "GaussianMLPValueFunction/LossBefore      -3.58351\n",
      "GaussianMLPValueFunction/dLoss            1.33947\n",
      "TotalEnvSteps                        345654\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.9711e-05,  9.5482e-05, -6.0511e-08,  ...,  1.7313e-03,\n",
      "        -7.0552e-04,  1.9783e-03])\n",
      "G is: \n",
      "tensor([[4.6718e-05, 9.7918e+00],\n",
      "        [9.7918e+00, 2.0526e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [2052625.1250,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0007, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0007, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:09 | [trpo_pendulum] epoch #173 | Saving snapshot...\n",
      "2022-08-23 10:40:09 | [trpo_pendulum] epoch #173 | Saved\n",
      "2022-08-23 10:40:09 | [trpo_pendulum] epoch #173 | Time 170.68 s\n",
      "2022-08-23 10:40:09 | [trpo_pendulum] epoch #173 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000948812\n",
      "Evaluation/AverageReturn                 -0.00980453\n",
      "Evaluation/Iteration                    173\n",
      "Evaluation/MaxReturn                     -0.00931416\n",
      "Evaluation/MinReturn                     -0.0102949\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000490371\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.47746\n",
      "GaussianMLPPolicy/KL                      0.000984968\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000652353\n",
      "GaussianMLPPolicy/LossBefore             -0.000650955\n",
      "GaussianMLPPolicy/dLoss                   1.39768e-06\n",
      "GaussianMLPValueFunction/LossAfter       -6.15047\n",
      "GaussianMLPValueFunction/LossBefore      -3.53267\n",
      "GaussianMLPValueFunction/dLoss            2.6178\n",
      "TotalEnvSteps                        347652\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.6514e-06, -6.6977e-05, -1.8645e-06,  ..., -7.9959e-04,\n",
      "         3.3391e-04, -9.0436e-04])\n",
      "G is: \n",
      "tensor([[9.9565e-06, 2.1408e+00],\n",
      "        [2.1408e+00, 4.6052e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [460518.3125,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:10 | [trpo_pendulum] epoch #174 | Saving snapshot...\n",
      "2022-08-23 10:40:10 | [trpo_pendulum] epoch #174 | Saved\n",
      "2022-08-23 10:40:10 | [trpo_pendulum] epoch #174 | Time 171.68 s\n",
      "2022-08-23 10:40:10 | [trpo_pendulum] epoch #174 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00102634\n",
      "Evaluation/AverageReturn                 -0.0108046\n",
      "Evaluation/Iteration                    174\n",
      "Evaluation/MaxReturn                     -0.010482\n",
      "Evaluation/MinReturn                     -0.0111272\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000322605\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.47871\n",
      "GaussianMLPPolicy/KL                      0.000881843\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000213896\n",
      "GaussianMLPPolicy/LossBefore              0.000214839\n",
      "GaussianMLPPolicy/dLoss                   9.43401e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.87492\n",
      "GaussianMLPValueFunction/LossBefore      -5.60625\n",
      "GaussianMLPValueFunction/dLoss            0.268667\n",
      "TotalEnvSteps                        349650\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.3401e-05,  1.3723e-04,  5.6406e-07,  ...,  2.0432e-03,\n",
      "        -8.4485e-04,  2.3219e-03])\n",
      "G is: \n",
      "tensor([[6.4868e-05, 1.3965e+01],\n",
      "        [1.3965e+01, 3.0065e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [3006486.,       0.]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:11 | [trpo_pendulum] epoch #175 | Saving snapshot...\n",
      "2022-08-23 10:40:11 | [trpo_pendulum] epoch #175 | Saved\n",
      "2022-08-23 10:40:11 | [trpo_pendulum] epoch #175 | Time 172.69 s\n",
      "2022-08-23 10:40:11 | [trpo_pendulum] epoch #175 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000846169\n",
      "Evaluation/AverageReturn                 -0.0095656\n",
      "Evaluation/Iteration                    175\n",
      "Evaluation/MaxReturn                     -0.00928962\n",
      "Evaluation/MinReturn                     -0.00984158\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000275977\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.496\n",
      "GaussianMLPPolicy/KL                      0.000832009\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000330412\n",
      "GaussianMLPPolicy/LossBefore             -0.000329252\n",
      "GaussianMLPPolicy/dLoss                   1.15921e-06\n",
      "GaussianMLPValueFunction/LossAfter       -6.12237\n",
      "GaussianMLPValueFunction/LossBefore      -5.49545\n",
      "GaussianMLPValueFunction/dLoss            0.626918\n",
      "TotalEnvSteps                        351648\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.9600e-06,  8.9533e-05,  4.3022e-08,  ...,  1.4217e-03,\n",
      "        -5.8516e-04,  1.6186e-03])\n",
      "G is: \n",
      "tensor([[3.1443e-05, 7.0140e+00],\n",
      "        [7.0140e+00, 1.5646e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1564607.1250,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-2.5928e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-2.6125e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:12 | [trpo_pendulum] epoch #176 | Saving snapshot...\n",
      "2022-08-23 10:40:12 | [trpo_pendulum] epoch #176 | Saved\n",
      "2022-08-23 10:40:12 | [trpo_pendulum] epoch #176 | Time 173.67 s\n",
      "2022-08-23 10:40:12 | [trpo_pendulum] epoch #176 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000849853\n",
      "Evaluation/AverageReturn                 -0.00844753\n",
      "Evaluation/Iteration                    176\n",
      "Evaluation/MaxReturn                     -0.00825418\n",
      "Evaluation/MinReturn                     -0.00864089\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000193357\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.496\n",
      "GaussianMLPPolicy/KL                      0.000138925\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -2.61251e-05\n",
      "GaussianMLPPolicy/LossBefore             -2.59284e-05\n",
      "GaussianMLPPolicy/dLoss                   1.96695e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.44147\n",
      "GaussianMLPValueFunction/LossBefore      -6.21367\n",
      "GaussianMLPValueFunction/dLoss           -0.772209\n",
      "TotalEnvSteps                        353646\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.3464e-06,  5.6845e-05, -1.0584e-07,  ...,  8.9736e-04,\n",
      "        -3.6965e-04,  1.0216e-03])\n",
      "G is: \n",
      "tensor([[1.2528e-05, 2.7947e+00],\n",
      "        [2.7947e+00, 6.2342e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [623419.3125,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:13 | [trpo_pendulum] epoch #177 | Saving snapshot...\n",
      "2022-08-23 10:40:13 | [trpo_pendulum] epoch #177 | Saved\n",
      "2022-08-23 10:40:13 | [trpo_pendulum] epoch #177 | Time 174.62 s\n",
      "2022-08-23 10:40:13 | [trpo_pendulum] epoch #177 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000779877\n",
      "Evaluation/AverageReturn                 -0.00835389\n",
      "Evaluation/Iteration                    177\n",
      "Evaluation/MaxReturn                     -0.008102\n",
      "Evaluation/MinReturn                     -0.00860578\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00025189\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.496\n",
      "GaussianMLPPolicy/KL                      5.57979e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000343679\n",
      "GaussianMLPPolicy/LossBefore             -0.0003436\n",
      "GaussianMLPPolicy/dLoss                   7.86677e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.26666\n",
      "GaussianMLPValueFunction/LossBefore      -5.42913\n",
      "GaussianMLPValueFunction/dLoss            0.837526\n",
      "TotalEnvSteps                        355644\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.6089e-05,  1.1276e-04, -4.4363e-07,  ...,  2.0206e-03,\n",
      "        -8.2536e-04,  2.3068e-03])\n",
      "G is: \n",
      "tensor([[6.3529e-05, 1.4169e+01],\n",
      "        [1.4169e+01, 3.1602e+06]])\n",
      "eig is:\n",
      "tensor([[-2.5000e-01,  0.0000e+00],\n",
      "        [ 3.1602e+06,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:14 | [trpo_pendulum] epoch #178 | Saving snapshot...\n",
      "2022-08-23 10:40:14 | [trpo_pendulum] epoch #178 | Saved\n",
      "2022-08-23 10:40:14 | [trpo_pendulum] epoch #178 | Time 175.62 s\n",
      "2022-08-23 10:40:14 | [trpo_pendulum] epoch #178 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000920672\n",
      "Evaluation/AverageReturn                 -0.00979122\n",
      "Evaluation/Iteration                    178\n",
      "Evaluation/MaxReturn                     -0.00966966\n",
      "Evaluation/MinReturn                     -0.00991278\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000121562\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.5076\n",
      "GaussianMLPPolicy/KL                      0.000906292\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00013454\n",
      "GaussianMLPPolicy/LossBefore              0.000135815\n",
      "GaussianMLPPolicy/dLoss                   1.27534e-06\n",
      "GaussianMLPValueFunction/LossAfter       -6.13365\n",
      "GaussianMLPValueFunction/LossBefore      -6.07797\n",
      "GaussianMLPValueFunction/dLoss            0.0556798\n",
      "TotalEnvSteps                        357642\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.8940e-07,  3.0546e-05, -2.8642e-07,  ...,  4.8137e-04,\n",
      "        -1.9857e-04,  5.4811e-04])\n",
      "G is: \n",
      "tensor([[3.6029e-06, 8.2184e-01],\n",
      "        [8.2184e-01, 1.8747e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [187468.4531,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-5.5289e-07, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-5.7503e-07, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:15 | [trpo_pendulum] epoch #179 | Saving snapshot...\n",
      "2022-08-23 10:40:15 | [trpo_pendulum] epoch #179 | Saved\n",
      "2022-08-23 10:40:15 | [trpo_pendulum] epoch #179 | Time 176.61 s\n",
      "2022-08-23 10:40:15 | [trpo_pendulum] epoch #179 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000743932\n",
      "Evaluation/AverageReturn                 -0.00807596\n",
      "Evaluation/Iteration                    179\n",
      "Evaluation/MaxReturn                     -0.0076998\n",
      "Evaluation/MinReturn                     -0.00845213\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000376167\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.5076\n",
      "GaussianMLPPolicy/KL                      1.57229e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.75026e-07\n",
      "GaussianMLPPolicy/LossBefore             -5.52886e-07\n",
      "GaussianMLPPolicy/dLoss                   2.21393e-08\n",
      "GaussianMLPValueFunction/LossAfter       -5.9365\n",
      "GaussianMLPValueFunction/LossBefore      -6.27611\n",
      "GaussianMLPValueFunction/dLoss           -0.339611\n",
      "TotalEnvSteps                        359640\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.9298e-05,  6.2287e-05, -3.7271e-09,  ...,  9.7989e-04,\n",
      "        -4.0364e-04,  1.1154e-03])\n",
      "G is: \n",
      "tensor([[1.4926e-05, 3.4050e+00],\n",
      "        [3.4050e+00, 7.7680e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [776801.7500,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:16 | [trpo_pendulum] epoch #180 | Saving snapshot...\n",
      "2022-08-23 10:40:16 | [trpo_pendulum] epoch #180 | Saved\n",
      "2022-08-23 10:40:16 | [trpo_pendulum] epoch #180 | Time 177.59 s\n",
      "2022-08-23 10:40:16 | [trpo_pendulum] epoch #180 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000795148\n",
      "Evaluation/AverageReturn                 -0.00831162\n",
      "Evaluation/Iteration                    180\n",
      "Evaluation/MaxReturn                     -0.00791752\n",
      "Evaluation/MinReturn                     -0.00870572\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000394104\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.52108\n",
      "GaussianMLPPolicy/KL                      0.000248821\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000190846\n",
      "GaussianMLPPolicy/LossBefore              0.000191197\n",
      "GaussianMLPPolicy/dLoss                   3.514e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.297\n",
      "GaussianMLPValueFunction/LossBefore      -6.02184\n",
      "GaussianMLPValueFunction/dLoss            0.275155\n",
      "TotalEnvSteps                        361638\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.1745e-05,  1.1164e-04, -5.2853e-08,  ...,  1.7243e-03,\n",
      "        -7.1130e-04,  1.9619e-03])\n",
      "G is: \n",
      "tensor([[4.6217e-05, 1.0832e+01],\n",
      "        [1.0832e+01, 2.5386e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [2538629.,       0.]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:17 | [trpo_pendulum] epoch #181 | Saving snapshot...\n",
      "2022-08-23 10:40:17 | [trpo_pendulum] epoch #181 | Saved\n",
      "2022-08-23 10:40:17 | [trpo_pendulum] epoch #181 | Time 178.57 s\n",
      "2022-08-23 10:40:17 | [trpo_pendulum] epoch #181 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000683914\n",
      "Evaluation/AverageReturn                 -0.00716446\n",
      "Evaluation/Iteration                    181\n",
      "Evaluation/MaxReturn                     -0.00712761\n",
      "Evaluation/MinReturn                     -0.00720132\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.68518e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.53015\n",
      "GaussianMLPPolicy/KL                      0.000301179\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000123224\n",
      "GaussianMLPPolicy/LossBefore             -0.000122788\n",
      "GaussianMLPPolicy/dLoss                   4.36165e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.82754\n",
      "GaussianMLPValueFunction/LossBefore      -6.21309\n",
      "GaussianMLPValueFunction/dLoss           -0.385549\n",
      "TotalEnvSteps                        363636\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.0710e-06, -7.2611e-05,  1.6887e-07,  ..., -1.1602e-03,\n",
      "         4.7768e-04, -1.3209e-03])\n",
      "G is: \n",
      "tensor([[2.0926e-05, 4.9949e+00],\n",
      "        [4.9949e+00, 1.1923e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1192271.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:18 | [trpo_pendulum] epoch #182 | Saving snapshot...\n",
      "2022-08-23 10:40:18 | [trpo_pendulum] epoch #182 | Saved\n",
      "2022-08-23 10:40:18 | [trpo_pendulum] epoch #182 | Time 179.67 s\n",
      "2022-08-23 10:40:18 | [trpo_pendulum] epoch #182 | EpochTime 1.09 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000891779\n",
      "Evaluation/AverageReturn                 -0.0100331\n",
      "Evaluation/Iteration                    182\n",
      "Evaluation/MaxReturn                     -0.00994086\n",
      "Evaluation/MinReturn                     -0.0101254\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      9.228e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.53015\n",
      "GaussianMLPPolicy/KL                      8.68708e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000117493\n",
      "GaussianMLPPolicy/LossBefore              0.000117616\n",
      "GaussianMLPPolicy/dLoss                   1.2292e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.77628\n",
      "GaussianMLPValueFunction/LossBefore      -5.85691\n",
      "GaussianMLPValueFunction/dLoss           -0.080626\n",
      "TotalEnvSteps                        365634\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.3423e-06,  2.2014e-05, -1.2849e-06,  ...,  3.4852e-04,\n",
      "        -1.4495e-04,  3.9730e-04])\n",
      "G is: \n",
      "tensor([[1.8917e-06, 4.5148e-01],\n",
      "        [4.5148e-01, 1.0778e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [107777.8594,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0005, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0005, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:19 | [trpo_pendulum] epoch #183 | Saving snapshot...\n",
      "2022-08-23 10:40:19 | [trpo_pendulum] epoch #183 | Saved\n",
      "2022-08-23 10:40:19 | [trpo_pendulum] epoch #183 | Time 180.71 s\n",
      "2022-08-23 10:40:19 | [trpo_pendulum] epoch #183 | EpochTime 1.04 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000778804\n",
      "Evaluation/AverageReturn                 -0.00815118\n",
      "Evaluation/Iteration                    183\n",
      "Evaluation/MaxReturn                     -0.00790758\n",
      "Evaluation/MinReturn                     -0.00839477\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000243595\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.53373\n",
      "GaussianMLPPolicy/KL                      0.00987555\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000461907\n",
      "GaussianMLPPolicy/LossBefore             -0.000461437\n",
      "GaussianMLPPolicy/dLoss                   4.7058e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.24485\n",
      "GaussianMLPValueFunction/LossBefore      -4.58296\n",
      "GaussianMLPValueFunction/dLoss            1.66188\n",
      "TotalEnvSteps                        367632\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.2620e-05,  5.8853e-05,  5.4363e-10,  ...,  1.0699e-03,\n",
      "        -4.3932e-04,  1.2164e-03])\n",
      "G is: \n",
      "tensor([[1.7704e-05, 4.2438e+00],\n",
      "        [4.2438e+00, 1.0173e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1017294.9375,       0.0000]])\n",
      "loss before is:\n",
      "tensor(5.2917e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(5.2703e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:20 | [trpo_pendulum] epoch #184 | Saving snapshot...\n",
      "2022-08-23 10:40:20 | [trpo_pendulum] epoch #184 | Saved\n",
      "2022-08-23 10:40:20 | [trpo_pendulum] epoch #184 | Time 181.70 s\n",
      "2022-08-23 10:40:20 | [trpo_pendulum] epoch #184 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000821905\n",
      "Evaluation/AverageReturn                 -0.00824152\n",
      "Evaluation/Iteration                    184\n",
      "Evaluation/MaxReturn                     -0.00802842\n",
      "Evaluation/MinReturn                     -0.00845461\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000213095\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.54258\n",
      "GaussianMLPPolicy/KL                      0.000152643\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               5.27031e-05\n",
      "GaussianMLPPolicy/LossBefore              5.29173e-05\n",
      "GaussianMLPPolicy/dLoss                   2.14182e-07\n",
      "GaussianMLPValueFunction/LossAfter       -4.81298\n",
      "GaussianMLPValueFunction/LossBefore      -6.31311\n",
      "GaussianMLPValueFunction/dLoss           -1.50013\n",
      "TotalEnvSteps                        369630\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-3.9261e-06, -7.9863e-05,  4.3982e-07,  ..., -1.4061e-03,\n",
      "         5.7920e-04, -1.5978e-03])\n",
      "G is: \n",
      "tensor([[3.0579e-05, 7.4604e+00],\n",
      "        [7.4604e+00, 1.8201e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [1820101.,       0.]])\n",
      "loss before is:\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:21 | [trpo_pendulum] epoch #185 | Saving snapshot...\n",
      "2022-08-23 10:40:21 | [trpo_pendulum] epoch #185 | Saved\n",
      "2022-08-23 10:40:21 | [trpo_pendulum] epoch #185 | Time 182.66 s\n",
      "2022-08-23 10:40:21 | [trpo_pendulum] epoch #185 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000924379\n",
      "Evaluation/AverageReturn                 -0.00879134\n",
      "Evaluation/Iteration                    185\n",
      "Evaluation/MaxReturn                     -0.00857645\n",
      "Evaluation/MinReturn                     -0.00900622\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000214882\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.5415\n",
      "GaussianMLPPolicy/KL                      0.000175337\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00053408\n",
      "GaussianMLPPolicy/LossBefore              0.000534325\n",
      "GaussianMLPPolicy/dLoss                   2.4488e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.33131\n",
      "GaussianMLPValueFunction/LossBefore      -3.77431\n",
      "GaussianMLPValueFunction/dLoss            2.557\n",
      "TotalEnvSteps                        371628\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.2031e-05,  3.8553e-06, -3.1322e-07,  ...,  2.9558e-05,\n",
      "        -1.3739e-05,  3.2662e-05])\n",
      "G is: \n",
      "tensor([[1.3823e-08, 3.2973e-03],\n",
      "        [3.2973e-03, 8.0255e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [802.5516,   0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:22 | [trpo_pendulum] epoch #186 | Saving snapshot...\n",
      "2022-08-23 10:40:22 | [trpo_pendulum] epoch #186 | Saved\n",
      "2022-08-23 10:40:22 | [trpo_pendulum] epoch #186 | Time 183.63 s\n",
      "2022-08-23 10:40:22 | [trpo_pendulum] epoch #186 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000975234\n",
      "Evaluation/AverageReturn                 -0.010437\n",
      "Evaluation/Iteration                    186\n",
      "Evaluation/MaxReturn                     -0.0103224\n",
      "Evaluation/MinReturn                     -0.0105516\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000114597\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.55039\n",
      "GaussianMLPPolicy/KL                      9.73821e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000142442\n",
      "GaussianMLPPolicy/LossBefore              0.000142579\n",
      "GaussianMLPPolicy/dLoss                   1.36657e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.91065\n",
      "GaussianMLPValueFunction/LossBefore      -5.95916\n",
      "GaussianMLPValueFunction/dLoss           -0.0485115\n",
      "TotalEnvSteps                        373626\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.9686e-05, -6.4903e-05,  1.0540e-08,  ..., -1.1872e-03,\n",
      "         4.8729e-04, -1.3498e-03])\n",
      "G is: \n",
      "tensor([[2.1792e-05, 5.3996e+00],\n",
      "        [5.3996e+00, 1.3380e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1337969.2500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0005, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0005, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:23 | [trpo_pendulum] epoch #187 | Saving snapshot...\n",
      "2022-08-23 10:40:23 | [trpo_pendulum] epoch #187 | Saved\n",
      "2022-08-23 10:40:23 | [trpo_pendulum] epoch #187 | Time 184.59 s\n",
      "2022-08-23 10:40:23 | [trpo_pendulum] epoch #187 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000858342\n",
      "Evaluation/AverageReturn                 -0.00840724\n",
      "Evaluation/Iteration                    187\n",
      "Evaluation/MaxReturn                     -0.00816253\n",
      "Evaluation/MinReturn                     -0.00865195\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00024471\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.57731\n",
      "GaussianMLPPolicy/KL                      0.000823449\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000460293\n",
      "GaussianMLPPolicy/LossBefore             -0.000459137\n",
      "GaussianMLPPolicy/dLoss                   1.15662e-06\n",
      "GaussianMLPValueFunction/LossAfter       -6.30899\n",
      "GaussianMLPValueFunction/LossBefore      -4.45026\n",
      "GaussianMLPValueFunction/dLoss            1.85872\n",
      "TotalEnvSteps                        375624\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-6.5693e-06,  7.7189e-05, -7.6046e-08,  ...,  1.4143e-03,\n",
      "        -5.8052e-04,  1.6082e-03])\n",
      "G is: \n",
      "tensor([[3.0929e-05, 8.0881e+00],\n",
      "        [8.0881e+00, 2.1151e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [2115100.,       0.]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:24 | [trpo_pendulum] epoch #188 | Saving snapshot...\n",
      "2022-08-23 10:40:24 | [trpo_pendulum] epoch #188 | Saved\n",
      "2022-08-23 10:40:24 | [trpo_pendulum] epoch #188 | Time 185.59 s\n",
      "2022-08-23 10:40:24 | [trpo_pendulum] epoch #188 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000874208\n",
      "Evaluation/AverageReturn                 -0.00886437\n",
      "Evaluation/Iteration                    188\n",
      "Evaluation/MaxReturn                     -0.0086116\n",
      "Evaluation/MinReturn                     -0.00911714\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000252766\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.57731\n",
      "GaussianMLPPolicy/KL                      0.000116786\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000196959\n",
      "GaussianMLPPolicy/LossBefore              0.000197126\n",
      "GaussianMLPPolicy/dLoss                   1.66794e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.73504\n",
      "GaussianMLPValueFunction/LossBefore      -5.99882\n",
      "GaussianMLPValueFunction/dLoss           -0.263775\n",
      "TotalEnvSteps                        377622\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.4928e-06,  8.4094e-05, -1.9201e-07,  ...,  1.6435e-03,\n",
      "        -6.7170e-04,  1.8716e-03])\n",
      "G is: \n",
      "tensor([[4.1771e-05, 1.0921e+01],\n",
      "        [1.0921e+01, 2.8555e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [2855539.,       0.]])\n",
      "loss before is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:25 | [trpo_pendulum] epoch #189 | Saving snapshot...\n",
      "2022-08-23 10:40:25 | [trpo_pendulum] epoch #189 | Saved\n",
      "2022-08-23 10:40:25 | [trpo_pendulum] epoch #189 | Time 186.58 s\n",
      "2022-08-23 10:40:25 | [trpo_pendulum] epoch #189 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000937643\n",
      "Evaluation/AverageReturn                 -0.00954559\n",
      "Evaluation/Iteration                    189\n",
      "Evaluation/MaxReturn                     -0.0094197\n",
      "Evaluation/MinReturn                     -0.00967147\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000125883\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.57713\n",
      "GaussianMLPPolicy/KL                      0.000226048\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000339936\n",
      "GaussianMLPPolicy/LossBefore              0.000340261\n",
      "GaussianMLPPolicy/dLoss                   3.25672e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.17323\n",
      "GaussianMLPValueFunction/LossBefore      -5.15828\n",
      "GaussianMLPValueFunction/dLoss            1.01496\n",
      "TotalEnvSteps                        379620\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.2980e-06, -9.4042e-05,  4.5813e-07,  ..., -1.3251e-03,\n",
      "         5.5563e-04, -1.4972e-03])\n",
      "G is: \n",
      "tensor([[2.7144e-05, 7.0902e+00],\n",
      "        [7.0902e+00, 1.8527e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1852719.7500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:26 | [trpo_pendulum] epoch #190 | Saving snapshot...\n",
      "2022-08-23 10:40:26 | [trpo_pendulum] epoch #190 | Saved\n",
      "2022-08-23 10:40:26 | [trpo_pendulum] epoch #190 | Time 187.55 s\n",
      "2022-08-23 10:40:26 | [trpo_pendulum] epoch #190 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00093767\n",
      "Evaluation/AverageReturn                 -0.00970529\n",
      "Evaluation/Iteration                    190\n",
      "Evaluation/MaxReturn                     -0.00944813\n",
      "Evaluation/MinReturn                     -0.00996244\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000257153\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.58303\n",
      "GaussianMLPPolicy/KL                      0.000886504\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000196133\n",
      "GaussianMLPPolicy/LossBefore              0.000197265\n",
      "GaussianMLPPolicy/dLoss                   1.13249e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.82589\n",
      "GaussianMLPValueFunction/LossBefore      -5.805\n",
      "GaussianMLPValueFunction/dLoss            0.0208812\n",
      "TotalEnvSteps                        381618\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.2788e-05,  1.0094e-04,  6.6462e-08,  ...,  1.7819e-03,\n",
      "        -7.3162e-04,  2.0265e-03])\n",
      "G is: \n",
      "tensor([[4.9110e-05, 1.2987e+01],\n",
      "        [1.2987e+01, 3.4345e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [3434487.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(4.9159e-06, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(4.5430e-06, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:27 | [trpo_pendulum] epoch #191 | Saving snapshot...\n",
      "2022-08-23 10:40:27 | [trpo_pendulum] epoch #191 | Saved\n",
      "2022-08-23 10:40:27 | [trpo_pendulum] epoch #191 | Time 188.48 s\n",
      "2022-08-23 10:40:27 | [trpo_pendulum] epoch #191 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00081446\n",
      "Evaluation/AverageReturn                 -0.00837654\n",
      "Evaluation/Iteration                    191\n",
      "Evaluation/MaxReturn                     -0.0078556\n",
      "Evaluation/MinReturn                     -0.00889748\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000520938\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.59196\n",
      "GaussianMLPPolicy/KL                      0.000263455\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               4.54297e-06\n",
      "GaussianMLPPolicy/LossBefore              4.91591e-06\n",
      "GaussianMLPPolicy/dLoss                   3.72934e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.34199\n",
      "GaussianMLPValueFunction/LossBefore      -6.36172\n",
      "GaussianMLPValueFunction/dLoss           -0.0197272\n",
      "TotalEnvSteps                        383616\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.1867e-06,  5.5361e-05, -8.9004e-09,  ...,  1.0278e-03,\n",
      "        -4.2053e-04,  1.1703e-03])\n",
      "G is: \n",
      "tensor([[1.6342e-05, 4.4002e+00],\n",
      "        [4.4002e+00, 1.1848e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1184780.3750,       0.0000]])\n",
      "loss before is:\n",
      "tensor(7.8934e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(7.8766e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:28 | [trpo_pendulum] epoch #192 | Saving snapshot...\n",
      "2022-08-23 10:40:28 | [trpo_pendulum] epoch #192 | Saved\n",
      "2022-08-23 10:40:28 | [trpo_pendulum] epoch #192 | Time 189.49 s\n",
      "2022-08-23 10:40:28 | [trpo_pendulum] epoch #192 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000781398\n",
      "Evaluation/AverageReturn                 -0.0082089\n",
      "Evaluation/Iteration                    192\n",
      "Evaluation/MaxReturn                     -0.00818446\n",
      "Evaluation/MinReturn                     -0.00823334\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.44407e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.59446\n",
      "GaussianMLPPolicy/KL                      0.000119047\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               7.87658e-05\n",
      "GaussianMLPPolicy/LossBefore              7.89336e-05\n",
      "GaussianMLPPolicy/dLoss                   1.67784e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.94409\n",
      "GaussianMLPValueFunction/LossBefore      -6.33589\n",
      "GaussianMLPValueFunction/dLoss           -0.391805\n",
      "TotalEnvSteps                        385614\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.8788e-05,  3.5808e-05, -1.1454e-07,  ...,  1.7658e-03,\n",
      "        -6.9185e-04,  2.0368e-03])\n",
      "G is: \n",
      "tensor([[4.8350e-05, 1.3053e+01],\n",
      "        [1.3053e+01, 3.5306e+06]])\n",
      "eig is:\n",
      "tensor([[2.5000e-01, 0.0000e+00],\n",
      "        [3.5306e+06, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.0007, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0007, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:29 | [trpo_pendulum] epoch #193 | Saving snapshot...\n",
      "2022-08-23 10:40:29 | [trpo_pendulum] epoch #193 | Saved\n",
      "2022-08-23 10:40:29 | [trpo_pendulum] epoch #193 | Time 190.56 s\n",
      "2022-08-23 10:40:29 | [trpo_pendulum] epoch #193 | EpochTime 1.06 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00105787\n",
      "Evaluation/AverageReturn                 -0.0108887\n",
      "Evaluation/Iteration                    193\n",
      "Evaluation/MaxReturn                     -0.0108822\n",
      "Evaluation/MinReturn                     -0.0108952\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.52355e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.62369\n",
      "GaussianMLPPolicy/KL                      0.00293043\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000656173\n",
      "GaussianMLPPolicy/LossBefore              0.000660727\n",
      "GaussianMLPPolicy/dLoss                   4.55393e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.3119\n",
      "GaussianMLPValueFunction/LossBefore      -0.80289\n",
      "GaussianMLPValueFunction/dLoss            4.50901\n",
      "TotalEnvSteps                        387612\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.3629e-06, -3.8828e-05,  1.3528e-06,  ..., -6.6014e-04,\n",
      "         2.7281e-04, -7.5167e-04])\n",
      "G is: \n",
      "tensor([[6.7447e-06, 1.9335e+00],\n",
      "        [1.9335e+00, 5.5432e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [554318.8750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:30 | [trpo_pendulum] epoch #194 | Saving snapshot...\n",
      "2022-08-23 10:40:30 | [trpo_pendulum] epoch #194 | Saved\n",
      "2022-08-23 10:40:30 | [trpo_pendulum] epoch #194 | Time 191.55 s\n",
      "2022-08-23 10:40:30 | [trpo_pendulum] epoch #194 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000976731\n",
      "Evaluation/AverageReturn                 -0.00950562\n",
      "Evaluation/Iteration                    194\n",
      "Evaluation/MaxReturn                     -0.00928773\n",
      "Evaluation/MinReturn                     -0.00972352\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000217895\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.62833\n",
      "GaussianMLPPolicy/KL                      0.000325695\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000301934\n",
      "GaussianMLPPolicy/LossBefore             -0.000301572\n",
      "GaussianMLPPolicy/dLoss                   3.61761e-07\n",
      "GaussianMLPValueFunction/LossAfter       -4.15073\n",
      "GaussianMLPValueFunction/LossBefore      -5.04379\n",
      "GaussianMLPValueFunction/dLoss           -0.893065\n",
      "TotalEnvSteps                        389610\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-7.7556e-06, -1.4555e-05, -1.6684e-06,  ..., -7.1304e-05,\n",
      "         3.2427e-05, -7.5942e-05])\n",
      "G is: \n",
      "tensor([[8.0761e-08, 2.2520e-02],\n",
      "        [2.2520e-02, 6.5217e+03]])\n",
      "eig is:\n",
      "tensor([[   0.0000,    0.0000],\n",
      "        [6521.7109,    0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:31 | [trpo_pendulum] epoch #195 | Saving snapshot...\n",
      "2022-08-23 10:40:31 | [trpo_pendulum] epoch #195 | Saved\n",
      "2022-08-23 10:40:31 | [trpo_pendulum] epoch #195 | Time 192.55 s\n",
      "2022-08-23 10:40:31 | [trpo_pendulum] epoch #195 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000913617\n",
      "Evaluation/AverageReturn                 -0.00981005\n",
      "Evaluation/Iteration                    195\n",
      "Evaluation/MaxReturn                     -0.00955258\n",
      "Evaluation/MinReturn                     -0.0100675\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000257477\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.62408\n",
      "GaussianMLPPolicy/KL                      0.00037025\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000448862\n",
      "GaussianMLPPolicy/LossBefore              0.000449336\n",
      "GaussianMLPPolicy/dLoss                   4.73374e-07\n",
      "GaussianMLPValueFunction/LossAfter       -4.74049\n",
      "GaussianMLPValueFunction/LossBefore      -4.08442\n",
      "GaussianMLPValueFunction/dLoss            0.656074\n",
      "TotalEnvSteps                        391608\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.1221e-05,  4.2289e-05, -1.3564e-08,  ...,  7.2983e-04,\n",
      "        -2.9976e-04,  8.3016e-04])\n",
      "G is: \n",
      "tensor([[8.2355e-06, 2.3629e+00],\n",
      "        [2.3629e+00, 6.7795e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [677952.5000,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-1.4523e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-1.4652e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:32 | [trpo_pendulum] epoch #196 | Saving snapshot...\n",
      "2022-08-23 10:40:32 | [trpo_pendulum] epoch #196 | Saved\n",
      "2022-08-23 10:40:32 | [trpo_pendulum] epoch #196 | Time 193.54 s\n",
      "2022-08-23 10:40:32 | [trpo_pendulum] epoch #196 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000735233\n",
      "Evaluation/AverageReturn                 -0.00752773\n",
      "Evaluation/Iteration                    196\n",
      "Evaluation/MaxReturn                     -0.00745694\n",
      "Evaluation/MinReturn                     -0.00759851\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.07822e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.63201\n",
      "GaussianMLPPolicy/KL                      9.23951e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -1.46524e-05\n",
      "GaussianMLPPolicy/LossBefore             -1.45233e-05\n",
      "GaussianMLPPolicy/dLoss                   1.29089e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.35795\n",
      "GaussianMLPValueFunction/LossBefore      -6.34646\n",
      "GaussianMLPValueFunction/dLoss            0.0114927\n",
      "TotalEnvSteps                        393606\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.3128e-06, -6.1264e-05,  3.8842e-07,  ..., -4.4708e-04,\n",
      "         2.0160e-04, -4.9432e-04])\n",
      "G is: \n",
      "tensor([[3.1121e-06, 8.9970e-01],\n",
      "        [8.9970e-01, 2.6224e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [262237.8750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:33 | [trpo_pendulum] epoch #197 | Saving snapshot...\n",
      "2022-08-23 10:40:33 | [trpo_pendulum] epoch #197 | Saved\n",
      "2022-08-23 10:40:33 | [trpo_pendulum] epoch #197 | Time 194.51 s\n",
      "2022-08-23 10:40:33 | [trpo_pendulum] epoch #197 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000809906\n",
      "Evaluation/AverageReturn                 -0.00838826\n",
      "Evaluation/Iteration                    197\n",
      "Evaluation/MaxReturn                     -0.00820028\n",
      "Evaluation/MinReturn                     -0.00857623\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000187977\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.63877\n",
      "GaussianMLPPolicy/KL                      0.00143101\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00025056\n",
      "GaussianMLPPolicy/LossBefore              0.000252534\n",
      "GaussianMLPPolicy/dLoss                   1.97347e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.43483\n",
      "GaussianMLPValueFunction/LossBefore      -5.63996\n",
      "GaussianMLPValueFunction/dLoss           -0.205133\n",
      "TotalEnvSteps                        395604\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.5678e-06,  1.2615e-04, -7.2218e-08,  ...,  2.1111e-03,\n",
      "        -8.6741e-04,  2.4020e-03])\n",
      "G is: \n",
      "tensor([[6.8932e-05, 2.0365e+01],\n",
      "        [2.0365e+01, 6.0165e+06]])\n",
      "eig is:\n",
      "tensor([[5.0000e-01, 0.0000e+00],\n",
      "        [6.0165e+06, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0005, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0005, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:34 | [trpo_pendulum] epoch #198 | Saving snapshot...\n",
      "2022-08-23 10:40:34 | [trpo_pendulum] epoch #198 | Saved\n",
      "2022-08-23 10:40:34 | [trpo_pendulum] epoch #198 | Time 195.48 s\n",
      "2022-08-23 10:40:34 | [trpo_pendulum] epoch #198 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000724466\n",
      "Evaluation/AverageReturn                 -0.00729138\n",
      "Evaluation/Iteration                    198\n",
      "Evaluation/MaxReturn                     -0.00721739\n",
      "Evaluation/MinReturn                     -0.00736536\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.39817e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.63877\n",
      "GaussianMLPPolicy/KL                      0.000227916\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00051118\n",
      "GaussianMLPPolicy/LossBefore             -0.000510856\n",
      "GaussianMLPPolicy/dLoss                   3.24682e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.40849\n",
      "GaussianMLPValueFunction/LossBefore      -3.99724\n",
      "GaussianMLPValueFunction/dLoss            1.41124\n",
      "TotalEnvSteps                        397602\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.8833e-06,  8.1767e-05,  1.0377e-07,  ...,  1.3466e-03,\n",
      "        -5.5377e-04,  1.5316e-03])\n",
      "G is: \n",
      "tensor([[2.8047e-05, 8.2859e+00],\n",
      "        [8.2859e+00, 2.4478e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [2447844.,       0.]])\n",
      "loss before is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:35 | [trpo_pendulum] epoch #199 | Saving snapshot...\n",
      "2022-08-23 10:40:35 | [trpo_pendulum] epoch #199 | Saved\n",
      "2022-08-23 10:40:35 | [trpo_pendulum] epoch #199 | Time 196.51 s\n",
      "2022-08-23 10:40:35 | [trpo_pendulum] epoch #199 | EpochTime 1.02 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000709246\n",
      "Evaluation/AverageReturn                 -0.00736233\n",
      "Evaluation/Iteration                    199\n",
      "Evaluation/MaxReturn                     -0.0071452\n",
      "Evaluation/MinReturn                     -0.00757945\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000217127\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.63877\n",
      "GaussianMLPPolicy/KL                      9.39641e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00032968\n",
      "GaussianMLPPolicy/LossBefore              0.000329813\n",
      "GaussianMLPPolicy/dLoss                   1.33208e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.43006\n",
      "GaussianMLPValueFunction/LossBefore      -5.37267\n",
      "GaussianMLPValueFunction/dLoss            1.05739\n",
      "TotalEnvSteps                        399600\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.4631e-06,  1.7190e-05,  8.9302e-08,  ...,  3.6669e-04,\n",
      "        -1.4829e-04,  4.1900e-04])\n",
      "G is: \n",
      "tensor([[2.0804e-06, 6.1442e-01],\n",
      "        [6.1442e-01, 1.8150e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [181503.8125,      0.0000]])\n",
      "loss before is:\n",
      "tensor(7.9913e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(7.9804e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:36 | [trpo_pendulum] epoch #200 | Saving snapshot...\n",
      "2022-08-23 10:40:36 | [trpo_pendulum] epoch #200 | Saved\n",
      "2022-08-23 10:40:36 | [trpo_pendulum] epoch #200 | Time 197.50 s\n",
      "2022-08-23 10:40:36 | [trpo_pendulum] epoch #200 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000788358\n",
      "Evaluation/AverageReturn                 -0.00762975\n",
      "Evaluation/Iteration                    200\n",
      "Evaluation/MaxReturn                     -0.00745553\n",
      "Evaluation/MinReturn                     -0.00780397\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000174218\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.63909\n",
      "GaussianMLPPolicy/KL                      7.67356e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               7.98035e-05\n",
      "GaussianMLPPolicy/LossBefore              7.99135e-05\n",
      "GaussianMLPPolicy/dLoss                   1.09954e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.1528\n",
      "GaussianMLPValueFunction/LossBefore      -6.35919\n",
      "GaussianMLPValueFunction/dLoss           -0.206391\n",
      "TotalEnvSteps                        401598\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.9259e-06,  1.3295e-04, -8.7025e-07,  ...,  2.6122e-03,\n",
      "        -1.0625e-03,  2.9824e-03])\n",
      "G is: \n",
      "tensor([[1.0558e-04, 3.1200e+01],\n",
      "        [3.1200e+01, 9.2215e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [9221478.,       0.]])\n",
      "loss before is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:37 | [trpo_pendulum] epoch #201 | Saving snapshot...\n",
      "2022-08-23 10:40:37 | [trpo_pendulum] epoch #201 | Saved\n",
      "2022-08-23 10:40:37 | [trpo_pendulum] epoch #201 | Time 198.46 s\n",
      "2022-08-23 10:40:37 | [trpo_pendulum] epoch #201 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000768745\n",
      "Evaluation/AverageReturn                 -0.00849334\n",
      "Evaluation/Iteration                    201\n",
      "Evaluation/MaxReturn                     -0.00828605\n",
      "Evaluation/MinReturn                     -0.00870063\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000207289\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.64599\n",
      "GaussianMLPPolicy/KL                      0.00104984\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000317311\n",
      "GaussianMLPPolicy/LossBefore              0.000318798\n",
      "GaussianMLPPolicy/dLoss                   1.48689e-06\n",
      "GaussianMLPValueFunction/LossAfter       -6.08375\n",
      "GaussianMLPValueFunction/LossBefore      -5.19436\n",
      "GaussianMLPValueFunction/dLoss            0.889386\n",
      "TotalEnvSteps                        403596\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.8508e-08,  5.1328e-05, -1.0693e-07,  ...,  8.7101e-04,\n",
      "        -3.5767e-04,  9.9116e-04])\n",
      "G is: \n",
      "tensor([[1.1720e-05, 3.5090e+00],\n",
      "        [3.5090e+00, 1.0506e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1050592.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-9.0014e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-9.0069e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:38 | [trpo_pendulum] epoch #202 | Saving snapshot...\n",
      "2022-08-23 10:40:38 | [trpo_pendulum] epoch #202 | Saved\n",
      "2022-08-23 10:40:38 | [trpo_pendulum] epoch #202 | Time 199.41 s\n",
      "2022-08-23 10:40:38 | [trpo_pendulum] epoch #202 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000695105\n",
      "Evaluation/AverageReturn                 -0.00718943\n",
      "Evaluation/Iteration                    202\n",
      "Evaluation/MaxReturn                     -0.00706396\n",
      "Evaluation/MinReturn                     -0.0073149\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000125469\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.64599\n",
      "GaussianMLPPolicy/KL                      3.89426e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -9.00692e-05\n",
      "GaussianMLPPolicy/LossBefore             -9.0014e-05\n",
      "GaussianMLPPolicy/dLoss                   5.51809e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.42312\n",
      "GaussianMLPValueFunction/LossBefore      -6.34581\n",
      "GaussianMLPValueFunction/dLoss            0.0773115\n",
      "TotalEnvSteps                        405594\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-9.9861e-06, -1.6292e-05, -6.1125e-07,  ..., -9.4637e-05,\n",
      "         4.3247e-05, -1.0339e-04])\n",
      "G is: \n",
      "tensor([[1.4003e-07, 4.1219e-02],\n",
      "        [4.1219e-02, 1.2341e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [12340.7012,     0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:39 | [trpo_pendulum] epoch #203 | Saving snapshot...\n",
      "2022-08-23 10:40:39 | [trpo_pendulum] epoch #203 | Saved\n",
      "2022-08-23 10:40:39 | [trpo_pendulum] epoch #203 | Time 200.40 s\n",
      "2022-08-23 10:40:39 | [trpo_pendulum] epoch #203 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000696582\n",
      "Evaluation/AverageReturn                 -0.00751246\n",
      "Evaluation/Iteration                    203\n",
      "Evaluation/MaxReturn                     -0.00742412\n",
      "Evaluation/MinReturn                     -0.00760079\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.83344e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.63776\n",
      "GaussianMLPPolicy/KL                      0.000239064\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000214461\n",
      "GaussianMLPPolicy/LossBefore              0.000214808\n",
      "GaussianMLPPolicy/dLoss                   3.47034e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.90196\n",
      "GaussianMLPValueFunction/LossBefore      -5.85475\n",
      "GaussianMLPValueFunction/dLoss            0.0472116\n",
      "TotalEnvSteps                        407592\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.3533e-05, -3.4486e-04,  6.5456e-07,  ..., -5.7591e-03,\n",
      "         2.3676e-03, -6.5508e-03])\n",
      "G is: \n",
      "tensor([[5.1191e-04, 1.5063e+02],\n",
      "        [1.5063e+02, 4.4323e+07]])\n",
      "eig is:\n",
      "tensor([[       0.,        0.],\n",
      "        [44323100.,        0.]])\n",
      "loss before is:\n",
      "tensor(0.0006, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0006, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:40 | [trpo_pendulum] epoch #204 | Saving snapshot...\n",
      "2022-08-23 10:40:40 | [trpo_pendulum] epoch #204 | Saved\n",
      "2022-08-23 10:40:40 | [trpo_pendulum] epoch #204 | Time 201.39 s\n",
      "2022-08-23 10:40:40 | [trpo_pendulum] epoch #204 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000786213\n",
      "Evaluation/AverageReturn                 -0.00889203\n",
      "Evaluation/Iteration                    204\n",
      "Evaluation/MaxReturn                     -0.00887296\n",
      "Evaluation/MinReturn                     -0.0089111\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.90701e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.64419\n",
      "GaussianMLPPolicy/KL                      0.0017399\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000570481\n",
      "GaussianMLPPolicy/LossBefore              0.000573017\n",
      "GaussianMLPPolicy/dLoss                   2.53558e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.12484\n",
      "GaussianMLPValueFunction/LossBefore      -1.71264\n",
      "GaussianMLPValueFunction/dLoss            3.41221\n",
      "TotalEnvSteps                        409590\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.7679e-05,  2.1113e-04, -5.9118e-08,  ...,  3.5093e-03,\n",
      "        -1.4423e-03,  3.9920e-03])\n",
      "G is: \n",
      "tensor([[1.9022e-04, 5.6736e+01],\n",
      "        [5.6736e+01, 1.6922e+07]])\n",
      "eig is:\n",
      "tensor([[       0.,        0.],\n",
      "        [16922320.,        0.]])\n",
      "loss before is:\n",
      "tensor(-0.0007, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0007, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:41 | [trpo_pendulum] epoch #205 | Saving snapshot...\n",
      "2022-08-23 10:40:41 | [trpo_pendulum] epoch #205 | Saved\n",
      "2022-08-23 10:40:41 | [trpo_pendulum] epoch #205 | Time 202.36 s\n",
      "2022-08-23 10:40:41 | [trpo_pendulum] epoch #205 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00071432\n",
      "Evaluation/AverageReturn                 -0.00720849\n",
      "Evaluation/Iteration                    205\n",
      "Evaluation/MaxReturn                     -0.00701543\n",
      "Evaluation/MinReturn                     -0.00740154\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000193056\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.63182\n",
      "GaussianMLPPolicy/KL                      0.000719654\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000711762\n",
      "GaussianMLPPolicy/LossBefore             -0.000710643\n",
      "GaussianMLPPolicy/dLoss                   1.11863e-06\n",
      "GaussianMLPValueFunction/LossAfter       -6.35656\n",
      "GaussianMLPValueFunction/LossBefore      -1.85201\n",
      "GaussianMLPValueFunction/dLoss            4.50455\n",
      "TotalEnvSteps                        411588\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.9149e-06,  4.5995e-05, -1.8637e-07,  ...,  9.4025e-04,\n",
      "        -3.8152e-04,  1.0737e-03])\n",
      "G is: \n",
      "tensor([[1.3660e-05, 3.9740e+00],\n",
      "        [3.9740e+00, 1.1563e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1156286.6250,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:42 | [trpo_pendulum] epoch #206 | Saving snapshot...\n",
      "2022-08-23 10:40:42 | [trpo_pendulum] epoch #206 | Saved\n",
      "2022-08-23 10:40:42 | [trpo_pendulum] epoch #206 | Time 203.34 s\n",
      "2022-08-23 10:40:42 | [trpo_pendulum] epoch #206 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000782802\n",
      "Evaluation/AverageReturn                 -0.00791334\n",
      "Evaluation/Iteration                    206\n",
      "Evaluation/MaxReturn                     -0.00774754\n",
      "Evaluation/MinReturn                     -0.00807914\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000165799\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.63169\n",
      "GaussianMLPPolicy/KL                      0.000145886\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000159124\n",
      "GaussianMLPPolicy/LossBefore              0.000159337\n",
      "GaussianMLPPolicy/dLoss                   2.12414e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.07373\n",
      "GaussianMLPValueFunction/LossBefore      -5.98865\n",
      "GaussianMLPValueFunction/dLoss            0.0850849\n",
      "TotalEnvSteps                        413586\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.1620e-05,  7.5087e-05, -1.1489e-06,  ...,  1.2164e-03,\n",
      "        -5.0197e-04,  1.3837e-03])\n",
      "G is: \n",
      "tensor([[2.2858e-05, 6.6484e+00],\n",
      "        [6.6484e+00, 1.9338e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [1933762.,       0.]])\n",
      "loss before is:\n",
      "tensor(8.3806e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(8.3421e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:43 | [trpo_pendulum] epoch #207 | Saving snapshot...\n",
      "2022-08-23 10:40:43 | [trpo_pendulum] epoch #207 | Saved\n",
      "2022-08-23 10:40:43 | [trpo_pendulum] epoch #207 | Time 204.46 s\n",
      "2022-08-23 10:40:43 | [trpo_pendulum] epoch #207 | EpochTime 1.12 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000791645\n",
      "Evaluation/AverageReturn                 -0.00803277\n",
      "Evaluation/Iteration                    207\n",
      "Evaluation/MaxReturn                     -0.00802243\n",
      "Evaluation/MinReturn                     -0.00804311\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.03391e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.64233\n",
      "GaussianMLPPolicy/KL                      0.000310827\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               8.34206e-05\n",
      "GaussianMLPPolicy/LossBefore              8.38059e-05\n",
      "GaussianMLPPolicy/dLoss                   3.85233e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.1148\n",
      "GaussianMLPValueFunction/LossBefore      -6.24269\n",
      "GaussianMLPValueFunction/dLoss           -0.127891\n",
      "TotalEnvSteps                        415584\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.1925e-06, -7.3871e-06,  4.2489e-07,  ..., -1.3608e-04,\n",
      "         5.6165e-05, -1.5513e-04])\n",
      "G is: \n",
      "tensor([[2.8599e-07, 8.4876e-02],\n",
      "        [8.4876e-02, 2.5195e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [25194.5898,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:44 | [trpo_pendulum] epoch #208 | Saving snapshot...\n",
      "2022-08-23 10:40:44 | [trpo_pendulum] epoch #208 | Saved\n",
      "2022-08-23 10:40:44 | [trpo_pendulum] epoch #208 | Time 205.43 s\n",
      "2022-08-23 10:40:44 | [trpo_pendulum] epoch #208 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000705205\n",
      "Evaluation/AverageReturn                 -0.00736566\n",
      "Evaluation/Iteration                    208\n",
      "Evaluation/MaxReturn                     -0.0071446\n",
      "Evaluation/MinReturn                     -0.00758672\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000221063\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.64233\n",
      "GaussianMLPPolicy/KL                      9.5093e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000283151\n",
      "GaussianMLPPolicy/LossBefore             -0.00028315\n",
      "GaussianMLPPolicy/dLoss                   1.39698e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.36956\n",
      "GaussianMLPValueFunction/LossBefore      -5.63764\n",
      "GaussianMLPValueFunction/dLoss            0.731915\n",
      "TotalEnvSteps                        417582\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-3.3625e-06,  1.1627e-04,  3.7962e-08,  ...,  1.9996e-03,\n",
      "        -8.2152e-04,  2.2732e-03])\n",
      "G is: \n",
      "tensor([[6.1648e-05, 1.8301e+01],\n",
      "        [1.8301e+01, 5.4328e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [5432806.,       0.]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:45 | [trpo_pendulum] epoch #209 | Saving snapshot...\n",
      "2022-08-23 10:40:45 | [trpo_pendulum] epoch #209 | Saved\n",
      "2022-08-23 10:40:45 | [trpo_pendulum] epoch #209 | Time 206.43 s\n",
      "2022-08-23 10:40:45 | [trpo_pendulum] epoch #209 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000801497\n",
      "Evaluation/AverageReturn                 -0.00734153\n",
      "Evaluation/Iteration                    209\n",
      "Evaluation/MaxReturn                     -0.00720554\n",
      "Evaluation/MinReturn                     -0.00747753\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000135994\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.64233\n",
      "GaussianMLPPolicy/KL                      0.000203531\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000107462\n",
      "GaussianMLPPolicy/LossBefore             -0.00010717\n",
      "GaussianMLPPolicy/dLoss                   2.91555e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.98271\n",
      "GaussianMLPValueFunction/LossBefore      -6.31424\n",
      "GaussianMLPValueFunction/dLoss           -0.331524\n",
      "TotalEnvSteps                        419580\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.0746e-06,  3.4782e-05, -1.9730e-07,  ...,  6.0088e-04,\n",
      "        -2.4703e-04,  6.8329e-04])\n",
      "G is: \n",
      "tensor([[5.5677e-06, 1.6528e+00],\n",
      "        [1.6528e+00, 4.9066e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [490664.8438,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:46 | [trpo_pendulum] epoch #210 | Saving snapshot...\n",
      "2022-08-23 10:40:46 | [trpo_pendulum] epoch #210 | Saved\n",
      "2022-08-23 10:40:46 | [trpo_pendulum] epoch #210 | Time 207.41 s\n",
      "2022-08-23 10:40:46 | [trpo_pendulum] epoch #210 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00067771\n",
      "Evaluation/AverageReturn                 -0.00707896\n",
      "Evaluation/Iteration                    210\n",
      "Evaluation/MaxReturn                     -0.00702659\n",
      "Evaluation/MinReturn                     -0.00713132\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.23639e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.64233\n",
      "GaussianMLPPolicy/KL                      1.87191e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000191499\n",
      "GaussianMLPPolicy/LossBefore             -0.000191472\n",
      "GaussianMLPPolicy/dLoss                   2.65718e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.17027\n",
      "GaussianMLPValueFunction/LossBefore      -6.06518\n",
      "GaussianMLPValueFunction/dLoss            0.105087\n",
      "TotalEnvSteps                        421578\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-2.3371e-06,  3.6394e-04, -1.8453e-07,  ...,  6.5860e-03,\n",
      "        -2.6959e-03,  7.4956e-03])\n",
      "G is: \n",
      "tensor([[6.6879e-04, 1.9848e+02],\n",
      "        [1.9848e+02, 5.8902e+07]])\n",
      "eig is:\n",
      "tensor([[       0.,        0.],\n",
      "        [58902232.,        0.]])\n",
      "loss before is:\n",
      "tensor(0.0007, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0007, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:47 | [trpo_pendulum] epoch #211 | Saving snapshot...\n",
      "2022-08-23 10:40:47 | [trpo_pendulum] epoch #211 | Saved\n",
      "2022-08-23 10:40:47 | [trpo_pendulum] epoch #211 | Time 208.39 s\n",
      "2022-08-23 10:40:47 | [trpo_pendulum] epoch #211 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000777398\n",
      "Evaluation/AverageReturn                 -0.00889079\n",
      "Evaluation/Iteration                    211\n",
      "Evaluation/MaxReturn                     -0.00867894\n",
      "Evaluation/MinReturn                     -0.00910265\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000211857\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.64226\n",
      "GaussianMLPPolicy/KL                      0.0018961\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000659548\n",
      "GaussianMLPPolicy/LossBefore              0.000662538\n",
      "GaussianMLPPolicy/dLoss                   2.99036e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.39715\n",
      "GaussianMLPValueFunction/LossBefore      -0.387176\n",
      "GaussianMLPValueFunction/dLoss            5.00997\n",
      "TotalEnvSteps                        423576\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.9387e-05,  1.5406e-04, -5.1582e-07,  ...,  2.6416e-03,\n",
      "        -1.0860e-03,  3.0034e-03])\n",
      "G is: \n",
      "tensor([[1.0760e-04, 3.1934e+01],\n",
      "        [3.1934e+01, 9.4778e+06]])\n",
      "eig is:\n",
      "tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [9.4778e+06, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0006, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0006, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:48 | [trpo_pendulum] epoch #212 | Saving snapshot...\n",
      "2022-08-23 10:40:48 | [trpo_pendulum] epoch #212 | Saved\n",
      "2022-08-23 10:40:48 | [trpo_pendulum] epoch #212 | Time 209.39 s\n",
      "2022-08-23 10:40:48 | [trpo_pendulum] epoch #212 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000634235\n",
      "Evaluation/AverageReturn                 -0.00666216\n",
      "Evaluation/Iteration                    212\n",
      "Evaluation/MaxReturn                     -0.00662086\n",
      "Evaluation/MinReturn                     -0.00670346\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.13018e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.6261\n",
      "GaussianMLPPolicy/KL                      0.000430975\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000586748\n",
      "GaussianMLPPolicy/LossBefore             -0.000585961\n",
      "GaussianMLPPolicy/dLoss                   7.86735e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.40907\n",
      "GaussianMLPValueFunction/LossBefore      -3.14406\n",
      "GaussianMLPValueFunction/dLoss            3.26501\n",
      "TotalEnvSteps                        425574\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-3.4120e-06, -1.3600e-05, -1.0966e-06,  ...,  7.4960e-05,\n",
      "        -2.2999e-05,  9.2769e-05])\n",
      "G is: \n",
      "tensor([[9.4310e-08, 2.5181e-02],\n",
      "        [2.5181e-02, 7.2314e+03]])\n",
      "eig is:\n",
      "tensor([[   0.0000,    0.0000],\n",
      "        [7231.4287,    0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:49 | [trpo_pendulum] epoch #213 | Saving snapshot...\n",
      "2022-08-23 10:40:49 | [trpo_pendulum] epoch #213 | Saved\n",
      "2022-08-23 10:40:49 | [trpo_pendulum] epoch #213 | Time 210.37 s\n",
      "2022-08-23 10:40:49 | [trpo_pendulum] epoch #213 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000822312\n",
      "Evaluation/AverageReturn                 -0.00821846\n",
      "Evaluation/Iteration                    213\n",
      "Evaluation/MaxReturn                     -0.00804871\n",
      "Evaluation/MinReturn                     -0.0083882\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000169745\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.62458\n",
      "GaussianMLPPolicy/KL                      0.000240932\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000368528\n",
      "GaussianMLPPolicy/LossBefore              0.000368876\n",
      "GaussianMLPPolicy/dLoss                   3.4814e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.77182\n",
      "GaussianMLPValueFunction/LossBefore      -4.38123\n",
      "GaussianMLPValueFunction/dLoss            1.39059\n",
      "TotalEnvSteps                        427572\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.3661e-06,  1.0188e-05, -1.4066e-07,  ...,  1.7132e-04,\n",
      "        -7.0830e-05,  1.9452e-04])\n",
      "G is: \n",
      "tensor([[4.5196e-07, 1.2936e-01],\n",
      "        [1.2936e-01, 3.7027e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [37026.6094,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:50 | [trpo_pendulum] epoch #214 | Saving snapshot...\n",
      "2022-08-23 10:40:50 | [trpo_pendulum] epoch #214 | Saved\n",
      "2022-08-23 10:40:50 | [trpo_pendulum] epoch #214 | Time 211.35 s\n",
      "2022-08-23 10:40:50 | [trpo_pendulum] epoch #214 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000682712\n",
      "Evaluation/AverageReturn                 -0.00674425\n",
      "Evaluation/Iteration                    214\n",
      "Evaluation/MaxReturn                     -0.00661765\n",
      "Evaluation/MinReturn                     -0.00687086\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000126602\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.62458\n",
      "GaussianMLPPolicy/KL                      1.57469e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000319406\n",
      "GaussianMLPPolicy/LossBefore             -0.000319403\n",
      "GaussianMLPPolicy/dLoss                   2.21189e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.38281\n",
      "GaussianMLPValueFunction/LossBefore      -5.45884\n",
      "GaussianMLPValueFunction/dLoss            0.923976\n",
      "TotalEnvSteps                        429570\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.4627e-06,  3.3426e-05, -1.3905e-07,  ...,  6.3487e-04,\n",
      "        -2.5976e-04,  7.2234e-04])\n",
      "G is: \n",
      "tensor([[6.2060e-06, 1.7764e+00],\n",
      "        [1.7764e+00, 5.0848e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [508483.1250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(3.4204e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(3.4173e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:51 | [trpo_pendulum] epoch #215 | Saving snapshot...\n",
      "2022-08-23 10:40:51 | [trpo_pendulum] epoch #215 | Saved\n",
      "2022-08-23 10:40:51 | [trpo_pendulum] epoch #215 | Time 212.34 s\n",
      "2022-08-23 10:40:51 | [trpo_pendulum] epoch #215 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000637125\n",
      "Evaluation/AverageReturn                 -0.00640969\n",
      "Evaluation/Iteration                    215\n",
      "Evaluation/MaxReturn                     -0.0060674\n",
      "Evaluation/MinReturn                     -0.00675198\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000342291\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.62458\n",
      "GaussianMLPPolicy/KL                      2.16573e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               3.4173e-05\n",
      "GaussianMLPPolicy/LossBefore              3.42036e-05\n",
      "GaussianMLPPolicy/dLoss                   3.06027e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.42737\n",
      "GaussianMLPValueFunction/LossBefore      -6.39513\n",
      "GaussianMLPValueFunction/dLoss            0.0322495\n",
      "TotalEnvSteps                        431568\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.6271e-06,  6.2842e-05, -6.5778e-08,  ...,  1.1274e-03,\n",
      "        -4.6286e-04,  1.2812e-03])\n",
      "G is: \n",
      "tensor([[1.9566e-05, 5.6011e+00],\n",
      "        [5.6011e+00, 1.6034e+06]])\n",
      "eig is:\n",
      "tensor([[-1.2500e-01,  0.0000e+00],\n",
      "        [ 1.6034e+06,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-2.8160e-06, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-2.9119e-06, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:51 | [trpo_pendulum] epoch #216 | Saving snapshot...\n",
      "2022-08-23 10:40:51 | [trpo_pendulum] epoch #216 | Saved\n",
      "2022-08-23 10:40:51 | [trpo_pendulum] epoch #216 | Time 213.27 s\n",
      "2022-08-23 10:40:51 | [trpo_pendulum] epoch #216 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000561968\n",
      "Evaluation/AverageReturn                 -0.00638908\n",
      "Evaluation/Iteration                    216\n",
      "Evaluation/MaxReturn                     -0.00631994\n",
      "Evaluation/MinReturn                     -0.00645822\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.91399e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.62458\n",
      "GaussianMLPPolicy/KL                      6.79167e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -2.91193e-06\n",
      "GaussianMLPPolicy/LossBefore             -2.81603e-06\n",
      "GaussianMLPPolicy/dLoss                   9.59019e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.23866\n",
      "GaussianMLPValueFunction/LossBefore      -6.43812\n",
      "GaussianMLPValueFunction/dLoss           -0.199459\n",
      "TotalEnvSteps                        433566\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-3.1880e-06,  1.9680e-05,  2.1382e-07,  ...,  4.0598e-04,\n",
      "        -1.6486e-04,  4.6243e-04])\n",
      "G is: \n",
      "tensor([[2.5377e-06, 7.2637e-01],\n",
      "        [7.2637e-01, 2.0793e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [207927.1250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:52 | [trpo_pendulum] epoch #217 | Saving snapshot...\n",
      "2022-08-23 10:40:52 | [trpo_pendulum] epoch #217 | Saved\n",
      "2022-08-23 10:40:52 | [trpo_pendulum] epoch #217 | Time 214.24 s\n",
      "2022-08-23 10:40:52 | [trpo_pendulum] epoch #217 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00063726\n",
      "Evaluation/AverageReturn                 -0.00664098\n",
      "Evaluation/Iteration                    217\n",
      "Evaluation/MaxReturn                     -0.00644915\n",
      "Evaluation/MinReturn                     -0.0068328\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000191825\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.62414\n",
      "GaussianMLPPolicy/KL                      2.40266e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000256376\n",
      "GaussianMLPPolicy/LossBefore              0.000256411\n",
      "GaussianMLPPolicy/dLoss                   3.45462e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.13347\n",
      "GaussianMLPValueFunction/LossBefore      -5.71148\n",
      "GaussianMLPValueFunction/dLoss            0.421987\n",
      "TotalEnvSteps                        435564\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.2435e-06,  7.2380e-05, -2.2947e-07,  ...,  1.3618e-03,\n",
      "        -5.5728e-04,  1.5492e-03])\n",
      "G is: \n",
      "tensor([[2.8552e-05, 8.1651e+00],\n",
      "        [8.1651e+00, 2.3350e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [2335041.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:53 | [trpo_pendulum] epoch #218 | Saving snapshot...\n",
      "2022-08-23 10:40:53 | [trpo_pendulum] epoch #218 | Saved\n",
      "2022-08-23 10:40:53 | [trpo_pendulum] epoch #218 | Time 215.21 s\n",
      "2022-08-23 10:40:53 | [trpo_pendulum] epoch #218 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000662232\n",
      "Evaluation/AverageReturn                 -0.00660176\n",
      "Evaluation/Iteration                    218\n",
      "Evaluation/MaxReturn                     -0.00637841\n",
      "Evaluation/MinReturn                     -0.00682511\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000223354\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.62383\n",
      "GaussianMLPPolicy/KL                      0.000123055\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000215801\n",
      "GaussianMLPPolicy/LossBefore             -0.000215625\n",
      "GaussianMLPPolicy/dLoss                   1.75773e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.38351\n",
      "GaussianMLPValueFunction/LossBefore      -5.95585\n",
      "GaussianMLPValueFunction/dLoss            0.427661\n",
      "TotalEnvSteps                        437562\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.0728e-05,  3.1099e-05, -2.8745e-09,  ...,  5.5974e-04,\n",
      "        -2.2960e-04,  6.3625e-04])\n",
      "G is: \n",
      "tensor([[4.8229e-06, 1.3783e+00],\n",
      "        [1.3783e+00, 3.9390e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [393895.4375,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:54 | [trpo_pendulum] epoch #219 | Saving snapshot...\n",
      "2022-08-23 10:40:54 | [trpo_pendulum] epoch #219 | Saved\n",
      "2022-08-23 10:40:54 | [trpo_pendulum] epoch #219 | Time 216.18 s\n",
      "2022-08-23 10:40:54 | [trpo_pendulum] epoch #219 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000684692\n",
      "Evaluation/AverageReturn                 -0.00632558\n",
      "Evaluation/Iteration                    219\n",
      "Evaluation/MaxReturn                     -0.00627591\n",
      "Evaluation/MinReturn                     -0.00637524\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.96691e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.63144\n",
      "GaussianMLPPolicy/KL                      7.51083e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000149835\n",
      "GaussianMLPPolicy/LossBefore             -0.000149729\n",
      "GaussianMLPPolicy/dLoss                   1.05443e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.08823\n",
      "GaussianMLPValueFunction/LossBefore      -6.21874\n",
      "GaussianMLPValueFunction/dLoss           -0.130508\n",
      "TotalEnvSteps                        439560\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.2219e-05, -7.5505e-05, -3.3192e-07,  ..., -1.3459e-03,\n",
      "         5.5194e-04, -1.5295e-03])\n",
      "G is: \n",
      "tensor([[2.7879e-05, 8.0895e+00],\n",
      "        [8.0895e+00, 2.3473e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [2347258.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:55 | [trpo_pendulum] epoch #220 | Saving snapshot...\n",
      "2022-08-23 10:40:55 | [trpo_pendulum] epoch #220 | Saved\n",
      "2022-08-23 10:40:55 | [trpo_pendulum] epoch #220 | Time 217.15 s\n",
      "2022-08-23 10:40:55 | [trpo_pendulum] epoch #220 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000617032\n",
      "Evaluation/AverageReturn                 -0.00644542\n",
      "Evaluation/Iteration                    220\n",
      "Evaluation/MaxReturn                     -0.00629885\n",
      "Evaluation/MinReturn                     -0.00659198\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000146567\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.64052\n",
      "GaussianMLPPolicy/KL                      0.000196995\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000323783\n",
      "GaussianMLPPolicy/LossBefore              0.000324055\n",
      "GaussianMLPPolicy/dLoss                   2.7183e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.2676\n",
      "GaussianMLPValueFunction/LossBefore      -5.21285\n",
      "GaussianMLPValueFunction/dLoss            1.05475\n",
      "TotalEnvSteps                        441558\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.2605e-06,  2.7172e-06, -2.4925e-08,  ...,  6.8165e-05,\n",
      "        -2.7457e-05,  7.7889e-05])\n",
      "G is: \n",
      "tensor([[7.1583e-08, 2.1141e-02],\n",
      "        [2.1141e-02, 6.2461e+03]])\n",
      "eig is:\n",
      "tensor([[   0.0000,    0.0000],\n",
      "        [6246.0918,    0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:56 | [trpo_pendulum] epoch #221 | Saving snapshot...\n",
      "2022-08-23 10:40:56 | [trpo_pendulum] epoch #221 | Saved\n",
      "2022-08-23 10:40:56 | [trpo_pendulum] epoch #221 | Time 218.10 s\n",
      "2022-08-23 10:40:56 | [trpo_pendulum] epoch #221 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000662837\n",
      "Evaluation/AverageReturn                 -0.00633241\n",
      "Evaluation/Iteration                    221\n",
      "Evaluation/MaxReturn                     -0.006223\n",
      "Evaluation/MinReturn                     -0.00644182\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000109409\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.64052\n",
      "GaussianMLPPolicy/KL                      2.39403e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000210945\n",
      "GaussianMLPPolicy/LossBefore             -0.000210945\n",
      "GaussianMLPPolicy/dLoss                   2.18279e-10\n",
      "GaussianMLPValueFunction/LossAfter       -6.45622\n",
      "GaussianMLPValueFunction/LossBefore      -5.98063\n",
      "GaussianMLPValueFunction/dLoss            0.475585\n",
      "TotalEnvSteps                        443556\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.8264e-06,  6.8835e-05, -1.2778e-07,  ...,  1.2813e-03,\n",
      "        -5.2473e-04,  1.4570e-03])\n",
      "G is: \n",
      "tensor([[2.5265e-05, 7.4636e+00],\n",
      "        [7.4636e+00, 2.2049e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [2204880.,       0.]])\n",
      "loss before is:\n",
      "tensor(-4.9448e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-4.9568e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:57 | [trpo_pendulum] epoch #222 | Saving snapshot...\n",
      "2022-08-23 10:40:57 | [trpo_pendulum] epoch #222 | Saved\n",
      "2022-08-23 10:40:57 | [trpo_pendulum] epoch #222 | Time 219.05 s\n",
      "2022-08-23 10:40:57 | [trpo_pendulum] epoch #222 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000583233\n",
      "Evaluation/AverageReturn                 -0.00640595\n",
      "Evaluation/Iteration                    222\n",
      "Evaluation/MaxReturn                     -0.00602447\n",
      "Evaluation/MinReturn                     -0.00678743\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00038148\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.64052\n",
      "GaussianMLPPolicy/KL                      8.47992e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.95679e-05\n",
      "GaussianMLPPolicy/LossBefore             -4.94476e-05\n",
      "GaussianMLPPolicy/dLoss                   1.20279e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.24596\n",
      "GaussianMLPValueFunction/LossBefore      -6.47906\n",
      "GaussianMLPValueFunction/dLoss           -0.233104\n",
      "TotalEnvSteps                        445554\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.4414e-06,  4.2038e-05, -1.1451e-07,  ...,  7.8005e-04,\n",
      "        -3.1959e-04,  8.8699e-04])\n",
      "G is: \n",
      "tensor([[9.3645e-06, 2.7666e+00],\n",
      "        [2.7666e+00, 8.1735e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [817352.6250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:58 | [trpo_pendulum] epoch #223 | Saving snapshot...\n",
      "2022-08-23 10:40:58 | [trpo_pendulum] epoch #223 | Saved\n",
      "2022-08-23 10:40:58 | [trpo_pendulum] epoch #223 | Time 220.08 s\n",
      "2022-08-23 10:40:58 | [trpo_pendulum] epoch #223 | EpochTime 1.03 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000629407\n",
      "Evaluation/AverageReturn                 -0.00596474\n",
      "Evaluation/Iteration                    223\n",
      "Evaluation/MaxReturn                     -0.00588423\n",
      "Evaluation/MinReturn                     -0.00604525\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.05081e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.64052\n",
      "GaussianMLPPolicy/KL                      3.16317e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000207951\n",
      "GaussianMLPPolicy/LossBefore             -0.000207906\n",
      "GaussianMLPPolicy/dLoss                   4.43979e-08\n",
      "GaussianMLPValueFunction/LossAfter       -5.60204\n",
      "GaussianMLPValueFunction/LossBefore      -6.0064\n",
      "GaussianMLPValueFunction/dLoss           -0.404363\n",
      "TotalEnvSteps                        447552\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.2452e-06,  1.9330e-05, -1.8101e-07,  ...,  4.7193e-04,\n",
      "        -1.9036e-04,  5.3908e-04])\n",
      "G is: \n",
      "tensor([[3.4307e-06, 1.0133e+00],\n",
      "        [1.0133e+00, 2.9937e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [299369.0938,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:40:59 | [trpo_pendulum] epoch #224 | Saving snapshot...\n",
      "2022-08-23 10:40:59 | [trpo_pendulum] epoch #224 | Saved\n",
      "2022-08-23 10:40:59 | [trpo_pendulum] epoch #224 | Time 221.05 s\n",
      "2022-08-23 10:40:59 | [trpo_pendulum] epoch #224 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000701233\n",
      "Evaluation/AverageReturn                 -0.00644424\n",
      "Evaluation/Iteration                    224\n",
      "Evaluation/MaxReturn                     -0.00601498\n",
      "Evaluation/MinReturn                     -0.0068735\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000429262\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.64156\n",
      "GaussianMLPPolicy/KL                      0.000115497\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000186534\n",
      "GaussianMLPPolicy/LossBefore             -0.000186369\n",
      "GaussianMLPPolicy/dLoss                   1.64859e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.14158\n",
      "GaussianMLPValueFunction/LossBefore      -6.05401\n",
      "GaussianMLPValueFunction/dLoss            0.0875683\n",
      "TotalEnvSteps                        449550\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.1653e-05, -7.4828e-05, -3.6388e-07,  ..., -1.0797e-03,\n",
      "         4.4984e-04, -1.2215e-03])\n",
      "G is: \n",
      "tensor([[1.7931e-05, 5.3059e+00],\n",
      "        [5.3059e+00, 1.5705e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [1570518.,       0.]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:00 | [trpo_pendulum] epoch #225 | Saving snapshot...\n",
      "2022-08-23 10:41:00 | [trpo_pendulum] epoch #225 | Saved\n",
      "2022-08-23 10:41:00 | [trpo_pendulum] epoch #225 | Time 221.99 s\n",
      "2022-08-23 10:41:00 | [trpo_pendulum] epoch #225 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00064165\n",
      "Evaluation/AverageReturn                 -0.00651582\n",
      "Evaluation/Iteration                    225\n",
      "Evaluation/MaxReturn                     -0.00650105\n",
      "Evaluation/MinReturn                     -0.00653058\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.47647e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.65673\n",
      "GaussianMLPPolicy/KL                      0.000590681\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000232083\n",
      "GaussianMLPPolicy/LossBefore              0.000232904\n",
      "GaussianMLPPolicy/dLoss                   8.2035e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.18729\n",
      "GaussianMLPValueFunction/LossBefore      -5.75036\n",
      "GaussianMLPValueFunction/dLoss            0.436926\n",
      "TotalEnvSteps                        451548\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.9469e-06,  5.7043e-05,  2.5768e-08,  ...,  1.0346e-03,\n",
      "        -4.2392e-04,  1.1762e-03])\n",
      "G is: \n",
      "tensor([[1.6466e-05, 5.0221e+00],\n",
      "        [5.0221e+00, 1.5318e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [1531805.,       0.]])\n",
      "loss before is:\n",
      "tensor(-1.0755e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-1.0831e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:01 | [trpo_pendulum] epoch #226 | Saving snapshot...\n",
      "2022-08-23 10:41:01 | [trpo_pendulum] epoch #226 | Saved\n",
      "2022-08-23 10:41:01 | [trpo_pendulum] epoch #226 | Time 222.94 s\n",
      "2022-08-23 10:41:01 | [trpo_pendulum] epoch #226 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000612791\n",
      "Evaluation/AverageReturn                 -0.00586288\n",
      "Evaluation/Iteration                    226\n",
      "Evaluation/MaxReturn                     -0.00582556\n",
      "Evaluation/MinReturn                     -0.00590021\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.73249e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.65673\n",
      "GaussianMLPPolicy/KL                      5.37325e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -1.08312e-05\n",
      "GaussianMLPPolicy/LossBefore             -1.07553e-05\n",
      "GaussianMLPPolicy/dLoss                   7.58928e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.54741\n",
      "GaussianMLPValueFunction/LossBefore      -6.55911\n",
      "GaussianMLPValueFunction/dLoss           -0.011704\n",
      "TotalEnvSteps                        453546\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.0878e-06,  6.2620e-05, -6.6036e-09,  ...,  1.1766e-03,\n",
      "        -4.8099e-04,  1.3385e-03])\n",
      "G is: \n",
      "tensor([[2.1297e-05, 6.4955e+00],\n",
      "        [6.4955e+00, 1.9811e+06]])\n",
      "eig is:\n",
      "tensor([[-1.2500e-01,  0.0000e+00],\n",
      "        [ 1.9811e+06,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(8.4224e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(8.4058e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:02 | [trpo_pendulum] epoch #227 | Saving snapshot...\n",
      "2022-08-23 10:41:02 | [trpo_pendulum] epoch #227 | Saved\n",
      "2022-08-23 10:41:02 | [trpo_pendulum] epoch #227 | Time 223.92 s\n",
      "2022-08-23 10:41:02 | [trpo_pendulum] epoch #227 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000657992\n",
      "Evaluation/AverageReturn                 -0.00617598\n",
      "Evaluation/Iteration                    227\n",
      "Evaluation/MaxReturn                     -0.00606853\n",
      "Evaluation/MinReturn                     -0.00628342\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000107446\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.66021\n",
      "GaussianMLPPolicy/KL                      0.000113461\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               8.4058e-05\n",
      "GaussianMLPPolicy/LossBefore              8.42238e-05\n",
      "GaussianMLPPolicy/dLoss                   1.65805e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.49563\n",
      "GaussianMLPValueFunction/LossBefore      -6.48125\n",
      "GaussianMLPValueFunction/dLoss            0.0143771\n",
      "TotalEnvSteps                        455544\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.6442e-06,  5.8028e-05, -1.4703e-07,  ...,  1.0125e-03,\n",
      "        -4.1589e-04,  1.1506e-03])\n",
      "G is: \n",
      "tensor([[1.5769e-05, 4.8422e+00],\n",
      "        [4.8422e+00, 1.4869e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1486859.7500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(9.7720e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(9.7647e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:03 | [trpo_pendulum] epoch #228 | Saving snapshot...\n",
      "2022-08-23 10:41:03 | [trpo_pendulum] epoch #228 | Saved\n",
      "2022-08-23 10:41:03 | [trpo_pendulum] epoch #228 | Time 224.89 s\n",
      "2022-08-23 10:41:03 | [trpo_pendulum] epoch #228 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000577166\n",
      "Evaluation/AverageReturn                 -0.00602152\n",
      "Evaluation/Iteration                    228\n",
      "Evaluation/MaxReturn                     -0.00601626\n",
      "Evaluation/MinReturn                     -0.00602678\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.26242e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.66021\n",
      "GaussianMLPPolicy/KL                      5.10464e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               9.76475e-05\n",
      "GaussianMLPPolicy/LossBefore              9.77196e-05\n",
      "GaussianMLPPolicy/dLoss                   7.21557e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.12495\n",
      "GaussianMLPValueFunction/LossBefore      -6.4504\n",
      "GaussianMLPValueFunction/dLoss           -0.32545\n",
      "TotalEnvSteps                        457542\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.3519e-06,  3.2100e-05,  8.8501e-08,  ...,  5.8540e-04,\n",
      "        -2.3952e-04,  6.6566e-04])\n",
      "G is: \n",
      "tensor([[5.2710e-06, 1.6186e+00],\n",
      "        [1.6186e+00, 4.9707e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [497065.7812,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:04 | [trpo_pendulum] epoch #229 | Saving snapshot...\n",
      "2022-08-23 10:41:04 | [trpo_pendulum] epoch #229 | Saved\n",
      "2022-08-23 10:41:04 | [trpo_pendulum] epoch #229 | Time 225.89 s\n",
      "2022-08-23 10:41:04 | [trpo_pendulum] epoch #229 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000616536\n",
      "Evaluation/AverageReturn                 -0.00580059\n",
      "Evaluation/Iteration                    229\n",
      "Evaluation/MaxReturn                     -0.00569391\n",
      "Evaluation/MinReturn                     -0.00590727\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000106681\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.66021\n",
      "GaussianMLPPolicy/KL                      1.71477e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000234233\n",
      "GaussianMLPPolicy/LossBefore             -0.000234209\n",
      "GaussianMLPPolicy/dLoss                   2.41416e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.49716\n",
      "GaussianMLPValueFunction/LossBefore      -5.82586\n",
      "GaussianMLPValueFunction/dLoss            0.671299\n",
      "TotalEnvSteps                        459540\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.0003e-05,  1.2660e-04,  1.0909e-06,  ...,  2.3266e-03,\n",
      "        -9.5033e-04,  2.6458e-03])\n",
      "G is: \n",
      "tensor([[8.3244e-05, 2.5561e+01],\n",
      "        [2.5561e+01, 7.8489e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [7848916.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:05 | [trpo_pendulum] epoch #230 | Saving snapshot...\n",
      "2022-08-23 10:41:05 | [trpo_pendulum] epoch #230 | Saved\n",
      "2022-08-23 10:41:05 | [trpo_pendulum] epoch #230 | Time 226.90 s\n",
      "2022-08-23 10:41:05 | [trpo_pendulum] epoch #230 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000629469\n",
      "Evaluation/AverageReturn                 -0.00634888\n",
      "Evaluation/Iteration                    230\n",
      "Evaluation/MaxReturn                     -0.00618714\n",
      "Evaluation/MinReturn                     -0.00651062\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000161741\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.6675\n",
      "GaussianMLPPolicy/KL                      0.000317792\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000116129\n",
      "GaussianMLPPolicy/LossBefore              0.000116661\n",
      "GaussianMLPPolicy/dLoss                   5.32105e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.14506\n",
      "GaussianMLPValueFunction/LossBefore      -6.15914\n",
      "GaussianMLPValueFunction/dLoss           -0.01408\n",
      "TotalEnvSteps                        461538\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.2975e-06,  8.9941e-05, -8.1216e-09,  ...,  1.5570e-03,\n",
      "        -6.3864e-04,  1.7704e-03])\n",
      "G is: \n",
      "tensor([[3.7325e-05, 1.1637e+01],\n",
      "        [1.1637e+01, 3.6279e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [3627851.2500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-6.7193e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-6.7360e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:06 | [trpo_pendulum] epoch #231 | Saving snapshot...\n",
      "2022-08-23 10:41:06 | [trpo_pendulum] epoch #231 | Saved\n",
      "2022-08-23 10:41:06 | [trpo_pendulum] epoch #231 | Time 227.87 s\n",
      "2022-08-23 10:41:06 | [trpo_pendulum] epoch #231 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000589996\n",
      "Evaluation/AverageReturn                 -0.00536285\n",
      "Evaluation/Iteration                    231\n",
      "Evaluation/MaxReturn                     -0.00530593\n",
      "Evaluation/MinReturn                     -0.00541977\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.69203e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.6675\n",
      "GaussianMLPPolicy/KL                      0.000118351\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.73602e-05\n",
      "GaussianMLPPolicy/LossBefore             -6.71929e-05\n",
      "GaussianMLPPolicy/dLoss                   1.67252e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.39104\n",
      "GaussianMLPValueFunction/LossBefore      -6.50799\n",
      "GaussianMLPValueFunction/dLoss           -0.116952\n",
      "TotalEnvSteps                        463536\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.0458e-05,  3.7291e-05,  8.2455e-09,  ...,  6.4837e-04,\n",
      "        -2.6586e-04,  7.3728e-04])\n",
      "G is: \n",
      "tensor([[6.4725e-06, 2.0179e+00],\n",
      "        [2.0179e+00, 6.2909e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [629092.6250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:07 | [trpo_pendulum] epoch #232 | Saving snapshot...\n",
      "2022-08-23 10:41:07 | [trpo_pendulum] epoch #232 | Saved\n",
      "2022-08-23 10:41:07 | [trpo_pendulum] epoch #232 | Time 228.92 s\n",
      "2022-08-23 10:41:07 | [trpo_pendulum] epoch #232 | EpochTime 1.05 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00053958\n",
      "Evaluation/AverageReturn                 -0.00558722\n",
      "Evaluation/Iteration                    232\n",
      "Evaluation/MaxReturn                     -0.00557834\n",
      "Evaluation/MinReturn                     -0.0055961\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.87945e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.67487\n",
      "GaussianMLPPolicy/KL                      7.53837e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000101867\n",
      "GaussianMLPPolicy/LossBefore              0.000101971\n",
      "GaussianMLPPolicy/dLoss                   1.04905e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.37307\n",
      "GaussianMLPValueFunction/LossBefore      -6.46682\n",
      "GaussianMLPValueFunction/dLoss           -0.0937538\n",
      "TotalEnvSteps                        465534\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.9286e-06, -1.3944e-05, -1.6577e-07,  ..., -2.6132e-04,\n",
      "         1.0643e-04, -2.9746e-04])\n",
      "G is: \n",
      "tensor([[1.0513e-06, 3.3261e-01],\n",
      "        [3.3261e-01, 1.0524e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [105238.5000,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:08 | [trpo_pendulum] epoch #233 | Saving snapshot...\n",
      "2022-08-23 10:41:08 | [trpo_pendulum] epoch #233 | Saved\n",
      "2022-08-23 10:41:08 | [trpo_pendulum] epoch #233 | Time 229.87 s\n",
      "2022-08-23 10:41:08 | [trpo_pendulum] epoch #233 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000484249\n",
      "Evaluation/AverageReturn                 -0.00517824\n",
      "Evaluation/Iteration                    233\n",
      "Evaluation/MaxReturn                     -0.0049837\n",
      "Evaluation/MinReturn                     -0.00537277\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000194538\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.67487\n",
      "GaussianMLPPolicy/KL                      3.30152e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000129372\n",
      "GaussianMLPPolicy/LossBefore              0.000129377\n",
      "GaussianMLPPolicy/dLoss                   4.68572e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.62096\n",
      "GaussianMLPValueFunction/LossBefore      -6.38789\n",
      "GaussianMLPValueFunction/dLoss            0.233069\n",
      "TotalEnvSteps                        467532\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.2854e-06,  3.8303e-05,  8.2337e-09,  ...,  6.6850e-04,\n",
      "        -2.7404e-04,  7.6024e-04])\n",
      "G is: \n",
      "tensor([[6.8809e-06, 2.1771e+00],\n",
      "        [2.1771e+00, 6.8881e+05]])\n",
      "eig is:\n",
      "tensor([[6.2500e-02, 0.0000e+00],\n",
      "        [6.8881e+05, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-3.4467e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-3.4498e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:09 | [trpo_pendulum] epoch #234 | Saving snapshot...\n",
      "2022-08-23 10:41:09 | [trpo_pendulum] epoch #234 | Saved\n",
      "2022-08-23 10:41:09 | [trpo_pendulum] epoch #234 | Time 230.86 s\n",
      "2022-08-23 10:41:09 | [trpo_pendulum] epoch #234 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000564163\n",
      "Evaluation/AverageReturn                 -0.00543403\n",
      "Evaluation/Iteration                    234\n",
      "Evaluation/MaxReturn                     -0.00539066\n",
      "Evaluation/MinReturn                     -0.00547739\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.33612e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.67487\n",
      "GaussianMLPPolicy/KL                      2.16385e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.44977e-05\n",
      "GaussianMLPPolicy/LossBefore             -3.4467e-05\n",
      "GaussianMLPPolicy/dLoss                   3.065e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.4556\n",
      "GaussianMLPValueFunction/LossBefore      -6.61768\n",
      "GaussianMLPValueFunction/dLoss           -0.162079\n",
      "TotalEnvSteps                        469530\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.8269e-05, -9.6826e-05, -7.0609e-07,  ..., -5.7117e-04,\n",
      "         2.6435e-04, -6.2629e-04])\n",
      "G is: \n",
      "tensor([[5.0822e-06, 1.5826e+00],\n",
      "        [1.5826e+00, 5.0061e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [500613.5625,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:10 | [trpo_pendulum] epoch #235 | Saving snapshot...\n",
      "2022-08-23 10:41:10 | [trpo_pendulum] epoch #235 | Saved\n",
      "2022-08-23 10:41:10 | [trpo_pendulum] epoch #235 | Time 231.84 s\n",
      "2022-08-23 10:41:10 | [trpo_pendulum] epoch #235 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000592589\n",
      "Evaluation/AverageReturn                 -0.0064641\n",
      "Evaluation/Iteration                    235\n",
      "Evaluation/MaxReturn                     -0.00634372\n",
      "Evaluation/MinReturn                     -0.00658447\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000120373\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.69179\n",
      "GaussianMLPPolicy/KL                      0.00203231\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000445405\n",
      "GaussianMLPPolicy/LossBefore              0.000448384\n",
      "GaussianMLPPolicy/dLoss                   2.97945e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.65545\n",
      "GaussianMLPValueFunction/LossBefore      -2.79498\n",
      "GaussianMLPValueFunction/dLoss            2.86046\n",
      "TotalEnvSteps                        471528\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-5.5808e-06,  2.1804e-05,  2.4638e-08,  ...,  3.8091e-04,\n",
      "        -1.5603e-04,  4.3320e-04])\n",
      "G is: \n",
      "tensor([[2.2327e-06, 7.3031e-01],\n",
      "        [7.3031e-01, 2.3888e+05]])\n",
      "eig is:\n",
      "tensor([[-1.5625e-02,  0.0000e+00],\n",
      "        [ 2.3888e+05,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:11 | [trpo_pendulum] epoch #236 | Saving snapshot...\n",
      "2022-08-23 10:41:11 | [trpo_pendulum] epoch #236 | Saved\n",
      "2022-08-23 10:41:11 | [trpo_pendulum] epoch #236 | Time 232.78 s\n",
      "2022-08-23 10:41:11 | [trpo_pendulum] epoch #236 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000543279\n",
      "Evaluation/AverageReturn                 -0.00552095\n",
      "Evaluation/Iteration                    236\n",
      "Evaluation/MaxReturn                     -0.0054555\n",
      "Evaluation/MinReturn                     -0.0055864\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.54533e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.69179\n",
      "GaussianMLPPolicy/KL                      6.8233e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000163058\n",
      "GaussianMLPPolicy/LossBefore             -0.000163048\n",
      "GaussianMLPPolicy/dLoss                   9.77889e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.60424\n",
      "GaussianMLPValueFunction/LossBefore      -6.2269\n",
      "GaussianMLPValueFunction/dLoss            0.377338\n",
      "TotalEnvSteps                        473526\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.5533e-05, -2.0959e-04, -2.4168e-06,  ..., -3.1717e-03,\n",
      "         1.3094e-03, -3.5971e-03])\n",
      "G is: \n",
      "tensor([[1.5472e-04, 5.0595e+01],\n",
      "        [5.0595e+01, 1.6547e+07]])\n",
      "eig is:\n",
      "tensor([[-1.0000e+00,  0.0000e+00],\n",
      "        [ 1.6547e+07,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:12 | [trpo_pendulum] epoch #237 | Saving snapshot...\n",
      "2022-08-23 10:41:12 | [trpo_pendulum] epoch #237 | Saved\n",
      "2022-08-23 10:41:12 | [trpo_pendulum] epoch #237 | Time 233.72 s\n",
      "2022-08-23 10:41:12 | [trpo_pendulum] epoch #237 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000586613\n",
      "Evaluation/AverageReturn                 -0.0060861\n",
      "Evaluation/Iteration                    237\n",
      "Evaluation/MaxReturn                     -0.00592849\n",
      "Evaluation/MinReturn                     -0.00624371\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000157612\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.70449\n",
      "GaussianMLPPolicy/KL                      0.00155017\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000306361\n",
      "GaussianMLPPolicy/LossBefore              0.000308381\n",
      "GaussianMLPPolicy/dLoss                   2.02004e-06\n",
      "GaussianMLPValueFunction/LossAfter       -6.04185\n",
      "GaussianMLPValueFunction/LossBefore      -4.68246\n",
      "GaussianMLPValueFunction/dLoss            1.35939\n",
      "TotalEnvSteps                        475524\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.7281e-05, -5.1021e-05,  3.2826e-07,  ..., -5.6695e-04,\n",
      "         2.4221e-04, -6.3794e-04])\n",
      "G is: \n",
      "tensor([[4.9429e-06, 1.6543e+00],\n",
      "        [1.6543e+00, 5.5453e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [554525.7500,      0.0000]])\n",
      "loss before is:\n",
      "tensor(1.5814e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(1.5275e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:13 | [trpo_pendulum] epoch #238 | Saving snapshot...\n",
      "2022-08-23 10:41:13 | [trpo_pendulum] epoch #238 | Saved\n",
      "2022-08-23 10:41:13 | [trpo_pendulum] epoch #238 | Time 234.69 s\n",
      "2022-08-23 10:41:13 | [trpo_pendulum] epoch #238 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000565695\n",
      "Evaluation/AverageReturn                 -0.00590812\n",
      "Evaluation/Iteration                    238\n",
      "Evaluation/MaxReturn                     -0.0058208\n",
      "Evaluation/MinReturn                     -0.00599545\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.73238e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.71615\n",
      "GaussianMLPPolicy/KL                      0.000390918\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               1.5275e-05\n",
      "GaussianMLPPolicy/LossBefore              1.58144e-05\n",
      "GaussianMLPPolicy/dLoss                   5.39418e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.97177\n",
      "GaussianMLPValueFunction/LossBefore      -6.16412\n",
      "GaussianMLPValueFunction/dLoss           -0.192348\n",
      "TotalEnvSteps                        477522\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.3805e-05,  4.5241e-06,  1.1682e-08,  ...,  1.0714e-04,\n",
      "        -4.3112e-05,  1.2235e-04])\n",
      "G is: \n",
      "tensor([[1.7679e-07, 6.0591e-02],\n",
      "        [6.0591e-02, 2.0794e+04]])\n",
      "eig is:\n",
      "tensor([[-1.9531e-03,  0.0000e+00],\n",
      "        [ 2.0794e+04,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-0.0004, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0004, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:14 | [trpo_pendulum] epoch #239 | Saving snapshot...\n",
      "2022-08-23 10:41:14 | [trpo_pendulum] epoch #239 | Saved\n",
      "2022-08-23 10:41:14 | [trpo_pendulum] epoch #239 | Time 235.69 s\n",
      "2022-08-23 10:41:14 | [trpo_pendulum] epoch #239 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000572073\n",
      "Evaluation/AverageReturn                 -0.00552707\n",
      "Evaluation/Iteration                    239\n",
      "Evaluation/MaxReturn                     -0.00541666\n",
      "Evaluation/MinReturn                     -0.00563747\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000110404\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.70526\n",
      "GaussianMLPPolicy/KL                      0.000130348\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00038901\n",
      "GaussianMLPPolicy/LossBefore             -0.00038882\n",
      "GaussianMLPPolicy/dLoss                   1.89757e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.56048\n",
      "GaussianMLPValueFunction/LossBefore      -4.65209\n",
      "GaussianMLPValueFunction/dLoss            1.90839\n",
      "TotalEnvSteps                        479520\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.9850e-06,  3.3545e-05,  2.5966e-09,  ...,  6.1201e-04,\n",
      "        -2.4992e-04,  6.9642e-04])\n",
      "G is: \n",
      "tensor([[5.7589e-06, 1.9333e+00],\n",
      "        [1.9333e+00, 6.4906e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [649058.3750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(4.4002e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(4.3978e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:15 | [trpo_pendulum] epoch #240 | Saving snapshot...\n",
      "2022-08-23 10:41:15 | [trpo_pendulum] epoch #240 | Saved\n",
      "2022-08-23 10:41:15 | [trpo_pendulum] epoch #240 | Time 236.70 s\n",
      "2022-08-23 10:41:15 | [trpo_pendulum] epoch #240 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000592698\n",
      "Evaluation/AverageReturn                 -0.00533867\n",
      "Evaluation/Iteration                    240\n",
      "Evaluation/MaxReturn                     -0.00516539\n",
      "Evaluation/MinReturn                     -0.00551196\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000173284\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.70526\n",
      "GaussianMLPPolicy/KL                      1.71529e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               4.39779e-05\n",
      "GaussianMLPPolicy/LossBefore              4.40021e-05\n",
      "GaussianMLPPolicy/dLoss                   2.41489e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.30656\n",
      "GaussianMLPValueFunction/LossBefore      -6.55237\n",
      "GaussianMLPValueFunction/dLoss           -0.245807\n",
      "TotalEnvSteps                        481518\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-2.5502e-06,  1.0581e-04,  1.3041e-07,  ...,  1.8569e-03,\n",
      "        -7.6009e-04,  2.1116e-03])\n",
      "G is: \n",
      "tensor([[5.3011e-05, 1.7797e+01],\n",
      "        [1.7797e+01, 5.9749e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [5974926.,       0.]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:16 | [trpo_pendulum] epoch #241 | Saving snapshot...\n",
      "2022-08-23 10:41:16 | [trpo_pendulum] epoch #241 | Saved\n",
      "2022-08-23 10:41:16 | [trpo_pendulum] epoch #241 | Time 237.68 s\n",
      "2022-08-23 10:41:16 | [trpo_pendulum] epoch #241 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000592656\n",
      "Evaluation/AverageReturn                 -0.00548444\n",
      "Evaluation/Iteration                    241\n",
      "Evaluation/MaxReturn                     -0.00528611\n",
      "Evaluation/MinReturn                     -0.00568276\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000198325\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.70526\n",
      "GaussianMLPPolicy/KL                      0.000155463\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000147903\n",
      "GaussianMLPPolicy/LossBefore             -0.000147681\n",
      "GaussianMLPPolicy/dLoss                   2.21989e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.562\n",
      "GaussianMLPValueFunction/LossBefore      -6.28988\n",
      "GaussianMLPValueFunction/dLoss            0.272125\n",
      "TotalEnvSteps                        483516\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.2018e-05,  7.6716e-05, -2.8894e-07,  ...,  1.3646e-03,\n",
      "        -5.5851e-04,  1.5524e-03])\n",
      "G is: \n",
      "tensor([[2.8633e-05, 9.6120e+00],\n",
      "        [9.6120e+00, 3.2268e+06]])\n",
      "eig is:\n",
      "tensor([[-2.5000e-01,  0.0000e+00],\n",
      "        [ 3.2268e+06,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:17 | [trpo_pendulum] epoch #242 | Saving snapshot...\n",
      "2022-08-23 10:41:17 | [trpo_pendulum] epoch #242 | Saved\n",
      "2022-08-23 10:41:17 | [trpo_pendulum] epoch #242 | Time 238.68 s\n",
      "2022-08-23 10:41:17 | [trpo_pendulum] epoch #242 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000536212\n",
      "Evaluation/AverageReturn                 -0.00582076\n",
      "Evaluation/Iteration                    242\n",
      "Evaluation/MaxReturn                     -0.00578542\n",
      "Evaluation/MinReturn                     -0.0058561\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.53434e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.69694\n",
      "GaussianMLPPolicy/KL                      0.000159256\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000141122\n",
      "GaussianMLPPolicy/LossBefore              0.000141357\n",
      "GaussianMLPPolicy/dLoss                   2.34621e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.28597\n",
      "GaussianMLPValueFunction/LossBefore      -6.0584\n",
      "GaussianMLPValueFunction/dLoss            0.227571\n",
      "TotalEnvSteps                        485514\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.8136e-10,  3.0823e-05, -3.0313e-07,  ...,  5.4937e-04,\n",
      "        -2.2511e-04,  6.2496e-04])\n",
      "G is: \n",
      "tensor([[4.6403e-06, 1.5320e+00],\n",
      "        [1.5320e+00, 5.0583e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [505828.5625,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:18 | [trpo_pendulum] epoch #243 | Saving snapshot...\n",
      "2022-08-23 10:41:18 | [trpo_pendulum] epoch #243 | Saved\n",
      "2022-08-23 10:41:18 | [trpo_pendulum] epoch #243 | Time 239.63 s\n",
      "2022-08-23 10:41:18 | [trpo_pendulum] epoch #243 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000572642\n",
      "Evaluation/AverageReturn                 -0.00559332\n",
      "Evaluation/Iteration                    243\n",
      "Evaluation/MaxReturn                     -0.00537232\n",
      "Evaluation/MinReturn                     -0.00581432\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000221004\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.69694\n",
      "GaussianMLPPolicy/KL                      1.40028e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000116119\n",
      "GaussianMLPPolicy/LossBefore             -0.000116099\n",
      "GaussianMLPPolicy/dLoss                   1.97761e-08\n",
      "GaussianMLPValueFunction/LossAfter       -5.02991\n",
      "GaussianMLPValueFunction/LossBefore      -6.39759\n",
      "GaussianMLPValueFunction/dLoss           -1.36767\n",
      "TotalEnvSteps                        487512\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-3.1612e-06, -1.5530e-06,  4.7941e-08,  ...,  1.3377e-05,\n",
      "        -4.2978e-06,  1.5971e-05])\n",
      "G is: \n",
      "tensor([[2.8802e-09, 9.1253e-04],\n",
      "        [9.1253e-04, 3.0129e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [301.2878,   0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0004, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0004, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:19 | [trpo_pendulum] epoch #244 | Saving snapshot...\n",
      "2022-08-23 10:41:19 | [trpo_pendulum] epoch #244 | Saved\n",
      "2022-08-23 10:41:19 | [trpo_pendulum] epoch #244 | Time 240.56 s\n",
      "2022-08-23 10:41:19 | [trpo_pendulum] epoch #244 | EpochTime 0.92 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000552107\n",
      "Evaluation/AverageReturn                 -0.00539118\n",
      "Evaluation/Iteration                    244\n",
      "Evaluation/MaxReturn                     -0.00522765\n",
      "Evaluation/MinReturn                     -0.00555471\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000163532\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.69033\n",
      "GaussianMLPPolicy/KL                      0.000395791\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000356808\n",
      "GaussianMLPPolicy/LossBefore             -0.00035656\n",
      "GaussianMLPPolicy/dLoss                   2.47441e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.4083\n",
      "GaussianMLPValueFunction/LossBefore      -4.79607\n",
      "GaussianMLPValueFunction/dLoss            1.61223\n",
      "TotalEnvSteps                        489510\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.8707e-06,  1.2222e-05, -2.3227e-07,  ...,  1.7971e-04,\n",
      "        -7.4525e-05,  2.0408e-04])\n",
      "G is: \n",
      "tensor([[4.9681e-07, 1.6172e-01],\n",
      "        [1.6172e-01, 5.2661e+04]])\n",
      "eig is:\n",
      "tensor([[3.9062e-03, 0.0000e+00],\n",
      "        [5.2661e+04, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-8.9619e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-8.9693e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:20 | [trpo_pendulum] epoch #245 | Saving snapshot...\n",
      "2022-08-23 10:41:20 | [trpo_pendulum] epoch #245 | Saved\n",
      "2022-08-23 10:41:20 | [trpo_pendulum] epoch #245 | Time 241.61 s\n",
      "2022-08-23 10:41:20 | [trpo_pendulum] epoch #245 | EpochTime 1.04 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000521687\n",
      "Evaluation/AverageReturn                 -0.00529059\n",
      "Evaluation/Iteration                    245\n",
      "Evaluation/MaxReturn                     -0.00521858\n",
      "Evaluation/MinReturn                     -0.0053626\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.20074e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.6949\n",
      "GaussianMLPPolicy/KL                      5.19681e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -8.96926e-05\n",
      "GaussianMLPPolicy/LossBefore             -8.96191e-05\n",
      "GaussianMLPPolicy/dLoss                   7.35163e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.57489\n",
      "GaussianMLPValueFunction/LossBefore      -6.48961\n",
      "GaussianMLPValueFunction/dLoss            0.0852795\n",
      "TotalEnvSteps                        491508\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.0065e-06,  1.5237e-06,  9.1257e-08,  ...,  8.4753e-05,\n",
      "        -3.2978e-05,  9.7441e-05])\n",
      "G is: \n",
      "tensor([[1.1076e-07, 3.6317e-02],\n",
      "        [3.6317e-02, 1.1935e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [11935.4268,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-7.6870e-06, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-7.7251e-06, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:21 | [trpo_pendulum] epoch #246 | Saving snapshot...\n",
      "2022-08-23 10:41:21 | [trpo_pendulum] epoch #246 | Saved\n",
      "2022-08-23 10:41:21 | [trpo_pendulum] epoch #246 | Time 242.61 s\n",
      "2022-08-23 10:41:21 | [trpo_pendulum] epoch #246 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000544051\n",
      "Evaluation/AverageReturn                 -0.0058151\n",
      "Evaluation/Iteration                    246\n",
      "Evaluation/MaxReturn                     -0.00578546\n",
      "Evaluation/MinReturn                     -0.00584474\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.96428e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.6955\n",
      "GaussianMLPPolicy/KL                      2.70783e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.7251e-06\n",
      "GaussianMLPPolicy/LossBefore             -7.68703e-06\n",
      "GaussianMLPPolicy/dLoss                   3.80733e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.55848\n",
      "GaussianMLPValueFunction/LossBefore      -6.59706\n",
      "GaussianMLPValueFunction/dLoss           -0.0385799\n",
      "TotalEnvSteps                        493506\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.3382e-06,  5.3986e-05, -9.6048e-08,  ...,  7.4021e-04,\n",
      "        -3.0763e-04,  8.3903e-04])\n",
      "G is: \n",
      "tensor([[8.4208e-06, 2.7699e+00],\n",
      "        [2.7699e+00, 9.1132e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [911319.6250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(2.6260e-06, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(2.4550e-06, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:22 | [trpo_pendulum] epoch #247 | Saving snapshot...\n",
      "2022-08-23 10:41:22 | [trpo_pendulum] epoch #247 | Saved\n",
      "2022-08-23 10:41:22 | [trpo_pendulum] epoch #247 | Time 243.57 s\n",
      "2022-08-23 10:41:22 | [trpo_pendulum] epoch #247 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000548825\n",
      "Evaluation/AverageReturn                 -0.0057325\n",
      "Evaluation/Iteration                    247\n",
      "Evaluation/MaxReturn                     -0.00567211\n",
      "Evaluation/MinReturn                     -0.00579289\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.03893e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.6956\n",
      "GaussianMLPPolicy/KL                      0.000118171\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               2.45503e-06\n",
      "GaussianMLPPolicy/LossBefore              2.62597e-06\n",
      "GaussianMLPPolicy/dLoss                   1.70942e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.27825\n",
      "GaussianMLPValueFunction/LossBefore      -6.52385\n",
      "GaussianMLPValueFunction/dLoss           -0.245599\n",
      "TotalEnvSteps                        495504\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.7311e-06,  4.3137e-05, -5.2314e-08,  ...,  7.2267e-04,\n",
      "        -2.9617e-04,  8.2180e-04])\n",
      "G is: \n",
      "tensor([[8.0282e-06, 2.6422e+00],\n",
      "        [2.6422e+00, 8.6960e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [869595.7500,      0.0000]])\n",
      "loss before is:\n",
      "tensor(1.3889e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(1.3788e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:23 | [trpo_pendulum] epoch #248 | Saving snapshot...\n",
      "2022-08-23 10:41:23 | [trpo_pendulum] epoch #248 | Saved\n",
      "2022-08-23 10:41:23 | [trpo_pendulum] epoch #248 | Time 244.53 s\n",
      "2022-08-23 10:41:23 | [trpo_pendulum] epoch #248 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000521799\n",
      "Evaluation/AverageReturn                 -0.00528508\n",
      "Evaluation/Iteration                    248\n",
      "Evaluation/MaxReturn                     -0.00512956\n",
      "Evaluation/MinReturn                     -0.00544061\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000155527\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.70218\n",
      "GaussianMLPPolicy/KL                      7.16299e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               1.37876e-05\n",
      "GaussianMLPPolicy/LossBefore              1.38888e-05\n",
      "GaussianMLPPolicy/dLoss                   1.01222e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.61753\n",
      "GaussianMLPValueFunction/LossBefore      -6.60979\n",
      "GaussianMLPValueFunction/dLoss            0.00773764\n",
      "TotalEnvSteps                        497502\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.6813e-06,  5.5334e-05, -1.9003e-09,  ...,  9.4416e-04,\n",
      "        -3.8650e-04,  1.0738e-03])\n",
      "G is: \n",
      "tensor([[1.3702e-05, 4.5694e+00],\n",
      "        [4.5694e+00, 1.5238e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [1523843.,       0.]])\n",
      "loss before is:\n",
      "tensor(-5.9577e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-5.9635e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:24 | [trpo_pendulum] epoch #249 | Saving snapshot...\n",
      "2022-08-23 10:41:24 | [trpo_pendulum] epoch #249 | Saved\n",
      "2022-08-23 10:41:24 | [trpo_pendulum] epoch #249 | Time 245.51 s\n",
      "2022-08-23 10:41:24 | [trpo_pendulum] epoch #249 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000511941\n",
      "Evaluation/AverageReturn                 -0.00501634\n",
      "Evaluation/Iteration                    249\n",
      "Evaluation/MaxReturn                     -0.00489075\n",
      "Evaluation/MinReturn                     -0.00514193\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000125589\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.70218\n",
      "GaussianMLPPolicy/KL                      4.08767e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.96347e-05\n",
      "GaussianMLPPolicy/LossBefore             -5.95771e-05\n",
      "GaussianMLPPolicy/dLoss                   5.75965e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.65245\n",
      "GaussianMLPValueFunction/LossBefore      -6.58232\n",
      "GaussianMLPValueFunction/dLoss            0.0701232\n",
      "TotalEnvSteps                        499500\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.9173e-07,  1.4512e-05, -3.8535e-07,  ...,  2.1455e-04,\n",
      "        -8.9242e-05,  2.4353e-04])\n",
      "G is: \n",
      "tensor([[7.0810e-07, 2.3606e-01],\n",
      "        [2.3606e-01, 7.8708e+04]])\n",
      "eig is:\n",
      "tensor([[-7.8125e-03,  0.0000e+00],\n",
      "        [ 7.8708e+04,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:25 | [trpo_pendulum] epoch #250 | Saving snapshot...\n",
      "2022-08-23 10:41:25 | [trpo_pendulum] epoch #250 | Saved\n",
      "2022-08-23 10:41:25 | [trpo_pendulum] epoch #250 | Time 246.47 s\n",
      "2022-08-23 10:41:25 | [trpo_pendulum] epoch #250 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000548209\n",
      "Evaluation/AverageReturn                 -0.00537582\n",
      "Evaluation/Iteration                    250\n",
      "Evaluation/MaxReturn                     -0.00534371\n",
      "Evaluation/MinReturn                     -0.00540793\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.21085e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.70221\n",
      "GaussianMLPPolicy/KL                      1.02147e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000121386\n",
      "GaussianMLPPolicy/LossBefore              0.0001214\n",
      "GaussianMLPPolicy/dLoss                   1.44719e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.47459\n",
      "GaussianMLPValueFunction/LossBefore      -6.32195\n",
      "GaussianMLPValueFunction/dLoss            0.152635\n",
      "TotalEnvSteps                        501498\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-6.9303e-06,  3.0026e-05, -2.2142e-07,  ...,  5.4633e-04,\n",
      "        -2.2301e-04,  6.2205e-04])\n",
      "G is: \n",
      "tensor([[4.5890e-06, 1.5304e+00],\n",
      "        [1.5304e+00, 5.1042e+05]])\n",
      "eig is:\n",
      "tensor([[-3.1250e-02,  0.0000e+00],\n",
      "        [ 5.1042e+05,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:26 | [trpo_pendulum] epoch #251 | Saving snapshot...\n",
      "2022-08-23 10:41:26 | [trpo_pendulum] epoch #251 | Saved\n",
      "2022-08-23 10:41:26 | [trpo_pendulum] epoch #251 | Time 247.45 s\n",
      "2022-08-23 10:41:26 | [trpo_pendulum] epoch #251 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000516468\n",
      "Evaluation/AverageReturn                 -0.00528792\n",
      "Evaluation/Iteration                    251\n",
      "Evaluation/MaxReturn                     -0.00513652\n",
      "Evaluation/MinReturn                     -0.00543932\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000151399\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.69913\n",
      "GaussianMLPPolicy/KL                      5.08605e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000160535\n",
      "GaussianMLPPolicy/LossBefore             -0.000160462\n",
      "GaussianMLPPolicy/dLoss                   7.36472e-08\n",
      "GaussianMLPValueFunction/LossAfter       -5.53989\n",
      "GaussianMLPValueFunction/LossBefore      -6.24856\n",
      "GaussianMLPValueFunction/dLoss           -0.708668\n",
      "TotalEnvSteps                        503496\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-4.0200e-06,  5.2553e-05,  8.6386e-08,  ...,  9.3760e-04,\n",
      "        -3.8252e-04,  1.0671e-03])\n",
      "G is: \n",
      "tensor([[1.3512e-05, 4.4778e+00],\n",
      "        [4.4778e+00, 1.4840e+06]])\n",
      "eig is:\n",
      "tensor([[-1.2500e-01,  0.0000e+00],\n",
      "        [ 1.4840e+06,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:27 | [trpo_pendulum] epoch #252 | Saving snapshot...\n",
      "2022-08-23 10:41:27 | [trpo_pendulum] epoch #252 | Saved\n",
      "2022-08-23 10:41:27 | [trpo_pendulum] epoch #252 | Time 248.44 s\n",
      "2022-08-23 10:41:27 | [trpo_pendulum] epoch #252 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000511164\n",
      "Evaluation/AverageReturn                 -0.00539481\n",
      "Evaluation/Iteration                    252\n",
      "Evaluation/MaxReturn                     -0.00516591\n",
      "Evaluation/MinReturn                     -0.0056237\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000228897\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.69344\n",
      "GaussianMLPPolicy/KL                      0.000140954\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000286736\n",
      "GaussianMLPPolicy/LossBefore             -0.000286568\n",
      "GaussianMLPPolicy/dLoss                   1.6822e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.52744\n",
      "GaussianMLPValueFunction/LossBefore      -5.36372\n",
      "GaussianMLPValueFunction/dLoss            1.16372\n",
      "TotalEnvSteps                        505494\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.5783e-06,  3.9583e-05,  1.2667e-08,  ...,  6.6588e-04,\n",
      "        -2.7211e-04,  7.5784e-04])\n",
      "G is: \n",
      "tensor([[6.8170e-06, 2.2329e+00],\n",
      "        [2.2329e+00, 7.3137e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [731366.6250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:28 | [trpo_pendulum] epoch #253 | Saving snapshot...\n",
      "2022-08-23 10:41:28 | [trpo_pendulum] epoch #253 | Saved\n",
      "2022-08-23 10:41:28 | [trpo_pendulum] epoch #253 | Time 249.40 s\n",
      "2022-08-23 10:41:28 | [trpo_pendulum] epoch #253 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000497264\n",
      "Evaluation/AverageReturn                 -0.0050786\n",
      "Evaluation/Iteration                    253\n",
      "Evaluation/MaxReturn                     -0.00498193\n",
      "Evaluation/MinReturn                     -0.00517528\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      9.6674e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.69344\n",
      "GaussianMLPPolicy/KL                      2.071e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.0001054\n",
      "GaussianMLPPolicy/LossBefore              0.000105429\n",
      "GaussianMLPPolicy/dLoss                   2.93439e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.55749\n",
      "GaussianMLPValueFunction/LossBefore      -6.48513\n",
      "GaussianMLPValueFunction/dLoss            0.0723562\n",
      "TotalEnvSteps                        507492\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.1507e-05,  5.5926e-05, -1.5756e-06,  ...,  9.8383e-04,\n",
      "        -4.0242e-04,  1.1215e-03])\n",
      "G is: \n",
      "tensor([[1.4892e-05, 4.8761e+00],\n",
      "        [4.8761e+00, 1.5968e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [1596844.,       0.]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:29 | [trpo_pendulum] epoch #254 | Saving snapshot...\n",
      "2022-08-23 10:41:29 | [trpo_pendulum] epoch #254 | Saved\n",
      "2022-08-23 10:41:29 | [trpo_pendulum] epoch #254 | Time 250.36 s\n",
      "2022-08-23 10:41:29 | [trpo_pendulum] epoch #254 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000571173\n",
      "Evaluation/AverageReturn                 -0.00620408\n",
      "Evaluation/Iteration                    254\n",
      "Evaluation/MaxReturn                     -0.00619619\n",
      "Evaluation/MinReturn                     -0.00621198\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.89657e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.72143\n",
      "GaussianMLPPolicy/KL                      0.000954213\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000237997\n",
      "GaussianMLPPolicy/LossBefore              0.000239336\n",
      "GaussianMLPPolicy/dLoss                   1.33947e-06\n",
      "GaussianMLPValueFunction/LossAfter       -5.97187\n",
      "GaussianMLPValueFunction/LossBefore      -4.93072\n",
      "GaussianMLPValueFunction/dLoss            1.04114\n",
      "TotalEnvSteps                        509490\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.6690e-05,  1.4086e-04, -1.8595e-06,  ...,  2.4322e-03,\n",
      "        -9.9498e-04,  2.7689e-03])\n",
      "G is: \n",
      "tensor([[9.0911e-05, 3.1477e+01],\n",
      "        [3.1477e+01, 1.0899e+07]])\n",
      "eig is:\n",
      "tensor([[       0.,        0.],\n",
      "        [10898670.,        0.]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:29 | [trpo_pendulum] epoch #255 | Saving snapshot...\n",
      "2022-08-23 10:41:30 | [trpo_pendulum] epoch #255 | Saved\n",
      "2022-08-23 10:41:30 | [trpo_pendulum] epoch #255 | Time 251.30 s\n",
      "2022-08-23 10:41:30 | [trpo_pendulum] epoch #255 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000490775\n",
      "Evaluation/AverageReturn                 -0.00506826\n",
      "Evaluation/Iteration                    255\n",
      "Evaluation/MaxReturn                     -0.00506737\n",
      "Evaluation/MinReturn                     -0.00506915\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.94335e-07\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.7315\n",
      "GaussianMLPPolicy/KL                      0.000502926\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000113406\n",
      "GaussianMLPPolicy/LossBefore             -0.000112593\n",
      "GaussianMLPPolicy/dLoss                   8.13532e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.71219\n",
      "GaussianMLPValueFunction/LossBefore      -6.19944\n",
      "GaussianMLPValueFunction/dLoss           -0.487251\n",
      "TotalEnvSteps                        511488\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.6984e-06,  5.6639e-05,  1.5107e-08,  ...,  9.8013e-04,\n",
      "        -4.0051e-04,  1.1146e-03])\n",
      "G is: \n",
      "tensor([[1.4743e-05, 5.2063e+00],\n",
      "        [5.2063e+00, 1.8386e+06]])\n",
      "eig is:\n",
      "tensor([[1.2500e-01, 0.0000e+00],\n",
      "        [1.8386e+06, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(1.9208e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(1.9150e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:30 | [trpo_pendulum] epoch #256 | Saving snapshot...\n",
      "2022-08-23 10:41:31 | [trpo_pendulum] epoch #256 | Saved\n",
      "2022-08-23 10:41:31 | [trpo_pendulum] epoch #256 | Time 252.32 s\n",
      "2022-08-23 10:41:31 | [trpo_pendulum] epoch #256 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000509279\n",
      "Evaluation/AverageReturn                 -0.00477769\n",
      "Evaluation/Iteration                    256\n",
      "Evaluation/MaxReturn                     -0.00463487\n",
      "Evaluation/MinReturn                     -0.00492052\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000142823\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.7315\n",
      "GaussianMLPPolicy/KL                      4.15436e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               1.91495e-05\n",
      "GaussianMLPPolicy/LossBefore              1.92082e-05\n",
      "GaussianMLPPolicy/dLoss                   5.87261e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.61268\n",
      "GaussianMLPValueFunction/LossBefore      -6.62092\n",
      "GaussianMLPValueFunction/dLoss           -0.00824165\n",
      "TotalEnvSteps                        513486\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.3795e-06,  3.2477e-05,  4.1894e-09,  ...,  5.6330e-04,\n",
      "        -2.3015e-04,  6.4059e-04])\n",
      "G is: \n",
      "tensor([[4.8696e-06, 1.7196e+00],\n",
      "        [1.7196e+00, 6.0726e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [607262.8750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-3.7933e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-3.7952e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:31 | [trpo_pendulum] epoch #257 | Saving snapshot...\n",
      "2022-08-23 10:41:31 | [trpo_pendulum] epoch #257 | Saved\n",
      "2022-08-23 10:41:31 | [trpo_pendulum] epoch #257 | Time 253.24 s\n",
      "2022-08-23 10:41:31 | [trpo_pendulum] epoch #257 | EpochTime 0.92 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000479553\n",
      "Evaluation/AverageReturn                 -0.00481385\n",
      "Evaluation/Iteration                    257\n",
      "Evaluation/MaxReturn                     -0.00481171\n",
      "Evaluation/MinReturn                     -0.00481598\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.13317e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.7315\n",
      "GaussianMLPPolicy/KL                      1.37177e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.7952e-05\n",
      "GaussianMLPPolicy/LossBefore             -3.79327e-05\n",
      "GaussianMLPPolicy/dLoss                   1.93359e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.49546\n",
      "GaussianMLPValueFunction/LossBefore      -6.61922\n",
      "GaussianMLPValueFunction/dLoss           -0.12376\n",
      "TotalEnvSteps                        515484\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.0827e-06, -4.9158e-06, -9.4184e-08,  ..., -8.7398e-05,\n",
      "         3.5539e-05, -9.9383e-05])\n",
      "G is: \n",
      "tensor([[1.1720e-07, 4.1383e-02],\n",
      "        [4.1383e-02, 1.4614e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [14614.1631,     0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:33 | [trpo_pendulum] epoch #258 | Saving snapshot...\n",
      "2022-08-23 10:41:33 | [trpo_pendulum] epoch #258 | Saved\n",
      "2022-08-23 10:41:33 | [trpo_pendulum] epoch #258 | Time 254.33 s\n",
      "2022-08-23 10:41:33 | [trpo_pendulum] epoch #258 | EpochTime 1.09 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000469354\n",
      "Evaluation/AverageReturn                 -0.00463938\n",
      "Evaluation/Iteration                    258\n",
      "Evaluation/MaxReturn                     -0.00454395\n",
      "Evaluation/MinReturn                     -0.00473481\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      9.54293e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.7315\n",
      "GaussianMLPPolicy/KL                      3.30481e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000110265\n",
      "GaussianMLPPolicy/LossBefore              0.000110266\n",
      "GaussianMLPPolicy/dLoss                   4.43833e-10\n",
      "GaussianMLPValueFunction/LossAfter       -6.40009\n",
      "GaussianMLPValueFunction/LossBefore      -6.47276\n",
      "GaussianMLPValueFunction/dLoss           -0.0726771\n",
      "TotalEnvSteps                        517482\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.9577e-06,  5.1866e-05, -3.2879e-07,  ...,  5.0990e-04,\n",
      "        -2.1907e-04,  5.7344e-04])\n",
      "G is: \n",
      "tensor([[3.9937e-06, 1.4067e+00],\n",
      "        [1.4067e+00, 4.9672e+05]])\n",
      "eig is:\n",
      "tensor([[3.1250e-02, 0.0000e+00],\n",
      "        [4.9672e+05, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(2.5984e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(2.5479e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:33 | [trpo_pendulum] epoch #259 | Saving snapshot...\n",
      "2022-08-23 10:41:33 | [trpo_pendulum] epoch #259 | Saved\n",
      "2022-08-23 10:41:33 | [trpo_pendulum] epoch #259 | Time 255.30 s\n",
      "2022-08-23 10:41:33 | [trpo_pendulum] epoch #259 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000510022\n",
      "Evaluation/AverageReturn                 -0.00524641\n",
      "Evaluation/Iteration                    259\n",
      "Evaluation/MaxReturn                     -0.00520801\n",
      "Evaluation/MinReturn                     -0.00528481\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.84006e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.7319\n",
      "GaussianMLPPolicy/KL                      0.000348773\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               2.54794e-05\n",
      "GaussianMLPPolicy/LossBefore              2.59835e-05\n",
      "GaussianMLPPolicy/dLoss                   5.0416e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.29543\n",
      "GaussianMLPValueFunction/LossBefore      -6.46807\n",
      "GaussianMLPValueFunction/dLoss           -0.172641\n",
      "TotalEnvSteps                        519480\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.3374e-06,  6.5808e-05,  9.5544e-08,  ...,  1.2142e-03,\n",
      "        -4.9442e-04,  1.3817e-03])\n",
      "G is: \n",
      "tensor([[2.2625e-05, 7.9969e+00],\n",
      "        [7.9969e+00, 2.8266e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [2826558.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:34 | [trpo_pendulum] epoch #260 | Saving snapshot...\n",
      "2022-08-23 10:41:34 | [trpo_pendulum] epoch #260 | Saved\n",
      "2022-08-23 10:41:34 | [trpo_pendulum] epoch #260 | Time 256.25 s\n",
      "2022-08-23 10:41:34 | [trpo_pendulum] epoch #260 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000499251\n",
      "Evaluation/AverageReturn                 -0.00488566\n",
      "Evaluation/Iteration                    260\n",
      "Evaluation/MaxReturn                     -0.00474837\n",
      "Evaluation/MinReturn                     -0.00502296\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000137292\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.73272\n",
      "GaussianMLPPolicy/KL                      8.61848e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000191313\n",
      "GaussianMLPPolicy/LossBefore             -0.000191192\n",
      "GaussianMLPPolicy/dLoss                   1.2177e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.34674\n",
      "GaussianMLPValueFunction/LossBefore      -6.04615\n",
      "GaussianMLPValueFunction/dLoss            0.300591\n",
      "TotalEnvSteps                        521478\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.3308e-05,  1.9747e-06, -1.3149e-07,  ...,  4.3897e-05,\n",
      "        -1.7850e-05,  5.0135e-05])\n",
      "G is: \n",
      "tensor([[2.9806e-08, 1.0486e-02],\n",
      "        [1.0486e-02, 3.7124e+03]])\n",
      "eig is:\n",
      "tensor([[2.4414e-04, 0.0000e+00],\n",
      "        [3.7124e+03, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:35 | [trpo_pendulum] epoch #261 | Saving snapshot...\n",
      "2022-08-23 10:41:35 | [trpo_pendulum] epoch #261 | Saved\n",
      "2022-08-23 10:41:35 | [trpo_pendulum] epoch #261 | Time 257.24 s\n",
      "2022-08-23 10:41:35 | [trpo_pendulum] epoch #261 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00050722\n",
      "Evaluation/AverageReturn                 -0.00482844\n",
      "Evaluation/Iteration                    261\n",
      "Evaluation/MaxReturn                     -0.00482144\n",
      "Evaluation/MinReturn                     -0.00483545\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.00345e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.74185\n",
      "GaussianMLPPolicy/KL                      8.99389e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000183104\n",
      "GaussianMLPPolicy/LossBefore             -0.00018298\n",
      "GaussianMLPPolicy/dLoss                   1.2487e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.65626\n",
      "GaussianMLPValueFunction/LossBefore      -6.12555\n",
      "GaussianMLPValueFunction/dLoss            0.530708\n",
      "TotalEnvSteps                        523476\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.5764e-06,  7.9556e-05,  2.0242e-07,  ...,  1.3605e-03,\n",
      "        -5.5632e-04,  1.5466e-03])\n",
      "G is: \n",
      "tensor([[2.8401e-05, 1.0238e+01],\n",
      "        [1.0238e+01, 3.6906e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [3690591.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(5.0053e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(4.9942e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:36 | [trpo_pendulum] epoch #262 | Saving snapshot...\n",
      "2022-08-23 10:41:36 | [trpo_pendulum] epoch #262 | Saved\n",
      "2022-08-23 10:41:36 | [trpo_pendulum] epoch #262 | Time 258.19 s\n",
      "2022-08-23 10:41:36 | [trpo_pendulum] epoch #262 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000532774\n",
      "Evaluation/AverageReturn                 -0.00505775\n",
      "Evaluation/Iteration                    262\n",
      "Evaluation/MaxReturn                     -0.00496973\n",
      "Evaluation/MinReturn                     -0.00514578\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.80251e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.74185\n",
      "GaussianMLPPolicy/KL                      7.81973e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               4.99419e-05\n",
      "GaussianMLPPolicy/LossBefore              5.00531e-05\n",
      "GaussianMLPPolicy/dLoss                   1.11111e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.29904\n",
      "GaussianMLPValueFunction/LossBefore      -6.57084\n",
      "GaussianMLPValueFunction/dLoss           -0.271798\n",
      "TotalEnvSteps                        525474\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.9398e-06, -4.3066e-05,  5.8334e-07,  ..., -8.2323e-04,\n",
      "         3.3516e-04, -9.3767e-04])\n",
      "G is: \n",
      "tensor([[1.0405e-05, 3.7507e+00],\n",
      "        [3.7507e+00, 1.3520e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1352010.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:37 | [trpo_pendulum] epoch #263 | Saving snapshot...\n",
      "2022-08-23 10:41:37 | [trpo_pendulum] epoch #263 | Saved\n",
      "2022-08-23 10:41:37 | [trpo_pendulum] epoch #263 | Time 259.17 s\n",
      "2022-08-23 10:41:37 | [trpo_pendulum] epoch #263 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000513549\n",
      "Evaluation/AverageReturn                 -0.0051347\n",
      "Evaluation/Iteration                    263\n",
      "Evaluation/MaxReturn                     -0.00500963\n",
      "Evaluation/MinReturn                     -0.00525977\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000125072\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.74202\n",
      "GaussianMLPPolicy/KL                      4.87512e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000110224\n",
      "GaussianMLPPolicy/LossBefore             -0.000110155\n",
      "GaussianMLPPolicy/dLoss                   6.84231e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.52893\n",
      "GaussianMLPValueFunction/LossBefore      -6.37553\n",
      "GaussianMLPValueFunction/dLoss            0.153405\n",
      "TotalEnvSteps                        527472\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.0804e-05,  9.6266e-05, -1.9801e-07,  ...,  1.7808e-03,\n",
      "        -7.2521e-04,  2.0268e-03])\n",
      "G is: \n",
      "tensor([[4.8672e-05, 1.7553e+01],\n",
      "        [1.7553e+01, 6.3305e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [6330541.,       0.]])\n",
      "loss before is:\n",
      "tensor(-3.9311e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-3.9629e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:38 | [trpo_pendulum] epoch #264 | Saving snapshot...\n",
      "2022-08-23 10:41:38 | [trpo_pendulum] epoch #264 | Saved\n",
      "2022-08-23 10:41:38 | [trpo_pendulum] epoch #264 | Time 260.17 s\n",
      "2022-08-23 10:41:38 | [trpo_pendulum] epoch #264 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000497727\n",
      "Evaluation/AverageReturn                 -0.00491529\n",
      "Evaluation/Iteration                    264\n",
      "Evaluation/MaxReturn                     -0.00483205\n",
      "Evaluation/MinReturn                     -0.00499853\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.32395e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.74967\n",
      "GaussianMLPPolicy/KL                      0.000224518\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.96286e-05\n",
      "GaussianMLPPolicy/LossBefore             -3.93109e-05\n",
      "GaussianMLPPolicy/dLoss                   3.17686e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.20096\n",
      "GaussianMLPValueFunction/LossBefore      -6.51318\n",
      "GaussianMLPValueFunction/dLoss           -0.312214\n",
      "TotalEnvSteps                        529470\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-6.3290e-06,  1.2905e-04,  1.8128e-07,  ...,  2.2472e-03,\n",
      "        -9.1809e-04,  2.5551e-03])\n",
      "G is: \n",
      "tensor([[7.7479e-05, 2.8369e+01],\n",
      "        [2.8369e+01, 1.0387e+07]])\n",
      "eig is:\n",
      "tensor([[       0.,        0.],\n",
      "        [10387490.,        0.]])\n",
      "loss before is:\n",
      "tensor(-8.8443e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-8.8741e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:39 | [trpo_pendulum] epoch #265 | Saving snapshot...\n",
      "2022-08-23 10:41:39 | [trpo_pendulum] epoch #265 | Saved\n",
      "2022-08-23 10:41:39 | [trpo_pendulum] epoch #265 | Time 261.20 s\n",
      "2022-08-23 10:41:39 | [trpo_pendulum] epoch #265 | EpochTime 1.02 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000492866\n",
      "Evaluation/AverageReturn                 -0.00480354\n",
      "Evaluation/Iteration                    265\n",
      "Evaluation/MaxReturn                     -0.0047259\n",
      "Evaluation/MinReturn                     -0.00488118\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.76406e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.74967\n",
      "GaussianMLPPolicy/KL                      0.000207239\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -8.87406e-05\n",
      "GaussianMLPPolicy/LossBefore             -8.84431e-05\n",
      "GaussianMLPPolicy/dLoss                   2.97507e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.35911\n",
      "GaussianMLPValueFunction/LossBefore      -6.27826\n",
      "GaussianMLPValueFunction/dLoss            0.0808492\n",
      "TotalEnvSteps                        531468\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.6593e-06,  4.0818e-05, -1.0862e-06,  ...,  7.5520e-04,\n",
      "        -3.0881e-04,  8.5995e-04])\n",
      "G is: \n",
      "tensor([[8.7580e-06, 3.2071e+00],\n",
      "        [3.2071e+00, 1.1744e+06]])\n",
      "eig is:\n",
      "tensor([[-1.2500e-01,  0.0000e+00],\n",
      "        [ 1.1744e+06,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:40 | [trpo_pendulum] epoch #266 | Saving snapshot...\n",
      "2022-08-23 10:41:40 | [trpo_pendulum] epoch #266 | Saved\n",
      "2022-08-23 10:41:40 | [trpo_pendulum] epoch #266 | Time 262.18 s\n",
      "2022-08-23 10:41:40 | [trpo_pendulum] epoch #266 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000448262\n",
      "Evaluation/AverageReturn                 -0.00445988\n",
      "Evaluation/Iteration                    266\n",
      "Evaluation/MaxReturn                     -0.00439696\n",
      "Evaluation/MinReturn                     -0.0045228\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.2918e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.76038\n",
      "GaussianMLPPolicy/KL                      0.00071981\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000205503\n",
      "GaussianMLPPolicy/LossBefore             -0.000205078\n",
      "GaussianMLPPolicy/dLoss                   4.248e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.04813\n",
      "GaussianMLPValueFunction/LossBefore      -6.00381\n",
      "GaussianMLPValueFunction/dLoss           -0.955685\n",
      "TotalEnvSteps                        533466\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.9824e-06,  4.5692e-05, -2.9509e-07,  ...,  1.1107e-03,\n",
      "        -4.4637e-04,  1.2667e-03])\n",
      "G is: \n",
      "tensor([[1.8916e-05, 7.0706e+00],\n",
      "        [7.0706e+00, 2.6434e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [2643374.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:41 | [trpo_pendulum] epoch #267 | Saving snapshot...\n",
      "2022-08-23 10:41:41 | [trpo_pendulum] epoch #267 | Saved\n",
      "2022-08-23 10:41:41 | [trpo_pendulum] epoch #267 | Time 263.14 s\n",
      "2022-08-23 10:41:41 | [trpo_pendulum] epoch #267 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000451497\n",
      "Evaluation/AverageReturn                 -0.00471458\n",
      "Evaluation/Iteration                    267\n",
      "Evaluation/MaxReturn                     -0.00469926\n",
      "Evaluation/MinReturn                     -0.00472991\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.53255e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.76772\n",
      "GaussianMLPPolicy/KL                      0.000293299\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000394896\n",
      "GaussianMLPPolicy/LossBefore              0.000395307\n",
      "GaussianMLPPolicy/dLoss                   4.1051e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.33702\n",
      "GaussianMLPValueFunction/LossBefore      -4.1429\n",
      "GaussianMLPValueFunction/dLoss            1.19412\n",
      "TotalEnvSteps                        535464\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.8191e-06,  1.8413e-05,  1.1126e-07,  ...,  3.3537e-04,\n",
      "        -1.3674e-04,  3.8097e-04])\n",
      "G is: \n",
      "tensor([[1.7226e-06, 6.5350e-01],\n",
      "        [6.5350e-01, 2.4793e+05]])\n",
      "eig is:\n",
      "tensor([[1.5625e-02, 0.0000e+00],\n",
      "        [2.4793e+05, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0004, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0004, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:42 | [trpo_pendulum] epoch #268 | Saving snapshot...\n",
      "2022-08-23 10:41:42 | [trpo_pendulum] epoch #268 | Saved\n",
      "2022-08-23 10:41:42 | [trpo_pendulum] epoch #268 | Time 264.07 s\n",
      "2022-08-23 10:41:42 | [trpo_pendulum] epoch #268 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000435937\n",
      "Evaluation/AverageReturn                 -0.00441662\n",
      "Evaluation/Iteration                    268\n",
      "Evaluation/MaxReturn                     -0.00434541\n",
      "Evaluation/MinReturn                     -0.00448783\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.12098e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.76772\n",
      "GaussianMLPPolicy/KL                      4.54427e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000397058\n",
      "GaussianMLPPolicy/LossBefore             -0.000397052\n",
      "GaussianMLPPolicy/dLoss                   6.28643e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.64457\n",
      "GaussianMLPValueFunction/LossBefore      -4.23146\n",
      "GaussianMLPValueFunction/dLoss            2.41311\n",
      "TotalEnvSteps                        537462\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.2333e-06,  3.5048e-05, -4.1174e-09,  ...,  6.5603e-04,\n",
      "        -2.6732e-04,  7.4564e-04])\n",
      "G is: \n",
      "tensor([[6.5929e-06, 2.5013e+00],\n",
      "        [2.5013e+00, 9.4896e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [948955.1250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-4.3194e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-4.3219e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:43 | [trpo_pendulum] epoch #269 | Saving snapshot...\n",
      "2022-08-23 10:41:43 | [trpo_pendulum] epoch #269 | Saved\n",
      "2022-08-23 10:41:43 | [trpo_pendulum] epoch #269 | Time 265.01 s\n",
      "2022-08-23 10:41:43 | [trpo_pendulum] epoch #269 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000436302\n",
      "Evaluation/AverageReturn                 -0.00433114\n",
      "Evaluation/Iteration                    269\n",
      "Evaluation/MaxReturn                     -0.00415683\n",
      "Evaluation/MinReturn                     -0.00450546\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000174313\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.76772\n",
      "GaussianMLPPolicy/KL                      1.73287e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.32189e-05\n",
      "GaussianMLPPolicy/LossBefore             -4.31944e-05\n",
      "GaussianMLPPolicy/dLoss                   2.44399e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.68085\n",
      "GaussianMLPValueFunction/LossBefore      -6.64259\n",
      "GaussianMLPValueFunction/dLoss            0.0382552\n",
      "TotalEnvSteps                        539460\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.5538e-06,  3.8164e-05, -3.3928e-08,  ...,  7.1003e-04,\n",
      "        -2.8946e-04,  8.0696e-04])\n",
      "G is: \n",
      "tensor([[7.7227e-06, 2.9299e+00],\n",
      "        [2.9299e+00, 1.1116e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1111589.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(9.5491e-07, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(9.2629e-07, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:44 | [trpo_pendulum] epoch #270 | Saving snapshot...\n",
      "2022-08-23 10:41:44 | [trpo_pendulum] epoch #270 | Saved\n",
      "2022-08-23 10:41:44 | [trpo_pendulum] epoch #270 | Time 265.97 s\n",
      "2022-08-23 10:41:44 | [trpo_pendulum] epoch #270 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000474658\n",
      "Evaluation/AverageReturn                 -0.00446014\n",
      "Evaluation/Iteration                    270\n",
      "Evaluation/MaxReturn                     -0.00435742\n",
      "Evaluation/MinReturn                     -0.00456285\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000102714\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.76772\n",
      "GaussianMLPPolicy/KL                      2.02428e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               9.26294e-07\n",
      "GaussianMLPPolicy/LossBefore              9.54909e-07\n",
      "GaussianMLPPolicy/dLoss                   2.86145e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.6079\n",
      "GaussianMLPValueFunction/LossBefore      -6.68395\n",
      "GaussianMLPValueFunction/dLoss           -0.0760527\n",
      "TotalEnvSteps                        541458\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.1061e-05, -5.8910e-05, -2.0033e-06,  ..., -1.0065e-03,\n",
      "         4.0947e-04, -1.1420e-03])\n",
      "G is: \n",
      "tensor([[1.5499e-05, 5.8787e+00],\n",
      "        [5.8787e+00, 2.2300e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [2229951.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:45 | [trpo_pendulum] epoch #271 | Saving snapshot...\n",
      "2022-08-23 10:41:45 | [trpo_pendulum] epoch #271 | Saved\n",
      "2022-08-23 10:41:45 | [trpo_pendulum] epoch #271 | Time 266.99 s\n",
      "2022-08-23 10:41:45 | [trpo_pendulum] epoch #271 | EpochTime 1.02 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000432122\n",
      "Evaluation/AverageReturn                 -0.00437816\n",
      "Evaluation/Iteration                    271\n",
      "Evaluation/MaxReturn                     -0.00422902\n",
      "Evaluation/MinReturn                     -0.0045273\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000149141\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.76188\n",
      "GaussianMLPPolicy/KL                      0.00047\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000121325\n",
      "GaussianMLPPolicy/LossBefore              0.000121942\n",
      "GaussianMLPPolicy/dLoss                   6.1655e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.3346\n",
      "GaussianMLPValueFunction/LossBefore      -6.12523\n",
      "GaussianMLPValueFunction/dLoss            0.209371\n",
      "TotalEnvSteps                        543456\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.9644e-07,  4.3388e-06,  1.9490e-07,  ...,  2.2754e-04,\n",
      "        -8.8610e-05,  2.6080e-04])\n",
      "G is: \n",
      "tensor([[7.9551e-07, 2.9781e-01],\n",
      "        [2.9781e-01, 1.1166e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [111660.9297,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:46 | [trpo_pendulum] epoch #272 | Saving snapshot...\n",
      "2022-08-23 10:41:46 | [trpo_pendulum] epoch #272 | Saved\n",
      "2022-08-23 10:41:46 | [trpo_pendulum] epoch #272 | Time 267.99 s\n",
      "2022-08-23 10:41:46 | [trpo_pendulum] epoch #272 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000435315\n",
      "Evaluation/AverageReturn                 -0.00455161\n",
      "Evaluation/Iteration                    272\n",
      "Evaluation/MaxReturn                     -0.00444667\n",
      "Evaluation/MinReturn                     -0.00465655\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000104939\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.76214\n",
      "GaussianMLPPolicy/KL                      0.000370078\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000227324\n",
      "GaussianMLPPolicy/LossBefore             -0.000226872\n",
      "GaussianMLPPolicy/dLoss                   4.52346e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.67588\n",
      "GaussianMLPValueFunction/LossBefore      -5.86138\n",
      "GaussianMLPValueFunction/dLoss            0.814506\n",
      "TotalEnvSteps                        545454\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.2665e-06,  3.8093e-05, -8.9679e-09,  ...,  6.8920e-04,\n",
      "        -2.8086e-04,  7.8306e-04])\n",
      "G is: \n",
      "tensor([[7.2734e-06, 2.7277e+00],\n",
      "        [2.7277e+00, 1.0230e+06]])\n",
      "eig is:\n",
      "tensor([[-6.2500e-02,  0.0000e+00],\n",
      "        [ 1.0230e+06,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-3.0255e-06, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-3.0529e-06, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:47 | [trpo_pendulum] epoch #273 | Saving snapshot...\n",
      "2022-08-23 10:41:47 | [trpo_pendulum] epoch #273 | Saved\n",
      "2022-08-23 10:41:47 | [trpo_pendulum] epoch #273 | Time 268.98 s\n",
      "2022-08-23 10:41:47 | [trpo_pendulum] epoch #273 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000410986\n",
      "Evaluation/AverageReturn                 -0.00457728\n",
      "Evaluation/Iteration                    273\n",
      "Evaluation/MaxReturn                     -0.00455322\n",
      "Evaluation/MinReturn                     -0.00460134\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.40623e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.76214\n",
      "GaussianMLPPolicy/KL                      1.93503e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.05287e-06\n",
      "GaussianMLPPolicy/LossBefore             -3.0255e-06\n",
      "GaussianMLPPolicy/dLoss                   2.73728e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.53689\n",
      "GaussianMLPValueFunction/LossBefore      -6.67645\n",
      "GaussianMLPValueFunction/dLoss           -0.139562\n",
      "TotalEnvSteps                        547452\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.2477e-06,  1.6877e-05,  1.7962e-08,  ...,  3.2269e-04,\n",
      "        -1.3103e-04,  3.6690e-04])\n",
      "G is: \n",
      "tensor([[1.5948e-06, 5.9810e-01],\n",
      "        [5.9810e-01, 2.2431e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [224306.2188,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:48 | [trpo_pendulum] epoch #274 | Saving snapshot...\n",
      "2022-08-23 10:41:48 | [trpo_pendulum] epoch #274 | Saved\n",
      "2022-08-23 10:41:48 | [trpo_pendulum] epoch #274 | Time 269.94 s\n",
      "2022-08-23 10:41:48 | [trpo_pendulum] epoch #274 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000446476\n",
      "Evaluation/AverageReturn                 -0.0046735\n",
      "Evaluation/Iteration                    274\n",
      "Evaluation/MaxReturn                     -0.00459609\n",
      "Evaluation/MinReturn                     -0.00475091\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.74098e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.76214\n",
      "GaussianMLPPolicy/KL                      4.26489e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000105155\n",
      "GaussianMLPPolicy/LossBefore             -0.000105149\n",
      "GaussianMLPPolicy/dLoss                   6.03177e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.25799\n",
      "GaussianMLPValueFunction/LossBefore      -6.49757\n",
      "GaussianMLPValueFunction/dLoss           -0.239584\n",
      "TotalEnvSteps                        549450\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-6.9446e-06,  3.1552e-05, -7.6558e-07,  ...,  5.8139e-04,\n",
      "        -2.3764e-04,  6.6112e-04])\n",
      "G is: \n",
      "tensor([[5.1789e-06, 1.9420e+00],\n",
      "        [1.9420e+00, 7.2826e+05]])\n",
      "eig is:\n",
      "tensor([[6.2500e-02, 0.0000e+00],\n",
      "        [7.2826e+05, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-6.6311e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-6.6473e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:49 | [trpo_pendulum] epoch #275 | Saving snapshot...\n",
      "2022-08-23 10:41:49 | [trpo_pendulum] epoch #275 | Saved\n",
      "2022-08-23 10:41:49 | [trpo_pendulum] epoch #275 | Time 270.93 s\n",
      "2022-08-23 10:41:49 | [trpo_pendulum] epoch #275 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000467089\n",
      "Evaluation/AverageReturn                 -0.00462316\n",
      "Evaluation/Iteration                    275\n",
      "Evaluation/MaxReturn                     -0.00439786\n",
      "Evaluation/MinReturn                     -0.00484847\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000225304\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.75625\n",
      "GaussianMLPPolicy/KL                      0.000107413\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.64734e-05\n",
      "GaussianMLPPolicy/LossBefore             -6.63108e-05\n",
      "GaussianMLPPolicy/dLoss                   1.62603e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.56454\n",
      "GaussianMLPValueFunction/LossBefore      -6.52879\n",
      "GaussianMLPValueFunction/dLoss            0.0357442\n",
      "TotalEnvSteps                        551448\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.3120e-06,  7.7157e-05, -5.3946e-09,  ...,  1.4732e-03,\n",
      "        -5.9873e-04,  1.6743e-03])\n",
      "G is: \n",
      "tensor([[3.3227e-05, 1.2315e+01],\n",
      "        [1.2315e+01, 4.5645e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [4564504.,       0.]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:50 | [trpo_pendulum] epoch #276 | Saving snapshot...\n",
      "2022-08-23 10:41:50 | [trpo_pendulum] epoch #276 | Saved\n",
      "2022-08-23 10:41:50 | [trpo_pendulum] epoch #276 | Time 271.94 s\n",
      "2022-08-23 10:41:50 | [trpo_pendulum] epoch #276 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000412468\n",
      "Evaluation/AverageReturn                 -0.00440138\n",
      "Evaluation/Iteration                    276\n",
      "Evaluation/MaxReturn                     -0.00427004\n",
      "Evaluation/MinReturn                     -0.00453273\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000131345\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.75625\n",
      "GaussianMLPPolicy/KL                      8.88424e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000158852\n",
      "GaussianMLPPolicy/LossBefore             -0.000158726\n",
      "GaussianMLPPolicy/dLoss                   1.26136e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.6846\n",
      "GaussianMLPValueFunction/LossBefore      -6.27054\n",
      "GaussianMLPValueFunction/dLoss            0.41406\n",
      "TotalEnvSteps                        553446\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.1142e-06,  2.8721e-05,  2.0230e-09,  ...,  5.5383e-04,\n",
      "        -2.2494e-04,  6.2951e-04])\n",
      "G is: \n",
      "tensor([[4.6961e-06, 1.7405e+00],\n",
      "        [1.7405e+00, 6.4510e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [645102.8750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-2.6828e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-2.6846e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:51 | [trpo_pendulum] epoch #277 | Saving snapshot...\n",
      "2022-08-23 10:41:51 | [trpo_pendulum] epoch #277 | Saved\n",
      "2022-08-23 10:41:51 | [trpo_pendulum] epoch #277 | Time 272.95 s\n",
      "2022-08-23 10:41:51 | [trpo_pendulum] epoch #277 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000409317\n",
      "Evaluation/AverageReturn                 -0.00442594\n",
      "Evaluation/Iteration                    277\n",
      "Evaluation/MaxReturn                     -0.00416783\n",
      "Evaluation/MinReturn                     -0.00468405\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000258111\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.75625\n",
      "GaussianMLPPolicy/KL                      1.26392e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -2.68456e-05\n",
      "GaussianMLPPolicy/LossBefore             -2.68278e-05\n",
      "GaussianMLPPolicy/dLoss                   1.7817e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.69725\n",
      "GaussianMLPValueFunction/LossBefore      -6.68393\n",
      "GaussianMLPValueFunction/dLoss            0.0133166\n",
      "TotalEnvSteps                        555444\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.2404e-06,  3.5160e-05, -1.3409e-08,  ...,  6.7009e-04,\n",
      "        -2.7237e-04,  7.6155e-04])\n",
      "G is: \n",
      "tensor([[6.8744e-06, 2.5478e+00],\n",
      "        [2.5478e+00, 9.4431e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [944309.5625,      0.0000]])\n",
      "loss before is:\n",
      "tensor(2.6357e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(2.6331e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:52 | [trpo_pendulum] epoch #278 | Saving snapshot...\n",
      "2022-08-23 10:41:52 | [trpo_pendulum] epoch #278 | Saved\n",
      "2022-08-23 10:41:52 | [trpo_pendulum] epoch #278 | Time 273.94 s\n",
      "2022-08-23 10:41:52 | [trpo_pendulum] epoch #278 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000469057\n",
      "Evaluation/AverageReturn                 -0.0044959\n",
      "Evaluation/Iteration                    278\n",
      "Evaluation/MaxReturn                     -0.00435291\n",
      "Evaluation/MinReturn                     -0.0046389\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000142995\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.75625\n",
      "GaussianMLPPolicy/KL                      1.84612e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               2.63306e-05\n",
      "GaussianMLPPolicy/LossBefore              2.63567e-05\n",
      "GaussianMLPPolicy/dLoss                   2.60898e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.5383\n",
      "GaussianMLPValueFunction/LossBefore      -6.69663\n",
      "GaussianMLPValueFunction/dLoss           -0.158339\n",
      "TotalEnvSteps                        557442\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.1773e-05,  6.4755e-05,  1.2959e-07,  ...,  1.2324e-03,\n",
      "        -5.0071e-04,  1.4005e-03])\n",
      "G is: \n",
      "tensor([[2.3249e-05, 8.6165e+00],\n",
      "        [8.6165e+00, 3.1934e+06]])\n",
      "eig is:\n",
      "tensor([[-2.5000e-01,  0.0000e+00],\n",
      "        [ 3.1934e+06,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:53 | [trpo_pendulum] epoch #279 | Saving snapshot...\n",
      "2022-08-23 10:41:53 | [trpo_pendulum] epoch #279 | Saved\n",
      "2022-08-23 10:41:53 | [trpo_pendulum] epoch #279 | Time 274.93 s\n",
      "2022-08-23 10:41:53 | [trpo_pendulum] epoch #279 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000483673\n",
      "Evaluation/AverageReturn                 -0.00478035\n",
      "Evaluation/Iteration                    279\n",
      "Evaluation/MaxReturn                     -0.00471644\n",
      "Evaluation/MinReturn                     -0.00484426\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.39099e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.7645\n",
      "GaussianMLPPolicy/KL                      0.000132423\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000181223\n",
      "GaussianMLPPolicy/LossBefore              0.00018141\n",
      "GaussianMLPPolicy/dLoss                   1.87531e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.59886\n",
      "GaussianMLPValueFunction/LossBefore      -6.09982\n",
      "GaussianMLPValueFunction/dLoss            0.499037\n",
      "TotalEnvSteps                        559440\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.4652e-05,  6.8481e-05, -3.7286e-08,  ...,  1.3147e-03,\n",
      "        -5.3407e-04,  1.4944e-03])\n",
      "G is: \n",
      "tensor([[2.6464e-05, 9.9716e+00],\n",
      "        [9.9716e+00, 3.7573e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [3757313.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:54 | [trpo_pendulum] epoch #280 | Saving snapshot...\n",
      "2022-08-23 10:41:54 | [trpo_pendulum] epoch #280 | Saved\n",
      "2022-08-23 10:41:54 | [trpo_pendulum] epoch #280 | Time 275.88 s\n",
      "2022-08-23 10:41:54 | [trpo_pendulum] epoch #280 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000373082\n",
      "Evaluation/AverageReturn                 -0.00401662\n",
      "Evaluation/Iteration                    280\n",
      "Evaluation/MaxReturn                     -0.00394325\n",
      "Evaluation/MinReturn                     -0.00409\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.33747e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.77515\n",
      "GaussianMLPPolicy/KL                      0.000182742\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000157176\n",
      "GaussianMLPPolicy/LossBefore             -0.000156919\n",
      "GaussianMLPPolicy/dLoss                   2.57438e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.49688\n",
      "GaussianMLPValueFunction/LossBefore      -6.2862\n",
      "GaussianMLPValueFunction/dLoss            0.210678\n",
      "TotalEnvSteps                        561438\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.2492e-05, -1.7588e-05,  5.0658e-07,  ..., -6.1133e-04,\n",
      "         2.4210e-04, -6.9934e-04])\n",
      "G is: \n",
      "tensor([[5.7384e-06, 2.2065e+00],\n",
      "        [2.2065e+00, 8.4915e+05]])\n",
      "eig is:\n",
      "tensor([[     0.,      0.],\n",
      "        [849151.,      0.]])\n",
      "loss before is:\n",
      "tensor(6.6544e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(6.6187e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:55 | [trpo_pendulum] epoch #281 | Saving snapshot...\n",
      "2022-08-23 10:41:55 | [trpo_pendulum] epoch #281 | Saved\n",
      "2022-08-23 10:41:55 | [trpo_pendulum] epoch #281 | Time 276.87 s\n",
      "2022-08-23 10:41:55 | [trpo_pendulum] epoch #281 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000475529\n",
      "Evaluation/AverageReturn                 -0.00459009\n",
      "Evaluation/Iteration                    281\n",
      "Evaluation/MaxReturn                     -0.00441545\n",
      "Evaluation/MinReturn                     -0.00476472\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000174634\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.76682\n",
      "GaussianMLPPolicy/KL                      0.000243031\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               6.61867e-05\n",
      "GaussianMLPPolicy/LossBefore              6.65437e-05\n",
      "GaussianMLPPolicy/dLoss                   3.57002e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.49062\n",
      "GaussianMLPValueFunction/LossBefore      -6.42439\n",
      "GaussianMLPValueFunction/dLoss            0.0662317\n",
      "TotalEnvSteps                        563436\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-4.9735e-06,  2.3766e-06, -4.0093e-08,  ..., -3.2990e-04,\n",
      "         1.2434e-04, -3.8093e-04])\n",
      "G is: \n",
      "tensor([[1.6810e-06, 6.3294e-01],\n",
      "        [6.3294e-01, 2.3957e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [239568.4844,      0.0000]])\n",
      "loss before is:\n",
      "tensor(2.3895e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(2.3610e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:56 | [trpo_pendulum] epoch #282 | Saving snapshot...\n",
      "2022-08-23 10:41:56 | [trpo_pendulum] epoch #282 | Saved\n",
      "2022-08-23 10:41:56 | [trpo_pendulum] epoch #282 | Time 277.85 s\n",
      "2022-08-23 10:41:56 | [trpo_pendulum] epoch #282 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00043253\n",
      "Evaluation/AverageReturn                 -0.00471332\n",
      "Evaluation/Iteration                    282\n",
      "Evaluation/MaxReturn                     -0.00464381\n",
      "Evaluation/MinReturn                     -0.00478282\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.95041e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.76666\n",
      "GaussianMLPPolicy/KL                      0.000203045\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               2.361e-05\n",
      "GaussianMLPPolicy/LossBefore              2.3895e-05\n",
      "GaussianMLPPolicy/dLoss                   2.85077e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.25553\n",
      "GaussianMLPValueFunction/LossBefore      -6.37428\n",
      "GaussianMLPValueFunction/dLoss           -0.118757\n",
      "TotalEnvSteps                        565434\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.7134e-05, -3.5716e-06, -8.1303e-08,  ..., -6.9164e-05,\n",
      "         2.7979e-05, -7.8592e-05])\n",
      "G is: \n",
      "tensor([[7.3514e-08, 2.7711e-02],\n",
      "        [2.7711e-02, 1.0488e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [10487.5576,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:57 | [trpo_pendulum] epoch #283 | Saving snapshot...\n",
      "2022-08-23 10:41:57 | [trpo_pendulum] epoch #283 | Saved\n",
      "2022-08-23 10:41:57 | [trpo_pendulum] epoch #283 | Time 278.86 s\n",
      "2022-08-23 10:41:57 | [trpo_pendulum] epoch #283 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000415345\n",
      "Evaluation/AverageReturn                 -0.0041081\n",
      "Evaluation/Iteration                    283\n",
      "Evaluation/MaxReturn                     -0.00389631\n",
      "Evaluation/MinReturn                     -0.0043199\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000211796\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.77874\n",
      "GaussianMLPPolicy/KL                      0.000147616\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000110268\n",
      "GaussianMLPPolicy/LossBefore             -0.000110061\n",
      "GaussianMLPPolicy/dLoss                   2.07132e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.50336\n",
      "GaussianMLPValueFunction/LossBefore      -6.47598\n",
      "GaussianMLPValueFunction/dLoss            0.0273819\n",
      "TotalEnvSteps                        567432\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.9142e-06,  2.2548e-05,  9.5405e-08,  ...,  4.2283e-04,\n",
      "        -1.7197e-04,  4.8042e-04])\n",
      "G is: \n",
      "tensor([[2.7371e-06, 1.0613e+00],\n",
      "        [1.0613e+00, 4.1149e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [411488.7500,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-8.8210e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-8.8220e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:58 | [trpo_pendulum] epoch #284 | Saving snapshot...\n",
      "2022-08-23 10:41:58 | [trpo_pendulum] epoch #284 | Saved\n",
      "2022-08-23 10:41:58 | [trpo_pendulum] epoch #284 | Time 280.02 s\n",
      "2022-08-23 10:41:58 | [trpo_pendulum] epoch #284 | EpochTime 1.15 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000398222\n",
      "Evaluation/AverageReturn                 -0.00433225\n",
      "Evaluation/Iteration                    284\n",
      "Evaluation/MaxReturn                     -0.00423858\n",
      "Evaluation/MinReturn                     -0.00442592\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      9.36719e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.77874\n",
      "GaussianMLPPolicy/KL                      7.06064e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -8.82203e-05\n",
      "GaussianMLPPolicy/LossBefore             -8.82101e-05\n",
      "GaussianMLPPolicy/dLoss                   1.01281e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.69155\n",
      "GaussianMLPValueFunction/LossBefore      -6.56706\n",
      "GaussianMLPValueFunction/dLoss            0.12449\n",
      "TotalEnvSteps                        569430\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.7763e-06,  2.7435e-05, -1.0785e-08,  ...,  5.1082e-04,\n",
      "        -2.0803e-04,  5.8038e-04])\n",
      "G is: \n",
      "tensor([[3.9951e-06, 1.5490e+00],\n",
      "        [1.5490e+00, 6.0062e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [600619.8750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-4.5230e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-4.5244e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:41:59 | [trpo_pendulum] epoch #285 | Saving snapshot...\n",
      "2022-08-23 10:41:59 | [trpo_pendulum] epoch #285 | Saved\n",
      "2022-08-23 10:41:59 | [trpo_pendulum] epoch #285 | Time 280.97 s\n",
      "2022-08-23 10:41:59 | [trpo_pendulum] epoch #285 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000394036\n",
      "Evaluation/AverageReturn                 -0.00425386\n",
      "Evaluation/Iteration                    285\n",
      "Evaluation/MaxReturn                     -0.00417228\n",
      "Evaluation/MinReturn                     -0.00433544\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.15785e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.77874\n",
      "GaussianMLPPolicy/KL                      1.03073e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.52444e-05\n",
      "GaussianMLPPolicy/LossBefore             -4.52299e-05\n",
      "GaussianMLPPolicy/dLoss                   1.44501e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.58475\n",
      "GaussianMLPValueFunction/LossBefore      -6.6756\n",
      "GaussianMLPValueFunction/dLoss           -0.0908537\n",
      "TotalEnvSteps                        571428\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.1581e-06,  1.8962e-05, -5.7953e-08,  ...,  3.8805e-04,\n",
      "        -1.5719e-04,  4.4147e-04])\n",
      "G is: \n",
      "tensor([[2.3065e-06, 8.9427e-01],\n",
      "        [8.9427e-01, 3.4674e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [346742.0625,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:00 | [trpo_pendulum] epoch #286 | Saving snapshot...\n",
      "2022-08-23 10:42:00 | [trpo_pendulum] epoch #286 | Saved\n",
      "2022-08-23 10:42:00 | [trpo_pendulum] epoch #286 | Time 281.94 s\n",
      "2022-08-23 10:42:00 | [trpo_pendulum] epoch #286 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000437827\n",
      "Evaluation/AverageReturn                 -0.00428334\n",
      "Evaluation/Iteration                    286\n",
      "Evaluation/MaxReturn                     -0.00419623\n",
      "Evaluation/MinReturn                     -0.00437045\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.71079e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.78336\n",
      "GaussianMLPPolicy/KL                      5.04305e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000101208\n",
      "GaussianMLPPolicy/LossBefore              0.00010128\n",
      "GaussianMLPPolicy/dLoss                   7.16173e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.70055\n",
      "GaussianMLPValueFunction/LossBefore      -6.54103\n",
      "GaussianMLPValueFunction/dLoss            0.159519\n",
      "TotalEnvSteps                        573426\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.8365e-06,  3.3294e-05,  6.7089e-09,  ...,  6.2796e-04,\n",
      "        -2.5531e-04,  7.1372e-04])\n",
      "G is: \n",
      "tensor([[6.0382e-06, 2.3627e+00],\n",
      "        [2.3627e+00, 9.2453e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [924530.1250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-5.7131e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-5.7153e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:01 | [trpo_pendulum] epoch #287 | Saving snapshot...\n",
      "2022-08-23 10:42:01 | [trpo_pendulum] epoch #287 | Saved\n",
      "2022-08-23 10:42:01 | [trpo_pendulum] epoch #287 | Time 282.88 s\n",
      "2022-08-23 10:42:01 | [trpo_pendulum] epoch #287 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00042063\n",
      "Evaluation/AverageReturn                 -0.00410695\n",
      "Evaluation/Iteration                    287\n",
      "Evaluation/MaxReturn                     -0.00407801\n",
      "Evaluation/MinReturn                     -0.00413589\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.89382e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.78336\n",
      "GaussianMLPPolicy/KL                      1.5435e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.7153e-05\n",
      "GaussianMLPPolicy/LossBefore             -5.71314e-05\n",
      "GaussianMLPPolicy/dLoss                   2.16824e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.66832\n",
      "GaussianMLPValueFunction/LossBefore      -6.66154\n",
      "GaussianMLPValueFunction/dLoss            0.00678015\n",
      "TotalEnvSteps                        575424\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.4658e-06,  5.4003e-05,  5.1358e-09,  ...,  1.0104e-03,\n",
      "        -4.1101e-04,  1.1482e-03])\n",
      "G is: \n",
      "tensor([[1.5631e-05, 6.1166e+00],\n",
      "        [6.1166e+00, 2.3934e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [2393413.,       0.]])\n",
      "loss before is:\n",
      "tensor(6.3777e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(6.3721e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:02 | [trpo_pendulum] epoch #288 | Saving snapshot...\n",
      "2022-08-23 10:42:02 | [trpo_pendulum] epoch #288 | Saved\n",
      "2022-08-23 10:42:02 | [trpo_pendulum] epoch #288 | Time 283.85 s\n",
      "2022-08-23 10:42:02 | [trpo_pendulum] epoch #288 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000428152\n",
      "Evaluation/AverageReturn                 -0.00421584\n",
      "Evaluation/Iteration                    288\n",
      "Evaluation/MaxReturn                     -0.00410757\n",
      "Evaluation/MinReturn                     -0.00432411\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000108272\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.78336\n",
      "GaussianMLPPolicy/KL                      3.9811e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               6.37209e-05\n",
      "GaussianMLPPolicy/LossBefore              6.37771e-05\n",
      "GaussianMLPPolicy/dLoss                   5.61922e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.72867\n",
      "GaussianMLPValueFunction/LossBefore      -6.661\n",
      "GaussianMLPValueFunction/dLoss            0.0676689\n",
      "TotalEnvSteps                        577422\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.6670e-06,  6.0850e-05,  2.4651e-08,  ...,  1.1525e-03,\n",
      "        -4.6845e-04,  1.3100e-03])\n",
      "G is: \n",
      "tensor([[2.0340e-05, 7.9590e+00],\n",
      "        [7.9590e+00, 3.1143e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [3114335.2500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-9.6313e-06, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-9.7044e-06, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:03 | [trpo_pendulum] epoch #289 | Saving snapshot...\n",
      "2022-08-23 10:42:03 | [trpo_pendulum] epoch #289 | Saved\n",
      "2022-08-23 10:42:03 | [trpo_pendulum] epoch #289 | Time 284.82 s\n",
      "2022-08-23 10:42:03 | [trpo_pendulum] epoch #289 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000427978\n",
      "Evaluation/AverageReturn                 -0.00423435\n",
      "Evaluation/Iteration                    289\n",
      "Evaluation/MaxReturn                     -0.00414198\n",
      "Evaluation/MinReturn                     -0.00432672\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      9.23727e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.78336\n",
      "GaussianMLPPolicy/KL                      5.18045e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -9.70442e-06\n",
      "GaussianMLPPolicy/LossBefore             -9.63133e-06\n",
      "GaussianMLPPolicy/dLoss                   7.30952e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.69405\n",
      "GaussianMLPValueFunction/LossBefore      -6.72315\n",
      "GaussianMLPValueFunction/dLoss           -0.0290999\n",
      "TotalEnvSteps                        579420\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-4.6307e-06, -4.1568e-05,  3.7306e-08,  ..., -8.6628e-04,\n",
      "         3.5010e-04, -9.8595e-04])\n",
      "G is: \n",
      "tensor([[1.1495e-05, 4.4975e+00],\n",
      "        [4.4975e+00, 1.7598e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1759772.7500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:04 | [trpo_pendulum] epoch #290 | Saving snapshot...\n",
      "2022-08-23 10:42:04 | [trpo_pendulum] epoch #290 | Saved\n",
      "2022-08-23 10:42:04 | [trpo_pendulum] epoch #290 | Time 285.78 s\n",
      "2022-08-23 10:42:04 | [trpo_pendulum] epoch #290 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00036609\n",
      "Evaluation/AverageReturn                 -0.00390015\n",
      "Evaluation/Iteration                    290\n",
      "Evaluation/MaxReturn                     -0.00369241\n",
      "Evaluation/MinReturn                     -0.0041079\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000207745\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.783\n",
      "GaussianMLPPolicy/KL                      5.56392e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000115133\n",
      "GaussianMLPPolicy/LossBefore              0.000115212\n",
      "GaussianMLPPolicy/dLoss                   7.89369e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.36865\n",
      "GaussianMLPValueFunction/LossBefore      -6.4427\n",
      "GaussianMLPValueFunction/dLoss           -0.0740504\n",
      "TotalEnvSteps                        581418\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.5090e-06,  3.0667e-05,  8.5835e-07,  ...,  5.2636e-04,\n",
      "        -2.1423e-04,  5.9699e-04])\n",
      "G is: \n",
      "tensor([[4.2380e-06, 1.6569e+00],\n",
      "        [1.6569e+00, 6.4787e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [647872.8750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-9.8803e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-9.8993e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:05 | [trpo_pendulum] epoch #291 | Saving snapshot...\n",
      "2022-08-23 10:42:05 | [trpo_pendulum] epoch #291 | Saved\n",
      "2022-08-23 10:42:05 | [trpo_pendulum] epoch #291 | Time 286.78 s\n",
      "2022-08-23 10:42:05 | [trpo_pendulum] epoch #291 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000410109\n",
      "Evaluation/AverageReturn                 -0.00439982\n",
      "Evaluation/Iteration                    291\n",
      "Evaluation/MaxReturn                     -0.0042921\n",
      "Evaluation/MinReturn                     -0.00450755\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000107724\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.78857\n",
      "GaussianMLPPolicy/KL                      0.000134015\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -9.89928e-05\n",
      "GaussianMLPPolicy/LossBefore             -9.88029e-05\n",
      "GaussianMLPPolicy/dLoss                   1.89881e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.08664\n",
      "GaussianMLPValueFunction/LossBefore      -6.48429\n",
      "GaussianMLPValueFunction/dLoss           -0.397645\n",
      "TotalEnvSteps                        583416\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-6.5416e-06, -7.1625e-06, -8.2415e-08,  ..., -1.2050e-04,\n",
      "         4.9219e-05, -1.3677e-04])\n",
      "G is: \n",
      "tensor([[2.2232e-07, 8.7887e-02],\n",
      "        [8.7887e-02, 3.4751e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [34750.9375,     0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:06 | [trpo_pendulum] epoch #292 | Saving snapshot...\n",
      "2022-08-23 10:42:06 | [trpo_pendulum] epoch #292 | Saved\n",
      "2022-08-23 10:42:06 | [trpo_pendulum] epoch #292 | Time 287.77 s\n",
      "2022-08-23 10:42:06 | [trpo_pendulum] epoch #292 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000384492\n",
      "Evaluation/AverageReturn                 -0.00387661\n",
      "Evaluation/Iteration                    292\n",
      "Evaluation/MaxReturn                     -0.00373894\n",
      "Evaluation/MinReturn                     -0.00401428\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000137672\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.78857\n",
      "GaussianMLPPolicy/KL                      5.60009e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000133877\n",
      "GaussianMLPPolicy/LossBefore              0.000133878\n",
      "GaussianMLPPolicy/dLoss                   8.73115e-10\n",
      "GaussianMLPValueFunction/LossAfter       -6.66253\n",
      "GaussianMLPValueFunction/LossBefore      -6.37507\n",
      "GaussianMLPValueFunction/dLoss            0.287456\n",
      "TotalEnvSteps                        585414\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.5241e-05,  8.0887e-06, -5.1956e-07,  ...,  9.8658e-05,\n",
      "        -4.2124e-05,  1.1161e-04])\n",
      "G is: \n",
      "tensor([[1.4962e-07, 5.8971e-02],\n",
      "        [5.8971e-02, 2.3319e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [23318.8125,     0.0000]])\n",
      "loss before is:\n",
      "tensor(9.6898e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(9.6684e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:07 | [trpo_pendulum] epoch #293 | Saving snapshot...\n",
      "2022-08-23 10:42:07 | [trpo_pendulum] epoch #293 | Saved\n",
      "2022-08-23 10:42:07 | [trpo_pendulum] epoch #293 | Time 288.75 s\n",
      "2022-08-23 10:42:07 | [trpo_pendulum] epoch #293 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00040635\n",
      "Evaluation/AverageReturn                 -0.00433552\n",
      "Evaluation/Iteration                    293\n",
      "Evaluation/MaxReturn                     -0.00422692\n",
      "Evaluation/MinReturn                     -0.00444413\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000108606\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.79955\n",
      "GaussianMLPPolicy/KL                      0.000155024\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               9.66843e-05\n",
      "GaussianMLPPolicy/LossBefore              9.68976e-05\n",
      "GaussianMLPPolicy/dLoss                   2.13302e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.21979\n",
      "GaussianMLPValueFunction/LossBefore      -6.47072\n",
      "GaussianMLPValueFunction/dLoss           -0.250932\n",
      "TotalEnvSteps                        587412\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.0452e-05,  6.1789e-05,  6.4706e-08,  ...,  1.1045e-03,\n",
      "        -4.5059e-04,  1.2545e-03])\n",
      "G is: \n",
      "tensor([[1.8677e-05, 7.5495e+00],\n",
      "        [7.5495e+00, 3.0516e+06]])\n",
      "eig is:\n",
      "tensor([[2.5000e-01, 0.0000e+00],\n",
      "        [3.0516e+06, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:08 | [trpo_pendulum] epoch #294 | Saving snapshot...\n",
      "2022-08-23 10:42:08 | [trpo_pendulum] epoch #294 | Saved\n",
      "2022-08-23 10:42:08 | [trpo_pendulum] epoch #294 | Time 289.70 s\n",
      "2022-08-23 10:42:08 | [trpo_pendulum] epoch #294 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000430763\n",
      "Evaluation/AverageReturn                 -0.00417979\n",
      "Evaluation/Iteration                    294\n",
      "Evaluation/MaxReturn                     -0.00409964\n",
      "Evaluation/MinReturn                     -0.00425994\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.01526e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.80693\n",
      "GaussianMLPPolicy/KL                      0.000111102\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000107876\n",
      "GaussianMLPPolicy/LossBefore              0.000108033\n",
      "GaussianMLPPolicy/dLoss                   1.56324e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.70467\n",
      "GaussianMLPValueFunction/LossBefore      -6.4933\n",
      "GaussianMLPValueFunction/dLoss            0.211364\n",
      "TotalEnvSteps                        589410\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.5446e-06,  7.3777e-05, -2.2262e-09,  ...,  1.3781e-03,\n",
      "        -5.6099e-04,  1.5662e-03])\n",
      "G is: \n",
      "tensor([[2.9087e-05, 1.1933e+01],\n",
      "        [1.1933e+01, 4.8955e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [4895540.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-9.7189e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-9.7289e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:09 | [trpo_pendulum] epoch #295 | Saving snapshot...\n",
      "2022-08-23 10:42:09 | [trpo_pendulum] epoch #295 | Saved\n",
      "2022-08-23 10:42:09 | [trpo_pendulum] epoch #295 | Time 290.64 s\n",
      "2022-08-23 10:42:09 | [trpo_pendulum] epoch #295 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000405344\n",
      "Evaluation/AverageReturn                 -0.00365353\n",
      "Evaluation/Iteration                    295\n",
      "Evaluation/MaxReturn                     -0.00362032\n",
      "Evaluation/MinReturn                     -0.00368674\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.32116e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.80693\n",
      "GaussianMLPPolicy/KL                      7.03595e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -9.72889e-05\n",
      "GaussianMLPPolicy/LossBefore             -9.71894e-05\n",
      "GaussianMLPPolicy/dLoss                   9.94405e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.72124\n",
      "GaussianMLPValueFunction/LossBefore      -6.56444\n",
      "GaussianMLPValueFunction/dLoss            0.156802\n",
      "TotalEnvSteps                        591408\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.5733e-06,  5.7821e-05, -8.7666e-08,  ...,  1.1125e-03,\n",
      "        -4.5209e-04,  1.2650e-03])\n",
      "G is: \n",
      "tensor([[1.8958e-05, 7.7770e+00],\n",
      "        [7.7770e+00, 3.1904e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [3190416.,       0.]])\n",
      "loss before is:\n",
      "tensor(3.0847e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(3.0782e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:10 | [trpo_pendulum] epoch #296 | Saving snapshot...\n",
      "2022-08-23 10:42:10 | [trpo_pendulum] epoch #296 | Saved\n",
      "2022-08-23 10:42:10 | [trpo_pendulum] epoch #296 | Time 291.63 s\n",
      "2022-08-23 10:42:10 | [trpo_pendulum] epoch #296 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000372308\n",
      "Evaluation/AverageReturn                 -0.00374036\n",
      "Evaluation/Iteration                    296\n",
      "Evaluation/MaxReturn                     -0.00361639\n",
      "Evaluation/MinReturn                     -0.00386434\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000123974\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.80693\n",
      "GaussianMLPPolicy/KL                      4.58898e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               3.07822e-05\n",
      "GaussianMLPPolicy/LossBefore              3.08471e-05\n",
      "GaussianMLPPolicy/dLoss                   6.49416e-08\n",
      "GaussianMLPValueFunction/LossAfter       -5.39501\n",
      "GaussianMLPValueFunction/LossBefore      -6.69924\n",
      "GaussianMLPValueFunction/dLoss           -1.30423\n",
      "TotalEnvSteps                        593406\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-2.7394e-06,  8.8285e-05,  1.2699e-07,  ...,  1.6352e-03,\n",
      "        -6.6579e-04,  1.8580e-03])\n",
      "G is: \n",
      "tensor([[4.0945e-05, 1.6797e+01],\n",
      "        [1.6797e+01, 6.8909e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [6890894.,       0.]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:11 | [trpo_pendulum] epoch #297 | Saving snapshot...\n",
      "2022-08-23 10:42:11 | [trpo_pendulum] epoch #297 | Saved\n",
      "2022-08-23 10:42:11 | [trpo_pendulum] epoch #297 | Time 292.66 s\n",
      "2022-08-23 10:42:11 | [trpo_pendulum] epoch #297 | EpochTime 1.02 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000367591\n",
      "Evaluation/AverageReturn                 -0.00379167\n",
      "Evaluation/Iteration                    297\n",
      "Evaluation/MaxReturn                     -0.0036042\n",
      "Evaluation/MinReturn                     -0.00397913\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000187464\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.80693\n",
      "GaussianMLPPolicy/KL                      9.86926e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000319219\n",
      "GaussianMLPPolicy/LossBefore             -0.000319079\n",
      "GaussianMLPPolicy/dLoss                   1.40106e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.68145\n",
      "GaussianMLPValueFunction/LossBefore      -4.85783\n",
      "GaussianMLPValueFunction/dLoss            1.82362\n",
      "TotalEnvSteps                        595404\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.9577e-06,  2.7264e-05, -4.5714e-08,  ...,  5.0055e-04,\n",
      "        -2.0403e-04,  5.6875e-04])\n",
      "G is: \n",
      "tensor([[3.8369e-06, 1.5740e+00],\n",
      "        [1.5740e+00, 6.4570e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [645704.3750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-5.2728e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-5.2742e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:12 | [trpo_pendulum] epoch #298 | Saving snapshot...\n",
      "2022-08-23 10:42:12 | [trpo_pendulum] epoch #298 | Saved\n",
      "2022-08-23 10:42:12 | [trpo_pendulum] epoch #298 | Time 293.67 s\n",
      "2022-08-23 10:42:12 | [trpo_pendulum] epoch #298 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000395308\n",
      "Evaluation/AverageReturn                 -0.00370925\n",
      "Evaluation/Iteration                    298\n",
      "Evaluation/MaxReturn                     -0.00365387\n",
      "Evaluation/MinReturn                     -0.00376462\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.53719e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.80693\n",
      "GaussianMLPPolicy/KL                      9.32132e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.27417e-05\n",
      "GaussianMLPPolicy/LossBefore             -5.27284e-05\n",
      "GaussianMLPPolicy/dLoss                   1.32095e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.65881\n",
      "GaussianMLPValueFunction/LossBefore      -6.70234\n",
      "GaussianMLPValueFunction/dLoss           -0.0435247\n",
      "TotalEnvSteps                        597402\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.2431e-05,  1.2109e-05,  3.7053e-07,  ...,  3.9959e-04,\n",
      "        -1.5765e-04,  4.5671e-04])\n",
      "G is: \n",
      "tensor([[2.4503e-06, 1.0042e+00],\n",
      "        [1.0042e+00, 4.1194e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [411943.8750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:13 | [trpo_pendulum] epoch #299 | Saving snapshot...\n",
      "2022-08-23 10:42:13 | [trpo_pendulum] epoch #299 | Saved\n",
      "2022-08-23 10:42:13 | [trpo_pendulum] epoch #299 | Time 294.66 s\n",
      "2022-08-23 10:42:13 | [trpo_pendulum] epoch #299 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000351935\n",
      "Evaluation/AverageReturn                 -0.00386982\n",
      "Evaluation/Iteration                    299\n",
      "Evaluation/MaxReturn                     -0.00385813\n",
      "Evaluation/MinReturn                     -0.0038815\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.16855e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.82266\n",
      "GaussianMLPPolicy/KL                      0.000344407\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000146445\n",
      "GaussianMLPPolicy/LossBefore              0.000146925\n",
      "GaussianMLPPolicy/dLoss                   4.79398e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.31761\n",
      "GaussianMLPValueFunction/LossBefore      -6.27411\n",
      "GaussianMLPValueFunction/dLoss            0.0435033\n",
      "TotalEnvSteps                        599400\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.0344e-06,  4.4783e-05,  4.6212e-07,  ...,  8.8281e-04,\n",
      "        -3.5718e-04,  1.0042e-03])\n",
      "G is: \n",
      "tensor([[1.1937e-05, 5.0528e+00],\n",
      "        [5.0528e+00, 2.1388e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [2138794.2500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-7.0689e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-7.0740e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:14 | [trpo_pendulum] epoch #300 | Saving snapshot...\n",
      "2022-08-23 10:42:14 | [trpo_pendulum] epoch #300 | Saved\n",
      "2022-08-23 10:42:14 | [trpo_pendulum] epoch #300 | Time 295.62 s\n",
      "2022-08-23 10:42:14 | [trpo_pendulum] epoch #300 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000327692\n",
      "Evaluation/AverageReturn                 -0.00410149\n",
      "Evaluation/Iteration                    300\n",
      "Evaluation/MaxReturn                     -0.00408156\n",
      "Evaluation/MinReturn                     -0.00412141\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.99253e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.82262\n",
      "GaussianMLPPolicy/KL                      3.57585e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.07395e-05\n",
      "GaussianMLPPolicy/LossBefore             -7.06886e-05\n",
      "GaussianMLPPolicy/dLoss                   5.08589e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.25921\n",
      "GaussianMLPValueFunction/LossBefore      -6.4606\n",
      "GaussianMLPValueFunction/dLoss           -0.201393\n",
      "TotalEnvSteps                        601398\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.0063e-05, -8.1399e-06,  1.8401e-07,  ..., -2.3435e-04,\n",
      "         9.3513e-05, -2.6772e-04])\n",
      "G is: \n",
      "tensor([[8.4309e-07, 3.5663e-01],\n",
      "        [3.5663e-01, 1.5095e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [150949.2188,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:15 | [trpo_pendulum] epoch #301 | Saving snapshot...\n",
      "2022-08-23 10:42:15 | [trpo_pendulum] epoch #301 | Saved\n",
      "2022-08-23 10:42:15 | [trpo_pendulum] epoch #301 | Time 296.63 s\n",
      "2022-08-23 10:42:15 | [trpo_pendulum] epoch #301 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00042535\n",
      "Evaluation/AverageReturn                 -0.00409269\n",
      "Evaluation/Iteration                    301\n",
      "Evaluation/MaxReturn                     -0.00376891\n",
      "Evaluation/MinReturn                     -0.00441648\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000323783\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.82968\n",
      "GaussianMLPPolicy/KL                      6.92224e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000161187\n",
      "GaussianMLPPolicy/LossBefore             -0.000161091\n",
      "GaussianMLPPolicy/dLoss                   9.6552e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.61098\n",
      "GaussianMLPValueFunction/LossBefore      -6.15291\n",
      "GaussianMLPValueFunction/dLoss            0.458068\n",
      "TotalEnvSteps                        603396\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.2850e-06,  4.3949e-05,  5.1404e-08,  ...,  8.0338e-04,\n",
      "        -3.2711e-04,  9.1308e-04])\n",
      "G is: \n",
      "tensor([[9.8861e-06, 4.2443e+00],\n",
      "        [4.2443e+00, 1.8222e+06]])\n",
      "eig is:\n",
      "tensor([[-1.2500e-01,  0.0000e+00],\n",
      "        [ 1.8222e+06,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:16 | [trpo_pendulum] epoch #302 | Saving snapshot...\n",
      "2022-08-23 10:42:16 | [trpo_pendulum] epoch #302 | Saved\n",
      "2022-08-23 10:42:16 | [trpo_pendulum] epoch #302 | Time 297.61 s\n",
      "2022-08-23 10:42:16 | [trpo_pendulum] epoch #302 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000360722\n",
      "Evaluation/AverageReturn                 -0.0035638\n",
      "Evaluation/Iteration                    302\n",
      "Evaluation/MaxReturn                     -0.00347924\n",
      "Evaluation/MinReturn                     -0.00364836\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.45605e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.82968\n",
      "GaussianMLPPolicy/KL                      2.28962e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000108414\n",
      "GaussianMLPPolicy/LossBefore             -0.000108381\n",
      "GaussianMLPPolicy/dLoss                   3.23998e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.52448\n",
      "GaussianMLPValueFunction/LossBefore      -6.52193\n",
      "GaussianMLPValueFunction/dLoss            0.00254965\n",
      "TotalEnvSteps                        605394\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.2515e-06,  6.3422e-05, -2.0543e-08,  ...,  1.1877e-03,\n",
      "        -4.8297e-04,  1.3504e-03])\n",
      "G is: \n",
      "tensor([[2.1609e-05, 9.2773e+00],\n",
      "        [9.2773e+00, 3.9829e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [3982890.,       0.]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:17 | [trpo_pendulum] epoch #303 | Saving snapshot...\n",
      "2022-08-23 10:42:17 | [trpo_pendulum] epoch #303 | Saved\n",
      "2022-08-23 10:42:17 | [trpo_pendulum] epoch #303 | Time 298.59 s\n",
      "2022-08-23 10:42:17 | [trpo_pendulum] epoch #303 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000313091\n",
      "Evaluation/AverageReturn                 -0.00354614\n",
      "Evaluation/Iteration                    303\n",
      "Evaluation/MaxReturn                     -0.00347739\n",
      "Evaluation/MinReturn                     -0.0036149\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.87551e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.82968\n",
      "GaussianMLPPolicy/KL                      4.99996e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000119404\n",
      "GaussianMLPPolicy/LossBefore              0.000119475\n",
      "GaussianMLPPolicy/dLoss                   7.09115e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.74516\n",
      "GaussianMLPValueFunction/LossBefore      -6.48268\n",
      "GaussianMLPValueFunction/dLoss            0.262476\n",
      "TotalEnvSteps                        607392\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.2861e-06, -5.8658e-06, -1.1825e-07,  ..., -1.8629e-05,\n",
      "         9.7119e-06, -1.9724e-05])\n",
      "G is: \n",
      "tensor([[5.7219e-09, 2.2398e-03],\n",
      "        [2.2398e-03, 9.6160e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [961.5968,   0.0000]])\n",
      "loss before is:\n",
      "tensor(4.9908e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(4.9870e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:18 | [trpo_pendulum] epoch #304 | Saving snapshot...\n",
      "2022-08-23 10:42:18 | [trpo_pendulum] epoch #304 | Saved\n",
      "2022-08-23 10:42:18 | [trpo_pendulum] epoch #304 | Time 299.59 s\n",
      "2022-08-23 10:42:18 | [trpo_pendulum] epoch #304 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00034474\n",
      "Evaluation/AverageReturn                 -0.0037924\n",
      "Evaluation/Iteration                    304\n",
      "Evaluation/MaxReturn                     -0.00376314\n",
      "Evaluation/MinReturn                     -0.00382165\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.92586e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.83007\n",
      "GaussianMLPPolicy/KL                      2.68754e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               4.98698e-05\n",
      "GaussianMLPPolicy/LossBefore              4.99077e-05\n",
      "GaussianMLPPolicy/dLoss                   3.79077e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.58108\n",
      "GaussianMLPValueFunction/LossBefore      -6.66059\n",
      "GaussianMLPValueFunction/dLoss           -0.0795045\n",
      "TotalEnvSteps                        609390\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.0368e-06,  5.6567e-05, -2.7134e-07,  ...,  1.0635e-03,\n",
      "        -4.3255e-04,  1.2094e-03])\n",
      "G is: \n",
      "tensor([[1.7328e-05, 7.4449e+00],\n",
      "        [7.4449e+00, 3.1986e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [3198642.2500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:19 | [trpo_pendulum] epoch #305 | Saving snapshot...\n",
      "2022-08-23 10:42:19 | [trpo_pendulum] epoch #305 | Saved\n",
      "2022-08-23 10:42:19 | [trpo_pendulum] epoch #305 | Time 300.54 s\n",
      "2022-08-23 10:42:19 | [trpo_pendulum] epoch #305 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000310825\n",
      "Evaluation/AverageReturn                 -0.00337465\n",
      "Evaluation/Iteration                    305\n",
      "Evaluation/MaxReturn                     -0.003337\n",
      "Evaluation/MinReturn                     -0.0034123\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.76501e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.8346\n",
      "GaussianMLPPolicy/KL                      8.08676e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000151147\n",
      "GaussianMLPPolicy/LossBefore             -0.000151032\n",
      "GaussianMLPPolicy/dLoss                   1.14916e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.5565\n",
      "GaussianMLPValueFunction/LossBefore      -6.33026\n",
      "GaussianMLPValueFunction/dLoss            0.226244\n",
      "TotalEnvSteps                        611388\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.5992e-06,  1.1975e-04, -1.2606e-06,  ...,  2.2131e-03,\n",
      "        -9.0137e-04,  2.5169e-03])\n",
      "G is: \n",
      "tensor([[7.5039e-05, 3.2525e+01],\n",
      "        [3.2525e+01, 1.4098e+07]])\n",
      "eig is:\n",
      "tensor([[-1.0000e+00,  0.0000e+00],\n",
      "        [ 1.4098e+07,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(7.9383e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(7.9023e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:20 | [trpo_pendulum] epoch #306 | Saving snapshot...\n",
      "2022-08-23 10:42:20 | [trpo_pendulum] epoch #306 | Saved\n",
      "2022-08-23 10:42:20 | [trpo_pendulum] epoch #306 | Time 301.50 s\n",
      "2022-08-23 10:42:20 | [trpo_pendulum] epoch #306 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000330111\n",
      "Evaluation/AverageReturn                 -0.0039552\n",
      "Evaluation/Iteration                    306\n",
      "Evaluation/MaxReturn                     -0.00389445\n",
      "Evaluation/MinReturn                     -0.00401595\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.0751e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.83526\n",
      "GaussianMLPPolicy/KL                      0.000236367\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               7.90233e-05\n",
      "GaussianMLPPolicy/LossBefore              7.93827e-05\n",
      "GaussianMLPPolicy/dLoss                   3.59374e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.45942\n",
      "GaussianMLPValueFunction/LossBefore      -6.34766\n",
      "GaussianMLPValueFunction/dLoss            0.111762\n",
      "TotalEnvSteps                        613386\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.1778e-06, -3.0150e-05,  2.2022e-07,  ..., -4.9993e-04,\n",
      "         2.0513e-04, -5.6743e-04])\n",
      "G is: \n",
      "tensor([[3.8269e-06, 1.6609e+00],\n",
      "        [1.6609e+00, 7.2092e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [720918.1875,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:21 | [trpo_pendulum] epoch #307 | Saving snapshot...\n",
      "2022-08-23 10:42:21 | [trpo_pendulum] epoch #307 | Saved\n",
      "2022-08-23 10:42:21 | [trpo_pendulum] epoch #307 | Time 302.49 s\n",
      "2022-08-23 10:42:21 | [trpo_pendulum] epoch #307 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000325098\n",
      "Evaluation/AverageReturn                 -0.00346349\n",
      "Evaluation/Iteration                    307\n",
      "Evaluation/MaxReturn                     -0.00336264\n",
      "Evaluation/MinReturn                     -0.00356434\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000100853\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.83542\n",
      "GaussianMLPPolicy/KL                      1.85761e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000125979\n",
      "GaussianMLPPolicy/LossBefore             -0.000125953\n",
      "GaussianMLPPolicy/dLoss                   2.60334e-08\n",
      "GaussianMLPValueFunction/LossAfter       -5.43582\n",
      "GaussianMLPValueFunction/LossBefore      -6.37611\n",
      "GaussianMLPValueFunction/dLoss           -0.940293\n",
      "TotalEnvSteps                        615384\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.5520e-06,  7.1347e-05, -1.6999e-07,  ...,  1.0849e-03,\n",
      "        -4.4735e-04,  1.2297e-03])\n",
      "G is: \n",
      "tensor([[1.8015e-05, 7.8195e+00],\n",
      "        [7.8195e+00, 3.3948e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [3394810.,       0.]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:22 | [trpo_pendulum] epoch #308 | Saving snapshot...\n",
      "2022-08-23 10:42:22 | [trpo_pendulum] epoch #308 | Saved\n",
      "2022-08-23 10:42:22 | [trpo_pendulum] epoch #308 | Time 303.45 s\n",
      "2022-08-23 10:42:22 | [trpo_pendulum] epoch #308 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000372677\n",
      "Evaluation/AverageReturn                 -0.00376242\n",
      "Evaluation/Iteration                    308\n",
      "Evaluation/MaxReturn                     -0.0037348\n",
      "Evaluation/MinReturn                     -0.00379003\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.76128e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.83601\n",
      "GaussianMLPPolicy/KL                      0.000194126\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000248223\n",
      "GaussianMLPPolicy/LossBefore              0.000248505\n",
      "GaussianMLPPolicy/dLoss                   2.81841e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.63786\n",
      "GaussianMLPValueFunction/LossBefore      -5.5825\n",
      "GaussianMLPValueFunction/dLoss            1.05536\n",
      "TotalEnvSteps                        617382\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.8947e-06,  5.8888e-05,  1.3756e-07,  ...,  1.1060e-03,\n",
      "        -4.4955e-04,  1.2571e-03])\n",
      "G is: \n",
      "tensor([[1.8731e-05, 8.1435e+00],\n",
      "        [8.1435e+00, 3.5405e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [3540491.,       0.]])\n",
      "loss before is:\n",
      "tensor(2.4731e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(2.4671e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:23 | [trpo_pendulum] epoch #309 | Saving snapshot...\n",
      "2022-08-23 10:42:23 | [trpo_pendulum] epoch #309 | Saved\n",
      "2022-08-23 10:42:23 | [trpo_pendulum] epoch #309 | Time 304.54 s\n",
      "2022-08-23 10:42:23 | [trpo_pendulum] epoch #309 | EpochTime 1.09 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000374353\n",
      "Evaluation/AverageReturn                 -0.00355904\n",
      "Evaluation/Iteration                    309\n",
      "Evaluation/MaxReturn                     -0.00352388\n",
      "Evaluation/MinReturn                     -0.0035942\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.51594e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.83601\n",
      "GaussianMLPPolicy/KL                      4.28161e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               2.46707e-05\n",
      "GaussianMLPPolicy/LossBefore              2.47311e-05\n",
      "GaussianMLPPolicy/dLoss                   6.03959e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.72965\n",
      "GaussianMLPValueFunction/LossBefore      -6.70586\n",
      "GaussianMLPValueFunction/dLoss            0.0237913\n",
      "TotalEnvSteps                        619380\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.8013e-06,  6.3501e-05, -2.7567e-07,  ...,  1.1804e-03,\n",
      "        -4.8058e-04,  1.3417e-03])\n",
      "G is: \n",
      "tensor([[2.1336e-05, 9.2757e+00],\n",
      "        [9.2757e+00, 4.0326e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [4032585.,       0.]])\n",
      "loss before is:\n",
      "tensor(2.7286e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(2.7217e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:24 | [trpo_pendulum] epoch #310 | Saving snapshot...\n",
      "2022-08-23 10:42:24 | [trpo_pendulum] epoch #310 | Saved\n",
      "2022-08-23 10:42:24 | [trpo_pendulum] epoch #310 | Time 305.51 s\n",
      "2022-08-23 10:42:24 | [trpo_pendulum] epoch #310 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000360452\n",
      "Evaluation/AverageReturn                 -0.00354373\n",
      "Evaluation/Iteration                    310\n",
      "Evaluation/MaxReturn                     -0.00353509\n",
      "Evaluation/MinReturn                     -0.00355237\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.6386e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.83601\n",
      "GaussianMLPPolicy/KL                      4.87021e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               2.72166e-05\n",
      "GaussianMLPPolicy/LossBefore              2.72858e-05\n",
      "GaussianMLPPolicy/dLoss                   6.91398e-08\n",
      "GaussianMLPValueFunction/LossAfter       -5.83475\n",
      "GaussianMLPValueFunction/LossBefore      -6.67879\n",
      "GaussianMLPValueFunction/dLoss           -0.84404\n",
      "TotalEnvSteps                        621378\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.8165e-06,  1.7468e-05,  3.7323e-07,  ...,  2.9739e-04,\n",
      "        -1.2122e-04,  3.3737e-04])\n",
      "G is: \n",
      "tensor([[1.3533e-06, 5.8832e-01],\n",
      "        [5.8832e-01, 2.5578e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [255780.3438,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:25 | [trpo_pendulum] epoch #311 | Saving snapshot...\n",
      "2022-08-23 10:42:25 | [trpo_pendulum] epoch #311 | Saved\n",
      "2022-08-23 10:42:25 | [trpo_pendulum] epoch #311 | Time 306.48 s\n",
      "2022-08-23 10:42:25 | [trpo_pendulum] epoch #311 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000353429\n",
      "Evaluation/AverageReturn                 -0.00349434\n",
      "Evaluation/Iteration                    311\n",
      "Evaluation/MaxReturn                     -0.00326508\n",
      "Evaluation/MinReturn                     -0.0037236\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000229261\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.83601\n",
      "GaussianMLPPolicy/KL                      3.0805e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00018311\n",
      "GaussianMLPPolicy/LossBefore              0.000183114\n",
      "GaussianMLPPolicy/dLoss                   4.23461e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.57638\n",
      "GaussianMLPValueFunction/LossBefore      -6.1214\n",
      "GaussianMLPValueFunction/dLoss            0.454979\n",
      "TotalEnvSteps                        623376\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.3260e-06,  6.4640e-05,  9.4918e-08,  ...,  1.2206e-03,\n",
      "        -4.9610e-04,  1.3874e-03])\n",
      "G is: \n",
      "tensor([[2.2816e-05, 9.9201e+00],\n",
      "        [9.9201e+00, 4.3131e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [4313110.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:26 | [trpo_pendulum] epoch #312 | Saving snapshot...\n",
      "2022-08-23 10:42:26 | [trpo_pendulum] epoch #312 | Saved\n",
      "2022-08-23 10:42:26 | [trpo_pendulum] epoch #312 | Time 307.54 s\n",
      "2022-08-23 10:42:26 | [trpo_pendulum] epoch #312 | EpochTime 1.06 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000340315\n",
      "Evaluation/AverageReturn                 -0.0032154\n",
      "Evaluation/Iteration                    312\n",
      "Evaluation/MaxReturn                     -0.00317511\n",
      "Evaluation/MinReturn                     -0.00325569\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.02906e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.83601\n",
      "GaussianMLPPolicy/KL                      5.23195e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000150452\n",
      "GaussianMLPPolicy/LossBefore             -0.000150379\n",
      "GaussianMLPPolicy/dLoss                   7.35163e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.44256\n",
      "GaussianMLPValueFunction/LossBefore      -6.33196\n",
      "GaussianMLPValueFunction/dLoss            0.110601\n",
      "TotalEnvSteps                        625374\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.6610e-06, -5.3100e-05,  2.0717e-06,  ..., -8.9445e-04,\n",
      "         3.6902e-04, -1.0162e-03])\n",
      "G is: \n",
      "tensor([[1.2259e-05, 5.3280e+00],\n",
      "        [5.3280e+00, 2.3159e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [2315909.,       0.]])\n",
      "loss before is:\n",
      "tensor(9.5280e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(9.4886e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:27 | [trpo_pendulum] epoch #313 | Saving snapshot...\n",
      "2022-08-23 10:42:27 | [trpo_pendulum] epoch #313 | Saved\n",
      "2022-08-23 10:42:27 | [trpo_pendulum] epoch #313 | Time 308.52 s\n",
      "2022-08-23 10:42:27 | [trpo_pendulum] epoch #313 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000367523\n",
      "Evaluation/AverageReturn                 -0.00387438\n",
      "Evaluation/Iteration                    313\n",
      "Evaluation/MaxReturn                     -0.00379199\n",
      "Evaluation/MinReturn                     -0.00395677\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.23926e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.83545\n",
      "GaussianMLPPolicy/KL                      0.000292287\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               9.48861e-05\n",
      "GaussianMLPPolicy/LossBefore              9.52805e-05\n",
      "GaussianMLPPolicy/dLoss                   3.9435e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.42905\n",
      "GaussianMLPValueFunction/LossBefore      -6.21238\n",
      "GaussianMLPValueFunction/dLoss            0.216674\n",
      "TotalEnvSteps                        627372\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.5031e-06,  2.4669e-05,  7.7798e-07,  ...,  4.1464e-04,\n",
      "        -1.6867e-04,  4.7043e-04])\n",
      "G is: \n",
      "tensor([[2.6312e-06, 1.1427e+00],\n",
      "        [1.1427e+00, 4.9627e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [496271.2500,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:28 | [trpo_pendulum] epoch #314 | Saving snapshot...\n",
      "2022-08-23 10:42:28 | [trpo_pendulum] epoch #314 | Saved\n",
      "2022-08-23 10:42:28 | [trpo_pendulum] epoch #314 | Time 309.55 s\n",
      "2022-08-23 10:42:28 | [trpo_pendulum] epoch #314 | EpochTime 1.03 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000354943\n",
      "Evaluation/AverageReturn                 -0.00349559\n",
      "Evaluation/Iteration                    314\n",
      "Evaluation/MaxReturn                     -0.00349103\n",
      "Evaluation/MinReturn                     -0.00350015\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.55966e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.84007\n",
      "GaussianMLPPolicy/KL                      0.000155059\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000155579\n",
      "GaussianMLPPolicy/LossBefore             -0.000155384\n",
      "GaussianMLPPolicy/dLoss                   1.94734e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.7047\n",
      "GaussianMLPValueFunction/LossBefore      -6.29458\n",
      "GaussianMLPValueFunction/dLoss            0.41012\n",
      "TotalEnvSteps                        629370\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.5830e-06,  2.6564e-05,  3.3966e-09,  ...,  4.7243e-04,\n",
      "        -1.9248e-04,  5.3719e-04])\n",
      "G is: \n",
      "tensor([[3.4217e-06, 1.5003e+00],\n",
      "        [1.5003e+00, 6.5784e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [657842.8750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(5.8232e-07, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(5.7132e-07, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:29 | [trpo_pendulum] epoch #315 | Saving snapshot...\n",
      "2022-08-23 10:42:29 | [trpo_pendulum] epoch #315 | Saved\n",
      "2022-08-23 10:42:29 | [trpo_pendulum] epoch #315 | Time 310.50 s\n",
      "2022-08-23 10:42:29 | [trpo_pendulum] epoch #315 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000317916\n",
      "Evaluation/AverageReturn                 -0.00326379\n",
      "Evaluation/Iteration                    315\n",
      "Evaluation/MaxReturn                     -0.00324266\n",
      "Evaluation/MinReturn                     -0.00328492\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.11305e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.84007\n",
      "GaussianMLPPolicy/KL                      7.82867e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               5.71318e-07\n",
      "GaussianMLPPolicy/LossBefore              5.82324e-07\n",
      "GaussianMLPPolicy/dLoss                   1.1006e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.75234\n",
      "GaussianMLPValueFunction/LossBefore      -6.75445\n",
      "GaussianMLPValueFunction/dLoss           -0.00211191\n",
      "TotalEnvSteps                        631368\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.9017e-06,  2.1554e-05, -2.5950e-09,  ...,  3.8375e-04,\n",
      "        -1.5634e-04,  4.3635e-04])\n",
      "G is: \n",
      "tensor([[2.2576e-06, 9.8990e-01],\n",
      "        [9.8990e-01, 4.3405e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [434045.5625,      0.0000]])\n",
      "loss before is:\n",
      "tensor(1.9321e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(1.9314e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:30 | [trpo_pendulum] epoch #316 | Saving snapshot...\n",
      "2022-08-23 10:42:30 | [trpo_pendulum] epoch #316 | Saved\n",
      "2022-08-23 10:42:30 | [trpo_pendulum] epoch #316 | Time 311.51 s\n",
      "2022-08-23 10:42:30 | [trpo_pendulum] epoch #316 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000363105\n",
      "Evaluation/AverageReturn                 -0.00320123\n",
      "Evaluation/Iteration                    316\n",
      "Evaluation/MaxReturn                     -0.00313139\n",
      "Evaluation/MinReturn                     -0.00327107\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.98395e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.84007\n",
      "GaussianMLPPolicy/KL                      5.16702e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               1.9314e-05\n",
      "GaussianMLPPolicy/LossBefore              1.93213e-05\n",
      "GaussianMLPPolicy/dLoss                   7.25777e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.66001\n",
      "GaussianMLPValueFunction/LossBefore      -6.75637\n",
      "GaussianMLPValueFunction/dLoss           -0.0963607\n",
      "TotalEnvSteps                        633366\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.2391e-06,  2.4061e-05,  1.0490e-07,  ...,  4.2654e-04,\n",
      "        -1.7368e-04,  4.8494e-04])\n",
      "G is: \n",
      "tensor([[2.7888e-06, 1.2228e+00],\n",
      "        [1.2228e+00, 5.3612e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [536124.8750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-4.1020e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-4.1029e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:31 | [trpo_pendulum] epoch #317 | Saving snapshot...\n",
      "2022-08-23 10:42:31 | [trpo_pendulum] epoch #317 | Saved\n",
      "2022-08-23 10:42:31 | [trpo_pendulum] epoch #317 | Time 312.45 s\n",
      "2022-08-23 10:42:31 | [trpo_pendulum] epoch #317 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000369028\n",
      "Evaluation/AverageReturn                 -0.00368148\n",
      "Evaluation/Iteration                    317\n",
      "Evaluation/MaxReturn                     -0.00340774\n",
      "Evaluation/MinReturn                     -0.00395522\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000273741\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.84007\n",
      "GaussianMLPPolicy/KL                      6.34345e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.10293e-05\n",
      "GaussianMLPPolicy/LossBefore             -4.10203e-05\n",
      "GaussianMLPPolicy/dLoss                   8.96762e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.72125\n",
      "GaussianMLPValueFunction/LossBefore      -6.72498\n",
      "GaussianMLPValueFunction/dLoss           -0.00373268\n",
      "TotalEnvSteps                        635364\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.0373e-05,  6.5101e-05, -7.1757e-08,  ...,  1.1447e-03,\n",
      "        -4.6681e-04,  1.3014e-03])\n",
      "G is: \n",
      "tensor([[2.0088e-05, 8.8082e+00],\n",
      "        [8.8082e+00, 3.8622e+06]])\n",
      "eig is:\n",
      "tensor([[-2.5000e-01,  0.0000e+00],\n",
      "        [ 3.8622e+06,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-7.3794e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-7.3935e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:32 | [trpo_pendulum] epoch #318 | Saving snapshot...\n",
      "2022-08-23 10:42:32 | [trpo_pendulum] epoch #318 | Saved\n",
      "2022-08-23 10:42:32 | [trpo_pendulum] epoch #318 | Time 313.46 s\n",
      "2022-08-23 10:42:32 | [trpo_pendulum] epoch #318 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000318006\n",
      "Evaluation/AverageReturn                 -0.00305529\n",
      "Evaluation/Iteration                    318\n",
      "Evaluation/MaxReturn                     -0.00282294\n",
      "Evaluation/MinReturn                     -0.00328765\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000232353\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.84728\n",
      "GaussianMLPPolicy/KL                      9.92777e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.39355e-05\n",
      "GaussianMLPPolicy/LossBefore             -7.3794e-05\n",
      "GaussianMLPPolicy/dLoss                   1.41452e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.58547\n",
      "GaussianMLPValueFunction/LossBefore      -6.65991\n",
      "GaussianMLPValueFunction/dLoss           -1.07443\n",
      "TotalEnvSteps                        637362\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.5056e-06,  2.1838e-04, -4.3966e-07,  ...,  3.4785e-03,\n",
      "        -1.4283e-03,  3.9490e-03])\n",
      "G is: \n",
      "tensor([[1.8543e-04, 8.2476e+01],\n",
      "        [8.2476e+01, 3.6686e+07]])\n",
      "eig is:\n",
      "tensor([[4.0000e+00, 0.0000e+00],\n",
      "        [3.6686e+07, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:33 | [trpo_pendulum] epoch #319 | Saving snapshot...\n",
      "2022-08-23 10:42:33 | [trpo_pendulum] epoch #319 | Saved\n",
      "2022-08-23 10:42:33 | [trpo_pendulum] epoch #319 | Time 314.46 s\n",
      "2022-08-23 10:42:33 | [trpo_pendulum] epoch #319 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000378324\n",
      "Evaluation/AverageReturn                 -0.00358924\n",
      "Evaluation/Iteration                    319\n",
      "Evaluation/MaxReturn                     -0.00331622\n",
      "Evaluation/MinReturn                     -0.00386227\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000273029\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.85387\n",
      "GaussianMLPPolicy/KL                      0.000668931\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000340222\n",
      "GaussianMLPPolicy/LossBefore              0.000341263\n",
      "GaussianMLPPolicy/dLoss                   1.0409e-06\n",
      "GaussianMLPValueFunction/LossAfter       -6.645\n",
      "GaussianMLPValueFunction/LossBefore      -4.49358\n",
      "GaussianMLPValueFunction/dLoss            2.15142\n",
      "TotalEnvSteps                        639360\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.2613e-06,  2.2506e-05, -7.9947e-08,  ...,  4.0144e-04,\n",
      "        -1.6389e-04,  4.5625e-04])\n",
      "G is: \n",
      "tensor([[2.4697e-06, 1.1132e+00],\n",
      "        [1.1132e+00, 5.0179e+05]])\n",
      "eig is:\n",
      "tensor([[3.1250e-02, 0.0000e+00],\n",
      "        [5.0179e+05, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-3.7368e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-3.7376e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:34 | [trpo_pendulum] epoch #320 | Saving snapshot...\n",
      "2022-08-23 10:42:34 | [trpo_pendulum] epoch #320 | Saved\n",
      "2022-08-23 10:42:34 | [trpo_pendulum] epoch #320 | Time 315.44 s\n",
      "2022-08-23 10:42:34 | [trpo_pendulum] epoch #320 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000304205\n",
      "Evaluation/AverageReturn                 -0.00297855\n",
      "Evaluation/Iteration                    320\n",
      "Evaluation/MaxReturn                     -0.0028762\n",
      "Evaluation/MinReturn                     -0.00308089\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000102346\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.85387\n",
      "GaussianMLPPolicy/KL                      5.47441e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.73762e-05\n",
      "GaussianMLPPolicy/LossBefore             -3.73685e-05\n",
      "GaussianMLPPolicy/dLoss                   7.73434e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.75673\n",
      "GaussianMLPValueFunction/LossBefore      -6.74237\n",
      "GaussianMLPValueFunction/dLoss            0.0143595\n",
      "TotalEnvSteps                        641358\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.3222e-06,  3.2834e-05,  4.7004e-08,  ...,  5.8054e-04,\n",
      "        -2.3692e-04,  6.5965e-04])\n",
      "G is: \n",
      "tensor([[5.1641e-06, 2.3277e+00],\n",
      "        [2.3277e+00, 1.0492e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1049173.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(4.2865e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(4.2849e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:35 | [trpo_pendulum] epoch #321 | Saving snapshot...\n",
      "2022-08-23 10:42:35 | [trpo_pendulum] epoch #321 | Saved\n",
      "2022-08-23 10:42:35 | [trpo_pendulum] epoch #321 | Time 316.38 s\n",
      "2022-08-23 10:42:35 | [trpo_pendulum] epoch #321 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000295428\n",
      "Evaluation/AverageReturn                 -0.00323256\n",
      "Evaluation/Iteration                    321\n",
      "Evaluation/MaxReturn                     -0.00322789\n",
      "Evaluation/MinReturn                     -0.00323723\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.66909e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.85387\n",
      "GaussianMLPPolicy/KL                      1.14195e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               4.28488e-05\n",
      "GaussianMLPPolicy/LossBefore              4.2865e-05\n",
      "GaussianMLPPolicy/dLoss                   1.61563e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.46864\n",
      "GaussianMLPValueFunction/LossBefore      -6.73131\n",
      "GaussianMLPValueFunction/dLoss           -0.262671\n",
      "TotalEnvSteps                        643356\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.0845e-06,  4.8010e-05, -6.3775e-09,  ...,  8.7985e-04,\n",
      "        -3.5836e-04,  1.0003e-03])\n",
      "G is: \n",
      "tensor([[1.1863e-05, 5.3476e+00],\n",
      "        [5.3476e+00, 2.4105e+06]])\n",
      "eig is:\n",
      "tensor([[2.5000e-01, 0.0000e+00],\n",
      "        [2.4105e+06, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:36 | [trpo_pendulum] epoch #322 | Saving snapshot...\n",
      "2022-08-23 10:42:36 | [trpo_pendulum] epoch #322 | Saved\n",
      "2022-08-23 10:42:36 | [trpo_pendulum] epoch #322 | Time 317.36 s\n",
      "2022-08-23 10:42:36 | [trpo_pendulum] epoch #322 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00031889\n",
      "Evaluation/AverageReturn                 -0.00321076\n",
      "Evaluation/Iteration                    322\n",
      "Evaluation/MaxReturn                     -0.0031659\n",
      "Evaluation/MinReturn                     -0.00325562\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.48582e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.85387\n",
      "GaussianMLPPolicy/KL                      2.62265e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00011765\n",
      "GaussianMLPPolicy/LossBefore              0.000117687\n",
      "GaussianMLPPolicy/dLoss                   3.70346e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.39023\n",
      "GaussianMLPValueFunction/LossBefore      -6.51019\n",
      "GaussianMLPValueFunction/dLoss           -0.119957\n",
      "TotalEnvSteps                        645354\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.1012e-05,  6.7202e-05,  3.6416e-07,  ...,  1.2587e-03,\n",
      "        -5.1135e-04,  1.4315e-03])\n",
      "G is: \n",
      "tensor([[2.4279e-05, 1.0943e+01],\n",
      "        [1.0943e+01, 4.9322e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [4932240.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:37 | [trpo_pendulum] epoch #323 | Saving snapshot...\n",
      "2022-08-23 10:42:37 | [trpo_pendulum] epoch #323 | Saved\n",
      "2022-08-23 10:42:37 | [trpo_pendulum] epoch #323 | Time 318.36 s\n",
      "2022-08-23 10:42:37 | [trpo_pendulum] epoch #323 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000313444\n",
      "Evaluation/AverageReturn                 -0.00322172\n",
      "Evaluation/Iteration                    323\n",
      "Evaluation/MaxReturn                     -0.00318808\n",
      "Evaluation/MinReturn                     -0.00325537\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.36428e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.84618\n",
      "GaussianMLPPolicy/KL                      0.000122011\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000223458\n",
      "GaussianMLPPolicy/LossBefore              0.00022364\n",
      "GaussianMLPPolicy/dLoss                   1.8187e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.26128\n",
      "GaussianMLPValueFunction/LossBefore      -5.74016\n",
      "GaussianMLPValueFunction/dLoss            0.521112\n",
      "TotalEnvSteps                        647352\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.1975e-05,  2.4944e-05,  2.6002e-07,  ...,  4.3277e-04,\n",
      "        -1.7646e-04,  4.9161e-04])\n",
      "G is: \n",
      "tensor([[2.8695e-06, 1.2737e+00],\n",
      "        [1.2737e+00, 5.6536e+05]])\n",
      "eig is:\n",
      "tensor([[6.2500e-02, 0.0000e+00],\n",
      "        [5.6536e+05, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:38 | [trpo_pendulum] epoch #324 | Saving snapshot...\n",
      "2022-08-23 10:42:38 | [trpo_pendulum] epoch #324 | Saved\n",
      "2022-08-23 10:42:38 | [trpo_pendulum] epoch #324 | Time 319.32 s\n",
      "2022-08-23 10:42:38 | [trpo_pendulum] epoch #324 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000353268\n",
      "Evaluation/AverageReturn                 -0.00321125\n",
      "Evaluation/Iteration                    324\n",
      "Evaluation/MaxReturn                     -0.00315247\n",
      "Evaluation/MinReturn                     -0.00327004\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.87842e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.85507\n",
      "GaussianMLPPolicy/KL                      9.00225e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000205468\n",
      "GaussianMLPPolicy/LossBefore             -0.000205343\n",
      "GaussianMLPPolicy/dLoss                   1.25263e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.73071\n",
      "GaussianMLPValueFunction/LossBefore      -5.94921\n",
      "GaussianMLPValueFunction/dLoss            0.781495\n",
      "TotalEnvSteps                        649350\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.3396e-05,  5.0399e-05, -1.2659e-06,  ...,  1.2667e-03,\n",
      "        -5.0827e-04,  1.4468e-03])\n",
      "G is: \n",
      "tensor([[2.4629e-05, 1.1123e+01],\n",
      "        [1.1123e+01, 5.0254e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [5025375.,       0.]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:38 | [trpo_pendulum] epoch #325 | Saving snapshot...\n",
      "2022-08-23 10:42:39 | [trpo_pendulum] epoch #325 | Saved\n",
      "2022-08-23 10:42:39 | [trpo_pendulum] epoch #325 | Time 320.31 s\n",
      "2022-08-23 10:42:39 | [trpo_pendulum] epoch #325 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000384312\n",
      "Evaluation/AverageReturn                 -0.00373789\n",
      "Evaluation/Iteration                    325\n",
      "Evaluation/MaxReturn                     -0.00371779\n",
      "Evaluation/MinReturn                     -0.00375799\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.01002e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.86061\n",
      "GaussianMLPPolicy/KL                      0.000320055\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000202061\n",
      "GaussianMLPPolicy/LossBefore              0.000202524\n",
      "GaussianMLPPolicy/dLoss                   4.62955e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.52185\n",
      "GaussianMLPValueFunction/LossBefore      -5.70782\n",
      "GaussianMLPValueFunction/dLoss            0.814028\n",
      "TotalEnvSteps                        651348\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.0753e-05,  1.5668e-05,  7.1197e-09,  ...,  2.8151e-04,\n",
      "        -1.1475e-04,  3.1996e-04])\n",
      "G is: \n",
      "tensor([[1.2144e-06, 5.5472e-01],\n",
      "        [5.5472e-01, 2.5342e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [253422.4375,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:39 | [trpo_pendulum] epoch #326 | Saving snapshot...\n",
      "2022-08-23 10:42:40 | [trpo_pendulum] epoch #326 | Saved\n",
      "2022-08-23 10:42:40 | [trpo_pendulum] epoch #326 | Time 321.31 s\n",
      "2022-08-23 10:42:40 | [trpo_pendulum] epoch #326 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000337726\n",
      "Evaluation/AverageReturn                 -0.00320721\n",
      "Evaluation/Iteration                    326\n",
      "Evaluation/MaxReturn                     -0.00306382\n",
      "Evaluation/MinReturn                     -0.0033506\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000143389\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.853\n",
      "GaussianMLPPolicy/KL                      6.02663e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000204526\n",
      "GaussianMLPPolicy/LossBefore             -0.000204438\n",
      "GaussianMLPPolicy/dLoss                   8.73843e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.57146\n",
      "GaussianMLPValueFunction/LossBefore      -5.97965\n",
      "GaussianMLPValueFunction/dLoss            0.591808\n",
      "TotalEnvSteps                        653346\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.4331e-07, -2.7482e-05,  1.1523e-07,  ..., -8.0055e-04,\n",
      "         3.1834e-04, -9.1511e-04])\n",
      "G is: \n",
      "tensor([[9.8370e-06, 4.4229e+00],\n",
      "        [4.4229e+00, 1.9897e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1989748.7500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:40 | [trpo_pendulum] epoch #327 | Saving snapshot...\n",
      "2022-08-23 10:42:40 | [trpo_pendulum] epoch #327 | Saved\n",
      "2022-08-23 10:42:40 | [trpo_pendulum] epoch #327 | Time 322.28 s\n",
      "2022-08-23 10:42:40 | [trpo_pendulum] epoch #327 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000294288\n",
      "Evaluation/AverageReturn                 -0.00342006\n",
      "Evaluation/Iteration                    327\n",
      "Evaluation/MaxReturn                     -0.00335273\n",
      "Evaluation/MinReturn                     -0.00348739\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.73301e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.85302\n",
      "GaussianMLPPolicy/KL                      0.000147208\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000233247\n",
      "GaussianMLPPolicy/LossBefore              0.000233455\n",
      "GaussianMLPPolicy/dLoss                   2.08616e-07\n",
      "GaussianMLPValueFunction/LossAfter       -4.20342\n",
      "GaussianMLPValueFunction/LossBefore      -5.57128\n",
      "GaussianMLPValueFunction/dLoss           -1.36786\n",
      "TotalEnvSteps                        655344\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.7788e-06,  1.4710e-04,  4.1250e-07,  ...,  2.4143e-03,\n",
      "        -9.9010e-04,  2.7399e-03])\n",
      "G is: \n",
      "tensor([[8.9276e-05, 4.0170e+01],\n",
      "        [4.0170e+01, 1.8075e+07]])\n",
      "eig is:\n",
      "tensor([[       0.,        0.],\n",
      "        [18075170.,        0.]])\n",
      "loss before is:\n",
      "tensor(-0.0004, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0004, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:41 | [trpo_pendulum] epoch #328 | Saving snapshot...\n",
      "2022-08-23 10:42:41 | [trpo_pendulum] epoch #328 | Saved\n",
      "2022-08-23 10:42:41 | [trpo_pendulum] epoch #328 | Time 323.28 s\n",
      "2022-08-23 10:42:41 | [trpo_pendulum] epoch #328 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000297286\n",
      "Evaluation/AverageReturn                 -0.00313821\n",
      "Evaluation/Iteration                    328\n",
      "Evaluation/MaxReturn                     -0.0030388\n",
      "Evaluation/MinReturn                     -0.00323761\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      9.94055e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.85919\n",
      "GaussianMLPPolicy/KL                      0.000454578\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000439698\n",
      "GaussianMLPPolicy/LossBefore             -0.000439049\n",
      "GaussianMLPPolicy/dLoss                   6.48899e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.72389\n",
      "GaussianMLPValueFunction/LossBefore      -3.14645\n",
      "GaussianMLPValueFunction/dLoss            3.57744\n",
      "TotalEnvSteps                        657342\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.1462e-06,  4.5571e-05, -1.0660e-07,  ...,  8.4528e-04,\n",
      "        -3.4425e-04,  9.6126e-04])\n",
      "G is: \n",
      "tensor([[1.0950e-05, 4.9890e+00],\n",
      "        [4.9890e+00, 2.2731e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [2273080.,       0.]])\n",
      "loss before is:\n",
      "tensor(2.0470e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(2.0437e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:42 | [trpo_pendulum] epoch #329 | Saving snapshot...\n",
      "2022-08-23 10:42:42 | [trpo_pendulum] epoch #329 | Saved\n",
      "2022-08-23 10:42:42 | [trpo_pendulum] epoch #329 | Time 324.23 s\n",
      "2022-08-23 10:42:42 | [trpo_pendulum] epoch #329 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000312436\n",
      "Evaluation/AverageReturn                 -0.00337611\n",
      "Evaluation/Iteration                    329\n",
      "Evaluation/MaxReturn                     -0.00330026\n",
      "Evaluation/MinReturn                     -0.00345197\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.58566e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.85919\n",
      "GaussianMLPPolicy/KL                      2.39767e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               2.04368e-05\n",
      "GaussianMLPPolicy/LossBefore              2.04705e-05\n",
      "GaussianMLPPolicy/dLoss                   3.37113e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.62965\n",
      "GaussianMLPValueFunction/LossBefore      -6.68005\n",
      "GaussianMLPValueFunction/dLoss           -0.0504003\n",
      "TotalEnvSteps                        659340\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.2615e-05,  8.0848e-05,  1.9281e-07,  ...,  1.4404e-03,\n",
      "        -5.8791e-04,  1.6366e-03])\n",
      "G is: \n",
      "tensor([[3.1792e-05, 1.4485e+01],\n",
      "        [1.4485e+01, 6.5997e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [6599715.,       0.]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:43 | [trpo_pendulum] epoch #330 | Saving snapshot...\n",
      "2022-08-23 10:42:43 | [trpo_pendulum] epoch #330 | Saved\n",
      "2022-08-23 10:42:43 | [trpo_pendulum] epoch #330 | Time 325.19 s\n",
      "2022-08-23 10:42:43 | [trpo_pendulum] epoch #330 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000236199\n",
      "Evaluation/AverageReturn                 -0.00284312\n",
      "Evaluation/Iteration                    330\n",
      "Evaluation/MaxReturn                     -0.00279698\n",
      "Evaluation/MinReturn                     -0.00288927\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.61424e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.86829\n",
      "GaussianMLPPolicy/KL                      0.000161135\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000133065\n",
      "GaussianMLPPolicy/LossBefore             -0.000132839\n",
      "GaussianMLPPolicy/dLoss                   2.25336e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.67048\n",
      "GaussianMLPValueFunction/LossBefore      -6.42649\n",
      "GaussianMLPValueFunction/dLoss            0.243985\n",
      "TotalEnvSteps                        661338\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.0368e-06,  1.5085e-05, -2.5880e-07,  ...,  2.5675e-04,\n",
      "        -1.0550e-04,  2.9167e-04])\n",
      "G is: \n",
      "tensor([[1.0106e-06, 4.6894e-01],\n",
      "        [4.6894e-01, 2.1761e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [217610.9688,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:44 | [trpo_pendulum] epoch #331 | Saving snapshot...\n",
      "2022-08-23 10:42:44 | [trpo_pendulum] epoch #331 | Saved\n",
      "2022-08-23 10:42:44 | [trpo_pendulum] epoch #331 | Time 326.18 s\n",
      "2022-08-23 10:42:44 | [trpo_pendulum] epoch #331 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000300269\n",
      "Evaluation/AverageReturn                 -0.00313989\n",
      "Evaluation/Iteration                    331\n",
      "Evaluation/MaxReturn                     -0.0030222\n",
      "Evaluation/MinReturn                     -0.00325758\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000117689\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.86829\n",
      "GaussianMLPPolicy/KL                      2.16814e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000105527\n",
      "GaussianMLPPolicy/LossBefore              0.00010553\n",
      "GaussianMLPPolicy/dLoss                   3.01225e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.68294\n",
      "GaussianMLPValueFunction/LossBefore      -6.52988\n",
      "GaussianMLPValueFunction/dLoss            0.153062\n",
      "TotalEnvSteps                        663336\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.6462e-06, -7.0115e-05, -3.8090e-07,  ..., -7.3465e-04,\n",
      "         3.1328e-04, -8.2594e-04])\n",
      "G is: \n",
      "tensor([[8.2700e-06, 3.8289e+00],\n",
      "        [3.8289e+00, 1.7765e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1776514.2500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:45 | [trpo_pendulum] epoch #332 | Saving snapshot...\n",
      "2022-08-23 10:42:45 | [trpo_pendulum] epoch #332 | Saved\n",
      "2022-08-23 10:42:45 | [trpo_pendulum] epoch #332 | Time 327.12 s\n",
      "2022-08-23 10:42:45 | [trpo_pendulum] epoch #332 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000328955\n",
      "Evaluation/AverageReturn                 -0.00339793\n",
      "Evaluation/Iteration                    332\n",
      "Evaluation/MaxReturn                     -0.00327238\n",
      "Evaluation/MinReturn                     -0.00352347\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000125545\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.86833\n",
      "GaussianMLPPolicy/KL                      0.000292099\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000157398\n",
      "GaussianMLPPolicy/LossBefore              0.000157815\n",
      "GaussianMLPPolicy/dLoss                   4.17363e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.4188\n",
      "GaussianMLPValueFunction/LossBefore      -6.09283\n",
      "GaussianMLPValueFunction/dLoss            0.325963\n",
      "TotalEnvSteps                        665334\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-3.2140e-06,  1.2932e-05,  1.9027e-07,  ...,  2.8951e-04,\n",
      "        -1.1636e-04,  3.2991e-04])\n",
      "G is: \n",
      "tensor([[1.2853e-06, 5.9628e-01],\n",
      "        [5.9628e-01, 2.7667e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [276666.0625,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-3.8424e-06, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-3.8592e-06, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:46 | [trpo_pendulum] epoch #333 | Saving snapshot...\n",
      "2022-08-23 10:42:46 | [trpo_pendulum] epoch #333 | Saved\n",
      "2022-08-23 10:42:46 | [trpo_pendulum] epoch #333 | Time 328.08 s\n",
      "2022-08-23 10:42:46 | [trpo_pendulum] epoch #333 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000303051\n",
      "Evaluation/AverageReturn                 -0.00305699\n",
      "Evaluation/Iteration                    333\n",
      "Evaluation/MaxReturn                     -0.00301152\n",
      "Evaluation/MinReturn                     -0.00310246\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.54718e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.86814\n",
      "GaussianMLPPolicy/KL                      1.1665e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.85917e-06\n",
      "GaussianMLPPolicy/LossBefore             -3.84236e-06\n",
      "GaussianMLPPolicy/dLoss                   1.6817e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.59164\n",
      "GaussianMLPValueFunction/LossBefore      -6.70941\n",
      "GaussianMLPValueFunction/dLoss           -0.117775\n",
      "TotalEnvSteps                        667332\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.1960e-05, -8.7859e-06, -7.2152e-08,  ..., -2.2521e-04,\n",
      "         9.0009e-05, -2.5706e-04])\n",
      "G is: \n",
      "tensor([[7.7849e-07, 3.6089e-01],\n",
      "        [3.6089e-01, 1.6739e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [167386.9688,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-9.8361e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-9.8482e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:47 | [trpo_pendulum] epoch #334 | Saving snapshot...\n",
      "2022-08-23 10:42:47 | [trpo_pendulum] epoch #334 | Saved\n",
      "2022-08-23 10:42:47 | [trpo_pendulum] epoch #334 | Time 329.18 s\n",
      "2022-08-23 10:42:47 | [trpo_pendulum] epoch #334 | EpochTime 1.10 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000298708\n",
      "Evaluation/AverageReturn                 -0.00303162\n",
      "Evaluation/Iteration                    334\n",
      "Evaluation/MaxReturn                     -0.0029004\n",
      "Evaluation/MinReturn                     -0.00316285\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000131225\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.87657\n",
      "GaussianMLPPolicy/KL                      8.67913e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -9.84821e-05\n",
      "GaussianMLPPolicy/LossBefore             -9.83615e-05\n",
      "GaussianMLPPolicy/dLoss                   1.20599e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.5417\n",
      "GaussianMLPValueFunction/LossBefore      -6.56137\n",
      "GaussianMLPValueFunction/dLoss           -0.0196743\n",
      "TotalEnvSteps                        669330\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.2141e-05,  3.6713e-05, -3.1902e-08,  ...,  6.5087e-04,\n",
      "        -2.6578e-04,  7.3967e-04])\n",
      "G is: \n",
      "tensor([[6.4929e-06, 3.0632e+00],\n",
      "        [3.0632e+00, 1.4452e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [1445201.,       0.]])\n",
      "loss before is:\n",
      "tensor(7.0712e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(7.0587e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:48 | [trpo_pendulum] epoch #335 | Saving snapshot...\n",
      "2022-08-23 10:42:48 | [trpo_pendulum] epoch #335 | Saved\n",
      "2022-08-23 10:42:48 | [trpo_pendulum] epoch #335 | Time 330.16 s\n",
      "2022-08-23 10:42:48 | [trpo_pendulum] epoch #335 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000332261\n",
      "Evaluation/AverageReturn                 -0.00326924\n",
      "Evaluation/Iteration                    335\n",
      "Evaluation/MaxReturn                     -0.00317688\n",
      "Evaluation/MinReturn                     -0.00336159\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      9.23578e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.88479\n",
      "GaussianMLPPolicy/KL                      8.82774e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               7.05866e-05\n",
      "GaussianMLPPolicy/LossBefore              7.07119e-05\n",
      "GaussianMLPPolicy/dLoss                   1.2527e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.77488\n",
      "GaussianMLPValueFunction/LossBefore      -6.67639\n",
      "GaussianMLPValueFunction/dLoss            0.0984898\n",
      "TotalEnvSteps                        671328\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.0820e-06,  1.2591e-05, -2.2831e-08,  ...,  2.3097e-04,\n",
      "        -9.4155e-05,  2.6260e-04])\n",
      "G is: \n",
      "tensor([[8.1766e-07, 3.9215e-01],\n",
      "        [3.9215e-01, 1.8807e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [188074.3125,      0.0000]])\n",
      "loss before is:\n",
      "tensor(4.0950e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(4.0948e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:49 | [trpo_pendulum] epoch #336 | Saving snapshot...\n",
      "2022-08-23 10:42:49 | [trpo_pendulum] epoch #336 | Saved\n",
      "2022-08-23 10:42:49 | [trpo_pendulum] epoch #336 | Time 331.11 s\n",
      "2022-08-23 10:42:49 | [trpo_pendulum] epoch #336 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000275091\n",
      "Evaluation/AverageReturn                 -0.00295099\n",
      "Evaluation/Iteration                    336\n",
      "Evaluation/MaxReturn                     -0.0029417\n",
      "Evaluation/MinReturn                     -0.00296027\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      9.28586e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.88479\n",
      "GaussianMLPPolicy/KL                      1.68325e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               4.09475e-05\n",
      "GaussianMLPPolicy/LossBefore              4.095e-05\n",
      "GaussianMLPPolicy/dLoss                   2.46291e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.57884\n",
      "GaussianMLPValueFunction/LossBefore      -6.71471\n",
      "GaussianMLPValueFunction/dLoss           -0.135865\n",
      "TotalEnvSteps                        673326\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-6.2883e-07,  2.6037e-05, -1.3874e-07,  ...,  4.7486e-04,\n",
      "        -1.9380e-04,  5.3985e-04])\n",
      "G is: \n",
      "tensor([[3.4565e-06, 1.6578e+00],\n",
      "        [1.6578e+00, 7.9516e+05]])\n",
      "eig is:\n",
      "tensor([[     0.,      0.],\n",
      "        [795161.,      0.]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:50 | [trpo_pendulum] epoch #337 | Saving snapshot...\n",
      "2022-08-23 10:42:50 | [trpo_pendulum] epoch #337 | Saved\n",
      "2022-08-23 10:42:50 | [trpo_pendulum] epoch #337 | Time 332.06 s\n",
      "2022-08-23 10:42:50 | [trpo_pendulum] epoch #337 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000273719\n",
      "Evaluation/AverageReturn                 -0.00289152\n",
      "Evaluation/Iteration                    337\n",
      "Evaluation/MaxReturn                     -0.00281995\n",
      "Evaluation/MinReturn                     -0.00296308\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.15662e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.88479\n",
      "GaussianMLPPolicy/KL                      7.18534e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000148449\n",
      "GaussianMLPPolicy/LossBefore             -0.000148439\n",
      "GaussianMLPPolicy/dLoss                   1.00263e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.68741\n",
      "GaussianMLPValueFunction/LossBefore      -6.3491\n",
      "GaussianMLPValueFunction/dLoss            0.338313\n",
      "TotalEnvSteps                        675324\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.3487e-06,  4.8761e-05,  8.4450e-08,  ...,  9.0911e-04,\n",
      "        -3.7005e-04,  1.0337e-03])\n",
      "G is: \n",
      "tensor([[1.2668e-05, 6.0748e+00],\n",
      "        [6.0748e+00, 2.9132e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [2913246.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-2.8320e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-2.8357e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:51 | [trpo_pendulum] epoch #338 | Saving snapshot...\n",
      "2022-08-23 10:42:51 | [trpo_pendulum] epoch #338 | Saved\n",
      "2022-08-23 10:42:51 | [trpo_pendulum] epoch #338 | Time 333.07 s\n",
      "2022-08-23 10:42:51 | [trpo_pendulum] epoch #338 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000331294\n",
      "Evaluation/AverageReturn                 -0.00296126\n",
      "Evaluation/Iteration                    338\n",
      "Evaluation/MaxReturn                     -0.00287299\n",
      "Evaluation/MinReturn                     -0.00304954\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.82772e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.88479\n",
      "GaussianMLPPolicy/KL                      2.64086e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -2.83573e-05\n",
      "GaussianMLPPolicy/LossBefore             -2.83202e-05\n",
      "GaussianMLPPolicy/dLoss                   3.71674e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.69396\n",
      "GaussianMLPValueFunction/LossBefore      -6.75248\n",
      "GaussianMLPValueFunction/dLoss           -0.0585213\n",
      "TotalEnvSteps                        677322\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.2150e-06, -1.1762e-05, -8.3011e-08,  ..., -2.4486e-04,\n",
      "         9.8932e-05, -2.7880e-04])\n",
      "G is: \n",
      "tensor([[9.1925e-07, 4.4080e-01],\n",
      "        [4.4080e-01, 2.1140e+05]])\n",
      "eig is:\n",
      "tensor([[1.5625e-02, 0.0000e+00],\n",
      "        [2.1140e+05, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-7.6363e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-7.6384e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:52 | [trpo_pendulum] epoch #339 | Saving snapshot...\n",
      "2022-08-23 10:42:52 | [trpo_pendulum] epoch #339 | Saved\n",
      "2022-08-23 10:42:52 | [trpo_pendulum] epoch #339 | Time 334.09 s\n",
      "2022-08-23 10:42:52 | [trpo_pendulum] epoch #339 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000305537\n",
      "Evaluation/AverageReturn                 -0.00293578\n",
      "Evaluation/Iteration                    339\n",
      "Evaluation/MaxReturn                     -0.00291353\n",
      "Evaluation/MinReturn                     -0.00295802\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.22438e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.88595\n",
      "GaussianMLPPolicy/KL                      1.49382e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.63838e-05\n",
      "GaussianMLPPolicy/LossBefore             -7.63628e-05\n",
      "GaussianMLPPolicy/dLoss                   2.09839e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.73497\n",
      "GaussianMLPValueFunction/LossBefore      -6.66472\n",
      "GaussianMLPValueFunction/dLoss            0.0702567\n",
      "TotalEnvSteps                        679320\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.0650e-05,  5.8741e-05, -7.1467e-09,  ...,  1.0086e-03,\n",
      "        -4.1298e-04,  1.1454e-03])\n",
      "G is: \n",
      "tensor([[1.5588e-05, 7.4939e+00],\n",
      "        [7.4939e+00, 3.6027e+06]])\n",
      "eig is:\n",
      "tensor([[2.5000e-01, 0.0000e+00],\n",
      "        [3.6027e+06, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-5.1550e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-5.1699e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:53 | [trpo_pendulum] epoch #340 | Saving snapshot...\n",
      "2022-08-23 10:42:53 | [trpo_pendulum] epoch #340 | Saved\n",
      "2022-08-23 10:42:53 | [trpo_pendulum] epoch #340 | Time 335.07 s\n",
      "2022-08-23 10:42:53 | [trpo_pendulum] epoch #340 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000273124\n",
      "Evaluation/AverageReturn                 -0.00288837\n",
      "Evaluation/Iteration                    340\n",
      "Evaluation/MaxReturn                     -0.00282202\n",
      "Evaluation/MinReturn                     -0.00295471\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.63451e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.89344\n",
      "GaussianMLPPolicy/KL                      0.000105585\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.16985e-05\n",
      "GaussianMLPPolicy/LossBefore             -5.15503e-05\n",
      "GaussianMLPPolicy/dLoss                   1.48204e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.69388\n",
      "GaussianMLPValueFunction/LossBefore      -6.72963\n",
      "GaussianMLPValueFunction/dLoss           -0.0357499\n",
      "TotalEnvSteps                        681318\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.0385e-05,  1.7842e-05, -2.4226e-07,  ...,  2.3265e-04,\n",
      "        -9.7668e-05,  2.6298e-04])\n",
      "G is: \n",
      "tensor([[8.2950e-07, 4.0447e-01],\n",
      "        [4.0447e-01, 1.9739e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [197386.1250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(9.6017e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(9.5902e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:54 | [trpo_pendulum] epoch #341 | Saving snapshot...\n",
      "2022-08-23 10:42:54 | [trpo_pendulum] epoch #341 | Saved\n",
      "2022-08-23 10:42:54 | [trpo_pendulum] epoch #341 | Time 336.08 s\n",
      "2022-08-23 10:42:54 | [trpo_pendulum] epoch #341 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000282754\n",
      "Evaluation/AverageReturn                 -0.00297519\n",
      "Evaluation/Iteration                    341\n",
      "Evaluation/MaxReturn                     -0.00294787\n",
      "Evaluation/MinReturn                     -0.0030025\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.73151e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.9008\n",
      "GaussianMLPPolicy/KL                      8.2614e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               9.59023e-05\n",
      "GaussianMLPPolicy/LossBefore              9.60175e-05\n",
      "GaussianMLPPolicy/dLoss                   1.15193e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.17579\n",
      "GaussianMLPValueFunction/LossBefore      -6.5842\n",
      "GaussianMLPValueFunction/dLoss           -0.408413\n",
      "TotalEnvSteps                        683316\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.4909e-06,  7.1897e-05,  6.0282e-09,  ...,  1.3467e-03,\n",
      "        -5.4869e-04,  1.5309e-03])\n",
      "G is: \n",
      "tensor([[2.7794e-05, 1.3766e+01],\n",
      "        [1.3766e+01, 6.8180e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [6818034.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:55 | [trpo_pendulum] epoch #342 | Saving snapshot...\n",
      "2022-08-23 10:42:55 | [trpo_pendulum] epoch #342 | Saved\n",
      "2022-08-23 10:42:55 | [trpo_pendulum] epoch #342 | Time 337.09 s\n",
      "2022-08-23 10:42:55 | [trpo_pendulum] epoch #342 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000294911\n",
      "Evaluation/AverageReturn                 -0.00286242\n",
      "Evaluation/Iteration                    342\n",
      "Evaluation/MaxReturn                     -0.00283444\n",
      "Evaluation/MinReturn                     -0.0028904\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.79834e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.9008\n",
      "GaussianMLPPolicy/KL                      5.59095e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000122322\n",
      "GaussianMLPPolicy/LossBefore              0.000122401\n",
      "GaussianMLPPolicy/dLoss                   7.87695e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.71471\n",
      "GaussianMLPValueFunction/LossBefore      -6.49994\n",
      "GaussianMLPValueFunction/dLoss            0.214766\n",
      "TotalEnvSteps                        685314\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.0631e-06,  3.6707e-05, -1.8121e-08,  ...,  6.9276e-04,\n",
      "        -2.8214e-04,  7.8759e-04])\n",
      "G is: \n",
      "tensor([[7.3548e-06, 3.6427e+00],\n",
      "        [3.6427e+00, 1.8042e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1804176.2500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(6.4407e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(6.4386e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:56 | [trpo_pendulum] epoch #343 | Saving snapshot...\n",
      "2022-08-23 10:42:56 | [trpo_pendulum] epoch #343 | Saved\n",
      "2022-08-23 10:42:56 | [trpo_pendulum] epoch #343 | Time 338.07 s\n",
      "2022-08-23 10:42:56 | [trpo_pendulum] epoch #343 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000292168\n",
      "Evaluation/AverageReturn                 -0.002848\n",
      "Evaluation/Iteration                    343\n",
      "Evaluation/MaxReturn                     -0.00271027\n",
      "Evaluation/MinReturn                     -0.00298572\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000137726\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.9008\n",
      "GaussianMLPPolicy/KL                      1.4868e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               6.43864e-05\n",
      "GaussianMLPPolicy/LossBefore              6.44072e-05\n",
      "GaussianMLPPolicy/dLoss                   2.08747e-08\n",
      "GaussianMLPValueFunction/LossAfter       -5.94616\n",
      "GaussianMLPValueFunction/LossBefore      -6.71567\n",
      "GaussianMLPValueFunction/dLoss           -0.769516\n",
      "TotalEnvSteps                        687312\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.1499e-06,  8.1921e-05,  1.7531e-06,  ...,  1.5676e-03,\n",
      "        -6.3545e-04,  1.7818e-03])\n",
      "G is: \n",
      "tensor([[3.7645e-05, 1.8642e+01],\n",
      "        [1.8642e+01, 9.2316e+06]])\n",
      "eig is:\n",
      "tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [9.2316e+06, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:57 | [trpo_pendulum] epoch #344 | Saving snapshot...\n",
      "2022-08-23 10:42:57 | [trpo_pendulum] epoch #344 | Saved\n",
      "2022-08-23 10:42:57 | [trpo_pendulum] epoch #344 | Time 339.09 s\n",
      "2022-08-23 10:42:57 | [trpo_pendulum] epoch #344 | EpochTime 1.02 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00029522\n",
      "Evaluation/AverageReturn                 -0.00286779\n",
      "Evaluation/Iteration                    344\n",
      "Evaluation/MaxReturn                     -0.00286238\n",
      "Evaluation/MinReturn                     -0.0028732\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.40677e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90769\n",
      "GaussianMLPPolicy/KL                      0.000507015\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000167829\n",
      "GaussianMLPPolicy/LossBefore             -0.000167254\n",
      "GaussianMLPPolicy/dLoss                   5.74699e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.41979\n",
      "GaussianMLPValueFunction/LossBefore      -6.21891\n",
      "GaussianMLPValueFunction/dLoss            0.200879\n",
      "TotalEnvSteps                        689310\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-4.7199e-06,  1.6951e-05,  1.6749e-07,  ...,  2.9266e-04,\n",
      "        -1.1945e-04,  3.3257e-04])\n",
      "G is: \n",
      "tensor([[1.3138e-06, 6.6004e-01],\n",
      "        [6.6004e-01, 3.3161e+05]])\n",
      "eig is:\n",
      "tensor([[     0.,      0.],\n",
      "        [331609.,      0.]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:58 | [trpo_pendulum] epoch #345 | Saving snapshot...\n",
      "2022-08-23 10:42:58 | [trpo_pendulum] epoch #345 | Saved\n",
      "2022-08-23 10:42:58 | [trpo_pendulum] epoch #345 | Time 340.10 s\n",
      "2022-08-23 10:42:58 | [trpo_pendulum] epoch #345 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000241607\n",
      "Evaluation/AverageReturn                 -0.00276581\n",
      "Evaluation/Iteration                    345\n",
      "Evaluation/MaxReturn                     -0.00271873\n",
      "Evaluation/MinReturn                     -0.00281289\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.70795e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90769\n",
      "GaussianMLPPolicy/KL                      2.64137e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000177446\n",
      "GaussianMLPPolicy/LossBefore             -0.000177442\n",
      "GaussianMLPPolicy/dLoss                   3.63798e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.25391\n",
      "GaussianMLPValueFunction/LossBefore      -6.166\n",
      "GaussianMLPValueFunction/dLoss            0.0879107\n",
      "TotalEnvSteps                        691308\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-2.4109e-06,  4.0610e-05, -2.8324e-07,  ...,  7.2188e-04,\n",
      "        -2.9493e-04,  8.2104e-04])\n",
      "G is: \n",
      "tensor([[7.9971e-06, 4.0178e+00],\n",
      "        [4.0178e+00, 2.0186e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [2018559.7500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:42:59 | [trpo_pendulum] epoch #346 | Saving snapshot...\n",
      "2022-08-23 10:42:59 | [trpo_pendulum] epoch #346 | Saved\n",
      "2022-08-23 10:42:59 | [trpo_pendulum] epoch #346 | Time 341.04 s\n",
      "2022-08-23 10:42:59 | [trpo_pendulum] epoch #346 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000274893\n",
      "Evaluation/AverageReturn                 -0.00274328\n",
      "Evaluation/Iteration                    346\n",
      "Evaluation/MaxReturn                     -0.00273227\n",
      "Evaluation/MinReturn                     -0.0027543\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.10144e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90769\n",
      "GaussianMLPPolicy/KL                      1.58449e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000164128\n",
      "GaussianMLPPolicy/LossBefore             -0.000164105\n",
      "GaussianMLPPolicy/dLoss                   2.25118e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.48739\n",
      "GaussianMLPValueFunction/LossBefore      -6.25319\n",
      "GaussianMLPValueFunction/dLoss            0.234204\n",
      "TotalEnvSteps                        693306\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.3934e-06,  7.6926e-06, -3.5883e-09,  ...,  1.2732e-05,\n",
      "        -8.4439e-06,  1.2405e-05])\n",
      "G is: \n",
      "tensor([[3.4002e-09, 1.2184e-03],\n",
      "        [1.2184e-03, 6.1205e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [612.0460,   0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:00 | [trpo_pendulum] epoch #347 | Saving snapshot...\n",
      "2022-08-23 10:43:00 | [trpo_pendulum] epoch #347 | Saved\n",
      "2022-08-23 10:43:00 | [trpo_pendulum] epoch #347 | Time 342.02 s\n",
      "2022-08-23 10:43:00 | [trpo_pendulum] epoch #347 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000283429\n",
      "Evaluation/AverageReturn                 -0.00275142\n",
      "Evaluation/Iteration                    347\n",
      "Evaluation/MaxReturn                     -0.00272301\n",
      "Evaluation/MinReturn                     -0.00277983\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.84112e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90809\n",
      "GaussianMLPPolicy/KL                      5.135e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000157061\n",
      "GaussianMLPPolicy/LossBefore              0.000157133\n",
      "GaussianMLPPolicy/dLoss                   7.20756e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.6379\n",
      "GaussianMLPValueFunction/LossBefore      -6.29147\n",
      "GaussianMLPValueFunction/dLoss            0.346432\n",
      "TotalEnvSteps                        695304\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.3487e-06,  8.9912e-06, -2.5596e-08,  ...,  2.0428e-04,\n",
      "        -8.2179e-05,  2.3307e-04])\n",
      "G is: \n",
      "tensor([[6.4055e-07, 3.2196e-01],\n",
      "        [3.2196e-01, 1.6187e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [161865.9688,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:01 | [trpo_pendulum] epoch #348 | Saving snapshot...\n",
      "2022-08-23 10:43:01 | [trpo_pendulum] epoch #348 | Saved\n",
      "2022-08-23 10:43:01 | [trpo_pendulum] epoch #348 | Time 342.97 s\n",
      "2022-08-23 10:43:01 | [trpo_pendulum] epoch #348 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000349062\n",
      "Evaluation/AverageReturn                 -0.0031332\n",
      "Evaluation/Iteration                    348\n",
      "Evaluation/MaxReturn                     -0.00304749\n",
      "Evaluation/MinReturn                     -0.00321891\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.57104e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90806\n",
      "GaussianMLPPolicy/KL                      3.57032e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000181672\n",
      "GaussianMLPPolicy/LossBefore              0.000181677\n",
      "GaussianMLPPolicy/dLoss                   5.02041e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.49759\n",
      "GaussianMLPValueFunction/LossBefore      -6.00301\n",
      "GaussianMLPValueFunction/dLoss            0.494582\n",
      "TotalEnvSteps                        697302\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-6.2407e-06,  4.3712e-06, -1.3326e-07,  ...,  7.0273e-05,\n",
      "        -2.9049e-05,  7.9843e-05])\n",
      "G is: \n",
      "tensor([[7.5856e-08, 3.8116e-02],\n",
      "        [3.8116e-02, 1.9164e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [19164.3027,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:02 | [trpo_pendulum] epoch #349 | Saving snapshot...\n",
      "2022-08-23 10:43:02 | [trpo_pendulum] epoch #349 | Saved\n",
      "2022-08-23 10:43:02 | [trpo_pendulum] epoch #349 | Time 343.97 s\n",
      "2022-08-23 10:43:02 | [trpo_pendulum] epoch #349 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000288772\n",
      "Evaluation/AverageReturn                 -0.00274994\n",
      "Evaluation/Iteration                    349\n",
      "Evaluation/MaxReturn                     -0.00268288\n",
      "Evaluation/MinReturn                     -0.002817\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.70591e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90806\n",
      "GaussianMLPPolicy/KL                      1.50802e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000217268\n",
      "GaussianMLPPolicy/LossBefore             -0.000217267\n",
      "GaussianMLPPolicy/dLoss                   3.7835e-10\n",
      "GaussianMLPValueFunction/LossAfter       -6.77327\n",
      "GaussianMLPValueFunction/LossBefore      -5.84072\n",
      "GaussianMLPValueFunction/dLoss            0.932551\n",
      "TotalEnvSteps                        699300\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.8764e-06,  1.6312e-05, -4.8678e-09,  ...,  2.9040e-04,\n",
      "        -1.1854e-04,  3.3021e-04])\n",
      "G is: \n",
      "tensor([[1.2940e-06, 6.5061e-01],\n",
      "        [6.5061e-01, 3.2713e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [327128.0625,      0.0000]])\n",
      "loss before is:\n",
      "tensor(3.6623e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(3.6619e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:03 | [trpo_pendulum] epoch #350 | Saving snapshot...\n",
      "2022-08-23 10:43:03 | [trpo_pendulum] epoch #350 | Saved\n",
      "2022-08-23 10:43:03 | [trpo_pendulum] epoch #350 | Time 344.92 s\n",
      "2022-08-23 10:43:03 | [trpo_pendulum] epoch #350 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0002849\n",
      "Evaluation/AverageReturn                 -0.00260729\n",
      "Evaluation/Iteration                    350\n",
      "Evaluation/MaxReturn                     -0.00253189\n",
      "Evaluation/MinReturn                     -0.00268269\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.54e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90806\n",
      "GaussianMLPPolicy/KL                      2.60202e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               3.66192e-05\n",
      "GaussianMLPPolicy/LossBefore              3.66228e-05\n",
      "GaussianMLPPolicy/dLoss                   3.64162e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.75652\n",
      "GaussianMLPValueFunction/LossBefore      -6.78681\n",
      "GaussianMLPValueFunction/dLoss           -0.0302925\n",
      "TotalEnvSteps                        701298\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.0213e-06,  2.9264e-05,  4.5563e-08,  ...,  5.1029e-04,\n",
      "        -2.0851e-04,  5.8003e-04])\n",
      "G is: \n",
      "tensor([[3.9949e-06, 2.0086e+00],\n",
      "        [2.0086e+00, 1.0099e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1009872.8750,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-4.0969e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-4.0980e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:04 | [trpo_pendulum] epoch #351 | Saving snapshot...\n",
      "2022-08-23 10:43:04 | [trpo_pendulum] epoch #351 | Saved\n",
      "2022-08-23 10:43:04 | [trpo_pendulum] epoch #351 | Time 345.99 s\n",
      "2022-08-23 10:43:04 | [trpo_pendulum] epoch #351 | EpochTime 1.06 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000276428\n",
      "Evaluation/AverageReturn                 -0.00271319\n",
      "Evaluation/Iteration                    351\n",
      "Evaluation/MaxReturn                     -0.00261442\n",
      "Evaluation/MinReturn                     -0.00281196\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      9.877e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90806\n",
      "GaussianMLPPolicy/KL                      7.95964e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.09801e-05\n",
      "GaussianMLPPolicy/LossBefore             -4.09689e-05\n",
      "GaussianMLPPolicy/dLoss                   1.11977e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.71551\n",
      "GaussianMLPValueFunction/LossBefore      -6.7799\n",
      "GaussianMLPValueFunction/dLoss           -0.0643935\n",
      "TotalEnvSteps                        703296\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.3689e-07,  6.1468e-06,  9.6205e-08,  ...,  9.3363e-05,\n",
      "        -3.8401e-05,  1.0585e-04])\n",
      "G is: \n",
      "tensor([[1.3363e-07, 6.7176e-02],\n",
      "        [6.7176e-02, 3.3773e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [33773.0078,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-4.3480e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-4.3481e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:05 | [trpo_pendulum] epoch #352 | Saving snapshot...\n",
      "2022-08-23 10:43:05 | [trpo_pendulum] epoch #352 | Saved\n",
      "2022-08-23 10:43:05 | [trpo_pendulum] epoch #352 | Time 346.95 s\n",
      "2022-08-23 10:43:05 | [trpo_pendulum] epoch #352 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000291985\n",
      "Evaluation/AverageReturn                 -0.00300111\n",
      "Evaluation/Iteration                    352\n",
      "Evaluation/MaxReturn                     -0.00295025\n",
      "Evaluation/MinReturn                     -0.00305198\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.08657e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90806\n",
      "GaussianMLPPolicy/KL                      2.54558e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.34807e-05\n",
      "GaussianMLPPolicy/LossBefore             -4.34803e-05\n",
      "GaussianMLPPolicy/dLoss                   3.74712e-10\n",
      "GaussianMLPValueFunction/LossAfter       -6.5364\n",
      "GaussianMLPValueFunction/LossBefore      -6.77459\n",
      "GaussianMLPValueFunction/dLoss           -0.238191\n",
      "TotalEnvSteps                        705294\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.7366e-06,  3.4540e-05, -5.8159e-08,  ...,  6.1141e-04,\n",
      "        -2.4973e-04,  6.9518e-04])\n",
      "G is: \n",
      "tensor([[5.7358e-06, 2.8840e+00],\n",
      "        [2.8840e+00, 1.4501e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [1450079.,       0.]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:06 | [trpo_pendulum] epoch #353 | Saving snapshot...\n",
      "2022-08-23 10:43:06 | [trpo_pendulum] epoch #353 | Saved\n",
      "2022-08-23 10:43:06 | [trpo_pendulum] epoch #353 | Time 347.94 s\n",
      "2022-08-23 10:43:06 | [trpo_pendulum] epoch #353 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000237734\n",
      "Evaluation/AverageReturn                 -0.00255389\n",
      "Evaluation/Iteration                    353\n",
      "Evaluation/MaxReturn                     -0.00247189\n",
      "Evaluation/MinReturn                     -0.00263589\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.1999e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90806\n",
      "GaussianMLPPolicy/KL                      1.13519e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000154645\n",
      "GaussianMLPPolicy/LossBefore             -0.000154629\n",
      "GaussianMLPPolicy/dLoss                   1.58761e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.79277\n",
      "GaussianMLPValueFunction/LossBefore      -6.31774\n",
      "GaussianMLPValueFunction/dLoss            0.475031\n",
      "TotalEnvSteps                        707292\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-5.7852e-06, -4.8379e-05,  2.3773e-07,  ..., -8.0730e-04,\n",
      "         3.3113e-04, -9.1728e-04])\n",
      "G is: \n",
      "tensor([[9.9986e-06, 5.0263e+00],\n",
      "        [5.0263e+00, 2.5267e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [2526746.,       0.]])\n",
      "loss before is:\n",
      "tensor(9.5372e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(9.5339e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:07 | [trpo_pendulum] epoch #354 | Saving snapshot...\n",
      "2022-08-23 10:43:07 | [trpo_pendulum] epoch #354 | Saved\n",
      "2022-08-23 10:43:07 | [trpo_pendulum] epoch #354 | Time 348.89 s\n",
      "2022-08-23 10:43:07 | [trpo_pendulum] epoch #354 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000309457\n",
      "Evaluation/AverageReturn                 -0.00313831\n",
      "Evaluation/Iteration                    354\n",
      "Evaluation/MaxReturn                     -0.00293468\n",
      "Evaluation/MinReturn                     -0.00334193\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000203624\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90789\n",
      "GaussianMLPPolicy/KL                      2.3682e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               9.53387e-05\n",
      "GaussianMLPPolicy/LossBefore              9.53723e-05\n",
      "GaussianMLPPolicy/dLoss                   3.35567e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.53586\n",
      "GaussianMLPValueFunction/LossBefore      -6.50367\n",
      "GaussianMLPValueFunction/dLoss            0.0321851\n",
      "TotalEnvSteps                        709290\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.9695e-06,  2.1235e-05, -9.3300e-08,  ...,  3.8339e-04,\n",
      "        -1.5646e-04,  4.3608e-04])\n",
      "G is: \n",
      "tensor([[2.2556e-06, 1.1337e+00],\n",
      "        [1.1337e+00, 5.6984e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [569838.0625,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-3.8067e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-3.8073e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:08 | [trpo_pendulum] epoch #355 | Saving snapshot...\n",
      "2022-08-23 10:43:08 | [trpo_pendulum] epoch #355 | Saved\n",
      "2022-08-23 10:43:08 | [trpo_pendulum] epoch #355 | Time 349.85 s\n",
      "2022-08-23 10:43:08 | [trpo_pendulum] epoch #355 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00028151\n",
      "Evaluation/AverageReturn                 -0.00254918\n",
      "Evaluation/Iteration                    355\n",
      "Evaluation/MaxReturn                     -0.00251569\n",
      "Evaluation/MinReturn                     -0.00258266\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.34827e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90789\n",
      "GaussianMLPPolicy/KL                      4.47259e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.80728e-05\n",
      "GaussianMLPPolicy/LossBefore             -3.80665e-05\n",
      "GaussianMLPPolicy/dLoss                   6.30098e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.58093\n",
      "GaussianMLPValueFunction/LossBefore      -6.77806\n",
      "GaussianMLPValueFunction/dLoss           -0.197129\n",
      "TotalEnvSteps                        711288\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.5601e-06, -3.6004e-05, -4.2764e-07,  ..., -4.7918e-04,\n",
      "         1.9920e-04, -5.4205e-04])\n",
      "G is: \n",
      "tensor([[3.5198e-06, 1.7681e+00],\n",
      "        [1.7681e+00, 8.8856e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [888564.2500,      0.0000]])\n",
      "loss before is:\n",
      "tensor(7.3396e-06, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(7.2912e-06, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:09 | [trpo_pendulum] epoch #356 | Saving snapshot...\n",
      "2022-08-23 10:43:09 | [trpo_pendulum] epoch #356 | Saved\n",
      "2022-08-23 10:43:09 | [trpo_pendulum] epoch #356 | Time 350.85 s\n",
      "2022-08-23 10:43:09 | [trpo_pendulum] epoch #356 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000286451\n",
      "Evaluation/AverageReturn                 -0.00315056\n",
      "Evaluation/Iteration                    356\n",
      "Evaluation/MaxReturn                     -0.00310487\n",
      "Evaluation/MinReturn                     -0.00319625\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.56886e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90798\n",
      "GaussianMLPPolicy/KL                      3.4313e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               7.29123e-06\n",
      "GaussianMLPPolicy/LossBefore              7.3396e-06\n",
      "GaussianMLPPolicy/dLoss                   4.83737e-08\n",
      "GaussianMLPValueFunction/LossAfter       -3.92089\n",
      "GaussianMLPValueFunction/LossBefore      -6.72353\n",
      "GaussianMLPValueFunction/dLoss           -2.80264\n",
      "TotalEnvSteps                        713286\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.8732e-07,  1.3863e-04,  8.1337e-08,  ...,  2.4548e-03,\n",
      "        -1.0020e-03,  2.7913e-03])\n",
      "G is: \n",
      "tensor([[9.2460e-05, 4.6480e+01],\n",
      "        [4.6480e+01, 2.3366e+07]])\n",
      "eig is:\n",
      "tensor([[       0.,        0.],\n",
      "        [23366168.,        0.]])\n",
      "loss before is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:10 | [trpo_pendulum] epoch #357 | Saving snapshot...\n",
      "2022-08-23 10:43:10 | [trpo_pendulum] epoch #357 | Saved\n",
      "2022-08-23 10:43:10 | [trpo_pendulum] epoch #357 | Time 351.82 s\n",
      "2022-08-23 10:43:10 | [trpo_pendulum] epoch #357 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000270026\n",
      "Evaluation/AverageReturn                 -0.00272378\n",
      "Evaluation/Iteration                    357\n",
      "Evaluation/MaxReturn                     -0.00268892\n",
      "Evaluation/MinReturn                     -0.00275864\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.48626e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90798\n",
      "GaussianMLPPolicy/KL                      0.000180629\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00026124\n",
      "GaussianMLPPolicy/LossBefore              0.000261498\n",
      "GaussianMLPPolicy/dLoss                   2.58005e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.7925\n",
      "GaussianMLPValueFunction/LossBefore      -5.40871\n",
      "GaussianMLPValueFunction/dLoss            1.38378\n",
      "TotalEnvSteps                        715284\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-8.5322e-06,  3.5288e-06, -2.0037e-07,  ...,  1.8201e-05,\n",
      "        -8.8335e-06,  2.0071e-05])\n",
      "G is: \n",
      "tensor([[5.2882e-09, 2.5507e-03],\n",
      "        [2.5507e-03, 1.2819e+03]])\n",
      "eig is:\n",
      "tensor([[   0.0000,    0.0000],\n",
      "        [1281.9404,    0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:11 | [trpo_pendulum] epoch #358 | Saving snapshot...\n",
      "2022-08-23 10:43:11 | [trpo_pendulum] epoch #358 | Saved\n",
      "2022-08-23 10:43:11 | [trpo_pendulum] epoch #358 | Time 352.78 s\n",
      "2022-08-23 10:43:11 | [trpo_pendulum] epoch #358 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000280893\n",
      "Evaluation/AverageReturn                 -0.00317344\n",
      "Evaluation/Iteration                    358\n",
      "Evaluation/MaxReturn                     -0.00312561\n",
      "Evaluation/MinReturn                     -0.00322127\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.78306e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90268\n",
      "GaussianMLPPolicy/KL                      3.68521e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000104788\n",
      "GaussianMLPPolicy/LossBefore              0.00010484\n",
      "GaussianMLPPolicy/dLoss                   5.28962e-08\n",
      "GaussianMLPValueFunction/LossAfter       -4.83015\n",
      "GaussianMLPValueFunction/LossBefore      -6.42264\n",
      "GaussianMLPValueFunction/dLoss           -1.59248\n",
      "TotalEnvSteps                        717282\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.6091e-06,  1.5279e-04,  1.1819e-07,  ...,  2.6305e-03,\n",
      "        -1.0753e-03,  2.9899e-03])\n",
      "G is: \n",
      "tensor([[1.0613e-04, 5.2780e+01],\n",
      "        [5.2780e+01, 2.6248e+07]])\n",
      "eig is:\n",
      "tensor([[       0.,        0.],\n",
      "        [26247612.,        0.]])\n",
      "loss before is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:12 | [trpo_pendulum] epoch #359 | Saving snapshot...\n",
      "2022-08-23 10:43:12 | [trpo_pendulum] epoch #359 | Saved\n",
      "2022-08-23 10:43:12 | [trpo_pendulum] epoch #359 | Time 353.88 s\n",
      "2022-08-23 10:43:12 | [trpo_pendulum] epoch #359 | EpochTime 1.10 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000290647\n",
      "Evaluation/AverageReturn                 -0.00315454\n",
      "Evaluation/Iteration                    359\n",
      "Evaluation/MaxReturn                     -0.00304169\n",
      "Evaluation/MinReturn                     -0.00326739\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000112848\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90289\n",
      "GaussianMLPPolicy/KL                      0.000214057\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000271832\n",
      "GaussianMLPPolicy/LossBefore              0.000272136\n",
      "GaussianMLPPolicy/dLoss                   3.04019e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.77016\n",
      "GaussianMLPValueFunction/LossBefore      -5.23171\n",
      "GaussianMLPValueFunction/dLoss            0.538443\n",
      "TotalEnvSteps                        719280\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.2749e-06, -4.8786e-06, -1.8443e-07,  ..., -9.2166e-05,\n",
      "         3.7249e-05, -1.0480e-04])\n",
      "G is: \n",
      "tensor([[1.3028e-07, 6.4805e-02],\n",
      "        [6.4805e-02, 3.2247e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [32247.4746,     0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:13 | [trpo_pendulum] epoch #360 | Saving snapshot...\n",
      "2022-08-23 10:43:13 | [trpo_pendulum] epoch #360 | Saved\n",
      "2022-08-23 10:43:13 | [trpo_pendulum] epoch #360 | Time 354.89 s\n",
      "2022-08-23 10:43:13 | [trpo_pendulum] epoch #360 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000266511\n",
      "Evaluation/AverageReturn                 -0.00267551\n",
      "Evaluation/Iteration                    360\n",
      "Evaluation/MaxReturn                     -0.00263285\n",
      "Evaluation/MinReturn                     -0.00271817\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.266e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90289\n",
      "GaussianMLPPolicy/KL                      2.46772e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000121279\n",
      "GaussianMLPPolicy/LossBefore              0.00012128\n",
      "GaussianMLPPolicy/dLoss                   2.61934e-10\n",
      "GaussianMLPValueFunction/LossAfter       -6.34175\n",
      "GaussianMLPValueFunction/LossBefore      -6.50751\n",
      "GaussianMLPValueFunction/dLoss           -0.165758\n",
      "TotalEnvSteps                        721278\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.7457e-06,  1.1880e-04,  8.3037e-08,  ...,  2.3913e-03,\n",
      "        -9.6852e-04,  2.7238e-03])\n",
      "G is: \n",
      "tensor([[8.7755e-05, 4.3661e+01],\n",
      "        [4.3661e+01, 2.1725e+07]])\n",
      "eig is:\n",
      "tensor([[       0.,        0.],\n",
      "        [21724552.,        0.]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:14 | [trpo_pendulum] epoch #361 | Saving snapshot...\n",
      "2022-08-23 10:43:14 | [trpo_pendulum] epoch #361 | Saved\n",
      "2022-08-23 10:43:14 | [trpo_pendulum] epoch #361 | Time 355.89 s\n",
      "2022-08-23 10:43:14 | [trpo_pendulum] epoch #361 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000243372\n",
      "Evaluation/AverageReturn                 -0.0028861\n",
      "Evaluation/Iteration                    361\n",
      "Evaluation/MaxReturn                     -0.00283009\n",
      "Evaluation/MinReturn                     -0.0029421\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.60049e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90328\n",
      "GaussianMLPPolicy/KL                      0.000349907\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000196795\n",
      "GaussianMLPPolicy/LossBefore              0.0001973\n",
      "GaussianMLPPolicy/dLoss                   5.04704e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.69607\n",
      "GaussianMLPValueFunction/LossBefore      -5.99057\n",
      "GaussianMLPValueFunction/dLoss            0.705501\n",
      "TotalEnvSteps                        723276\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-7.9885e-06, -2.8553e-05,  4.8853e-08,  ..., -2.4663e-04,\n",
      "         1.0738e-04, -2.7628e-04])\n",
      "G is: \n",
      "tensor([[9.3478e-07, 4.6337e-01],\n",
      "        [4.6337e-01, 2.3071e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [230711.0625,      0.0000]])\n",
      "loss before is:\n",
      "tensor(8.1655e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(8.1503e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:15 | [trpo_pendulum] epoch #362 | Saving snapshot...\n",
      "2022-08-23 10:43:15 | [trpo_pendulum] epoch #362 | Saved\n",
      "2022-08-23 10:43:15 | [trpo_pendulum] epoch #362 | Time 356.88 s\n",
      "2022-08-23 10:43:15 | [trpo_pendulum] epoch #362 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000249682\n",
      "Evaluation/AverageReturn                 -0.0027115\n",
      "Evaluation/Iteration                    362\n",
      "Evaluation/MaxReturn                     -0.00256597\n",
      "Evaluation/MinReturn                     -0.00285703\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000145528\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.903\n",
      "GaussianMLPPolicy/KL                      0.000106281\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               8.15031e-05\n",
      "GaussianMLPPolicy/LossBefore              8.16551e-05\n",
      "GaussianMLPPolicy/dLoss                   1.51944e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.75086\n",
      "GaussianMLPValueFunction/LossBefore      -6.64107\n",
      "GaussianMLPValueFunction/dLoss            0.109787\n",
      "TotalEnvSteps                        725274\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.8832e-06,  2.1991e-05, -1.7921e-08,  ...,  4.0173e-04,\n",
      "        -1.6356e-04,  4.5709e-04])\n",
      "G is: \n",
      "tensor([[2.4764e-06, 1.2323e+00],\n",
      "        [1.2323e+00, 6.1322e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [613215.6250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-1.5644e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-1.5652e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:16 | [trpo_pendulum] epoch #363 | Saving snapshot...\n",
      "2022-08-23 10:43:16 | [trpo_pendulum] epoch #363 | Saved\n",
      "2022-08-23 10:43:16 | [trpo_pendulum] epoch #363 | Time 357.87 s\n",
      "2022-08-23 10:43:16 | [trpo_pendulum] epoch #363 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000270681\n",
      "Evaluation/AverageReturn                 -0.0027817\n",
      "Evaluation/Iteration                    363\n",
      "Evaluation/MaxReturn                     -0.00276459\n",
      "Evaluation/MinReturn                     -0.0027988\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.71065e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.903\n",
      "GaussianMLPPolicy/KL                      4.984e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -1.56515e-05\n",
      "GaussianMLPPolicy/LossBefore             -1.56445e-05\n",
      "GaussianMLPPolicy/dLoss                   7.03403e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.60058\n",
      "GaussianMLPValueFunction/LossBefore      -6.80778\n",
      "GaussianMLPValueFunction/dLoss           -0.207195\n",
      "TotalEnvSteps                        727272\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.5617e-06,  5.7787e-05, -8.2385e-08,  ...,  1.0011e-03,\n",
      "        -4.0901e-04,  1.1382e-03])\n",
      "G is: \n",
      "tensor([[1.5376e-05, 7.6517e+00],\n",
      "        [7.6517e+00, 3.8078e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [3807775.,       0.]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:17 | [trpo_pendulum] epoch #364 | Saving snapshot...\n",
      "2022-08-23 10:43:17 | [trpo_pendulum] epoch #364 | Saved\n",
      "2022-08-23 10:43:17 | [trpo_pendulum] epoch #364 | Time 358.85 s\n",
      "2022-08-23 10:43:17 | [trpo_pendulum] epoch #364 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000281122\n",
      "Evaluation/AverageReturn                 -0.00282631\n",
      "Evaluation/Iteration                    364\n",
      "Evaluation/MaxReturn                     -0.00276279\n",
      "Evaluation/MinReturn                     -0.00288982\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.3517e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.903\n",
      "GaussianMLPPolicy/KL                      3.07702e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000112097\n",
      "GaussianMLPPolicy/LossBefore              0.000112141\n",
      "GaussianMLPPolicy/dLoss                   4.34011e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.25248\n",
      "GaussianMLPValueFunction/LossBefore      -6.55599\n",
      "GaussianMLPValueFunction/dLoss           -0.303506\n",
      "TotalEnvSteps                        729270\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.9992e-06,  3.7151e-05,  3.0659e-07,  ...,  6.6369e-04,\n",
      "        -2.7018e-04,  7.5477e-04])\n",
      "G is: \n",
      "tensor([[6.7574e-06, 3.3627e+00],\n",
      "        [3.3627e+00, 1.6734e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [1673418.,       0.]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:18 | [trpo_pendulum] epoch #365 | Saving snapshot...\n",
      "2022-08-23 10:43:18 | [trpo_pendulum] epoch #365 | Saved\n",
      "2022-08-23 10:43:18 | [trpo_pendulum] epoch #365 | Time 359.84 s\n",
      "2022-08-23 10:43:18 | [trpo_pendulum] epoch #365 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000276762\n",
      "Evaluation/AverageReturn                 -0.0025859\n",
      "Evaluation/Iteration                    365\n",
      "Evaluation/MaxReturn                     -0.0024452\n",
      "Evaluation/MinReturn                     -0.00272659\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000140695\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.903\n",
      "GaussianMLPPolicy/KL                      1.35761e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000153375\n",
      "GaussianMLPPolicy/LossBefore              0.000153395\n",
      "GaussianMLPPolicy/dLoss                   1.9354e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.41973\n",
      "GaussianMLPValueFunction/LossBefore      -6.33063\n",
      "GaussianMLPValueFunction/dLoss            0.0890994\n",
      "TotalEnvSteps                        731268\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.0657e-06,  3.0536e-07, -5.2029e-07,  ...,  1.5966e-04,\n",
      "        -6.1775e-05,  1.8432e-04])\n",
      "G is: \n",
      "tensor([[3.9405e-07, 1.9535e-01],\n",
      "        [1.9535e-01, 9.7208e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [97207.7969,     0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:19 | [trpo_pendulum] epoch #366 | Saving snapshot...\n",
      "2022-08-23 10:43:19 | [trpo_pendulum] epoch #366 | Saved\n",
      "2022-08-23 10:43:19 | [trpo_pendulum] epoch #366 | Time 360.86 s\n",
      "2022-08-23 10:43:19 | [trpo_pendulum] epoch #366 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00026352\n",
      "Evaluation/AverageReturn                 -0.00281962\n",
      "Evaluation/Iteration                    366\n",
      "Evaluation/MaxReturn                     -0.00276551\n",
      "Evaluation/MinReturn                     -0.00287372\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.41068e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90311\n",
      "GaussianMLPPolicy/KL                      5.62946e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000179243\n",
      "GaussianMLPPolicy/LossBefore              0.000179323\n",
      "GaussianMLPPolicy/dLoss                   7.99482e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.80523\n",
      "GaussianMLPValueFunction/LossBefore      -6.12968\n",
      "GaussianMLPValueFunction/dLoss            0.675549\n",
      "TotalEnvSteps                        733266\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.6208e-06, -1.2741e-05,  1.9520e-07,  ..., -2.4681e-04,\n",
      "         1.0033e-04, -2.8116e-04])\n",
      "G is: \n",
      "tensor([[9.3524e-07, 4.6536e-01],\n",
      "        [4.6536e-01, 2.3157e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [231573.4688,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-7.0188e-06, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-7.0215e-06, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:20 | [trpo_pendulum] epoch #367 | Saving snapshot...\n",
      "2022-08-23 10:43:20 | [trpo_pendulum] epoch #367 | Saved\n",
      "2022-08-23 10:43:20 | [trpo_pendulum] epoch #367 | Time 361.84 s\n",
      "2022-08-23 10:43:20 | [trpo_pendulum] epoch #367 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000320854\n",
      "Evaluation/AverageReturn                 -0.0030099\n",
      "Evaluation/Iteration                    367\n",
      "Evaluation/MaxReturn                     -0.00290667\n",
      "Evaluation/MinReturn                     -0.00311312\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000103226\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90311\n",
      "GaussianMLPPolicy/KL                      1.87978e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.02147e-06\n",
      "GaussianMLPPolicy/LossBefore             -7.01879e-06\n",
      "GaussianMLPPolicy/dLoss                   2.67346e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.60362\n",
      "GaussianMLPValueFunction/LossBefore      -6.80555\n",
      "GaussianMLPValueFunction/dLoss           -0.201929\n",
      "TotalEnvSteps                        735264\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.2002e-06,  1.7945e-05,  7.0748e-09,  ...,  3.2296e-04,\n",
      "        -1.3154e-04,  3.6743e-04])\n",
      "G is: \n",
      "tensor([[1.6005e-06, 7.9650e-01],\n",
      "        [7.9650e-01, 3.9639e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [396394.9688,      0.0000]])\n",
      "loss before is:\n",
      "tensor(6.0013e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(6.0009e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:21 | [trpo_pendulum] epoch #368 | Saving snapshot...\n",
      "2022-08-23 10:43:21 | [trpo_pendulum] epoch #368 | Saved\n",
      "2022-08-23 10:43:21 | [trpo_pendulum] epoch #368 | Time 362.88 s\n",
      "2022-08-23 10:43:21 | [trpo_pendulum] epoch #368 | EpochTime 1.03 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000258501\n",
      "Evaluation/AverageReturn                 -0.00264489\n",
      "Evaluation/Iteration                    368\n",
      "Evaluation/MaxReturn                     -0.00253032\n",
      "Evaluation/MinReturn                     -0.00275945\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000114567\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90311\n",
      "GaussianMLPPolicy/KL                      3.25525e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               6.00087e-05\n",
      "GaussianMLPPolicy/LossBefore              6.00133e-05\n",
      "GaussianMLPPolicy/dLoss                   4.57294e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.62653\n",
      "GaussianMLPValueFunction/LossBefore      -6.74249\n",
      "GaussianMLPValueFunction/dLoss           -0.115967\n",
      "TotalEnvSteps                        737262\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.9865e-06,  1.0447e-05, -8.9112e-08,  ...,  1.6652e-04,\n",
      "        -6.8477e-05,  1.8915e-04])\n",
      "G is: \n",
      "tensor([[4.2545e-07, 2.1172e-01],\n",
      "        [2.1172e-01, 1.0537e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [105372.3594,      0.0000]])\n",
      "loss before is:\n",
      "tensor(8.6402e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(8.6401e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:22 | [trpo_pendulum] epoch #369 | Saving snapshot...\n",
      "2022-08-23 10:43:22 | [trpo_pendulum] epoch #369 | Saved\n",
      "2022-08-23 10:43:22 | [trpo_pendulum] epoch #369 | Time 363.89 s\n",
      "2022-08-23 10:43:22 | [trpo_pendulum] epoch #369 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000259306\n",
      "Evaluation/AverageReturn                 -0.00263832\n",
      "Evaluation/Iteration                    369\n",
      "Evaluation/MaxReturn                     -0.00242214\n",
      "Evaluation/MinReturn                     -0.0028545\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000216183\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.90311\n",
      "GaussianMLPPolicy/KL                      8.67937e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               8.64009e-05\n",
      "GaussianMLPPolicy/LossBefore              8.64019e-05\n",
      "GaussianMLPPolicy/dLoss                   1.06957e-09\n",
      "GaussianMLPValueFunction/LossAfter       -5.74364\n",
      "GaussianMLPValueFunction/LossBefore      -6.66955\n",
      "GaussianMLPValueFunction/dLoss           -0.925905\n",
      "TotalEnvSteps                        739260\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.2236e-05, -6.9798e-05,  9.1845e-08,  ..., -1.3796e-03,\n",
      "         5.5887e-04, -1.5717e-03])\n",
      "G is: \n",
      "tensor([[2.9215e-05, 1.4538e+01],\n",
      "        [1.4538e+01, 7.2350e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [7234976.,       0.]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:23 | [trpo_pendulum] epoch #370 | Saving snapshot...\n",
      "2022-08-23 10:43:23 | [trpo_pendulum] epoch #370 | Saved\n",
      "2022-08-23 10:43:23 | [trpo_pendulum] epoch #370 | Time 364.84 s\n",
      "2022-08-23 10:43:23 | [trpo_pendulum] epoch #370 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000264062\n",
      "Evaluation/AverageReturn                 -0.00274953\n",
      "Evaluation/Iteration                    370\n",
      "Evaluation/MaxReturn                     -0.00266226\n",
      "Evaluation/MinReturn                     -0.0028368\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.727e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.91172\n",
      "GaussianMLPPolicy/KL                      0.000232871\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00024495\n",
      "GaussianMLPPolicy/LossBefore              0.000245272\n",
      "GaussianMLPPolicy/dLoss                   3.22121e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.7353\n",
      "GaussianMLPValueFunction/LossBefore      -5.53753\n",
      "GaussianMLPValueFunction/dLoss            1.19778\n",
      "TotalEnvSteps                        741258\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.3987e-06,  5.6898e-06,  4.0255e-08,  ...,  8.5544e-05,\n",
      "        -3.5255e-05,  9.7011e-05])\n",
      "G is: \n",
      "tensor([[1.1231e-07, 5.6827e-02],\n",
      "        [5.6827e-02, 2.8775e+04]])\n",
      "eig is:\n",
      "tensor([[-1.9531e-03,  0.0000e+00],\n",
      "        [ 2.8775e+04,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-6.7545e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-6.7546e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:24 | [trpo_pendulum] epoch #371 | Saving snapshot...\n",
      "2022-08-23 10:43:24 | [trpo_pendulum] epoch #371 | Saved\n",
      "2022-08-23 10:43:24 | [trpo_pendulum] epoch #371 | Time 365.81 s\n",
      "2022-08-23 10:43:24 | [trpo_pendulum] epoch #371 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000256374\n",
      "Evaluation/AverageReturn                 -0.00258804\n",
      "Evaluation/Iteration                    371\n",
      "Evaluation/MaxReturn                     -0.00245516\n",
      "Evaluation/MinReturn                     -0.00272091\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000132878\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.91172\n",
      "GaussianMLPPolicy/KL                      2.21504e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.75457e-05\n",
      "GaussianMLPPolicy/LossBefore             -6.75455e-05\n",
      "GaussianMLPPolicy/dLoss                   2.25555e-10\n",
      "GaussianMLPValueFunction/LossAfter       -6.78013\n",
      "GaussianMLPValueFunction/LossBefore      -6.72722\n",
      "GaussianMLPValueFunction/dLoss            0.0529165\n",
      "TotalEnvSteps                        743256\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.5524e-06,  3.1425e-05,  3.4987e-08,  ...,  5.4713e-04,\n",
      "        -2.2340e-04,  6.2207e-04])\n",
      "G is: \n",
      "tensor([[4.5930e-06, 2.3260e+00],\n",
      "        [2.3260e+00, 1.1780e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1177994.7500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(2.3061e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(2.3048e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:25 | [trpo_pendulum] epoch #372 | Saving snapshot...\n",
      "2022-08-23 10:43:25 | [trpo_pendulum] epoch #372 | Saved\n",
      "2022-08-23 10:43:25 | [trpo_pendulum] epoch #372 | Time 366.78 s\n",
      "2022-08-23 10:43:25 | [trpo_pendulum] epoch #372 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000293072\n",
      "Evaluation/AverageReturn                 -0.00261261\n",
      "Evaluation/Iteration                    372\n",
      "Evaluation/MaxReturn                     -0.00258421\n",
      "Evaluation/MinReturn                     -0.00264102\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.84044e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.91172\n",
      "GaussianMLPPolicy/KL                      9.09329e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               2.30483e-05\n",
      "GaussianMLPPolicy/LossBefore              2.30611e-05\n",
      "GaussianMLPPolicy/dLoss                   1.28293e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.35312\n",
      "GaussianMLPValueFunction/LossBefore      -6.82811\n",
      "GaussianMLPValueFunction/dLoss           -0.474981\n",
      "TotalEnvSteps                        745254\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-2.1259e-06, -3.1208e-05,  3.7014e-09,  ..., -5.4164e-04,\n",
      "         2.2126e-04, -6.1581e-04])\n",
      "G is: \n",
      "tensor([[4.5014e-06, 2.2797e+00],\n",
      "        [2.2797e+00, 1.1545e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [1154500.,       0.]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:26 | [trpo_pendulum] epoch #373 | Saving snapshot...\n",
      "2022-08-23 10:43:26 | [trpo_pendulum] epoch #373 | Saved\n",
      "2022-08-23 10:43:26 | [trpo_pendulum] epoch #373 | Time 367.72 s\n",
      "2022-08-23 10:43:26 | [trpo_pendulum] epoch #373 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000225118\n",
      "Evaluation/AverageReturn                 -0.00240595\n",
      "Evaluation/Iteration                    373\n",
      "Evaluation/MaxReturn                     -0.00239365\n",
      "Evaluation/MinReturn                     -0.00241825\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.22988e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.91172\n",
      "GaussianMLPPolicy/KL                      8.83679e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000141425\n",
      "GaussianMLPPolicy/LossBefore              0.000141438\n",
      "GaussianMLPPolicy/dLoss                   1.23982e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.48447\n",
      "GaussianMLPValueFunction/LossBefore      -6.40669\n",
      "GaussianMLPValueFunction/dLoss            0.0777769\n",
      "TotalEnvSteps                        747252\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.4813e-06,  1.4129e-05,  1.6832e-08,  ...,  2.3322e-04,\n",
      "        -9.5565e-05,  2.6495e-04])\n",
      "G is: \n",
      "tensor([[8.3445e-07, 4.2258e-01],\n",
      "        [4.2258e-01, 2.1401e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [214005.8125,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:27 | [trpo_pendulum] epoch #374 | Saving snapshot...\n",
      "2022-08-23 10:43:27 | [trpo_pendulum] epoch #374 | Saved\n",
      "2022-08-23 10:43:27 | [trpo_pendulum] epoch #374 | Time 368.66 s\n",
      "2022-08-23 10:43:27 | [trpo_pendulum] epoch #374 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000261426\n",
      "Evaluation/AverageReturn                 -0.00256853\n",
      "Evaluation/Iteration                    374\n",
      "Evaluation/MaxReturn                     -0.00251659\n",
      "Evaluation/MinReturn                     -0.00262048\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.19431e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.91172\n",
      "GaussianMLPPolicy/KL                      1.62985e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000133576\n",
      "GaussianMLPPolicy/LossBefore              0.000133578\n",
      "GaussianMLPPolicy/dLoss                   2.41562e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.73625\n",
      "GaussianMLPValueFunction/LossBefore      -6.45659\n",
      "GaussianMLPValueFunction/dLoss            0.279661\n",
      "TotalEnvSteps                        749250\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-8.2904e-07,  2.5909e-05, -2.0256e-07,  ...,  3.8316e-04,\n",
      "        -1.5853e-04,  4.3461e-04])\n",
      "G is: \n",
      "tensor([[2.2524e-06, 1.1405e+00],\n",
      "        [1.1405e+00, 5.7754e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [577544.1250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-2.0046e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-2.0070e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:28 | [trpo_pendulum] epoch #375 | Saving snapshot...\n",
      "2022-08-23 10:43:28 | [trpo_pendulum] epoch #375 | Saved\n",
      "2022-08-23 10:43:28 | [trpo_pendulum] epoch #375 | Time 369.61 s\n",
      "2022-08-23 10:43:28 | [trpo_pendulum] epoch #375 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000290609\n",
      "Evaluation/AverageReturn                 -0.00285451\n",
      "Evaluation/Iteration                    375\n",
      "Evaluation/MaxReturn                     -0.002735\n",
      "Evaluation/MinReturn                     -0.00297402\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000119508\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.91168\n",
      "GaussianMLPPolicy/KL                      1.6405e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -2.00696e-05\n",
      "GaussianMLPPolicy/LossBefore             -2.00462e-05\n",
      "GaussianMLPPolicy/dLoss                   2.33867e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.41984\n",
      "GaussianMLPValueFunction/LossBefore      -6.81861\n",
      "GaussianMLPValueFunction/dLoss           -0.398763\n",
      "TotalEnvSteps                        751248\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.9088e-06, -1.9329e-06, -3.7670e-07,  ..., -1.8466e-04,\n",
      "         7.0940e-05, -2.1232e-04])\n",
      "G is: \n",
      "tensor([[5.2538e-07, 2.6525e-01],\n",
      "        [2.6525e-01, 1.3432e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [134315.7500,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:29 | [trpo_pendulum] epoch #376 | Saving snapshot...\n",
      "2022-08-23 10:43:29 | [trpo_pendulum] epoch #376 | Saved\n",
      "2022-08-23 10:43:29 | [trpo_pendulum] epoch #376 | Time 370.58 s\n",
      "2022-08-23 10:43:29 | [trpo_pendulum] epoch #376 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000258604\n",
      "Evaluation/AverageReturn                 -0.00276789\n",
      "Evaluation/Iteration                    376\n",
      "Evaluation/MaxReturn                     -0.00274345\n",
      "Evaluation/MinReturn                     -0.00279233\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.44403e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.91194\n",
      "GaussianMLPPolicy/KL                      7.56925e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000125423\n",
      "GaussianMLPPolicy/LossBefore              0.00012553\n",
      "GaussianMLPPolicy/dLoss                   1.07102e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.39878\n",
      "GaussianMLPValueFunction/LossBefore      -6.48598\n",
      "GaussianMLPValueFunction/dLoss           -1.08719\n",
      "TotalEnvSteps                        753246\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.4865e-06,  7.3889e-05,  2.7821e-07,  ...,  1.2657e-03,\n",
      "        -5.1744e-04,  1.4383e-03])\n",
      "G is: \n",
      "tensor([[2.4573e-05, 1.2449e+01],\n",
      "        [1.2449e+01, 6.3070e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [6307049.,       0.]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:30 | [trpo_pendulum] epoch #377 | Saving snapshot...\n",
      "2022-08-23 10:43:30 | [trpo_pendulum] epoch #377 | Saved\n",
      "2022-08-23 10:43:30 | [trpo_pendulum] epoch #377 | Time 371.61 s\n",
      "2022-08-23 10:43:30 | [trpo_pendulum] epoch #377 | EpochTime 1.03 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000288008\n",
      "Evaluation/AverageReturn                 -0.00266256\n",
      "Evaluation/Iteration                    377\n",
      "Evaluation/MaxReturn                     -0.00259859\n",
      "Evaluation/MinReturn                     -0.00272653\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.39681e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.91233\n",
      "GaussianMLPPolicy/KL                      5.56054e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000257618\n",
      "GaussianMLPPolicy/LossBefore             -0.00025754\n",
      "GaussianMLPPolicy/dLoss                   7.8202e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.31787\n",
      "GaussianMLPValueFunction/LossBefore      -5.37762\n",
      "GaussianMLPValueFunction/dLoss            0.940247\n",
      "TotalEnvSteps                        755244\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.8230e-07, -5.6743e-06, -2.3540e-08,  ..., -1.0240e-04,\n",
      "         4.1730e-05, -1.1645e-04])\n",
      "G is: \n",
      "tensor([[1.6089e-07, 8.1588e-02],\n",
      "        [8.1588e-02, 4.1374e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [41373.7969,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:31 | [trpo_pendulum] epoch #378 | Saving snapshot...\n",
      "2022-08-23 10:43:31 | [trpo_pendulum] epoch #378 | Saved\n",
      "2022-08-23 10:43:31 | [trpo_pendulum] epoch #378 | Time 372.63 s\n",
      "2022-08-23 10:43:31 | [trpo_pendulum] epoch #378 | EpochTime 1.02 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000285625\n",
      "Evaluation/AverageReturn                 -0.00263564\n",
      "Evaluation/Iteration                    378\n",
      "Evaluation/MaxReturn                     -0.00256171\n",
      "Evaluation/MinReturn                     -0.00270957\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.39318e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.91233\n",
      "GaussianMLPPolicy/KL                      3.17951e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000183805\n",
      "GaussianMLPPolicy/LossBefore             -0.000183805\n",
      "GaussianMLPPolicy/dLoss                   3.34694e-10\n",
      "GaussianMLPValueFunction/LossAfter       -6.84127\n",
      "GaussianMLPValueFunction/LossBefore      -6.09524\n",
      "GaussianMLPValueFunction/dLoss            0.746028\n",
      "TotalEnvSteps                        757242\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.9372e-06,  1.4729e-05,  7.6402e-10,  ...,  2.5939e-04,\n",
      "        -1.0594e-04,  2.9490e-04])\n",
      "G is: \n",
      "tensor([[1.0323e-06, 5.2346e-01],\n",
      "        [5.2346e-01, 2.6545e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [265446.2500,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-8.8479e-06, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-8.8508e-06, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:32 | [trpo_pendulum] epoch #379 | Saving snapshot...\n",
      "2022-08-23 10:43:32 | [trpo_pendulum] epoch #379 | Saved\n",
      "2022-08-23 10:43:32 | [trpo_pendulum] epoch #379 | Time 373.64 s\n",
      "2022-08-23 10:43:32 | [trpo_pendulum] epoch #379 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00021651\n",
      "Evaluation/AverageReturn                 -0.00236845\n",
      "Evaluation/Iteration                    379\n",
      "Evaluation/MaxReturn                     -0.00229188\n",
      "Evaluation/MinReturn                     -0.00244501\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.65658e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.91233\n",
      "GaussianMLPPolicy/KL                      2.04288e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -8.85077e-06\n",
      "GaussianMLPPolicy/LossBefore             -8.84787e-06\n",
      "GaussianMLPPolicy/dLoss                   2.90675e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.7761\n",
      "GaussianMLPValueFunction/LossBefore      -6.84285\n",
      "GaussianMLPValueFunction/dLoss           -0.066752\n",
      "TotalEnvSteps                        759240\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-2.5463e-06, -1.1071e-04, -1.2067e-07,  ..., -1.6577e-03,\n",
      "         6.8437e-04, -1.8798e-03])\n",
      "G is: \n",
      "tensor([[4.2140e-05, 2.1365e+01],\n",
      "        [2.1365e+01, 1.0833e+07]])\n",
      "eig is:\n",
      "tensor([[       0.,        0.],\n",
      "        [10833194.,        0.]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:33 | [trpo_pendulum] epoch #380 | Saving snapshot...\n",
      "2022-08-23 10:43:33 | [trpo_pendulum] epoch #380 | Saved\n",
      "2022-08-23 10:43:33 | [trpo_pendulum] epoch #380 | Time 374.66 s\n",
      "2022-08-23 10:43:33 | [trpo_pendulum] epoch #380 | EpochTime 1.02 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000263265\n",
      "Evaluation/AverageReturn                 -0.00265879\n",
      "Evaluation/Iteration                    380\n",
      "Evaluation/MaxReturn                     -0.0025218\n",
      "Evaluation/MinReturn                     -0.00279579\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000136996\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.91223\n",
      "GaussianMLPPolicy/KL                      0.000226786\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000121301\n",
      "GaussianMLPPolicy/LossBefore              0.000121622\n",
      "GaussianMLPPolicy/dLoss                   3.20702e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.29983\n",
      "GaussianMLPValueFunction/LossBefore      -6.49197\n",
      "GaussianMLPValueFunction/dLoss           -0.192143\n",
      "TotalEnvSteps                        761238\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.6138e-06, -1.7203e-05, -3.1810e-07,  ..., -3.0406e-04,\n",
      "         1.2369e-04, -3.4561e-04])\n",
      "G is: \n",
      "tensor([[1.4179e-06, 7.1874e-01],\n",
      "        [7.1874e-01, 3.6434e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [364341.8438,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:34 | [trpo_pendulum] epoch #381 | Saving snapshot...\n",
      "2022-08-23 10:43:34 | [trpo_pendulum] epoch #381 | Saved\n",
      "2022-08-23 10:43:34 | [trpo_pendulum] epoch #381 | Time 375.60 s\n",
      "2022-08-23 10:43:34 | [trpo_pendulum] epoch #381 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000275679\n",
      "Evaluation/AverageReturn                 -0.00267342\n",
      "Evaluation/Iteration                    381\n",
      "Evaluation/MaxReturn                     -0.00263809\n",
      "Evaluation/MinReturn                     -0.00270875\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.53299e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.91223\n",
      "GaussianMLPPolicy/KL                      2.77669e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000187906\n",
      "GaussianMLPPolicy/LossBefore             -0.000187902\n",
      "GaussianMLPPolicy/dLoss                   3.92902e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.76588\n",
      "GaussianMLPValueFunction/LossBefore      -6.06136\n",
      "GaussianMLPValueFunction/dLoss            0.704524\n",
      "TotalEnvSteps                        763236\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.3919e-06, -8.3146e-06,  3.6773e-08,  ..., -1.3464e-04,\n",
      "         5.5317e-05, -1.5291e-04])\n",
      "G is: \n",
      "tensor([[2.7814e-07, 1.4098e-01],\n",
      "        [1.4098e-01, 7.1473e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [71472.6875,     0.0000]])\n",
      "loss before is:\n",
      "tensor(3.9426e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(3.9425e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:35 | [trpo_pendulum] epoch #382 | Saving snapshot...\n",
      "2022-08-23 10:43:35 | [trpo_pendulum] epoch #382 | Saved\n",
      "2022-08-23 10:43:35 | [trpo_pendulum] epoch #382 | Time 376.54 s\n",
      "2022-08-23 10:43:35 | [trpo_pendulum] epoch #382 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000254288\n",
      "Evaluation/AverageReturn                 -0.00250298\n",
      "Evaluation/Iteration                    382\n",
      "Evaluation/MaxReturn                     -0.00243577\n",
      "Evaluation/MinReturn                     -0.00257018\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.7206e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.91223\n",
      "GaussianMLPPolicy/KL                      5.54818e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               3.94254e-05\n",
      "GaussianMLPPolicy/LossBefore              3.94261e-05\n",
      "GaussianMLPPolicy/dLoss                   7.63976e-10\n",
      "GaussianMLPValueFunction/LossAfter       -6.83457\n",
      "GaussianMLPValueFunction/LossBefore      -6.81603\n",
      "GaussianMLPValueFunction/dLoss            0.0185466\n",
      "TotalEnvSteps                        765234\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.4540e-06,  2.8115e-06, -8.3274e-09,  ...,  4.3214e-05,\n",
      "        -1.7817e-05,  4.9035e-05])\n",
      "G is: \n",
      "tensor([[2.8676e-08, 1.4521e-02],\n",
      "        [1.4521e-02, 7.3618e+03]])\n",
      "eig is:\n",
      "tensor([[   0.0000,    0.0000],\n",
      "        [7361.7705,    0.0000]])\n",
      "loss before is:\n",
      "tensor(-2.4770e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-2.4770e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:36 | [trpo_pendulum] epoch #383 | Saving snapshot...\n",
      "2022-08-23 10:43:36 | [trpo_pendulum] epoch #383 | Saved\n",
      "2022-08-23 10:43:36 | [trpo_pendulum] epoch #383 | Time 377.56 s\n",
      "2022-08-23 10:43:36 | [trpo_pendulum] epoch #383 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00024784\n",
      "Evaluation/AverageReturn                 -0.00259686\n",
      "Evaluation/Iteration                    383\n",
      "Evaluation/MaxReturn                     -0.00250513\n",
      "Evaluation/MinReturn                     -0.0026886\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      9.17372e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.91223\n",
      "GaussianMLPPolicy/KL                      5.96046e-08\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -2.47698e-05\n",
      "GaussianMLPPolicy/LossBefore             -2.47698e-05\n",
      "GaussianMLPPolicy/dLoss                   6.36646e-11\n",
      "GaussianMLPValueFunction/LossAfter       -6.67404\n",
      "GaussianMLPValueFunction/LossBefore      -6.83633\n",
      "GaussianMLPValueFunction/dLoss           -0.162292\n",
      "TotalEnvSteps                        767232\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.9742e-06,  2.3130e-05,  8.4574e-08,  ...,  3.8627e-04,\n",
      "        -1.5812e-04,  4.3883e-04])\n",
      "G is: \n",
      "tensor([[2.2887e-06, 1.1603e+00],\n",
      "        [1.1603e+00, 5.8822e+05]])\n",
      "eig is:\n",
      "tensor([[     0.,      0.],\n",
      "        [588221.,      0.]])\n",
      "loss before is:\n",
      "tensor(-6.8109e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-6.8116e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:37 | [trpo_pendulum] epoch #384 | Saving snapshot...\n",
      "2022-08-23 10:43:37 | [trpo_pendulum] epoch #384 | Saved\n",
      "2022-08-23 10:43:37 | [trpo_pendulum] epoch #384 | Time 378.51 s\n",
      "2022-08-23 10:43:37 | [trpo_pendulum] epoch #384 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000251453\n",
      "Evaluation/AverageReturn                 -0.00274087\n",
      "Evaluation/Iteration                    384\n",
      "Evaluation/MaxReturn                     -0.00268289\n",
      "Evaluation/MinReturn                     -0.00279884\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.79759e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.91223\n",
      "GaussianMLPPolicy/KL                      4.49893e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.81156e-05\n",
      "GaussianMLPPolicy/LossBefore             -6.81093e-05\n",
      "GaussianMLPPolicy/dLoss                   6.33736e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.02781\n",
      "GaussianMLPValueFunction/LossBefore      -6.74369\n",
      "GaussianMLPValueFunction/dLoss           -0.715877\n",
      "TotalEnvSteps                        769230\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.3977e-06,  7.6557e-05,  1.0669e-09,  ...,  1.3217e-03,\n",
      "        -5.4024e-04,  1.5024e-03])\n",
      "G is: \n",
      "tensor([[2.6801e-05, 1.3585e+01],\n",
      "        [1.3585e+01, 6.8865e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [6886505.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:38 | [trpo_pendulum] epoch #385 | Saving snapshot...\n",
      "2022-08-23 10:43:38 | [trpo_pendulum] epoch #385 | Saved\n",
      "2022-08-23 10:43:38 | [trpo_pendulum] epoch #385 | Time 379.60 s\n",
      "2022-08-23 10:43:38 | [trpo_pendulum] epoch #385 | EpochTime 1.09 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000268123\n",
      "Evaluation/AverageReturn                 -0.00271765\n",
      "Evaluation/Iteration                    385\n",
      "Evaluation/MaxReturn                     -0.00263434\n",
      "Evaluation/MinReturn                     -0.00280096\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.33113e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.91223\n",
      "GaussianMLPPolicy/KL                      5.25356e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000183857\n",
      "GaussianMLPPolicy/LossBefore             -0.000183783\n",
      "GaussianMLPPolicy/dLoss                   7.46368e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.37336\n",
      "GaussianMLPValueFunction/LossBefore      -6.08544\n",
      "GaussianMLPValueFunction/dLoss            0.287928\n",
      "TotalEnvSteps                        771228\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.8759e-06, -2.3156e-05, -3.0943e-07,  ..., -3.4931e-04,\n",
      "         1.4374e-04, -3.9607e-04])\n",
      "G is: \n",
      "tensor([[1.8709e-06, 9.4832e-01],\n",
      "        [9.4832e-01, 4.8075e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [480752.4375,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:39 | [trpo_pendulum] epoch #386 | Saving snapshot...\n",
      "2022-08-23 10:43:39 | [trpo_pendulum] epoch #386 | Saved\n",
      "2022-08-23 10:43:39 | [trpo_pendulum] epoch #386 | Time 380.62 s\n",
      "2022-08-23 10:43:39 | [trpo_pendulum] epoch #386 | EpochTime 1.02 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000265894\n",
      "Evaluation/AverageReturn                 -0.00258392\n",
      "Evaluation/Iteration                    386\n",
      "Evaluation/MaxReturn                     -0.00253752\n",
      "Evaluation/MinReturn                     -0.00263033\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.64027e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.91889\n",
      "GaussianMLPPolicy/KL                      6.65416e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000147307\n",
      "GaussianMLPPolicy/LossBefore             -0.000147214\n",
      "GaussianMLPPolicy/dLoss                   9.32341e-08\n",
      "GaussianMLPValueFunction/LossAfter       -4.90106\n",
      "GaussianMLPValueFunction/LossBefore      -6.3592\n",
      "GaussianMLPValueFunction/dLoss           -1.45814\n",
      "TotalEnvSteps                        773226\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-2.8863e-06, -1.4108e-05, -1.5097e-06,  ..., -1.7010e-04,\n",
      "         6.9583e-05, -1.9142e-04])\n",
      "G is: \n",
      "tensor([[4.4237e-07, 2.2685e-01],\n",
      "        [2.2685e-01, 1.1651e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [116514.4375,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:40 | [trpo_pendulum] epoch #387 | Saving snapshot...\n",
      "2022-08-23 10:43:40 | [trpo_pendulum] epoch #387 | Saved\n",
      "2022-08-23 10:43:40 | [trpo_pendulum] epoch #387 | Time 381.61 s\n",
      "2022-08-23 10:43:40 | [trpo_pendulum] epoch #387 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000284207\n",
      "Evaluation/AverageReturn                 -0.00296548\n",
      "Evaluation/Iteration                    387\n",
      "Evaluation/MaxReturn                     -0.00280246\n",
      "Evaluation/MinReturn                     -0.00312849\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000163015\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.91777\n",
      "GaussianMLPPolicy/KL                      0.000136546\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0002325\n",
      "GaussianMLPPolicy/LossBefore             -0.000232309\n",
      "GaussianMLPPolicy/dLoss                   1.91023e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.76812\n",
      "GaussianMLPValueFunction/LossBefore      -5.58517\n",
      "GaussianMLPValueFunction/dLoss            1.18294\n",
      "TotalEnvSteps                        775224\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.2709e-06, -1.2848e-05,  3.6988e-07,  ..., -2.0055e-04,\n",
      "         8.3082e-05, -2.2766e-04])\n",
      "G is: \n",
      "tensor([[6.1706e-07, 3.1608e-01],\n",
      "        [3.1608e-01, 1.6194e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [161944.7188,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-6.6569e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-6.6629e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:41 | [trpo_pendulum] epoch #388 | Saving snapshot...\n",
      "2022-08-23 10:43:41 | [trpo_pendulum] epoch #388 | Saved\n",
      "2022-08-23 10:43:41 | [trpo_pendulum] epoch #388 | Time 382.60 s\n",
      "2022-08-23 10:43:41 | [trpo_pendulum] epoch #388 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000287091\n",
      "Evaluation/AverageReturn                 -0.0028326\n",
      "Evaluation/Iteration                    388\n",
      "Evaluation/MaxReturn                     -0.00279447\n",
      "Evaluation/MinReturn                     -0.00287073\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.81304e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.92277\n",
      "GaussianMLPPolicy/KL                      4.39634e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.66293e-05\n",
      "GaussianMLPPolicy/LossBefore             -6.65688e-05\n",
      "GaussianMLPPolicy/dLoss                   6.04923e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.54653\n",
      "GaussianMLPValueFunction/LossBefore      -6.72673\n",
      "GaussianMLPValueFunction/dLoss           -0.180192\n",
      "TotalEnvSteps                        777222\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.5596e-06,  8.7554e-06,  8.8062e-10,  ...,  1.5593e-04,\n",
      "        -6.3623e-05,  1.7727e-04])\n",
      "G is: \n",
      "tensor([[3.7290e-07, 1.9301e-01],\n",
      "        [1.9301e-01, 9.9913e+04]])\n",
      "eig is:\n",
      "tensor([[-7.8125e-03,  0.0000e+00],\n",
      "        [ 9.9913e+04,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(6.1010e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(6.1009e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:42 | [trpo_pendulum] epoch #389 | Saving snapshot...\n",
      "2022-08-23 10:43:42 | [trpo_pendulum] epoch #389 | Saved\n",
      "2022-08-23 10:43:42 | [trpo_pendulum] epoch #389 | Time 383.59 s\n",
      "2022-08-23 10:43:42 | [trpo_pendulum] epoch #389 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000252986\n",
      "Evaluation/AverageReturn                 -0.00251993\n",
      "Evaluation/Iteration                    389\n",
      "Evaluation/MaxReturn                     -0.00251863\n",
      "Evaluation/MinReturn                     -0.00252123\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.30216e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.92277\n",
      "GaussianMLPPolicy/KL                      7.12839e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               6.10089e-05\n",
      "GaussianMLPPolicy/LossBefore              6.10098e-05\n",
      "GaussianMLPPolicy/dLoss                   9.34961e-10\n",
      "GaussianMLPValueFunction/LossAfter       -4.63067\n",
      "GaussianMLPValueFunction/LossBefore      -6.76868\n",
      "GaussianMLPValueFunction/dLoss           -2.13801\n",
      "TotalEnvSteps                        779220\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.5703e-05, -4.5305e-05, -4.5109e-09,  ..., -7.8819e-04,\n",
      "         3.2210e-04, -8.9579e-04])\n",
      "G is: \n",
      "tensor([[9.5277e-06, 4.9316e+00],\n",
      "        [4.9316e+00, 2.5529e+06]])\n",
      "eig is:\n",
      "tensor([[2.5000e-01, 0.0000e+00],\n",
      "        [2.5529e+06, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:43 | [trpo_pendulum] epoch #390 | Saving snapshot...\n",
      "2022-08-23 10:43:43 | [trpo_pendulum] epoch #390 | Saved\n",
      "2022-08-23 10:43:43 | [trpo_pendulum] epoch #390 | Time 384.52 s\n",
      "2022-08-23 10:43:43 | [trpo_pendulum] epoch #390 | EpochTime 0.92 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000280827\n",
      "Evaluation/AverageReturn                 -0.0026155\n",
      "Evaluation/Iteration                    390\n",
      "Evaluation/MaxReturn                     -0.00253964\n",
      "Evaluation/MinReturn                     -0.00269137\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.5865e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.94114\n",
      "GaussianMLPPolicy/KL                      0.000364784\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000317345\n",
      "GaussianMLPPolicy/LossBefore              0.000317842\n",
      "GaussianMLPPolicy/dLoss                   4.96744e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.37867\n",
      "GaussianMLPValueFunction/LossBefore      -4.59295\n",
      "GaussianMLPValueFunction/dLoss            1.78572\n",
      "TotalEnvSteps                        781218\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.3426e-06,  4.6304e-05,  3.8655e-08,  ...,  8.1728e-04,\n",
      "        -3.3344e-04,  9.2919e-04])\n",
      "G is: \n",
      "tensor([[1.0244e-05, 5.5008e+00],\n",
      "        [5.5008e+00, 2.9537e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [2953748.2500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:44 | [trpo_pendulum] epoch #391 | Saving snapshot...\n",
      "2022-08-23 10:43:44 | [trpo_pendulum] epoch #391 | Saved\n",
      "2022-08-23 10:43:44 | [trpo_pendulum] epoch #391 | Time 385.49 s\n",
      "2022-08-23 10:43:44 | [trpo_pendulum] epoch #391 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000241146\n",
      "Evaluation/AverageReturn                 -0.00243985\n",
      "Evaluation/Iteration                    391\n",
      "Evaluation/MaxReturn                     -0.0023533\n",
      "Evaluation/MinReturn                     -0.0025264\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.65481e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.94114\n",
      "GaussianMLPPolicy/KL                      1.89896e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00015008\n",
      "GaussianMLPPolicy/LossBefore             -0.000150053\n",
      "GaussianMLPPolicy/dLoss                   2.69647e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.53245\n",
      "GaussianMLPValueFunction/LossBefore      -6.3479\n",
      "GaussianMLPValueFunction/dLoss            0.184553\n",
      "TotalEnvSteps                        783216\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-2.4267e-06,  9.8604e-06,  4.0759e-07,  ...,  2.5116e-04,\n",
      "        -9.9915e-05,  2.8666e-04])\n",
      "G is: \n",
      "tensor([[9.6799e-07, 5.1944e-01],\n",
      "        [5.1944e-01, 2.7887e+05]])\n",
      "eig is:\n",
      "tensor([[     0.,      0.],\n",
      "        [278874.,      0.]])\n",
      "loss before is:\n",
      "tensor(-7.3033e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-7.3059e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:45 | [trpo_pendulum] epoch #392 | Saving snapshot...\n",
      "2022-08-23 10:43:45 | [trpo_pendulum] epoch #392 | Saved\n",
      "2022-08-23 10:43:45 | [trpo_pendulum] epoch #392 | Time 386.42 s\n",
      "2022-08-23 10:43:45 | [trpo_pendulum] epoch #392 | EpochTime 0.92 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00026364\n",
      "Evaluation/AverageReturn                 -0.00268181\n",
      "Evaluation/Iteration                    392\n",
      "Evaluation/MaxReturn                     -0.00263321\n",
      "Evaluation/MinReturn                     -0.00273041\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.86021e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.94102\n",
      "GaussianMLPPolicy/KL                      1.81891e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.30586e-05\n",
      "GaussianMLPPolicy/LossBefore             -7.30328e-05\n",
      "GaussianMLPPolicy/dLoss                   2.58078e-08\n",
      "GaussianMLPValueFunction/LossAfter       -5.55435\n",
      "GaussianMLPValueFunction/LossBefore      -6.71117\n",
      "GaussianMLPValueFunction/dLoss           -1.15681\n",
      "TotalEnvSteps                        785214\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-8.3576e-06,  4.8792e-05,  2.1804e-07,  ...,  8.3485e-04,\n",
      "        -3.4099e-04,  9.4873e-04])\n",
      "G is: \n",
      "tensor([[1.0688e-05, 5.7373e+00],\n",
      "        [5.7373e+00, 3.0798e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [3079775.,       0.]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:46 | [trpo_pendulum] epoch #393 | Saving snapshot...\n",
      "2022-08-23 10:43:46 | [trpo_pendulum] epoch #393 | Saved\n",
      "2022-08-23 10:43:46 | [trpo_pendulum] epoch #393 | Time 387.42 s\n",
      "2022-08-23 10:43:46 | [trpo_pendulum] epoch #393 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00023418\n",
      "Evaluation/AverageReturn                 -0.00254956\n",
      "Evaluation/Iteration                    393\n",
      "Evaluation/MaxReturn                     -0.00253546\n",
      "Evaluation/MinReturn                     -0.00256367\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.41071e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.93687\n",
      "GaussianMLPPolicy/KL                      5.71172e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000274942\n",
      "GaussianMLPPolicy/LossBefore             -0.00027486\n",
      "GaussianMLPPolicy/dLoss                   8.24512e-08\n",
      "GaussianMLPValueFunction/LossAfter       -5.63796\n",
      "GaussianMLPValueFunction/LossBefore      -5.15634\n",
      "GaussianMLPValueFunction/dLoss            0.481614\n",
      "TotalEnvSteps                        787212\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.0973e-05,  5.2055e-05, -1.2789e-06,  ...,  1.1517e-03,\n",
      "        -4.6561e-04,  1.3138e-03])\n",
      "G is: \n",
      "tensor([[2.0371e-05, 1.0843e+01],\n",
      "        [1.0843e+01, 5.7727e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [5772746.,       0.]])\n",
      "loss before is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:47 | [trpo_pendulum] epoch #394 | Saving snapshot...\n",
      "2022-08-23 10:43:47 | [trpo_pendulum] epoch #394 | Saved\n",
      "2022-08-23 10:43:47 | [trpo_pendulum] epoch #394 | Time 388.35 s\n",
      "2022-08-23 10:43:47 | [trpo_pendulum] epoch #394 | EpochTime 0.92 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000272185\n",
      "Evaluation/AverageReturn                 -0.00277682\n",
      "Evaluation/Iteration                    394\n",
      "Evaluation/MaxReturn                     -0.0026358\n",
      "Evaluation/MinReturn                     -0.00291784\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000141021\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.93166\n",
      "GaussianMLPPolicy/KL                      0.000233963\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000295408\n",
      "GaussianMLPPolicy/LossBefore              0.000295759\n",
      "GaussianMLPPolicy/dLoss                   3.51254e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.81411\n",
      "GaussianMLPValueFunction/LossBefore      -4.85671\n",
      "GaussianMLPValueFunction/dLoss            1.9574\n",
      "TotalEnvSteps                        789210\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.5888e-06,  2.0397e-05,  3.3255e-08,  ...,  3.5534e-04,\n",
      "        -1.4515e-04,  4.0378e-04])\n",
      "G is: \n",
      "tensor([[1.9357e-06, 1.0197e+00],\n",
      "        [1.0197e+00, 5.3720e+05]])\n",
      "eig is:\n",
      "tensor([[6.2500e-02, 0.0000e+00],\n",
      "        [5.3720e+05, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-5.1573e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-5.1578e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:48 | [trpo_pendulum] epoch #395 | Saving snapshot...\n",
      "2022-08-23 10:43:48 | [trpo_pendulum] epoch #395 | Saved\n",
      "2022-08-23 10:43:48 | [trpo_pendulum] epoch #395 | Time 389.40 s\n",
      "2022-08-23 10:43:48 | [trpo_pendulum] epoch #395 | EpochTime 1.05 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000275057\n",
      "Evaluation/AverageReturn                 -0.0025245\n",
      "Evaluation/Iteration                    395\n",
      "Evaluation/MaxReturn                     -0.00247812\n",
      "Evaluation/MinReturn                     -0.00257088\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.6379e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.93166\n",
      "GaussianMLPPolicy/KL                      3.66661e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.15783e-05\n",
      "GaussianMLPPolicy/LossBefore             -5.15732e-05\n",
      "GaussianMLPPolicy/dLoss                   5.16229e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.8499\n",
      "GaussianMLPValueFunction/LossBefore      -6.7916\n",
      "GaussianMLPValueFunction/dLoss            0.0582972\n",
      "TotalEnvSteps                        791208\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.8453e-06,  1.9541e-05, -5.0216e-08,  ...,  3.6273e-04,\n",
      "        -1.4767e-04,  4.1259e-04])\n",
      "G is: \n",
      "tensor([[2.0176e-06, 1.0628e+00],\n",
      "        [1.0628e+00, 5.5991e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [559908.3750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(8.6598e-06, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(8.6545e-06, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:49 | [trpo_pendulum] epoch #396 | Saving snapshot...\n",
      "2022-08-23 10:43:49 | [trpo_pendulum] epoch #396 | Saved\n",
      "2022-08-23 10:43:49 | [trpo_pendulum] epoch #396 | Time 390.34 s\n",
      "2022-08-23 10:43:49 | [trpo_pendulum] epoch #396 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000231778\n",
      "Evaluation/AverageReturn                 -0.00237536\n",
      "Evaluation/Iteration                    396\n",
      "Evaluation/MaxReturn                     -0.00231738\n",
      "Evaluation/MinReturn                     -0.00243333\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.79713e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.93166\n",
      "GaussianMLPPolicy/KL                      3.82693e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               8.65447e-06\n",
      "GaussianMLPPolicy/LossBefore              8.65984e-06\n",
      "GaussianMLPPolicy/dLoss                   5.36966e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.75589\n",
      "GaussianMLPValueFunction/LossBefore      -6.85185\n",
      "GaussianMLPValueFunction/dLoss           -0.0959516\n",
      "TotalEnvSteps                        793206\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.5354e-06,  1.2930e-05,  6.3863e-08,  ...,  2.3680e-04,\n",
      "        -9.6339e-05,  2.6928e-04])\n",
      "G is: \n",
      "tensor([[8.5965e-07, 4.5284e-01],\n",
      "        [4.5284e-01, 2.3855e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [238548.6250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-2.2520e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-2.2522e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:50 | [trpo_pendulum] epoch #397 | Saving snapshot...\n",
      "2022-08-23 10:43:50 | [trpo_pendulum] epoch #397 | Saved\n",
      "2022-08-23 10:43:50 | [trpo_pendulum] epoch #397 | Time 391.32 s\n",
      "2022-08-23 10:43:50 | [trpo_pendulum] epoch #397 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000241998\n",
      "Evaluation/AverageReturn                 -0.00263454\n",
      "Evaluation/Iteration                    397\n",
      "Evaluation/MaxReturn                     -0.00254477\n",
      "Evaluation/MinReturn                     -0.00272431\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.97692e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.93166\n",
      "GaussianMLPPolicy/KL                      1.62973e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -2.25225e-05\n",
      "GaussianMLPPolicy/LossBefore             -2.25201e-05\n",
      "GaussianMLPPolicy/dLoss                   2.35741e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.60204\n",
      "GaussianMLPValueFunction/LossBefore      -6.83082\n",
      "GaussianMLPValueFunction/dLoss           -0.228776\n",
      "TotalEnvSteps                        795204\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-6.9106e-06,  1.7162e-05, -4.1786e-08,  ...,  2.4612e-04,\n",
      "        -1.0202e-04,  2.7883e-04])\n",
      "G is: \n",
      "tensor([[9.2837e-07, 4.8893e-01],\n",
      "        [4.8893e-01, 2.5758e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [257579.6250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:50 | [trpo_pendulum] epoch #398 | Saving snapshot...\n",
      "2022-08-23 10:43:51 | [trpo_pendulum] epoch #398 | Saved\n",
      "2022-08-23 10:43:51 | [trpo_pendulum] epoch #398 | Time 392.31 s\n",
      "2022-08-23 10:43:51 | [trpo_pendulum] epoch #398 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000269313\n",
      "Evaluation/AverageReturn                 -0.00267341\n",
      "Evaluation/Iteration                    398\n",
      "Evaluation/MaxReturn                     -0.00266271\n",
      "Evaluation/MinReturn                     -0.00268412\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.07029e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.93048\n",
      "GaussianMLPPolicy/KL                      3.49386e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000132327\n",
      "GaussianMLPPolicy/LossBefore             -0.000132277\n",
      "GaussianMLPPolicy/dLoss                   5.05534e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.77221\n",
      "GaussianMLPValueFunction/LossBefore      -6.45561\n",
      "GaussianMLPValueFunction/dLoss            0.316599\n",
      "TotalEnvSteps                        797202\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.1362e-06,  1.9914e-05, -3.8410e-10,  ...,  3.0556e-04,\n",
      "        -1.2603e-04,  3.4648e-04])\n",
      "G is: \n",
      "tensor([[1.4309e-06, 7.5192e-01],\n",
      "        [7.5192e-01, 3.9518e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [395176.3438,      0.0000]])\n",
      "loss before is:\n",
      "tensor(6.6055e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(6.6033e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:51 | [trpo_pendulum] epoch #399 | Saving snapshot...\n",
      "2022-08-23 10:43:51 | [trpo_pendulum] epoch #399 | Saved\n",
      "2022-08-23 10:43:51 | [trpo_pendulum] epoch #399 | Time 393.26 s\n",
      "2022-08-23 10:43:51 | [trpo_pendulum] epoch #399 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000266112\n",
      "Evaluation/AverageReturn                 -0.00254119\n",
      "Evaluation/Iteration                    399\n",
      "Evaluation/MaxReturn                     -0.00253408\n",
      "Evaluation/MinReturn                     -0.00254831\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.11404e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.93085\n",
      "GaussianMLPPolicy/KL                      1.52997e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               6.60329e-05\n",
      "GaussianMLPPolicy/LossBefore              6.60546e-05\n",
      "GaussianMLPPolicy/dLoss                   2.16605e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.7033\n",
      "GaussianMLPValueFunction/LossBefore      -6.75689\n",
      "GaussianMLPValueFunction/dLoss           -0.0535913\n",
      "TotalEnvSteps                        799200\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-4.5297e-07,  1.9576e-05, -2.6624e-07,  ...,  2.7603e-04,\n",
      "        -1.1494e-04,  3.1265e-04])\n",
      "G is: \n",
      "tensor([[1.1679e-06, 6.1407e-01],\n",
      "        [6.1407e-01, 3.2298e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [322982.8125,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:52 | [trpo_pendulum] epoch #400 | Saving snapshot...\n",
      "2022-08-23 10:43:52 | [trpo_pendulum] epoch #400 | Saved\n",
      "2022-08-23 10:43:52 | [trpo_pendulum] epoch #400 | Time 394.18 s\n",
      "2022-08-23 10:43:52 | [trpo_pendulum] epoch #400 | EpochTime 0.92 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000247625\n",
      "Evaluation/AverageReturn                 -0.00258436\n",
      "Evaluation/Iteration                    400\n",
      "Evaluation/MaxReturn                     -0.00253437\n",
      "Evaluation/MinReturn                     -0.00263435\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.99914e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.93084\n",
      "GaussianMLPPolicy/KL                      1.12937e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000120864\n",
      "GaussianMLPPolicy/LossBefore              0.00012088\n",
      "GaussianMLPPolicy/dLoss                   1.60871e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.7848\n",
      "GaussianMLPValueFunction/LossBefore      -6.49109\n",
      "GaussianMLPValueFunction/dLoss            0.293713\n",
      "TotalEnvSteps                        801198\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.5131e-06,  4.8561e-06, -2.6261e-07,  ...,  3.8167e-05,\n",
      "        -1.7188e-05,  4.2721e-05])\n",
      "G is: \n",
      "tensor([[2.2508e-08, 1.1731e-02],\n",
      "        [1.1731e-02, 6.1703e+03]])\n",
      "eig is:\n",
      "tensor([[   0.0000,    0.0000],\n",
      "        [6170.3271,    0.0000]])\n",
      "loss before is:\n",
      "tensor(-5.0507e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-5.0516e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:53 | [trpo_pendulum] epoch #401 | Saving snapshot...\n",
      "2022-08-23 10:43:53 | [trpo_pendulum] epoch #401 | Saved\n",
      "2022-08-23 10:43:53 | [trpo_pendulum] epoch #401 | Time 395.18 s\n",
      "2022-08-23 10:43:53 | [trpo_pendulum] epoch #401 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000247608\n",
      "Evaluation/AverageReturn                 -0.00262199\n",
      "Evaluation/Iteration                    401\n",
      "Evaluation/MaxReturn                     -0.00242826\n",
      "Evaluation/MinReturn                     -0.00281571\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000193728\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.93104\n",
      "GaussianMLPPolicy/KL                      6.47389e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.05157e-05\n",
      "GaussianMLPPolicy/LossBefore             -5.05065e-05\n",
      "GaussianMLPPolicy/dLoss                   9.17134e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.49442\n",
      "GaussianMLPValueFunction/LossBefore      -6.77534\n",
      "GaussianMLPValueFunction/dLoss           -0.280925\n",
      "TotalEnvSteps                        803196\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.1022e-05, -1.7985e-05,  4.7861e-07,  ..., -4.2075e-04,\n",
      "         1.6978e-04, -4.8003e-04])\n",
      "G is: \n",
      "tensor([[2.7176e-06, 1.4294e+00],\n",
      "        [1.4294e+00, 7.5205e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [752052.3750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-6.5380e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-6.5481e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:54 | [trpo_pendulum] epoch #402 | Saving snapshot...\n",
      "2022-08-23 10:43:54 | [trpo_pendulum] epoch #402 | Saved\n",
      "2022-08-23 10:43:54 | [trpo_pendulum] epoch #402 | Time 396.12 s\n",
      "2022-08-23 10:43:54 | [trpo_pendulum] epoch #402 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000261258\n",
      "Evaluation/AverageReturn                 -0.00295919\n",
      "Evaluation/Iteration                    402\n",
      "Evaluation/MaxReturn                     -0.00295632\n",
      "Evaluation/MinReturn                     -0.00296206\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.86945e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.93646\n",
      "GaussianMLPPolicy/KL                      7.28486e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.54809e-05\n",
      "GaussianMLPPolicy/LossBefore             -6.53802e-05\n",
      "GaussianMLPPolicy/dLoss                   1.00743e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.5971\n",
      "GaussianMLPValueFunction/LossBefore      -6.67357\n",
      "GaussianMLPValueFunction/dLoss           -0.0764618\n",
      "TotalEnvSteps                        805194\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.4606e-06,  2.1944e-05, -1.1229e-08,  ...,  4.0275e-04,\n",
      "        -1.6416e-04,  4.5796e-04])\n",
      "G is: \n",
      "tensor([[2.4873e-06, 1.3232e+00],\n",
      "        [1.3232e+00, 7.0395e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [703946.6250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-1.3661e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-1.3668e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:55 | [trpo_pendulum] epoch #403 | Saving snapshot...\n",
      "2022-08-23 10:43:55 | [trpo_pendulum] epoch #403 | Saved\n",
      "2022-08-23 10:43:55 | [trpo_pendulum] epoch #403 | Time 397.12 s\n",
      "2022-08-23 10:43:55 | [trpo_pendulum] epoch #403 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000245395\n",
      "Evaluation/AverageReturn                 -0.00240822\n",
      "Evaluation/Iteration                    403\n",
      "Evaluation/MaxReturn                     -0.00236238\n",
      "Evaluation/MinReturn                     -0.00245406\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.58359e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.93646\n",
      "GaussianMLPPolicy/KL                      4.63216e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -1.36676e-05\n",
      "GaussianMLPPolicy/LossBefore             -1.36611e-05\n",
      "GaussianMLPPolicy/dLoss                   6.54927e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.77489\n",
      "GaussianMLPValueFunction/LossBefore      -6.83569\n",
      "GaussianMLPValueFunction/dLoss           -0.0608001\n",
      "TotalEnvSteps                        807192\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.5899e-06, -1.3706e-05, -2.7184e-07,  ..., -3.2230e-04,\n",
      "         1.2919e-04, -3.6751e-04])\n",
      "G is: \n",
      "tensor([[1.5938e-06, 8.4754e-01],\n",
      "        [8.4754e-01, 4.5082e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [450820.0625,      0.0000]])\n",
      "loss before is:\n",
      "tensor(2.7913e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(2.7899e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:56 | [trpo_pendulum] epoch #404 | Saving snapshot...\n",
      "2022-08-23 10:43:56 | [trpo_pendulum] epoch #404 | Saved\n",
      "2022-08-23 10:43:56 | [trpo_pendulum] epoch #404 | Time 398.09 s\n",
      "2022-08-23 10:43:56 | [trpo_pendulum] epoch #404 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000269654\n",
      "Evaluation/AverageReturn                 -0.00287096\n",
      "Evaluation/Iteration                    404\n",
      "Evaluation/MaxReturn                     -0.00276411\n",
      "Evaluation/MinReturn                     -0.00297782\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000106855\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.93658\n",
      "GaussianMLPPolicy/KL                      1.02004e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               2.7899e-05\n",
      "GaussianMLPPolicy/LossBefore              2.79134e-05\n",
      "GaussianMLPPolicy/dLoss                   1.44337e-08\n",
      "GaussianMLPValueFunction/LossAfter       -4.80498\n",
      "GaussianMLPValueFunction/LossBefore      -6.77475\n",
      "GaussianMLPValueFunction/dLoss           -1.96977\n",
      "TotalEnvSteps                        809190\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.4048e-06,  6.4372e-05, -5.7324e-07,  ...,  1.1830e-03,\n",
      "        -4.8276e-04,  1.3455e-03])\n",
      "G is: \n",
      "tensor([[2.1461e-05, 1.1418e+01],\n",
      "        [1.1418e+01, 6.0749e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [6074935.,       0.]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:57 | [trpo_pendulum] epoch #405 | Saving snapshot...\n",
      "2022-08-23 10:43:57 | [trpo_pendulum] epoch #405 | Saved\n",
      "2022-08-23 10:43:57 | [trpo_pendulum] epoch #405 | Time 399.11 s\n",
      "2022-08-23 10:43:57 | [trpo_pendulum] epoch #405 | EpochTime 1.02 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000239083\n",
      "Evaluation/AverageReturn                 -0.0028004\n",
      "Evaluation/Iteration                    405\n",
      "Evaluation/MaxReturn                     -0.00268147\n",
      "Evaluation/MinReturn                     -0.00291934\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000118935\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.93977\n",
      "GaussianMLPPolicy/KL                      7.4655e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000304763\n",
      "GaussianMLPPolicy/LossBefore             -0.000304656\n",
      "GaussianMLPPolicy/dLoss                   1.07422e-07\n",
      "GaussianMLPValueFunction/LossAfter       -4.20415\n",
      "GaussianMLPValueFunction/LossBefore      -4.78557\n",
      "GaussianMLPValueFunction/dLoss           -0.581412\n",
      "TotalEnvSteps                        811188\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.4448e-06,  6.7309e-05,  1.7486e-07,  ...,  1.2073e-03,\n",
      "        -4.9273e-04,  1.3720e-03])\n",
      "G is: \n",
      "tensor([[2.2344e-05, 1.1966e+01],\n",
      "        [1.1966e+01, 6.4080e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [6408037.,       0.]])\n",
      "loss before is:\n",
      "tensor(-0.0004, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0004, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:58 | [trpo_pendulum] epoch #406 | Saving snapshot...\n",
      "2022-08-23 10:43:58 | [trpo_pendulum] epoch #406 | Saved\n",
      "2022-08-23 10:43:58 | [trpo_pendulum] epoch #406 | Time 400.13 s\n",
      "2022-08-23 10:43:58 | [trpo_pendulum] epoch #406 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000235205\n",
      "Evaluation/AverageReturn                 -0.00236037\n",
      "Evaluation/Iteration                    406\n",
      "Evaluation/MaxReturn                     -0.00230212\n",
      "Evaluation/MinReturn                     -0.00241862\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.8252e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.93977\n",
      "GaussianMLPPolicy/KL                      4.15432e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000426542\n",
      "GaussianMLPPolicy/LossBefore             -0.000426483\n",
      "GaussianMLPPolicy/dLoss                   5.8586e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.80238\n",
      "GaussianMLPValueFunction/LossBefore      -2.82347\n",
      "GaussianMLPValueFunction/dLoss            3.97891\n",
      "TotalEnvSteps                        813186\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.7219e-06, -7.1278e-06,  3.3824e-08,  ..., -1.2584e-04,\n",
      "         5.1478e-05, -1.4299e-04])\n",
      "G is: \n",
      "tensor([[2.4278e-07, 1.3001e-01],\n",
      "        [1.3001e-01, 6.9623e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [69622.7266,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-4.3433e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-4.3434e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:43:59 | [trpo_pendulum] epoch #407 | Saving snapshot...\n",
      "2022-08-23 10:43:59 | [trpo_pendulum] epoch #407 | Saved\n",
      "2022-08-23 10:43:59 | [trpo_pendulum] epoch #407 | Time 401.12 s\n",
      "2022-08-23 10:43:59 | [trpo_pendulum] epoch #407 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000232045\n",
      "Evaluation/AverageReturn                 -0.00238503\n",
      "Evaluation/Iteration                    407\n",
      "Evaluation/MaxReturn                     -0.0023415\n",
      "Evaluation/MinReturn                     -0.00242857\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.35334e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.93977\n",
      "GaussianMLPPolicy/KL                      4.44529e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.34339e-05\n",
      "GaussianMLPPolicy/LossBefore             -4.34334e-05\n",
      "GaussianMLPPolicy/dLoss                   5.67525e-10\n",
      "GaussianMLPValueFunction/LossAfter       -6.84582\n",
      "GaussianMLPValueFunction/LossBefore      -6.80566\n",
      "GaussianMLPValueFunction/dLoss            0.0401597\n",
      "TotalEnvSteps                        815184\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.3124e-06,  1.5815e-05,  4.7412e-09,  ...,  2.8767e-04,\n",
      "        -1.1734e-04,  3.2699e-04])\n",
      "G is: \n",
      "tensor([[1.2687e-06, 6.7939e-01],\n",
      "        [6.7939e-01, 3.6383e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [363831.7188,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-3.4642e-06, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-3.4675e-06, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:00 | [trpo_pendulum] epoch #408 | Saving snapshot...\n",
      "2022-08-23 10:44:00 | [trpo_pendulum] epoch #408 | Saved\n",
      "2022-08-23 10:44:00 | [trpo_pendulum] epoch #408 | Time 402.15 s\n",
      "2022-08-23 10:44:00 | [trpo_pendulum] epoch #408 | EpochTime 1.02 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00025385\n",
      "Evaluation/AverageReturn                 -0.00243279\n",
      "Evaluation/Iteration                    408\n",
      "Evaluation/MaxReturn                     -0.00236336\n",
      "Evaluation/MinReturn                     -0.00250221\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.94296e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.93977\n",
      "GaussianMLPPolicy/KL                      2.34707e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.4675e-06\n",
      "GaussianMLPPolicy/LossBefore             -3.4642e-06\n",
      "GaussianMLPPolicy/dLoss                   3.29533e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.82585\n",
      "GaussianMLPValueFunction/LossBefore      -6.84562\n",
      "GaussianMLPValueFunction/dLoss           -0.0197697\n",
      "TotalEnvSteps                        817182\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.4747e-06,  4.7305e-06,  2.1460e-08,  ...,  8.7443e-05,\n",
      "        -3.5609e-05,  9.9404e-05])\n",
      "G is: \n",
      "tensor([[1.1725e-07, 6.2772e-02],\n",
      "        [6.2772e-02, 3.3615e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [33615.4219,     0.0000]])\n",
      "loss before is:\n",
      "tensor(4.7649e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(4.7649e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:01 | [trpo_pendulum] epoch #409 | Saving snapshot...\n",
      "2022-08-23 10:44:01 | [trpo_pendulum] epoch #409 | Saved\n",
      "2022-08-23 10:44:01 | [trpo_pendulum] epoch #409 | Time 403.18 s\n",
      "2022-08-23 10:44:01 | [trpo_pendulum] epoch #409 | EpochTime 1.02 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000230288\n",
      "Evaluation/AverageReturn                 -0.00250687\n",
      "Evaluation/Iteration                    409\n",
      "Evaluation/MaxReturn                     -0.00248654\n",
      "Evaluation/MinReturn                     -0.0025272\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.03301e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.93977\n",
      "GaussianMLPPolicy/KL                      2.07065e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               4.76491e-05\n",
      "GaussianMLPPolicy/LossBefore              4.76495e-05\n",
      "GaussianMLPPolicy/dLoss                   3.27418e-10\n",
      "GaussianMLPValueFunction/LossAfter       -6.68232\n",
      "GaussianMLPValueFunction/LossBefore      -6.80033\n",
      "GaussianMLPValueFunction/dLoss           -0.118009\n",
      "TotalEnvSteps                        819180\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.2536e-07, -9.1538e-06, -4.1557e-08,  ..., -1.6566e-04,\n",
      "         6.7545e-05, -1.8827e-04])\n",
      "G is: \n",
      "tensor([[4.2066e-07, 2.2527e-01],\n",
      "        [2.2527e-01, 1.2064e+05]])\n",
      "eig is:\n",
      "tensor([[-7.8125e-03,  0.0000e+00],\n",
      "        [ 1.2064e+05,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(6.8589e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(6.8588e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:02 | [trpo_pendulum] epoch #410 | Saving snapshot...\n",
      "2022-08-23 10:44:02 | [trpo_pendulum] epoch #410 | Saved\n",
      "2022-08-23 10:44:02 | [trpo_pendulum] epoch #410 | Time 404.22 s\n",
      "2022-08-23 10:44:02 | [trpo_pendulum] epoch #410 | EpochTime 1.03 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000227257\n",
      "Evaluation/AverageReturn                 -0.00224919\n",
      "Evaluation/Iteration                    410\n",
      "Evaluation/MaxReturn                     -0.00214234\n",
      "Evaluation/MinReturn                     -0.00235604\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000106851\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.93977\n",
      "GaussianMLPPolicy/KL                      7.69282e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               6.8588e-05\n",
      "GaussianMLPPolicy/LossBefore              6.85891e-05\n",
      "GaussianMLPPolicy/dLoss                   1.10595e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.62356\n",
      "GaussianMLPValueFunction/LossBefore      -6.75126\n",
      "GaussianMLPValueFunction/dLoss           -0.127702\n",
      "TotalEnvSteps                        821178\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.5464e-06,  2.5900e-05, -1.5288e-09,  ...,  4.5765e-04,\n",
      "        -1.8704e-04,  5.1997e-04])\n",
      "G is: \n",
      "tensor([[3.2106e-06, 1.7193e+00],\n",
      "        [1.7193e+00, 9.2074e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [920743.3750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-9.8886e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-9.8894e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:03 | [trpo_pendulum] epoch #411 | Saving snapshot...\n",
      "2022-08-23 10:44:03 | [trpo_pendulum] epoch #411 | Saved\n",
      "2022-08-23 10:44:03 | [trpo_pendulum] epoch #411 | Time 405.22 s\n",
      "2022-08-23 10:44:03 | [trpo_pendulum] epoch #411 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000261068\n",
      "Evaluation/AverageReturn                 -0.00236778\n",
      "Evaluation/Iteration                    411\n",
      "Evaluation/MaxReturn                     -0.00219568\n",
      "Evaluation/MinReturn                     -0.00253988\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000172104\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.93977\n",
      "GaussianMLPPolicy/KL                      6.03836e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -9.88945e-05\n",
      "GaussianMLPPolicy/LossBefore             -9.88861e-05\n",
      "GaussianMLPPolicy/dLoss                   8.3819e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.43868\n",
      "GaussianMLPValueFunction/LossBefore      -6.62866\n",
      "GaussianMLPValueFunction/dLoss           -0.189981\n",
      "TotalEnvSteps                        823176\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.0368e-05,  2.4812e-05,  6.0396e-09,  ...,  4.3698e-04,\n",
      "        -1.7863e-04,  4.9647e-04])\n",
      "G is: \n",
      "tensor([[2.9272e-06, 1.5675e+00],\n",
      "        [1.5675e+00, 8.3942e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [839421.1250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:04 | [trpo_pendulum] epoch #412 | Saving snapshot...\n",
      "2022-08-23 10:44:04 | [trpo_pendulum] epoch #412 | Saved\n",
      "2022-08-23 10:44:04 | [trpo_pendulum] epoch #412 | Time 406.18 s\n",
      "2022-08-23 10:44:04 | [trpo_pendulum] epoch #412 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000238543\n",
      "Evaluation/AverageReturn                 -0.00226475\n",
      "Evaluation/Iteration                    412\n",
      "Evaluation/MaxReturn                     -0.00223329\n",
      "Evaluation/MinReturn                     -0.0022962\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.14527e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.94722\n",
      "GaussianMLPPolicy/KL                      6.59003e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000136823\n",
      "GaussianMLPPolicy/LossBefore             -0.00013673\n",
      "GaussianMLPPolicy/dLoss                   9.30304e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.85955\n",
      "GaussianMLPValueFunction/LossBefore      -6.43094\n",
      "GaussianMLPValueFunction/dLoss            0.428612\n",
      "TotalEnvSteps                        825174\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.2951e-06,  8.8134e-06, -6.9274e-09,  ...,  1.6261e-04,\n",
      "        -6.6314e-05,  1.8485e-04])\n",
      "G is: \n",
      "tensor([[4.0539e-07, 2.2035e-01],\n",
      "        [2.2035e-01, 1.1978e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [119778.5234,      0.0000]])\n",
      "loss before is:\n",
      "tensor(6.9539e-06, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(6.9528e-06, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:05 | [trpo_pendulum] epoch #413 | Saving snapshot...\n",
      "2022-08-23 10:44:05 | [trpo_pendulum] epoch #413 | Saved\n",
      "2022-08-23 10:44:05 | [trpo_pendulum] epoch #413 | Time 407.11 s\n",
      "2022-08-23 10:44:05 | [trpo_pendulum] epoch #413 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000240592\n",
      "Evaluation/AverageReturn                 -0.00238649\n",
      "Evaluation/Iteration                    413\n",
      "Evaluation/MaxReturn                     -0.00236695\n",
      "Evaluation/MinReturn                     -0.00240603\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.95389e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.94722\n",
      "GaussianMLPPolicy/KL                      7.43238e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               6.95282e-06\n",
      "GaussianMLPPolicy/LossBefore              6.95386e-06\n",
      "GaussianMLPPolicy/dLoss                   1.03773e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.76613\n",
      "GaussianMLPValueFunction/LossBefore      -6.85742\n",
      "GaussianMLPValueFunction/dLoss           -0.0912957\n",
      "TotalEnvSteps                        827172\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.3117e-06, -7.6753e-06, -1.9750e-07,  ..., -1.4094e-04,\n",
      "         5.7230e-05, -1.6011e-04])\n",
      "G is: \n",
      "tensor([[3.0439e-07, 1.6542e-01],\n",
      "        [1.6542e-01, 8.9916e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [89916.0469,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-4.6492e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-4.6493e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:06 | [trpo_pendulum] epoch #414 | Saving snapshot...\n",
      "2022-08-23 10:44:06 | [trpo_pendulum] epoch #414 | Saved\n",
      "2022-08-23 10:44:06 | [trpo_pendulum] epoch #414 | Time 408.06 s\n",
      "2022-08-23 10:44:06 | [trpo_pendulum] epoch #414 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000257754\n",
      "Evaluation/AverageReturn                 -0.00249285\n",
      "Evaluation/Iteration                    414\n",
      "Evaluation/MaxReturn                     -0.00245891\n",
      "Evaluation/MinReturn                     -0.0025268\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.39423e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.94722\n",
      "GaussianMLPPolicy/KL                      5.48703e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.64926e-05\n",
      "GaussianMLPPolicy/LossBefore             -4.64918e-05\n",
      "GaussianMLPPolicy/dLoss                   7.78527e-10\n",
      "GaussianMLPValueFunction/LossAfter       -6.8564\n",
      "GaussianMLPValueFunction/LossBefore      -6.80536\n",
      "GaussianMLPValueFunction/dLoss            0.0510354\n",
      "TotalEnvSteps                        829170\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.7650e-06,  1.6724e-05, -3.6089e-08,  ...,  2.9714e-04,\n",
      "        -1.2151e-04,  3.3761e-04])\n",
      "G is: \n",
      "tensor([[1.3535e-06, 7.3576e-01],\n",
      "        [7.3576e-01, 3.9996e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [399963.6250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-2.9457e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-2.9461e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:07 | [trpo_pendulum] epoch #415 | Saving snapshot...\n",
      "2022-08-23 10:44:07 | [trpo_pendulum] epoch #415 | Saved\n",
      "2022-08-23 10:44:07 | [trpo_pendulum] epoch #415 | Time 409.01 s\n",
      "2022-08-23 10:44:07 | [trpo_pendulum] epoch #415 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000229876\n",
      "Evaluation/AverageReturn                 -0.00224629\n",
      "Evaluation/Iteration                    415\n",
      "Evaluation/MaxReturn                     -0.00218338\n",
      "Evaluation/MinReturn                     -0.00230919\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.29055e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.94722\n",
      "GaussianMLPPolicy/KL                      2.47777e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -2.94605e-05\n",
      "GaussianMLPPolicy/LossBefore             -2.9457e-05\n",
      "GaussianMLPPolicy/dLoss                   3.487e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.85678\n",
      "GaussianMLPValueFunction/LossBefore      -6.84135\n",
      "GaussianMLPValueFunction/dLoss            0.0154281\n",
      "TotalEnvSteps                        831168\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.7486e-06,  2.0533e-05,  2.1131e-09,  ...,  3.6362e-04,\n",
      "        -1.4862e-04,  4.1315e-04])\n",
      "G is: \n",
      "tensor([[2.0267e-06, 1.1015e+00],\n",
      "        [1.1015e+00, 5.9868e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [598675.3750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(4.9763e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(4.9758e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:08 | [trpo_pendulum] epoch #416 | Saving snapshot...\n",
      "2022-08-23 10:44:08 | [trpo_pendulum] epoch #416 | Saved\n",
      "2022-08-23 10:44:08 | [trpo_pendulum] epoch #416 | Time 410.05 s\n",
      "2022-08-23 10:44:08 | [trpo_pendulum] epoch #416 | EpochTime 1.03 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000257045\n",
      "Evaluation/AverageReturn                 -0.0025234\n",
      "Evaluation/Iteration                    416\n",
      "Evaluation/MaxReturn                     -0.0024175\n",
      "Evaluation/MinReturn                     -0.0026293\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0001059\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.94722\n",
      "GaussianMLPPolicy/KL                      3.7383e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               4.97582e-05\n",
      "GaussianMLPPolicy/LossBefore              4.97634e-05\n",
      "GaussianMLPPolicy/dLoss                   5.20959e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.48029\n",
      "GaussianMLPValueFunction/LossBefore      -6.79648\n",
      "GaussianMLPValueFunction/dLoss           -0.31619\n",
      "TotalEnvSteps                        833166\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.0817e-06,  8.5607e-05,  9.2958e-09,  ...,  1.6290e-03,\n",
      "        -6.6283e-04,  1.8527e-03])\n",
      "G is: \n",
      "tensor([[4.0685e-05, 2.2115e+01],\n",
      "        [2.2115e+01, 1.2021e+07]])\n",
      "eig is:\n",
      "tensor([[       0.,        0.],\n",
      "        [12020716.,        0.]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:09 | [trpo_pendulum] epoch #417 | Saving snapshot...\n",
      "2022-08-23 10:44:09 | [trpo_pendulum] epoch #417 | Saved\n",
      "2022-08-23 10:44:09 | [trpo_pendulum] epoch #417 | Time 411.02 s\n",
      "2022-08-23 10:44:09 | [trpo_pendulum] epoch #417 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000254798\n",
      "Evaluation/AverageReturn                 -0.00255667\n",
      "Evaluation/Iteration                    417\n",
      "Evaluation/MaxReturn                     -0.00234265\n",
      "Evaluation/MinReturn                     -0.00277069\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000214023\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.94755\n",
      "GaussianMLPPolicy/KL                      8.49067e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000133264\n",
      "GaussianMLPPolicy/LossBefore              0.000133384\n",
      "GaussianMLPPolicy/dLoss                   1.2017e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.78657\n",
      "GaussianMLPValueFunction/LossBefore      -6.45323\n",
      "GaussianMLPValueFunction/dLoss            0.333334\n",
      "TotalEnvSteps                        835164\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.6340e-06,  2.0960e-05, -2.5149e-07,  ...,  2.3695e-04,\n",
      "        -1.0077e-04,  2.6707e-04])\n",
      "G is: \n",
      "tensor([[8.6073e-07, 4.6736e-01],\n",
      "        [4.6736e-01, 2.5417e+05]])\n",
      "eig is:\n",
      "tensor([[-1.5625e-02,  0.0000e+00],\n",
      "        [ 2.5417e+05,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(9.1492e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(9.1455e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:10 | [trpo_pendulum] epoch #418 | Saving snapshot...\n",
      "2022-08-23 10:44:10 | [trpo_pendulum] epoch #418 | Saved\n",
      "2022-08-23 10:44:10 | [trpo_pendulum] epoch #418 | Time 412.00 s\n",
      "2022-08-23 10:44:10 | [trpo_pendulum] epoch #418 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000265074\n",
      "Evaluation/AverageReturn                 -0.002757\n",
      "Evaluation/Iteration                    418\n",
      "Evaluation/MaxReturn                     -0.00269049\n",
      "Evaluation/MinReturn                     -0.00282351\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.65142e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.94774\n",
      "GaussianMLPPolicy/KL                      2.62073e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               9.14549e-05\n",
      "GaussianMLPPolicy/LossBefore              9.14919e-05\n",
      "GaussianMLPPolicy/dLoss                   3.70201e-08\n",
      "GaussianMLPValueFunction/LossAfter       -2.90466\n",
      "GaussianMLPValueFunction/LossBefore      -6.63097\n",
      "GaussianMLPValueFunction/dLoss           -3.72631\n",
      "TotalEnvSteps                        837162\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.7212e-05,  1.4974e-04,  4.2706e-09,  ...,  2.7428e-03,\n",
      "        -1.1190e-03,  3.1175e-03])\n",
      "G is: \n",
      "tensor([[1.1533e-04, 6.2758e+01],\n",
      "        [6.2758e+01, 3.4151e+07]])\n",
      "eig is:\n",
      "tensor([[       0.,        0.],\n",
      "        [34151128.,        0.]])\n",
      "loss before is:\n",
      "tensor(-0.0005, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0005, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:11 | [trpo_pendulum] epoch #419 | Saving snapshot...\n",
      "2022-08-23 10:44:11 | [trpo_pendulum] epoch #419 | Saved\n",
      "2022-08-23 10:44:11 | [trpo_pendulum] epoch #419 | Time 412.97 s\n",
      "2022-08-23 10:44:11 | [trpo_pendulum] epoch #419 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000232517\n",
      "Evaluation/AverageReturn                 -0.00218501\n",
      "Evaluation/Iteration                    419\n",
      "Evaluation/MaxReturn                     -0.00207845\n",
      "Evaluation/MinReturn                     -0.00229157\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000106558\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.96647\n",
      "GaussianMLPPolicy/KL                      0.000562444\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000496806\n",
      "GaussianMLPPolicy/LossBefore             -0.000496016\n",
      "GaussianMLPPolicy/dLoss                   7.90053e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.66403\n",
      "GaussianMLPValueFunction/LossBefore      -1.26598\n",
      "GaussianMLPValueFunction/dLoss            5.39804\n",
      "TotalEnvSteps                        839160\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.2100e-06,  4.3237e-05, -2.0956e-08,  ...,  8.5695e-04,\n",
      "        -3.4792e-04,  9.7513e-04])\n",
      "G is: \n",
      "tensor([[1.1260e-05, 6.3602e+00],\n",
      "        [6.3602e+00, 3.5925e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [3592534.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:12 | [trpo_pendulum] epoch #420 | Saving snapshot...\n",
      "2022-08-23 10:44:12 | [trpo_pendulum] epoch #420 | Saved\n",
      "2022-08-23 10:44:12 | [trpo_pendulum] epoch #420 | Time 413.94 s\n",
      "2022-08-23 10:44:12 | [trpo_pendulum] epoch #420 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000246843\n",
      "Evaluation/AverageReturn                 -0.00242063\n",
      "Evaluation/Iteration                    420\n",
      "Evaluation/MaxReturn                     -0.0024185\n",
      "Evaluation/MinReturn                     -0.00242277\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.1327e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.96668\n",
      "GaussianMLPPolicy/KL                      2.82751e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000132798\n",
      "GaussianMLPPolicy/LossBefore              0.000132838\n",
      "GaussianMLPPolicy/dLoss                   4.0367e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.59067\n",
      "GaussianMLPValueFunction/LossBefore      -6.45482\n",
      "GaussianMLPValueFunction/dLoss            0.135849\n",
      "TotalEnvSteps                        841158\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.4459e-06,  3.2208e-05,  1.7155e-08,  ...,  5.8639e-04,\n",
      "        -2.3929e-04,  6.6644e-04])\n",
      "G is: \n",
      "tensor([[5.2711e-06, 2.9791e+00],\n",
      "        [2.9791e+00, 1.6837e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1683741.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:13 | [trpo_pendulum] epoch #421 | Saving snapshot...\n",
      "2022-08-23 10:44:13 | [trpo_pendulum] epoch #421 | Saved\n",
      "2022-08-23 10:44:13 | [trpo_pendulum] epoch #421 | Time 414.89 s\n",
      "2022-08-23 10:44:13 | [trpo_pendulum] epoch #421 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000228541\n",
      "Evaluation/AverageReturn                 -0.00214972\n",
      "Evaluation/Iteration                    421\n",
      "Evaluation/MaxReturn                     -0.0021161\n",
      "Evaluation/MinReturn                     -0.00218334\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.36216e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.96668\n",
      "GaussianMLPPolicy/KL                      9.31455e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00014557\n",
      "GaussianMLPPolicy/LossBefore             -0.000145557\n",
      "GaussianMLPPolicy/dLoss                   1.32131e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.80167\n",
      "GaussianMLPValueFunction/LossBefore      -6.37695\n",
      "GaussianMLPValueFunction/dLoss            0.424719\n",
      "TotalEnvSteps                        843156\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.4542e-06,  3.3023e-07, -1.4471e-08,  ...,  5.6248e-06,\n",
      "        -2.3248e-06,  6.3928e-06])\n",
      "G is: \n",
      "tensor([[4.9741e-10, 2.7434e-04],\n",
      "        [2.7434e-04, 1.5505e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [155.0526,   0.0000]])\n",
      "loss before is:\n",
      "tensor(-4.6994e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-4.6994e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:14 | [trpo_pendulum] epoch #422 | Saving snapshot...\n",
      "2022-08-23 10:44:14 | [trpo_pendulum] epoch #422 | Saved\n",
      "2022-08-23 10:44:14 | [trpo_pendulum] epoch #422 | Time 415.90 s\n",
      "2022-08-23 10:44:14 | [trpo_pendulum] epoch #422 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000219285\n",
      "Evaluation/AverageReturn                 -0.00222616\n",
      "Evaluation/Iteration                    422\n",
      "Evaluation/MaxReturn                     -0.00221875\n",
      "Evaluation/MinReturn                     -0.00223358\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.41508e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.96668\n",
      "GaussianMLPPolicy/KL                      0\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.69944e-05\n",
      "GaussianMLPPolicy/LossBefore             -4.69944e-05\n",
      "GaussianMLPPolicy/dLoss                   3.63798e-12\n",
      "GaussianMLPValueFunction/LossAfter       -4.70996\n",
      "GaussianMLPValueFunction/LossBefore      -6.8074\n",
      "GaussianMLPValueFunction/dLoss           -2.09744\n",
      "TotalEnvSteps                        845154\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.2108e-06,  2.8521e-05,  1.4690e-07,  ...,  4.6737e-04,\n",
      "        -1.9191e-04,  5.3026e-04])\n",
      "G is: \n",
      "tensor([[3.3472e-06, 1.8916e+00],\n",
      "        [1.8916e+00, 1.0691e+06]])\n",
      "eig is:\n",
      "tensor([[1.2500e-01, 0.0000e+00],\n",
      "        [1.0691e+06, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:15 | [trpo_pendulum] epoch #423 | Saving snapshot...\n",
      "2022-08-23 10:44:15 | [trpo_pendulum] epoch #423 | Saved\n",
      "2022-08-23 10:44:15 | [trpo_pendulum] epoch #423 | Time 416.86 s\n",
      "2022-08-23 10:44:15 | [trpo_pendulum] epoch #423 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000229075\n",
      "Evaluation/AverageReturn                 -0.00221446\n",
      "Evaluation/Iteration                    423\n",
      "Evaluation/MaxReturn                     -0.00219943\n",
      "Evaluation/MinReturn                     -0.0022295\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.50368e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.96709\n",
      "GaussianMLPPolicy/KL                      2.83891e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000299341\n",
      "GaussianMLPPolicy/LossBefore             -0.000299301\n",
      "GaussianMLPPolicy/dLoss                   3.99596e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.66951\n",
      "GaussianMLPValueFunction/LossBefore      -4.80705\n",
      "GaussianMLPValueFunction/dLoss            1.86246\n",
      "TotalEnvSteps                        847152\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.5068e-06, -2.2239e-05,  2.0727e-08,  ..., -4.0816e-04,\n",
      "         1.6659e-04, -4.6390e-04])\n",
      "G is: \n",
      "tensor([[2.5540e-06, 1.4447e+00],\n",
      "        [1.4447e+00, 8.1728e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [817279.1250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-9.9767e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-9.9773e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:16 | [trpo_pendulum] epoch #424 | Saving snapshot...\n",
      "2022-08-23 10:44:16 | [trpo_pendulum] epoch #424 | Saved\n",
      "2022-08-23 10:44:16 | [trpo_pendulum] epoch #424 | Time 417.84 s\n",
      "2022-08-23 10:44:16 | [trpo_pendulum] epoch #424 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000243194\n",
      "Evaluation/AverageReturn                 -0.00222928\n",
      "Evaluation/Iteration                    424\n",
      "Evaluation/MaxReturn                     -0.00216852\n",
      "Evaluation/MinReturn                     -0.00229005\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.07656e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.96709\n",
      "GaussianMLPPolicy/KL                      4.51468e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -9.97731e-05\n",
      "GaussianMLPPolicy/LossBefore             -9.97667e-05\n",
      "GaussianMLPPolicy/dLoss                   6.38101e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.1073\n",
      "GaussianMLPValueFunction/LossBefore      -6.63471\n",
      "GaussianMLPValueFunction/dLoss           -0.527412\n",
      "TotalEnvSteps                        849150\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.7745e-06,  1.0382e-05, -1.3470e-07,  ...,  2.1223e-04,\n",
      "        -8.6206e-05,  2.4164e-04])\n",
      "G is: \n",
      "tensor([[6.9098e-07, 3.9082e-01],\n",
      "        [3.9082e-01, 2.2109e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [221085.7500,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:17 | [trpo_pendulum] epoch #425 | Saving snapshot...\n",
      "2022-08-23 10:44:17 | [trpo_pendulum] epoch #425 | Saved\n",
      "2022-08-23 10:44:17 | [trpo_pendulum] epoch #425 | Time 418.87 s\n",
      "2022-08-23 10:44:17 | [trpo_pendulum] epoch #425 | EpochTime 1.02 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000213101\n",
      "Evaluation/AverageReturn                 -0.00223681\n",
      "Evaluation/Iteration                    425\n",
      "Evaluation/MaxReturn                     -0.00203856\n",
      "Evaluation/MinReturn                     -0.00243505\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000198244\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.97371\n",
      "GaussianMLPPolicy/KL                      5.62776e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000184866\n",
      "GaussianMLPPolicy/LossBefore              0.000184944\n",
      "GaussianMLPPolicy/dLoss                   7.81729e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.62043\n",
      "GaussianMLPValueFunction/LossBefore      -6.0834\n",
      "GaussianMLPValueFunction/dLoss            0.537035\n",
      "TotalEnvSteps                        851148\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.7550e-06,  2.0386e-05, -2.3000e-07,  ...,  3.9231e-04,\n",
      "        -1.5984e-04,  4.4632e-04])\n",
      "G is: \n",
      "tensor([[2.3603e-06, 1.3526e+00],\n",
      "        [1.3526e+00, 7.7518e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [775178.8750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-6.2280e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-6.2344e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:18 | [trpo_pendulum] epoch #426 | Saving snapshot...\n",
      "2022-08-23 10:44:18 | [trpo_pendulum] epoch #426 | Saved\n",
      "2022-08-23 10:44:18 | [trpo_pendulum] epoch #426 | Time 419.86 s\n",
      "2022-08-23 10:44:18 | [trpo_pendulum] epoch #426 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000202031\n",
      "Evaluation/AverageReturn                 -0.00224248\n",
      "Evaluation/Iteration                    426\n",
      "Evaluation/MaxReturn                     -0.0021125\n",
      "Evaluation/MinReturn                     -0.00237245\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000129979\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.97952\n",
      "GaussianMLPPolicy/KL                      4.57098e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.2344e-05\n",
      "GaussianMLPPolicy/LossBefore             -6.22796e-05\n",
      "GaussianMLPPolicy/dLoss                   6.43631e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.51233\n",
      "GaussianMLPValueFunction/LossBefore      -6.75551\n",
      "GaussianMLPValueFunction/dLoss           -0.243177\n",
      "TotalEnvSteps                        853146\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.8694e-06, -3.2069e-05, -8.6948e-07,  ..., -6.4833e-04,\n",
      "         2.6171e-04, -7.3747e-04])\n",
      "G is: \n",
      "tensor([[6.4414e-06, 3.7343e+00],\n",
      "        [3.7343e+00, 2.1651e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [2165092.,       0.]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:19 | [trpo_pendulum] epoch #427 | Saving snapshot...\n",
      "2022-08-23 10:44:19 | [trpo_pendulum] epoch #427 | Saved\n",
      "2022-08-23 10:44:19 | [trpo_pendulum] epoch #427 | Time 420.85 s\n",
      "2022-08-23 10:44:19 | [trpo_pendulum] epoch #427 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000223322\n",
      "Evaluation/AverageReturn                 -0.00222365\n",
      "Evaluation/Iteration                    427\n",
      "Evaluation/MaxReturn                     -0.00220065\n",
      "Evaluation/MinReturn                     -0.00224665\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.29992e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.98175\n",
      "GaussianMLPPolicy/KL                      0.000322457\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000147668\n",
      "GaussianMLPPolicy/LossBefore             -0.000147378\n",
      "GaussianMLPPolicy/dLoss                   2.89758e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.71064\n",
      "GaussianMLPValueFunction/LossBefore      -6.36069\n",
      "GaussianMLPValueFunction/dLoss           -0.650045\n",
      "TotalEnvSteps                        855144\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-2.0891e-07, -8.5620e-06,  5.8468e-08,  ..., -1.5531e-04,\n",
      "         6.3581e-05, -1.7636e-04])\n",
      "G is: \n",
      "tensor([[3.6948e-07, 2.1516e-01],\n",
      "        [2.1516e-01, 1.2530e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [125298.9219,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:20 | [trpo_pendulum] epoch #428 | Saving snapshot...\n",
      "2022-08-23 10:44:20 | [trpo_pendulum] epoch #428 | Saved\n",
      "2022-08-23 10:44:20 | [trpo_pendulum] epoch #428 | Time 421.80 s\n",
      "2022-08-23 10:44:20 | [trpo_pendulum] epoch #428 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000228048\n",
      "Evaluation/AverageReturn                 -0.00210345\n",
      "Evaluation/Iteration                    428\n",
      "Evaluation/MaxReturn                     -0.00209374\n",
      "Evaluation/MinReturn                     -0.00211315\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      9.70536e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.98175\n",
      "GaussianMLPPolicy/KL                      6.40825e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000205466\n",
      "GaussianMLPPolicy/LossBefore              0.000205467\n",
      "GaussianMLPPolicy/dLoss                   8.73115e-10\n",
      "GaussianMLPValueFunction/LossAfter       -6.4031\n",
      "GaussianMLPValueFunction/LossBefore      -5.9081\n",
      "GaussianMLPValueFunction/dLoss            0.495003\n",
      "TotalEnvSteps                        857142\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.6354e-06,  6.3099e-05, -6.7861e-08,  ...,  1.1710e-03,\n",
      "        -4.7811e-04,  1.3300e-03])\n",
      "G is: \n",
      "tensor([[2.1002e-05, 1.2230e+01],\n",
      "        [1.2230e+01, 7.1221e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [7122060.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:21 | [trpo_pendulum] epoch #429 | Saving snapshot...\n",
      "2022-08-23 10:44:21 | [trpo_pendulum] epoch #429 | Saved\n",
      "2022-08-23 10:44:21 | [trpo_pendulum] epoch #429 | Time 422.76 s\n",
      "2022-08-23 10:44:21 | [trpo_pendulum] epoch #429 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000204156\n",
      "Evaluation/AverageReturn                 -0.0022702\n",
      "Evaluation/Iteration                    429\n",
      "Evaluation/MaxReturn                     -0.00217908\n",
      "Evaluation/MinReturn                     -0.00236133\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      9.11252e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.98299\n",
      "GaussianMLPPolicy/KL                      5.10475e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000162202\n",
      "GaussianMLPPolicy/LossBefore              0.000162275\n",
      "GaussianMLPPolicy/dLoss                   7.32252e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.84281\n",
      "GaussianMLPValueFunction/LossBefore      -6.25825\n",
      "GaussianMLPValueFunction/dLoss            0.584563\n",
      "TotalEnvSteps                        859140\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.3823e-05,  5.7738e-05,  8.2881e-08,  ...,  9.1442e-04,\n",
      "        -3.7729e-04,  1.0361e-03])\n",
      "G is: \n",
      "tensor([[1.2798e-05, 7.4686e+00],\n",
      "        [7.4686e+00, 4.3592e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [4359205.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:22 | [trpo_pendulum] epoch #430 | Saving snapshot...\n",
      "2022-08-23 10:44:22 | [trpo_pendulum] epoch #430 | Saved\n",
      "2022-08-23 10:44:22 | [trpo_pendulum] epoch #430 | Time 423.72 s\n",
      "2022-08-23 10:44:22 | [trpo_pendulum] epoch #430 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000263234\n",
      "Evaluation/AverageReturn                 -0.00261586\n",
      "Evaluation/Iteration                    430\n",
      "Evaluation/MaxReturn                     -0.00256565\n",
      "Evaluation/MinReturn                     -0.00266607\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.02093e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.97338\n",
      "GaussianMLPPolicy/KL                      0.000139288\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000105903\n",
      "GaussianMLPPolicy/LossBefore              0.000106107\n",
      "GaussianMLPPolicy/dLoss                   2.03996e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.70536\n",
      "GaussianMLPValueFunction/LossBefore      -6.53953\n",
      "GaussianMLPValueFunction/dLoss            0.165827\n",
      "TotalEnvSteps                        861138\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.4748e-06,  5.2220e-05,  7.2478e-08,  ...,  1.0184e-03,\n",
      "        -4.1450e-04,  1.1574e-03])\n",
      "G is: \n",
      "tensor([[1.5887e-05, 9.0986e+00],\n",
      "        [9.0986e+00, 5.2108e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [5210781.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:23 | [trpo_pendulum] epoch #431 | Saving snapshot...\n",
      "2022-08-23 10:44:23 | [trpo_pendulum] epoch #431 | Saved\n",
      "2022-08-23 10:44:23 | [trpo_pendulum] epoch #431 | Time 424.71 s\n",
      "2022-08-23 10:44:23 | [trpo_pendulum] epoch #431 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000214648\n",
      "Evaluation/AverageReturn                 -0.00215053\n",
      "Evaluation/Iteration                    431\n",
      "Evaluation/MaxReturn                     -0.00210067\n",
      "Evaluation/MinReturn                     -0.00220038\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.98595e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.97338\n",
      "GaussianMLPPolicy/KL                      2.76954e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00014865\n",
      "GaussianMLPPolicy/LossBefore             -0.00014861\n",
      "GaussianMLPPolicy/dLoss                   3.91447e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.83324\n",
      "GaussianMLPValueFunction/LossBefore      -6.35576\n",
      "GaussianMLPValueFunction/dLoss            0.477479\n",
      "TotalEnvSteps                        863136\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.8385e-06,  4.2817e-06, -1.5956e-07,  ...,  7.2598e-05,\n",
      "        -3.0056e-05,  8.2403e-05])\n",
      "G is: \n",
      "tensor([[8.0789e-08, 4.6252e-02],\n",
      "        [4.6252e-02, 2.6489e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [26488.9375,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-3.9724e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-3.9724e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:24 | [trpo_pendulum] epoch #432 | Saving snapshot...\n",
      "2022-08-23 10:44:24 | [trpo_pendulum] epoch #432 | Saved\n",
      "2022-08-23 10:44:24 | [trpo_pendulum] epoch #432 | Time 425.66 s\n",
      "2022-08-23 10:44:24 | [trpo_pendulum] epoch #432 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000221303\n",
      "Evaluation/AverageReturn                 -0.00218858\n",
      "Evaluation/Iteration                    432\n",
      "Evaluation/MaxReturn                     -0.00210521\n",
      "Evaluation/MinReturn                     -0.00227195\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.33715e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.97338\n",
      "GaussianMLPPolicy/KL                      1.35229e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.97238e-05\n",
      "GaussianMLPPolicy/LossBefore             -3.97236e-05\n",
      "GaussianMLPPolicy/dLoss                   2.14641e-10\n",
      "GaussianMLPValueFunction/LossAfter       -0.468951\n",
      "GaussianMLPValueFunction/LossBefore      -6.82783\n",
      "GaussianMLPValueFunction/dLoss           -6.35888\n",
      "TotalEnvSteps                        865134\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.5759e-05,  1.7333e-05, -1.6476e-07,  ...,  3.7268e-04,\n",
      "        -1.5106e-04,  4.2417e-04])\n",
      "G is: \n",
      "tensor([[2.1289e-06, 1.2190e+00],\n",
      "        [1.2190e+00, 6.9816e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [698159.8750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0005, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0005, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:25 | [trpo_pendulum] epoch #433 | Saving snapshot...\n",
      "2022-08-23 10:44:25 | [trpo_pendulum] epoch #433 | Saved\n",
      "2022-08-23 10:44:25 | [trpo_pendulum] epoch #433 | Time 426.63 s\n",
      "2022-08-23 10:44:25 | [trpo_pendulum] epoch #433 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000236479\n",
      "Evaluation/AverageReturn                 -0.00211332\n",
      "Evaluation/Iteration                    433\n",
      "Evaluation/MaxReturn                     -0.00200776\n",
      "Evaluation/MinReturn                     -0.00221888\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000105562\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.98653\n",
      "GaussianMLPPolicy/KL                      0.000196142\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000535323\n",
      "GaussianMLPPolicy/LossBefore             -0.000535046\n",
      "GaussianMLPPolicy/dLoss                   2.77942e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.83907\n",
      "GaussianMLPValueFunction/LossBefore      -0.23245\n",
      "GaussianMLPValueFunction/dLoss            6.60662\n",
      "TotalEnvSteps                        867132\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.0718e-06,  1.4635e-05, -2.0521e-07,  ...,  2.5607e-04,\n",
      "        -1.0513e-04,  2.9073e-04])\n",
      "G is: \n",
      "tensor([[1.0044e-06, 5.9032e-01],\n",
      "        [5.9032e-01, 3.4697e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [346968.6250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-1.2574e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-1.2577e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:26 | [trpo_pendulum] epoch #434 | Saving snapshot...\n",
      "2022-08-23 10:44:26 | [trpo_pendulum] epoch #434 | Saved\n",
      "2022-08-23 10:44:26 | [trpo_pendulum] epoch #434 | Time 427.62 s\n",
      "2022-08-23 10:44:26 | [trpo_pendulum] epoch #434 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000196827\n",
      "Evaluation/AverageReturn                 -0.00220219\n",
      "Evaluation/Iteration                    434\n",
      "Evaluation/MaxReturn                     -0.00217371\n",
      "Evaluation/MinReturn                     -0.00223068\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.84858e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.98653\n",
      "GaussianMLPPolicy/KL                      1.72158e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -1.25766e-05\n",
      "GaussianMLPPolicy/LossBefore             -1.25742e-05\n",
      "GaussianMLPPolicy/dLoss                   2.38288e-09\n",
      "GaussianMLPValueFunction/LossAfter       -3.92081\n",
      "GaussianMLPValueFunction/LossBefore      -6.85773\n",
      "GaussianMLPValueFunction/dLoss           -2.93692\n",
      "TotalEnvSteps                        869130\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.4867e-05, -2.7390e-04, -6.2524e-07,  ..., -4.6154e-03,\n",
      "         1.8934e-03, -5.2355e-03])\n",
      "G is: \n",
      "tensor([[3.2610e-04, 1.9166e+02],\n",
      "        [1.9166e+02, 1.1265e+08]])\n",
      "eig is:\n",
      "tensor([[0.0000e+00, 0.0000e+00],\n",
      "        [1.1265e+08, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0004, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:27 | [trpo_pendulum] epoch #435 | Saving snapshot...\n",
      "2022-08-23 10:44:27 | [trpo_pendulum] epoch #435 | Saved\n",
      "2022-08-23 10:44:27 | [trpo_pendulum] epoch #435 | Time 428.73 s\n",
      "2022-08-23 10:44:27 | [trpo_pendulum] epoch #435 | EpochTime 1.10 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000215928\n",
      "Evaluation/AverageReturn                 -0.00237601\n",
      "Evaluation/Iteration                    435\n",
      "Evaluation/MaxReturn                     -0.00230971\n",
      "Evaluation/MinReturn                     -0.0024423\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.62955e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.9946\n",
      "GaussianMLPPolicy/KL                      0.000947709\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000391016\n",
      "GaussianMLPPolicy/LossBefore              0.00039239\n",
      "GaussianMLPPolicy/dLoss                   1.37454e-06\n",
      "GaussianMLPValueFunction/LossAfter       -6.83739\n",
      "GaussianMLPValueFunction/LossBefore      -3.27974\n",
      "GaussianMLPValueFunction/dLoss            3.55765\n",
      "TotalEnvSteps                        871128\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.7638e-06, -6.6195e-07, -4.9504e-08,  ..., -4.2314e-05,\n",
      "         1.6389e-05, -4.8532e-05])\n",
      "G is: \n",
      "tensor([[2.7535e-08, 1.6409e-02],\n",
      "        [1.6409e-02, 9.8002e+03]])\n",
      "eig is:\n",
      "tensor([[   0.0000,    0.0000],\n",
      "        [9800.2109,    0.0000]])\n",
      "loss before is:\n",
      "tensor(-1.4828e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-1.4828e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:28 | [trpo_pendulum] epoch #436 | Saving snapshot...\n",
      "2022-08-23 10:44:28 | [trpo_pendulum] epoch #436 | Saved\n",
      "2022-08-23 10:44:28 | [trpo_pendulum] epoch #436 | Time 429.72 s\n",
      "2022-08-23 10:44:28 | [trpo_pendulum] epoch #436 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000219148\n",
      "Evaluation/AverageReturn                 -0.00221377\n",
      "Evaluation/Iteration                    436\n",
      "Evaluation/MaxReturn                     -0.00221373\n",
      "Evaluation/MinReturn                     -0.00221381\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.93188e-08\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.9946\n",
      "GaussianMLPPolicy/KL                      5.8292e-08\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -1.4828e-05\n",
      "GaussianMLPPolicy/LossBefore             -1.48279e-05\n",
      "GaussianMLPPolicy/dLoss                   1.00954e-10\n",
      "GaussianMLPValueFunction/LossAfter       -6.48454\n",
      "GaussianMLPValueFunction/LossBefore      -6.86181\n",
      "GaussianMLPValueFunction/dLoss           -0.377267\n",
      "TotalEnvSteps                        873126\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.8969e-07, -3.8715e-05,  2.6964e-08,  ..., -7.3575e-04,\n",
      "         2.9954e-04, -8.3604e-04])\n",
      "G is: \n",
      "tensor([[8.2900e-06, 4.9518e+00],\n",
      "        [4.9518e+00, 2.9579e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [2957850.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:29 | [trpo_pendulum] epoch #437 | Saving snapshot...\n",
      "2022-08-23 10:44:29 | [trpo_pendulum] epoch #437 | Saved\n",
      "2022-08-23 10:44:29 | [trpo_pendulum] epoch #437 | Time 430.69 s\n",
      "2022-08-23 10:44:29 | [trpo_pendulum] epoch #437 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000201273\n",
      "Evaluation/AverageReturn                 -0.00198426\n",
      "Evaluation/Iteration                    437\n",
      "Evaluation/MaxReturn                     -0.00196152\n",
      "Evaluation/MinReturn                     -0.00200701\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.27424e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.9946\n",
      "GaussianMLPPolicy/KL                      1.39201e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000106549\n",
      "GaussianMLPPolicy/LossBefore              0.000106569\n",
      "GaussianMLPPolicy/dLoss                   1.95578e-08\n",
      "GaussianMLPValueFunction/LossAfter       -5.31836\n",
      "GaussianMLPValueFunction/LossBefore      -6.61256\n",
      "GaussianMLPValueFunction/dLoss           -1.2942\n",
      "TotalEnvSteps                        875124\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.4985e-07,  4.5458e-05, -9.3324e-09,  ...,  8.6957e-04,\n",
      "        -3.5384e-04,  9.8818e-04])\n",
      "G is: \n",
      "tensor([[1.1580e-05, 6.9170e+00],\n",
      "        [6.9170e+00, 4.1317e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [4131701.,       0.]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:30 | [trpo_pendulum] epoch #438 | Saving snapshot...\n",
      "2022-08-23 10:44:30 | [trpo_pendulum] epoch #438 | Saved\n",
      "2022-08-23 10:44:30 | [trpo_pendulum] epoch #438 | Time 431.65 s\n",
      "2022-08-23 10:44:30 | [trpo_pendulum] epoch #438 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000208759\n",
      "Evaluation/AverageReturn                 -0.00211523\n",
      "Evaluation/Iteration                    438\n",
      "Evaluation/MaxReturn                     -0.00207803\n",
      "Evaluation/MinReturn                     -0.00215243\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.72036e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.9946\n",
      "GaussianMLPPolicy/KL                      1.94266e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000255185\n",
      "GaussianMLPPolicy/LossBefore             -0.000255158\n",
      "GaussianMLPPolicy/dLoss                   2.75031e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.80024\n",
      "GaussianMLPValueFunction/LossBefore      -5.3677\n",
      "GaussianMLPValueFunction/dLoss            1.43254\n",
      "TotalEnvSteps                        877122\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.5882e-06, -2.8288e-06,  1.5118e-08,  ..., -5.0945e-05,\n",
      "         2.0831e-05, -5.7850e-05])\n",
      "G is: \n",
      "tensor([[3.9755e-08, 2.3739e-02],\n",
      "        [2.3739e-02, 1.4180e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [14180.1230,     0.0000]])\n",
      "loss before is:\n",
      "tensor(5.5615e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(5.5615e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:31 | [trpo_pendulum] epoch #439 | Saving snapshot...\n",
      "2022-08-23 10:44:31 | [trpo_pendulum] epoch #439 | Saved\n",
      "2022-08-23 10:44:31 | [trpo_pendulum] epoch #439 | Time 432.62 s\n",
      "2022-08-23 10:44:31 | [trpo_pendulum] epoch #439 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000209311\n",
      "Evaluation/AverageReturn                 -0.00207539\n",
      "Evaluation/Iteration                    439\n",
      "Evaluation/MaxReturn                     -0.00197346\n",
      "Evaluation/MinReturn                     -0.00217732\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000101928\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.9946\n",
      "GaussianMLPPolicy/KL                      5.99925e-08\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               5.56152e-05\n",
      "GaussianMLPPolicy/LossBefore              5.56153e-05\n",
      "GaussianMLPPolicy/dLoss                   1.12777e-10\n",
      "GaussianMLPValueFunction/LossAfter       -5.20857\n",
      "GaussianMLPValueFunction/LossBefore      -6.80002\n",
      "GaussianMLPValueFunction/dLoss           -1.59146\n",
      "TotalEnvSteps                        879120\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.1825e-06, -2.3026e-05, -9.7062e-08,  ..., -4.2404e-04,\n",
      "         1.7283e-04, -4.8158e-04])\n",
      "G is: \n",
      "tensor([[2.7531e-06, 1.6445e+00],\n",
      "        [1.6445e+00, 9.8230e+05]])\n",
      "eig is:\n",
      "tensor([[-6.2500e-02,  0.0000e+00],\n",
      "        [ 9.8230e+05,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:32 | [trpo_pendulum] epoch #440 | Saving snapshot...\n",
      "2022-08-23 10:44:32 | [trpo_pendulum] epoch #440 | Saved\n",
      "2022-08-23 10:44:32 | [trpo_pendulum] epoch #440 | Time 433.59 s\n",
      "2022-08-23 10:44:32 | [trpo_pendulum] epoch #440 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00024838\n",
      "Evaluation/AverageReturn                 -0.0021001\n",
      "Evaluation/Iteration                    440\n",
      "Evaluation/MaxReturn                     -0.00203931\n",
      "Evaluation/MinReturn                     -0.00216088\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.07861e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.9946\n",
      "GaussianMLPPolicy/KL                      4.63962e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000267209\n",
      "GaussianMLPPolicy/LossBefore             -0.000267202\n",
      "GaussianMLPPolicy/dLoss                   6.43195e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.86834\n",
      "GaussianMLPValueFunction/LossBefore      -5.2023\n",
      "GaussianMLPValueFunction/dLoss            1.66603\n",
      "TotalEnvSteps                        881118\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.9773e-06,  3.1444e-05, -6.6764e-08,  ...,  5.5326e-04,\n",
      "        -2.2641e-04,  6.2803e-04])\n",
      "G is: \n",
      "tensor([[4.6864e-06, 2.7991e+00],\n",
      "        [2.7991e+00, 1.6719e+06]])\n",
      "eig is:\n",
      "tensor([[-1.2500e-01,  0.0000e+00],\n",
      "        [ 1.6719e+06,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(3.5948e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(3.5928e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:33 | [trpo_pendulum] epoch #441 | Saving snapshot...\n",
      "2022-08-23 10:44:33 | [trpo_pendulum] epoch #441 | Saved\n",
      "2022-08-23 10:44:33 | [trpo_pendulum] epoch #441 | Time 434.57 s\n",
      "2022-08-23 10:44:33 | [trpo_pendulum] epoch #441 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000216968\n",
      "Evaluation/AverageReturn                 -0.00225076\n",
      "Evaluation/Iteration                    441\n",
      "Evaluation/MaxReturn                     -0.00218074\n",
      "Evaluation/MinReturn                     -0.00232077\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.00135e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.9949\n",
      "GaussianMLPPolicy/KL                      1.40287e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               3.5928e-05\n",
      "GaussianMLPPolicy/LossBefore              3.59479e-05\n",
      "GaussianMLPPolicy/dLoss                   1.9907e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.80832\n",
      "GaussianMLPValueFunction/LossBefore      -6.835\n",
      "GaussianMLPValueFunction/dLoss           -0.0266757\n",
      "TotalEnvSteps                        883116\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-5.2886e-06, -1.1765e-04, -2.9277e-07,  ..., -1.9386e-03,\n",
      "         7.9607e-04, -2.1983e-03])\n",
      "G is: \n",
      "tensor([[5.7513e-05, 3.4365e+01],\n",
      "        [3.4365e+01, 2.0536e+07]])\n",
      "eig is:\n",
      "tensor([[       0.,        0.],\n",
      "        [20535920.,        0.]])\n",
      "loss before is:\n",
      "tensor(8.8798e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(8.8561e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:34 | [trpo_pendulum] epoch #442 | Saving snapshot...\n",
      "2022-08-23 10:44:34 | [trpo_pendulum] epoch #442 | Saved\n",
      "2022-08-23 10:44:34 | [trpo_pendulum] epoch #442 | Time 435.58 s\n",
      "2022-08-23 10:44:34 | [trpo_pendulum] epoch #442 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0002244\n",
      "Evaluation/AverageReturn                 -0.00225387\n",
      "Evaluation/Iteration                    442\n",
      "Evaluation/MaxReturn                     -0.00221651\n",
      "Evaluation/MinReturn                     -0.00229123\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.73605e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.9948\n",
      "GaussianMLPPolicy/KL                      0.000165099\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               8.8561e-05\n",
      "GaussianMLPPolicy/LossBefore              8.87981e-05\n",
      "GaussianMLPPolicy/dLoss                   2.37022e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.92266\n",
      "GaussianMLPValueFunction/LossBefore      -6.63715\n",
      "GaussianMLPValueFunction/dLoss           -0.714483\n",
      "TotalEnvSteps                        885114\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.4504e-06, -1.6370e-05,  6.4660e-07,  ..., -2.1723e-04,\n",
      "         9.1723e-05, -2.4568e-04])\n",
      "G is: \n",
      "tensor([[7.2326e-07, 4.3170e-01],\n",
      "        [4.3170e-01, 2.5793e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [257933.1875,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:35 | [trpo_pendulum] epoch #443 | Saving snapshot...\n",
      "2022-08-23 10:44:35 | [trpo_pendulum] epoch #443 | Saved\n",
      "2022-08-23 10:44:35 | [trpo_pendulum] epoch #443 | Time 436.58 s\n",
      "2022-08-23 10:44:35 | [trpo_pendulum] epoch #443 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000242263\n",
      "Evaluation/AverageReturn                 -0.00237082\n",
      "Evaluation/Iteration                    443\n",
      "Evaluation/MaxReturn                     -0.0022835\n",
      "Evaluation/MinReturn                     -0.00245813\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.73131e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.99693\n",
      "GaussianMLPPolicy/KL                      5.26643e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000214973\n",
      "GaussianMLPPolicy/LossBefore             -0.0002149\n",
      "GaussianMLPPolicy/dLoss                   7.24103e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.7865\n",
      "GaussianMLPValueFunction/LossBefore      -5.7812\n",
      "GaussianMLPValueFunction/dLoss            1.00529\n",
      "TotalEnvSteps                        887112\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.6338e-06,  4.3200e-05,  2.4782e-07,  ...,  7.1454e-04,\n",
      "        -2.9302e-04,  8.1041e-04])\n",
      "G is: \n",
      "tensor([[7.8156e-06, 4.6889e+00],\n",
      "        [4.6889e+00, 2.8132e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [2813228.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(-2.5898e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-2.5927e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:36 | [trpo_pendulum] epoch #444 | Saving snapshot...\n",
      "2022-08-23 10:44:36 | [trpo_pendulum] epoch #444 | Saved\n",
      "2022-08-23 10:44:36 | [trpo_pendulum] epoch #444 | Time 437.57 s\n",
      "2022-08-23 10:44:36 | [trpo_pendulum] epoch #444 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000253286\n",
      "Evaluation/AverageReturn                 -0.00257332\n",
      "Evaluation/Iteration                    444\n",
      "Evaluation/MaxReturn                     -0.00254012\n",
      "Evaluation/MinReturn                     -0.00260652\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.3198e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -3.9969\n",
      "GaussianMLPPolicy/KL                      1.97889e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -2.59268e-05\n",
      "GaussianMLPPolicy/LossBefore             -2.58985e-05\n",
      "GaussianMLPPolicy/dLoss                   2.83053e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.7878\n",
      "GaussianMLPValueFunction/LossBefore      -6.81875\n",
      "GaussianMLPValueFunction/dLoss           -0.0309553\n",
      "TotalEnvSteps                        889110\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.0771e-05,  4.9744e-06,  8.6854e-09,  ...,  1.0796e-04,\n",
      "        -4.3551e-05,  1.2294e-04])\n",
      "G is: \n",
      "tensor([[1.7872e-07, 1.0715e-01],\n",
      "        [1.0715e-01, 6.4289e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [64289.4922,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-9.3790e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-9.3873e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:37 | [trpo_pendulum] epoch #445 | Saving snapshot...\n",
      "2022-08-23 10:44:37 | [trpo_pendulum] epoch #445 | Saved\n",
      "2022-08-23 10:44:37 | [trpo_pendulum] epoch #445 | Time 438.57 s\n",
      "2022-08-23 10:44:37 | [trpo_pendulum] epoch #445 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00021535\n",
      "Evaluation/AverageReturn                 -0.00215426\n",
      "Evaluation/Iteration                    445\n",
      "Evaluation/MaxReturn                     -0.00206539\n",
      "Evaluation/MinReturn                     -0.00224313\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.88718e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.00449\n",
      "GaussianMLPPolicy/KL                      5.87235e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -9.38727e-05\n",
      "GaussianMLPPolicy/LossBefore             -9.37904e-05\n",
      "GaussianMLPPolicy/dLoss                   8.23566e-08\n",
      "GaussianMLPValueFunction/LossAfter       -0.426486\n",
      "GaussianMLPValueFunction/LossBefore      -6.65674\n",
      "GaussianMLPValueFunction/dLoss           -6.23026\n",
      "TotalEnvSteps                        891108\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.4682e-05, -3.9029e-05,  3.5637e-08,  ..., -7.0679e-04,\n",
      "         2.8849e-04, -8.0280e-04])\n",
      "G is: \n",
      "tensor([[7.6517e-06, 4.6611e+00],\n",
      "        [4.6611e+00, 2.8398e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [2839827.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0005, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:38 | [trpo_pendulum] epoch #446 | Saving snapshot...\n",
      "2022-08-23 10:44:38 | [trpo_pendulum] epoch #446 | Saved\n",
      "2022-08-23 10:44:38 | [trpo_pendulum] epoch #446 | Time 439.52 s\n",
      "2022-08-23 10:44:38 | [trpo_pendulum] epoch #446 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000221269\n",
      "Evaluation/AverageReturn                 -0.00217162\n",
      "Evaluation/Iteration                    446\n",
      "Evaluation/MaxReturn                     -0.00207664\n",
      "Evaluation/MinReturn                     -0.00226661\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      9.49848e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.02905\n",
      "GaussianMLPPolicy/KL                      0.000640911\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000504995\n",
      "GaussianMLPPolicy/LossBefore              0.000505878\n",
      "GaussianMLPPolicy/dLoss                   8.82952e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.7536\n",
      "GaussianMLPValueFunction/LossBefore      -0.952157\n",
      "GaussianMLPValueFunction/dLoss            5.80145\n",
      "TotalEnvSteps                        893106\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.3877e-06,  2.1672e-05, -3.3015e-08,  ...,  3.9873e-04,\n",
      "        -1.6243e-04,  4.5313e-04])\n",
      "G is: \n",
      "tensor([[2.4353e-06, 1.5582e+00],\n",
      "        [1.5582e+00, 9.9702e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [997020.3750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-7.2429e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-7.2434e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:39 | [trpo_pendulum] epoch #447 | Saving snapshot...\n",
      "2022-08-23 10:44:39 | [trpo_pendulum] epoch #447 | Saved\n",
      "2022-08-23 10:44:39 | [trpo_pendulum] epoch #447 | Time 440.47 s\n",
      "2022-08-23 10:44:39 | [trpo_pendulum] epoch #447 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000209606\n",
      "Evaluation/AverageReturn                 -0.00207464\n",
      "Evaluation/Iteration                    447\n",
      "Evaluation/MaxReturn                     -0.00193672\n",
      "Evaluation/MinReturn                     -0.00221255\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000137914\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.02905\n",
      "GaussianMLPPolicy/KL                      3.7826e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.24343e-05\n",
      "GaussianMLPPolicy/LossBefore             -7.2429e-05\n",
      "GaussianMLPPolicy/dLoss                   5.28962e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.16148\n",
      "GaussianMLPValueFunction/LossBefore      -6.74537\n",
      "GaussianMLPValueFunction/dLoss           -0.583893\n",
      "TotalEnvSteps                        895104\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.9907e-06,  5.0757e-06,  2.1661e-07,  ...,  1.2275e-04,\n",
      "        -4.8939e-05,  1.3986e-04])\n",
      "G is: \n",
      "tensor([[2.3098e-07, 1.4768e-01],\n",
      "        [1.4768e-01, 9.4495e+04]])\n",
      "eig is:\n",
      "tensor([[-7.8125e-03,  0.0000e+00],\n",
      "        [ 9.4495e+04,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:40 | [trpo_pendulum] epoch #448 | Saving snapshot...\n",
      "2022-08-23 10:44:40 | [trpo_pendulum] epoch #448 | Saved\n",
      "2022-08-23 10:44:40 | [trpo_pendulum] epoch #448 | Time 441.51 s\n",
      "2022-08-23 10:44:40 | [trpo_pendulum] epoch #448 | EpochTime 1.03 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0001964\n",
      "Evaluation/AverageReturn                 -0.00196001\n",
      "Evaluation/Iteration                    448\n",
      "Evaluation/MaxReturn                     -0.00191872\n",
      "Evaluation/MinReturn                     -0.00200131\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.1298e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.0356\n",
      "GaussianMLPPolicy/KL                      8.24423e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000177592\n",
      "GaussianMLPPolicy/LossBefore             -0.000177483\n",
      "GaussianMLPPolicy/dLoss                   1.09692e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.55392\n",
      "GaussianMLPValueFunction/LossBefore      -6.1412\n",
      "GaussianMLPValueFunction/dLoss            0.412719\n",
      "TotalEnvSteps                        897102\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.5808e-06,  7.6343e-06, -7.7772e-08,  ...,  1.9118e-04,\n",
      "        -7.6583e-05,  2.1816e-04])\n",
      "G is: \n",
      "tensor([[5.6071e-07, 3.6331e-01],\n",
      "        [3.6331e-01, 2.3548e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [235478.8438,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-9.9931e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-9.9944e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:41 | [trpo_pendulum] epoch #449 | Saving snapshot...\n",
      "2022-08-23 10:44:41 | [trpo_pendulum] epoch #449 | Saved\n",
      "2022-08-23 10:44:41 | [trpo_pendulum] epoch #449 | Time 442.51 s\n",
      "2022-08-23 10:44:41 | [trpo_pendulum] epoch #449 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000201949\n",
      "Evaluation/AverageReturn                 -0.00208942\n",
      "Evaluation/Iteration                    449\n",
      "Evaluation/MaxReturn                     -0.00207475\n",
      "Evaluation/MinReturn                     -0.00210408\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.46657e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03577\n",
      "GaussianMLPPolicy/KL                      8.78319e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -9.9944e-05\n",
      "GaussianMLPPolicy/LossBefore             -9.99314e-05\n",
      "GaussianMLPPolicy/dLoss                   1.25947e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.21127\n",
      "GaussianMLPValueFunction/LossBefore      -6.63895\n",
      "GaussianMLPValueFunction/dLoss           -0.42768\n",
      "TotalEnvSteps                        899100\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.2213e-06, -7.1471e-05, -4.0078e-08,  ..., -1.3124e-03,\n",
      "         5.3375e-04, -1.4919e-03])\n",
      "G is: \n",
      "tensor([[2.6386e-05, 1.7110e+01],\n",
      "        [1.7110e+01, 1.1094e+07]])\n",
      "eig is:\n",
      "tensor([[       0.,        0.],\n",
      "        [11094418.,        0.]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:42 | [trpo_pendulum] epoch #450 | Saving snapshot...\n",
      "2022-08-23 10:44:42 | [trpo_pendulum] epoch #450 | Saved\n",
      "2022-08-23 10:44:42 | [trpo_pendulum] epoch #450 | Time 443.49 s\n",
      "2022-08-23 10:44:42 | [trpo_pendulum] epoch #450 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000211216\n",
      "Evaluation/AverageReturn                 -0.00189961\n",
      "Evaluation/Iteration                    450\n",
      "Evaluation/MaxReturn                     -0.00187255\n",
      "Evaluation/MinReturn                     -0.00192667\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.70597e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03577\n",
      "GaussianMLPPolicy/KL                      4.04222e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000149227\n",
      "GaussianMLPPolicy/LossBefore              0.000149285\n",
      "GaussianMLPPolicy/dLoss                   5.74655e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.74851\n",
      "GaussianMLPValueFunction/LossBefore      -6.36371\n",
      "GaussianMLPValueFunction/dLoss            0.384806\n",
      "TotalEnvSteps                        901098\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-1.2944e-06,  1.5047e-05,  2.4760e-08,  ...,  2.8062e-04,\n",
      "        -1.1400e-04,  3.1907e-04])\n",
      "G is: \n",
      "tensor([[1.2065e-06, 7.8230e-01],\n",
      "        [7.8230e-01, 5.0726e+05]])\n",
      "eig is:\n",
      "tensor([[-3.1250e-02,  0.0000e+00],\n",
      "        [ 5.0726e+05,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(7.2360e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(7.2357e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:43 | [trpo_pendulum] epoch #451 | Saving snapshot...\n",
      "2022-08-23 10:44:43 | [trpo_pendulum] epoch #451 | Saved\n",
      "2022-08-23 10:44:43 | [trpo_pendulum] epoch #451 | Time 444.46 s\n",
      "2022-08-23 10:44:43 | [trpo_pendulum] epoch #451 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000182296\n",
      "Evaluation/AverageReturn                 -0.00184928\n",
      "Evaluation/Iteration                    451\n",
      "Evaluation/MaxReturn                     -0.0018445\n",
      "Evaluation/MinReturn                     -0.00185407\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.78525e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03577\n",
      "GaussianMLPPolicy/KL                      1.87337e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               7.23571e-05\n",
      "GaussianMLPPolicy/LossBefore              7.23597e-05\n",
      "GaussianMLPPolicy/dLoss                   2.67028e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.61076\n",
      "GaussianMLPValueFunction/LossBefore      -6.75593\n",
      "GaussianMLPValueFunction/dLoss           -0.145164\n",
      "TotalEnvSteps                        903096\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.8332e-06, -1.4025e-05, -1.6344e-07,  ..., -2.5350e-04,\n",
      "         1.0298e-04, -2.8807e-04])\n",
      "G is: \n",
      "tensor([[9.8422e-07, 6.3809e-01],\n",
      "        [6.3809e-01, 4.1370e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [413701.7500,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-5.4656e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-5.4658e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:44 | [trpo_pendulum] epoch #452 | Saving snapshot...\n",
      "2022-08-23 10:44:44 | [trpo_pendulum] epoch #452 | Saved\n",
      "2022-08-23 10:44:44 | [trpo_pendulum] epoch #452 | Time 445.42 s\n",
      "2022-08-23 10:44:44 | [trpo_pendulum] epoch #452 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000213303\n",
      "Evaluation/AverageReturn                 -0.00223202\n",
      "Evaluation/Iteration                    452\n",
      "Evaluation/MaxReturn                     -0.00216646\n",
      "Evaluation/MinReturn                     -0.00229758\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.55605e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03577\n",
      "GaussianMLPPolicy/KL                      1.50813e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.46583e-05\n",
      "GaussianMLPPolicy/LossBefore             -5.46561e-05\n",
      "GaussianMLPPolicy/dLoss                   2.17187e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.73819\n",
      "GaussianMLPValueFunction/LossBefore      -6.78623\n",
      "GaussianMLPValueFunction/dLoss           -0.0480423\n",
      "TotalEnvSteps                        905094\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.2330e-06,  3.4990e-05, -2.2358e-07,  ...,  6.3436e-04,\n",
      "        -2.5845e-04,  7.2124e-04])\n",
      "G is: \n",
      "tensor([[6.1655e-06, 3.9975e+00],\n",
      "        [3.9975e+00, 2.5918e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [2591806.,       0.]])\n",
      "loss before is:\n",
      "tensor(-8.1932e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-8.1945e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:45 | [trpo_pendulum] epoch #453 | Saving snapshot...\n",
      "2022-08-23 10:44:45 | [trpo_pendulum] epoch #453 | Saved\n",
      "2022-08-23 10:44:45 | [trpo_pendulum] epoch #453 | Time 446.39 s\n",
      "2022-08-23 10:44:45 | [trpo_pendulum] epoch #453 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000213475\n",
      "Evaluation/AverageReturn                 -0.00218695\n",
      "Evaluation/Iteration                    453\n",
      "Evaluation/MaxReturn                     -0.00211411\n",
      "Evaluation/MinReturn                     -0.00225979\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.2842e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03577\n",
      "GaussianMLPPolicy/KL                      9.46911e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -8.19454e-05\n",
      "GaussianMLPPolicy/LossBefore             -8.1932e-05\n",
      "GaussianMLPPolicy/dLoss                   1.34023e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.86315\n",
      "GaussianMLPValueFunction/LossBefore      -6.70991\n",
      "GaussianMLPValueFunction/dLoss            0.15324\n",
      "TotalEnvSteps                        907092\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.8715e-06,  2.5106e-05, -3.2479e-07,  ...,  4.1922e-04,\n",
      "        -1.7197e-04,  4.7613e-04])\n",
      "G is: \n",
      "tensor([[2.6926e-06, 1.7457e+00],\n",
      "        [1.7457e+00, 1.1319e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1131856.1250,       0.0000]])\n",
      "loss before is:\n",
      "tensor(1.0137e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(1.0126e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:46 | [trpo_pendulum] epoch #454 | Saving snapshot...\n",
      "2022-08-23 10:44:46 | [trpo_pendulum] epoch #454 | Saved\n",
      "2022-08-23 10:44:46 | [trpo_pendulum] epoch #454 | Time 447.39 s\n",
      "2022-08-23 10:44:46 | [trpo_pendulum] epoch #454 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000189823\n",
      "Evaluation/AverageReturn                 -0.00221261\n",
      "Evaluation/Iteration                    454\n",
      "Evaluation/MaxReturn                     -0.00218485\n",
      "Evaluation/MinReturn                     -0.00224037\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.77587e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03589\n",
      "GaussianMLPPolicy/KL                      7.89616e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               1.01261e-05\n",
      "GaussianMLPPolicy/LossBefore              1.01374e-05\n",
      "GaussianMLPPolicy/dLoss                   1.12477e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.67866\n",
      "GaussianMLPValueFunction/LossBefore      -6.86477\n",
      "GaussianMLPValueFunction/dLoss           -0.186113\n",
      "TotalEnvSteps                        909090\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.6063e-06,  1.9243e-05, -9.2955e-08,  ...,  3.7433e-04,\n",
      "        -1.5187e-04,  4.2590e-04])\n",
      "G is: \n",
      "tensor([[2.1474e-06, 1.3927e+00],\n",
      "        [1.3927e+00, 9.0332e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [903315.6250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:47 | [trpo_pendulum] epoch #455 | Saving snapshot...\n",
      "2022-08-23 10:44:47 | [trpo_pendulum] epoch #455 | Saved\n",
      "2022-08-23 10:44:47 | [trpo_pendulum] epoch #455 | Time 448.38 s\n",
      "2022-08-23 10:44:47 | [trpo_pendulum] epoch #455 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000187294\n",
      "Evaluation/AverageReturn                 -0.00198002\n",
      "Evaluation/Iteration                    455\n",
      "Evaluation/MaxReturn                     -0.00188719\n",
      "Evaluation/MinReturn                     -0.00207284\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      9.28223e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03589\n",
      "GaussianMLPPolicy/KL                      3.3355e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000125196\n",
      "GaussianMLPPolicy/LossBefore             -0.000125191\n",
      "GaussianMLPPolicy/dLoss                   4.75848e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.72322\n",
      "GaussianMLPValueFunction/LossBefore      -6.50744\n",
      "GaussianMLPValueFunction/dLoss            0.215781\n",
      "TotalEnvSteps                        911088\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 5.5935e-06, -1.0638e-05,  3.0241e-08,  ..., -1.9826e-04,\n",
      "         8.0616e-05, -2.2544e-04])\n",
      "G is: \n",
      "tensor([[6.0228e-07, 3.9061e-01],\n",
      "        [3.9061e-01, 2.5335e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [253348.0312,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-8.1346e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-8.1348e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:48 | [trpo_pendulum] epoch #456 | Saving snapshot...\n",
      "2022-08-23 10:44:48 | [trpo_pendulum] epoch #456 | Saved\n",
      "2022-08-23 10:44:48 | [trpo_pendulum] epoch #456 | Time 449.37 s\n",
      "2022-08-23 10:44:48 | [trpo_pendulum] epoch #456 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000185066\n",
      "Evaluation/AverageReturn                 -0.00197227\n",
      "Evaluation/Iteration                    456\n",
      "Evaluation/MaxReturn                     -0.0018544\n",
      "Evaluation/MinReturn                     -0.00209015\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000117877\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03589\n",
      "GaussianMLPPolicy/KL                      9.16981e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -8.13477e-05\n",
      "GaussianMLPPolicy/LossBefore             -8.13465e-05\n",
      "GaussianMLPPolicy/dLoss                   1.23691e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.87457\n",
      "GaussianMLPValueFunction/LossBefore      -6.72057\n",
      "GaussianMLPValueFunction/dLoss            0.154005\n",
      "TotalEnvSteps                        913086\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.1644e-06,  1.3321e-05, -3.5704e-08,  ...,  2.4319e-04,\n",
      "        -9.9009e-05,  2.7646e-04])\n",
      "G is: \n",
      "tensor([[9.0613e-07, 5.8766e-01],\n",
      "        [5.8766e-01, 3.8113e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [381125.0938,      0.0000]])\n",
      "loss before is:\n",
      "tensor(1.6978e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(1.6976e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:49 | [trpo_pendulum] epoch #457 | Saving snapshot...\n",
      "2022-08-23 10:44:49 | [trpo_pendulum] epoch #457 | Saved\n",
      "2022-08-23 10:44:49 | [trpo_pendulum] epoch #457 | Time 450.37 s\n",
      "2022-08-23 10:44:49 | [trpo_pendulum] epoch #457 | EpochTime 1.00 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000210731\n",
      "Evaluation/AverageReturn                 -0.00199189\n",
      "Evaluation/Iteration                    457\n",
      "Evaluation/MaxReturn                     -0.00189962\n",
      "Evaluation/MinReturn                     -0.00208415\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      9.22652e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03589\n",
      "GaussianMLPPolicy/KL                      1.38824e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               1.69761e-05\n",
      "GaussianMLPPolicy/LossBefore              1.6978e-05\n",
      "GaussianMLPPolicy/dLoss                   1.98088e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.87679\n",
      "GaussianMLPValueFunction/LossBefore      -6.87022\n",
      "GaussianMLPValueFunction/dLoss            0.00656986\n",
      "TotalEnvSteps                        915084\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.2944e-06,  1.9521e-05,  1.1992e-09,  ...,  3.6202e-04,\n",
      "        -1.4717e-04,  4.1160e-04])\n",
      "G is: \n",
      "tensor([[2.0079e-06, 1.3022e+00],\n",
      "        [1.3022e+00, 8.4452e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [844517.5000,      0.0000]])\n",
      "loss before is:\n",
      "tensor(1.0668e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(1.0663e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:50 | [trpo_pendulum] epoch #458 | Saving snapshot...\n",
      "2022-08-23 10:44:50 | [trpo_pendulum] epoch #458 | Saved\n",
      "2022-08-23 10:44:50 | [trpo_pendulum] epoch #458 | Time 451.33 s\n",
      "2022-08-23 10:44:50 | [trpo_pendulum] epoch #458 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000230173\n",
      "Evaluation/AverageReturn                 -0.00219325\n",
      "Evaluation/Iteration                    458\n",
      "Evaluation/MaxReturn                     -0.0020471\n",
      "Evaluation/MinReturn                     -0.0023394\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000146151\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03589\n",
      "GaussianMLPPolicy/KL                      3.12277e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               1.06635e-05\n",
      "GaussianMLPPolicy/LossBefore              1.06679e-05\n",
      "GaussianMLPPolicy/dLoss                   4.40104e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.86341\n",
      "GaussianMLPValueFunction/LossBefore      -6.87313\n",
      "GaussianMLPValueFunction/dLoss           -0.00971079\n",
      "TotalEnvSteps                        917082\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.8801e-06,  2.9491e-06, -8.2843e-09,  ...,  5.2319e-05,\n",
      "        -2.1340e-05,  5.9452e-05])\n",
      "G is: \n",
      "tensor([[4.1949e-08, 2.7198e-02],\n",
      "        [2.7198e-02, 1.7640e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [17640.1133,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-3.6354e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-3.6355e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:50 | [trpo_pendulum] epoch #459 | Saving snapshot...\n",
      "2022-08-23 10:44:51 | [trpo_pendulum] epoch #459 | Saved\n",
      "2022-08-23 10:44:51 | [trpo_pendulum] epoch #459 | Time 452.30 s\n",
      "2022-08-23 10:44:51 | [trpo_pendulum] epoch #459 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000193934\n",
      "Evaluation/AverageReturn                 -0.00193128\n",
      "Evaluation/Iteration                    459\n",
      "Evaluation/MaxReturn                     -0.00187663\n",
      "Evaluation/MinReturn                     -0.00198593\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.4652e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03589\n",
      "GaussianMLPPolicy/KL                      5.97836e-08\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.63546e-05\n",
      "GaussianMLPPolicy/LossBefore             -3.63545e-05\n",
      "GaussianMLPPolicy/dLoss                   1.09139e-10\n",
      "GaussianMLPValueFunction/LossAfter       -6.82632\n",
      "GaussianMLPValueFunction/LossBefore      -6.84477\n",
      "GaussianMLPValueFunction/dLoss           -0.0184522\n",
      "TotalEnvSteps                        919080\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.8846e-06,  5.8687e-05,  1.8460e-07,  ...,  9.2526e-04,\n",
      "        -3.7986e-04,  1.0496e-03])\n",
      "G is: \n",
      "tensor([[1.3108e-05, 8.4990e+00],\n",
      "        [8.4990e+00, 5.5110e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [5511006.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(2.9924e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(2.9877e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:52 | [trpo_pendulum] epoch #460 | Saving snapshot...\n",
      "2022-08-23 10:44:52 | [trpo_pendulum] epoch #460 | Saved\n",
      "2022-08-23 10:44:52 | [trpo_pendulum] epoch #460 | Time 453.41 s\n",
      "2022-08-23 10:44:52 | [trpo_pendulum] epoch #460 | EpochTime 1.11 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000226578\n",
      "Evaluation/AverageReturn                 -0.00242084\n",
      "Evaluation/Iteration                    460\n",
      "Evaluation/MaxReturn                     -0.00239009\n",
      "Evaluation/MinReturn                     -0.0024516\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.07513e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03597\n",
      "GaussianMLPPolicy/KL                      3.33819e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               2.98771e-05\n",
      "GaussianMLPPolicy/LossBefore              2.99241e-05\n",
      "GaussianMLPPolicy/dLoss                   4.703e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.84252\n",
      "GaussianMLPValueFunction/LossBefore      -6.81818\n",
      "GaussianMLPValueFunction/dLoss            0.0243387\n",
      "TotalEnvSteps                        921078\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.6235e-06,  4.2852e-05, -2.8927e-07,  ...,  6.2186e-04,\n",
      "        -2.5745e-04,  7.0461e-04])\n",
      "G is: \n",
      "tensor([[5.9216e-06, 3.8394e+00],\n",
      "        [3.8394e+00, 2.4901e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [2490099.5000,       0.0000]])\n",
      "loss before is:\n",
      "tensor(1.6113e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(1.6072e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:53 | [trpo_pendulum] epoch #461 | Saving snapshot...\n",
      "2022-08-23 10:44:53 | [trpo_pendulum] epoch #461 | Saved\n",
      "2022-08-23 10:44:53 | [trpo_pendulum] epoch #461 | Time 454.38 s\n",
      "2022-08-23 10:44:53 | [trpo_pendulum] epoch #461 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000234821\n",
      "Evaluation/AverageReturn                 -0.00244304\n",
      "Evaluation/Iteration                    461\n",
      "Evaluation/MaxReturn                     -0.00232272\n",
      "Evaluation/MinReturn                     -0.00256337\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000120324\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03608\n",
      "GaussianMLPPolicy/KL                      2.90165e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               1.60723e-05\n",
      "GaussianMLPPolicy/LossBefore              1.61133e-05\n",
      "GaussianMLPPolicy/dLoss                   4.09909e-08\n",
      "GaussianMLPValueFunction/LossAfter       -5.26525\n",
      "GaussianMLPValueFunction/LossBefore      -6.84591\n",
      "GaussianMLPValueFunction/dLoss           -1.58067\n",
      "TotalEnvSteps                        923076\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.3292e-06,  3.6963e-06,  1.4726e-07,  ...,  6.2819e-06,\n",
      "        -3.9270e-06,  6.1205e-06])\n",
      "G is: \n",
      "tensor([[8.7149e-10, 3.7623e-04],\n",
      "        [3.7623e-04, 2.4412e+02]])\n",
      "eig is:\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [244.1194,   0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:54 | [trpo_pendulum] epoch #462 | Saving snapshot...\n",
      "2022-08-23 10:44:54 | [trpo_pendulum] epoch #462 | Saved\n",
      "2022-08-23 10:44:54 | [trpo_pendulum] epoch #462 | Time 455.40 s\n",
      "2022-08-23 10:44:54 | [trpo_pendulum] epoch #462 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000195951\n",
      "Evaluation/AverageReturn                 -0.00198755\n",
      "Evaluation/Iteration                    462\n",
      "Evaluation/MaxReturn                     -0.00190499\n",
      "Evaluation/MinReturn                     -0.00207011\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.25631e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.04054\n",
      "GaussianMLPPolicy/KL                      0.00011796\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000197869\n",
      "GaussianMLPPolicy/LossBefore              0.000198022\n",
      "GaussianMLPPolicy/dLoss                   1.53013e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.78298\n",
      "GaussianMLPValueFunction/LossBefore      -5.96818\n",
      "GaussianMLPValueFunction/dLoss            0.814802\n",
      "TotalEnvSteps                        925074\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-2.7801e-06, -3.5949e-05, -2.2703e-07,  ..., -5.5811e-04,\n",
      "         2.2972e-04, -6.3252e-04])\n",
      "G is: \n",
      "tensor([[4.7679e-06, 3.1214e+00],\n",
      "        [3.1214e+00, 2.0437e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [2043708.6250,       0.0000]])\n",
      "loss before is:\n",
      "tensor(9.0493e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(9.0462e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:55 | [trpo_pendulum] epoch #463 | Saving snapshot...\n",
      "2022-08-23 10:44:55 | [trpo_pendulum] epoch #463 | Saved\n",
      "2022-08-23 10:44:55 | [trpo_pendulum] epoch #463 | Time 456.41 s\n",
      "2022-08-23 10:44:55 | [trpo_pendulum] epoch #463 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000205961\n",
      "Evaluation/AverageReturn                 -0.00202808\n",
      "Evaluation/Iteration                    463\n",
      "Evaluation/MaxReturn                     -0.00194774\n",
      "Evaluation/MinReturn                     -0.00210841\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.03327e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.04046\n",
      "GaussianMLPPolicy/KL                      2.24939e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               9.04618e-05\n",
      "GaussianMLPPolicy/LossBefore              9.04935e-05\n",
      "GaussianMLPPolicy/dLoss                   3.16868e-08\n",
      "GaussianMLPValueFunction/LossAfter       -5.54532\n",
      "GaussianMLPValueFunction/LossBefore      -6.67418\n",
      "GaussianMLPValueFunction/dLoss           -1.12886\n",
      "TotalEnvSteps                        927072\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.5365e-06,  5.4795e-05, -4.4982e-07,  ...,  1.0464e-03,\n",
      "        -4.2588e-04,  1.1900e-03])\n",
      "G is: \n",
      "tensor([[1.6779e-05, 1.0984e+01],\n",
      "        [1.0984e+01, 7.1911e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [7191145.,       0.]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:56 | [trpo_pendulum] epoch #464 | Saving snapshot...\n",
      "2022-08-23 10:44:56 | [trpo_pendulum] epoch #464 | Saved\n",
      "2022-08-23 10:44:56 | [trpo_pendulum] epoch #464 | Time 457.37 s\n",
      "2022-08-23 10:44:56 | [trpo_pendulum] epoch #464 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000185539\n",
      "Evaluation/AverageReturn                 -0.00205457\n",
      "Evaluation/Iteration                    464\n",
      "Evaluation/MaxReturn                     -0.00205313\n",
      "Evaluation/MinReturn                     -0.00205601\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.44273e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.04046\n",
      "GaussianMLPPolicy/KL                      2.56667e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000252342\n",
      "GaussianMLPPolicy/LossBefore             -0.000252306\n",
      "GaussianMLPPolicy/dLoss                   3.59723e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.83135\n",
      "GaussianMLPValueFunction/LossBefore      -5.38198\n",
      "GaussianMLPValueFunction/dLoss            1.44937\n",
      "TotalEnvSteps                        929070\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.2060e-06,  3.5745e-05, -1.0692e-09,  ...,  6.6314e-04,\n",
      "        -2.7003e-04,  7.5366e-04])\n",
      "G is: \n",
      "tensor([[6.7365e-06, 4.4103e+00],\n",
      "        [4.4103e+00, 2.8874e+06]])\n",
      "eig is:\n",
      "tensor([[2.5000e-01, 0.0000e+00],\n",
      "        [2.8874e+06, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(-6.5521e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-6.5536e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:56 | [trpo_pendulum] epoch #465 | Saving snapshot...\n",
      "2022-08-23 10:44:57 | [trpo_pendulum] epoch #465 | Saved\n",
      "2022-08-23 10:44:57 | [trpo_pendulum] epoch #465 | Time 458.32 s\n",
      "2022-08-23 10:44:57 | [trpo_pendulum] epoch #465 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000153357\n",
      "Evaluation/AverageReturn                 -0.00178764\n",
      "Evaluation/Iteration                    465\n",
      "Evaluation/MaxReturn                     -0.00172968\n",
      "Evaluation/MinReturn                     -0.0018456\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.79631e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.04046\n",
      "GaussianMLPPolicy/KL                      1.03095e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.55356e-05\n",
      "GaussianMLPPolicy/LossBefore             -6.55212e-05\n",
      "GaussianMLPPolicy/dLoss                   1.43846e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.07699\n",
      "GaussianMLPValueFunction/LossBefore      -6.77979\n",
      "GaussianMLPValueFunction/dLoss           -0.702796\n",
      "TotalEnvSteps                        931068\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-2.0660e-06,  8.1211e-06, -2.1982e-07,  ...,  1.9919e-04,\n",
      "        -8.0161e-05,  2.2724e-04])\n",
      "G is: \n",
      "tensor([[6.0871e-07, 3.9843e-01],\n",
      "        [3.9843e-01, 2.6085e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [260849.1562,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:57 | [trpo_pendulum] epoch #466 | Saving snapshot...\n",
      "2022-08-23 10:44:58 | [trpo_pendulum] epoch #466 | Saved\n",
      "2022-08-23 10:44:58 | [trpo_pendulum] epoch #466 | Time 459.32 s\n",
      "2022-08-23 10:44:58 | [trpo_pendulum] epoch #466 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000196452\n",
      "Evaluation/AverageReturn                 -0.00187096\n",
      "Evaluation/Iteration                    466\n",
      "Evaluation/MaxReturn                     -0.00178915\n",
      "Evaluation/MinReturn                     -0.00195276\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.18039e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.0389\n",
      "GaussianMLPPolicy/KL                      7.70664e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000188824\n",
      "GaussianMLPPolicy/LossBefore              0.000188926\n",
      "GaussianMLPPolicy/dLoss                   1.02416e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.76258\n",
      "GaussianMLPValueFunction/LossBefore      -6.05431\n",
      "GaussianMLPValueFunction/dLoss            0.708271\n",
      "TotalEnvSteps                        933066\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.2105e-06,  1.4691e-06,  2.4543e-07,  ...,  3.2540e-05,\n",
      "        -1.2764e-05,  3.6975e-05])\n",
      "G is: \n",
      "tensor([[1.6206e-08, 1.0556e-02],\n",
      "        [1.0556e-02, 6.8873e+03]])\n",
      "eig is:\n",
      "tensor([[   0.0000,    0.0000],\n",
      "        [6887.2520,    0.0000]])\n",
      "loss before is:\n",
      "tensor(-4.9761e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-4.9761e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:44:59 | [trpo_pendulum] epoch #467 | Saving snapshot...\n",
      "2022-08-23 10:44:59 | [trpo_pendulum] epoch #467 | Saved\n",
      "2022-08-23 10:44:59 | [trpo_pendulum] epoch #467 | Time 460.37 s\n",
      "2022-08-23 10:44:59 | [trpo_pendulum] epoch #467 | EpochTime 1.05 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00021878\n",
      "Evaluation/AverageReturn                 -0.00210599\n",
      "Evaluation/Iteration                    467\n",
      "Evaluation/MaxReturn                     -0.00209975\n",
      "Evaluation/MinReturn                     -0.00211223\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.23965e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.0389\n",
      "GaussianMLPPolicy/KL                      1.16345e-08\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.9761e-05\n",
      "GaussianMLPPolicy/LossBefore             -4.9761e-05\n",
      "GaussianMLPPolicy/dLoss                   7.27596e-12\n",
      "GaussianMLPValueFunction/LossAfter       -6.81595\n",
      "GaussianMLPValueFunction/LossBefore      -6.82031\n",
      "GaussianMLPValueFunction/dLoss           -0.00435543\n",
      "TotalEnvSteps                        935064\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.8555e-06,  5.0675e-05, -1.5587e-08,  ...,  9.2203e-04,\n",
      "        -3.7533e-04,  1.0480e-03])\n",
      "G is: \n",
      "tensor([[1.3023e-05, 8.4975e+00],\n",
      "        [8.4975e+00, 5.5446e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [5544612.,       0.]])\n",
      "loss before is:\n",
      "tensor(-6.5751e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-6.5779e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:00 | [trpo_pendulum] epoch #468 | Saving snapshot...\n",
      "2022-08-23 10:45:00 | [trpo_pendulum] epoch #468 | Saved\n",
      "2022-08-23 10:45:00 | [trpo_pendulum] epoch #468 | Time 461.39 s\n",
      "2022-08-23 10:45:00 | [trpo_pendulum] epoch #468 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000187485\n",
      "Evaluation/AverageReturn                 -0.00192554\n",
      "Evaluation/Iteration                    468\n",
      "Evaluation/MaxReturn                     -0.00191543\n",
      "Evaluation/MinReturn                     -0.00193565\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.01101e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.0389\n",
      "GaussianMLPPolicy/KL                      1.99145e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.57786e-05\n",
      "GaussianMLPPolicy/LossBefore             -6.57505e-05\n",
      "GaussianMLPPolicy/dLoss                   2.81361e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.73711\n",
      "GaussianMLPValueFunction/LossBefore      -6.77778\n",
      "GaussianMLPValueFunction/dLoss           -0.0406713\n",
      "TotalEnvSteps                        937062\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.1525e-06, -7.3055e-06, -2.1530e-08,  ..., -9.2759e-05,\n",
      "         3.8742e-05, -1.0482e-04])\n",
      "G is: \n",
      "tensor([[1.3175e-07, 8.5864e-02],\n",
      "        [8.5864e-02, 5.6022e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [56022.3203,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-5.4835e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-5.4844e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:01 | [trpo_pendulum] epoch #469 | Saving snapshot...\n",
      "2022-08-23 10:45:01 | [trpo_pendulum] epoch #469 | Saved\n",
      "2022-08-23 10:45:01 | [trpo_pendulum] epoch #469 | Time 462.36 s\n",
      "2022-08-23 10:45:01 | [trpo_pendulum] epoch #469 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000191111\n",
      "Evaluation/AverageReturn                 -0.00208234\n",
      "Evaluation/Iteration                    469\n",
      "Evaluation/MaxReturn                     -0.00199884\n",
      "Evaluation/MinReturn                     -0.00216584\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      8.35017e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03933\n",
      "GaussianMLPPolicy/KL                      6.69515e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.48441e-05\n",
      "GaussianMLPPolicy/LossBefore             -5.48348e-05\n",
      "GaussianMLPPolicy/dLoss                   9.34597e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.87435\n",
      "GaussianMLPValueFunction/LossBefore      -6.80441\n",
      "GaussianMLPValueFunction/dLoss            0.069943\n",
      "TotalEnvSteps                        939060\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.5704e-06,  5.8467e-06, -8.5806e-09,  ...,  1.0361e-04,\n",
      "        -4.2250e-05,  1.1772e-04])\n",
      "G is: \n",
      "tensor([[1.6443e-07, 1.0738e-01],\n",
      "        [1.0738e-01, 7.0123e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [70122.8281,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-3.9233e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-3.9233e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:01 | [trpo_pendulum] epoch #470 | Saving snapshot...\n",
      "2022-08-23 10:45:02 | [trpo_pendulum] epoch #470 | Saved\n",
      "2022-08-23 10:45:02 | [trpo_pendulum] epoch #470 | Time 463.32 s\n",
      "2022-08-23 10:45:02 | [trpo_pendulum] epoch #470 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000195962\n",
      "Evaluation/AverageReturn                 -0.00197277\n",
      "Evaluation/Iteration                    470\n",
      "Evaluation/MaxReturn                     -0.00179293\n",
      "Evaluation/MinReturn                     -0.00215261\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000179837\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03933\n",
      "GaussianMLPPolicy/KL                      2.4164e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.92333e-05\n",
      "GaussianMLPPolicy/LossBefore             -3.92329e-05\n",
      "GaussianMLPPolicy/dLoss                   3.85626e-10\n",
      "GaussianMLPValueFunction/LossAfter       -6.74643\n",
      "GaussianMLPValueFunction/LossBefore      -6.84658\n",
      "GaussianMLPValueFunction/dLoss           -0.100157\n",
      "TotalEnvSteps                        941058\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.3256e-06, -1.4277e-05,  1.1466e-07,  ..., -2.4546e-04,\n",
      "         1.0042e-04, -2.7883e-04])\n",
      "G is: \n",
      "tensor([[9.2301e-07, 6.0276e-01],\n",
      "        [6.0276e-01, 3.9364e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [393637.2500,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-7.2781e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-7.2783e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:02 | [trpo_pendulum] epoch #471 | Saving snapshot...\n",
      "2022-08-23 10:45:02 | [trpo_pendulum] epoch #471 | Saved\n",
      "2022-08-23 10:45:02 | [trpo_pendulum] epoch #471 | Time 464.27 s\n",
      "2022-08-23 10:45:02 | [trpo_pendulum] epoch #471 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00019354\n",
      "Evaluation/AverageReturn                 -0.00200153\n",
      "Evaluation/Iteration                    471\n",
      "Evaluation/MaxReturn                     -0.0018699\n",
      "Evaluation/MinReturn                     -0.00213315\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000131625\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03933\n",
      "GaussianMLPPolicy/KL                      1.40459e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.27825e-05\n",
      "GaussianMLPPolicy/LossBefore             -7.27806e-05\n",
      "GaussianMLPPolicy/dLoss                   1.96451e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.84981\n",
      "GaussianMLPValueFunction/LossBefore      -6.75574\n",
      "GaussianMLPValueFunction/dLoss            0.0940633\n",
      "TotalEnvSteps                        943056\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.5259e-06,  4.9163e-05, -9.2248e-08,  ...,  8.0627e-04,\n",
      "        -3.3041e-04,  9.1523e-04])\n",
      "G is: \n",
      "tensor([[9.9549e-06, 6.5001e+00],\n",
      "        [6.5001e+00, 4.2445e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [4244451.,       0.]])\n",
      "loss before is:\n",
      "tensor(6.9952e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(6.9916e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:03 | [trpo_pendulum] epoch #472 | Saving snapshot...\n",
      "2022-08-23 10:45:03 | [trpo_pendulum] epoch #472 | Saved\n",
      "2022-08-23 10:45:03 | [trpo_pendulum] epoch #472 | Time 465.25 s\n",
      "2022-08-23 10:45:03 | [trpo_pendulum] epoch #472 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0002023\n",
      "Evaluation/AverageReturn                 -0.00216479\n",
      "Evaluation/Iteration                    472\n",
      "Evaluation/MaxReturn                     -0.00212355\n",
      "Evaluation/MinReturn                     -0.00220602\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.12339e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03944\n",
      "GaussianMLPPolicy/KL                      2.58458e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               6.9916e-05\n",
      "GaussianMLPPolicy/LossBefore              6.99525e-05\n",
      "GaussianMLPPolicy/dLoss                   3.64889e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.84276\n",
      "GaussianMLPValueFunction/LossBefore      -6.7581\n",
      "GaussianMLPValueFunction/dLoss            0.0846562\n",
      "TotalEnvSteps                        945054\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.7063e-06, -1.5875e-06, -2.5087e-07,  ..., -6.8551e-05,\n",
      "         2.6557e-05, -7.8417e-05])\n",
      "G is: \n",
      "tensor([[7.2162e-08, 4.7038e-02],\n",
      "        [4.7038e-02, 3.0725e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [30725.1113,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-6.3786e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-6.3807e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:04 | [trpo_pendulum] epoch #473 | Saving snapshot...\n",
      "2022-08-23 10:45:04 | [trpo_pendulum] epoch #473 | Saved\n",
      "2022-08-23 10:45:04 | [trpo_pendulum] epoch #473 | Time 466.24 s\n",
      "2022-08-23 10:45:04 | [trpo_pendulum] epoch #473 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00018771\n",
      "Evaluation/AverageReturn                 -0.00197269\n",
      "Evaluation/Iteration                    473\n",
      "Evaluation/MaxReturn                     -0.00195689\n",
      "Evaluation/MinReturn                     -0.00198849\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.58018e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.0401\n",
      "GaussianMLPPolicy/KL                      1.49099e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.38073e-05\n",
      "GaussianMLPPolicy/LossBefore             -6.37864e-05\n",
      "GaussianMLPPolicy/dLoss                   2.09111e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.8045\n",
      "GaussianMLPValueFunction/LossBefore      -6.78475\n",
      "GaussianMLPValueFunction/dLoss            0.0197449\n",
      "TotalEnvSteps                        947052\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.5300e-06,  1.4734e-05,  4.2819e-08,  ...,  2.7572e-04,\n",
      "        -1.1202e-04,  3.1345e-04])\n",
      "G is: \n",
      "tensor([[1.1645e-06, 7.6169e-01],\n",
      "        [7.6169e-01, 4.9821e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [498211.1875,      0.0000]])\n",
      "loss before is:\n",
      "tensor(5.2789e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(5.2786e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:05 | [trpo_pendulum] epoch #474 | Saving snapshot...\n",
      "2022-08-23 10:45:05 | [trpo_pendulum] epoch #474 | Saved\n",
      "2022-08-23 10:45:05 | [trpo_pendulum] epoch #474 | Time 467.21 s\n",
      "2022-08-23 10:45:05 | [trpo_pendulum] epoch #474 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000194541\n",
      "Evaluation/AverageReturn                 -0.00195724\n",
      "Evaluation/Iteration                    474\n",
      "Evaluation/MaxReturn                     -0.00194389\n",
      "Evaluation/MinReturn                     -0.00197059\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.33503e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.0401\n",
      "GaussianMLPPolicy/KL                      1.78811e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               5.27861e-05\n",
      "GaussianMLPPolicy/LossBefore              5.27887e-05\n",
      "GaussianMLPPolicy/dLoss                   2.56841e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.86532\n",
      "GaussianMLPValueFunction/LossBefore      -6.81992\n",
      "GaussianMLPValueFunction/dLoss            0.0453992\n",
      "TotalEnvSteps                        949050\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.1534e-06,  9.7650e-06, -3.6329e-07,  ...,  1.5416e-04,\n",
      "        -6.3819e-05,  1.7504e-04])\n",
      "G is: \n",
      "tensor([[3.6428e-07, 2.3816e-01],\n",
      "        [2.3816e-01, 1.5576e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [155759.3125,      0.0000]])\n",
      "loss before is:\n",
      "tensor(8.9015e-06, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(8.8531e-06, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:06 | [trpo_pendulum] epoch #475 | Saving snapshot...\n",
      "2022-08-23 10:45:06 | [trpo_pendulum] epoch #475 | Saved\n",
      "2022-08-23 10:45:06 | [trpo_pendulum] epoch #475 | Time 468.13 s\n",
      "2022-08-23 10:45:06 | [trpo_pendulum] epoch #475 | EpochTime 0.92 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000198614\n",
      "Evaluation/AverageReturn                 -0.00221085\n",
      "Evaluation/Iteration                    475\n",
      "Evaluation/MaxReturn                     -0.00214918\n",
      "Evaluation/MinReturn                     -0.00227253\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.16708e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.04435\n",
      "GaussianMLPPolicy/KL                      3.41383e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               8.85312e-06\n",
      "GaussianMLPPolicy/LossBefore              8.9015e-06\n",
      "GaussianMLPPolicy/dLoss                   4.83769e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.67045\n",
      "GaussianMLPValueFunction/LossBefore      -6.8615\n",
      "GaussianMLPValueFunction/dLoss           -0.191057\n",
      "TotalEnvSteps                        951048\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.2182e-06,  9.3547e-06,  2.8330e-07,  ...,  8.0326e-05,\n",
      "        -3.4631e-05,  8.9763e-05])\n",
      "G is: \n",
      "tensor([[9.8771e-08, 6.4816e-02],\n",
      "        [6.4816e-02, 4.2751e+04]])\n",
      "eig is:\n",
      "tensor([[    0.0000,     0.0000],\n",
      "        [42750.7266,     0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:07 | [trpo_pendulum] epoch #476 | Saving snapshot...\n",
      "2022-08-23 10:45:07 | [trpo_pendulum] epoch #476 | Saved\n",
      "2022-08-23 10:45:07 | [trpo_pendulum] epoch #476 | Time 469.07 s\n",
      "2022-08-23 10:45:07 | [trpo_pendulum] epoch #476 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000207588\n",
      "Evaluation/AverageReturn                 -0.00204448\n",
      "Evaluation/Iteration                    476\n",
      "Evaluation/MaxReturn                     -0.0020262\n",
      "Evaluation/MinReturn                     -0.00206276\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.82791e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.04442\n",
      "GaussianMLPPolicy/KL                      2.05558e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000111986\n",
      "GaussianMLPPolicy/LossBefore             -0.000111957\n",
      "GaussianMLPPolicy/dLoss                   2.91184e-08\n",
      "GaussianMLPValueFunction/LossAfter       -5.39729\n",
      "GaussianMLPValueFunction/LossBefore      -6.58434\n",
      "GaussianMLPValueFunction/dLoss           -1.18705\n",
      "TotalEnvSteps                        953046\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-8.0579e-06,  7.5418e-05, -1.8431e-06,  ...,  1.6898e-03,\n",
      "        -6.8256e-04,  1.9260e-03])\n",
      "G is: \n",
      "tensor([[4.3783e-05, 2.8879e+01],\n",
      "        [2.8879e+01, 1.9051e+07]])\n",
      "eig is:\n",
      "tensor([[       0.,        0.],\n",
      "        [19051116.,        0.]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:08 | [trpo_pendulum] epoch #477 | Saving snapshot...\n",
      "2022-08-23 10:45:08 | [trpo_pendulum] epoch #477 | Saved\n",
      "2022-08-23 10:45:08 | [trpo_pendulum] epoch #477 | Time 470.05 s\n",
      "2022-08-23 10:45:08 | [trpo_pendulum] epoch #477 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000197175\n",
      "Evaluation/AverageReturn                 -0.00224586\n",
      "Evaluation/Iteration                    477\n",
      "Evaluation/MaxReturn                     -0.00222992\n",
      "Evaluation/MinReturn                     -0.00226181\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.59479e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.04141\n",
      "GaussianMLPPolicy/KL                      0.000317184\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000222989\n",
      "GaussianMLPPolicy/LossBefore             -0.000222506\n",
      "GaussianMLPPolicy/dLoss                   4.83458e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.74806\n",
      "GaussianMLPValueFunction/LossBefore      -5.69221\n",
      "GaussianMLPValueFunction/dLoss            0.0558529\n",
      "TotalEnvSteps                        955044\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.8195e-06,  2.3236e-05,  5.3279e-09,  ...,  4.0116e-04,\n",
      "        -1.6405e-04,  4.5530e-04])\n",
      "G is: \n",
      "tensor([[2.4633e-06, 1.6152e+00],\n",
      "        [1.6152e+00, 1.0592e+06]])\n",
      "eig is:\n",
      "tensor([[-1.2500e-01,  0.0000e+00],\n",
      "        [ 1.0592e+06,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:09 | [trpo_pendulum] epoch #478 | Saving snapshot...\n",
      "2022-08-23 10:45:09 | [trpo_pendulum] epoch #478 | Saved\n",
      "2022-08-23 10:45:09 | [trpo_pendulum] epoch #478 | Time 471.00 s\n",
      "2022-08-23 10:45:09 | [trpo_pendulum] epoch #478 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000198861\n",
      "Evaluation/AverageReturn                 -0.00190351\n",
      "Evaluation/Iteration                    478\n",
      "Evaluation/MaxReturn                     -0.00183588\n",
      "Evaluation/MinReturn                     -0.00197115\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.76373e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.04141\n",
      "GaussianMLPPolicy/KL                      3.72037e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000262516\n",
      "GaussianMLPPolicy/LossBefore             -0.000262511\n",
      "GaussianMLPPolicy/dLoss                   4.97676e-09\n",
      "GaussianMLPValueFunction/LossAfter       -3.43531\n",
      "GaussianMLPValueFunction/LossBefore      -5.24639\n",
      "GaussianMLPValueFunction/dLoss           -1.81108\n",
      "TotalEnvSteps                        957042\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-2.3375e-06,  8.4329e-05,  3.9904e-07,  ...,  1.6330e-03,\n",
      "        -6.6237e-04,  1.8562e-03])\n",
      "G is: \n",
      "tensor([[4.0832e-05, 2.6775e+01],\n",
      "        [2.6775e+01, 1.7558e+07]])\n",
      "eig is:\n",
      "tensor([[       0.,        0.],\n",
      "        [17557676.,        0.]])\n",
      "loss before is:\n",
      "tensor(-0.0004, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0004, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:10 | [trpo_pendulum] epoch #479 | Saving snapshot...\n",
      "2022-08-23 10:45:10 | [trpo_pendulum] epoch #479 | Saved\n",
      "2022-08-23 10:45:10 | [trpo_pendulum] epoch #479 | Time 472.04 s\n",
      "2022-08-23 10:45:10 | [trpo_pendulum] epoch #479 | EpochTime 1.03 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000180726\n",
      "Evaluation/AverageReturn                 -0.00194081\n",
      "Evaluation/Iteration                    479\n",
      "Evaluation/MaxReturn                     -0.0019358\n",
      "Evaluation/MinReturn                     -0.00194583\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.01283e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03928\n",
      "GaussianMLPPolicy/KL                      0.000101201\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000379197\n",
      "GaussianMLPPolicy/LossBefore             -0.000379077\n",
      "GaussianMLPPolicy/dLoss                   1.20461e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.77308\n",
      "GaussianMLPValueFunction/LossBefore      -3.46443\n",
      "GaussianMLPValueFunction/dLoss            3.30865\n",
      "TotalEnvSteps                        959040\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.0034e-06, -7.2266e-06,  6.3180e-09,  ..., -1.3286e-04,\n",
      "         5.3984e-05, -1.5104e-04])\n",
      "G is: \n",
      "tensor([[2.7037e-07, 1.7650e-01],\n",
      "        [1.7650e-01, 1.1523e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [115225.1250,      0.0000]])\n",
      "loss before is:\n",
      "tensor(6.3570e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(6.3569e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:11 | [trpo_pendulum] epoch #480 | Saving snapshot...\n",
      "2022-08-23 10:45:11 | [trpo_pendulum] epoch #480 | Saved\n",
      "2022-08-23 10:45:11 | [trpo_pendulum] epoch #480 | Time 472.98 s\n",
      "2022-08-23 10:45:11 | [trpo_pendulum] epoch #480 | EpochTime 0.94 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000194008\n",
      "Evaluation/AverageReturn                 -0.00188095\n",
      "Evaluation/Iteration                    480\n",
      "Evaluation/MaxReturn                     -0.00177591\n",
      "Evaluation/MinReturn                     -0.00198599\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000105039\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03928\n",
      "GaussianMLPPolicy/KL                      4.12728e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               6.35694e-05\n",
      "GaussianMLPPolicy/LossBefore              6.35699e-05\n",
      "GaussianMLPPolicy/dLoss                   4.94765e-10\n",
      "GaussianMLPValueFunction/LossAfter       -6.87801\n",
      "GaussianMLPValueFunction/LossBefore      -6.78508\n",
      "GaussianMLPValueFunction/dLoss            0.0929317\n",
      "TotalEnvSteps                        961038\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 4.4214e-06,  5.3408e-05, -3.5791e-07,  ...,  8.1067e-04,\n",
      "        -3.3392e-04,  9.1938e-04])\n",
      "G is: \n",
      "tensor([[1.0061e-05, 6.5664e+00],\n",
      "        [6.5664e+00, 4.2862e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [4286222.,       0.]])\n",
      "loss before is:\n",
      "tensor(2.6205e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(2.6140e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:12 | [trpo_pendulum] epoch #481 | Saving snapshot...\n",
      "2022-08-23 10:45:12 | [trpo_pendulum] epoch #481 | Saved\n",
      "2022-08-23 10:45:12 | [trpo_pendulum] epoch #481 | Time 474.01 s\n",
      "2022-08-23 10:45:12 | [trpo_pendulum] epoch #481 | EpochTime 1.03 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000222711\n",
      "Evaluation/AverageReturn                 -0.00226305\n",
      "Evaluation/Iteration                    481\n",
      "Evaluation/MaxReturn                     -0.00223084\n",
      "Evaluation/MinReturn                     -0.00229527\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.22181e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03939\n",
      "GaussianMLPPolicy/KL                      4.58259e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               2.61402e-05\n",
      "GaussianMLPPolicy/LossBefore              2.62053e-05\n",
      "GaussianMLPPolicy/dLoss                   6.51216e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.87039\n",
      "GaussianMLPValueFunction/LossBefore      -6.84787\n",
      "GaussianMLPValueFunction/dLoss            0.0225129\n",
      "TotalEnvSteps                        963036\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.5440e-06,  1.8805e-05, -2.1307e-07,  ...,  3.2501e-04,\n",
      "        -1.3284e-04,  3.6927e-04])\n",
      "G is: \n",
      "tensor([[1.6179e-06, 1.0564e+00],\n",
      "        [1.0564e+00, 6.8976e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [689763.5000,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-6.5128e-06, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-6.5162e-06, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:13 | [trpo_pendulum] epoch #482 | Saving snapshot...\n",
      "2022-08-23 10:45:13 | [trpo_pendulum] epoch #482 | Saved\n",
      "2022-08-23 10:45:13 | [trpo_pendulum] epoch #482 | Time 474.94 s\n",
      "2022-08-23 10:45:13 | [trpo_pendulum] epoch #482 | EpochTime 0.92 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000222897\n",
      "Evaluation/AverageReturn                 -0.00205861\n",
      "Evaluation/Iteration                    482\n",
      "Evaluation/MaxReturn                     -0.00205453\n",
      "Evaluation/MinReturn                     -0.00206269\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.08096e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03939\n",
      "GaussianMLPPolicy/KL                      2.48439e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.5162e-06\n",
      "GaussianMLPPolicy/LossBefore             -6.51276e-06\n",
      "GaussianMLPPolicy/dLoss                   3.43971e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.16317\n",
      "GaussianMLPValueFunction/LossBefore      -6.88152\n",
      "GaussianMLPValueFunction/dLoss           -0.718351\n",
      "TotalEnvSteps                        965034\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.8875e-06,  2.6698e-05, -1.4083e-07,  ...,  2.0015e-04,\n",
      "        -8.8594e-05,  2.2343e-04])\n",
      "G is: \n",
      "tensor([[6.1564e-07, 3.9859e-01],\n",
      "        [3.9859e-01, 2.6025e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [260250.3125,      0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:14 | [trpo_pendulum] epoch #483 | Saving snapshot...\n",
      "2022-08-23 10:45:14 | [trpo_pendulum] epoch #483 | Saved\n",
      "2022-08-23 10:45:14 | [trpo_pendulum] epoch #483 | Time 475.95 s\n",
      "2022-08-23 10:45:14 | [trpo_pendulum] epoch #483 | EpochTime 1.01 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000212654\n",
      "Evaluation/AverageReturn                 -0.00219051\n",
      "Evaluation/Iteration                    483\n",
      "Evaluation/MaxReturn                     -0.00217103\n",
      "Evaluation/MinReturn                     -0.00220999\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.9477e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.03947\n",
      "GaussianMLPPolicy/KL                      0.000104254\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000189373\n",
      "GaussianMLPPolicy/LossBefore              0.000189521\n",
      "GaussianMLPPolicy/dLoss                   1.48211e-07\n",
      "GaussianMLPValueFunction/LossAfter       -5.39789\n",
      "GaussianMLPValueFunction/LossBefore      -6.02674\n",
      "GaussianMLPValueFunction/dLoss           -0.628851\n",
      "TotalEnvSteps                        967032\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.3909e-06, -2.9437e-05,  2.6105e-07,  ..., -5.9600e-04,\n",
      "         2.4122e-04, -6.7842e-04])\n",
      "G is: \n",
      "tensor([[5.4429e-06, 3.5546e+00],\n",
      "        [3.5546e+00, 2.3215e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [2321483.7500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:15 | [trpo_pendulum] epoch #484 | Saving snapshot...\n",
      "2022-08-23 10:45:15 | [trpo_pendulum] epoch #484 | Saved\n",
      "2022-08-23 10:45:15 | [trpo_pendulum] epoch #484 | Time 477.02 s\n",
      "2022-08-23 10:45:15 | [trpo_pendulum] epoch #484 | EpochTime 1.07 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000219723\n",
      "Evaluation/AverageReturn                 -0.00210502\n",
      "Evaluation/Iteration                    484\n",
      "Evaluation/MaxReturn                     -0.00209053\n",
      "Evaluation/MinReturn                     -0.00211951\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.4492e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.04608\n",
      "GaussianMLPPolicy/KL                      6.66767e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000237024\n",
      "GaussianMLPPolicy/LossBefore              0.000237117\n",
      "GaussianMLPPolicy/dLoss                   9.25211e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.25955\n",
      "GaussianMLPValueFunction/LossBefore      -5.55522\n",
      "GaussianMLPValueFunction/dLoss            0.70433\n",
      "TotalEnvSteps                        969030\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.2752e-07,  6.8773e-05, -2.8226e-07,  ...,  1.2592e-03,\n",
      "        -5.1232e-04,  1.4314e-03])\n",
      "G is: \n",
      "tensor([[2.4286e-05, 1.6072e+01],\n",
      "        [1.6072e+01, 1.0636e+07]])\n",
      "eig is:\n",
      "tensor([[       0.,        0.],\n",
      "        [10635638.,        0.]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:16 | [trpo_pendulum] epoch #485 | Saving snapshot...\n",
      "2022-08-23 10:45:16 | [trpo_pendulum] epoch #485 | Saved\n",
      "2022-08-23 10:45:16 | [trpo_pendulum] epoch #485 | Time 478.06 s\n",
      "2022-08-23 10:45:16 | [trpo_pendulum] epoch #485 | EpochTime 1.03 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000203113\n",
      "Evaluation/AverageReturn                 -0.00199716\n",
      "Evaluation/Iteration                    485\n",
      "Evaluation/MaxReturn                     -0.00196984\n",
      "Evaluation/MinReturn                     -0.00202448\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.73183e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.04608\n",
      "GaussianMLPPolicy/KL                      3.66228e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000165901\n",
      "GaussianMLPPolicy/LossBefore             -0.000165849\n",
      "GaussianMLPPolicy/dLoss                   5.19067e-08\n",
      "GaussianMLPValueFunction/LossAfter       -5.88084\n",
      "GaussianMLPValueFunction/LossBefore      -6.2268\n",
      "GaussianMLPValueFunction/dLoss           -0.345964\n",
      "TotalEnvSteps                        971028\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.5056e-06, -1.1010e-05, -5.6889e-07,  ..., -1.2439e-04,\n",
      "         5.1735e-05, -1.4000e-04])\n",
      "G is: \n",
      "tensor([[2.3640e-07, 1.5620e-01],\n",
      "        [1.5620e-01, 1.0338e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [103375.2344,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:17 | [trpo_pendulum] epoch #486 | Saving snapshot...\n",
      "2022-08-23 10:45:17 | [trpo_pendulum] epoch #486 | Saved\n",
      "2022-08-23 10:45:17 | [trpo_pendulum] epoch #486 | Time 479.16 s\n",
      "2022-08-23 10:45:17 | [trpo_pendulum] epoch #486 | EpochTime 1.09 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000206804\n",
      "Evaluation/AverageReturn                 -0.0020863\n",
      "Evaluation/Iteration                    486\n",
      "Evaluation/MaxReturn                     -0.00204426\n",
      "Evaluation/MinReturn                     -0.00212835\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.20444e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.04623\n",
      "GaussianMLPPolicy/KL                      1.16523e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000194937\n",
      "GaussianMLPPolicy/LossBefore             -0.00019492\n",
      "GaussianMLPPolicy/dLoss                   1.63564e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.8796\n",
      "GaussianMLPValueFunction/LossBefore      -5.9708\n",
      "GaussianMLPValueFunction/dLoss            0.908803\n",
      "TotalEnvSteps                        973026\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.9308e-06, -9.2109e-06, -1.2668e-08,  ..., -1.6174e-04,\n",
      "         6.5922e-05, -1.8373e-04])\n",
      "G is: \n",
      "tensor([[4.0064e-07, 2.6523e-01],\n",
      "        [2.6523e-01, 1.7559e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [175591.8438,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-2.8588e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-2.8588e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:18 | [trpo_pendulum] epoch #487 | Saving snapshot...\n",
      "2022-08-23 10:45:18 | [trpo_pendulum] epoch #487 | Saved\n",
      "2022-08-23 10:45:18 | [trpo_pendulum] epoch #487 | Time 480.11 s\n",
      "2022-08-23 10:45:18 | [trpo_pendulum] epoch #487 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000208083\n",
      "Evaluation/AverageReturn                 -0.00193303\n",
      "Evaluation/Iteration                    487\n",
      "Evaluation/MaxReturn                     -0.00191253\n",
      "Evaluation/MinReturn                     -0.00195354\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.05054e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.04623\n",
      "GaussianMLPPolicy/KL                      5.95927e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -2.85883e-05\n",
      "GaussianMLPPolicy/LossBefore             -2.85875e-05\n",
      "GaussianMLPPolicy/dLoss                   8.29459e-10\n",
      "GaussianMLPValueFunction/LossAfter       -3.67018\n",
      "GaussianMLPValueFunction/LossBefore      -6.86508\n",
      "GaussianMLPValueFunction/dLoss           -3.19489\n",
      "TotalEnvSteps                        975024\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([-3.9129e-06,  8.6200e-05,  1.8818e-07,  ...,  1.5763e-03,\n",
      "        -6.4055e-04,  1.7918e-03])\n",
      "G is: \n",
      "tensor([[3.8054e-05, 2.5190e+01],\n",
      "        [2.5190e+01, 1.6674e+07]])\n",
      "eig is:\n",
      "tensor([[       0.,        0.],\n",
      "        [16674323.,        0.]])\n",
      "loss before is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0003, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:19 | [trpo_pendulum] epoch #488 | Saving snapshot...\n",
      "2022-08-23 10:45:19 | [trpo_pendulum] epoch #488 | Saved\n",
      "2022-08-23 10:45:19 | [trpo_pendulum] epoch #488 | Time 481.06 s\n",
      "2022-08-23 10:45:19 | [trpo_pendulum] epoch #488 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000221309\n",
      "Evaluation/AverageReturn                 -0.00223366\n",
      "Evaluation/Iteration                    488\n",
      "Evaluation/MaxReturn                     -0.00212692\n",
      "Evaluation/MinReturn                     -0.0023404\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000106743\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.04623\n",
      "GaussianMLPPolicy/KL                      5.71043e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000330513\n",
      "GaussianMLPPolicy/LossBefore             -0.000330432\n",
      "GaussianMLPPolicy/dLoss                   8.11124e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.55356\n",
      "GaussianMLPValueFunction/LossBefore      -4.25908\n",
      "GaussianMLPValueFunction/dLoss            2.29448\n",
      "TotalEnvSteps                        977022\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.5711e-06,  4.1736e-05, -8.9859e-08,  ...,  5.8214e-04,\n",
      "        -2.4131e-04,  6.5907e-04])\n",
      "G is: \n",
      "tensor([[5.1873e-06, 3.4325e+00],\n",
      "        [3.4325e+00, 2.2722e+06]])\n",
      "eig is:\n",
      "tensor([[2.5000e-01, 0.0000e+00],\n",
      "        [2.2722e+06, 0.0000e+00]])\n",
      "loss before is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:20 | [trpo_pendulum] epoch #489 | Saving snapshot...\n",
      "2022-08-23 10:45:20 | [trpo_pendulum] epoch #489 | Saved\n",
      "2022-08-23 10:45:20 | [trpo_pendulum] epoch #489 | Time 482.09 s\n",
      "2022-08-23 10:45:20 | [trpo_pendulum] epoch #489 | EpochTime 1.02 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.00021277\n",
      "Evaluation/AverageReturn                 -0.00219141\n",
      "Evaluation/Iteration                    489\n",
      "Evaluation/MaxReturn                     -0.00218156\n",
      "Evaluation/MinReturn                     -0.00220127\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      9.85066e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.04633\n",
      "GaussianMLPPolicy/KL                      4.60189e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000109163\n",
      "GaussianMLPPolicy/LossBefore              0.000109228\n",
      "GaussianMLPPolicy/dLoss                   6.54836e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.86894\n",
      "GaussianMLPValueFunction/LossBefore      -6.59069\n",
      "GaussianMLPValueFunction/dLoss            0.278249\n",
      "TotalEnvSteps                        979020\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.3313e-06,  2.7237e-05, -4.3930e-08,  ...,  3.9437e-04,\n",
      "        -1.6303e-04,  4.4674e-04])\n",
      "G is: \n",
      "tensor([[2.3807e-06, 1.5757e+00],\n",
      "        [1.5757e+00, 1.0432e+06]])\n",
      "eig is:\n",
      "tensor([[-6.2500e-02,  0.0000e+00],\n",
      "        [ 1.0432e+06,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-3.2427e-06, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-3.2598e-06, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:21 | [trpo_pendulum] epoch #490 | Saving snapshot...\n",
      "2022-08-23 10:45:21 | [trpo_pendulum] epoch #490 | Saved\n",
      "2022-08-23 10:45:21 | [trpo_pendulum] epoch #490 | Time 483.07 s\n",
      "2022-08-23 10:45:21 | [trpo_pendulum] epoch #490 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000229505\n",
      "Evaluation/AverageReturn                 -0.00228947\n",
      "Evaluation/Iteration                    490\n",
      "Evaluation/MaxReturn                     -0.00225362\n",
      "Evaluation/MinReturn                     -0.00232532\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.58499e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.04637\n",
      "GaussianMLPPolicy/KL                      1.2055e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.25975e-06\n",
      "GaussianMLPPolicy/LossBefore             -3.24269e-06\n",
      "GaussianMLPPolicy/dLoss                   1.70667e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.65583\n",
      "GaussianMLPValueFunction/LossBefore      -6.86578\n",
      "GaussianMLPValueFunction/dLoss           -0.209942\n",
      "TotalEnvSteps                        981018\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 7.8152e-06, -1.1103e-05, -6.9043e-07,  ..., -1.7625e-04,\n",
      "         7.1450e-05, -1.9960e-04])\n",
      "G is: \n",
      "tensor([[4.7494e-07, 3.1435e-01],\n",
      "        [3.1435e-01, 2.0814e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [208139.2031,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-9.5343e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-9.5401e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:22 | [trpo_pendulum] epoch #491 | Saving snapshot...\n",
      "2022-08-23 10:45:22 | [trpo_pendulum] epoch #491 | Saved\n",
      "2022-08-23 10:45:22 | [trpo_pendulum] epoch #491 | Time 484.07 s\n",
      "2022-08-23 10:45:22 | [trpo_pendulum] epoch #491 | EpochTime 0.99 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000240496\n",
      "Evaluation/AverageReturn                 -0.00228105\n",
      "Evaluation/Iteration                    491\n",
      "Evaluation/MaxReturn                     -0.00224988\n",
      "Evaluation/MinReturn                     -0.00231223\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.11795e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.04926\n",
      "GaussianMLPPolicy/KL                      4.23056e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -9.54014e-05\n",
      "GaussianMLPPolicy/LossBefore             -9.53426e-05\n",
      "GaussianMLPPolicy/dLoss                   5.87606e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.54675\n",
      "GaussianMLPValueFunction/LossBefore      -6.65269\n",
      "GaussianMLPValueFunction/dLoss           -0.105944\n",
      "TotalEnvSteps                        983016\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 1.1978e-05,  5.4866e-05,  1.5307e-08,  ...,  1.0217e-03,\n",
      "        -4.1518e-04,  1.1614e-03])\n",
      "G is: \n",
      "tensor([[1.5988e-05, 1.0649e+01],\n",
      "        [1.0649e+01, 7.0929e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [7092917.,       0.]])\n",
      "loss before is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0002, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:23 | [trpo_pendulum] epoch #492 | Saving snapshot...\n",
      "2022-08-23 10:45:23 | [trpo_pendulum] epoch #492 | Saved\n",
      "2022-08-23 10:45:23 | [trpo_pendulum] epoch #492 | Time 485.05 s\n",
      "2022-08-23 10:45:23 | [trpo_pendulum] epoch #492 | EpochTime 0.97 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000178523\n",
      "Evaluation/AverageReturn                 -0.00177861\n",
      "Evaluation/Iteration                    492\n",
      "Evaluation/MaxReturn                     -0.00176401\n",
      "Evaluation/MinReturn                     -0.00179322\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.46046e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.05784\n",
      "GaussianMLPPolicy/KL                      9.74288e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000170153\n",
      "GaussianMLPPolicy/LossBefore             -0.000170016\n",
      "GaussianMLPPolicy/dLoss                   1.37225e-07\n",
      "GaussianMLPValueFunction/LossAfter       -6.84761\n",
      "GaussianMLPValueFunction/LossBefore      -6.19797\n",
      "GaussianMLPValueFunction/dLoss            0.649638\n",
      "TotalEnvSteps                        985014\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.8975e-06,  8.5293e-06, -1.0964e-07,  ...,  1.3932e-04,\n",
      "        -5.7237e-05,  1.5813e-04])\n",
      "G is: \n",
      "tensor([[2.9729e-07, 2.0139e-01],\n",
      "        [2.0139e-01, 1.3645e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [136446.9688,      0.0000]])\n",
      "loss before is:\n",
      "tensor(5.2872e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(5.2871e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:24 | [trpo_pendulum] epoch #493 | Saving snapshot...\n",
      "2022-08-23 10:45:24 | [trpo_pendulum] epoch #493 | Saved\n",
      "2022-08-23 10:45:24 | [trpo_pendulum] epoch #493 | Time 486.00 s\n",
      "2022-08-23 10:45:24 | [trpo_pendulum] epoch #493 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000208796\n",
      "Evaluation/AverageReturn                 -0.00194723\n",
      "Evaluation/Iteration                    493\n",
      "Evaluation/MaxReturn                     -0.00184996\n",
      "Evaluation/MinReturn                     -0.0020445\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      9.72692e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.05784\n",
      "GaussianMLPPolicy/KL                      4.46498e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               5.28711e-05\n",
      "GaussianMLPPolicy/LossBefore              5.28716e-05\n",
      "GaussianMLPPolicy/dLoss                   5.89353e-10\n",
      "GaussianMLPValueFunction/LossAfter       -6.80277\n",
      "GaussianMLPValueFunction/LossBefore      -6.81192\n",
      "GaussianMLPValueFunction/dLoss           -0.00915051\n",
      "TotalEnvSteps                        987012\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.5266e-06, -2.6236e-05, -8.3941e-08,  ..., -4.2549e-04,\n",
      "         1.7423e-04, -4.8277e-04])\n",
      "G is: \n",
      "tensor([[2.7710e-06, 1.8771e+00],\n",
      "        [1.8771e+00, 1.2717e+06]])\n",
      "eig is:\n",
      "tensor([[      0.0000,       0.0000],\n",
      "        [1271711.2500,       0.0000]])\n",
      "loss before is:\n",
      "tensor(8.7313e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(8.7301e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:25 | [trpo_pendulum] epoch #494 | Saving snapshot...\n",
      "2022-08-23 10:45:25 | [trpo_pendulum] epoch #494 | Saved\n",
      "2022-08-23 10:45:25 | [trpo_pendulum] epoch #494 | Time 486.97 s\n",
      "2022-08-23 10:45:25 | [trpo_pendulum] epoch #494 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000197897\n",
      "Evaluation/AverageReturn                 -0.00217267\n",
      "Evaluation/Iteration                    494\n",
      "Evaluation/MaxReturn                     -0.00214352\n",
      "Evaluation/MinReturn                     -0.00220181\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.91424e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.05801\n",
      "GaussianMLPPolicy/KL                      8.37535e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               8.73012e-05\n",
      "GaussianMLPPolicy/LossBefore              8.7313e-05\n",
      "GaussianMLPPolicy/dLoss                   1.17288e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.87321\n",
      "GaussianMLPValueFunction/LossBefore      -6.69183\n",
      "GaussianMLPValueFunction/dLoss            0.181377\n",
      "TotalEnvSteps                        989010\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 9.7641e-07, -5.7731e-07, -9.5989e-08,  ..., -2.2963e-06,\n",
      "         1.0209e-06, -2.4371e-06])\n",
      "G is: \n",
      "tensor([[8.4527e-11, 5.3233e-05],\n",
      "        [5.3233e-05, 3.6077e+01]])\n",
      "eig is:\n",
      "tensor([[ 0.0000,  0.0000],\n",
      "        [36.0771,  0.0000]])\n",
      "2022-08-23 10:45:26 | [trpo_pendulum] epoch #495 | Line search condition violated. Rejecting the step!\n",
      "2022-08-23 10:45:26 | [trpo_pendulum] epoch #495 | Violated because loss not improving\n",
      "2022-08-23 10:45:26 | [trpo_pendulum] epoch #495 | Saving snapshot...\n",
      "2022-08-23 10:45:26 | [trpo_pendulum] epoch #495 | Saved\n",
      "2022-08-23 10:45:26 | [trpo_pendulum] epoch #495 | Time 488.01 s\n",
      "2022-08-23 10:45:26 | [trpo_pendulum] epoch #495 | EpochTime 1.04 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000196577\n",
      "Evaluation/AverageReturn                 -0.00216771\n",
      "Evaluation/Iteration                    495\n",
      "Evaluation/MaxReturn                     -0.00216555\n",
      "Evaluation/MinReturn                     -0.00216987\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.15866e-06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.05801\n",
      "GaussianMLPPolicy/KL                      0\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -1.17848e-05\n",
      "GaussianMLPPolicy/LossBefore             -1.17848e-05\n",
      "GaussianMLPPolicy/dLoss                   0\n",
      "GaussianMLPValueFunction/LossAfter       -6.62474\n",
      "GaussianMLPValueFunction/LossBefore      -6.87497\n",
      "GaussianMLPValueFunction/dLoss           -0.250224\n",
      "TotalEnvSteps                        991008\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 8.4124e-06,  3.1638e-05,  2.1642e-07,  ...,  5.7886e-04,\n",
      "        -2.3512e-04,  6.5779e-04])\n",
      "G is: \n",
      "tensor([[5.1309e-06, 3.4776e+00],\n",
      "        [3.4776e+00, 2.3570e+06]])\n",
      "eig is:\n",
      "tensor([[      0.,       0.],\n",
      "        [2357035.,       0.]])\n",
      "loss before is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-0.0001, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:27 | [trpo_pendulum] epoch #496 | Saving snapshot...\n",
      "2022-08-23 10:45:27 | [trpo_pendulum] epoch #496 | Saved\n",
      "2022-08-23 10:45:27 | [trpo_pendulum] epoch #496 | Time 488.99 s\n",
      "2022-08-23 10:45:27 | [trpo_pendulum] epoch #496 | EpochTime 0.98 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000186201\n",
      "Evaluation/AverageReturn                 -0.00176563\n",
      "Evaluation/Iteration                    496\n",
      "Evaluation/MaxReturn                     -0.0016629\n",
      "Evaluation/MinReturn                     -0.00186837\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000102735\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.05801\n",
      "GaussianMLPPolicy/KL                      7.62984e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000141665\n",
      "GaussianMLPPolicy/LossBefore             -0.000141655\n",
      "GaussianMLPPolicy/dLoss                   1.07539e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.79722\n",
      "GaussianMLPValueFunction/LossBefore      -6.40841\n",
      "GaussianMLPValueFunction/dLoss            0.388807\n",
      "TotalEnvSteps                        993006\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 3.5944e-06,  2.0950e-05, -1.4868e-07,  ...,  3.6733e-04,\n",
      "        -1.4996e-04,  4.1732e-04])\n",
      "G is: \n",
      "tensor([[2.0664e-06, 1.4004e+00],\n",
      "        [1.4004e+00, 9.4910e+05]])\n",
      "eig is:\n",
      "tensor([[     0.0000,      0.0000],\n",
      "        [949097.8750,      0.0000]])\n",
      "loss before is:\n",
      "tensor(-4.6189e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-4.6194e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:28 | [trpo_pendulum] epoch #497 | Saving snapshot...\n",
      "2022-08-23 10:45:28 | [trpo_pendulum] epoch #497 | Saved\n",
      "2022-08-23 10:45:28 | [trpo_pendulum] epoch #497 | Time 489.95 s\n",
      "2022-08-23 10:45:28 | [trpo_pendulum] epoch #497 | EpochTime 0.95 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000217653\n",
      "Evaluation/AverageReturn                 -0.00197782\n",
      "Evaluation/Iteration                    497\n",
      "Evaluation/MaxReturn                     -0.00195994\n",
      "Evaluation/MinReturn                     -0.0019957\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.78822e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.05801\n",
      "GaussianMLPPolicy/KL                      3.03587e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.61937e-05\n",
      "GaussianMLPPolicy/LossBefore             -4.61894e-05\n",
      "GaussianMLPPolicy/dLoss                   4.29645e-09\n",
      "GaussianMLPValueFunction/LossAfter       -6.62441\n",
      "GaussianMLPValueFunction/LossBefore      -6.83482\n",
      "GaussianMLPValueFunction/dLoss           -0.210408\n",
      "TotalEnvSteps                        995004\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 6.3466e-06,  7.7962e-06, -1.7015e-07,  ...,  2.6228e-05,\n",
      "        -1.3852e-05,  2.8092e-05])\n",
      "G is: \n",
      "tensor([[1.1337e-08, 7.0499e-03],\n",
      "        [7.0499e-03, 4.7777e+03]])\n",
      "eig is:\n",
      "tensor([[   0.0000,    0.0000],\n",
      "        [4777.6582,    0.0000]])\n",
      "loss before is:\n",
      "tensor(-7.8890e-05, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-7.8909e-05, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:29 | [trpo_pendulum] epoch #498 | Saving snapshot...\n",
      "2022-08-23 10:45:29 | [trpo_pendulum] epoch #498 | Saved\n",
      "2022-08-23 10:45:29 | [trpo_pendulum] epoch #498 | Time 490.91 s\n",
      "2022-08-23 10:45:29 | [trpo_pendulum] epoch #498 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000207769\n",
      "Evaluation/AverageReturn                 -0.0021274\n",
      "Evaluation/Iteration                    498\n",
      "Evaluation/MaxReturn                     -0.00211509\n",
      "Evaluation/MinReturn                     -0.00213972\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.23155e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.05814\n",
      "GaussianMLPPolicy/KL                      1.37096e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.89089e-05\n",
      "GaussianMLPPolicy/LossBefore             -7.88896e-05\n",
      "GaussianMLPPolicy/dLoss                   1.93395e-08\n",
      "GaussianMLPValueFunction/LossAfter       -6.85963\n",
      "GaussianMLPValueFunction/LossBefore      -6.73191\n",
      "GaussianMLPValueFunction/dLoss            0.127725\n",
      "TotalEnvSteps                        997002\n",
      "-----------------------------------  ----------------\n",
      "flat loss grads is: \n",
      "tensor([ 2.9406e-06, -3.9717e-06, -6.5184e-08,  ..., -6.7294e-05,\n",
      "         2.7421e-05, -7.6365e-05])\n",
      "G is: \n",
      "tensor([[6.9315e-08, 4.6986e-02],\n",
      "        [4.6986e-02, 3.1855e+04]])\n",
      "eig is:\n",
      "tensor([[-1.9531e-03,  0.0000e+00],\n",
      "        [ 3.1855e+04,  0.0000e+00]])\n",
      "indefinite\n",
      "loss before is:\n",
      "tensor(-6.7756e-06, grad_fn=<NegBackward>)\n",
      "loss now is:\n",
      "tensor(-6.7758e-06, grad_fn=<NegBackward>)\n",
      "----------------------------\n",
      "2022-08-23 10:45:30 | [trpo_pendulum] epoch #499 | Saving snapshot...\n",
      "2022-08-23 10:45:30 | [trpo_pendulum] epoch #499 | Saved\n",
      "2022-08-23 10:45:30 | [trpo_pendulum] epoch #499 | Time 491.87 s\n",
      "2022-08-23 10:45:30 | [trpo_pendulum] epoch #499 | EpochTime 0.96 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.000205134\n",
      "Evaluation/AverageReturn                 -0.0018948\n",
      "Evaluation/Iteration                    499\n",
      "Evaluation/MaxReturn                     -0.00183976\n",
      "Evaluation/MinReturn                     -0.00194984\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.50412e-05\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -4.05814\n",
      "GaussianMLPPolicy/KL                      1.0301e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.77576e-06\n",
      "GaussianMLPPolicy/LossBefore             -6.7756e-06\n",
      "GaussianMLPPolicy/dLoss                   1.52795e-10\n",
      "GaussianMLPValueFunction/LossAfter       -6.82513\n",
      "GaussianMLPValueFunction/LossBefore      -6.88668\n",
      "GaussianMLPValueFunction/dLoss           -0.0615501\n",
      "TotalEnvSteps                        999000\n",
      "-----------------------------------  ----------------\n"
     ]
    }
   ],
   "source": [
    "trpo_pendulum(seed=1234)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
