{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from garage import wrap_experiment\n",
    "from garage.envs import GymEnv\n",
    "from garage.experiment.deterministic import set_seed\n",
    "from garage.sampler import LocalSampler\n",
    "from garage.torch.algos import TRPO\n",
    "from garage.torch.algos import VPG\n",
    "from garage.torch.policies import GaussianMLPPolicy\n",
    "from garage.torch.value_functions import GaussianMLPValueFunction\n",
    "from garage.trainer import Trainer\n",
    "\n",
    "@wrap_experiment\n",
    "def trpo_pendulum(ctxt=None, seed=1):\n",
    "    \"\"\"Train TRPO with InvertedDoublePendulum-v2 environment.\n",
    "    Args:\n",
    "        ctxt (garage.experiment.ExperimentContext): The experiment\n",
    "            configuration used by Trainer to create the snapshotter.\n",
    "        seed (int): Used to seed the random number generator to produce\n",
    "            determinism.\n",
    "    \"\"\"\n",
    "    set_seed(seed)\n",
    "    env = GymEnv('Pendulum-v0')\n",
    "\n",
    "    trainer = Trainer(ctxt)\n",
    "\n",
    "    policy = GaussianMLPPolicy(env.spec,\n",
    "                               hidden_sizes=[32, 32],\n",
    "                               hidden_nonlinearity=torch.tanh,\n",
    "                               output_nonlinearity=None)\n",
    "\n",
    "    value_function = GaussianMLPValueFunction(env_spec=env.spec,\n",
    "                                              hidden_sizes=(32, 32),\n",
    "                                              hidden_nonlinearity=torch.tanh,\n",
    "                                              output_nonlinearity=None)\n",
    "\n",
    "    sampler = LocalSampler(agents=policy,\n",
    "                           envs=env,\n",
    "                           max_episode_length=env.spec.max_episode_length)\n",
    "\n",
    "    algo = TRPO(env_spec=env.spec,\n",
    "                policy=policy,\n",
    "                value_function=value_function,\n",
    "                sampler=sampler,\n",
    "                discount=0.99,\n",
    "                center_adv=False)\n",
    "\n",
    "    trainer.setup(algo, env)\n",
    "    trainer.train(n_epochs=1000, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-17 18:04:44 | [trpo_pendulum] Logging to d:\\Github\\DRSOM-for-RL\\data/local/experiment/trpo_pendulum_2\n",
      "2022-08-17 18:04:44 | [trpo_pendulum] Obtaining samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\lib\\site-packages\\garage\\experiment\\deterministic.py:36: UserWarning: Enabeling deterministic mode in PyTorch can have a performance impact when using GPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-17 18:04:44 | [trpo_pendulum] epoch #0 | Saving snapshot...\n",
      "2022-08-17 18:04:44 | [trpo_pendulum] epoch #0 | Saved\n",
      "2022-08-17 18:04:44 | [trpo_pendulum] epoch #0 | Time 0.66 s\n",
      "2022-08-17 18:04:44 | [trpo_pendulum] epoch #0 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -781.443\n",
      "Evaluation/AverageReturn              -1820.62\n",
      "Evaluation/Iteration                      0\n",
      "Evaluation/MaxReturn                  -1796.07\n",
      "Evaluation/MinReturn                  -1831.93\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     11.4397\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.41622\n",
      "GaussianMLPPolicy/KL                      0.00508066\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             255.405\n",
      "GaussianMLPPolicy/LossBefore            257.089\n",
      "GaussianMLPPolicy/dLoss                   1.6841\n",
      "GaussianMLPValueFunction/LossAfter   145473\n",
      "GaussianMLPValueFunction/LossBefore  161289\n",
      "GaussianMLPValueFunction/dLoss        15815.8\n",
      "TotalEnvSteps                          1200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:04:45 | [trpo_pendulum] epoch #1 | Saving snapshot...\n",
      "2022-08-17 18:04:45 | [trpo_pendulum] epoch #1 | Saved\n",
      "2022-08-17 18:04:45 | [trpo_pendulum] epoch #1 | Time 1.45 s\n",
      "2022-08-17 18:04:45 | [trpo_pendulum] epoch #1 | EpochTime 0.78 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -532.452\n",
      "Evaluation/AverageReturn             -1319.82\n",
      "Evaluation/Iteration                     1\n",
      "Evaluation/MaxReturn                 -1293.65\n",
      "Evaluation/MinReturn                 -1333.23\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    14.7533\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.41287\n",
      "GaussianMLPPolicy/KL                     0.00916445\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            191.179\n",
      "GaussianMLPPolicy/LossBefore           192.44\n",
      "GaussianMLPPolicy/dLoss                  1.26132\n",
      "GaussianMLPValueFunction/LossAfter   76739.8\n",
      "GaussianMLPValueFunction/LossBefore  83157.6\n",
      "GaussianMLPValueFunction/dLoss        6417.84\n",
      "TotalEnvSteps                         2400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:04:46 | [trpo_pendulum] epoch #2 | Saving snapshot...\n",
      "2022-08-17 18:04:46 | [trpo_pendulum] epoch #2 | Saved\n",
      "2022-08-17 18:04:46 | [trpo_pendulum] epoch #2 | Time 2.16 s\n",
      "2022-08-17 18:04:46 | [trpo_pendulum] epoch #2 | EpochTime 0.71 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -542.336\n",
      "Evaluation/AverageReturn             -1224.1\n",
      "Evaluation/Iteration                     2\n",
      "Evaluation/MaxReturn                 -1095.93\n",
      "Evaluation/MinReturn                 -1371.01\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    80.6247\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.40929\n",
      "GaussianMLPPolicy/KL                     0.00725884\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            166.202\n",
      "GaussianMLPPolicy/LossBefore           169.018\n",
      "GaussianMLPPolicy/dLoss                  2.81534\n",
      "GaussianMLPValueFunction/LossAfter   55877.4\n",
      "GaussianMLPValueFunction/LossBefore  59541.9\n",
      "GaussianMLPValueFunction/dLoss        3664.51\n",
      "TotalEnvSteps                         3600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:04:47 | [trpo_pendulum] epoch #3 | Saving snapshot...\n",
      "2022-08-17 18:04:47 | [trpo_pendulum] epoch #3 | Saved\n",
      "2022-08-17 18:04:47 | [trpo_pendulum] epoch #3 | Time 2.83 s\n",
      "2022-08-17 18:04:47 | [trpo_pendulum] epoch #3 | EpochTime 0.66 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn    -561.206\n",
      "Evaluation/AverageReturn             -1249.46\n",
      "Evaluation/Iteration                     3\n",
      "Evaluation/MaxReturn                 -1162.38\n",
      "Evaluation/MinReturn                 -1428.41\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    84.8067\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.43097\n",
      "GaussianMLPPolicy/KL                     0.0093822\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            166.754\n",
      "GaussianMLPPolicy/LossBefore           169.97\n",
      "GaussianMLPPolicy/dLoss                  3.21602\n",
      "GaussianMLPValueFunction/LossAfter   53345.4\n",
      "GaussianMLPValueFunction/LossBefore  57452.1\n",
      "GaussianMLPValueFunction/dLoss        4106.71\n",
      "TotalEnvSteps                         4800\n",
      "-----------------------------------  -------------\n",
      "2022-08-17 18:04:47 | [trpo_pendulum] epoch #4 | Saving snapshot...\n",
      "2022-08-17 18:04:47 | [trpo_pendulum] epoch #4 | Saved\n",
      "2022-08-17 18:04:47 | [trpo_pendulum] epoch #4 | Time 3.48 s\n",
      "2022-08-17 18:04:47 | [trpo_pendulum] epoch #4 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -526.13\n",
      "Evaluation/AverageReturn             -1283.49\n",
      "Evaluation/Iteration                     4\n",
      "Evaluation/MaxReturn                 -1213.03\n",
      "Evaluation/MinReturn                 -1328.04\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    42.7216\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.44805\n",
      "GaussianMLPPolicy/KL                     0.00913798\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            179.277\n",
      "GaussianMLPPolicy/LossBefore           181.986\n",
      "GaussianMLPPolicy/dLoss                  2.70923\n",
      "GaussianMLPValueFunction/LossAfter   58251.1\n",
      "GaussianMLPValueFunction/LossBefore  63407.3\n",
      "GaussianMLPValueFunction/dLoss        5156.2\n",
      "TotalEnvSteps                         6000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:04:48 | [trpo_pendulum] epoch #5 | Saving snapshot...\n",
      "2022-08-17 18:04:48 | [trpo_pendulum] epoch #5 | Saved\n",
      "2022-08-17 18:04:48 | [trpo_pendulum] epoch #5 | Time 4.11 s\n",
      "2022-08-17 18:04:48 | [trpo_pendulum] epoch #5 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -481.6\n",
      "Evaluation/AverageReturn             -1180.66\n",
      "Evaluation/Iteration                     5\n",
      "Evaluation/MaxReturn                 -1052.62\n",
      "Evaluation/MinReturn                 -1257.43\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    78.3684\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.41102\n",
      "GaussianMLPPolicy/KL                     0.00720053\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            166.498\n",
      "GaussianMLPPolicy/LossBefore           168.005\n",
      "GaussianMLPPolicy/dLoss                  1.50748\n",
      "GaussianMLPValueFunction/LossAfter   46348.8\n",
      "GaussianMLPValueFunction/LossBefore  50635.2\n",
      "GaussianMLPValueFunction/dLoss        4286.43\n",
      "TotalEnvSteps                         7200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:04:48 | [trpo_pendulum] epoch #6 | Saving snapshot...\n",
      "2022-08-17 18:04:48 | [trpo_pendulum] epoch #6 | Saved\n",
      "2022-08-17 18:04:48 | [trpo_pendulum] epoch #6 | Time 4.74 s\n",
      "2022-08-17 18:04:48 | [trpo_pendulum] epoch #6 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -735.861\n",
      "Evaluation/AverageReturn             -1713.64\n",
      "Evaluation/Iteration                     6\n",
      "Evaluation/MaxReturn                 -1391.33\n",
      "Evaluation/MinReturn                 -1851.08\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                   154.393\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.42396\n",
      "GaussianMLPPolicy/KL                     0.00702261\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            233.276\n",
      "GaussianMLPPolicy/LossBefore           235.395\n",
      "GaussianMLPPolicy/dLoss                  2.11879\n",
      "GaussianMLPValueFunction/LossAfter   82565.3\n",
      "GaussianMLPValueFunction/LossBefore  92798.3\n",
      "GaussianMLPValueFunction/dLoss       10233\n",
      "TotalEnvSteps                         8400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:04:49 | [trpo_pendulum] epoch #7 | Saving snapshot...\n",
      "2022-08-17 18:04:49 | [trpo_pendulum] epoch #7 | Saved\n",
      "2022-08-17 18:04:49 | [trpo_pendulum] epoch #7 | Time 5.37 s\n",
      "2022-08-17 18:04:49 | [trpo_pendulum] epoch #7 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -448.465\n",
      "Evaluation/AverageReturn             -1133.73\n",
      "Evaluation/Iteration                     7\n",
      "Evaluation/MaxReturn                 -1005.34\n",
      "Evaluation/MinReturn                 -1204.99\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    67.4442\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.4064\n",
      "GaussianMLPPolicy/KL                     0.00801691\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            157.089\n",
      "GaussianMLPPolicy/LossBefore           159.188\n",
      "GaussianMLPPolicy/dLoss                  2.09914\n",
      "GaussianMLPValueFunction/LossAfter   36486.3\n",
      "GaussianMLPValueFunction/LossBefore  38944.3\n",
      "GaussianMLPValueFunction/dLoss        2458.08\n",
      "TotalEnvSteps                         9600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:04:50 | [trpo_pendulum] epoch #8 | Saving snapshot...\n",
      "2022-08-17 18:04:50 | [trpo_pendulum] epoch #8 | Saved\n",
      "2022-08-17 18:04:50 | [trpo_pendulum] epoch #8 | Time 6.04 s\n",
      "2022-08-17 18:04:50 | [trpo_pendulum] epoch #8 | EpochTime 0.67 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -677.424\n",
      "Evaluation/AverageReturn             -1576.27\n",
      "Evaluation/Iteration                     8\n",
      "Evaluation/MaxReturn                 -1198.93\n",
      "Evaluation/MinReturn                 -1722.37\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                   181.82\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.38821\n",
      "GaussianMLPPolicy/KL                     0.00671731\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            211.668\n",
      "GaussianMLPPolicy/LossBefore           213.956\n",
      "GaussianMLPPolicy/dLoss                  2.28836\n",
      "GaussianMLPValueFunction/LossAfter   60507.7\n",
      "GaussianMLPValueFunction/LossBefore  66303.6\n",
      "GaussianMLPValueFunction/dLoss        5795.84\n",
      "TotalEnvSteps                        10800\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:04:50 | [trpo_pendulum] epoch #9 | Saving snapshot...\n",
      "2022-08-17 18:04:50 | [trpo_pendulum] epoch #9 | Saved\n",
      "2022-08-17 18:04:50 | [trpo_pendulum] epoch #9 | Time 6.67 s\n",
      "2022-08-17 18:04:50 | [trpo_pendulum] epoch #9 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -457.391\n",
      "Evaluation/AverageReturn             -1165.8\n",
      "Evaluation/Iteration                     9\n",
      "Evaluation/MaxReturn                 -1078.72\n",
      "Evaluation/MinReturn                 -1210.65\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    49.8502\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.376\n",
      "GaussianMLPPolicy/KL                     0.00431574\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            164.037\n",
      "GaussianMLPPolicy/LossBefore           164.795\n",
      "GaussianMLPPolicy/dLoss                  0.757385\n",
      "GaussianMLPValueFunction/LossAfter   34002.8\n",
      "GaussianMLPValueFunction/LossBefore  36162.9\n",
      "GaussianMLPValueFunction/dLoss        2160.09\n",
      "TotalEnvSteps                        12000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:04:51 | [trpo_pendulum] epoch #10 | Saving snapshot...\n",
      "2022-08-17 18:04:51 | [trpo_pendulum] epoch #10 | Saved\n",
      "2022-08-17 18:04:51 | [trpo_pendulum] epoch #10 | Time 7.33 s\n",
      "2022-08-17 18:04:51 | [trpo_pendulum] epoch #10 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -548.641\n",
      "Evaluation/AverageReturn             -1309.99\n",
      "Evaluation/Iteration                    10\n",
      "Evaluation/MaxReturn                 -1220.24\n",
      "Evaluation/MinReturn                 -1342.36\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    41.0997\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.37665\n",
      "GaussianMLPPolicy/KL                     0.00600999\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            177.319\n",
      "GaussianMLPPolicy/LossBefore           178.022\n",
      "GaussianMLPPolicy/dLoss                  0.702332\n",
      "GaussianMLPValueFunction/LossAfter   36888.9\n",
      "GaussianMLPValueFunction/LossBefore  39378.1\n",
      "GaussianMLPValueFunction/dLoss        2489.21\n",
      "TotalEnvSteps                        13200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:04:52 | [trpo_pendulum] epoch #11 | Saving snapshot...\n",
      "2022-08-17 18:04:52 | [trpo_pendulum] epoch #11 | Saved\n",
      "2022-08-17 18:04:52 | [trpo_pendulum] epoch #11 | Time 7.96 s\n",
      "2022-08-17 18:04:52 | [trpo_pendulum] epoch #11 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -499.512\n",
      "Evaluation/AverageReturn             -1226.08\n",
      "Evaluation/Iteration                    11\n",
      "Evaluation/MaxReturn                 -1146.31\n",
      "Evaluation/MinReturn                 -1274.16\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    53.067\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.3788\n",
      "GaussianMLPPolicy/KL                     0.00626133\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            165.204\n",
      "GaussianMLPPolicy/LossBefore           167.575\n",
      "GaussianMLPPolicy/dLoss                  2.37154\n",
      "GaussianMLPValueFunction/LossAfter   30802.6\n",
      "GaussianMLPValueFunction/LossBefore  33343.1\n",
      "GaussianMLPValueFunction/dLoss        2540.43\n",
      "TotalEnvSteps                        14400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:04:52 | [trpo_pendulum] epoch #12 | Saving snapshot...\n",
      "2022-08-17 18:04:52 | [trpo_pendulum] epoch #12 | Saved\n",
      "2022-08-17 18:04:52 | [trpo_pendulum] epoch #12 | Time 8.57 s\n",
      "2022-08-17 18:04:52 | [trpo_pendulum] epoch #12 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -565.061\n",
      "Evaluation/AverageReturn             -1244.87\n",
      "Evaluation/Iteration                    12\n",
      "Evaluation/MaxReturn                 -1125.81\n",
      "Evaluation/MinReturn                 -1367.49\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    91.7845\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.4086\n",
      "GaussianMLPPolicy/KL                     0.00976514\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            156.952\n",
      "GaussianMLPPolicy/LossBefore           160.224\n",
      "GaussianMLPPolicy/dLoss                  3.27231\n",
      "GaussianMLPValueFunction/LossAfter   27195.8\n",
      "GaussianMLPValueFunction/LossBefore  28768.6\n",
      "GaussianMLPValueFunction/dLoss        1572.79\n",
      "TotalEnvSteps                        15600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:04:53 | [trpo_pendulum] epoch #13 | Saving snapshot...\n",
      "2022-08-17 18:04:53 | [trpo_pendulum] epoch #13 | Saved\n",
      "2022-08-17 18:04:53 | [trpo_pendulum] epoch #13 | Time 9.20 s\n",
      "2022-08-17 18:04:53 | [trpo_pendulum] epoch #13 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -721.17\n",
      "Evaluation/AverageReturn             -1659.11\n",
      "Evaluation/Iteration                    13\n",
      "Evaluation/MaxReturn                 -1581.58\n",
      "Evaluation/MinReturn                 -1704.02\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    47.7599\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.42562\n",
      "GaussianMLPPolicy/KL                     0.00757263\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            218.879\n",
      "GaussianMLPPolicy/LossBefore           221.474\n",
      "GaussianMLPPolicy/dLoss                  2.59563\n",
      "GaussianMLPValueFunction/LossAfter   46967.9\n",
      "GaussianMLPValueFunction/LossBefore  51679.5\n",
      "GaussianMLPValueFunction/dLoss        4711.66\n",
      "TotalEnvSteps                        16800\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:04:54 | [trpo_pendulum] epoch #14 | Saving snapshot...\n",
      "2022-08-17 18:04:54 | [trpo_pendulum] epoch #14 | Saved\n",
      "2022-08-17 18:04:54 | [trpo_pendulum] epoch #14 | Time 9.82 s\n",
      "2022-08-17 18:04:54 | [trpo_pendulum] epoch #14 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -671.706\n",
      "Evaluation/AverageReturn             -1507.86\n",
      "Evaluation/Iteration                    14\n",
      "Evaluation/MaxReturn                 -1349.66\n",
      "Evaluation/MinReturn                 -1709.33\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                   144.27\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.38411\n",
      "GaussianMLPPolicy/KL                     0.00686711\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            194.485\n",
      "GaussianMLPPolicy/LossBefore           196.813\n",
      "GaussianMLPPolicy/dLoss                  2.32852\n",
      "GaussianMLPValueFunction/LossAfter   34982.4\n",
      "GaussianMLPValueFunction/LossBefore  37737.1\n",
      "GaussianMLPValueFunction/dLoss        2754.68\n",
      "TotalEnvSteps                        18000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:04:54 | [trpo_pendulum] epoch #15 | Saving snapshot...\n",
      "2022-08-17 18:04:54 | [trpo_pendulum] epoch #15 | Saved\n",
      "2022-08-17 18:04:54 | [trpo_pendulum] epoch #15 | Time 10.44 s\n",
      "2022-08-17 18:04:54 | [trpo_pendulum] epoch #15 | EpochTime 0.61 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn    -537.621\n",
      "Evaluation/AverageReturn             -1287.03\n",
      "Evaluation/Iteration                    15\n",
      "Evaluation/MaxReturn                 -1265.39\n",
      "Evaluation/MinReturn                 -1338.29\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    27.8083\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.35119\n",
      "GaussianMLPPolicy/KL                     0.0077006\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            168.408\n",
      "GaussianMLPPolicy/LossBefore           170.035\n",
      "GaussianMLPPolicy/dLoss                  1.62628\n",
      "GaussianMLPValueFunction/LossAfter   24902.9\n",
      "GaussianMLPValueFunction/LossBefore  26417.8\n",
      "GaussianMLPValueFunction/dLoss        1514.87\n",
      "TotalEnvSteps                        19200\n",
      "-----------------------------------  -------------\n",
      "2022-08-17 18:04:55 | [trpo_pendulum] epoch #16 | Saving snapshot...\n",
      "2022-08-17 18:04:55 | [trpo_pendulum] epoch #16 | Saved\n",
      "2022-08-17 18:04:55 | [trpo_pendulum] epoch #16 | Time 11.08 s\n",
      "2022-08-17 18:04:55 | [trpo_pendulum] epoch #16 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -639.499\n",
      "Evaluation/AverageReturn             -1447.15\n",
      "Evaluation/Iteration                    16\n",
      "Evaluation/MaxReturn                 -1288.58\n",
      "Evaluation/MinReturn                 -1613.4\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                   117.946\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.35843\n",
      "GaussianMLPPolicy/KL                     0.00755162\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            185.128\n",
      "GaussianMLPPolicy/LossBefore           188.041\n",
      "GaussianMLPPolicy/dLoss                  2.91229\n",
      "GaussianMLPValueFunction/LossAfter   28379.6\n",
      "GaussianMLPValueFunction/LossBefore  30383.3\n",
      "GaussianMLPValueFunction/dLoss        2003.62\n",
      "TotalEnvSteps                        20400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:04:55 | [trpo_pendulum] epoch #17 | Saving snapshot...\n",
      "2022-08-17 18:04:55 | [trpo_pendulum] epoch #17 | Saved\n",
      "2022-08-17 18:04:55 | [trpo_pendulum] epoch #17 | Time 11.71 s\n",
      "2022-08-17 18:04:55 | [trpo_pendulum] epoch #17 | EpochTime 0.63 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn    -575.304\n",
      "Evaluation/AverageReturn             -1342.98\n",
      "Evaluation/Iteration                    17\n",
      "Evaluation/MaxReturn                 -1310.57\n",
      "Evaluation/MinReturn                 -1373.61\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    18.6035\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.33391\n",
      "GaussianMLPPolicy/KL                     0.0068331\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            175.456\n",
      "GaussianMLPPolicy/LossBefore           176.829\n",
      "GaussianMLPPolicy/dLoss                  1.37369\n",
      "GaussianMLPValueFunction/LossAfter   23713.2\n",
      "GaussianMLPValueFunction/LossBefore  25229.2\n",
      "GaussianMLPValueFunction/dLoss        1515.97\n",
      "TotalEnvSteps                        21600\n",
      "-----------------------------------  -------------\n",
      "2022-08-17 18:04:56 | [trpo_pendulum] epoch #18 | Saving snapshot...\n",
      "2022-08-17 18:04:56 | [trpo_pendulum] epoch #18 | Saved\n",
      "2022-08-17 18:04:56 | [trpo_pendulum] epoch #18 | Time 12.34 s\n",
      "2022-08-17 18:04:56 | [trpo_pendulum] epoch #18 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -722.552\n",
      "Evaluation/AverageReturn             -1666.12\n",
      "Evaluation/Iteration                    18\n",
      "Evaluation/MaxReturn                 -1658.58\n",
      "Evaluation/MinReturn                 -1671.89\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     4.25628\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.33189\n",
      "GaussianMLPPolicy/KL                     0.00745881\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            217.767\n",
      "GaussianMLPPolicy/LossBefore           219.541\n",
      "GaussianMLPPolicy/dLoss                  1.77423\n",
      "GaussianMLPValueFunction/LossAfter   33408.3\n",
      "GaussianMLPValueFunction/LossBefore  36454.9\n",
      "GaussianMLPValueFunction/dLoss        3046.6\n",
      "TotalEnvSteps                        22800\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:04:57 | [trpo_pendulum] epoch #19 | Saving snapshot...\n",
      "2022-08-17 18:04:57 | [trpo_pendulum] epoch #19 | Saved\n",
      "2022-08-17 18:04:57 | [trpo_pendulum] epoch #19 | Time 12.96 s\n",
      "2022-08-17 18:04:57 | [trpo_pendulum] epoch #19 | EpochTime 0.62 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn    -614.065\n",
      "Evaluation/AverageReturn             -1463.78\n",
      "Evaluation/Iteration                    19\n",
      "Evaluation/MaxReturn                 -1392.12\n",
      "Evaluation/MinReturn                 -1484.26\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    32.3789\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.32768\n",
      "GaussianMLPPolicy/KL                     0.0085652\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            193.13\n",
      "GaussianMLPPolicy/LossBefore           195.022\n",
      "GaussianMLPPolicy/dLoss                  1.89209\n",
      "GaussianMLPValueFunction/LossAfter   24709\n",
      "GaussianMLPValueFunction/LossBefore  26486.5\n",
      "GaussianMLPValueFunction/dLoss        1777.53\n",
      "TotalEnvSteps                        24000\n",
      "-----------------------------------  -------------\n",
      "2022-08-17 18:04:57 | [trpo_pendulum] epoch #20 | Saving snapshot...\n",
      "2022-08-17 18:04:57 | [trpo_pendulum] epoch #20 | Saved\n",
      "2022-08-17 18:04:57 | [trpo_pendulum] epoch #20 | Time 13.59 s\n",
      "2022-08-17 18:04:57 | [trpo_pendulum] epoch #20 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -651.616\n",
      "Evaluation/AverageReturn             -1533.8\n",
      "Evaluation/Iteration                    20\n",
      "Evaluation/MaxReturn                 -1303.57\n",
      "Evaluation/MinReturn                 -1667.75\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                   156.554\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.31191\n",
      "GaussianMLPPolicy/KL                     0.00837117\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            197.874\n",
      "GaussianMLPPolicy/LossBefore           201.74\n",
      "GaussianMLPPolicy/dLoss                  3.86555\n",
      "GaussianMLPValueFunction/LossAfter   25172.1\n",
      "GaussianMLPValueFunction/LossBefore  27073.8\n",
      "GaussianMLPValueFunction/dLoss        1901.75\n",
      "TotalEnvSteps                        25200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:04:58 | [trpo_pendulum] epoch #21 | Saving snapshot...\n",
      "2022-08-17 18:04:58 | [trpo_pendulum] epoch #21 | Saved\n",
      "2022-08-17 18:04:58 | [trpo_pendulum] epoch #21 | Time 14.25 s\n",
      "2022-08-17 18:04:58 | [trpo_pendulum] epoch #21 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -581.433\n",
      "Evaluation/AverageReturn             -1405.34\n",
      "Evaluation/Iteration                    21\n",
      "Evaluation/MaxReturn                 -1354.73\n",
      "Evaluation/MinReturn                 -1462.48\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    36.2653\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.30693\n",
      "GaussianMLPPolicy/KL                     0.00986008\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            184.582\n",
      "GaussianMLPPolicy/LossBefore           186.613\n",
      "GaussianMLPPolicy/dLoss                  2.03114\n",
      "GaussianMLPValueFunction/LossAfter   20245\n",
      "GaussianMLPValueFunction/LossBefore  21558.7\n",
      "GaussianMLPValueFunction/dLoss        1313.72\n",
      "TotalEnvSteps                        26400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:04:59 | [trpo_pendulum] epoch #22 | Saving snapshot...\n",
      "2022-08-17 18:04:59 | [trpo_pendulum] epoch #22 | Saved\n",
      "2022-08-17 18:04:59 | [trpo_pendulum] epoch #22 | Time 14.88 s\n",
      "2022-08-17 18:04:59 | [trpo_pendulum] epoch #22 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -565.326\n",
      "Evaluation/AverageReturn             -1369.19\n",
      "Evaluation/Iteration                    22\n",
      "Evaluation/MaxReturn                 -1344.96\n",
      "Evaluation/MinReturn                 -1436.66\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    33.2707\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.3025\n",
      "GaussianMLPPolicy/KL                     0.00816652\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            181.434\n",
      "GaussianMLPPolicy/LossBefore           182.618\n",
      "GaussianMLPPolicy/dLoss                  1.18451\n",
      "GaussianMLPValueFunction/LossAfter   18330\n",
      "GaussianMLPValueFunction/LossBefore  19467.7\n",
      "GaussianMLPValueFunction/dLoss        1137.69\n",
      "TotalEnvSteps                        27600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:04:59 | [trpo_pendulum] epoch #23 | Saving snapshot...\n",
      "2022-08-17 18:04:59 | [trpo_pendulum] epoch #23 | Saved\n",
      "2022-08-17 18:04:59 | [trpo_pendulum] epoch #23 | Time 15.49 s\n",
      "2022-08-17 18:04:59 | [trpo_pendulum] epoch #23 | EpochTime 0.61 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn    -559.053\n",
      "Evaluation/AverageReturn             -1337.66\n",
      "Evaluation/Iteration                    23\n",
      "Evaluation/MaxReturn                 -1317.72\n",
      "Evaluation/MinReturn                 -1356.9\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    14.0517\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.29153\n",
      "GaussianMLPPolicy/KL                     0.0099557\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            174.712\n",
      "GaussianMLPPolicy/LossBefore           175.564\n",
      "GaussianMLPPolicy/dLoss                  0.852112\n",
      "GaussianMLPValueFunction/LossAfter   16044.7\n",
      "GaussianMLPValueFunction/LossBefore  16979.2\n",
      "GaussianMLPValueFunction/dLoss         934.525\n",
      "TotalEnvSteps                        28800\n",
      "-----------------------------------  -------------\n",
      "2022-08-17 18:05:00 | [trpo_pendulum] epoch #24 | Saving snapshot...\n",
      "2022-08-17 18:05:00 | [trpo_pendulum] epoch #24 | Saved\n",
      "2022-08-17 18:05:00 | [trpo_pendulum] epoch #24 | Time 16.12 s\n",
      "2022-08-17 18:05:00 | [trpo_pendulum] epoch #24 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -554.398\n",
      "Evaluation/AverageReturn             -1327.84\n",
      "Evaluation/Iteration                    24\n",
      "Evaluation/MaxReturn                 -1224.27\n",
      "Evaluation/MinReturn                 -1364.11\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    47.6523\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.2994\n",
      "GaussianMLPPolicy/KL                     0.00895109\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            169.434\n",
      "GaussianMLPPolicy/LossBefore           171.395\n",
      "GaussianMLPPolicy/dLoss                  1.96071\n",
      "GaussianMLPValueFunction/LossAfter   14666.8\n",
      "GaussianMLPValueFunction/LossBefore  15507\n",
      "GaussianMLPValueFunction/dLoss         840.248\n",
      "TotalEnvSteps                        30000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:00 | [trpo_pendulum] epoch #25 | Saving snapshot...\n",
      "2022-08-17 18:05:00 | [trpo_pendulum] epoch #25 | Saved\n",
      "2022-08-17 18:05:00 | [trpo_pendulum] epoch #25 | Time 16.74 s\n",
      "2022-08-17 18:05:00 | [trpo_pendulum] epoch #25 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -533.196\n",
      "Evaluation/AverageReturn             -1274.12\n",
      "Evaluation/Iteration                    25\n",
      "Evaluation/MaxReturn                 -1153.2\n",
      "Evaluation/MinReturn                 -1311.08\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    56.323\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.27868\n",
      "GaussianMLPPolicy/KL                     0.00935154\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            159.43\n",
      "GaussianMLPPolicy/LossBefore           163.474\n",
      "GaussianMLPPolicy/dLoss                  4.04419\n",
      "GaussianMLPValueFunction/LossAfter   12738.9\n",
      "GaussianMLPValueFunction/LossBefore  13419.6\n",
      "GaussianMLPValueFunction/dLoss         680.653\n",
      "TotalEnvSteps                        31200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:01 | [trpo_pendulum] epoch #26 | Saving snapshot...\n",
      "2022-08-17 18:05:01 | [trpo_pendulum] epoch #26 | Saved\n",
      "2022-08-17 18:05:01 | [trpo_pendulum] epoch #26 | Time 17.34 s\n",
      "2022-08-17 18:05:01 | [trpo_pendulum] epoch #26 | EpochTime 0.60 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn    -658.8\n",
      "Evaluation/AverageReturn             -1540.47\n",
      "Evaluation/Iteration                    26\n",
      "Evaluation/MaxReturn                 -1524.4\n",
      "Evaluation/MinReturn                 -1559.18\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    10.6226\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.32464\n",
      "GaussianMLPPolicy/KL                     0.0079823\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            196.372\n",
      "GaussianMLPPolicy/LossBefore           200.018\n",
      "GaussianMLPPolicy/dLoss                  3.64636\n",
      "GaussianMLPValueFunction/LossAfter   17547.4\n",
      "GaussianMLPValueFunction/LossBefore  18878.4\n",
      "GaussianMLPValueFunction/dLoss        1331.04\n",
      "TotalEnvSteps                        32400\n",
      "-----------------------------------  -------------\n",
      "2022-08-17 18:05:02 | [trpo_pendulum] epoch #27 | Saving snapshot...\n",
      "2022-08-17 18:05:02 | [trpo_pendulum] epoch #27 | Saved\n",
      "2022-08-17 18:05:02 | [trpo_pendulum] epoch #27 | Time 17.97 s\n",
      "2022-08-17 18:05:02 | [trpo_pendulum] epoch #27 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -684.242\n",
      "Evaluation/AverageReturn             -1572.28\n",
      "Evaluation/Iteration                    27\n",
      "Evaluation/MaxReturn                 -1558.26\n",
      "Evaluation/MinReturn                 -1580.33\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     7.30813\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.33092\n",
      "GaussianMLPPolicy/KL                     0.00879141\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            199.96\n",
      "GaussianMLPPolicy/LossBefore           201.72\n",
      "GaussianMLPPolicy/dLoss                  1.7608\n",
      "GaussianMLPValueFunction/LossAfter   16592.2\n",
      "GaussianMLPValueFunction/LossBefore  17856.7\n",
      "GaussianMLPValueFunction/dLoss        1264.46\n",
      "TotalEnvSteps                        33600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:02 | [trpo_pendulum] epoch #28 | Saving snapshot...\n",
      "2022-08-17 18:05:02 | [trpo_pendulum] epoch #28 | Saved\n",
      "2022-08-17 18:05:02 | [trpo_pendulum] epoch #28 | Time 18.61 s\n",
      "2022-08-17 18:05:02 | [trpo_pendulum] epoch #28 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -675.904\n",
      "Evaluation/AverageReturn             -1567.09\n",
      "Evaluation/Iteration                    28\n",
      "Evaluation/MaxReturn                 -1554.11\n",
      "Evaluation/MinReturn                 -1578.89\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     7.80244\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.3571\n",
      "GaussianMLPPolicy/KL                     0.00867829\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            198.851\n",
      "GaussianMLPPolicy/LossBefore           201.471\n",
      "GaussianMLPPolicy/dLoss                  2.6196\n",
      "GaussianMLPValueFunction/LossAfter   15536.4\n",
      "GaussianMLPValueFunction/LossBefore  16691.3\n",
      "GaussianMLPValueFunction/dLoss        1154.95\n",
      "TotalEnvSteps                        34800\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:03 | [trpo_pendulum] epoch #29 | Saving snapshot...\n",
      "2022-08-17 18:05:03 | [trpo_pendulum] epoch #29 | Saved\n",
      "2022-08-17 18:05:03 | [trpo_pendulum] epoch #29 | Time 19.26 s\n",
      "2022-08-17 18:05:03 | [trpo_pendulum] epoch #29 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -682.027\n",
      "Evaluation/AverageReturn             -1563.9\n",
      "Evaluation/Iteration                    29\n",
      "Evaluation/MaxReturn                 -1557.54\n",
      "Evaluation/MinReturn                 -1575.54\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     6.53228\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.37498\n",
      "GaussianMLPPolicy/KL                     0.00797219\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            198.226\n",
      "GaussianMLPPolicy/LossBefore           198.772\n",
      "GaussianMLPPolicy/dLoss                  0.546051\n",
      "GaussianMLPValueFunction/LossAfter   14149.5\n",
      "GaussianMLPValueFunction/LossBefore  15159\n",
      "GaussianMLPValueFunction/dLoss        1009.53\n",
      "TotalEnvSteps                        36000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:04 | [trpo_pendulum] epoch #30 | Saving snapshot...\n",
      "2022-08-17 18:05:04 | [trpo_pendulum] epoch #30 | Saved\n",
      "2022-08-17 18:05:04 | [trpo_pendulum] epoch #30 | Time 19.89 s\n",
      "2022-08-17 18:05:04 | [trpo_pendulum] epoch #30 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -678.814\n",
      "Evaluation/AverageReturn             -1574.75\n",
      "Evaluation/Iteration                    30\n",
      "Evaluation/MaxReturn                 -1564.79\n",
      "Evaluation/MinReturn                 -1585.21\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     7.34288\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.34524\n",
      "GaussianMLPPolicy/KL                     0.00646464\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            199.492\n",
      "GaussianMLPPolicy/LossBefore           201.838\n",
      "GaussianMLPPolicy/dLoss                  2.34605\n",
      "GaussianMLPValueFunction/LossAfter   13672.9\n",
      "GaussianMLPValueFunction/LossBefore  14661.9\n",
      "GaussianMLPValueFunction/dLoss         988.919\n",
      "TotalEnvSteps                        37200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:04 | [trpo_pendulum] epoch #31 | Saving snapshot...\n",
      "2022-08-17 18:05:04 | [trpo_pendulum] epoch #31 | Saved\n",
      "2022-08-17 18:05:04 | [trpo_pendulum] epoch #31 | Time 20.51 s\n",
      "2022-08-17 18:05:04 | [trpo_pendulum] epoch #31 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -645.295\n",
      "Evaluation/AverageReturn             -1532.36\n",
      "Evaluation/Iteration                    31\n",
      "Evaluation/MaxReturn                 -1516.24\n",
      "Evaluation/MinReturn                 -1542.85\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     8.69484\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.34177\n",
      "GaussianMLPPolicy/KL                     0.00963607\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            194.883\n",
      "GaussianMLPPolicy/LossBefore           198.069\n",
      "GaussianMLPPolicy/dLoss                  3.1857\n",
      "GaussianMLPValueFunction/LossAfter   12450.7\n",
      "GaussianMLPValueFunction/LossBefore  13315.4\n",
      "GaussianMLPValueFunction/dLoss         864.734\n",
      "TotalEnvSteps                        38400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:05 | [trpo_pendulum] epoch #32 | Saving snapshot...\n",
      "2022-08-17 18:05:05 | [trpo_pendulum] epoch #32 | Saved\n",
      "2022-08-17 18:05:05 | [trpo_pendulum] epoch #32 | Time 21.14 s\n",
      "2022-08-17 18:05:05 | [trpo_pendulum] epoch #32 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -497.587\n",
      "Evaluation/AverageReturn             -1348.63\n",
      "Evaluation/Iteration                    32\n",
      "Evaluation/MaxReturn                 -1169.37\n",
      "Evaluation/MinReturn                 -1390.81\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    80.3691\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.34874\n",
      "GaussianMLPPolicy/KL                     0.00769049\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            180.714\n",
      "GaussianMLPPolicy/LossBefore           183.749\n",
      "GaussianMLPPolicy/dLoss                  3.03432\n",
      "GaussianMLPValueFunction/LossAfter   10478.3\n",
      "GaussianMLPValueFunction/LossBefore  11130.8\n",
      "GaussianMLPValueFunction/dLoss         652.534\n",
      "TotalEnvSteps                        39600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:05 | [trpo_pendulum] epoch #33 | Saving snapshot...\n",
      "2022-08-17 18:05:05 | [trpo_pendulum] epoch #33 | Saved\n",
      "2022-08-17 18:05:05 | [trpo_pendulum] epoch #33 | Time 21.75 s\n",
      "2022-08-17 18:05:05 | [trpo_pendulum] epoch #33 | EpochTime 0.60 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -601.387\n",
      "Evaluation/AverageReturn             -1478.35\n",
      "Evaluation/Iteration                    33\n",
      "Evaluation/MaxReturn                 -1471.64\n",
      "Evaluation/MinReturn                 -1494.81\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     8.08195\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.37273\n",
      "GaussianMLPPolicy/KL                     0.00975692\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            189.949\n",
      "GaussianMLPPolicy/LossBefore           193.537\n",
      "GaussianMLPPolicy/dLoss                  3.58847\n",
      "GaussianMLPValueFunction/LossAfter   10665.2\n",
      "GaussianMLPValueFunction/LossBefore  11374\n",
      "GaussianMLPValueFunction/dLoss         708.809\n",
      "TotalEnvSteps                        40800\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:06 | [trpo_pendulum] epoch #34 | Saving snapshot...\n",
      "2022-08-17 18:05:06 | [trpo_pendulum] epoch #34 | Saved\n",
      "2022-08-17 18:05:06 | [trpo_pendulum] epoch #34 | Time 22.37 s\n",
      "2022-08-17 18:05:06 | [trpo_pendulum] epoch #34 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -680.649\n",
      "Evaluation/AverageReturn             -1576.66\n",
      "Evaluation/Iteration                    34\n",
      "Evaluation/MaxReturn                 -1570.14\n",
      "Evaluation/MinReturn                 -1583.36\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     5.26941\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.35604\n",
      "GaussianMLPPolicy/KL                     0.00773859\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            197.375\n",
      "GaussianMLPPolicy/LossBefore           200.152\n",
      "GaussianMLPPolicy/dLoss                  2.77657\n",
      "GaussianMLPValueFunction/LossAfter   10574\n",
      "GaussianMLPValueFunction/LossBefore  11310.7\n",
      "GaussianMLPValueFunction/dLoss         736.71\n",
      "TotalEnvSteps                        42000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:07 | [trpo_pendulum] epoch #35 | Saving snapshot...\n",
      "2022-08-17 18:05:07 | [trpo_pendulum] epoch #35 | Saved\n",
      "2022-08-17 18:05:07 | [trpo_pendulum] epoch #35 | Time 22.99 s\n",
      "2022-08-17 18:05:07 | [trpo_pendulum] epoch #35 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -612.104\n",
      "Evaluation/AverageReturn             -1484.75\n",
      "Evaluation/Iteration                    35\n",
      "Evaluation/MaxReturn                 -1454.98\n",
      "Evaluation/MinReturn                 -1524.49\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    24.8385\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.35083\n",
      "GaussianMLPPolicy/KL                     0.00729163\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            187.557\n",
      "GaussianMLPPolicy/LossBefore           190.853\n",
      "GaussianMLPPolicy/dLoss                  3.2959\n",
      "GaussianMLPValueFunction/LossAfter    9205.62\n",
      "GaussianMLPValueFunction/LossBefore   9801.07\n",
      "GaussianMLPValueFunction/dLoss         595.45\n",
      "TotalEnvSteps                        43200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:07 | [trpo_pendulum] epoch #36 | Saving snapshot...\n",
      "2022-08-17 18:05:07 | [trpo_pendulum] epoch #36 | Saved\n",
      "2022-08-17 18:05:07 | [trpo_pendulum] epoch #36 | Time 23.61 s\n",
      "2022-08-17 18:05:07 | [trpo_pendulum] epoch #36 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -641.136\n",
      "Evaluation/AverageReturn             -1530.61\n",
      "Evaluation/Iteration                    36\n",
      "Evaluation/MaxReturn                 -1496.72\n",
      "Evaluation/MinReturn                 -1564.6\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    21.038\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.34025\n",
      "GaussianMLPPolicy/KL                     0.00636631\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            193.185\n",
      "GaussianMLPPolicy/LossBefore           195.803\n",
      "GaussianMLPPolicy/dLoss                  2.61821\n",
      "GaussianMLPValueFunction/LossAfter    9083.47\n",
      "GaussianMLPValueFunction/LossBefore   9692.86\n",
      "GaussianMLPValueFunction/dLoss         609.387\n",
      "TotalEnvSteps                        44400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:08 | [trpo_pendulum] epoch #37 | Saving snapshot...\n",
      "2022-08-17 18:05:08 | [trpo_pendulum] epoch #37 | Saved\n",
      "2022-08-17 18:05:08 | [trpo_pendulum] epoch #37 | Time 24.22 s\n",
      "2022-08-17 18:05:08 | [trpo_pendulum] epoch #37 | EpochTime 0.60 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -598.332\n",
      "Evaluation/AverageReturn             -1470.71\n",
      "Evaluation/Iteration                    37\n",
      "Evaluation/MaxReturn                 -1450.5\n",
      "Evaluation/MinReturn                 -1493.36\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    16.9856\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.33452\n",
      "GaussianMLPPolicy/KL                     0.00739906\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            186.077\n",
      "GaussianMLPPolicy/LossBefore           189.004\n",
      "GaussianMLPPolicy/dLoss                  2.92757\n",
      "GaussianMLPValueFunction/LossAfter    8075.44\n",
      "GaussianMLPValueFunction/LossBefore   8588.84\n",
      "GaussianMLPValueFunction/dLoss         513.4\n",
      "TotalEnvSteps                        45600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:09 | [trpo_pendulum] epoch #38 | Saving snapshot...\n",
      "2022-08-17 18:05:09 | [trpo_pendulum] epoch #38 | Saved\n",
      "2022-08-17 18:05:09 | [trpo_pendulum] epoch #38 | Time 24.84 s\n",
      "2022-08-17 18:05:09 | [trpo_pendulum] epoch #38 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -600.012\n",
      "Evaluation/AverageReturn             -1479.95\n",
      "Evaluation/Iteration                    38\n",
      "Evaluation/MaxReturn                 -1466.16\n",
      "Evaluation/MinReturn                 -1499.81\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    10.6239\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.3292\n",
      "GaussianMLPPolicy/KL                     0.00879991\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            187.519\n",
      "GaussianMLPPolicy/LossBefore           190.515\n",
      "GaussianMLPPolicy/dLoss                  2.99557\n",
      "GaussianMLPValueFunction/LossAfter    7739.6\n",
      "GaussianMLPValueFunction/LossBefore   8238.61\n",
      "GaussianMLPValueFunction/dLoss         499.01\n",
      "TotalEnvSteps                        46800\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:09 | [trpo_pendulum] epoch #39 | Saving snapshot...\n",
      "2022-08-17 18:05:09 | [trpo_pendulum] epoch #39 | Saved\n",
      "2022-08-17 18:05:09 | [trpo_pendulum] epoch #39 | Time 25.48 s\n",
      "2022-08-17 18:05:09 | [trpo_pendulum] epoch #39 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -562.133\n",
      "Evaluation/AverageReturn             -1441.11\n",
      "Evaluation/Iteration                    39\n",
      "Evaluation/MaxReturn                 -1419.94\n",
      "Evaluation/MinReturn                 -1467.11\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    14.3128\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.32987\n",
      "GaussianMLPPolicy/KL                     0.00663558\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            186.95\n",
      "GaussianMLPPolicy/LossBefore           189.794\n",
      "GaussianMLPPolicy/dLoss                  2.84383\n",
      "GaussianMLPValueFunction/LossAfter    7257.11\n",
      "GaussianMLPValueFunction/LossBefore   7722.98\n",
      "GaussianMLPValueFunction/dLoss         465.871\n",
      "TotalEnvSteps                        48000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:10 | [trpo_pendulum] epoch #40 | Saving snapshot...\n",
      "2022-08-17 18:05:10 | [trpo_pendulum] epoch #40 | Saved\n",
      "2022-08-17 18:05:10 | [trpo_pendulum] epoch #40 | Time 26.11 s\n",
      "2022-08-17 18:05:10 | [trpo_pendulum] epoch #40 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -658.848\n",
      "Evaluation/AverageReturn             -1552.31\n",
      "Evaluation/Iteration                    40\n",
      "Evaluation/MaxReturn                 -1540.96\n",
      "Evaluation/MinReturn                 -1566.48\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     7.78932\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.35238\n",
      "GaussianMLPPolicy/KL                     0.00707211\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            193.098\n",
      "GaussianMLPPolicy/LossBefore           195.711\n",
      "GaussianMLPPolicy/dLoss                  2.61293\n",
      "GaussianMLPValueFunction/LossAfter    7169.34\n",
      "GaussianMLPValueFunction/LossBefore   7648.85\n",
      "GaussianMLPValueFunction/dLoss         479.519\n",
      "TotalEnvSteps                        49200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:10 | [trpo_pendulum] epoch #41 | Saving snapshot...\n",
      "2022-08-17 18:05:10 | [trpo_pendulum] epoch #41 | Saved\n",
      "2022-08-17 18:05:10 | [trpo_pendulum] epoch #41 | Time 26.71 s\n",
      "2022-08-17 18:05:10 | [trpo_pendulum] epoch #41 | EpochTime 0.60 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -684.044\n",
      "Evaluation/AverageReturn             -1578.24\n",
      "Evaluation/Iteration                    41\n",
      "Evaluation/MaxReturn                 -1568.18\n",
      "Evaluation/MinReturn                 -1587.83\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     6.58961\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.36168\n",
      "GaussianMLPPolicy/KL                     0.00683646\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            196.19\n",
      "GaussianMLPPolicy/LossBefore           196.229\n",
      "GaussianMLPPolicy/dLoss                  0.0392151\n",
      "GaussianMLPValueFunction/LossAfter    6750.4\n",
      "GaussianMLPValueFunction/LossBefore   7201.04\n",
      "GaussianMLPValueFunction/dLoss         450.648\n",
      "TotalEnvSteps                        50400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:11 | [trpo_pendulum] epoch #42 | Saving snapshot...\n",
      "2022-08-17 18:05:11 | [trpo_pendulum] epoch #42 | Saved\n",
      "2022-08-17 18:05:11 | [trpo_pendulum] epoch #42 | Time 27.33 s\n",
      "2022-08-17 18:05:11 | [trpo_pendulum] epoch #42 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -559.942\n",
      "Evaluation/AverageReturn             -1325.81\n",
      "Evaluation/Iteration                    42\n",
      "Evaluation/MaxReturn                 -1281.81\n",
      "Evaluation/MinReturn                 -1427.4\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    49.6777\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.3474\n",
      "GaussianMLPPolicy/KL                     0.00796381\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            159.125\n",
      "GaussianMLPPolicy/LossBefore           162.156\n",
      "GaussianMLPPolicy/dLoss                  3.03134\n",
      "GaussianMLPValueFunction/LossAfter    4458.15\n",
      "GaussianMLPValueFunction/LossBefore   4674.59\n",
      "GaussianMLPValueFunction/dLoss         216.435\n",
      "TotalEnvSteps                        51600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:12 | [trpo_pendulum] epoch #43 | Saving snapshot...\n",
      "2022-08-17 18:05:12 | [trpo_pendulum] epoch #43 | Saved\n",
      "2022-08-17 18:05:12 | [trpo_pendulum] epoch #43 | Time 27.96 s\n",
      "2022-08-17 18:05:12 | [trpo_pendulum] epoch #43 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -576.616\n",
      "Evaluation/AverageReturn             -1409.99\n",
      "Evaluation/Iteration                    43\n",
      "Evaluation/MaxReturn                 -1330.03\n",
      "Evaluation/MinReturn                 -1447.81\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    39.8634\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.33981\n",
      "GaussianMLPPolicy/KL                     0.00690613\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            173.831\n",
      "GaussianMLPPolicy/LossBefore           176.414\n",
      "GaussianMLPPolicy/dLoss                  2.58284\n",
      "GaussianMLPValueFunction/LossAfter    5030.44\n",
      "GaussianMLPValueFunction/LossBefore   5317.37\n",
      "GaussianMLPValueFunction/dLoss         286.938\n",
      "TotalEnvSteps                        52800\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:12 | [trpo_pendulum] epoch #44 | Saving snapshot...\n",
      "2022-08-17 18:05:12 | [trpo_pendulum] epoch #44 | Saved\n",
      "2022-08-17 18:05:12 | [trpo_pendulum] epoch #44 | Time 28.61 s\n",
      "2022-08-17 18:05:12 | [trpo_pendulum] epoch #44 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -597.729\n",
      "Evaluation/AverageReturn             -1434.48\n",
      "Evaluation/Iteration                    44\n",
      "Evaluation/MaxReturn                 -1384.68\n",
      "Evaluation/MinReturn                 -1496.63\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    35.9515\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.35085\n",
      "GaussianMLPPolicy/KL                     0.00635082\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            176.047\n",
      "GaussianMLPPolicy/LossBefore           178.455\n",
      "GaussianMLPPolicy/dLoss                  2.40742\n",
      "GaussianMLPValueFunction/LossAfter    4861.95\n",
      "GaussianMLPValueFunction/LossBefore   5149.44\n",
      "GaussianMLPValueFunction/dLoss         287.487\n",
      "TotalEnvSteps                        54000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:13 | [trpo_pendulum] epoch #45 | Saving snapshot...\n",
      "2022-08-17 18:05:13 | [trpo_pendulum] epoch #45 | Saved\n",
      "2022-08-17 18:05:13 | [trpo_pendulum] epoch #45 | Time 29.22 s\n",
      "2022-08-17 18:05:13 | [trpo_pendulum] epoch #45 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -495.375\n",
      "Evaluation/AverageReturn             -1272.83\n",
      "Evaluation/Iteration                    45\n",
      "Evaluation/MaxReturn                 -1141.92\n",
      "Evaluation/MinReturn                 -1378.07\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    71.7617\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.32102\n",
      "GaussianMLPPolicy/KL                     0.00871888\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            159.438\n",
      "GaussianMLPPolicy/LossBefore           161.775\n",
      "GaussianMLPPolicy/dLoss                  2.33662\n",
      "GaussianMLPValueFunction/LossAfter    3860.06\n",
      "GaussianMLPValueFunction/LossBefore   4057.94\n",
      "GaussianMLPValueFunction/dLoss         197.878\n",
      "TotalEnvSteps                        55200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:14 | [trpo_pendulum] epoch #46 | Saving snapshot...\n",
      "2022-08-17 18:05:14 | [trpo_pendulum] epoch #46 | Saved\n",
      "2022-08-17 18:05:14 | [trpo_pendulum] epoch #46 | Time 29.84 s\n",
      "2022-08-17 18:05:14 | [trpo_pendulum] epoch #46 | EpochTime 0.61 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn    -601.828\n",
      "Evaluation/AverageReturn             -1429.08\n",
      "Evaluation/Iteration                    46\n",
      "Evaluation/MaxReturn                 -1365.78\n",
      "Evaluation/MinReturn                 -1494.64\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    40.209\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.31591\n",
      "GaussianMLPPolicy/KL                     0.0072531\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            173.559\n",
      "GaussianMLPPolicy/LossBefore           176.132\n",
      "GaussianMLPPolicy/dLoss                  2.57263\n",
      "GaussianMLPValueFunction/LossAfter    4304.25\n",
      "GaussianMLPValueFunction/LossBefore   4561.76\n",
      "GaussianMLPValueFunction/dLoss         257.515\n",
      "TotalEnvSteps                        56400\n",
      "-----------------------------------  -------------\n",
      "2022-08-17 18:05:14 | [trpo_pendulum] epoch #47 | Saving snapshot...\n",
      "2022-08-17 18:05:14 | [trpo_pendulum] epoch #47 | Saved\n",
      "2022-08-17 18:05:14 | [trpo_pendulum] epoch #47 | Time 30.45 s\n",
      "2022-08-17 18:05:14 | [trpo_pendulum] epoch #47 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -623.187\n",
      "Evaluation/AverageReturn             -1474.85\n",
      "Evaluation/Iteration                    47\n",
      "Evaluation/MaxReturn                 -1397.14\n",
      "Evaluation/MinReturn                 -1517.59\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    39.9239\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.3155\n",
      "GaussianMLPPolicy/KL                     0.00733579\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            179.138\n",
      "GaussianMLPPolicy/LossBefore           181.578\n",
      "GaussianMLPPolicy/dLoss                  2.43982\n",
      "GaussianMLPValueFunction/LossAfter    4284.08\n",
      "GaussianMLPValueFunction/LossBefore   4556.79\n",
      "GaussianMLPValueFunction/dLoss         272.708\n",
      "TotalEnvSteps                        57600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:15 | [trpo_pendulum] epoch #48 | Saving snapshot...\n",
      "2022-08-17 18:05:15 | [trpo_pendulum] epoch #48 | Saved\n",
      "2022-08-17 18:05:15 | [trpo_pendulum] epoch #48 | Time 31.08 s\n",
      "2022-08-17 18:05:15 | [trpo_pendulum] epoch #48 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -594.947\n",
      "Evaluation/AverageReturn             -1437.05\n",
      "Evaluation/Iteration                    48\n",
      "Evaluation/MaxReturn                 -1403.34\n",
      "Evaluation/MinReturn                 -1456.38\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    17.1079\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.31298\n",
      "GaussianMLPPolicy/KL                     0.00675291\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            174.54\n",
      "GaussianMLPPolicy/LossBefore           177.984\n",
      "GaussianMLPPolicy/dLoss                  3.44327\n",
      "GaussianMLPValueFunction/LossAfter    3934.85\n",
      "GaussianMLPValueFunction/LossBefore   4180.38\n",
      "GaussianMLPValueFunction/dLoss         245.53\n",
      "TotalEnvSteps                        58800\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:15 | [trpo_pendulum] epoch #49 | Saving snapshot...\n",
      "2022-08-17 18:05:15 | [trpo_pendulum] epoch #49 | Saved\n",
      "2022-08-17 18:05:15 | [trpo_pendulum] epoch #49 | Time 31.69 s\n",
      "2022-08-17 18:05:15 | [trpo_pendulum] epoch #49 | EpochTime 0.61 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn    -659.762\n",
      "Evaluation/AverageReturn             -1546.76\n",
      "Evaluation/Iteration                    49\n",
      "Evaluation/MaxReturn                 -1499.99\n",
      "Evaluation/MinReturn                 -1576.26\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    27.3766\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.3207\n",
      "GaussianMLPPolicy/KL                     0.0085073\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            187.854\n",
      "GaussianMLPPolicy/LossBefore           190.13\n",
      "GaussianMLPPolicy/dLoss                  2.27678\n",
      "GaussianMLPValueFunction/LossAfter    4180.75\n",
      "GaussianMLPValueFunction/LossBefore   4471.79\n",
      "GaussianMLPValueFunction/dLoss         291.04\n",
      "TotalEnvSteps                        60000\n",
      "-----------------------------------  -------------\n",
      "2022-08-17 18:05:16 | [trpo_pendulum] epoch #50 | Saving snapshot...\n",
      "2022-08-17 18:05:16 | [trpo_pendulum] epoch #50 | Saved\n",
      "2022-08-17 18:05:16 | [trpo_pendulum] epoch #50 | Time 32.30 s\n",
      "2022-08-17 18:05:16 | [trpo_pendulum] epoch #50 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -444.565\n",
      "Evaluation/AverageReturn             -1119.97\n",
      "Evaluation/Iteration                    50\n",
      "Evaluation/MaxReturn                  -998.356\n",
      "Evaluation/MinReturn                 -1309.47\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                   134.485\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.30878\n",
      "GaussianMLPPolicy/KL                     0.00699904\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            131.233\n",
      "GaussianMLPPolicy/LossBefore           133.656\n",
      "GaussianMLPPolicy/dLoss                  2.42216\n",
      "GaussianMLPValueFunction/LossAfter    2108.66\n",
      "GaussianMLPValueFunction/LossBefore   2193.6\n",
      "GaussianMLPValueFunction/dLoss          84.9414\n",
      "TotalEnvSteps                        61200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:17 | [trpo_pendulum] epoch #51 | Saving snapshot...\n",
      "2022-08-17 18:05:17 | [trpo_pendulum] epoch #51 | Saved\n",
      "2022-08-17 18:05:17 | [trpo_pendulum] epoch #51 | Time 32.90 s\n",
      "2022-08-17 18:05:17 | [trpo_pendulum] epoch #51 | EpochTime 0.60 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -659.82\n",
      "Evaluation/AverageReturn             -1561.09\n",
      "Evaluation/Iteration                    51\n",
      "Evaluation/MaxReturn                 -1507.14\n",
      "Evaluation/MinReturn                 -1585.03\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    26.5398\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.31803\n",
      "GaussianMLPPolicy/KL                     0.00899894\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            189.64\n",
      "GaussianMLPPolicy/LossBefore           192.258\n",
      "GaussianMLPPolicy/dLoss                  2.61777\n",
      "GaussianMLPValueFunction/LossAfter    3867.99\n",
      "GaussianMLPValueFunction/LossBefore   4147.81\n",
      "GaussianMLPValueFunction/dLoss         279.822\n",
      "TotalEnvSteps                        62400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:17 | [trpo_pendulum] epoch #52 | Saving snapshot...\n",
      "2022-08-17 18:05:17 | [trpo_pendulum] epoch #52 | Saved\n",
      "2022-08-17 18:05:17 | [trpo_pendulum] epoch #52 | Time 33.52 s\n",
      "2022-08-17 18:05:17 | [trpo_pendulum] epoch #52 | EpochTime 0.62 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn    -546.185\n",
      "Evaluation/AverageReturn             -1388.53\n",
      "Evaluation/Iteration                    52\n",
      "Evaluation/MaxReturn                 -1335.02\n",
      "Evaluation/MinReturn                 -1426.45\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    28.4244\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.31244\n",
      "GaussianMLPPolicy/KL                     0.0090833\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            170.268\n",
      "GaussianMLPPolicy/LossBefore           174.572\n",
      "GaussianMLPPolicy/dLoss                  4.30362\n",
      "GaussianMLPValueFunction/LossAfter    3038.2\n",
      "GaussianMLPValueFunction/LossBefore   3227.45\n",
      "GaussianMLPValueFunction/dLoss         189.244\n",
      "TotalEnvSteps                        63600\n",
      "-----------------------------------  -------------\n",
      "2022-08-17 18:05:18 | [trpo_pendulum] epoch #53 | Saving snapshot...\n",
      "2022-08-17 18:05:18 | [trpo_pendulum] epoch #53 | Saved\n",
      "2022-08-17 18:05:18 | [trpo_pendulum] epoch #53 | Time 34.16 s\n",
      "2022-08-17 18:05:18 | [trpo_pendulum] epoch #53 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -654.044\n",
      "Evaluation/AverageReturn             -1551\n",
      "Evaluation/Iteration                    53\n",
      "Evaluation/MaxReturn                 -1538.94\n",
      "Evaluation/MinReturn                 -1565.98\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    12.0087\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.33596\n",
      "GaussianMLPPolicy/KL                     0.00561468\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            188.051\n",
      "GaussianMLPPolicy/LossBefore           190.609\n",
      "GaussianMLPPolicy/dLoss                  2.55797\n",
      "GaussianMLPValueFunction/LossAfter    3378.65\n",
      "GaussianMLPValueFunction/LossBefore   3620.99\n",
      "GaussianMLPValueFunction/dLoss         242.339\n",
      "TotalEnvSteps                        64800\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:18 | [trpo_pendulum] epoch #54 | Saving snapshot...\n",
      "2022-08-17 18:05:19 | [trpo_pendulum] epoch #54 | Saved\n",
      "2022-08-17 18:05:19 | [trpo_pendulum] epoch #54 | Time 34.78 s\n",
      "2022-08-17 18:05:19 | [trpo_pendulum] epoch #54 | EpochTime 0.61 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn    -651.724\n",
      "Evaluation/AverageReturn             -1551.87\n",
      "Evaluation/Iteration                    54\n",
      "Evaluation/MaxReturn                 -1522.08\n",
      "Evaluation/MinReturn                 -1569.74\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    17.401\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.32292\n",
      "GaussianMLPPolicy/KL                     0.0076935\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            188.165\n",
      "GaussianMLPPolicy/LossBefore           190.219\n",
      "GaussianMLPPolicy/dLoss                  2.05397\n",
      "GaussianMLPValueFunction/LossAfter    3154.71\n",
      "GaussianMLPValueFunction/LossBefore   3378.65\n",
      "GaussianMLPValueFunction/dLoss         223.944\n",
      "TotalEnvSteps                        66000\n",
      "-----------------------------------  -------------\n",
      "2022-08-17 18:05:19 | [trpo_pendulum] epoch #55 | Saving snapshot...\n",
      "2022-08-17 18:05:19 | [trpo_pendulum] epoch #55 | Saved\n",
      "2022-08-17 18:05:19 | [trpo_pendulum] epoch #55 | Time 35.39 s\n",
      "2022-08-17 18:05:19 | [trpo_pendulum] epoch #55 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -693.297\n",
      "Evaluation/AverageReturn             -1597.69\n",
      "Evaluation/Iteration                    55\n",
      "Evaluation/MaxReturn                 -1585.15\n",
      "Evaluation/MinReturn                 -1605.82\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     8.7879\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.31881\n",
      "GaussianMLPPolicy/KL                     0.00727999\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            190.213\n",
      "GaussianMLPPolicy/LossBefore           193.167\n",
      "GaussianMLPPolicy/dLoss                  2.95439\n",
      "GaussianMLPValueFunction/LossAfter    3028.72\n",
      "GaussianMLPValueFunction/LossBefore   3245.23\n",
      "GaussianMLPValueFunction/dLoss         216.511\n",
      "TotalEnvSteps                        67200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:20 | [trpo_pendulum] epoch #56 | Saving snapshot...\n",
      "2022-08-17 18:05:20 | [trpo_pendulum] epoch #56 | Saved\n",
      "2022-08-17 18:05:20 | [trpo_pendulum] epoch #56 | Time 36.00 s\n",
      "2022-08-17 18:05:20 | [trpo_pendulum] epoch #56 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -566.882\n",
      "Evaluation/AverageReturn             -1358.14\n",
      "Evaluation/Iteration                    56\n",
      "Evaluation/MaxReturn                 -1300.94\n",
      "Evaluation/MinReturn                 -1435.77\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    50.8135\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.30405\n",
      "GaussianMLPPolicy/KL                     0.00772874\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            159.78\n",
      "GaussianMLPPolicy/LossBefore           161.79\n",
      "GaussianMLPPolicy/dLoss                  2.00969\n",
      "GaussianMLPValueFunction/LossAfter    2059.69\n",
      "GaussianMLPValueFunction/LossBefore   2168.99\n",
      "GaussianMLPValueFunction/dLoss         109.299\n",
      "TotalEnvSteps                        68400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:20 | [trpo_pendulum] epoch #57 | Saving snapshot...\n",
      "2022-08-17 18:05:20 | [trpo_pendulum] epoch #57 | Saved\n",
      "2022-08-17 18:05:20 | [trpo_pendulum] epoch #57 | Time 36.61 s\n",
      "2022-08-17 18:05:20 | [trpo_pendulum] epoch #57 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -474.287\n",
      "Evaluation/AverageReturn             -1102.83\n",
      "Evaluation/Iteration                    57\n",
      "Evaluation/MaxReturn                  -971.02\n",
      "Evaluation/MinReturn                 -1181.68\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    70.2617\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.26117\n",
      "GaussianMLPPolicy/KL                     0.00939128\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            120.912\n",
      "GaussianMLPPolicy/LossBefore           123.28\n",
      "GaussianMLPPolicy/dLoss                  2.36758\n",
      "GaussianMLPValueFunction/LossAfter    1171.18\n",
      "GaussianMLPValueFunction/LossBefore   1211.03\n",
      "GaussianMLPValueFunction/dLoss          39.8506\n",
      "TotalEnvSteps                        69600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:21 | [trpo_pendulum] epoch #58 | Saving snapshot...\n",
      "2022-08-17 18:05:21 | [trpo_pendulum] epoch #58 | Saved\n",
      "2022-08-17 18:05:21 | [trpo_pendulum] epoch #58 | Time 37.24 s\n",
      "2022-08-17 18:05:21 | [trpo_pendulum] epoch #58 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -543.362\n",
      "Evaluation/AverageReturn             -1280.42\n",
      "Evaluation/Iteration                    58\n",
      "Evaluation/MaxReturn                 -1245.95\n",
      "Evaluation/MinReturn                 -1324.14\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    27.9651\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.2539\n",
      "GaussianMLPPolicy/KL                     0.00682559\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            146.975\n",
      "GaussianMLPPolicy/LossBefore           148.751\n",
      "GaussianMLPPolicy/dLoss                  1.77672\n",
      "GaussianMLPValueFunction/LossAfter    1619.06\n",
      "GaussianMLPValueFunction/LossBefore   1696.36\n",
      "GaussianMLPValueFunction/dLoss          77.2958\n",
      "TotalEnvSteps                        70800\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:22 | [trpo_pendulum] epoch #59 | Saving snapshot...\n",
      "2022-08-17 18:05:22 | [trpo_pendulum] epoch #59 | Saved\n",
      "2022-08-17 18:05:22 | [trpo_pendulum] epoch #59 | Time 37.86 s\n",
      "2022-08-17 18:05:22 | [trpo_pendulum] epoch #59 | EpochTime 0.62 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn    -475.038\n",
      "Evaluation/AverageReturn             -1100.35\n",
      "Evaluation/Iteration                    59\n",
      "Evaluation/MaxReturn                 -1028.62\n",
      "Evaluation/MinReturn                 -1171.74\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    64.168\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.22481\n",
      "GaussianMLPPolicy/KL                     0.0086607\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            121.857\n",
      "GaussianMLPPolicy/LossBefore           122.373\n",
      "GaussianMLPPolicy/dLoss                  0.51651\n",
      "GaussianMLPValueFunction/LossAfter    1084.19\n",
      "GaussianMLPValueFunction/LossBefore   1123.94\n",
      "GaussianMLPValueFunction/dLoss          39.7484\n",
      "TotalEnvSteps                        72000\n",
      "-----------------------------------  -------------\n",
      "2022-08-17 18:05:22 | [trpo_pendulum] epoch #60 | Saving snapshot...\n",
      "2022-08-17 18:05:22 | [trpo_pendulum] epoch #60 | Saved\n",
      "2022-08-17 18:05:22 | [trpo_pendulum] epoch #60 | Time 38.50 s\n",
      "2022-08-17 18:05:22 | [trpo_pendulum] epoch #60 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -521.526\n",
      "Evaluation/AverageReturn             -1231.25\n",
      "Evaluation/Iteration                    60\n",
      "Evaluation/MaxReturn                 -1074.18\n",
      "Evaluation/MinReturn                 -1408.14\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                   120.256\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.21852\n",
      "GaussianMLPPolicy/KL                     0.00980041\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            138.459\n",
      "GaussianMLPPolicy/LossBefore           141.251\n",
      "GaussianMLPPolicy/dLoss                  2.79213\n",
      "GaussianMLPValueFunction/LossAfter    1384.32\n",
      "GaussianMLPValueFunction/LossBefore   1451.08\n",
      "GaussianMLPValueFunction/dLoss          66.7585\n",
      "TotalEnvSteps                        73200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:23 | [trpo_pendulum] epoch #61 | Saving snapshot...\n",
      "2022-08-17 18:05:23 | [trpo_pendulum] epoch #61 | Saved\n",
      "2022-08-17 18:05:23 | [trpo_pendulum] epoch #61 | Time 39.15 s\n",
      "2022-08-17 18:05:23 | [trpo_pendulum] epoch #61 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -617.858\n",
      "Evaluation/AverageReturn             -1468.45\n",
      "Evaluation/Iteration                    61\n",
      "Evaluation/MaxReturn                 -1330.63\n",
      "Evaluation/MinReturn                 -1553.29\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    74.9415\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.24211\n",
      "GaussianMLPPolicy/KL                     0.00989011\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            172.73\n",
      "GaussianMLPPolicy/LossBefore           175.116\n",
      "GaussianMLPPolicy/dLoss                  2.38609\n",
      "GaussianMLPValueFunction/LossAfter    1946.31\n",
      "GaussianMLPValueFunction/LossBefore   2085.12\n",
      "GaussianMLPValueFunction/dLoss         138.817\n",
      "TotalEnvSteps                        74400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:24 | [trpo_pendulum] epoch #62 | Saving snapshot...\n",
      "2022-08-17 18:05:24 | [trpo_pendulum] epoch #62 | Saved\n",
      "2022-08-17 18:05:24 | [trpo_pendulum] epoch #62 | Time 39.80 s\n",
      "2022-08-17 18:05:24 | [trpo_pendulum] epoch #62 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -639.833\n",
      "Evaluation/AverageReturn             -1503.08\n",
      "Evaluation/Iteration                    62\n",
      "Evaluation/MaxReturn                 -1436\n",
      "Evaluation/MinReturn                 -1583.43\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    54.3134\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.23588\n",
      "GaussianMLPPolicy/KL                     0.00871737\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            176.528\n",
      "GaussianMLPPolicy/LossBefore           178.569\n",
      "GaussianMLPPolicy/dLoss                  2.04132\n",
      "GaussianMLPValueFunction/LossAfter    1898.15\n",
      "GaussianMLPValueFunction/LossBefore   2038.71\n",
      "GaussianMLPValueFunction/dLoss         140.555\n",
      "TotalEnvSteps                        75600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:24 | [trpo_pendulum] epoch #63 | Saving snapshot...\n",
      "2022-08-17 18:05:24 | [trpo_pendulum] epoch #63 | Saved\n",
      "2022-08-17 18:05:24 | [trpo_pendulum] epoch #63 | Time 40.43 s\n",
      "2022-08-17 18:05:24 | [trpo_pendulum] epoch #63 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -546.189\n",
      "Evaluation/AverageReturn             -1319.5\n",
      "Evaluation/Iteration                    63\n",
      "Evaluation/MaxReturn                 -1198.5\n",
      "Evaluation/MinReturn                 -1374.31\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    62.1978\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.22108\n",
      "GaussianMLPPolicy/KL                     0.00760917\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            151.8\n",
      "GaussianMLPPolicy/LossBefore           154.244\n",
      "GaussianMLPPolicy/dLoss                  2.44456\n",
      "GaussianMLPValueFunction/LossAfter    1359.14\n",
      "GaussianMLPValueFunction/LossBefore   1437.05\n",
      "GaussianMLPValueFunction/dLoss          77.9038\n",
      "TotalEnvSteps                        76800\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:25 | [trpo_pendulum] epoch #64 | Saving snapshot...\n",
      "2022-08-17 18:05:25 | [trpo_pendulum] epoch #64 | Saved\n",
      "2022-08-17 18:05:25 | [trpo_pendulum] epoch #64 | Time 41.06 s\n",
      "2022-08-17 18:05:25 | [trpo_pendulum] epoch #64 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -695.622\n",
      "Evaluation/AverageReturn             -1610.84\n",
      "Evaluation/Iteration                    64\n",
      "Evaluation/MaxReturn                 -1599.2\n",
      "Evaluation/MinReturn                 -1624.12\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     8.82016\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.20913\n",
      "GaussianMLPPolicy/KL                     0.00709967\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            188.896\n",
      "GaussianMLPPolicy/LossBefore           191.627\n",
      "GaussianMLPPolicy/dLoss                  2.73109\n",
      "GaussianMLPValueFunction/LossAfter    1912.66\n",
      "GaussianMLPValueFunction/LossBefore   2069.47\n",
      "GaussianMLPValueFunction/dLoss         156.815\n",
      "TotalEnvSteps                        78000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:25 | [trpo_pendulum] epoch #65 | Saving snapshot...\n",
      "2022-08-17 18:05:25 | [trpo_pendulum] epoch #65 | Saved\n",
      "2022-08-17 18:05:25 | [trpo_pendulum] epoch #65 | Time 41.68 s\n",
      "2022-08-17 18:05:25 | [trpo_pendulum] epoch #65 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -533.864\n",
      "Evaluation/AverageReturn             -1301.78\n",
      "Evaluation/Iteration                    65\n",
      "Evaluation/MaxReturn                 -1181.47\n",
      "Evaluation/MinReturn                 -1362.99\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    57.5765\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.20549\n",
      "GaussianMLPPolicy/KL                     0.00754131\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            150.153\n",
      "GaussianMLPPolicy/LossBefore           151.795\n",
      "GaussianMLPPolicy/dLoss                  1.6416\n",
      "GaussianMLPValueFunction/LossAfter    1186.2\n",
      "GaussianMLPValueFunction/LossBefore   1252.53\n",
      "GaussianMLPValueFunction/dLoss          66.3236\n",
      "TotalEnvSteps                        79200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:26 | [trpo_pendulum] epoch #66 | Saving snapshot...\n",
      "2022-08-17 18:05:26 | [trpo_pendulum] epoch #66 | Saved\n",
      "2022-08-17 18:05:26 | [trpo_pendulum] epoch #66 | Time 42.29 s\n",
      "2022-08-17 18:05:26 | [trpo_pendulum] epoch #66 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -607.093\n",
      "Evaluation/AverageReturn             -1339.99\n",
      "Evaluation/Iteration                    66\n",
      "Evaluation/MaxReturn                 -1273.1\n",
      "Evaluation/MinReturn                 -1430.5\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    50.1948\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.21935\n",
      "GaussianMLPPolicy/KL                     0.00857452\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            145.849\n",
      "GaussianMLPPolicy/LossBefore           148.268\n",
      "GaussianMLPPolicy/dLoss                  2.41891\n",
      "GaussianMLPValueFunction/LossAfter    1048.85\n",
      "GaussianMLPValueFunction/LossBefore   1103.34\n",
      "GaussianMLPValueFunction/dLoss          54.4928\n",
      "TotalEnvSteps                        80400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:27 | [trpo_pendulum] epoch #67 | Saving snapshot...\n",
      "2022-08-17 18:05:27 | [trpo_pendulum] epoch #67 | Saved\n",
      "2022-08-17 18:05:27 | [trpo_pendulum] epoch #67 | Time 42.93 s\n",
      "2022-08-17 18:05:27 | [trpo_pendulum] epoch #67 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -535.666\n",
      "Evaluation/AverageReturn             -1315.28\n",
      "Evaluation/Iteration                    67\n",
      "Evaluation/MaxReturn                 -1257.73\n",
      "Evaluation/MinReturn                 -1361.03\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    34.1951\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.22002\n",
      "GaussianMLPPolicy/KL                     0.00683381\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            150.961\n",
      "GaussianMLPPolicy/LossBefore           153.041\n",
      "GaussianMLPPolicy/dLoss                  2.07999\n",
      "GaussianMLPValueFunction/LossAfter    1098.24\n",
      "GaussianMLPValueFunction/LossBefore   1161.8\n",
      "GaussianMLPValueFunction/dLoss          63.5593\n",
      "TotalEnvSteps                        81600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:27 | [trpo_pendulum] epoch #68 | Saving snapshot...\n",
      "2022-08-17 18:05:27 | [trpo_pendulum] epoch #68 | Saved\n",
      "2022-08-17 18:05:27 | [trpo_pendulum] epoch #68 | Time 43.55 s\n",
      "2022-08-17 18:05:27 | [trpo_pendulum] epoch #68 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -573.314\n",
      "Evaluation/AverageReturn             -1413.72\n",
      "Evaluation/Iteration                    68\n",
      "Evaluation/MaxReturn                 -1359.34\n",
      "Evaluation/MinReturn                 -1459.32\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    37.8351\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.25053\n",
      "GaussianMLPPolicy/KL                     0.00588201\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            167.126\n",
      "GaussianMLPPolicy/LossBefore           169.048\n",
      "GaussianMLPPolicy/dLoss                  1.92192\n",
      "GaussianMLPValueFunction/LossAfter    1231.81\n",
      "GaussianMLPValueFunction/LossBefore   1316.37\n",
      "GaussianMLPValueFunction/dLoss          84.5571\n",
      "TotalEnvSteps                        82800\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:28 | [trpo_pendulum] epoch #69 | Saving snapshot...\n",
      "2022-08-17 18:05:28 | [trpo_pendulum] epoch #69 | Saved\n",
      "2022-08-17 18:05:28 | [trpo_pendulum] epoch #69 | Time 44.17 s\n",
      "2022-08-17 18:05:28 | [trpo_pendulum] epoch #69 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -661.47\n",
      "Evaluation/AverageReturn             -1515.57\n",
      "Evaluation/Iteration                    69\n",
      "Evaluation/MaxReturn                 -1505.59\n",
      "Evaluation/MinReturn                 -1527.35\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     8.75946\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.2342\n",
      "GaussianMLPPolicy/KL                     0.00582888\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            174.115\n",
      "GaussianMLPPolicy/LossBefore           174.727\n",
      "GaussianMLPPolicy/dLoss                  0.612793\n",
      "GaussianMLPValueFunction/LossAfter    1220\n",
      "GaussianMLPValueFunction/LossBefore   1307.72\n",
      "GaussianMLPValueFunction/dLoss          87.7236\n",
      "TotalEnvSteps                        84000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:29 | [trpo_pendulum] epoch #70 | Saving snapshot...\n",
      "2022-08-17 18:05:29 | [trpo_pendulum] epoch #70 | Saved\n",
      "2022-08-17 18:05:29 | [trpo_pendulum] epoch #70 | Time 44.82 s\n",
      "2022-08-17 18:05:29 | [trpo_pendulum] epoch #70 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -648.962\n",
      "Evaluation/AverageReturn             -1505.01\n",
      "Evaluation/Iteration                    70\n",
      "Evaluation/MaxReturn                 -1501.77\n",
      "Evaluation/MinReturn                 -1510.69\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     3.31313\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.23643\n",
      "GaussianMLPPolicy/KL                     0.00546278\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            173.986\n",
      "GaussianMLPPolicy/LossBefore           174.371\n",
      "GaussianMLPPolicy/dLoss                  0.385101\n",
      "GaussianMLPValueFunction/LossAfter    1136.46\n",
      "GaussianMLPValueFunction/LossBefore   1216.65\n",
      "GaussianMLPValueFunction/dLoss          80.197\n",
      "TotalEnvSteps                        85200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:29 | [trpo_pendulum] epoch #71 | Saving snapshot...\n",
      "2022-08-17 18:05:29 | [trpo_pendulum] epoch #71 | Saved\n",
      "2022-08-17 18:05:29 | [trpo_pendulum] epoch #71 | Time 45.44 s\n",
      "2022-08-17 18:05:29 | [trpo_pendulum] epoch #71 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -663.924\n",
      "Evaluation/AverageReturn             -1524.47\n",
      "Evaluation/Iteration                    71\n",
      "Evaluation/MaxReturn                 -1517.7\n",
      "Evaluation/MinReturn                 -1528.49\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     3.93185\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.22713\n",
      "GaussianMLPPolicy/KL                     0.00784402\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            174.239\n",
      "GaussianMLPPolicy/LossBefore           175.545\n",
      "GaussianMLPPolicy/dLoss                  1.30643\n",
      "GaussianMLPValueFunction/LossAfter    1081.55\n",
      "GaussianMLPValueFunction/LossBefore   1157.78\n",
      "GaussianMLPValueFunction/dLoss          76.2246\n",
      "TotalEnvSteps                        86400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:30 | [trpo_pendulum] epoch #72 | Saving snapshot...\n",
      "2022-08-17 18:05:30 | [trpo_pendulum] epoch #72 | Saved\n",
      "2022-08-17 18:05:30 | [trpo_pendulum] epoch #72 | Time 46.08 s\n",
      "2022-08-17 18:05:30 | [trpo_pendulum] epoch #72 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -650.908\n",
      "Evaluation/AverageReturn             -1516.15\n",
      "Evaluation/Iteration                    72\n",
      "Evaluation/MaxReturn                 -1509.28\n",
      "Evaluation/MinReturn                 -1524.68\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     5.38064\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.22187\n",
      "GaussianMLPPolicy/KL                     0.00719913\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            173\n",
      "GaussianMLPPolicy/LossBefore           175.993\n",
      "GaussianMLPPolicy/dLoss                  2.99355\n",
      "GaussianMLPValueFunction/LossAfter    1021.59\n",
      "GaussianMLPValueFunction/LossBefore   1093.31\n",
      "GaussianMLPValueFunction/dLoss          71.7168\n",
      "TotalEnvSteps                        87600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:30 | [trpo_pendulum] epoch #73 | Saving snapshot...\n",
      "2022-08-17 18:05:30 | [trpo_pendulum] epoch #73 | Saved\n",
      "2022-08-17 18:05:30 | [trpo_pendulum] epoch #73 | Time 46.70 s\n",
      "2022-08-17 18:05:30 | [trpo_pendulum] epoch #73 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -549.927\n",
      "Evaluation/AverageReturn             -1311.95\n",
      "Evaluation/Iteration                    73\n",
      "Evaluation/MaxReturn                 -1214.99\n",
      "Evaluation/MinReturn                 -1387.24\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    50.7077\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.20608\n",
      "GaussianMLPPolicy/KL                     0.00791982\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            146.381\n",
      "GaussianMLPPolicy/LossBefore           148.1\n",
      "GaussianMLPPolicy/dLoss                  1.71947\n",
      "GaussianMLPValueFunction/LossAfter     717.455\n",
      "GaussianMLPValueFunction/LossBefore    755.964\n",
      "GaussianMLPValueFunction/dLoss          38.5096\n",
      "TotalEnvSteps                        88800\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:31 | [trpo_pendulum] epoch #74 | Saving snapshot...\n",
      "2022-08-17 18:05:31 | [trpo_pendulum] epoch #74 | Saved\n",
      "2022-08-17 18:05:31 | [trpo_pendulum] epoch #74 | Time 47.33 s\n",
      "2022-08-17 18:05:31 | [trpo_pendulum] epoch #74 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -652.684\n",
      "Evaluation/AverageReturn             -1514.17\n",
      "Evaluation/Iteration                    74\n",
      "Evaluation/MaxReturn                 -1503.51\n",
      "Evaluation/MinReturn                 -1533.72\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    11.2147\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.19749\n",
      "GaussianMLPPolicy/KL                     0.00973236\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            173.582\n",
      "GaussianMLPPolicy/LossBefore           174.113\n",
      "GaussianMLPPolicy/dLoss                  0.531601\n",
      "GaussianMLPValueFunction/LossAfter     897.656\n",
      "GaussianMLPValueFunction/LossBefore    959.531\n",
      "GaussianMLPValueFunction/dLoss          61.8752\n",
      "TotalEnvSteps                        90000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:32 | [trpo_pendulum] epoch #75 | Saving snapshot...\n",
      "2022-08-17 18:05:32 | [trpo_pendulum] epoch #75 | Saved\n",
      "2022-08-17 18:05:32 | [trpo_pendulum] epoch #75 | Time 47.97 s\n",
      "2022-08-17 18:05:32 | [trpo_pendulum] epoch #75 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -479.045\n",
      "Evaluation/AverageReturn             -1152.19\n",
      "Evaluation/Iteration                    75\n",
      "Evaluation/MaxReturn                  -947.624\n",
      "Evaluation/MinReturn                 -1310.31\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                   132.593\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.20749\n",
      "GaussianMLPPolicy/KL                     0.00879509\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            122.941\n",
      "GaussianMLPPolicy/LossBefore           124.197\n",
      "GaussianMLPPolicy/dLoss                  1.2559\n",
      "GaussianMLPValueFunction/LossAfter     465.711\n",
      "GaussianMLPValueFunction/LossBefore    484.76\n",
      "GaussianMLPValueFunction/dLoss          19.0489\n",
      "TotalEnvSteps                        91200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:32 | [trpo_pendulum] epoch #76 | Saving snapshot...\n",
      "2022-08-17 18:05:32 | [trpo_pendulum] epoch #76 | Saved\n",
      "2022-08-17 18:05:32 | [trpo_pendulum] epoch #76 | Time 48.60 s\n",
      "2022-08-17 18:05:32 | [trpo_pendulum] epoch #76 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -494.041\n",
      "Evaluation/AverageReturn             -1161.73\n",
      "Evaluation/Iteration                    76\n",
      "Evaluation/MaxReturn                 -1057.99\n",
      "Evaluation/MinReturn                 -1279.6\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    82.4716\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.20769\n",
      "GaussianMLPPolicy/KL                     0.00896536\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            121.062\n",
      "GaussianMLPPolicy/LossBefore           123.05\n",
      "GaussianMLPPolicy/dLoss                  1.98774\n",
      "GaussianMLPValueFunction/LossAfter     432.325\n",
      "GaussianMLPValueFunction/LossBefore    449.618\n",
      "GaussianMLPValueFunction/dLoss          17.2931\n",
      "TotalEnvSteps                        92400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:33 | [trpo_pendulum] epoch #77 | Saving snapshot...\n",
      "2022-08-17 18:05:33 | [trpo_pendulum] epoch #77 | Saved\n",
      "2022-08-17 18:05:33 | [trpo_pendulum] epoch #77 | Time 49.23 s\n",
      "2022-08-17 18:05:33 | [trpo_pendulum] epoch #77 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -524.474\n",
      "Evaluation/AverageReturn             -1243.97\n",
      "Evaluation/Iteration                    77\n",
      "Evaluation/MaxReturn                 -1169.1\n",
      "Evaluation/MinReturn                 -1320.63\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    52.9219\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.19188\n",
      "GaussianMLPPolicy/KL                     0.00955395\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            135.708\n",
      "GaussianMLPPolicy/LossBefore           136.639\n",
      "GaussianMLPPolicy/dLoss                  0.930038\n",
      "GaussianMLPValueFunction/LossAfter     504.508\n",
      "GaussianMLPValueFunction/LossBefore    529.461\n",
      "GaussianMLPValueFunction/dLoss          24.9533\n",
      "TotalEnvSteps                        93600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:34 | [trpo_pendulum] epoch #78 | Saving snapshot...\n",
      "2022-08-17 18:05:34 | [trpo_pendulum] epoch #78 | Saved\n",
      "2022-08-17 18:05:34 | [trpo_pendulum] epoch #78 | Time 49.85 s\n",
      "2022-08-17 18:05:34 | [trpo_pendulum] epoch #78 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -490.081\n",
      "Evaluation/AverageReturn             -1164.33\n",
      "Evaluation/Iteration                    78\n",
      "Evaluation/MaxReturn                 -1135.04\n",
      "Evaluation/MinReturn                 -1221.23\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    27.0565\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.18692\n",
      "GaussianMLPPolicy/KL                     0.00634159\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            122.241\n",
      "GaussianMLPPolicy/LossBefore           124.088\n",
      "GaussianMLPPolicy/dLoss                  1.84679\n",
      "GaussianMLPValueFunction/LossAfter     406.5\n",
      "GaussianMLPValueFunction/LossBefore    424.431\n",
      "GaussianMLPValueFunction/dLoss          17.9307\n",
      "TotalEnvSteps                        94800\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:34 | [trpo_pendulum] epoch #79 | Saving snapshot...\n",
      "2022-08-17 18:05:34 | [trpo_pendulum] epoch #79 | Saved\n",
      "2022-08-17 18:05:34 | [trpo_pendulum] epoch #79 | Time 50.48 s\n",
      "2022-08-17 18:05:34 | [trpo_pendulum] epoch #79 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -659.719\n",
      "Evaluation/AverageReturn             -1507.22\n",
      "Evaluation/Iteration                    79\n",
      "Evaluation/MaxReturn                 -1504.68\n",
      "Evaluation/MinReturn                 -1510.46\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     1.69571\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.19996\n",
      "GaussianMLPPolicy/KL                     0.00756281\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            167.212\n",
      "GaussianMLPPolicy/LossBefore           168.968\n",
      "GaussianMLPPolicy/dLoss                  1.75682\n",
      "GaussianMLPValueFunction/LossAfter     681.516\n",
      "GaussianMLPValueFunction/LossBefore    732.825\n",
      "GaussianMLPValueFunction/dLoss          51.3097\n",
      "TotalEnvSteps                        96000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:35 | [trpo_pendulum] epoch #80 | Saving snapshot...\n",
      "2022-08-17 18:05:35 | [trpo_pendulum] epoch #80 | Saved\n",
      "2022-08-17 18:05:35 | [trpo_pendulum] epoch #80 | Time 51.11 s\n",
      "2022-08-17 18:05:35 | [trpo_pendulum] epoch #80 | EpochTime 0.63 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn    -581.47\n",
      "Evaluation/AverageReturn             -1435.87\n",
      "Evaluation/Iteration                    80\n",
      "Evaluation/MaxReturn                 -1357.39\n",
      "Evaluation/MinReturn                 -1480.66\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    41.376\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.19631\n",
      "GaussianMLPPolicy/KL                     0.0066716\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            168.169\n",
      "GaussianMLPPolicy/LossBefore           168.279\n",
      "GaussianMLPPolicy/dLoss                  0.10994\n",
      "GaussianMLPValueFunction/LossAfter     635.955\n",
      "GaussianMLPValueFunction/LossBefore    683.695\n",
      "GaussianMLPValueFunction/dLoss          47.7404\n",
      "TotalEnvSteps                        97200\n",
      "-----------------------------------  -------------\n",
      "2022-08-17 18:05:35 | [trpo_pendulum] epoch #81 | Saving snapshot...\n",
      "2022-08-17 18:05:35 | [trpo_pendulum] epoch #81 | Saved\n",
      "2022-08-17 18:05:35 | [trpo_pendulum] epoch #81 | Time 51.73 s\n",
      "2022-08-17 18:05:35 | [trpo_pendulum] epoch #81 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -652.146\n",
      "Evaluation/AverageReturn             -1507.75\n",
      "Evaluation/Iteration                    81\n",
      "Evaluation/MaxReturn                 -1505.55\n",
      "Evaluation/MinReturn                 -1509.67\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     1.37749\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.18279\n",
      "GaussianMLPPolicy/KL                     0.00786775\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            167.198\n",
      "GaussianMLPPolicy/LossBefore           170.174\n",
      "GaussianMLPPolicy/dLoss                  2.97668\n",
      "GaussianMLPValueFunction/LossAfter     603.015\n",
      "GaussianMLPValueFunction/LossBefore    647.813\n",
      "GaussianMLPValueFunction/dLoss          44.7982\n",
      "TotalEnvSteps                        98400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:36 | [trpo_pendulum] epoch #82 | Saving snapshot...\n",
      "2022-08-17 18:05:36 | [trpo_pendulum] epoch #82 | Saved\n",
      "2022-08-17 18:05:36 | [trpo_pendulum] epoch #82 | Time 52.34 s\n",
      "2022-08-17 18:05:36 | [trpo_pendulum] epoch #82 | EpochTime 0.61 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn    -561.246\n",
      "Evaluation/AverageReturn             -1359.45\n",
      "Evaluation/Iteration                    82\n",
      "Evaluation/MaxReturn                 -1336.96\n",
      "Evaluation/MinReturn                 -1416.12\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    27.9306\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.1777\n",
      "GaussianMLPPolicy/KL                     0.0081134\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            150.541\n",
      "GaussianMLPPolicy/LossBefore           152.741\n",
      "GaussianMLPPolicy/dLoss                  2.20023\n",
      "GaussianMLPValueFunction/LossAfter     474.701\n",
      "GaussianMLPValueFunction/LossBefore    504.263\n",
      "GaussianMLPValueFunction/dLoss          29.5629\n",
      "TotalEnvSteps                        99600\n",
      "-----------------------------------  -------------\n",
      "2022-08-17 18:05:37 | [trpo_pendulum] epoch #83 | Saving snapshot...\n",
      "2022-08-17 18:05:37 | [trpo_pendulum] epoch #83 | Saved\n",
      "2022-08-17 18:05:37 | [trpo_pendulum] epoch #83 | Time 52.96 s\n",
      "2022-08-17 18:05:37 | [trpo_pendulum] epoch #83 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -650.095\n",
      "Evaluation/AverageReturn              -1505.06\n",
      "Evaluation/Iteration                     83\n",
      "Evaluation/MaxReturn                  -1502.94\n",
      "Evaluation/MinReturn                  -1508.53\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      1.80826\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.21231\n",
      "GaussianMLPPolicy/KL                      0.00786599\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             166.715\n",
      "GaussianMLPPolicy/LossBefore            169.096\n",
      "GaussianMLPPolicy/dLoss                   2.38161\n",
      "GaussianMLPValueFunction/LossAfter      528.578\n",
      "GaussianMLPValueFunction/LossBefore     566.652\n",
      "GaussianMLPValueFunction/dLoss           38.0738\n",
      "TotalEnvSteps                        100800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:37 | [trpo_pendulum] epoch #84 | Saving snapshot...\n",
      "2022-08-17 18:05:37 | [trpo_pendulum] epoch #84 | Saved\n",
      "2022-08-17 18:05:37 | [trpo_pendulum] epoch #84 | Time 53.60 s\n",
      "2022-08-17 18:05:37 | [trpo_pendulum] epoch #84 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -533.476\n",
      "Evaluation/AverageReturn              -1186.68\n",
      "Evaluation/Iteration                     84\n",
      "Evaluation/MaxReturn                   -966.396\n",
      "Evaluation/MinReturn                  -1284.21\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    104.468\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.21184\n",
      "GaussianMLPPolicy/KL                      0.00878988\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             117.914\n",
      "GaussianMLPPolicy/LossBefore            120.541\n",
      "GaussianMLPPolicy/dLoss                   2.62647\n",
      "GaussianMLPValueFunction/LossAfter      277.361\n",
      "GaussianMLPValueFunction/LossBefore     289.071\n",
      "GaussianMLPValueFunction/dLoss           11.7094\n",
      "TotalEnvSteps                        102000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:38 | [trpo_pendulum] epoch #85 | Saving snapshot...\n",
      "2022-08-17 18:05:38 | [trpo_pendulum] epoch #85 | Saved\n",
      "2022-08-17 18:05:38 | [trpo_pendulum] epoch #85 | Time 54.23 s\n",
      "2022-08-17 18:05:38 | [trpo_pendulum] epoch #85 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -658.54\n",
      "Evaluation/AverageReturn              -1511.14\n",
      "Evaluation/Iteration                     85\n",
      "Evaluation/MaxReturn                  -1507.47\n",
      "Evaluation/MinReturn                  -1516.6\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      3.09983\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.21484\n",
      "GaussianMLPPolicy/KL                      0.00673354\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             165.546\n",
      "GaussianMLPPolicy/LossBefore            167.609\n",
      "GaussianMLPPolicy/dLoss                   2.06218\n",
      "GaussianMLPValueFunction/LossAfter      471.381\n",
      "GaussianMLPValueFunction/LossBefore     505.348\n",
      "GaussianMLPValueFunction/dLoss           33.9672\n",
      "TotalEnvSteps                        103200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:39 | [trpo_pendulum] epoch #86 | Saving snapshot...\n",
      "2022-08-17 18:05:39 | [trpo_pendulum] epoch #86 | Saved\n",
      "2022-08-17 18:05:39 | [trpo_pendulum] epoch #86 | Time 54.85 s\n",
      "2022-08-17 18:05:39 | [trpo_pendulum] epoch #86 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -443.521\n",
      "Evaluation/AverageReturn               -962.925\n",
      "Evaluation/Iteration                     86\n",
      "Evaluation/MaxReturn                   -748.358\n",
      "Evaluation/MinReturn                  -1084.19\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    102.926\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.21026\n",
      "GaussianMLPPolicy/KL                      0.00935717\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              84.8415\n",
      "GaussianMLPPolicy/LossBefore             85.8047\n",
      "GaussianMLPPolicy/dLoss                   0.963219\n",
      "GaussianMLPValueFunction/LossAfter      135.61\n",
      "GaussianMLPValueFunction/LossBefore     139.125\n",
      "GaussianMLPValueFunction/dLoss            3.51506\n",
      "TotalEnvSteps                        104400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:39 | [trpo_pendulum] epoch #87 | Saving snapshot...\n",
      "2022-08-17 18:05:39 | [trpo_pendulum] epoch #87 | Saved\n",
      "2022-08-17 18:05:39 | [trpo_pendulum] epoch #87 | Time 55.46 s\n",
      "2022-08-17 18:05:39 | [trpo_pendulum] epoch #87 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -658.553\n",
      "Evaluation/AverageReturn              -1512.79\n",
      "Evaluation/Iteration                     87\n",
      "Evaluation/MaxReturn                  -1509.79\n",
      "Evaluation/MinReturn                  -1516.69\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      2.43669\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.2334\n",
      "GaussianMLPPolicy/KL                      0.00844781\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             164.324\n",
      "GaussianMLPPolicy/LossBefore            167.277\n",
      "GaussianMLPPolicy/dLoss                   2.95375\n",
      "GaussianMLPValueFunction/LossAfter      430.201\n",
      "GaussianMLPValueFunction/LossBefore     462.277\n",
      "GaussianMLPValueFunction/dLoss           32.0758\n",
      "TotalEnvSteps                        105600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:40 | [trpo_pendulum] epoch #88 | Saving snapshot...\n",
      "2022-08-17 18:05:40 | [trpo_pendulum] epoch #88 | Saved\n",
      "2022-08-17 18:05:40 | [trpo_pendulum] epoch #88 | Time 56.09 s\n",
      "2022-08-17 18:05:40 | [trpo_pendulum] epoch #88 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -467.274\n",
      "Evaluation/AverageReturn              -1106.68\n",
      "Evaluation/Iteration                     88\n",
      "Evaluation/MaxReturn                  -1018.99\n",
      "Evaluation/MinReturn                  -1205.11\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     67.8079\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.246\n",
      "GaussianMLPPolicy/KL                      0.0078909\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             110.635\n",
      "GaussianMLPPolicy/LossBefore            112.017\n",
      "GaussianMLPPolicy/dLoss                   1.3819\n",
      "GaussianMLPValueFunction/LossAfter      197.144\n",
      "GaussianMLPValueFunction/LossBefore     205.007\n",
      "GaussianMLPValueFunction/dLoss            7.86378\n",
      "TotalEnvSteps                        106800\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:40 | [trpo_pendulum] epoch #89 | Saving snapshot...\n",
      "2022-08-17 18:05:40 | [trpo_pendulum] epoch #89 | Saved\n",
      "2022-08-17 18:05:40 | [trpo_pendulum] epoch #89 | Time 56.70 s\n",
      "2022-08-17 18:05:40 | [trpo_pendulum] epoch #89 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -449.99\n",
      "Evaluation/AverageReturn              -1033.67\n",
      "Evaluation/Iteration                     89\n",
      "Evaluation/MaxReturn                   -765.537\n",
      "Evaluation/MinReturn                  -1165.23\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    133.145\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.24596\n",
      "GaussianMLPPolicy/KL                      0.0095529\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              97.9965\n",
      "GaussianMLPPolicy/LossBefore             99.4068\n",
      "GaussianMLPPolicy/dLoss                   1.4103\n",
      "GaussianMLPValueFunction/LossAfter      155.209\n",
      "GaussianMLPValueFunction/LossBefore     160.343\n",
      "GaussianMLPValueFunction/dLoss            5.13432\n",
      "TotalEnvSteps                        108000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:41 | [trpo_pendulum] epoch #90 | Saving snapshot...\n",
      "2022-08-17 18:05:41 | [trpo_pendulum] epoch #90 | Saved\n",
      "2022-08-17 18:05:41 | [trpo_pendulum] epoch #90 | Time 57.32 s\n",
      "2022-08-17 18:05:41 | [trpo_pendulum] epoch #90 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -662.345\n",
      "Evaluation/AverageReturn              -1522.38\n",
      "Evaluation/Iteration                     90\n",
      "Evaluation/MaxReturn                  -1513.46\n",
      "Evaluation/MinReturn                  -1533.71\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      6.60279\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.29421\n",
      "GaussianMLPPolicy/KL                      0.00929743\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             164.688\n",
      "GaussianMLPPolicy/LossBefore            167.595\n",
      "GaussianMLPPolicy/dLoss                   2.90683\n",
      "GaussianMLPValueFunction/LossAfter      378.784\n",
      "GaussianMLPValueFunction/LossBefore     409.58\n",
      "GaussianMLPValueFunction/dLoss           30.7961\n",
      "TotalEnvSteps                        109200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:42 | [trpo_pendulum] epoch #91 | Saving snapshot...\n",
      "2022-08-17 18:05:42 | [trpo_pendulum] epoch #91 | Saved\n",
      "2022-08-17 18:05:42 | [trpo_pendulum] epoch #91 | Time 57.94 s\n",
      "2022-08-17 18:05:42 | [trpo_pendulum] epoch #91 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -661.209\n",
      "Evaluation/AverageReturn              -1513.59\n",
      "Evaluation/Iteration                     91\n",
      "Evaluation/MaxReturn                  -1510.16\n",
      "Evaluation/MinReturn                  -1520.58\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      3.61789\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.32793\n",
      "GaussianMLPPolicy/KL                      0.00632201\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             163.322\n",
      "GaussianMLPPolicy/LossBefore            165.149\n",
      "GaussianMLPPolicy/dLoss                   1.82701\n",
      "GaussianMLPValueFunction/LossAfter      342.246\n",
      "GaussianMLPValueFunction/LossBefore     369.104\n",
      "GaussianMLPValueFunction/dLoss           26.8577\n",
      "TotalEnvSteps                        110400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:42 | [trpo_pendulum] epoch #92 | Saving snapshot...\n",
      "2022-08-17 18:05:42 | [trpo_pendulum] epoch #92 | Saved\n",
      "2022-08-17 18:05:42 | [trpo_pendulum] epoch #92 | Time 58.57 s\n",
      "2022-08-17 18:05:42 | [trpo_pendulum] epoch #92 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -497.558\n",
      "Evaluation/AverageReturn              -1038.21\n",
      "Evaluation/Iteration                     92\n",
      "Evaluation/MaxReturn                   -939.039\n",
      "Evaluation/MinReturn                  -1152.87\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     73.8904\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.32737\n",
      "GaussianMLPPolicy/KL                      0.00784701\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              90.6295\n",
      "GaussianMLPPolicy/LossBefore             92.6727\n",
      "GaussianMLPPolicy/dLoss                   2.04321\n",
      "GaussianMLPValueFunction/LossAfter      123\n",
      "GaussianMLPValueFunction/LossBefore     126.893\n",
      "GaussianMLPValueFunction/dLoss            3.89254\n",
      "TotalEnvSteps                        111600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:43 | [trpo_pendulum] epoch #93 | Saving snapshot...\n",
      "2022-08-17 18:05:43 | [trpo_pendulum] epoch #93 | Saved\n",
      "2022-08-17 18:05:43 | [trpo_pendulum] epoch #93 | Time 59.17 s\n",
      "2022-08-17 18:05:43 | [trpo_pendulum] epoch #93 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -376.52\n",
      "Evaluation/AverageReturn               -877.496\n",
      "Evaluation/Iteration                     93\n",
      "Evaluation/MaxReturn                   -633.522\n",
      "Evaluation/MinReturn                   -985.958\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    118.568\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.32945\n",
      "GaussianMLPPolicy/KL                      0.00638536\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              75.6927\n",
      "GaussianMLPPolicy/LossBefore             76.5765\n",
      "GaussianMLPPolicy/dLoss                   0.88385\n",
      "GaussianMLPValueFunction/LossAfter       85.1563\n",
      "GaussianMLPValueFunction/LossBefore      87.1539\n",
      "GaussianMLPValueFunction/dLoss            1.99758\n",
      "TotalEnvSteps                        112800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:44 | [trpo_pendulum] epoch #94 | Saving snapshot...\n",
      "2022-08-17 18:05:44 | [trpo_pendulum] epoch #94 | Saved\n",
      "2022-08-17 18:05:44 | [trpo_pendulum] epoch #94 | Time 59.80 s\n",
      "2022-08-17 18:05:44 | [trpo_pendulum] epoch #94 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -358.217\n",
      "Evaluation/AverageReturn               -842.434\n",
      "Evaluation/Iteration                     94\n",
      "Evaluation/MaxReturn                   -757.402\n",
      "Evaluation/MinReturn                   -967.7\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     69.0395\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.32155\n",
      "GaussianMLPPolicy/KL                      0.00690715\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              72.7598\n",
      "GaussianMLPPolicy/LossBefore             73.9479\n",
      "GaussianMLPPolicy/dLoss                   1.18811\n",
      "GaussianMLPValueFunction/LossAfter       76.2726\n",
      "GaussianMLPValueFunction/LossBefore      78.0023\n",
      "GaussianMLPValueFunction/dLoss            1.72971\n",
      "TotalEnvSteps                        114000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:44 | [trpo_pendulum] epoch #95 | Saving snapshot...\n",
      "2022-08-17 18:05:44 | [trpo_pendulum] epoch #95 | Saved\n",
      "2022-08-17 18:05:44 | [trpo_pendulum] epoch #95 | Time 60.43 s\n",
      "2022-08-17 18:05:44 | [trpo_pendulum] epoch #95 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -390.012\n",
      "Evaluation/AverageReturn               -888.507\n",
      "Evaluation/Iteration                     95\n",
      "Evaluation/MaxReturn                   -790.664\n",
      "Evaluation/MinReturn                   -965.114\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     60.3403\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.32074\n",
      "GaussianMLPPolicy/KL                      0.0083933\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              73.2889\n",
      "GaussianMLPPolicy/LossBefore             75.0217\n",
      "GaussianMLPPolicy/dLoss                   1.73285\n",
      "GaussianMLPValueFunction/LossAfter       74.7843\n",
      "GaussianMLPValueFunction/LossBefore      76.6295\n",
      "GaussianMLPValueFunction/dLoss            1.8452\n",
      "TotalEnvSteps                        115200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:45 | [trpo_pendulum] epoch #96 | Saving snapshot...\n",
      "2022-08-17 18:05:45 | [trpo_pendulum] epoch #96 | Saved\n",
      "2022-08-17 18:05:45 | [trpo_pendulum] epoch #96 | Time 61.07 s\n",
      "2022-08-17 18:05:45 | [trpo_pendulum] epoch #96 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -336.625\n",
      "Evaluation/AverageReturn               -832.341\n",
      "Evaluation/Iteration                     96\n",
      "Evaluation/MaxReturn                   -668.739\n",
      "Evaluation/MinReturn                   -873.755\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     73.4874\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.30338\n",
      "GaussianMLPPolicy/KL                      0.00931518\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              72.2784\n",
      "GaussianMLPPolicy/LossBefore             73.5409\n",
      "GaussianMLPPolicy/dLoss                   1.26246\n",
      "GaussianMLPValueFunction/LossAfter       70.8513\n",
      "GaussianMLPValueFunction/LossBefore      72.6734\n",
      "GaussianMLPValueFunction/dLoss            1.8221\n",
      "TotalEnvSteps                        116400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:45 | [trpo_pendulum] epoch #97 | Saving snapshot...\n",
      "2022-08-17 18:05:45 | [trpo_pendulum] epoch #97 | Saved\n",
      "2022-08-17 18:05:45 | [trpo_pendulum] epoch #97 | Time 61.70 s\n",
      "2022-08-17 18:05:45 | [trpo_pendulum] epoch #97 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -660.382\n",
      "Evaluation/AverageReturn              -1514.98\n",
      "Evaluation/Iteration                     97\n",
      "Evaluation/MaxReturn                  -1507.01\n",
      "Evaluation/MinReturn                  -1525.53\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      6.25886\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.30981\n",
      "GaussianMLPPolicy/KL                      0.00977101\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             161.831\n",
      "GaussianMLPPolicy/LossBefore            163.871\n",
      "GaussianMLPPolicy/dLoss                   2.04057\n",
      "GaussianMLPValueFunction/LossAfter      277.891\n",
      "GaussianMLPValueFunction/LossBefore     305.58\n",
      "GaussianMLPValueFunction/dLoss           27.6883\n",
      "TotalEnvSteps                        117600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:46 | [trpo_pendulum] epoch #98 | Saving snapshot...\n",
      "2022-08-17 18:05:46 | [trpo_pendulum] epoch #98 | Saved\n",
      "2022-08-17 18:05:46 | [trpo_pendulum] epoch #98 | Time 62.34 s\n",
      "2022-08-17 18:05:46 | [trpo_pendulum] epoch #98 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -659.361\n",
      "Evaluation/AverageReturn              -1512.62\n",
      "Evaluation/Iteration                     98\n",
      "Evaluation/MaxReturn                  -1506.9\n",
      "Evaluation/MinReturn                  -1523.82\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      6.09634\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.30874\n",
      "GaussianMLPPolicy/KL                      0.00779661\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             161.315\n",
      "GaussianMLPPolicy/LossBefore            162.677\n",
      "GaussianMLPPolicy/dLoss                   1.36244\n",
      "GaussianMLPValueFunction/LossAfter      252.125\n",
      "GaussianMLPValueFunction/LossBefore     275.869\n",
      "GaussianMLPValueFunction/dLoss           23.7446\n",
      "TotalEnvSteps                        118800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:47 | [trpo_pendulum] epoch #99 | Saving snapshot...\n",
      "2022-08-17 18:05:47 | [trpo_pendulum] epoch #99 | Saved\n",
      "2022-08-17 18:05:47 | [trpo_pendulum] epoch #99 | Time 62.98 s\n",
      "2022-08-17 18:05:47 | [trpo_pendulum] epoch #99 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -648.506\n",
      "Evaluation/AverageReturn              -1505.33\n",
      "Evaluation/Iteration                     99\n",
      "Evaluation/MaxReturn                  -1500.08\n",
      "Evaluation/MinReturn                  -1512.08\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      3.73053\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.31945\n",
      "GaussianMLPPolicy/KL                      0.00680731\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             161.471\n",
      "GaussianMLPPolicy/LossBefore            163.246\n",
      "GaussianMLPPolicy/dLoss                   1.77446\n",
      "GaussianMLPValueFunction/LossAfter      234.559\n",
      "GaussianMLPValueFunction/LossBefore     255.44\n",
      "GaussianMLPValueFunction/dLoss           20.8807\n",
      "TotalEnvSteps                        120000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:47 | [trpo_pendulum] epoch #100 | Saving snapshot...\n",
      "2022-08-17 18:05:47 | [trpo_pendulum] epoch #100 | Saved\n",
      "2022-08-17 18:05:47 | [trpo_pendulum] epoch #100 | Time 63.59 s\n",
      "2022-08-17 18:05:47 | [trpo_pendulum] epoch #100 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -656.093\n",
      "Evaluation/AverageReturn              -1510.96\n",
      "Evaluation/Iteration                    100\n",
      "Evaluation/MaxReturn                  -1504.17\n",
      "Evaluation/MinReturn                  -1516.58\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      3.83684\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.32194\n",
      "GaussianMLPPolicy/KL                      0.00764064\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             160.532\n",
      "GaussianMLPPolicy/LossBefore            162.329\n",
      "GaussianMLPPolicy/dLoss                   1.79738\n",
      "GaussianMLPValueFunction/LossAfter      215.458\n",
      "GaussianMLPValueFunction/LossBefore     233.463\n",
      "GaussianMLPValueFunction/dLoss           18.0041\n",
      "TotalEnvSteps                        121200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:48 | [trpo_pendulum] epoch #101 | Saving snapshot...\n",
      "2022-08-17 18:05:48 | [trpo_pendulum] epoch #101 | Saved\n",
      "2022-08-17 18:05:48 | [trpo_pendulum] epoch #101 | Time 64.22 s\n",
      "2022-08-17 18:05:48 | [trpo_pendulum] epoch #101 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -390.669\n",
      "Evaluation/AverageReturn              -1144.38\n",
      "Evaluation/Iteration                    101\n",
      "Evaluation/MaxReturn                   -982.897\n",
      "Evaluation/MinReturn                  -1221.84\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     85.6858\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.32738\n",
      "GaussianMLPPolicy/KL                      0.00723165\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             124.297\n",
      "GaussianMLPPolicy/LossBefore            126.805\n",
      "GaussianMLPPolicy/dLoss                   2.50802\n",
      "GaussianMLPValueFunction/LossAfter      137.717\n",
      "GaussianMLPValueFunction/LossBefore     145.564\n",
      "GaussianMLPValueFunction/dLoss            7.84688\n",
      "TotalEnvSteps                        122400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:49 | [trpo_pendulum] epoch #102 | Saving snapshot...\n",
      "2022-08-17 18:05:49 | [trpo_pendulum] epoch #102 | Saved\n",
      "2022-08-17 18:05:49 | [trpo_pendulum] epoch #102 | Time 64.84 s\n",
      "2022-08-17 18:05:49 | [trpo_pendulum] epoch #102 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -570.37\n",
      "Evaluation/AverageReturn              -1413.21\n",
      "Evaluation/Iteration                    102\n",
      "Evaluation/MaxReturn                  -1392.71\n",
      "Evaluation/MinReturn                  -1440.9\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     18.3295\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.33268\n",
      "GaussianMLPPolicy/KL                      0.00690781\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             153.484\n",
      "GaussianMLPPolicy/LossBefore            155.554\n",
      "GaussianMLPPolicy/dLoss                   2.07088\n",
      "GaussianMLPValueFunction/LossAfter      179.949\n",
      "GaussianMLPValueFunction/LossBefore     193.609\n",
      "GaussianMLPValueFunction/dLoss           13.6606\n",
      "TotalEnvSteps                        123600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:49 | [trpo_pendulum] epoch #103 | Saving snapshot...\n",
      "2022-08-17 18:05:49 | [trpo_pendulum] epoch #103 | Saved\n",
      "2022-08-17 18:05:49 | [trpo_pendulum] epoch #103 | Time 65.47 s\n",
      "2022-08-17 18:05:49 | [trpo_pendulum] epoch #103 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -582.678\n",
      "Evaluation/AverageReturn              -1427.54\n",
      "Evaluation/Iteration                    103\n",
      "Evaluation/MaxReturn                  -1406.48\n",
      "Evaluation/MinReturn                  -1455.26\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     15.5925\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.31698\n",
      "GaussianMLPPolicy/KL                      0.00598143\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             153.413\n",
      "GaussianMLPPolicy/LossBefore            155.713\n",
      "GaussianMLPPolicy/dLoss                   2.30026\n",
      "GaussianMLPValueFunction/LossAfter      168.579\n",
      "GaussianMLPValueFunction/LossBefore     181.195\n",
      "GaussianMLPValueFunction/dLoss           12.6168\n",
      "TotalEnvSteps                        124800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:50 | [trpo_pendulum] epoch #104 | Saving snapshot...\n",
      "2022-08-17 18:05:50 | [trpo_pendulum] epoch #104 | Saved\n",
      "2022-08-17 18:05:50 | [trpo_pendulum] epoch #104 | Time 66.11 s\n",
      "2022-08-17 18:05:50 | [trpo_pendulum] epoch #104 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -571.907\n",
      "Evaluation/AverageReturn              -1423.41\n",
      "Evaluation/Iteration                    104\n",
      "Evaluation/MaxReturn                  -1407.35\n",
      "Evaluation/MinReturn                  -1437.63\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     10.5277\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.31016\n",
      "GaussianMLPPolicy/KL                      0.00669109\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             153.886\n",
      "GaussianMLPPolicy/LossBefore            156.872\n",
      "GaussianMLPPolicy/dLoss                   2.98538\n",
      "GaussianMLPValueFunction/LossAfter      160.457\n",
      "GaussianMLPValueFunction/LossBefore     172.365\n",
      "GaussianMLPValueFunction/dLoss           11.908\n",
      "TotalEnvSteps                        126000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:50 | [trpo_pendulum] epoch #105 | Saving snapshot...\n",
      "2022-08-17 18:05:50 | [trpo_pendulum] epoch #105 | Saved\n",
      "2022-08-17 18:05:50 | [trpo_pendulum] epoch #105 | Time 66.71 s\n",
      "2022-08-17 18:05:50 | [trpo_pendulum] epoch #105 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -662.733\n",
      "Evaluation/AverageReturn              -1518.48\n",
      "Evaluation/Iteration                    105\n",
      "Evaluation/MaxReturn                  -1513.93\n",
      "Evaluation/MinReturn                  -1523.59\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      3.17643\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.33568\n",
      "GaussianMLPPolicy/KL                      0.00866118\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             158.305\n",
      "GaussianMLPPolicy/LossBefore            159.667\n",
      "GaussianMLPPolicy/dLoss                   1.3616\n",
      "GaussianMLPValueFunction/LossAfter      152.663\n",
      "GaussianMLPValueFunction/LossBefore     163.885\n",
      "GaussianMLPValueFunction/dLoss           11.2222\n",
      "TotalEnvSteps                        127200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:51 | [trpo_pendulum] epoch #106 | Saving snapshot...\n",
      "2022-08-17 18:05:51 | [trpo_pendulum] epoch #106 | Saved\n",
      "2022-08-17 18:05:51 | [trpo_pendulum] epoch #106 | Time 67.34 s\n",
      "2022-08-17 18:05:51 | [trpo_pendulum] epoch #106 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -644.12\n",
      "Evaluation/AverageReturn              -1502.37\n",
      "Evaluation/Iteration                    106\n",
      "Evaluation/MaxReturn                  -1490.8\n",
      "Evaluation/MinReturn                  -1512.2\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      6.61324\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38348\n",
      "GaussianMLPPolicy/KL                      0.00902623\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             158.023\n",
      "GaussianMLPPolicy/LossBefore            160.067\n",
      "GaussianMLPPolicy/dLoss                   2.04321\n",
      "GaussianMLPValueFunction/LossAfter      144.102\n",
      "GaussianMLPValueFunction/LossBefore     154.531\n",
      "GaussianMLPValueFunction/dLoss           10.4284\n",
      "TotalEnvSteps                        128400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:52 | [trpo_pendulum] epoch #107 | Saving snapshot...\n",
      "2022-08-17 18:05:52 | [trpo_pendulum] epoch #107 | Saved\n",
      "2022-08-17 18:05:52 | [trpo_pendulum] epoch #107 | Time 67.97 s\n",
      "2022-08-17 18:05:52 | [trpo_pendulum] epoch #107 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -596.742\n",
      "Evaluation/AverageReturn              -1454.25\n",
      "Evaluation/Iteration                    107\n",
      "Evaluation/MaxReturn                  -1443.53\n",
      "Evaluation/MinReturn                  -1464.41\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      7.93536\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.411\n",
      "GaussianMLPPolicy/KL                      0.00972998\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             154.85\n",
      "GaussianMLPPolicy/LossBefore            157.86\n",
      "GaussianMLPPolicy/dLoss                   3.01076\n",
      "GaussianMLPValueFunction/LossAfter      133.214\n",
      "GaussianMLPValueFunction/LossBefore     142.524\n",
      "GaussianMLPValueFunction/dLoss            9.30951\n",
      "TotalEnvSteps                        129600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:52 | [trpo_pendulum] epoch #108 | Saving snapshot...\n",
      "2022-08-17 18:05:52 | [trpo_pendulum] epoch #108 | Saved\n",
      "2022-08-17 18:05:52 | [trpo_pendulum] epoch #108 | Time 68.58 s\n",
      "2022-08-17 18:05:52 | [trpo_pendulum] epoch #108 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -533.88\n",
      "Evaluation/AverageReturn              -1371.02\n",
      "Evaluation/Iteration                    108\n",
      "Evaluation/MaxReturn                  -1288.56\n",
      "Evaluation/MinReturn                  -1410.44\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     41.1704\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.39987\n",
      "GaussianMLPPolicy/KL                      0.00877982\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             146.353\n",
      "GaussianMLPPolicy/LossBefore            149.245\n",
      "GaussianMLPPolicy/dLoss                   2.8922\n",
      "GaussianMLPValueFunction/LossAfter      115.876\n",
      "GaussianMLPValueFunction/LossBefore     123.274\n",
      "GaussianMLPValueFunction/dLoss            7.39783\n",
      "TotalEnvSteps                        130800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:53 | [trpo_pendulum] epoch #109 | Saving snapshot...\n",
      "2022-08-17 18:05:53 | [trpo_pendulum] epoch #109 | Saved\n",
      "2022-08-17 18:05:53 | [trpo_pendulum] epoch #109 | Time 69.20 s\n",
      "2022-08-17 18:05:53 | [trpo_pendulum] epoch #109 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -602.457\n",
      "Evaluation/AverageReturn              -1462.19\n",
      "Evaluation/Iteration                    109\n",
      "Evaluation/MaxReturn                  -1447.1\n",
      "Evaluation/MinReturn                  -1470.56\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      8.49246\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.40296\n",
      "GaussianMLPPolicy/KL                      0.00978456\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             153.921\n",
      "GaussianMLPPolicy/LossBefore            157.197\n",
      "GaussianMLPPolicy/dLoss                   3.27522\n",
      "GaussianMLPValueFunction/LossAfter      117.422\n",
      "GaussianMLPValueFunction/LossBefore     125.377\n",
      "GaussianMLPValueFunction/dLoss            7.95563\n",
      "TotalEnvSteps                        132000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:54 | [trpo_pendulum] epoch #110 | Saving snapshot...\n",
      "2022-08-17 18:05:54 | [trpo_pendulum] epoch #110 | Saved\n",
      "2022-08-17 18:05:54 | [trpo_pendulum] epoch #110 | Time 69.82 s\n",
      "2022-08-17 18:05:54 | [trpo_pendulum] epoch #110 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -640.757\n",
      "Evaluation/AverageReturn              -1507.26\n",
      "Evaluation/Iteration                    110\n",
      "Evaluation/MaxReturn                  -1492.74\n",
      "Evaluation/MinReturn                  -1518.87\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      9.11295\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.4143\n",
      "GaussianMLPPolicy/KL                      0.00808053\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             157.229\n",
      "GaussianMLPPolicy/LossBefore            159.766\n",
      "GaussianMLPPolicy/dLoss                   2.53728\n",
      "GaussianMLPValueFunction/LossAfter      113.345\n",
      "GaussianMLPValueFunction/LossBefore     121.128\n",
      "GaussianMLPValueFunction/dLoss            7.78316\n",
      "TotalEnvSteps                        133200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:54 | [trpo_pendulum] epoch #111 | Saving snapshot...\n",
      "2022-08-17 18:05:54 | [trpo_pendulum] epoch #111 | Saved\n",
      "2022-08-17 18:05:54 | [trpo_pendulum] epoch #111 | Time 70.45 s\n",
      "2022-08-17 18:05:54 | [trpo_pendulum] epoch #111 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -664.193\n",
      "Evaluation/AverageReturn              -1533.15\n",
      "Evaluation/Iteration                    111\n",
      "Evaluation/MaxReturn                  -1522.52\n",
      "Evaluation/MinReturn                  -1544.54\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      8.61496\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.39751\n",
      "GaussianMLPPolicy/KL                      0.0097255\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             158.053\n",
      "GaussianMLPPolicy/LossBefore            160.558\n",
      "GaussianMLPPolicy/dLoss                   2.50558\n",
      "GaussianMLPValueFunction/LossAfter      107.154\n",
      "GaussianMLPValueFunction/LossBefore     114.44\n",
      "GaussianMLPValueFunction/dLoss            7.28661\n",
      "TotalEnvSteps                        134400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:05:55 | [trpo_pendulum] epoch #112 | Saving snapshot...\n",
      "2022-08-17 18:05:55 | [trpo_pendulum] epoch #112 | Saved\n",
      "2022-08-17 18:05:55 | [trpo_pendulum] epoch #112 | Time 71.07 s\n",
      "2022-08-17 18:05:55 | [trpo_pendulum] epoch #112 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -657.096\n",
      "Evaluation/AverageReturn              -1521.8\n",
      "Evaluation/Iteration                    112\n",
      "Evaluation/MaxReturn                  -1516.16\n",
      "Evaluation/MinReturn                  -1532.53\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.14899\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.3977\n",
      "GaussianMLPPolicy/KL                      0.00719097\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             156.819\n",
      "GaussianMLPPolicy/LossBefore            158.889\n",
      "GaussianMLPPolicy/dLoss                   2.06982\n",
      "GaussianMLPValueFunction/LossAfter       99.2397\n",
      "GaussianMLPValueFunction/LossBefore     105.783\n",
      "GaussianMLPValueFunction/dLoss            6.54289\n",
      "TotalEnvSteps                        135600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:55 | [trpo_pendulum] epoch #113 | Saving snapshot...\n",
      "2022-08-17 18:05:55 | [trpo_pendulum] epoch #113 | Saved\n",
      "2022-08-17 18:05:55 | [trpo_pendulum] epoch #113 | Time 71.69 s\n",
      "2022-08-17 18:05:55 | [trpo_pendulum] epoch #113 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -643.27\n",
      "Evaluation/AverageReturn              -1507.27\n",
      "Evaluation/Iteration                    113\n",
      "Evaluation/MaxReturn                  -1493.9\n",
      "Evaluation/MinReturn                  -1517.43\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      6.9363\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.39553\n",
      "GaussianMLPPolicy/KL                      0.00950533\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             155.308\n",
      "GaussianMLPPolicy/LossBefore            157.892\n",
      "GaussianMLPPolicy/dLoss                   2.58363\n",
      "GaussianMLPValueFunction/LossAfter       92.6204\n",
      "GaussianMLPValueFunction/LossBefore      98.594\n",
      "GaussianMLPValueFunction/dLoss            5.97352\n",
      "TotalEnvSteps                        136800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:56 | [trpo_pendulum] epoch #114 | Saving snapshot...\n",
      "2022-08-17 18:05:56 | [trpo_pendulum] epoch #114 | Saved\n",
      "2022-08-17 18:05:56 | [trpo_pendulum] epoch #114 | Time 72.30 s\n",
      "2022-08-17 18:05:56 | [trpo_pendulum] epoch #114 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -324.48\n",
      "Evaluation/AverageReturn              -1070.13\n",
      "Evaluation/Iteration                    114\n",
      "Evaluation/MaxReturn                  -1010.3\n",
      "Evaluation/MinReturn                  -1142.16\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     49.1829\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37312\n",
      "GaussianMLPPolicy/KL                      0.00686011\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             112.9\n",
      "GaussianMLPPolicy/LossBefore            114.949\n",
      "GaussianMLPPolicy/dLoss                   2.04916\n",
      "GaussianMLPValueFunction/LossAfter       57.4515\n",
      "GaussianMLPValueFunction/LossBefore      59.8623\n",
      "GaussianMLPValueFunction/dLoss            2.41085\n",
      "TotalEnvSteps                        138000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:57 | [trpo_pendulum] epoch #115 | Saving snapshot...\n",
      "2022-08-17 18:05:57 | [trpo_pendulum] epoch #115 | Saved\n",
      "2022-08-17 18:05:57 | [trpo_pendulum] epoch #115 | Time 72.92 s\n",
      "2022-08-17 18:05:57 | [trpo_pendulum] epoch #115 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -564.906\n",
      "Evaluation/AverageReturn              -1415.93\n",
      "Evaluation/Iteration                    115\n",
      "Evaluation/MaxReturn                  -1404.99\n",
      "Evaluation/MinReturn                  -1431.45\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     10.1948\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.35198\n",
      "GaussianMLPPolicy/KL                      0.00681072\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             148.647\n",
      "GaussianMLPPolicy/LossBefore            151.201\n",
      "GaussianMLPPolicy/dLoss                   2.55392\n",
      "GaussianMLPValueFunction/LossAfter       79.2384\n",
      "GaussianMLPValueFunction/LossBefore      84.0962\n",
      "GaussianMLPValueFunction/dLoss            4.85776\n",
      "TotalEnvSteps                        139200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:57 | [trpo_pendulum] epoch #116 | Saving snapshot...\n",
      "2022-08-17 18:05:57 | [trpo_pendulum] epoch #116 | Saved\n",
      "2022-08-17 18:05:57 | [trpo_pendulum] epoch #116 | Time 73.56 s\n",
      "2022-08-17 18:05:57 | [trpo_pendulum] epoch #116 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -624.504\n",
      "Evaluation/AverageReturn              -1490.32\n",
      "Evaluation/Iteration                    116\n",
      "Evaluation/MaxReturn                  -1477.32\n",
      "Evaluation/MinReturn                  -1499.68\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      7.92015\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38795\n",
      "GaussianMLPPolicy/KL                      0.00978314\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             152.573\n",
      "GaussianMLPPolicy/LossBefore            156.452\n",
      "GaussianMLPPolicy/dLoss                   3.87904\n",
      "GaussianMLPValueFunction/LossAfter       78.6904\n",
      "GaussianMLPValueFunction/LossBefore      83.802\n",
      "GaussianMLPValueFunction/dLoss            5.11156\n",
      "TotalEnvSteps                        140400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:58 | [trpo_pendulum] epoch #117 | Saving snapshot...\n",
      "2022-08-17 18:05:58 | [trpo_pendulum] epoch #117 | Saved\n",
      "2022-08-17 18:05:58 | [trpo_pendulum] epoch #117 | Time 74.20 s\n",
      "2022-08-17 18:05:58 | [trpo_pendulum] epoch #117 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -645.374\n",
      "Evaluation/AverageReturn              -1510.28\n",
      "Evaluation/Iteration                    117\n",
      "Evaluation/MaxReturn                  -1498.85\n",
      "Evaluation/MinReturn                  -1529.9\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     10.4937\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.40215\n",
      "GaussianMLPPolicy/KL                      0.00893921\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             153.87\n",
      "GaussianMLPPolicy/LossBefore            156.28\n",
      "GaussianMLPPolicy/dLoss                   2.40958\n",
      "GaussianMLPValueFunction/LossAfter       74.3586\n",
      "GaussianMLPValueFunction/LossBefore      79.1433\n",
      "GaussianMLPValueFunction/dLoss            4.7847\n",
      "TotalEnvSteps                        141600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:59 | [trpo_pendulum] epoch #118 | Saving snapshot...\n",
      "2022-08-17 18:05:59 | [trpo_pendulum] epoch #118 | Saved\n",
      "2022-08-17 18:05:59 | [trpo_pendulum] epoch #118 | Time 74.81 s\n",
      "2022-08-17 18:05:59 | [trpo_pendulum] epoch #118 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -562.729\n",
      "Evaluation/AverageReturn              -1408.29\n",
      "Evaluation/Iteration                    118\n",
      "Evaluation/MaxReturn                  -1359.52\n",
      "Evaluation/MinReturn                  -1462.99\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     37.3531\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.36217\n",
      "GaussianMLPPolicy/KL                      0.00720368\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             144.16\n",
      "GaussianMLPPolicy/LossBefore            147.402\n",
      "GaussianMLPPolicy/dLoss                   3.24147\n",
      "GaussianMLPValueFunction/LossAfter       64.4019\n",
      "GaussianMLPValueFunction/LossBefore      68.1533\n",
      "GaussianMLPValueFunction/dLoss            3.7514\n",
      "TotalEnvSteps                        142800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:05:59 | [trpo_pendulum] epoch #119 | Saving snapshot...\n",
      "2022-08-17 18:05:59 | [trpo_pendulum] epoch #119 | Saved\n",
      "2022-08-17 18:05:59 | [trpo_pendulum] epoch #119 | Time 75.44 s\n",
      "2022-08-17 18:05:59 | [trpo_pendulum] epoch #119 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -592.427\n",
      "Evaluation/AverageReturn              -1450.78\n",
      "Evaluation/Iteration                    119\n",
      "Evaluation/MaxReturn                  -1398.88\n",
      "Evaluation/MinReturn                  -1481.84\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     25.4431\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38284\n",
      "GaussianMLPPolicy/KL                      0.00691496\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             150.587\n",
      "GaussianMLPPolicy/LossBefore            151.91\n",
      "GaussianMLPPolicy/dLoss                   1.32324\n",
      "GaussianMLPValueFunction/LossAfter       63.7946\n",
      "GaussianMLPValueFunction/LossBefore      67.6662\n",
      "GaussianMLPValueFunction/dLoss            3.8716\n",
      "TotalEnvSteps                        144000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:00 | [trpo_pendulum] epoch #120 | Saving snapshot...\n",
      "2022-08-17 18:06:00 | [trpo_pendulum] epoch #120 | Saved\n",
      "2022-08-17 18:06:00 | [trpo_pendulum] epoch #120 | Time 76.07 s\n",
      "2022-08-17 18:06:00 | [trpo_pendulum] epoch #120 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -624.216\n",
      "Evaluation/AverageReturn              -1491\n",
      "Evaluation/Iteration                    120\n",
      "Evaluation/MaxReturn                  -1479.22\n",
      "Evaluation/MinReturn                  -1512.91\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     11.1496\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37627\n",
      "GaussianMLPPolicy/KL                      0.0070352\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             152.235\n",
      "GaussianMLPPolicy/LossBefore            154.751\n",
      "GaussianMLPPolicy/dLoss                   2.51614\n",
      "GaussianMLPValueFunction/LossAfter       62.3415\n",
      "GaussianMLPValueFunction/LossBefore      66.2232\n",
      "GaussianMLPValueFunction/dLoss            3.88176\n",
      "TotalEnvSteps                        145200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:06:00 | [trpo_pendulum] epoch #121 | Saving snapshot...\n",
      "2022-08-17 18:06:00 | [trpo_pendulum] epoch #121 | Saved\n",
      "2022-08-17 18:06:00 | [trpo_pendulum] epoch #121 | Time 76.70 s\n",
      "2022-08-17 18:06:00 | [trpo_pendulum] epoch #121 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -626.442\n",
      "Evaluation/AverageReturn              -1488.16\n",
      "Evaluation/Iteration                    121\n",
      "Evaluation/MaxReturn                  -1477.43\n",
      "Evaluation/MinReturn                  -1496.72\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.7508\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37735\n",
      "GaussianMLPPolicy/KL                      0.00769456\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             151.085\n",
      "GaussianMLPPolicy/LossBefore            153.197\n",
      "GaussianMLPPolicy/dLoss                   2.11188\n",
      "GaussianMLPValueFunction/LossAfter       58.0721\n",
      "GaussianMLPValueFunction/LossBefore      61.6014\n",
      "GaussianMLPValueFunction/dLoss            3.5293\n",
      "TotalEnvSteps                        146400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:01 | [trpo_pendulum] epoch #122 | Saving snapshot...\n",
      "2022-08-17 18:06:01 | [trpo_pendulum] epoch #122 | Saved\n",
      "2022-08-17 18:06:01 | [trpo_pendulum] epoch #122 | Time 77.34 s\n",
      "2022-08-17 18:06:01 | [trpo_pendulum] epoch #122 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -666.355\n",
      "Evaluation/AverageReturn              -1537.16\n",
      "Evaluation/Iteration                    122\n",
      "Evaluation/MaxReturn                  -1523.73\n",
      "Evaluation/MinReturn                  -1552.52\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     10.699\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.35014\n",
      "GaussianMLPPolicy/KL                      0.00752858\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             154.078\n",
      "GaussianMLPPolicy/LossBefore            156.004\n",
      "GaussianMLPPolicy/dLoss                   1.9263\n",
      "GaussianMLPValueFunction/LossAfter       56.3443\n",
      "GaussianMLPValueFunction/LossBefore      59.8293\n",
      "GaussianMLPValueFunction/dLoss            3.485\n",
      "TotalEnvSteps                        147600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:02 | [trpo_pendulum] epoch #123 | Saving snapshot...\n",
      "2022-08-17 18:06:02 | [trpo_pendulum] epoch #123 | Saved\n",
      "2022-08-17 18:06:02 | [trpo_pendulum] epoch #123 | Time 77.96 s\n",
      "2022-08-17 18:06:02 | [trpo_pendulum] epoch #123 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -671.045\n",
      "Evaluation/AverageReturn              -1535.23\n",
      "Evaluation/Iteration                    123\n",
      "Evaluation/MaxReturn                  -1524.8\n",
      "Evaluation/MinReturn                  -1546.53\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      7.94749\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.36077\n",
      "GaussianMLPPolicy/KL                      0.00973557\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             152.627\n",
      "GaussianMLPPolicy/LossBefore            153.8\n",
      "GaussianMLPPolicy/dLoss                   1.17325\n",
      "GaussianMLPValueFunction/LossAfter       52.0585\n",
      "GaussianMLPValueFunction/LossBefore      55.1616\n",
      "GaussianMLPValueFunction/dLoss            3.1031\n",
      "TotalEnvSteps                        148800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:02 | [trpo_pendulum] epoch #124 | Saving snapshot...\n",
      "2022-08-17 18:06:02 | [trpo_pendulum] epoch #124 | Saved\n",
      "2022-08-17 18:06:02 | [trpo_pendulum] epoch #124 | Time 78.59 s\n",
      "2022-08-17 18:06:02 | [trpo_pendulum] epoch #124 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -555.339\n",
      "Evaluation/AverageReturn              -1418.29\n",
      "Evaluation/Iteration                    124\n",
      "Evaluation/MaxReturn                  -1390.51\n",
      "Evaluation/MinReturn                  -1439.08\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     15.7455\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.3673\n",
      "GaussianMLPPolicy/KL                      0.00646781\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             147.184\n",
      "GaussianMLPPolicy/LossBefore            149.594\n",
      "GaussianMLPPolicy/dLoss                   2.41093\n",
      "GaussianMLPValueFunction/LossAfter       47.9386\n",
      "GaussianMLPValueFunction/LossBefore      50.6854\n",
      "GaussianMLPValueFunction/dLoss            2.74677\n",
      "TotalEnvSteps                        150000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:03 | [trpo_pendulum] epoch #125 | Saving snapshot...\n",
      "2022-08-17 18:06:03 | [trpo_pendulum] epoch #125 | Saved\n",
      "2022-08-17 18:06:03 | [trpo_pendulum] epoch #125 | Time 79.19 s\n",
      "2022-08-17 18:06:03 | [trpo_pendulum] epoch #125 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -667.791\n",
      "Evaluation/AverageReturn              -1534.61\n",
      "Evaluation/Iteration                    125\n",
      "Evaluation/MaxReturn                  -1519.09\n",
      "Evaluation/MinReturn                  -1550.15\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     10.0604\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.35246\n",
      "GaussianMLPPolicy/KL                      0.00810059\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             153.003\n",
      "GaussianMLPPolicy/LossBefore            153.444\n",
      "GaussianMLPPolicy/dLoss                   0.440948\n",
      "GaussianMLPValueFunction/LossAfter       46.8248\n",
      "GaussianMLPValueFunction/LossBefore      49.5665\n",
      "GaussianMLPValueFunction/dLoss            2.74161\n",
      "TotalEnvSteps                        151200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:04 | [trpo_pendulum] epoch #126 | Saving snapshot...\n",
      "2022-08-17 18:06:04 | [trpo_pendulum] epoch #126 | Saved\n",
      "2022-08-17 18:06:04 | [trpo_pendulum] epoch #126 | Time 79.81 s\n",
      "2022-08-17 18:06:04 | [trpo_pendulum] epoch #126 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -475.24\n",
      "Evaluation/AverageReturn              -1147.28\n",
      "Evaluation/Iteration                    126\n",
      "Evaluation/MaxReturn                  -1002.31\n",
      "Evaluation/MinReturn                  -1238.94\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     72.1008\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.34269\n",
      "GaussianMLPPolicy/KL                      0.00720555\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             100.48\n",
      "GaussianMLPPolicy/LossBefore            101.735\n",
      "GaussianMLPPolicy/dLoss                   1.25455\n",
      "GaussianMLPValueFunction/LossAfter       23.7822\n",
      "GaussianMLPValueFunction/LossBefore      24.4344\n",
      "GaussianMLPValueFunction/dLoss            0.652203\n",
      "TotalEnvSteps                        152400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:04 | [trpo_pendulum] epoch #127 | Saving snapshot...\n",
      "2022-08-17 18:06:04 | [trpo_pendulum] epoch #127 | Saved\n",
      "2022-08-17 18:06:04 | [trpo_pendulum] epoch #127 | Time 80.45 s\n",
      "2022-08-17 18:06:04 | [trpo_pendulum] epoch #127 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -664.095\n",
      "Evaluation/AverageReturn              -1541.25\n",
      "Evaluation/Iteration                    127\n",
      "Evaluation/MaxReturn                  -1517.87\n",
      "Evaluation/MinReturn                  -1564.37\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     14.3809\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37969\n",
      "GaussianMLPPolicy/KL                      0.00646532\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             153.576\n",
      "GaussianMLPPolicy/LossBefore            155.076\n",
      "GaussianMLPPolicy/dLoss                   1.49992\n",
      "GaussianMLPValueFunction/LossAfter       43.8951\n",
      "GaussianMLPValueFunction/LossBefore      46.566\n",
      "GaussianMLPValueFunction/dLoss            2.67085\n",
      "TotalEnvSteps                        153600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:05 | [trpo_pendulum] epoch #128 | Saving snapshot...\n",
      "2022-08-17 18:06:05 | [trpo_pendulum] epoch #128 | Saved\n",
      "2022-08-17 18:06:05 | [trpo_pendulum] epoch #128 | Time 81.07 s\n",
      "2022-08-17 18:06:05 | [trpo_pendulum] epoch #128 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -644.186\n",
      "Evaluation/AverageReturn              -1518.76\n",
      "Evaluation/Iteration                    128\n",
      "Evaluation/MaxReturn                  -1502.79\n",
      "Evaluation/MinReturn                  -1547.84\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     15.9568\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.35393\n",
      "GaussianMLPPolicy/KL                      0.00987175\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             151.675\n",
      "GaussianMLPPolicy/LossBefore            153.844\n",
      "GaussianMLPPolicy/dLoss                   2.16951\n",
      "GaussianMLPValueFunction/LossAfter       41.2704\n",
      "GaussianMLPValueFunction/LossBefore      43.7802\n",
      "GaussianMLPValueFunction/dLoss            2.50982\n",
      "TotalEnvSteps                        154800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:05 | [trpo_pendulum] epoch #129 | Saving snapshot...\n",
      "2022-08-17 18:06:05 | [trpo_pendulum] epoch #129 | Saved\n",
      "2022-08-17 18:06:05 | [trpo_pendulum] epoch #129 | Time 81.70 s\n",
      "2022-08-17 18:06:05 | [trpo_pendulum] epoch #129 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -328.649\n",
      "Evaluation/AverageReturn               -764.806\n",
      "Evaluation/Iteration                    129\n",
      "Evaluation/MaxReturn                   -504.184\n",
      "Evaluation/MinReturn                   -899.404\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    148.881\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.33872\n",
      "GaussianMLPPolicy/KL                      0.00814958\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              44.0688\n",
      "GaussianMLPPolicy/LossBefore             45.5578\n",
      "GaussianMLPPolicy/dLoss                   1.48904\n",
      "GaussianMLPValueFunction/LossAfter       10.4301\n",
      "GaussianMLPValueFunction/LossBefore      10.5086\n",
      "GaussianMLPValueFunction/dLoss            0.0785275\n",
      "TotalEnvSteps                        156000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:06 | [trpo_pendulum] epoch #130 | Saving snapshot...\n",
      "2022-08-17 18:06:06 | [trpo_pendulum] epoch #130 | Saved\n",
      "2022-08-17 18:06:06 | [trpo_pendulum] epoch #130 | Time 82.31 s\n",
      "2022-08-17 18:06:06 | [trpo_pendulum] epoch #130 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -546.644\n",
      "Evaluation/AverageReturn              -1352.5\n",
      "Evaluation/Iteration                    130\n",
      "Evaluation/MaxReturn                  -1096.31\n",
      "Evaluation/MinReturn                  -1457.08\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    119.104\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.31396\n",
      "GaussianMLPPolicy/KL                      0.00709339\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             130.985\n",
      "GaussianMLPPolicy/LossBefore            133.229\n",
      "GaussianMLPPolicy/dLoss                   2.24364\n",
      "GaussianMLPValueFunction/LossAfter       31.5407\n",
      "GaussianMLPValueFunction/LossBefore      33.0567\n",
      "GaussianMLPValueFunction/dLoss            1.51603\n",
      "TotalEnvSteps                        157200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:07 | [trpo_pendulum] epoch #131 | Saving snapshot...\n",
      "2022-08-17 18:06:07 | [trpo_pendulum] epoch #131 | Saved\n",
      "2022-08-17 18:06:07 | [trpo_pendulum] epoch #131 | Time 82.93 s\n",
      "2022-08-17 18:06:07 | [trpo_pendulum] epoch #131 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -666.827\n",
      "Evaluation/AverageReturn              -1536.54\n",
      "Evaluation/Iteration                    131\n",
      "Evaluation/MaxReturn                  -1511.26\n",
      "Evaluation/MinReturn                  -1551.53\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     13.3894\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.30128\n",
      "GaussianMLPPolicy/KL                      0.00927492\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             150.989\n",
      "GaussianMLPPolicy/LossBefore            152.48\n",
      "GaussianMLPPolicy/dLoss                   1.4911\n",
      "GaussianMLPValueFunction/LossAfter       36.112\n",
      "GaussianMLPValueFunction/LossBefore      38.3685\n",
      "GaussianMLPValueFunction/dLoss            2.25651\n",
      "TotalEnvSteps                        158400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:07 | [trpo_pendulum] epoch #132 | Saving snapshot...\n",
      "2022-08-17 18:06:07 | [trpo_pendulum] epoch #132 | Saved\n",
      "2022-08-17 18:06:07 | [trpo_pendulum] epoch #132 | Time 83.54 s\n",
      "2022-08-17 18:06:07 | [trpo_pendulum] epoch #132 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -595.595\n",
      "Evaluation/AverageReturn              -1453.5\n",
      "Evaluation/Iteration                    132\n",
      "Evaluation/MaxReturn                  -1441.27\n",
      "Evaluation/MinReturn                  -1463.51\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      8.73533\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.33304\n",
      "GaussianMLPPolicy/KL                      0.00860206\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             145.257\n",
      "GaussianMLPPolicy/LossBefore            146.914\n",
      "GaussianMLPPolicy/dLoss                   1.65784\n",
      "GaussianMLPValueFunction/LossAfter       32.5984\n",
      "GaussianMLPValueFunction/LossBefore      34.49\n",
      "GaussianMLPValueFunction/dLoss            1.89158\n",
      "TotalEnvSteps                        159600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:08 | [trpo_pendulum] epoch #133 | Saving snapshot...\n",
      "2022-08-17 18:06:08 | [trpo_pendulum] epoch #133 | Saved\n",
      "2022-08-17 18:06:08 | [trpo_pendulum] epoch #133 | Time 84.18 s\n",
      "2022-08-17 18:06:08 | [trpo_pendulum] epoch #133 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -604.92\n",
      "Evaluation/AverageReturn              -1468.04\n",
      "Evaluation/Iteration                    133\n",
      "Evaluation/MaxReturn                  -1456.49\n",
      "Evaluation/MinReturn                  -1482.13\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      8.21514\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.32037\n",
      "GaussianMLPPolicy/KL                      0.00820664\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             145.887\n",
      "GaussianMLPPolicy/LossBefore            148.31\n",
      "GaussianMLPPolicy/dLoss                   2.42316\n",
      "GaussianMLPValueFunction/LossAfter       31.5289\n",
      "GaussianMLPValueFunction/LossBefore      33.3589\n",
      "GaussianMLPValueFunction/dLoss            1.82994\n",
      "TotalEnvSteps                        160800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:09 | [trpo_pendulum] epoch #134 | Saving snapshot...\n",
      "2022-08-17 18:06:09 | [trpo_pendulum] epoch #134 | Saved\n",
      "2022-08-17 18:06:09 | [trpo_pendulum] epoch #134 | Time 84.80 s\n",
      "2022-08-17 18:06:09 | [trpo_pendulum] epoch #134 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -662.295\n",
      "Evaluation/AverageReturn              -1528.67\n",
      "Evaluation/Iteration                    134\n",
      "Evaluation/MaxReturn                  -1514.23\n",
      "Evaluation/MinReturn                  -1538.34\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      7.83323\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.32066\n",
      "GaussianMLPPolicy/KL                      0.00991749\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             147.911\n",
      "GaussianMLPPolicy/LossBefore            149.759\n",
      "GaussianMLPPolicy/dLoss                   1.84773\n",
      "GaussianMLPValueFunction/LossAfter       30.2057\n",
      "GaussianMLPValueFunction/LossBefore      31.9428\n",
      "GaussianMLPValueFunction/dLoss            1.73717\n",
      "TotalEnvSteps                        162000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:09 | [trpo_pendulum] epoch #135 | Saving snapshot...\n",
      "2022-08-17 18:06:09 | [trpo_pendulum] epoch #135 | Saved\n",
      "2022-08-17 18:06:09 | [trpo_pendulum] epoch #135 | Time 85.41 s\n",
      "2022-08-17 18:06:09 | [trpo_pendulum] epoch #135 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -662.357\n",
      "Evaluation/AverageReturn              -1524.18\n",
      "Evaluation/Iteration                    135\n",
      "Evaluation/MaxReturn                  -1516.28\n",
      "Evaluation/MinReturn                  -1535.83\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      6.73844\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.29307\n",
      "GaussianMLPPolicy/KL                      0.0068578\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             146.719\n",
      "GaussianMLPPolicy/LossBefore            148.663\n",
      "GaussianMLPPolicy/dLoss                   1.94411\n",
      "GaussianMLPValueFunction/LossAfter       28.4239\n",
      "GaussianMLPValueFunction/LossBefore      30.0009\n",
      "GaussianMLPValueFunction/dLoss            1.577\n",
      "TotalEnvSteps                        163200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:06:10 | [trpo_pendulum] epoch #136 | Saving snapshot...\n",
      "2022-08-17 18:06:10 | [trpo_pendulum] epoch #136 | Saved\n",
      "2022-08-17 18:06:10 | [trpo_pendulum] epoch #136 | Time 86.03 s\n",
      "2022-08-17 18:06:10 | [trpo_pendulum] epoch #136 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -670.236\n",
      "Evaluation/AverageReturn              -1529.51\n",
      "Evaluation/Iteration                    136\n",
      "Evaluation/MaxReturn                  -1521.32\n",
      "Evaluation/MinReturn                  -1537.82\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.66504\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.30021\n",
      "GaussianMLPPolicy/KL                      0.0066612\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             147.032\n",
      "GaussianMLPPolicy/LossBefore            147.374\n",
      "GaussianMLPPolicy/dLoss                   0.342789\n",
      "GaussianMLPValueFunction/LossAfter       26.6652\n",
      "GaussianMLPValueFunction/LossBefore      28.0888\n",
      "GaussianMLPValueFunction/dLoss            1.4236\n",
      "TotalEnvSteps                        164400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:06:10 | [trpo_pendulum] epoch #137 | Saving snapshot...\n",
      "2022-08-17 18:06:10 | [trpo_pendulum] epoch #137 | Saved\n",
      "2022-08-17 18:06:10 | [trpo_pendulum] epoch #137 | Time 86.65 s\n",
      "2022-08-17 18:06:10 | [trpo_pendulum] epoch #137 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -680.438\n",
      "Evaluation/AverageReturn              -1547.33\n",
      "Evaluation/Iteration                    137\n",
      "Evaluation/MaxReturn                  -1538.69\n",
      "Evaluation/MinReturn                  -1565.1\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      8.38032\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.27444\n",
      "GaussianMLPPolicy/KL                      0.0071064\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             147.621\n",
      "GaussianMLPPolicy/LossBefore            149.181\n",
      "GaussianMLPPolicy/dLoss                   1.56059\n",
      "GaussianMLPValueFunction/LossAfter       25.8781\n",
      "GaussianMLPValueFunction/LossBefore      27.2678\n",
      "GaussianMLPValueFunction/dLoss            1.38973\n",
      "TotalEnvSteps                        165600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:06:11 | [trpo_pendulum] epoch #138 | Saving snapshot...\n",
      "2022-08-17 18:06:11 | [trpo_pendulum] epoch #138 | Saved\n",
      "2022-08-17 18:06:11 | [trpo_pendulum] epoch #138 | Time 87.28 s\n",
      "2022-08-17 18:06:11 | [trpo_pendulum] epoch #138 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -670.216\n",
      "Evaluation/AverageReturn              -1527.16\n",
      "Evaluation/Iteration                    138\n",
      "Evaluation/MaxReturn                  -1522.48\n",
      "Evaluation/MinReturn                  -1538.02\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.64176\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.29509\n",
      "GaussianMLPPolicy/KL                      0.00875141\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             144.102\n",
      "GaussianMLPPolicy/LossBefore            145.852\n",
      "GaussianMLPPolicy/dLoss                   1.75055\n",
      "GaussianMLPValueFunction/LossAfter       23.9999\n",
      "GaussianMLPValueFunction/LossBefore      25.2149\n",
      "GaussianMLPValueFunction/dLoss            1.21502\n",
      "TotalEnvSteps                        166800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:12 | [trpo_pendulum] epoch #139 | Saving snapshot...\n",
      "2022-08-17 18:06:12 | [trpo_pendulum] epoch #139 | Saved\n",
      "2022-08-17 18:06:12 | [trpo_pendulum] epoch #139 | Time 87.92 s\n",
      "2022-08-17 18:06:12 | [trpo_pendulum] epoch #139 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -629.197\n",
      "Evaluation/AverageReturn              -1489.44\n",
      "Evaluation/Iteration                    139\n",
      "Evaluation/MaxReturn                  -1478.46\n",
      "Evaluation/MinReturn                  -1512.1\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     12.3162\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.28653\n",
      "GaussianMLPPolicy/KL                      0.00697644\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             143.126\n",
      "GaussianMLPPolicy/LossBefore            145.158\n",
      "GaussianMLPPolicy/dLoss                   2.03262\n",
      "GaussianMLPValueFunction/LossAfter       22.8698\n",
      "GaussianMLPValueFunction/LossBefore      24.003\n",
      "GaussianMLPValueFunction/dLoss            1.13317\n",
      "TotalEnvSteps                        168000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:12 | [trpo_pendulum] epoch #140 | Saving snapshot...\n",
      "2022-08-17 18:06:12 | [trpo_pendulum] epoch #140 | Saved\n",
      "2022-08-17 18:06:12 | [trpo_pendulum] epoch #140 | Time 88.53 s\n",
      "2022-08-17 18:06:12 | [trpo_pendulum] epoch #140 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -653.272\n",
      "Evaluation/AverageReturn              -1511.63\n",
      "Evaluation/Iteration                    140\n",
      "Evaluation/MaxReturn                  -1506.91\n",
      "Evaluation/MinReturn                  -1518.46\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      4.78988\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.30998\n",
      "GaussianMLPPolicy/KL                      0.00600333\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             143.373\n",
      "GaussianMLPPolicy/LossBefore            144.882\n",
      "GaussianMLPPolicy/dLoss                   1.50851\n",
      "GaussianMLPValueFunction/LossAfter       21.7758\n",
      "GaussianMLPValueFunction/LossBefore      22.8288\n",
      "GaussianMLPValueFunction/dLoss            1.05301\n",
      "TotalEnvSteps                        169200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:13 | [trpo_pendulum] epoch #141 | Saving snapshot...\n",
      "2022-08-17 18:06:13 | [trpo_pendulum] epoch #141 | Saved\n",
      "2022-08-17 18:06:13 | [trpo_pendulum] epoch #141 | Time 89.14 s\n",
      "2022-08-17 18:06:13 | [trpo_pendulum] epoch #141 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -665.865\n",
      "Evaluation/AverageReturn              -1531.34\n",
      "Evaluation/Iteration                    141\n",
      "Evaluation/MaxReturn                  -1525.77\n",
      "Evaluation/MinReturn                  -1539.02\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      4.93002\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.31211\n",
      "GaussianMLPPolicy/KL                      0.00770574\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             145.43\n",
      "GaussianMLPPolicy/LossBefore            147.009\n",
      "GaussianMLPPolicy/dLoss                   1.57912\n",
      "GaussianMLPValueFunction/LossAfter       21.2594\n",
      "GaussianMLPValueFunction/LossBefore      22.3012\n",
      "GaussianMLPValueFunction/dLoss            1.04181\n",
      "TotalEnvSteps                        170400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:13 | [trpo_pendulum] epoch #142 | Saving snapshot...\n",
      "2022-08-17 18:06:14 | [trpo_pendulum] epoch #142 | Saved\n",
      "2022-08-17 18:06:14 | [trpo_pendulum] epoch #142 | Time 89.78 s\n",
      "2022-08-17 18:06:14 | [trpo_pendulum] epoch #142 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -546.892\n",
      "Evaluation/AverageReturn              -1383.61\n",
      "Evaluation/Iteration                    142\n",
      "Evaluation/MaxReturn                  -1358.94\n",
      "Evaluation/MinReturn                  -1422.55\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     24.7625\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.32577\n",
      "GaussianMLPPolicy/KL                      0.00819975\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             136.416\n",
      "GaussianMLPPolicy/LossBefore            137.192\n",
      "GaussianMLPPolicy/dLoss                   0.775986\n",
      "GaussianMLPValueFunction/LossAfter       18.9451\n",
      "GaussianMLPValueFunction/LossBefore      19.7548\n",
      "GaussianMLPValueFunction/dLoss            0.809687\n",
      "TotalEnvSteps                        171600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:14 | [trpo_pendulum] epoch #143 | Saving snapshot...\n",
      "2022-08-17 18:06:14 | [trpo_pendulum] epoch #143 | Saved\n",
      "2022-08-17 18:06:14 | [trpo_pendulum] epoch #143 | Time 90.42 s\n",
      "2022-08-17 18:06:14 | [trpo_pendulum] epoch #143 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -483.805\n",
      "Evaluation/AverageReturn              -1262.6\n",
      "Evaluation/Iteration                    143\n",
      "Evaluation/MaxReturn                  -1085.98\n",
      "Evaluation/MinReturn                  -1411.93\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    107.588\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.34951\n",
      "GaussianMLPPolicy/KL                      0.00962839\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             114.407\n",
      "GaussianMLPPolicy/LossBefore            116.468\n",
      "GaussianMLPPolicy/dLoss                   2.06033\n",
      "GaussianMLPValueFunction/LossAfter       15.476\n",
      "GaussianMLPValueFunction/LossBefore      15.9619\n",
      "GaussianMLPValueFunction/dLoss            0.485996\n",
      "TotalEnvSteps                        172800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:15 | [trpo_pendulum] epoch #144 | Saving snapshot...\n",
      "2022-08-17 18:06:15 | [trpo_pendulum] epoch #144 | Saved\n",
      "2022-08-17 18:06:15 | [trpo_pendulum] epoch #144 | Time 91.03 s\n",
      "2022-08-17 18:06:15 | [trpo_pendulum] epoch #144 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -584.85\n",
      "Evaluation/AverageReturn              -1423.94\n",
      "Evaluation/Iteration                    144\n",
      "Evaluation/MaxReturn                  -1372.71\n",
      "Evaluation/MinReturn                  -1477.35\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     36.6537\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.3778\n",
      "GaussianMLPPolicy/KL                      0.00996302\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             135.279\n",
      "GaussianMLPPolicy/LossBefore            137.781\n",
      "GaussianMLPPolicy/dLoss                   2.5011\n",
      "GaussianMLPValueFunction/LossAfter       17.6211\n",
      "GaussianMLPValueFunction/LossBefore      18.3618\n",
      "GaussianMLPValueFunction/dLoss            0.740612\n",
      "TotalEnvSteps                        174000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:15 | [trpo_pendulum] epoch #145 | Saving snapshot...\n",
      "2022-08-17 18:06:15 | [trpo_pendulum] epoch #145 | Saved\n",
      "2022-08-17 18:06:15 | [trpo_pendulum] epoch #145 | Time 91.66 s\n",
      "2022-08-17 18:06:15 | [trpo_pendulum] epoch #145 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -474.04\n",
      "Evaluation/AverageReturn              -1140.85\n",
      "Evaluation/Iteration                    145\n",
      "Evaluation/MaxReturn                  -1071.41\n",
      "Evaluation/MinReturn                  -1200.28\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     49.832\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38755\n",
      "GaussianMLPPolicy/KL                      0.00571416\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              90.7446\n",
      "GaussianMLPPolicy/LossBefore             92.3405\n",
      "GaussianMLPPolicy/dLoss                   1.59591\n",
      "GaussianMLPValueFunction/LossAfter       11.1888\n",
      "GaussianMLPValueFunction/LossBefore      11.3811\n",
      "GaussianMLPValueFunction/dLoss            0.192246\n",
      "TotalEnvSteps                        175200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:16 | [trpo_pendulum] epoch #146 | Saving snapshot...\n",
      "2022-08-17 18:06:16 | [trpo_pendulum] epoch #146 | Saved\n",
      "2022-08-17 18:06:16 | [trpo_pendulum] epoch #146 | Time 92.28 s\n",
      "2022-08-17 18:06:16 | [trpo_pendulum] epoch #146 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -585.325\n",
      "Evaluation/AverageReturn              -1419.19\n",
      "Evaluation/Iteration                    146\n",
      "Evaluation/MaxReturn                  -1359.1\n",
      "Evaluation/MinReturn                  -1477.64\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     37.2394\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.40128\n",
      "GaussianMLPPolicy/KL                      0.00588239\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             134.373\n",
      "GaussianMLPPolicy/LossBefore            135.976\n",
      "GaussianMLPPolicy/dLoss                   1.60265\n",
      "GaussianMLPValueFunction/LossAfter       16.3439\n",
      "GaussianMLPValueFunction/LossBefore      17.019\n",
      "GaussianMLPValueFunction/dLoss            0.675064\n",
      "TotalEnvSteps                        176400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:17 | [trpo_pendulum] epoch #147 | Saving snapshot...\n",
      "2022-08-17 18:06:17 | [trpo_pendulum] epoch #147 | Saved\n",
      "2022-08-17 18:06:17 | [trpo_pendulum] epoch #147 | Time 92.90 s\n",
      "2022-08-17 18:06:17 | [trpo_pendulum] epoch #147 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -602.254\n",
      "Evaluation/AverageReturn              -1449.26\n",
      "Evaluation/Iteration                    147\n",
      "Evaluation/MaxReturn                  -1401.58\n",
      "Evaluation/MinReturn                  -1482.1\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     24.7867\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38892\n",
      "GaussianMLPPolicy/KL                      0.00797664\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             134.208\n",
      "GaussianMLPPolicy/LossBefore            136.519\n",
      "GaussianMLPPolicy/dLoss                   2.31097\n",
      "GaussianMLPValueFunction/LossAfter       15.8144\n",
      "GaussianMLPValueFunction/LossBefore      16.4771\n",
      "GaussianMLPValueFunction/dLoss            0.66268\n",
      "TotalEnvSteps                        177600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:17 | [trpo_pendulum] epoch #148 | Saving snapshot...\n",
      "2022-08-17 18:06:17 | [trpo_pendulum] epoch #148 | Saved\n",
      "2022-08-17 18:06:17 | [trpo_pendulum] epoch #148 | Time 93.52 s\n",
      "2022-08-17 18:06:17 | [trpo_pendulum] epoch #148 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -615.336\n",
      "Evaluation/AverageReturn              -1454.01\n",
      "Evaluation/Iteration                    148\n",
      "Evaluation/MaxReturn                  -1426.61\n",
      "Evaluation/MinReturn                  -1499.17\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     29.3892\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38076\n",
      "GaussianMLPPolicy/KL                      0.00562169\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             135.777\n",
      "GaussianMLPPolicy/LossBefore            136.427\n",
      "GaussianMLPPolicy/dLoss                   0.650345\n",
      "GaussianMLPValueFunction/LossAfter       15.1773\n",
      "GaussianMLPValueFunction/LossBefore      15.7909\n",
      "GaussianMLPValueFunction/dLoss            0.613633\n",
      "TotalEnvSteps                        178800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:18 | [trpo_pendulum] epoch #149 | Saving snapshot...\n",
      "2022-08-17 18:06:18 | [trpo_pendulum] epoch #149 | Saved\n",
      "2022-08-17 18:06:18 | [trpo_pendulum] epoch #149 | Time 94.13 s\n",
      "2022-08-17 18:06:18 | [trpo_pendulum] epoch #149 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -654.552\n",
      "Evaluation/AverageReturn              -1521.52\n",
      "Evaluation/Iteration                    149\n",
      "Evaluation/MaxReturn                  -1513.73\n",
      "Evaluation/MinReturn                  -1529.89\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.07156\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37486\n",
      "GaussianMLPPolicy/KL                      0.00714277\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             142.367\n",
      "GaussianMLPPolicy/LossBefore            143.406\n",
      "GaussianMLPPolicy/dLoss                   1.03931\n",
      "GaussianMLPValueFunction/LossAfter       15.5893\n",
      "GaussianMLPValueFunction/LossBefore      16.2871\n",
      "GaussianMLPValueFunction/dLoss            0.697733\n",
      "TotalEnvSteps                        180000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:18 | [trpo_pendulum] epoch #150 | Saving snapshot...\n",
      "2022-08-17 18:06:18 | [trpo_pendulum] epoch #150 | Saved\n",
      "2022-08-17 18:06:18 | [trpo_pendulum] epoch #150 | Time 94.74 s\n",
      "2022-08-17 18:06:18 | [trpo_pendulum] epoch #150 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -660.026\n",
      "Evaluation/AverageReturn              -1517.66\n",
      "Evaluation/Iteration                    150\n",
      "Evaluation/MaxReturn                  -1510.9\n",
      "Evaluation/MinReturn                  -1526.28\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.46468\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.39959\n",
      "GaussianMLPPolicy/KL                      0.00697503\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             138.566\n",
      "GaussianMLPPolicy/LossBefore            140.9\n",
      "GaussianMLPPolicy/dLoss                   2.33383\n",
      "GaussianMLPValueFunction/LossAfter       14.7304\n",
      "GaussianMLPValueFunction/LossBefore      15.3436\n",
      "GaussianMLPValueFunction/dLoss            0.613216\n",
      "TotalEnvSteps                        181200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:19 | [trpo_pendulum] epoch #151 | Saving snapshot...\n",
      "2022-08-17 18:06:19 | [trpo_pendulum] epoch #151 | Saved\n",
      "2022-08-17 18:06:19 | [trpo_pendulum] epoch #151 | Time 95.37 s\n",
      "2022-08-17 18:06:19 | [trpo_pendulum] epoch #151 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -658.514\n",
      "Evaluation/AverageReturn              -1513.9\n",
      "Evaluation/Iteration                    151\n",
      "Evaluation/MaxReturn                  -1509.22\n",
      "Evaluation/MinReturn                  -1518.83\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      3.53387\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.40071\n",
      "GaussianMLPPolicy/KL                      0.00706691\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             138.365\n",
      "GaussianMLPPolicy/LossBefore            139.604\n",
      "GaussianMLPPolicy/dLoss                   1.23924\n",
      "GaussianMLPValueFunction/LossAfter       14.0446\n",
      "GaussianMLPValueFunction/LossBefore      14.5959\n",
      "GaussianMLPValueFunction/dLoss            0.551348\n",
      "TotalEnvSteps                        182400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:20 | [trpo_pendulum] epoch #152 | Saving snapshot...\n",
      "2022-08-17 18:06:20 | [trpo_pendulum] epoch #152 | Saved\n",
      "2022-08-17 18:06:20 | [trpo_pendulum] epoch #152 | Time 96.00 s\n",
      "2022-08-17 18:06:20 | [trpo_pendulum] epoch #152 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -558.962\n",
      "Evaluation/AverageReturn              -1293.54\n",
      "Evaluation/Iteration                    152\n",
      "Evaluation/MaxReturn                  -1230.98\n",
      "Evaluation/MinReturn                  -1369.25\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     40.7592\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.43538\n",
      "GaussianMLPPolicy/KL                      0.00920586\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             107.568\n",
      "GaussianMLPPolicy/LossBefore            109.826\n",
      "GaussianMLPPolicy/dLoss                   2.25769\n",
      "GaussianMLPValueFunction/LossAfter       10.8567\n",
      "GaussianMLPValueFunction/LossBefore      11.087\n",
      "GaussianMLPValueFunction/dLoss            0.2303\n",
      "TotalEnvSteps                        183600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:20 | [trpo_pendulum] epoch #153 | Saving snapshot...\n",
      "2022-08-17 18:06:20 | [trpo_pendulum] epoch #153 | Saved\n",
      "2022-08-17 18:06:20 | [trpo_pendulum] epoch #153 | Time 96.62 s\n",
      "2022-08-17 18:06:20 | [trpo_pendulum] epoch #153 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -548.035\n",
      "Evaluation/AverageReturn              -1424.49\n",
      "Evaluation/Iteration                    153\n",
      "Evaluation/MaxReturn                  -1381.34\n",
      "Evaluation/MinReturn                  -1482.78\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     32.9898\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.43857\n",
      "GaussianMLPPolicy/KL                      0.00899619\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             134.085\n",
      "GaussianMLPPolicy/LossBefore            136.578\n",
      "GaussianMLPPolicy/dLoss                   2.49356\n",
      "GaussianMLPValueFunction/LossAfter       13.3018\n",
      "GaussianMLPValueFunction/LossBefore      13.8132\n",
      "GaussianMLPValueFunction/dLoss            0.511369\n",
      "TotalEnvSteps                        184800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:21 | [trpo_pendulum] epoch #154 | Saving snapshot...\n",
      "2022-08-17 18:06:21 | [trpo_pendulum] epoch #154 | Saved\n",
      "2022-08-17 18:06:21 | [trpo_pendulum] epoch #154 | Time 97.27 s\n",
      "2022-08-17 18:06:21 | [trpo_pendulum] epoch #154 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -684.097\n",
      "Evaluation/AverageReturn              -1621.96\n",
      "Evaluation/Iteration                    154\n",
      "Evaluation/MaxReturn                  -1607.67\n",
      "Evaluation/MinReturn                  -1635.22\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      8.27668\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.44849\n",
      "GaussianMLPPolicy/KL                      0.00779092\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             155.854\n",
      "GaussianMLPPolicy/LossBefore            157.97\n",
      "GaussianMLPPolicy/dLoss                   2.11594\n",
      "GaussianMLPValueFunction/LossAfter       14.5699\n",
      "GaussianMLPValueFunction/LossBefore      15.2981\n",
      "GaussianMLPValueFunction/dLoss            0.72811\n",
      "TotalEnvSteps                        186000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:22 | [trpo_pendulum] epoch #155 | Saving snapshot...\n",
      "2022-08-17 18:06:22 | [trpo_pendulum] epoch #155 | Saved\n",
      "2022-08-17 18:06:22 | [trpo_pendulum] epoch #155 | Time 97.89 s\n",
      "2022-08-17 18:06:22 | [trpo_pendulum] epoch #155 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -682.13\n",
      "Evaluation/AverageReturn              -1618.72\n",
      "Evaluation/Iteration                    155\n",
      "Evaluation/MaxReturn                  -1599.98\n",
      "Evaluation/MinReturn                  -1633.84\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     11.4829\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.41918\n",
      "GaussianMLPPolicy/KL                      0.00877756\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             155.557\n",
      "GaussianMLPPolicy/LossBefore            157.242\n",
      "GaussianMLPPolicy/dLoss                   1.6848\n",
      "GaussianMLPValueFunction/LossAfter       13.921\n",
      "GaussianMLPValueFunction/LossBefore      14.5671\n",
      "GaussianMLPValueFunction/dLoss            0.64612\n",
      "TotalEnvSteps                        187200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:22 | [trpo_pendulum] epoch #156 | Saving snapshot...\n",
      "2022-08-17 18:06:22 | [trpo_pendulum] epoch #156 | Saved\n",
      "2022-08-17 18:06:22 | [trpo_pendulum] epoch #156 | Time 98.53 s\n",
      "2022-08-17 18:06:22 | [trpo_pendulum] epoch #156 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -665.718\n",
      "Evaluation/AverageReturn              -1596.53\n",
      "Evaluation/Iteration                    156\n",
      "Evaluation/MaxReturn                  -1572.93\n",
      "Evaluation/MinReturn                  -1612.58\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     11.8964\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.41109\n",
      "GaussianMLPPolicy/KL                      0.00650137\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             152.794\n",
      "GaussianMLPPolicy/LossBefore            154.36\n",
      "GaussianMLPPolicy/dLoss                   1.56619\n",
      "GaussianMLPValueFunction/LossAfter       13.1958\n",
      "GaussianMLPValueFunction/LossBefore      13.7497\n",
      "GaussianMLPValueFunction/dLoss            0.553841\n",
      "TotalEnvSteps                        188400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:23 | [trpo_pendulum] epoch #157 | Saving snapshot...\n",
      "2022-08-17 18:06:23 | [trpo_pendulum] epoch #157 | Saved\n",
      "2022-08-17 18:06:23 | [trpo_pendulum] epoch #157 | Time 99.15 s\n",
      "2022-08-17 18:06:23 | [trpo_pendulum] epoch #157 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -504.025\n",
      "Evaluation/AverageReturn              -1364.61\n",
      "Evaluation/Iteration                    157\n",
      "Evaluation/MaxReturn                  -1335.23\n",
      "Evaluation/MinReturn                  -1467.11\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     46.5481\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.39838\n",
      "GaussianMLPPolicy/KL                      0.00703374\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             129.157\n",
      "GaussianMLPPolicy/LossBefore            131.244\n",
      "GaussianMLPPolicy/dLoss                   2.0863\n",
      "GaussianMLPValueFunction/LossAfter       11.1483\n",
      "GaussianMLPValueFunction/LossBefore      11.4546\n",
      "GaussianMLPValueFunction/dLoss            0.306281\n",
      "TotalEnvSteps                        189600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:23 | [trpo_pendulum] epoch #158 | Saving snapshot...\n",
      "2022-08-17 18:06:23 | [trpo_pendulum] epoch #158 | Saved\n",
      "2022-08-17 18:06:23 | [trpo_pendulum] epoch #158 | Time 99.77 s\n",
      "2022-08-17 18:06:23 | [trpo_pendulum] epoch #158 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -535.662\n",
      "Evaluation/AverageReturn              -1396.79\n",
      "Evaluation/Iteration                    158\n",
      "Evaluation/MaxReturn                  -1192.03\n",
      "Evaluation/MinReturn                  -1504.31\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    102.725\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.42476\n",
      "GaussianMLPPolicy/KL                      0.0055714\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             129.109\n",
      "GaussianMLPPolicy/LossBefore            130.336\n",
      "GaussianMLPPolicy/dLoss                   1.22656\n",
      "GaussianMLPValueFunction/LossAfter       10.9228\n",
      "GaussianMLPValueFunction/LossBefore      11.215\n",
      "GaussianMLPValueFunction/dLoss            0.292202\n",
      "TotalEnvSteps                        190800\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:06:24 | [trpo_pendulum] epoch #159 | Saving snapshot...\n",
      "2022-08-17 18:06:24 | [trpo_pendulum] epoch #159 | Saved\n",
      "2022-08-17 18:06:24 | [trpo_pendulum] epoch #159 | Time 100.40 s\n",
      "2022-08-17 18:06:24 | [trpo_pendulum] epoch #159 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -505.033\n",
      "Evaluation/AverageReturn              -1325.54\n",
      "Evaluation/Iteration                    159\n",
      "Evaluation/MaxReturn                  -1273.08\n",
      "Evaluation/MinReturn                  -1400.73\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     41.0628\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.42725\n",
      "GaussianMLPPolicy/KL                      0.00734265\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             116.698\n",
      "GaussianMLPPolicy/LossBefore            118.611\n",
      "GaussianMLPPolicy/dLoss                   1.91318\n",
      "GaussianMLPValueFunction/LossAfter        9.84658\n",
      "GaussianMLPValueFunction/LossBefore      10.0422\n",
      "GaussianMLPValueFunction/dLoss            0.195575\n",
      "TotalEnvSteps                        192000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:25 | [trpo_pendulum] epoch #160 | Saving snapshot...\n",
      "2022-08-17 18:06:25 | [trpo_pendulum] epoch #160 | Saved\n",
      "2022-08-17 18:06:25 | [trpo_pendulum] epoch #160 | Time 101.03 s\n",
      "2022-08-17 18:06:25 | [trpo_pendulum] epoch #160 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -670.107\n",
      "Evaluation/AverageReturn              -1593.97\n",
      "Evaluation/Iteration                    160\n",
      "Evaluation/MaxReturn                  -1578.07\n",
      "Evaluation/MinReturn                  -1612.14\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     10.7148\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.43469\n",
      "GaussianMLPPolicy/KL                      0.00671077\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             150.693\n",
      "GaussianMLPPolicy/LossBefore            152.1\n",
      "GaussianMLPPolicy/dLoss                   1.40686\n",
      "GaussianMLPValueFunction/LossAfter       11.6339\n",
      "GaussianMLPValueFunction/LossBefore      12.0524\n",
      "GaussianMLPValueFunction/dLoss            0.418449\n",
      "TotalEnvSteps                        193200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:25 | [trpo_pendulum] epoch #161 | Saving snapshot...\n",
      "2022-08-17 18:06:25 | [trpo_pendulum] epoch #161 | Saved\n",
      "2022-08-17 18:06:25 | [trpo_pendulum] epoch #161 | Time 101.67 s\n",
      "2022-08-17 18:06:25 | [trpo_pendulum] epoch #161 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -663.741\n",
      "Evaluation/AverageReturn              -1571.94\n",
      "Evaluation/Iteration                    161\n",
      "Evaluation/MaxReturn                  -1557.15\n",
      "Evaluation/MinReturn                  -1597.16\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     14.0421\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.4314\n",
      "GaussianMLPPolicy/KL                      0.00646256\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             147.669\n",
      "GaussianMLPPolicy/LossBefore            148.105\n",
      "GaussianMLPPolicy/dLoss                   0.436798\n",
      "GaussianMLPValueFunction/LossAfter       11.0506\n",
      "GaussianMLPValueFunction/LossBefore      11.406\n",
      "GaussianMLPValueFunction/dLoss            0.355356\n",
      "TotalEnvSteps                        194400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:26 | [trpo_pendulum] epoch #162 | Saving snapshot...\n",
      "2022-08-17 18:06:26 | [trpo_pendulum] epoch #162 | Saved\n",
      "2022-08-17 18:06:26 | [trpo_pendulum] epoch #162 | Time 102.29 s\n",
      "2022-08-17 18:06:26 | [trpo_pendulum] epoch #162 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -613.794\n",
      "Evaluation/AverageReturn              -1438.6\n",
      "Evaluation/Iteration                    162\n",
      "Evaluation/MaxReturn                  -1369.6\n",
      "Evaluation/MinReturn                  -1481.32\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     39.6081\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.44535\n",
      "GaussianMLPPolicy/KL                      0.00690137\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             123.621\n",
      "GaussianMLPPolicy/LossBefore            125.967\n",
      "GaussianMLPPolicy/dLoss                   2.34544\n",
      "GaussianMLPValueFunction/LossAfter        9.50999\n",
      "GaussianMLPValueFunction/LossBefore       9.69314\n",
      "GaussianMLPValueFunction/dLoss            0.183148\n",
      "TotalEnvSteps                        195600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:27 | [trpo_pendulum] epoch #163 | Saving snapshot...\n",
      "2022-08-17 18:06:27 | [trpo_pendulum] epoch #163 | Saved\n",
      "2022-08-17 18:06:27 | [trpo_pendulum] epoch #163 | Time 102.91 s\n",
      "2022-08-17 18:06:27 | [trpo_pendulum] epoch #163 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -654.298\n",
      "Evaluation/AverageReturn              -1549.98\n",
      "Evaluation/Iteration                    163\n",
      "Evaluation/MaxReturn                  -1536.44\n",
      "Evaluation/MinReturn                  -1574.13\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     12.4338\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.41049\n",
      "GaussianMLPPolicy/KL                      0.00658483\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             142.962\n",
      "GaussianMLPPolicy/LossBefore            144.327\n",
      "GaussianMLPPolicy/dLoss                   1.36542\n",
      "GaussianMLPValueFunction/LossAfter       10.3656\n",
      "GaussianMLPValueFunction/LossBefore      10.6552\n",
      "GaussianMLPValueFunction/dLoss            0.289518\n",
      "TotalEnvSteps                        196800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:27 | [trpo_pendulum] epoch #164 | Saving snapshot...\n",
      "2022-08-17 18:06:27 | [trpo_pendulum] epoch #164 | Saved\n",
      "2022-08-17 18:06:27 | [trpo_pendulum] epoch #164 | Time 103.53 s\n",
      "2022-08-17 18:06:27 | [trpo_pendulum] epoch #164 | EpochTime 0.61 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn     -650.406\n",
      "Evaluation/AverageReturn              -1503.44\n",
      "Evaluation/Iteration                    164\n",
      "Evaluation/MaxReturn                  -1501.91\n",
      "Evaluation/MinReturn                  -1504.74\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      0.846991\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.40646\n",
      "GaussianMLPPolicy/KL                      0.00678\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             130.941\n",
      "GaussianMLPPolicy/LossBefore            133.215\n",
      "GaussianMLPPolicy/dLoss                   2.27411\n",
      "GaussianMLPValueFunction/LossAfter        9.48036\n",
      "GaussianMLPValueFunction/LossBefore       9.67647\n",
      "GaussianMLPValueFunction/dLoss            0.196107\n",
      "TotalEnvSteps                        198000\n",
      "-----------------------------------  -------------\n",
      "2022-08-17 18:06:28 | [trpo_pendulum] epoch #165 | Saving snapshot...\n",
      "2022-08-17 18:06:28 | [trpo_pendulum] epoch #165 | Saved\n",
      "2022-08-17 18:06:28 | [trpo_pendulum] epoch #165 | Time 104.15 s\n",
      "2022-08-17 18:06:28 | [trpo_pendulum] epoch #165 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -527.391\n",
      "Evaluation/AverageReturn              -1422.79\n",
      "Evaluation/Iteration                    165\n",
      "Evaluation/MaxReturn                  -1372.95\n",
      "Evaluation/MinReturn                  -1456.74\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     28.0441\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.40974\n",
      "GaussianMLPPolicy/KL                      0.00638616\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             135.973\n",
      "GaussianMLPPolicy/LossBefore            137.915\n",
      "GaussianMLPPolicy/dLoss                   1.94127\n",
      "GaussianMLPValueFunction/LossAfter        9.68331\n",
      "GaussianMLPValueFunction/LossBefore       9.91103\n",
      "GaussianMLPValueFunction/dLoss            0.227716\n",
      "TotalEnvSteps                        199200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:28 | [trpo_pendulum] epoch #166 | Saving snapshot...\n",
      "2022-08-17 18:06:29 | [trpo_pendulum] epoch #166 | Saved\n",
      "2022-08-17 18:06:29 | [trpo_pendulum] epoch #166 | Time 104.78 s\n",
      "2022-08-17 18:06:29 | [trpo_pendulum] epoch #166 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -570.789\n",
      "Evaluation/AverageReturn              -1462.48\n",
      "Evaluation/Iteration                    166\n",
      "Evaluation/MaxReturn                  -1388.77\n",
      "Evaluation/MinReturn                  -1506.58\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     40.1482\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.40864\n",
      "GaussianMLPPolicy/KL                      0.00567165\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             134.913\n",
      "GaussianMLPPolicy/LossBefore            136.006\n",
      "GaussianMLPPolicy/dLoss                   1.09285\n",
      "GaussianMLPValueFunction/LossAfter        9.42783\n",
      "GaussianMLPValueFunction/LossBefore       9.63444\n",
      "GaussianMLPValueFunction/dLoss            0.20661\n",
      "TotalEnvSteps                        200400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:29 | [trpo_pendulum] epoch #167 | Saving snapshot...\n",
      "2022-08-17 18:06:29 | [trpo_pendulum] epoch #167 | Saved\n",
      "2022-08-17 18:06:29 | [trpo_pendulum] epoch #167 | Time 105.40 s\n",
      "2022-08-17 18:06:29 | [trpo_pendulum] epoch #167 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -632.559\n",
      "Evaluation/AverageReturn              -1545.52\n",
      "Evaluation/Iteration                    167\n",
      "Evaluation/MaxReturn                  -1518.13\n",
      "Evaluation/MinReturn                  -1575.35\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     19.9293\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37647\n",
      "GaussianMLPPolicy/KL                      0.00649952\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             143.222\n",
      "GaussianMLPPolicy/LossBefore            144.699\n",
      "GaussianMLPPolicy/dLoss                   1.47684\n",
      "GaussianMLPValueFunction/LossAfter        9.55832\n",
      "GaussianMLPValueFunction/LossBefore       9.78911\n",
      "GaussianMLPValueFunction/dLoss            0.2308\n",
      "TotalEnvSteps                        201600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:30 | [trpo_pendulum] epoch #168 | Saving snapshot...\n",
      "2022-08-17 18:06:30 | [trpo_pendulum] epoch #168 | Saved\n",
      "2022-08-17 18:06:30 | [trpo_pendulum] epoch #168 | Time 106.02 s\n",
      "2022-08-17 18:06:30 | [trpo_pendulum] epoch #168 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -631.323\n",
      "Evaluation/AverageReturn              -1537.33\n",
      "Evaluation/Iteration                    168\n",
      "Evaluation/MaxReturn                  -1525.02\n",
      "Evaluation/MinReturn                  -1545.28\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      7.65788\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.42579\n",
      "GaussianMLPPolicy/KL                      0.00817137\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             142.767\n",
      "GaussianMLPPolicy/LossBefore            144.289\n",
      "GaussianMLPPolicy/dLoss                   1.52228\n",
      "GaussianMLPValueFunction/LossAfter        9.37486\n",
      "GaussianMLPValueFunction/LossBefore       9.58862\n",
      "GaussianMLPValueFunction/dLoss            0.213754\n",
      "TotalEnvSteps                        202800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:30 | [trpo_pendulum] epoch #169 | Saving snapshot...\n",
      "2022-08-17 18:06:30 | [trpo_pendulum] epoch #169 | Saved\n",
      "2022-08-17 18:06:30 | [trpo_pendulum] epoch #169 | Time 106.64 s\n",
      "2022-08-17 18:06:30 | [trpo_pendulum] epoch #169 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -668.021\n",
      "Evaluation/AverageReturn              -1598.72\n",
      "Evaluation/Iteration                    169\n",
      "Evaluation/MaxReturn                  -1575.44\n",
      "Evaluation/MinReturn                  -1621.39\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     16.2376\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.43918\n",
      "GaussianMLPPolicy/KL                      0.00812295\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             148.291\n",
      "GaussianMLPPolicy/LossBefore            149.609\n",
      "GaussianMLPPolicy/dLoss                   1.31798\n",
      "GaussianMLPValueFunction/LossAfter        9.34045\n",
      "GaussianMLPValueFunction/LossBefore       9.55746\n",
      "GaussianMLPValueFunction/dLoss            0.21701\n",
      "TotalEnvSteps                        204000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:31 | [trpo_pendulum] epoch #170 | Saving snapshot...\n",
      "2022-08-17 18:06:31 | [trpo_pendulum] epoch #170 | Saved\n",
      "2022-08-17 18:06:31 | [trpo_pendulum] epoch #170 | Time 107.28 s\n",
      "2022-08-17 18:06:31 | [trpo_pendulum] epoch #170 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -581.852\n",
      "Evaluation/AverageReturn              -1451.8\n",
      "Evaluation/Iteration                    170\n",
      "Evaluation/MaxReturn                  -1323.16\n",
      "Evaluation/MinReturn                  -1507.72\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     60.1063\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.43689\n",
      "GaussianMLPPolicy/KL                      0.0099131\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             127.335\n",
      "GaussianMLPPolicy/LossBefore            129.652\n",
      "GaussianMLPPolicy/dLoss                   2.31744\n",
      "GaussianMLPValueFunction/LossAfter        8.53064\n",
      "GaussianMLPValueFunction/LossBefore       8.65608\n",
      "GaussianMLPValueFunction/dLoss            0.125437\n",
      "TotalEnvSteps                        205200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:06:32 | [trpo_pendulum] epoch #171 | Saving snapshot...\n",
      "2022-08-17 18:06:32 | [trpo_pendulum] epoch #171 | Saved\n",
      "2022-08-17 18:06:32 | [trpo_pendulum] epoch #171 | Time 107.91 s\n",
      "2022-08-17 18:06:32 | [trpo_pendulum] epoch #171 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -574.481\n",
      "Evaluation/AverageReturn              -1405.76\n",
      "Evaluation/Iteration                    171\n",
      "Evaluation/MaxReturn                  -1381.02\n",
      "Evaluation/MinReturn                  -1430.74\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     16.5505\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.4423\n",
      "GaussianMLPPolicy/KL                      0.0067528\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             117.551\n",
      "GaussianMLPPolicy/LossBefore            119.905\n",
      "GaussianMLPPolicy/dLoss                   2.35389\n",
      "GaussianMLPValueFunction/LossAfter        7.98959\n",
      "GaussianMLPValueFunction/LossBefore       8.06758\n",
      "GaussianMLPValueFunction/dLoss            0.0779948\n",
      "TotalEnvSteps                        206400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:06:32 | [trpo_pendulum] epoch #172 | Saving snapshot...\n",
      "2022-08-17 18:06:32 | [trpo_pendulum] epoch #172 | Saved\n",
      "2022-08-17 18:06:32 | [trpo_pendulum] epoch #172 | Time 108.53 s\n",
      "2022-08-17 18:06:32 | [trpo_pendulum] epoch #172 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -614.035\n",
      "Evaluation/AverageReturn              -1403.54\n",
      "Evaluation/Iteration                    172\n",
      "Evaluation/MaxReturn                  -1355.61\n",
      "Evaluation/MinReturn                  -1446.21\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     32.0192\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.45679\n",
      "GaussianMLPPolicy/KL                      0.00647602\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             112.57\n",
      "GaussianMLPPolicy/LossBefore            114.693\n",
      "GaussianMLPPolicy/dLoss                   2.12305\n",
      "GaussianMLPValueFunction/LossAfter        7.8508\n",
      "GaussianMLPValueFunction/LossBefore       7.9185\n",
      "GaussianMLPValueFunction/dLoss            0.0676961\n",
      "TotalEnvSteps                        207600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:33 | [trpo_pendulum] epoch #173 | Saving snapshot...\n",
      "2022-08-17 18:06:33 | [trpo_pendulum] epoch #173 | Saved\n",
      "2022-08-17 18:06:33 | [trpo_pendulum] epoch #173 | Time 109.18 s\n",
      "2022-08-17 18:06:33 | [trpo_pendulum] epoch #173 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -508.712\n",
      "Evaluation/AverageReturn              -1357.28\n",
      "Evaluation/Iteration                    173\n",
      "Evaluation/MaxReturn                  -1223.81\n",
      "Evaluation/MinReturn                  -1452.72\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     76.5704\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.47809\n",
      "GaussianMLPPolicy/KL                      0.00650216\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             117.327\n",
      "GaussianMLPPolicy/LossBefore            119.065\n",
      "GaussianMLPPolicy/dLoss                   1.73854\n",
      "GaussianMLPValueFunction/LossAfter        8.00024\n",
      "GaussianMLPValueFunction/LossBefore       8.08617\n",
      "GaussianMLPValueFunction/dLoss            0.0859318\n",
      "TotalEnvSteps                        208800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:34 | [trpo_pendulum] epoch #174 | Saving snapshot...\n",
      "2022-08-17 18:06:34 | [trpo_pendulum] epoch #174 | Saved\n",
      "2022-08-17 18:06:34 | [trpo_pendulum] epoch #174 | Time 109.81 s\n",
      "2022-08-17 18:06:34 | [trpo_pendulum] epoch #174 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -664.186\n",
      "Evaluation/AverageReturn              -1572.72\n",
      "Evaluation/Iteration                    174\n",
      "Evaluation/MaxReturn                  -1562.08\n",
      "Evaluation/MinReturn                  -1587.4\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     10.343\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.46097\n",
      "GaussianMLPPolicy/KL                      0.0062855\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             141.882\n",
      "GaussianMLPPolicy/LossBefore            142.456\n",
      "GaussianMLPPolicy/dLoss                   0.573685\n",
      "GaussianMLPValueFunction/LossAfter        8.50113\n",
      "GaussianMLPValueFunction/LossBefore       8.64794\n",
      "GaussianMLPValueFunction/dLoss            0.146814\n",
      "TotalEnvSteps                        210000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:06:34 | [trpo_pendulum] epoch #175 | Saving snapshot...\n",
      "2022-08-17 18:06:34 | [trpo_pendulum] epoch #175 | Saved\n",
      "2022-08-17 18:06:34 | [trpo_pendulum] epoch #175 | Time 110.44 s\n",
      "2022-08-17 18:06:34 | [trpo_pendulum] epoch #175 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -614.973\n",
      "Evaluation/AverageReturn              -1494.98\n",
      "Evaluation/Iteration                    175\n",
      "Evaluation/MaxReturn                  -1391.73\n",
      "Evaluation/MinReturn                  -1538.4\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     49.2817\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.45401\n",
      "GaussianMLPPolicy/KL                      0.00802846\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             131.234\n",
      "GaussianMLPPolicy/LossBefore            132.931\n",
      "GaussianMLPPolicy/dLoss                   1.69652\n",
      "GaussianMLPValueFunction/LossAfter        8.16348\n",
      "GaussianMLPValueFunction/LossBefore       8.27294\n",
      "GaussianMLPValueFunction/dLoss            0.10946\n",
      "TotalEnvSteps                        211200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:35 | [trpo_pendulum] epoch #176 | Saving snapshot...\n",
      "2022-08-17 18:06:35 | [trpo_pendulum] epoch #176 | Saved\n",
      "2022-08-17 18:06:35 | [trpo_pendulum] epoch #176 | Time 111.06 s\n",
      "2022-08-17 18:06:35 | [trpo_pendulum] epoch #176 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -620.592\n",
      "Evaluation/AverageReturn              -1490.22\n",
      "Evaluation/Iteration                    176\n",
      "Evaluation/MaxReturn                  -1473.06\n",
      "Evaluation/MinReturn                  -1519.77\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     14.9971\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.48137\n",
      "GaussianMLPPolicy/KL                      0.00729855\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             128.748\n",
      "GaussianMLPPolicy/LossBefore            130.682\n",
      "GaussianMLPPolicy/dLoss                   1.9341\n",
      "GaussianMLPValueFunction/LossAfter        8.01279\n",
      "GaussianMLPValueFunction/LossBefore       8.10708\n",
      "GaussianMLPValueFunction/dLoss            0.0942936\n",
      "TotalEnvSteps                        212400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:35 | [trpo_pendulum] epoch #177 | Saving snapshot...\n",
      "2022-08-17 18:06:35 | [trpo_pendulum] epoch #177 | Saved\n",
      "2022-08-17 18:06:35 | [trpo_pendulum] epoch #177 | Time 111.69 s\n",
      "2022-08-17 18:06:35 | [trpo_pendulum] epoch #177 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -486.835\n",
      "Evaluation/AverageReturn              -1297.08\n",
      "Evaluation/Iteration                    177\n",
      "Evaluation/MaxReturn                  -1212.9\n",
      "Evaluation/MinReturn                  -1423.6\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     83.4842\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.44568\n",
      "GaussianMLPPolicy/KL                      0.00665414\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             106.028\n",
      "GaussianMLPPolicy/LossBefore            108.349\n",
      "GaussianMLPPolicy/dLoss                   2.32129\n",
      "GaussianMLPValueFunction/LossAfter        7.48697\n",
      "GaussianMLPValueFunction/LossBefore       7.53315\n",
      "GaussianMLPValueFunction/dLoss            0.0461798\n",
      "TotalEnvSteps                        213600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:36 | [trpo_pendulum] epoch #178 | Saving snapshot...\n",
      "2022-08-17 18:06:36 | [trpo_pendulum] epoch #178 | Saved\n",
      "2022-08-17 18:06:36 | [trpo_pendulum] epoch #178 | Time 112.32 s\n",
      "2022-08-17 18:06:36 | [trpo_pendulum] epoch #178 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -616.73\n",
      "Evaluation/AverageReturn              -1493.94\n",
      "Evaluation/Iteration                    178\n",
      "Evaluation/MaxReturn                  -1482.65\n",
      "Evaluation/MinReturn                  -1500.61\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.52351\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.44906\n",
      "GaussianMLPPolicy/KL                      0.00694222\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             129.989\n",
      "GaussianMLPPolicy/LossBefore            132.242\n",
      "GaussianMLPPolicy/dLoss                   2.25333\n",
      "GaussianMLPValueFunction/LossAfter        7.91355\n",
      "GaussianMLPValueFunction/LossBefore       8.00228\n",
      "GaussianMLPValueFunction/dLoss            0.0887256\n",
      "TotalEnvSteps                        214800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:37 | [trpo_pendulum] epoch #179 | Saving snapshot...\n",
      "2022-08-17 18:06:37 | [trpo_pendulum] epoch #179 | Saved\n",
      "2022-08-17 18:06:37 | [trpo_pendulum] epoch #179 | Time 112.94 s\n",
      "2022-08-17 18:06:37 | [trpo_pendulum] epoch #179 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -582.216\n",
      "Evaluation/AverageReturn              -1471.52\n",
      "Evaluation/Iteration                    179\n",
      "Evaluation/MaxReturn                  -1451.89\n",
      "Evaluation/MinReturn                  -1492.62\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     15.4506\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.45669\n",
      "GaussianMLPPolicy/KL                      0.0076229\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             130.628\n",
      "GaussianMLPPolicy/LossBefore            132.711\n",
      "GaussianMLPPolicy/dLoss                   2.08247\n",
      "GaussianMLPValueFunction/LossAfter        7.83276\n",
      "GaussianMLPValueFunction/LossBefore       7.91565\n",
      "GaussianMLPValueFunction/dLoss            0.0828867\n",
      "TotalEnvSteps                        216000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:06:37 | [trpo_pendulum] epoch #180 | Saving snapshot...\n",
      "2022-08-17 18:06:37 | [trpo_pendulum] epoch #180 | Saved\n",
      "2022-08-17 18:06:37 | [trpo_pendulum] epoch #180 | Time 113.59 s\n",
      "2022-08-17 18:06:37 | [trpo_pendulum] epoch #180 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -647.836\n",
      "Evaluation/AverageReturn              -1537.12\n",
      "Evaluation/Iteration                    180\n",
      "Evaluation/MaxReturn                  -1524.35\n",
      "Evaluation/MinReturn                  -1554.34\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     10.6202\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.5045\n",
      "GaussianMLPPolicy/KL                      0.0098813\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             133.22\n",
      "GaussianMLPPolicy/LossBefore            135.574\n",
      "GaussianMLPPolicy/dLoss                   2.35324\n",
      "GaussianMLPValueFunction/LossAfter        7.84433\n",
      "GaussianMLPValueFunction/LossBefore       7.92945\n",
      "GaussianMLPValueFunction/dLoss            0.0851183\n",
      "TotalEnvSteps                        217200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:06:38 | [trpo_pendulum] epoch #181 | Saving snapshot...\n",
      "2022-08-17 18:06:38 | [trpo_pendulum] epoch #181 | Saved\n",
      "2022-08-17 18:06:38 | [trpo_pendulum] epoch #181 | Time 114.21 s\n",
      "2022-08-17 18:06:38 | [trpo_pendulum] epoch #181 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -644.784\n",
      "Evaluation/AverageReturn              -1507.51\n",
      "Evaluation/Iteration                    181\n",
      "Evaluation/MaxReturn                  -1500.2\n",
      "Evaluation/MinReturn                  -1514.03\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      4.33726\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.51734\n",
      "GaussianMLPPolicy/KL                      0.00903883\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             124.892\n",
      "GaussianMLPPolicy/LossBefore            127.822\n",
      "GaussianMLPPolicy/dLoss                   2.92986\n",
      "GaussianMLPValueFunction/LossAfter        7.57644\n",
      "GaussianMLPValueFunction/LossBefore       7.63293\n",
      "GaussianMLPValueFunction/dLoss            0.0564909\n",
      "TotalEnvSteps                        218400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:39 | [trpo_pendulum] epoch #182 | Saving snapshot...\n",
      "2022-08-17 18:06:39 | [trpo_pendulum] epoch #182 | Saved\n",
      "2022-08-17 18:06:39 | [trpo_pendulum] epoch #182 | Time 114.84 s\n",
      "2022-08-17 18:06:39 | [trpo_pendulum] epoch #182 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -516.631\n",
      "Evaluation/AverageReturn              -1317.72\n",
      "Evaluation/Iteration                    182\n",
      "Evaluation/MaxReturn                  -1054.46\n",
      "Evaluation/MinReturn                  -1462.12\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    153.893\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.50133\n",
      "GaussianMLPPolicy/KL                      0.00662648\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             103.102\n",
      "GaussianMLPPolicy/LossBefore            105.052\n",
      "GaussianMLPPolicy/dLoss                   1.94955\n",
      "GaussianMLPValueFunction/LossAfter        7.19999\n",
      "GaussianMLPValueFunction/LossBefore       7.22537\n",
      "GaussianMLPValueFunction/dLoss            0.0253825\n",
      "TotalEnvSteps                        219600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:39 | [trpo_pendulum] epoch #183 | Saving snapshot...\n",
      "2022-08-17 18:06:39 | [trpo_pendulum] epoch #183 | Saved\n",
      "2022-08-17 18:06:39 | [trpo_pendulum] epoch #183 | Time 115.45 s\n",
      "2022-08-17 18:06:39 | [trpo_pendulum] epoch #183 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -588.347\n",
      "Evaluation/AverageReturn              -1471.55\n",
      "Evaluation/Iteration                    183\n",
      "Evaluation/MaxReturn                  -1397.04\n",
      "Evaluation/MinReturn                  -1492.34\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     33.4804\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.49791\n",
      "GaussianMLPPolicy/KL                      0.00928845\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             127.812\n",
      "GaussianMLPPolicy/LossBefore            129.866\n",
      "GaussianMLPPolicy/dLoss                   2.05418\n",
      "GaussianMLPValueFunction/LossAfter        7.583\n",
      "GaussianMLPValueFunction/LossBefore       7.64289\n",
      "GaussianMLPValueFunction/dLoss            0.0598965\n",
      "TotalEnvSteps                        220800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:40 | [trpo_pendulum] epoch #184 | Saving snapshot...\n",
      "2022-08-17 18:06:40 | [trpo_pendulum] epoch #184 | Saved\n",
      "2022-08-17 18:06:40 | [trpo_pendulum] epoch #184 | Time 116.08 s\n",
      "2022-08-17 18:06:40 | [trpo_pendulum] epoch #184 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -533.9\n",
      "Evaluation/AverageReturn              -1379.65\n",
      "Evaluation/Iteration                    184\n",
      "Evaluation/MaxReturn                  -1207.64\n",
      "Evaluation/MinReturn                  -1466.44\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     95.4425\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.52873\n",
      "GaussianMLPPolicy/KL                      0.00958598\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             113.028\n",
      "GaussianMLPPolicy/LossBefore            115.598\n",
      "GaussianMLPPolicy/dLoss                   2.5705\n",
      "GaussianMLPValueFunction/LossAfter        7.32714\n",
      "GaussianMLPValueFunction/LossBefore       7.36282\n",
      "GaussianMLPValueFunction/dLoss            0.0356784\n",
      "TotalEnvSteps                        222000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:40 | [trpo_pendulum] epoch #185 | Saving snapshot...\n",
      "2022-08-17 18:06:40 | [trpo_pendulum] epoch #185 | Saved\n",
      "2022-08-17 18:06:40 | [trpo_pendulum] epoch #185 | Time 116.70 s\n",
      "2022-08-17 18:06:40 | [trpo_pendulum] epoch #185 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -509.785\n",
      "Evaluation/AverageReturn              -1369.53\n",
      "Evaluation/Iteration                    185\n",
      "Evaluation/MaxReturn                  -1356.41\n",
      "Evaluation/MinReturn                  -1381.17\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      9.4943\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.55408\n",
      "GaussianMLPPolicy/KL                      0.00656777\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             119.142\n",
      "GaussianMLPPolicy/LossBefore            121.141\n",
      "GaussianMLPPolicy/dLoss                   1.99969\n",
      "GaussianMLPValueFunction/LossAfter        7.38548\n",
      "GaussianMLPValueFunction/LossBefore       7.42643\n",
      "GaussianMLPValueFunction/dLoss            0.0409479\n",
      "TotalEnvSteps                        223200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:41 | [trpo_pendulum] epoch #186 | Saving snapshot...\n",
      "2022-08-17 18:06:41 | [trpo_pendulum] epoch #186 | Saved\n",
      "2022-08-17 18:06:41 | [trpo_pendulum] epoch #186 | Time 117.34 s\n",
      "2022-08-17 18:06:41 | [trpo_pendulum] epoch #186 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -584.252\n",
      "Evaluation/AverageReturn              -1459.93\n",
      "Evaluation/Iteration                    186\n",
      "Evaluation/MaxReturn                  -1456.7\n",
      "Evaluation/MinReturn                  -1463.01\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      2.14586\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.57305\n",
      "GaussianMLPPolicy/KL                      0.00845872\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             122.936\n",
      "GaussianMLPPolicy/LossBefore            124.517\n",
      "GaussianMLPPolicy/dLoss                   1.5817\n",
      "GaussianMLPValueFunction/LossAfter        7.37904\n",
      "GaussianMLPValueFunction/LossBefore       7.41993\n",
      "GaussianMLPValueFunction/dLoss            0.0408878\n",
      "TotalEnvSteps                        224400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:42 | [trpo_pendulum] epoch #187 | Saving snapshot...\n",
      "2022-08-17 18:06:42 | [trpo_pendulum] epoch #187 | Saved\n",
      "2022-08-17 18:06:42 | [trpo_pendulum] epoch #187 | Time 117.96 s\n",
      "2022-08-17 18:06:42 | [trpo_pendulum] epoch #187 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -643.387\n",
      "Evaluation/AverageReturn              -1492.06\n",
      "Evaluation/Iteration                    187\n",
      "Evaluation/MaxReturn                  -1492.06\n",
      "Evaluation/MinReturn                  -1492.06\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      0\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.57146\n",
      "GaussianMLPPolicy/KL                      0.00558837\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             121.132\n",
      "GaussianMLPPolicy/LossBefore            121.896\n",
      "GaussianMLPPolicy/dLoss                   0.764015\n",
      "GaussianMLPValueFunction/LossAfter        7.28175\n",
      "GaussianMLPValueFunction/LossBefore       7.31298\n",
      "GaussianMLPValueFunction/dLoss            0.0312257\n",
      "TotalEnvSteps                        225600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:42 | [trpo_pendulum] epoch #188 | Saving snapshot...\n",
      "2022-08-17 18:06:42 | [trpo_pendulum] epoch #188 | Saved\n",
      "2022-08-17 18:06:42 | [trpo_pendulum] epoch #188 | Time 118.58 s\n",
      "2022-08-17 18:06:42 | [trpo_pendulum] epoch #188 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -656.036\n",
      "Evaluation/AverageReturn              -1511.69\n",
      "Evaluation/Iteration                    188\n",
      "Evaluation/MaxReturn                  -1509.5\n",
      "Evaluation/MinReturn                  -1513.43\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      1.30054\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.5828\n",
      "GaussianMLPPolicy/KL                      0.00983819\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             121.352\n",
      "GaussianMLPPolicy/LossBefore            123.51\n",
      "GaussianMLPPolicy/dLoss                   2.15819\n",
      "GaussianMLPValueFunction/LossAfter        7.28183\n",
      "GaussianMLPValueFunction/LossBefore       7.31279\n",
      "GaussianMLPValueFunction/dLoss            0.0309668\n",
      "TotalEnvSteps                        226800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:43 | [trpo_pendulum] epoch #189 | Saving snapshot...\n",
      "2022-08-17 18:06:43 | [trpo_pendulum] epoch #189 | Saved\n",
      "2022-08-17 18:06:43 | [trpo_pendulum] epoch #189 | Time 119.21 s\n",
      "2022-08-17 18:06:43 | [trpo_pendulum] epoch #189 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -644.725\n",
      "Evaluation/AverageReturn              -1492.56\n",
      "Evaluation/Iteration                    189\n",
      "Evaluation/MaxReturn                  -1492.45\n",
      "Evaluation/MinReturn                  -1492.82\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      0.132303\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.58235\n",
      "GaussianMLPPolicy/KL                      0.00778507\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             119.853\n",
      "GaussianMLPPolicy/LossBefore            120.854\n",
      "GaussianMLPPolicy/dLoss                   1.00138\n",
      "GaussianMLPValueFunction/LossAfter        7.22707\n",
      "GaussianMLPValueFunction/LossBefore       7.25296\n",
      "GaussianMLPValueFunction/dLoss            0.0258894\n",
      "TotalEnvSteps                        228000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:44 | [trpo_pendulum] epoch #190 | Saving snapshot...\n",
      "2022-08-17 18:06:44 | [trpo_pendulum] epoch #190 | Saved\n",
      "2022-08-17 18:06:44 | [trpo_pendulum] epoch #190 | Time 119.81 s\n",
      "2022-08-17 18:06:44 | [trpo_pendulum] epoch #190 | EpochTime 0.59 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -615.273\n",
      "Evaluation/AverageReturn              -1472.92\n",
      "Evaluation/Iteration                    190\n",
      "Evaluation/MaxReturn                  -1467.14\n",
      "Evaluation/MinReturn                  -1483.59\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.39767\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.56182\n",
      "GaussianMLPPolicy/KL                      0.00769587\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             120.314\n",
      "GaussianMLPPolicy/LossBefore            122.195\n",
      "GaussianMLPPolicy/dLoss                   1.88125\n",
      "GaussianMLPValueFunction/LossAfter        7.22699\n",
      "GaussianMLPValueFunction/LossBefore       7.25246\n",
      "GaussianMLPValueFunction/dLoss            0.0254712\n",
      "TotalEnvSteps                        229200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:44 | [trpo_pendulum] epoch #191 | Saving snapshot...\n",
      "2022-08-17 18:06:44 | [trpo_pendulum] epoch #191 | Saved\n",
      "2022-08-17 18:06:44 | [trpo_pendulum] epoch #191 | Time 120.44 s\n",
      "2022-08-17 18:06:44 | [trpo_pendulum] epoch #191 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -655.381\n",
      "Evaluation/AverageReturn              -1501.47\n",
      "Evaluation/Iteration                    191\n",
      "Evaluation/MaxReturn                  -1499.92\n",
      "Evaluation/MinReturn                  -1503.95\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      1.52509\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.58387\n",
      "GaussianMLPPolicy/KL                      0.00643464\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             118.166\n",
      "GaussianMLPPolicy/LossBefore            119.956\n",
      "GaussianMLPPolicy/dLoss                   1.78957\n",
      "GaussianMLPValueFunction/LossAfter        7.18753\n",
      "GaussianMLPValueFunction/LossBefore       7.20903\n",
      "GaussianMLPValueFunction/dLoss            0.0215039\n",
      "TotalEnvSteps                        230400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:45 | [trpo_pendulum] epoch #192 | Saving snapshot...\n",
      "2022-08-17 18:06:45 | [trpo_pendulum] epoch #192 | Saved\n",
      "2022-08-17 18:06:45 | [trpo_pendulum] epoch #192 | Time 121.06 s\n",
      "2022-08-17 18:06:45 | [trpo_pendulum] epoch #192 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -556.906\n",
      "Evaluation/AverageReturn              -1400.21\n",
      "Evaluation/Iteration                    192\n",
      "Evaluation/MaxReturn                  -1392.57\n",
      "Evaluation/MinReturn                  -1407.52\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.04506\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.56533\n",
      "GaussianMLPPolicy/KL                      0.00964547\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             113.257\n",
      "GaussianMLPPolicy/LossBefore            115.963\n",
      "GaussianMLPPolicy/dLoss                   2.70643\n",
      "GaussianMLPValueFunction/LossAfter        7.12885\n",
      "GaussianMLPValueFunction/LossBefore       7.14538\n",
      "GaussianMLPValueFunction/dLoss            0.0165339\n",
      "TotalEnvSteps                        231600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:45 | [trpo_pendulum] epoch #193 | Saving snapshot...\n",
      "2022-08-17 18:06:45 | [trpo_pendulum] epoch #193 | Saved\n",
      "2022-08-17 18:06:45 | [trpo_pendulum] epoch #193 | Time 121.67 s\n",
      "2022-08-17 18:06:45 | [trpo_pendulum] epoch #193 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -193.624\n",
      "Evaluation/AverageReturn               -790.223\n",
      "Evaluation/Iteration                    193\n",
      "Evaluation/MaxReturn                   -738.001\n",
      "Evaluation/MinReturn                   -844.736\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     36.0431\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.56532\n",
      "GaussianMLPPolicy/KL                      0.00699607\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              36.8265\n",
      "GaussianMLPPolicy/LossBefore             38.8714\n",
      "GaussianMLPPolicy/dLoss                   2.04488\n",
      "GaussianMLPValueFunction/LossAfter        6.518\n",
      "GaussianMLPValueFunction/LossBefore       6.527\n",
      "GaussianMLPValueFunction/dLoss            0.0089941\n",
      "TotalEnvSteps                        232800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:46 | [trpo_pendulum] epoch #194 | Saving snapshot...\n",
      "2022-08-17 18:06:46 | [trpo_pendulum] epoch #194 | Saved\n",
      "2022-08-17 18:06:46 | [trpo_pendulum] epoch #194 | Time 122.31 s\n",
      "2022-08-17 18:06:46 | [trpo_pendulum] epoch #194 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -636.594\n",
      "Evaluation/AverageReturn              -1484.62\n",
      "Evaluation/Iteration                    194\n",
      "Evaluation/MaxReturn                  -1474.99\n",
      "Evaluation/MinReturn                  -1491.48\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.5426\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.58306\n",
      "GaussianMLPPolicy/KL                      0.00647514\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             117.001\n",
      "GaussianMLPPolicy/LossBefore            118.844\n",
      "GaussianMLPPolicy/dLoss                   1.84242\n",
      "GaussianMLPValueFunction/LossAfter        7.16156\n",
      "GaussianMLPValueFunction/LossBefore       7.18181\n",
      "GaussianMLPValueFunction/dLoss            0.0202546\n",
      "TotalEnvSteps                        234000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:47 | [trpo_pendulum] epoch #195 | Saving snapshot...\n",
      "2022-08-17 18:06:47 | [trpo_pendulum] epoch #195 | Saved\n",
      "2022-08-17 18:06:47 | [trpo_pendulum] epoch #195 | Time 122.93 s\n",
      "2022-08-17 18:06:47 | [trpo_pendulum] epoch #195 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -643.095\n",
      "Evaluation/AverageReturn              -1491.87\n",
      "Evaluation/Iteration                    195\n",
      "Evaluation/MaxReturn                  -1488.2\n",
      "Evaluation/MinReturn                  -1493.56\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      1.97957\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.59596\n",
      "GaussianMLPPolicy/KL                      0.00662677\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             116.793\n",
      "GaussianMLPPolicy/LossBefore            118.716\n",
      "GaussianMLPPolicy/dLoss                   1.92269\n",
      "GaussianMLPValueFunction/LossAfter        7.14522\n",
      "GaussianMLPValueFunction/LossBefore       7.16447\n",
      "GaussianMLPValueFunction/dLoss            0.0192432\n",
      "TotalEnvSteps                        235200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:47 | [trpo_pendulum] epoch #196 | Saving snapshot...\n",
      "2022-08-17 18:06:47 | [trpo_pendulum] epoch #196 | Saved\n",
      "2022-08-17 18:06:47 | [trpo_pendulum] epoch #196 | Time 123.55 s\n",
      "2022-08-17 18:06:47 | [trpo_pendulum] epoch #196 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -646.844\n",
      "Evaluation/AverageReturn              -1497.25\n",
      "Evaluation/Iteration                    196\n",
      "Evaluation/MaxReturn                  -1497.24\n",
      "Evaluation/MinReturn                  -1497.26\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      0.00737273\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.59774\n",
      "GaussianMLPPolicy/KL                      0.00724977\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             117.851\n",
      "GaussianMLPPolicy/LossBefore            118.375\n",
      "GaussianMLPPolicy/dLoss                   0.524025\n",
      "GaussianMLPValueFunction/LossAfter        7.12158\n",
      "GaussianMLPValueFunction/LossBefore       7.13771\n",
      "GaussianMLPValueFunction/dLoss            0.0161271\n",
      "TotalEnvSteps                        236400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:48 | [trpo_pendulum] epoch #197 | Saving snapshot...\n",
      "2022-08-17 18:06:48 | [trpo_pendulum] epoch #197 | Saved\n",
      "2022-08-17 18:06:48 | [trpo_pendulum] epoch #197 | Time 124.16 s\n",
      "2022-08-17 18:06:48 | [trpo_pendulum] epoch #197 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -68.4623\n",
      "Evaluation/AverageReturn               -269.902\n",
      "Evaluation/Iteration                    197\n",
      "Evaluation/MaxReturn                    -11.6494\n",
      "Evaluation/MinReturn                   -939.49\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    372.947\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.58267\n",
      "GaussianMLPPolicy/KL                      0.00659879\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -50.3794\n",
      "GaussianMLPPolicy/LossBefore            -48.718\n",
      "GaussianMLPPolicy/dLoss                   1.6614\n",
      "GaussianMLPValueFunction/LossAfter        6.68587\n",
      "GaussianMLPValueFunction/LossBefore       6.69055\n",
      "GaussianMLPValueFunction/dLoss            0.00468636\n",
      "TotalEnvSteps                        237600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:48 | [trpo_pendulum] epoch #198 | Saving snapshot...\n",
      "2022-08-17 18:06:48 | [trpo_pendulum] epoch #198 | Saved\n",
      "2022-08-17 18:06:48 | [trpo_pendulum] epoch #198 | Time 124.77 s\n",
      "2022-08-17 18:06:48 | [trpo_pendulum] epoch #198 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -635.786\n",
      "Evaluation/AverageReturn              -1483.06\n",
      "Evaluation/Iteration                    198\n",
      "Evaluation/MaxReturn                  -1476.45\n",
      "Evaluation/MinReturn                  -1490\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      4.78803\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.55927\n",
      "GaussianMLPPolicy/KL                      0.00695748\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             115.371\n",
      "GaussianMLPPolicy/LossBefore            117.753\n",
      "GaussianMLPPolicy/dLoss                   2.38171\n",
      "GaussianMLPValueFunction/LossAfter        7.11884\n",
      "GaussianMLPValueFunction/LossBefore       7.13495\n",
      "GaussianMLPValueFunction/dLoss            0.0161123\n",
      "TotalEnvSteps                        238800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:49 | [trpo_pendulum] epoch #199 | Saving snapshot...\n",
      "2022-08-17 18:06:49 | [trpo_pendulum] epoch #199 | Saved\n",
      "2022-08-17 18:06:49 | [trpo_pendulum] epoch #199 | Time 125.39 s\n",
      "2022-08-17 18:06:49 | [trpo_pendulum] epoch #199 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -630.793\n",
      "Evaluation/AverageReturn              -1485.52\n",
      "Evaluation/Iteration                    199\n",
      "Evaluation/MaxReturn                  -1484.06\n",
      "Evaluation/MinReturn                  -1486.77\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      0.850492\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.54173\n",
      "GaussianMLPPolicy/KL                      0.0065919\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             116.416\n",
      "GaussianMLPPolicy/LossBefore            118.58\n",
      "GaussianMLPPolicy/dLoss                   2.16376\n",
      "GaussianMLPValueFunction/LossAfter        7.10824\n",
      "GaussianMLPValueFunction/LossBefore       7.12343\n",
      "GaussianMLPValueFunction/dLoss            0.0151892\n",
      "TotalEnvSteps                        240000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:06:50 | [trpo_pendulum] epoch #200 | Saving snapshot...\n",
      "2022-08-17 18:06:50 | [trpo_pendulum] epoch #200 | Saved\n",
      "2022-08-17 18:06:50 | [trpo_pendulum] epoch #200 | Time 126.00 s\n",
      "2022-08-17 18:06:50 | [trpo_pendulum] epoch #200 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -649.729\n",
      "Evaluation/AverageReturn              -1495.73\n",
      "Evaluation/Iteration                    200\n",
      "Evaluation/MaxReturn                  -1493.55\n",
      "Evaluation/MinReturn                  -1497.82\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      1.40739\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.57187\n",
      "GaussianMLPPolicy/KL                      0.00918416\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             114.08\n",
      "GaussianMLPPolicy/LossBefore            116.252\n",
      "GaussianMLPPolicy/dLoss                   2.17113\n",
      "GaussianMLPValueFunction/LossAfter        7.08592\n",
      "GaussianMLPValueFunction/LossBefore       7.09788\n",
      "GaussianMLPValueFunction/dLoss            0.0119538\n",
      "TotalEnvSteps                        241200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:50 | [trpo_pendulum] epoch #201 | Saving snapshot...\n",
      "2022-08-17 18:06:50 | [trpo_pendulum] epoch #201 | Saved\n",
      "2022-08-17 18:06:50 | [trpo_pendulum] epoch #201 | Time 126.60 s\n",
      "2022-08-17 18:06:50 | [trpo_pendulum] epoch #201 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -587.517\n",
      "Evaluation/AverageReturn              -1439.2\n",
      "Evaluation/Iteration                    201\n",
      "Evaluation/MaxReturn                  -1436.95\n",
      "Evaluation/MinReturn                  -1440.62\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      1.25617\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.55613\n",
      "GaussianMLPPolicy/KL                      0.00796817\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             112.929\n",
      "GaussianMLPPolicy/LossBefore            115.775\n",
      "GaussianMLPPolicy/dLoss                   2.84544\n",
      "GaussianMLPValueFunction/LossAfter        7.07633\n",
      "GaussianMLPValueFunction/LossBefore       7.0865\n",
      "GaussianMLPValueFunction/dLoss            0.0101638\n",
      "TotalEnvSteps                        242400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:51 | [trpo_pendulum] epoch #202 | Saving snapshot...\n",
      "2022-08-17 18:06:51 | [trpo_pendulum] epoch #202 | Saved\n",
      "2022-08-17 18:06:51 | [trpo_pendulum] epoch #202 | Time 127.24 s\n",
      "2022-08-17 18:06:51 | [trpo_pendulum] epoch #202 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -635.485\n",
      "Evaluation/AverageReturn              -1483\n",
      "Evaluation/Iteration                    202\n",
      "Evaluation/MaxReturn                  -1478.42\n",
      "Evaluation/MinReturn                  -1487.87\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      3.64055\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.57965\n",
      "GaussianMLPPolicy/KL                      0.00808035\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             113.483\n",
      "GaussianMLPPolicy/LossBefore            115.66\n",
      "GaussianMLPPolicy/dLoss                   2.17727\n",
      "GaussianMLPValueFunction/LossAfter        7.0736\n",
      "GaussianMLPValueFunction/LossBefore       7.08266\n",
      "GaussianMLPValueFunction/dLoss            0.00905895\n",
      "TotalEnvSteps                        243600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:52 | [trpo_pendulum] epoch #203 | Saving snapshot...\n",
      "2022-08-17 18:06:52 | [trpo_pendulum] epoch #203 | Saved\n",
      "2022-08-17 18:06:52 | [trpo_pendulum] epoch #203 | Time 127.97 s\n",
      "2022-08-17 18:06:52 | [trpo_pendulum] epoch #203 | EpochTime 0.73 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -643.652\n",
      "Evaluation/AverageReturn              -1498.97\n",
      "Evaluation/Iteration                    203\n",
      "Evaluation/MaxReturn                  -1498.56\n",
      "Evaluation/MinReturn                  -1499.28\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      0.290074\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.55514\n",
      "GaussianMLPPolicy/KL                      0.00942788\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             114.99\n",
      "GaussianMLPPolicy/LossBefore            116.841\n",
      "GaussianMLPPolicy/dLoss                   1.85138\n",
      "GaussianMLPValueFunction/LossAfter        7.07196\n",
      "GaussianMLPValueFunction/LossBefore       7.08014\n",
      "GaussianMLPValueFunction/dLoss            0.00818682\n",
      "TotalEnvSteps                        244800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:52 | [trpo_pendulum] epoch #204 | Saving snapshot...\n",
      "2022-08-17 18:06:52 | [trpo_pendulum] epoch #204 | Saved\n",
      "2022-08-17 18:06:52 | [trpo_pendulum] epoch #204 | Time 128.59 s\n",
      "2022-08-17 18:06:52 | [trpo_pendulum] epoch #204 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -632.664\n",
      "Evaluation/AverageReturn              -1478.33\n",
      "Evaluation/Iteration                    204\n",
      "Evaluation/MaxReturn                  -1465.95\n",
      "Evaluation/MinReturn                  -1482.74\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.67706\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.5987\n",
      "GaussianMLPPolicy/KL                      0.00967894\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             111.25\n",
      "GaussianMLPPolicy/LossBefore            113.767\n",
      "GaussianMLPPolicy/dLoss                   2.51711\n",
      "GaussianMLPValueFunction/LossAfter        7.05292\n",
      "GaussianMLPValueFunction/LossBefore       7.05918\n",
      "GaussianMLPValueFunction/dLoss            0.00625324\n",
      "TotalEnvSteps                        246000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:53 | [trpo_pendulum] epoch #205 | Saving snapshot...\n",
      "2022-08-17 18:06:53 | [trpo_pendulum] epoch #205 | Saved\n",
      "2022-08-17 18:06:53 | [trpo_pendulum] epoch #205 | Time 129.22 s\n",
      "2022-08-17 18:06:53 | [trpo_pendulum] epoch #205 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -627.495\n",
      "Evaluation/AverageReturn              -1473.88\n",
      "Evaluation/Iteration                    205\n",
      "Evaluation/MaxReturn                  -1470.17\n",
      "Evaluation/MinReturn                  -1479.42\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      3.31253\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.60088\n",
      "GaussianMLPPolicy/KL                      0.00860836\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             111.606\n",
      "GaussianMLPPolicy/LossBefore            113.427\n",
      "GaussianMLPPolicy/dLoss                   1.82138\n",
      "GaussianMLPValueFunction/LossAfter        7.04958\n",
      "GaussianMLPValueFunction/LossBefore       7.05519\n",
      "GaussianMLPValueFunction/dLoss            0.00560856\n",
      "TotalEnvSteps                        247200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:54 | [trpo_pendulum] epoch #206 | Saving snapshot...\n",
      "2022-08-17 18:06:54 | [trpo_pendulum] epoch #206 | Saved\n",
      "2022-08-17 18:06:54 | [trpo_pendulum] epoch #206 | Time 129.85 s\n",
      "2022-08-17 18:06:54 | [trpo_pendulum] epoch #206 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -656.444\n",
      "Evaluation/AverageReturn              -1501.9\n",
      "Evaluation/Iteration                    206\n",
      "Evaluation/MaxReturn                  -1501.41\n",
      "Evaluation/MinReturn                  -1503.48\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      0.721251\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.59751\n",
      "GaussianMLPPolicy/KL                      0.00702447\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             111.081\n",
      "GaussianMLPPolicy/LossBefore            112.821\n",
      "GaussianMLPPolicy/dLoss                   1.73941\n",
      "GaussianMLPValueFunction/LossAfter        7.04152\n",
      "GaussianMLPValueFunction/LossBefore       7.04638\n",
      "GaussianMLPValueFunction/dLoss            0.00486422\n",
      "TotalEnvSteps                        248400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:54 | [trpo_pendulum] epoch #207 | Saving snapshot...\n",
      "2022-08-17 18:06:54 | [trpo_pendulum] epoch #207 | Saved\n",
      "2022-08-17 18:06:54 | [trpo_pendulum] epoch #207 | Time 130.46 s\n",
      "2022-08-17 18:06:54 | [trpo_pendulum] epoch #207 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -650.439\n",
      "Evaluation/AverageReturn              -1505.75\n",
      "Evaluation/Iteration                    207\n",
      "Evaluation/MaxReturn                  -1504.47\n",
      "Evaluation/MinReturn                  -1507.79\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      1.01179\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.58549\n",
      "GaussianMLPPolicy/KL                      0.00706593\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             112.578\n",
      "GaussianMLPPolicy/LossBefore            114.753\n",
      "GaussianMLPPolicy/dLoss                   2.17466\n",
      "GaussianMLPValueFunction/LossAfter        7.05088\n",
      "GaussianMLPValueFunction/LossBefore       7.05594\n",
      "GaussianMLPValueFunction/dLoss            0.00506067\n",
      "TotalEnvSteps                        249600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:55 | [trpo_pendulum] epoch #208 | Saving snapshot...\n",
      "2022-08-17 18:06:55 | [trpo_pendulum] epoch #208 | Saved\n",
      "2022-08-17 18:06:55 | [trpo_pendulum] epoch #208 | Time 131.07 s\n",
      "2022-08-17 18:06:55 | [trpo_pendulum] epoch #208 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -279.95\n",
      "Evaluation/AverageReturn               -983.476\n",
      "Evaluation/Iteration                    208\n",
      "Evaluation/MaxReturn                   -911.79\n",
      "Evaluation/MinReturn                  -1020.7\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     35.8338\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.58043\n",
      "GaussianMLPPolicy/KL                      0.00751233\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              58.5532\n",
      "GaussianMLPPolicy/LossBefore             61.1965\n",
      "GaussianMLPPolicy/dLoss                   2.64327\n",
      "GaussianMLPValueFunction/LossAfter        6.73371\n",
      "GaussianMLPValueFunction/LossBefore       6.75463\n",
      "GaussianMLPValueFunction/dLoss            0.0209203\n",
      "TotalEnvSteps                        250800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:55 | [trpo_pendulum] epoch #209 | Saving snapshot...\n",
      "2022-08-17 18:06:55 | [trpo_pendulum] epoch #209 | Saved\n",
      "2022-08-17 18:06:55 | [trpo_pendulum] epoch #209 | Time 131.68 s\n",
      "2022-08-17 18:06:55 | [trpo_pendulum] epoch #209 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -655.559\n",
      "Evaluation/AverageReturn              -1501.05\n",
      "Evaluation/Iteration                    209\n",
      "Evaluation/MaxReturn                  -1499.65\n",
      "Evaluation/MinReturn                  -1505.29\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      1.937\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.59788\n",
      "GaussianMLPPolicy/KL                      0.00942043\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             109.302\n",
      "GaussianMLPPolicy/LossBefore            111.218\n",
      "GaussianMLPPolicy/dLoss                   1.91575\n",
      "GaussianMLPValueFunction/LossAfter        7.03116\n",
      "GaussianMLPValueFunction/LossBefore       7.03705\n",
      "GaussianMLPValueFunction/dLoss            0.0058918\n",
      "TotalEnvSteps                        252000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:56 | [trpo_pendulum] epoch #210 | Saving snapshot...\n",
      "2022-08-17 18:06:56 | [trpo_pendulum] epoch #210 | Saved\n",
      "2022-08-17 18:06:56 | [trpo_pendulum] epoch #210 | Time 132.31 s\n",
      "2022-08-17 18:06:56 | [trpo_pendulum] epoch #210 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -509.285\n",
      "Evaluation/AverageReturn              -1341.2\n",
      "Evaluation/Iteration                    210\n",
      "Evaluation/MaxReturn                  -1320.62\n",
      "Evaluation/MinReturn                  -1364.95\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     19.7858\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.60421\n",
      "GaussianMLPPolicy/KL                      0.00672566\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             100.078\n",
      "GaussianMLPPolicy/LossBefore            102.611\n",
      "GaussianMLPPolicy/dLoss                   2.53297\n",
      "GaussianMLPValueFunction/LossAfter        6.97174\n",
      "GaussianMLPValueFunction/LossBefore       6.97582\n",
      "GaussianMLPValueFunction/dLoss            0.0040822\n",
      "TotalEnvSteps                        253200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:57 | [trpo_pendulum] epoch #211 | Saving snapshot...\n",
      "2022-08-17 18:06:57 | [trpo_pendulum] epoch #211 | Saved\n",
      "2022-08-17 18:06:57 | [trpo_pendulum] epoch #211 | Time 132.92 s\n",
      "2022-08-17 18:06:57 | [trpo_pendulum] epoch #211 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -647.287\n",
      "Evaluation/AverageReturn              -1501.51\n",
      "Evaluation/Iteration                    211\n",
      "Evaluation/MaxReturn                  -1499.87\n",
      "Evaluation/MinReturn                  -1502.95\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      1.23752\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.57304\n",
      "GaussianMLPPolicy/KL                      0.00806381\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             110.822\n",
      "GaussianMLPPolicy/LossBefore            112.239\n",
      "GaussianMLPPolicy/dLoss                   1.41725\n",
      "GaussianMLPValueFunction/LossAfter        7.03486\n",
      "GaussianMLPValueFunction/LossBefore       7.04085\n",
      "GaussianMLPValueFunction/dLoss            0.0059948\n",
      "TotalEnvSteps                        254400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:57 | [trpo_pendulum] epoch #212 | Saving snapshot...\n",
      "2022-08-17 18:06:57 | [trpo_pendulum] epoch #212 | Saved\n",
      "2022-08-17 18:06:57 | [trpo_pendulum] epoch #212 | Time 133.55 s\n",
      "2022-08-17 18:06:57 | [trpo_pendulum] epoch #212 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -644.68\n",
      "Evaluation/AverageReturn              -1492.65\n",
      "Evaluation/Iteration                    212\n",
      "Evaluation/MaxReturn                  -1492.14\n",
      "Evaluation/MinReturn                  -1493.79\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      0.538444\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.56974\n",
      "GaussianMLPPolicy/KL                      0.00767799\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             108.396\n",
      "GaussianMLPPolicy/LossBefore            109.625\n",
      "GaussianMLPPolicy/dLoss                   1.22893\n",
      "GaussianMLPValueFunction/LossAfter        7.016\n",
      "GaussianMLPValueFunction/LossBefore       7.0206\n",
      "GaussianMLPValueFunction/dLoss            0.00460768\n",
      "TotalEnvSteps                        255600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:58 | [trpo_pendulum] epoch #213 | Saving snapshot...\n",
      "2022-08-17 18:06:58 | [trpo_pendulum] epoch #213 | Saved\n",
      "2022-08-17 18:06:58 | [trpo_pendulum] epoch #213 | Time 134.19 s\n",
      "2022-08-17 18:06:58 | [trpo_pendulum] epoch #213 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -658.924\n",
      "Evaluation/AverageReturn              -1506.09\n",
      "Evaluation/Iteration                    213\n",
      "Evaluation/MaxReturn                  -1502.43\n",
      "Evaluation/MinReturn                  -1510.84\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      2.54287\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.56626\n",
      "GaussianMLPPolicy/KL                      0.00692595\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             106.67\n",
      "GaussianMLPPolicy/LossBefore            109.433\n",
      "GaussianMLPPolicy/dLoss                   2.76302\n",
      "GaussianMLPValueFunction/LossAfter        7.01921\n",
      "GaussianMLPValueFunction/LossBefore       7.02359\n",
      "GaussianMLPValueFunction/dLoss            0.00438499\n",
      "TotalEnvSteps                        256800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:58 | [trpo_pendulum] epoch #214 | Saving snapshot...\n",
      "2022-08-17 18:06:59 | [trpo_pendulum] epoch #214 | Saved\n",
      "2022-08-17 18:06:59 | [trpo_pendulum] epoch #214 | Time 134.79 s\n",
      "2022-08-17 18:06:59 | [trpo_pendulum] epoch #214 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -615.665\n",
      "Evaluation/AverageReturn              -1458.13\n",
      "Evaluation/Iteration                    214\n",
      "Evaluation/MaxReturn                  -1440.09\n",
      "Evaluation/MinReturn                  -1472.61\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     10.5381\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.55477\n",
      "GaussianMLPPolicy/KL                      0.00970836\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             103.562\n",
      "GaussianMLPPolicy/LossBefore            106.098\n",
      "GaussianMLPPolicy/dLoss                   2.53693\n",
      "GaussianMLPValueFunction/LossAfter        6.99853\n",
      "GaussianMLPValueFunction/LossBefore       7.00242\n",
      "GaussianMLPValueFunction/dLoss            0.00388622\n",
      "TotalEnvSteps                        258000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:06:59 | [trpo_pendulum] epoch #215 | Saving snapshot...\n",
      "2022-08-17 18:06:59 | [trpo_pendulum] epoch #215 | Saved\n",
      "2022-08-17 18:06:59 | [trpo_pendulum] epoch #215 | Time 135.43 s\n",
      "2022-08-17 18:06:59 | [trpo_pendulum] epoch #215 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -660.386\n",
      "Evaluation/AverageReturn              -1514.99\n",
      "Evaluation/Iteration                    215\n",
      "Evaluation/MaxReturn                  -1511.78\n",
      "Evaluation/MinReturn                  -1517.96\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      2.00902\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.50782\n",
      "GaussianMLPPolicy/KL                      0.00647575\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             108.464\n",
      "GaussianMLPPolicy/LossBefore            109.981\n",
      "GaussianMLPPolicy/dLoss                   1.51627\n",
      "GaussianMLPValueFunction/LossAfter        7.01799\n",
      "GaussianMLPValueFunction/LossBefore       7.02228\n",
      "GaussianMLPValueFunction/dLoss            0.00428486\n",
      "TotalEnvSteps                        259200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:00 | [trpo_pendulum] epoch #216 | Saving snapshot...\n",
      "2022-08-17 18:07:00 | [trpo_pendulum] epoch #216 | Saved\n",
      "2022-08-17 18:07:00 | [trpo_pendulum] epoch #216 | Time 136.06 s\n",
      "2022-08-17 18:07:00 | [trpo_pendulum] epoch #216 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -610.494\n",
      "Evaluation/AverageReturn              -1477.49\n",
      "Evaluation/Iteration                    216\n",
      "Evaluation/MaxReturn                  -1399.46\n",
      "Evaluation/MinReturn                  -1506.38\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     35.9066\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.49155\n",
      "GaussianMLPPolicy/KL                      0.00576824\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             108.406\n",
      "GaussianMLPPolicy/LossBefore            110.063\n",
      "GaussianMLPPolicy/dLoss                   1.6574\n",
      "GaussianMLPValueFunction/LossAfter        7.03219\n",
      "GaussianMLPValueFunction/LossBefore       7.03684\n",
      "GaussianMLPValueFunction/dLoss            0.0046525\n",
      "TotalEnvSteps                        260400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:00 | [trpo_pendulum] epoch #217 | Saving snapshot...\n",
      "2022-08-17 18:07:00 | [trpo_pendulum] epoch #217 | Saved\n",
      "2022-08-17 18:07:00 | [trpo_pendulum] epoch #217 | Time 136.66 s\n",
      "2022-08-17 18:07:00 | [trpo_pendulum] epoch #217 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -363.033\n",
      "Evaluation/AverageReturn              -1024.15\n",
      "Evaluation/Iteration                    217\n",
      "Evaluation/MaxReturn                   -805.43\n",
      "Evaluation/MinReturn                  -1349.96\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    175.175\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.49234\n",
      "GaussianMLPPolicy/KL                      0.00832353\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              46.275\n",
      "GaussianMLPPolicy/LossBefore             47.6884\n",
      "GaussianMLPPolicy/dLoss                   1.41338\n",
      "GaussianMLPValueFunction/LossAfter        6.65999\n",
      "GaussianMLPValueFunction/LossBefore       6.70989\n",
      "GaussianMLPValueFunction/dLoss            0.0498948\n",
      "TotalEnvSteps                        261600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:01 | [trpo_pendulum] epoch #218 | Saving snapshot...\n",
      "2022-08-17 18:07:01 | [trpo_pendulum] epoch #218 | Saved\n",
      "2022-08-17 18:07:01 | [trpo_pendulum] epoch #218 | Time 137.29 s\n",
      "2022-08-17 18:07:01 | [trpo_pendulum] epoch #218 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -644.969\n",
      "Evaluation/AverageReturn              -1492.33\n",
      "Evaluation/Iteration                    218\n",
      "Evaluation/MaxReturn                  -1491.85\n",
      "Evaluation/MinReturn                  -1493.77\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      0.660119\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.48033\n",
      "GaussianMLPPolicy/KL                      0.00940307\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             104.585\n",
      "GaussianMLPPolicy/LossBefore            105.968\n",
      "GaussianMLPPolicy/dLoss                   1.38287\n",
      "GaussianMLPValueFunction/LossAfter        6.9955\n",
      "GaussianMLPValueFunction/LossBefore       7.00255\n",
      "GaussianMLPValueFunction/dLoss            0.00704813\n",
      "TotalEnvSteps                        262800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:02 | [trpo_pendulum] epoch #219 | Saving snapshot...\n",
      "2022-08-17 18:07:02 | [trpo_pendulum] epoch #219 | Saved\n",
      "2022-08-17 18:07:02 | [trpo_pendulum] epoch #219 | Time 137.90 s\n",
      "2022-08-17 18:07:02 | [trpo_pendulum] epoch #219 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -583.423\n",
      "Evaluation/AverageReturn              -1425.04\n",
      "Evaluation/Iteration                    219\n",
      "Evaluation/MaxReturn                  -1421.07\n",
      "Evaluation/MinReturn                  -1429.76\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      2.71807\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.47716\n",
      "GaussianMLPPolicy/KL                      0.00802847\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             100.368\n",
      "GaussianMLPPolicy/LossBefore            102.426\n",
      "GaussianMLPPolicy/dLoss                   2.05882\n",
      "GaussianMLPValueFunction/LossAfter        6.97371\n",
      "GaussianMLPValueFunction/LossBefore       6.979\n",
      "GaussianMLPValueFunction/dLoss            0.00529528\n",
      "TotalEnvSteps                        264000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:02 | [trpo_pendulum] epoch #220 | Saving snapshot...\n",
      "2022-08-17 18:07:02 | [trpo_pendulum] epoch #220 | Saved\n",
      "2022-08-17 18:07:02 | [trpo_pendulum] epoch #220 | Time 138.54 s\n",
      "2022-08-17 18:07:02 | [trpo_pendulum] epoch #220 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -650.725\n",
      "Evaluation/AverageReturn              -1499.64\n",
      "Evaluation/Iteration                    220\n",
      "Evaluation/MaxReturn                  -1489.17\n",
      "Evaluation/MinReturn                  -1506.06\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.4732\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.48587\n",
      "GaussianMLPPolicy/KL                      0.00845824\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             103.15\n",
      "GaussianMLPPolicy/LossBefore            105.327\n",
      "GaussianMLPPolicy/dLoss                   2.17654\n",
      "GaussianMLPValueFunction/LossAfter        6.9956\n",
      "GaussianMLPValueFunction/LossBefore       7.00128\n",
      "GaussianMLPValueFunction/dLoss            0.00567102\n",
      "TotalEnvSteps                        265200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:03 | [trpo_pendulum] epoch #221 | Saving snapshot...\n",
      "2022-08-17 18:07:03 | [trpo_pendulum] epoch #221 | Saved\n",
      "2022-08-17 18:07:03 | [trpo_pendulum] epoch #221 | Time 139.16 s\n",
      "2022-08-17 18:07:03 | [trpo_pendulum] epoch #221 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -657.934\n",
      "Evaluation/AverageReturn              -1511.28\n",
      "Evaluation/Iteration                    221\n",
      "Evaluation/MaxReturn                  -1509.43\n",
      "Evaluation/MinReturn                  -1512.85\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      1.26712\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.48549\n",
      "GaussianMLPPolicy/KL                      0.00939251\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             103.463\n",
      "GaussianMLPPolicy/LossBefore            105.715\n",
      "GaussianMLPPolicy/dLoss                   2.25146\n",
      "GaussianMLPValueFunction/LossAfter        6.99254\n",
      "GaussianMLPValueFunction/LossBefore       6.99748\n",
      "GaussianMLPValueFunction/dLoss            0.0049448\n",
      "TotalEnvSteps                        266400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:03 | [trpo_pendulum] epoch #222 | Saving snapshot...\n",
      "2022-08-17 18:07:04 | [trpo_pendulum] epoch #222 | Saved\n",
      "2022-08-17 18:07:04 | [trpo_pendulum] epoch #222 | Time 139.79 s\n",
      "2022-08-17 18:07:04 | [trpo_pendulum] epoch #222 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -273.21\n",
      "Evaluation/AverageReturn               -920.603\n",
      "Evaluation/Iteration                    222\n",
      "Evaluation/MaxReturn                   -778.06\n",
      "Evaluation/MinReturn                  -1055.42\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     80.4152\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.47309\n",
      "GaussianMLPPolicy/KL                      0.00803264\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              40.7965\n",
      "GaussianMLPPolicy/LossBefore             41.444\n",
      "GaussianMLPPolicy/dLoss                   0.647507\n",
      "GaussianMLPValueFunction/LossAfter        6.58503\n",
      "GaussianMLPValueFunction/LossBefore       6.64457\n",
      "GaussianMLPValueFunction/dLoss            0.0595369\n",
      "TotalEnvSteps                        267600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:04 | [trpo_pendulum] epoch #223 | Saving snapshot...\n",
      "2022-08-17 18:07:04 | [trpo_pendulum] epoch #223 | Saved\n",
      "2022-08-17 18:07:04 | [trpo_pendulum] epoch #223 | Time 140.40 s\n",
      "2022-08-17 18:07:04 | [trpo_pendulum] epoch #223 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -620.232\n",
      "Evaluation/AverageReturn              -1473.14\n",
      "Evaluation/Iteration                    223\n",
      "Evaluation/MaxReturn                  -1468.09\n",
      "Evaluation/MinReturn                  -1481.94\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      4.4362\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.45451\n",
      "GaussianMLPPolicy/KL                      0.00667791\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             101.002\n",
      "GaussianMLPPolicy/LossBefore            103.567\n",
      "GaussianMLPPolicy/dLoss                   2.56479\n",
      "GaussianMLPValueFunction/LossAfter        6.98546\n",
      "GaussianMLPValueFunction/LossBefore       6.99597\n",
      "GaussianMLPValueFunction/dLoss            0.0105085\n",
      "TotalEnvSteps                        268800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:05 | [trpo_pendulum] epoch #224 | Saving snapshot...\n",
      "2022-08-17 18:07:05 | [trpo_pendulum] epoch #224 | Saved\n",
      "2022-08-17 18:07:05 | [trpo_pendulum] epoch #224 | Time 141.01 s\n",
      "2022-08-17 18:07:05 | [trpo_pendulum] epoch #224 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -653.684\n",
      "Evaluation/AverageReturn              -1508.38\n",
      "Evaluation/Iteration                    224\n",
      "Evaluation/MaxReturn                  -1507.25\n",
      "Evaluation/MinReturn                  -1509.2\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      0.670921\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.44444\n",
      "GaussianMLPPolicy/KL                      0.00647916\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             102.471\n",
      "GaussianMLPPolicy/LossBefore            104.001\n",
      "GaussianMLPPolicy/dLoss                   1.52999\n",
      "GaussianMLPValueFunction/LossAfter        6.98296\n",
      "GaussianMLPValueFunction/LossBefore       6.99148\n",
      "GaussianMLPValueFunction/dLoss            0.00851822\n",
      "TotalEnvSteps                        270000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:05 | [trpo_pendulum] epoch #225 | Saving snapshot...\n",
      "2022-08-17 18:07:05 | [trpo_pendulum] epoch #225 | Saved\n",
      "2022-08-17 18:07:05 | [trpo_pendulum] epoch #225 | Time 141.63 s\n",
      "2022-08-17 18:07:05 | [trpo_pendulum] epoch #225 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -578.54\n",
      "Evaluation/AverageReturn              -1412.53\n",
      "Evaluation/Iteration                    225\n",
      "Evaluation/MaxReturn                  -1396.14\n",
      "Evaluation/MinReturn                  -1427.53\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      9.43029\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.43428\n",
      "GaussianMLPPolicy/KL                      0.00658687\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              93.0878\n",
      "GaussianMLPPolicy/LossBefore             95.8296\n",
      "GaussianMLPPolicy/dLoss                   2.74182\n",
      "GaussianMLPValueFunction/LossAfter        6.92443\n",
      "GaussianMLPValueFunction/LossBefore       6.92896\n",
      "GaussianMLPValueFunction/dLoss            0.00453043\n",
      "TotalEnvSteps                        271200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:06 | [trpo_pendulum] epoch #226 | Saving snapshot...\n",
      "2022-08-17 18:07:06 | [trpo_pendulum] epoch #226 | Saved\n",
      "2022-08-17 18:07:06 | [trpo_pendulum] epoch #226 | Time 142.26 s\n",
      "2022-08-17 18:07:06 | [trpo_pendulum] epoch #226 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -658.727\n",
      "Evaluation/AverageReturn              -1503.92\n",
      "Evaluation/Iteration                    226\n",
      "Evaluation/MaxReturn                  -1502.32\n",
      "Evaluation/MinReturn                  -1506.23\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      1.27033\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.49143\n",
      "GaussianMLPPolicy/KL                      0.00961215\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              98.2608\n",
      "GaussianMLPPolicy/LossBefore            100.291\n",
      "GaussianMLPPolicy/dLoss                   2.03006\n",
      "GaussianMLPValueFunction/LossAfter        6.96135\n",
      "GaussianMLPValueFunction/LossBefore       6.96665\n",
      "GaussianMLPValueFunction/dLoss            0.00530052\n",
      "TotalEnvSteps                        272400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:07 | [trpo_pendulum] epoch #227 | Saving snapshot...\n",
      "2022-08-17 18:07:07 | [trpo_pendulum] epoch #227 | Saved\n",
      "2022-08-17 18:07:07 | [trpo_pendulum] epoch #227 | Time 142.88 s\n",
      "2022-08-17 18:07:07 | [trpo_pendulum] epoch #227 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -474.999\n",
      "Evaluation/AverageReturn              -1257.28\n",
      "Evaluation/Iteration                    227\n",
      "Evaluation/MaxReturn                  -1115.79\n",
      "Evaluation/MinReturn                  -1431.7\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    120.932\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.466\n",
      "GaussianMLPPolicy/KL                      0.00978542\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              73.9267\n",
      "GaussianMLPPolicy/LossBefore             75.3442\n",
      "GaussianMLPPolicy/dLoss                   1.41745\n",
      "GaussianMLPValueFunction/LossAfter        6.78455\n",
      "GaussianMLPValueFunction/LossBefore       6.7985\n",
      "GaussianMLPValueFunction/dLoss            0.0139489\n",
      "TotalEnvSteps                        273600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:07 | [trpo_pendulum] epoch #228 | Saving snapshot...\n",
      "2022-08-17 18:07:07 | [trpo_pendulum] epoch #228 | Saved\n",
      "2022-08-17 18:07:07 | [trpo_pendulum] epoch #228 | Time 143.52 s\n",
      "2022-08-17 18:07:07 | [trpo_pendulum] epoch #228 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -650.423\n",
      "Evaluation/AverageReturn              -1503.23\n",
      "Evaluation/Iteration                    228\n",
      "Evaluation/MaxReturn                  -1501.85\n",
      "Evaluation/MinReturn                  -1504.08\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      0.781434\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.46102\n",
      "GaussianMLPPolicy/KL                      0.00647833\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              99.298\n",
      "GaussianMLPPolicy/LossBefore            100.667\n",
      "GaussianMLPPolicy/dLoss                   1.36914\n",
      "GaussianMLPValueFunction/LossAfter        6.96176\n",
      "GaussianMLPValueFunction/LossBefore       6.96944\n",
      "GaussianMLPValueFunction/dLoss            0.00768232\n",
      "TotalEnvSteps                        274800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:08 | [trpo_pendulum] epoch #229 | Saving snapshot...\n",
      "2022-08-17 18:07:08 | [trpo_pendulum] epoch #229 | Saved\n",
      "2022-08-17 18:07:08 | [trpo_pendulum] epoch #229 | Time 144.13 s\n",
      "2022-08-17 18:07:08 | [trpo_pendulum] epoch #229 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -628.777\n",
      "Evaluation/AverageReturn              -1475.44\n",
      "Evaluation/Iteration                    229\n",
      "Evaluation/MaxReturn                  -1466.94\n",
      "Evaluation/MinReturn                  -1483.82\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      7.51287\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.43778\n",
      "GaussianMLPPolicy/KL                      0.00686814\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              95.0997\n",
      "GaussianMLPPolicy/LossBefore             97.7524\n",
      "GaussianMLPPolicy/dLoss                   2.65269\n",
      "GaussianMLPValueFunction/LossAfter        6.94943\n",
      "GaussianMLPValueFunction/LossBefore       6.95484\n",
      "GaussianMLPValueFunction/dLoss            0.00541162\n",
      "TotalEnvSteps                        276000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:08 | [trpo_pendulum] epoch #230 | Saving snapshot...\n",
      "2022-08-17 18:07:08 | [trpo_pendulum] epoch #230 | Saved\n",
      "2022-08-17 18:07:08 | [trpo_pendulum] epoch #230 | Time 144.75 s\n",
      "2022-08-17 18:07:08 | [trpo_pendulum] epoch #230 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -524.196\n",
      "Evaluation/AverageReturn              -1368.28\n",
      "Evaluation/Iteration                    230\n",
      "Evaluation/MaxReturn                  -1354.31\n",
      "Evaluation/MinReturn                  -1405.46\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     16.9785\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.41779\n",
      "GaussianMLPPolicy/KL                      0.00780491\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              93.1881\n",
      "GaussianMLPPolicy/LossBefore             94.0438\n",
      "GaussianMLPPolicy/dLoss                   0.855721\n",
      "GaussianMLPValueFunction/LossAfter        6.92926\n",
      "GaussianMLPValueFunction/LossBefore       6.93361\n",
      "GaussianMLPValueFunction/dLoss            0.00434923\n",
      "TotalEnvSteps                        277200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:09 | [trpo_pendulum] epoch #231 | Saving snapshot...\n",
      "2022-08-17 18:07:09 | [trpo_pendulum] epoch #231 | Saved\n",
      "2022-08-17 18:07:09 | [trpo_pendulum] epoch #231 | Time 145.36 s\n",
      "2022-08-17 18:07:09 | [trpo_pendulum] epoch #231 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -617.373\n",
      "Evaluation/AverageReturn              -1477.99\n",
      "Evaluation/Iteration                    231\n",
      "Evaluation/MaxReturn                  -1431.42\n",
      "Evaluation/MinReturn                  -1496.2\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     21.8412\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.43955\n",
      "GaussianMLPPolicy/KL                      0.00912804\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              98.4228\n",
      "GaussianMLPPolicy/LossBefore             99.6586\n",
      "GaussianMLPPolicy/dLoss                   1.2358\n",
      "GaussianMLPValueFunction/LossAfter        6.95431\n",
      "GaussianMLPValueFunction/LossBefore       6.95935\n",
      "GaussianMLPValueFunction/dLoss            0.00504255\n",
      "TotalEnvSteps                        278400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:10 | [trpo_pendulum] epoch #232 | Saving snapshot...\n",
      "2022-08-17 18:07:10 | [trpo_pendulum] epoch #232 | Saved\n",
      "2022-08-17 18:07:10 | [trpo_pendulum] epoch #232 | Time 145.96 s\n",
      "2022-08-17 18:07:10 | [trpo_pendulum] epoch #232 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -547.203\n",
      "Evaluation/AverageReturn              -1361.82\n",
      "Evaluation/Iteration                    232\n",
      "Evaluation/MaxReturn                  -1302.71\n",
      "Evaluation/MinReturn                  -1409.81\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     36.8221\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.40228\n",
      "GaussianMLPPolicy/KL                      0.00886965\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              82.8792\n",
      "GaussianMLPPolicy/LossBefore             85.0233\n",
      "GaussianMLPPolicy/dLoss                   2.14405\n",
      "GaussianMLPValueFunction/LossAfter        6.84504\n",
      "GaussianMLPValueFunction/LossBefore       6.85358\n",
      "GaussianMLPValueFunction/dLoss            0.00853586\n",
      "TotalEnvSteps                        279600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:10 | [trpo_pendulum] epoch #233 | Saving snapshot...\n",
      "2022-08-17 18:07:10 | [trpo_pendulum] epoch #233 | Saved\n",
      "2022-08-17 18:07:10 | [trpo_pendulum] epoch #233 | Time 146.58 s\n",
      "2022-08-17 18:07:10 | [trpo_pendulum] epoch #233 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -483.997\n",
      "Evaluation/AverageReturn              -1221.54\n",
      "Evaluation/Iteration                    233\n",
      "Evaluation/MaxReturn                   -922.228\n",
      "Evaluation/MinReturn                  -1393\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    165.393\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.42969\n",
      "GaussianMLPPolicy/KL                      0.00887035\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              61.0907\n",
      "GaussianMLPPolicy/LossBefore             63.8394\n",
      "GaussianMLPPolicy/dLoss                   2.74877\n",
      "GaussianMLPValueFunction/LossAfter        6.69289\n",
      "GaussianMLPValueFunction/LossBefore       6.71894\n",
      "GaussianMLPValueFunction/dLoss            0.0260501\n",
      "TotalEnvSteps                        280800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:11 | [trpo_pendulum] epoch #234 | Saving snapshot...\n",
      "2022-08-17 18:07:11 | [trpo_pendulum] epoch #234 | Saved\n",
      "2022-08-17 18:07:11 | [trpo_pendulum] epoch #234 | Time 147.18 s\n",
      "2022-08-17 18:07:11 | [trpo_pendulum] epoch #234 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -656.684\n",
      "Evaluation/AverageReturn              -1500.88\n",
      "Evaluation/Iteration                    234\n",
      "Evaluation/MaxReturn                  -1500.07\n",
      "Evaluation/MinReturn                  -1502.18\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      0.655889\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.40173\n",
      "GaussianMLPPolicy/KL                      0.00860134\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              92.7547\n",
      "GaussianMLPPolicy/LossBefore             94.6361\n",
      "GaussianMLPPolicy/dLoss                   1.88135\n",
      "GaussianMLPValueFunction/LossAfter        6.92843\n",
      "GaussianMLPValueFunction/LossBefore       6.93948\n",
      "GaussianMLPValueFunction/dLoss            0.0110517\n",
      "TotalEnvSteps                        282000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:12 | [trpo_pendulum] epoch #235 | Saving snapshot...\n",
      "2022-08-17 18:07:12 | [trpo_pendulum] epoch #235 | Saved\n",
      "2022-08-17 18:07:12 | [trpo_pendulum] epoch #235 | Time 147.80 s\n",
      "2022-08-17 18:07:12 | [trpo_pendulum] epoch #235 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -638.214\n",
      "Evaluation/AverageReturn              -1560.11\n",
      "Evaluation/Iteration                    235\n",
      "Evaluation/MaxReturn                  -1547.85\n",
      "Evaluation/MinReturn                  -1575.5\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      9.64917\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.41046\n",
      "GaussianMLPPolicy/KL                      0.00547622\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             111.469\n",
      "GaussianMLPPolicy/LossBefore            112.256\n",
      "GaussianMLPPolicy/dLoss                   0.787132\n",
      "GaussianMLPValueFunction/LossAfter        7.08827\n",
      "GaussianMLPValueFunction/LossBefore       7.12473\n",
      "GaussianMLPValueFunction/dLoss            0.0364609\n",
      "TotalEnvSteps                        283200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:12 | [trpo_pendulum] epoch #236 | Saving snapshot...\n",
      "2022-08-17 18:07:12 | [trpo_pendulum] epoch #236 | Saved\n",
      "2022-08-17 18:07:12 | [trpo_pendulum] epoch #236 | Time 148.41 s\n",
      "2022-08-17 18:07:12 | [trpo_pendulum] epoch #236 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -557.457\n",
      "Evaluation/AverageReturn              -1331.3\n",
      "Evaluation/Iteration                    236\n",
      "Evaluation/MaxReturn                  -1137.79\n",
      "Evaluation/MinReturn                  -1456.64\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    121.64\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.4124\n",
      "GaussianMLPPolicy/KL                      0.0071981\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              70.7335\n",
      "GaussianMLPPolicy/LossBefore             72.9898\n",
      "GaussianMLPPolicy/dLoss                   2.25624\n",
      "GaussianMLPValueFunction/LossAfter        6.75629\n",
      "GaussianMLPValueFunction/LossBefore       6.7734\n",
      "GaussianMLPValueFunction/dLoss            0.0171089\n",
      "TotalEnvSteps                        284400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:07:13 | [trpo_pendulum] epoch #237 | Saving snapshot...\n",
      "2022-08-17 18:07:13 | [trpo_pendulum] epoch #237 | Saved\n",
      "2022-08-17 18:07:13 | [trpo_pendulum] epoch #237 | Time 149.04 s\n",
      "2022-08-17 18:07:13 | [trpo_pendulum] epoch #237 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -644.556\n",
      "Evaluation/AverageReturn              -1565.69\n",
      "Evaluation/Iteration                    237\n",
      "Evaluation/MaxReturn                  -1557.59\n",
      "Evaluation/MinReturn                  -1575.65\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      7.55727\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.43559\n",
      "GaussianMLPPolicy/KL                      0.00569856\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             108.906\n",
      "GaussianMLPPolicy/LossBefore            110.902\n",
      "GaussianMLPPolicy/dLoss                   1.99683\n",
      "GaussianMLPValueFunction/LossAfter        7.07711\n",
      "GaussianMLPValueFunction/LossBefore       7.10088\n",
      "GaussianMLPValueFunction/dLoss            0.0237651\n",
      "TotalEnvSteps                        285600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:13 | [trpo_pendulum] epoch #238 | Saving snapshot...\n",
      "2022-08-17 18:07:13 | [trpo_pendulum] epoch #238 | Saved\n",
      "2022-08-17 18:07:13 | [trpo_pendulum] epoch #238 | Time 149.65 s\n",
      "2022-08-17 18:07:13 | [trpo_pendulum] epoch #238 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -589.44\n",
      "Evaluation/AverageReturn              -1515.27\n",
      "Evaluation/Iteration                    238\n",
      "Evaluation/MaxReturn                  -1503.49\n",
      "Evaluation/MinReturn                  -1526.35\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      7.27931\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.44383\n",
      "GaussianMLPPolicy/KL                      0.00980682\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             108.188\n",
      "GaussianMLPPolicy/LossBefore            108.899\n",
      "GaussianMLPPolicy/dLoss                   0.710945\n",
      "GaussianMLPValueFunction/LossAfter        7.05078\n",
      "GaussianMLPValueFunction/LossBefore       7.06212\n",
      "GaussianMLPValueFunction/dLoss            0.0113478\n",
      "TotalEnvSteps                        286800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:14 | [trpo_pendulum] epoch #239 | Saving snapshot...\n",
      "2022-08-17 18:07:14 | [trpo_pendulum] epoch #239 | Saved\n",
      "2022-08-17 18:07:14 | [trpo_pendulum] epoch #239 | Time 150.27 s\n",
      "2022-08-17 18:07:14 | [trpo_pendulum] epoch #239 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -507.036\n",
      "Evaluation/AverageReturn              -1300.39\n",
      "Evaluation/Iteration                    239\n",
      "Evaluation/MaxReturn                  -1180.61\n",
      "Evaluation/MinReturn                  -1459.75\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     97.6081\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.44573\n",
      "GaussianMLPPolicy/KL                      0.00689944\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              68.7221\n",
      "GaussianMLPPolicy/LossBefore             70.7187\n",
      "GaussianMLPPolicy/dLoss                   1.9966\n",
      "GaussianMLPValueFunction/LossAfter        6.76911\n",
      "GaussianMLPValueFunction/LossBefore       6.78927\n",
      "GaussianMLPValueFunction/dLoss            0.0201612\n",
      "TotalEnvSteps                        288000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:15 | [trpo_pendulum] epoch #240 | Saving snapshot...\n",
      "2022-08-17 18:07:15 | [trpo_pendulum] epoch #240 | Saved\n",
      "2022-08-17 18:07:15 | [trpo_pendulum] epoch #240 | Time 150.88 s\n",
      "2022-08-17 18:07:15 | [trpo_pendulum] epoch #240 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -574.301\n",
      "Evaluation/AverageReturn              -1328.03\n",
      "Evaluation/Iteration                    240\n",
      "Evaluation/MaxReturn                  -1120.5\n",
      "Evaluation/MinReturn                  -1477.85\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    121.373\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.44337\n",
      "GaussianMLPPolicy/KL                      0.00649025\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              65.571\n",
      "GaussianMLPPolicy/LossBefore             67.8013\n",
      "GaussianMLPPolicy/dLoss                   2.23026\n",
      "GaussianMLPValueFunction/LossAfter        6.75852\n",
      "GaussianMLPValueFunction/LossBefore       6.77269\n",
      "GaussianMLPValueFunction/dLoss            0.0141726\n",
      "TotalEnvSteps                        289200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:15 | [trpo_pendulum] epoch #241 | Saving snapshot...\n",
      "2022-08-17 18:07:15 | [trpo_pendulum] epoch #241 | Saved\n",
      "2022-08-17 18:07:15 | [trpo_pendulum] epoch #241 | Time 151.50 s\n",
      "2022-08-17 18:07:15 | [trpo_pendulum] epoch #241 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -648.81\n",
      "Evaluation/AverageReturn              -1504.96\n",
      "Evaluation/Iteration                    241\n",
      "Evaluation/MaxReturn                  -1502.83\n",
      "Evaluation/MinReturn                  -1506.18\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      1.4099\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.45177\n",
      "GaussianMLPPolicy/KL                      0.00743112\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              91.5079\n",
      "GaussianMLPPolicy/LossBefore             92.9277\n",
      "GaussianMLPPolicy/dLoss                   1.41982\n",
      "GaussianMLPValueFunction/LossAfter        6.91368\n",
      "GaussianMLPValueFunction/LossBefore       6.91907\n",
      "GaussianMLPValueFunction/dLoss            0.00538778\n",
      "TotalEnvSteps                        290400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:16 | [trpo_pendulum] epoch #242 | Saving snapshot...\n",
      "2022-08-17 18:07:16 | [trpo_pendulum] epoch #242 | Saved\n",
      "2022-08-17 18:07:16 | [trpo_pendulum] epoch #242 | Time 152.13 s\n",
      "2022-08-17 18:07:16 | [trpo_pendulum] epoch #242 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -665.933\n",
      "Evaluation/AverageReturn              -1603.48\n",
      "Evaluation/Iteration                    242\n",
      "Evaluation/MaxReturn                  -1592.74\n",
      "Evaluation/MinReturn                  -1617.96\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     10.5495\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.43844\n",
      "GaussianMLPPolicy/KL                      0.00795256\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             109.115\n",
      "GaussianMLPPolicy/LossBefore            110.443\n",
      "GaussianMLPPolicy/dLoss                   1.32859\n",
      "GaussianMLPValueFunction/LossAfter        7.06108\n",
      "GaussianMLPValueFunction/LossBefore       7.08372\n",
      "GaussianMLPValueFunction/dLoss            0.0226421\n",
      "TotalEnvSteps                        291600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:16 | [trpo_pendulum] epoch #243 | Saving snapshot...\n",
      "2022-08-17 18:07:16 | [trpo_pendulum] epoch #243 | Saved\n",
      "2022-08-17 18:07:16 | [trpo_pendulum] epoch #243 | Time 152.74 s\n",
      "2022-08-17 18:07:16 | [trpo_pendulum] epoch #243 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -649.228\n",
      "Evaluation/AverageReturn              -1504.61\n",
      "Evaluation/Iteration                    243\n",
      "Evaluation/MaxReturn                  -1503.25\n",
      "Evaluation/MinReturn                  -1507.13\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      1.29885\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.45675\n",
      "GaussianMLPPolicy/KL                      0.00984598\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              88.9806\n",
      "GaussianMLPPolicy/LossBefore             91.2502\n",
      "GaussianMLPPolicy/dLoss                   2.26963\n",
      "GaussianMLPValueFunction/LossAfter        6.90423\n",
      "GaussianMLPValueFunction/LossBefore       6.90837\n",
      "GaussianMLPValueFunction/dLoss            0.00414276\n",
      "TotalEnvSteps                        292800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:17 | [trpo_pendulum] epoch #244 | Saving snapshot...\n",
      "2022-08-17 18:07:17 | [trpo_pendulum] epoch #244 | Saved\n",
      "2022-08-17 18:07:17 | [trpo_pendulum] epoch #244 | Time 153.38 s\n",
      "2022-08-17 18:07:17 | [trpo_pendulum] epoch #244 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -597.475\n",
      "Evaluation/AverageReturn              -1420.01\n",
      "Evaluation/Iteration                    244\n",
      "Evaluation/MaxReturn                  -1360.84\n",
      "Evaluation/MinReturn                  -1467.24\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     39.7804\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.46415\n",
      "GaussianMLPPolicy/KL                      0.00623678\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              81.1554\n",
      "GaussianMLPPolicy/LossBefore             81.9623\n",
      "GaussianMLPPolicy/dLoss                   0.806938\n",
      "GaussianMLPValueFunction/LossAfter        6.83725\n",
      "GaussianMLPValueFunction/LossBefore       6.84462\n",
      "GaussianMLPValueFunction/dLoss            0.00737143\n",
      "TotalEnvSteps                        294000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:18 | [trpo_pendulum] epoch #245 | Saving snapshot...\n",
      "2022-08-17 18:07:18 | [trpo_pendulum] epoch #245 | Saved\n",
      "2022-08-17 18:07:18 | [trpo_pendulum] epoch #245 | Time 153.99 s\n",
      "2022-08-17 18:07:18 | [trpo_pendulum] epoch #245 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -541.088\n",
      "Evaluation/AverageReturn              -1313.27\n",
      "Evaluation/Iteration                    245\n",
      "Evaluation/MaxReturn                   -962.492\n",
      "Evaluation/MinReturn                  -1438.94\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    164.284\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.4689\n",
      "GaussianMLPPolicy/KL                      0.00920232\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              61.6278\n",
      "GaussianMLPPolicy/LossBefore             63.5099\n",
      "GaussianMLPPolicy/dLoss                   1.88211\n",
      "GaussianMLPValueFunction/LossAfter        6.69017\n",
      "GaussianMLPValueFunction/LossBefore       6.71365\n",
      "GaussianMLPValueFunction/dLoss            0.0234799\n",
      "TotalEnvSteps                        295200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:18 | [trpo_pendulum] epoch #246 | Saving snapshot...\n",
      "2022-08-17 18:07:18 | [trpo_pendulum] epoch #246 | Saved\n",
      "2022-08-17 18:07:18 | [trpo_pendulum] epoch #246 | Time 154.60 s\n",
      "2022-08-17 18:07:18 | [trpo_pendulum] epoch #246 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -574.687\n",
      "Evaluation/AverageReturn              -1431.3\n",
      "Evaluation/Iteration                    246\n",
      "Evaluation/MaxReturn                  -1332.47\n",
      "Evaluation/MinReturn                  -1483.88\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     55.8266\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.46217\n",
      "GaussianMLPPolicy/KL                      0.00806716\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              82.9399\n",
      "GaussianMLPPolicy/LossBefore             84.5495\n",
      "GaussianMLPPolicy/dLoss                   1.60954\n",
      "GaussianMLPValueFunction/LossAfter        6.8659\n",
      "GaussianMLPValueFunction/LossBefore       6.87135\n",
      "GaussianMLPValueFunction/dLoss            0.00545549\n",
      "TotalEnvSteps                        296400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:19 | [trpo_pendulum] epoch #247 | Saving snapshot...\n",
      "2022-08-17 18:07:19 | [trpo_pendulum] epoch #247 | Saved\n",
      "2022-08-17 18:07:19 | [trpo_pendulum] epoch #247 | Time 155.22 s\n",
      "2022-08-17 18:07:19 | [trpo_pendulum] epoch #247 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -658.45\n",
      "Evaluation/AverageReturn              -1591.77\n",
      "Evaluation/Iteration                    247\n",
      "Evaluation/MaxReturn                  -1564.16\n",
      "Evaluation/MinReturn                  -1606.95\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     14.9982\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.47309\n",
      "GaussianMLPPolicy/KL                      0.00564115\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             105.501\n",
      "GaussianMLPPolicy/LossBefore            106.87\n",
      "GaussianMLPPolicy/dLoss                   1.36891\n",
      "GaussianMLPValueFunction/LossAfter        7.04781\n",
      "GaussianMLPValueFunction/LossBefore       7.0769\n",
      "GaussianMLPValueFunction/dLoss            0.0290818\n",
      "TotalEnvSteps                        297600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:20 | [trpo_pendulum] epoch #248 | Saving snapshot...\n",
      "2022-08-17 18:07:20 | [trpo_pendulum] epoch #248 | Saved\n",
      "2022-08-17 18:07:20 | [trpo_pendulum] epoch #248 | Time 155.84 s\n",
      "2022-08-17 18:07:20 | [trpo_pendulum] epoch #248 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -673.566\n",
      "Evaluation/AverageReturn              -1614.78\n",
      "Evaluation/Iteration                    248\n",
      "Evaluation/MaxReturn                  -1586.45\n",
      "Evaluation/MinReturn                  -1629.62\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     14.0545\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.50328\n",
      "GaussianMLPPolicy/KL                      0.00987866\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             106.825\n",
      "GaussianMLPPolicy/LossBefore            107.405\n",
      "GaussianMLPPolicy/dLoss                   0.580872\n",
      "GaussianMLPValueFunction/LossAfter        7.03881\n",
      "GaussianMLPValueFunction/LossBefore       7.05339\n",
      "GaussianMLPValueFunction/dLoss            0.0145779\n",
      "TotalEnvSteps                        298800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:20 | [trpo_pendulum] epoch #249 | Saving snapshot...\n",
      "2022-08-17 18:07:20 | [trpo_pendulum] epoch #249 | Saved\n",
      "2022-08-17 18:07:20 | [trpo_pendulum] epoch #249 | Time 156.45 s\n",
      "2022-08-17 18:07:20 | [trpo_pendulum] epoch #249 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -579.684\n",
      "Evaluation/AverageReturn              -1407.06\n",
      "Evaluation/Iteration                    249\n",
      "Evaluation/MaxReturn                  -1186.85\n",
      "Evaluation/MinReturn                  -1465.62\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     99.3086\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.49316\n",
      "GaussianMLPPolicy/KL                      0.00667186\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              73.6615\n",
      "GaussianMLPPolicy/LossBefore             75.8469\n",
      "GaussianMLPPolicy/dLoss                   2.18538\n",
      "GaussianMLPValueFunction/LossAfter        6.81045\n",
      "GaussianMLPValueFunction/LossBefore       6.82182\n",
      "GaussianMLPValueFunction/dLoss            0.0113649\n",
      "TotalEnvSteps                        300000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:21 | [trpo_pendulum] epoch #250 | Saving snapshot...\n",
      "2022-08-17 18:07:21 | [trpo_pendulum] epoch #250 | Saved\n",
      "2022-08-17 18:07:21 | [trpo_pendulum] epoch #250 | Time 157.06 s\n",
      "2022-08-17 18:07:21 | [trpo_pendulum] epoch #250 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -690.116\n",
      "Evaluation/AverageReturn              -1635.27\n",
      "Evaluation/Iteration                    250\n",
      "Evaluation/MaxReturn                  -1627.39\n",
      "Evaluation/MinReturn                  -1638.98\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      4.05815\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.54756\n",
      "GaussianMLPPolicy/KL                      0.00831224\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             105.864\n",
      "GaussianMLPPolicy/LossBefore            107.557\n",
      "GaussianMLPPolicy/dLoss                   1.69262\n",
      "GaussianMLPValueFunction/LossAfter        7.03967\n",
      "GaussianMLPValueFunction/LossBefore       7.05367\n",
      "GaussianMLPValueFunction/dLoss            0.0139999\n",
      "TotalEnvSteps                        301200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:21 | [trpo_pendulum] epoch #251 | Saving snapshot...\n",
      "2022-08-17 18:07:21 | [trpo_pendulum] epoch #251 | Saved\n",
      "2022-08-17 18:07:21 | [trpo_pendulum] epoch #251 | Time 157.68 s\n",
      "2022-08-17 18:07:21 | [trpo_pendulum] epoch #251 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -606.765\n",
      "Evaluation/AverageReturn              -1471.95\n",
      "Evaluation/Iteration                    251\n",
      "Evaluation/MaxReturn                  -1411.66\n",
      "Evaluation/MinReturn                  -1496.89\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     27.9043\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.56131\n",
      "GaussianMLPPolicy/KL                      0.00747854\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              85.8429\n",
      "GaussianMLPPolicy/LossBefore             86.5746\n",
      "GaussianMLPPolicy/dLoss                   0.731667\n",
      "GaussianMLPValueFunction/LossAfter        6.87686\n",
      "GaussianMLPValueFunction/LossBefore       6.88258\n",
      "GaussianMLPValueFunction/dLoss            0.00571871\n",
      "TotalEnvSteps                        302400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:22 | [trpo_pendulum] epoch #252 | Saving snapshot...\n",
      "2022-08-17 18:07:22 | [trpo_pendulum] epoch #252 | Saved\n",
      "2022-08-17 18:07:22 | [trpo_pendulum] epoch #252 | Time 158.29 s\n",
      "2022-08-17 18:07:22 | [trpo_pendulum] epoch #252 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -687.812\n",
      "Evaluation/AverageReturn              -1638.76\n",
      "Evaluation/Iteration                    252\n",
      "Evaluation/MaxReturn                  -1632.23\n",
      "Evaluation/MinReturn                  -1642.6\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      3.45688\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.56935\n",
      "GaussianMLPPolicy/KL                      0.00713519\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             106.077\n",
      "GaussianMLPPolicy/LossBefore            107.558\n",
      "GaussianMLPPolicy/dLoss                   1.48087\n",
      "GaussianMLPValueFunction/LossAfter        7.04079\n",
      "GaussianMLPValueFunction/LossBefore       7.05281\n",
      "GaussianMLPValueFunction/dLoss            0.0120249\n",
      "TotalEnvSteps                        303600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:23 | [trpo_pendulum] epoch #253 | Saving snapshot...\n",
      "2022-08-17 18:07:23 | [trpo_pendulum] epoch #253 | Saved\n",
      "2022-08-17 18:07:23 | [trpo_pendulum] epoch #253 | Time 158.93 s\n",
      "2022-08-17 18:07:23 | [trpo_pendulum] epoch #253 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -676.091\n",
      "Evaluation/AverageReturn              -1616.35\n",
      "Evaluation/Iteration                    253\n",
      "Evaluation/MaxReturn                  -1599.85\n",
      "Evaluation/MinReturn                  -1630.8\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     11.3498\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.5874\n",
      "GaussianMLPPolicy/KL                      0.00713081\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             102.287\n",
      "GaussianMLPPolicy/LossBefore            103.952\n",
      "GaussianMLPPolicy/dLoss                   1.66413\n",
      "GaussianMLPValueFunction/LossAfter        7.0126\n",
      "GaussianMLPValueFunction/LossBefore       7.01826\n",
      "GaussianMLPValueFunction/dLoss            0.00566244\n",
      "TotalEnvSteps                        304800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:23 | [trpo_pendulum] epoch #254 | Saving snapshot...\n",
      "2022-08-17 18:07:23 | [trpo_pendulum] epoch #254 | Saved\n",
      "2022-08-17 18:07:23 | [trpo_pendulum] epoch #254 | Time 159.56 s\n",
      "2022-08-17 18:07:23 | [trpo_pendulum] epoch #254 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -685.422\n",
      "Evaluation/AverageReturn              -1629.66\n",
      "Evaluation/Iteration                    254\n",
      "Evaluation/MaxReturn                  -1614.41\n",
      "Evaluation/MinReturn                  -1642.05\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      8.36514\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.58752\n",
      "GaussianMLPPolicy/KL                      0.00685111\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             103.411\n",
      "GaussianMLPPolicy/LossBefore            104.206\n",
      "GaussianMLPPolicy/dLoss                   0.794937\n",
      "GaussianMLPValueFunction/LossAfter        7.01384\n",
      "GaussianMLPValueFunction/LossBefore       7.0186\n",
      "GaussianMLPValueFunction/dLoss            0.00475502\n",
      "TotalEnvSteps                        306000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:24 | [trpo_pendulum] epoch #255 | Saving snapshot...\n",
      "2022-08-17 18:07:24 | [trpo_pendulum] epoch #255 | Saved\n",
      "2022-08-17 18:07:24 | [trpo_pendulum] epoch #255 | Time 160.19 s\n",
      "2022-08-17 18:07:24 | [trpo_pendulum] epoch #255 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -571.312\n",
      "Evaluation/AverageReturn              -1496.82\n",
      "Evaluation/Iteration                    255\n",
      "Evaluation/MaxReturn                  -1472.75\n",
      "Evaluation/MinReturn                  -1508.79\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     12.6127\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.58104\n",
      "GaussianMLPPolicy/KL                      0.00920095\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              94.7937\n",
      "GaussianMLPPolicy/LossBefore             96.4264\n",
      "GaussianMLPPolicy/dLoss                   1.63271\n",
      "GaussianMLPValueFunction/LossAfter        6.96697\n",
      "GaussianMLPValueFunction/LossBefore       6.97096\n",
      "GaussianMLPValueFunction/dLoss            0.00399113\n",
      "TotalEnvSteps                        307200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:25 | [trpo_pendulum] epoch #256 | Saving snapshot...\n",
      "2022-08-17 18:07:25 | [trpo_pendulum] epoch #256 | Saved\n",
      "2022-08-17 18:07:25 | [trpo_pendulum] epoch #256 | Time 160.81 s\n",
      "2022-08-17 18:07:25 | [trpo_pendulum] epoch #256 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -563.935\n",
      "Evaluation/AverageReturn              -1379.38\n",
      "Evaluation/Iteration                    256\n",
      "Evaluation/MaxReturn                  -1309.28\n",
      "Evaluation/MinReturn                  -1472.12\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     65.8405\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.56835\n",
      "GaussianMLPPolicy/KL                      0.00691559\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              67.5114\n",
      "GaussianMLPPolicy/LossBefore             69.0549\n",
      "GaussianMLPPolicy/dLoss                   1.54356\n",
      "GaussianMLPValueFunction/LossAfter        6.78504\n",
      "GaussianMLPValueFunction/LossBefore       6.80776\n",
      "GaussianMLPValueFunction/dLoss            0.0227242\n",
      "TotalEnvSteps                        308400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:25 | [trpo_pendulum] epoch #257 | Saving snapshot...\n",
      "2022-08-17 18:07:25 | [trpo_pendulum] epoch #257 | Saved\n",
      "2022-08-17 18:07:25 | [trpo_pendulum] epoch #257 | Time 161.43 s\n",
      "2022-08-17 18:07:25 | [trpo_pendulum] epoch #257 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -651.301\n",
      "Evaluation/AverageReturn              -1501.57\n",
      "Evaluation/Iteration                    257\n",
      "Evaluation/MaxReturn                  -1499.78\n",
      "Evaluation/MinReturn                  -1504.62\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      1.69842\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.56706\n",
      "GaussianMLPPolicy/KL                      0.00938841\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              79.1733\n",
      "GaussianMLPPolicy/LossBefore             80.4464\n",
      "GaussianMLPPolicy/dLoss                   1.27308\n",
      "GaussianMLPValueFunction/LossAfter        6.83943\n",
      "GaussianMLPValueFunction/LossBefore       6.84615\n",
      "GaussianMLPValueFunction/dLoss            0.00672102\n",
      "TotalEnvSteps                        309600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:26 | [trpo_pendulum] epoch #258 | Saving snapshot...\n",
      "2022-08-17 18:07:26 | [trpo_pendulum] epoch #258 | Saved\n",
      "2022-08-17 18:07:26 | [trpo_pendulum] epoch #258 | Time 162.09 s\n",
      "2022-08-17 18:07:26 | [trpo_pendulum] epoch #258 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -585.003\n",
      "Evaluation/AverageReturn              -1451.96\n",
      "Evaluation/Iteration                    258\n",
      "Evaluation/MaxReturn                  -1427.73\n",
      "Evaluation/MinReturn                  -1466.31\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     13.299\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.54152\n",
      "GaussianMLPPolicy/KL                      0.00673583\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              77.5891\n",
      "GaussianMLPPolicy/LossBefore             79.5059\n",
      "GaussianMLPPolicy/dLoss                   1.91679\n",
      "GaussianMLPValueFunction/LossAfter        6.82916\n",
      "GaussianMLPValueFunction/LossBefore       6.83522\n",
      "GaussianMLPValueFunction/dLoss            0.00606251\n",
      "TotalEnvSteps                        310800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:26 | [trpo_pendulum] epoch #259 | Saving snapshot...\n",
      "2022-08-17 18:07:26 | [trpo_pendulum] epoch #259 | Saved\n",
      "2022-08-17 18:07:26 | [trpo_pendulum] epoch #259 | Time 162.71 s\n",
      "2022-08-17 18:07:26 | [trpo_pendulum] epoch #259 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -661.742\n",
      "Evaluation/AverageReturn              -1508.12\n",
      "Evaluation/Iteration                    259\n",
      "Evaluation/MaxReturn                  -1502.98\n",
      "Evaluation/MinReturn                  -1512.98\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      3.20123\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.57218\n",
      "GaussianMLPPolicy/KL                      0.00865874\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              76.7167\n",
      "GaussianMLPPolicy/LossBefore             78.4571\n",
      "GaussianMLPPolicy/dLoss                   1.74037\n",
      "GaussianMLPValueFunction/LossAfter        6.83056\n",
      "GaussianMLPValueFunction/LossBefore       6.83503\n",
      "GaussianMLPValueFunction/dLoss            0.00447321\n",
      "TotalEnvSteps                        312000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:27 | [trpo_pendulum] epoch #260 | Saving snapshot...\n",
      "2022-08-17 18:07:27 | [trpo_pendulum] epoch #260 | Saved\n",
      "2022-08-17 18:07:27 | [trpo_pendulum] epoch #260 | Time 163.33 s\n",
      "2022-08-17 18:07:27 | [trpo_pendulum] epoch #260 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -607.779\n",
      "Evaluation/AverageReturn              -1498.47\n",
      "Evaluation/Iteration                    260\n",
      "Evaluation/MaxReturn                  -1347.01\n",
      "Evaluation/MinReturn                  -1569.79\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     74.3721\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.59082\n",
      "GaussianMLPPolicy/KL                      0.00634767\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              81.2745\n",
      "GaussianMLPPolicy/LossBefore             83.1572\n",
      "GaussianMLPPolicy/dLoss                   1.88268\n",
      "GaussianMLPValueFunction/LossAfter        6.86873\n",
      "GaussianMLPValueFunction/LossBefore       6.87374\n",
      "GaussianMLPValueFunction/dLoss            0.00500727\n",
      "TotalEnvSteps                        313200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:28 | [trpo_pendulum] epoch #261 | Saving snapshot...\n",
      "2022-08-17 18:07:28 | [trpo_pendulum] epoch #261 | Saved\n",
      "2022-08-17 18:07:28 | [trpo_pendulum] epoch #261 | Time 163.95 s\n",
      "2022-08-17 18:07:28 | [trpo_pendulum] epoch #261 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -651.28\n",
      "Evaluation/AverageReturn              -1500.21\n",
      "Evaluation/Iteration                    261\n",
      "Evaluation/MaxReturn                  -1499.4\n",
      "Evaluation/MinReturn                  -1500.95\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      0.47936\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.61338\n",
      "GaussianMLPPolicy/KL                      0.00972306\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              76.2955\n",
      "GaussianMLPPolicy/LossBefore             77.3546\n",
      "GaussianMLPPolicy/dLoss                   1.05913\n",
      "GaussianMLPValueFunction/LossAfter        6.81991\n",
      "GaussianMLPValueFunction/LossBefore       6.82452\n",
      "GaussianMLPValueFunction/dLoss            0.00461149\n",
      "TotalEnvSteps                        314400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:28 | [trpo_pendulum] epoch #262 | Saving snapshot...\n",
      "2022-08-17 18:07:28 | [trpo_pendulum] epoch #262 | Saved\n",
      "2022-08-17 18:07:28 | [trpo_pendulum] epoch #262 | Time 164.58 s\n",
      "2022-08-17 18:07:28 | [trpo_pendulum] epoch #262 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -702.302\n",
      "Evaluation/AverageReturn              -1649.44\n",
      "Evaluation/Iteration                    262\n",
      "Evaluation/MaxReturn                  -1644.38\n",
      "Evaluation/MinReturn                  -1653.92\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      3.05599\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.61167\n",
      "GaussianMLPPolicy/KL                      0.00676168\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              98.9402\n",
      "GaussianMLPPolicy/LossBefore            100.495\n",
      "GaussianMLPPolicy/dLoss                   1.55475\n",
      "GaussianMLPValueFunction/LossAfter        7.00787\n",
      "GaussianMLPValueFunction/LossBefore       7.0327\n",
      "GaussianMLPValueFunction/dLoss            0.0248308\n",
      "TotalEnvSteps                        315600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:29 | [trpo_pendulum] epoch #263 | Saving snapshot...\n",
      "2022-08-17 18:07:29 | [trpo_pendulum] epoch #263 | Saved\n",
      "2022-08-17 18:07:29 | [trpo_pendulum] epoch #263 | Time 165.21 s\n",
      "2022-08-17 18:07:29 | [trpo_pendulum] epoch #263 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -619.264\n",
      "Evaluation/AverageReturn              -1541.09\n",
      "Evaluation/Iteration                    263\n",
      "Evaluation/MaxReturn                  -1499.61\n",
      "Evaluation/MinReturn                  -1564.58\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     21.2846\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62635\n",
      "GaussianMLPPolicy/KL                      0.00818332\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              89.2539\n",
      "GaussianMLPPolicy/LossBefore             91.1763\n",
      "GaussianMLPPolicy/dLoss                   1.92236\n",
      "GaussianMLPValueFunction/LossAfter        6.94617\n",
      "GaussianMLPValueFunction/LossBefore       6.95129\n",
      "GaussianMLPValueFunction/dLoss            0.00512218\n",
      "TotalEnvSteps                        316800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:30 | [trpo_pendulum] epoch #264 | Saving snapshot...\n",
      "2022-08-17 18:07:30 | [trpo_pendulum] epoch #264 | Saved\n",
      "2022-08-17 18:07:30 | [trpo_pendulum] epoch #264 | Time 165.85 s\n",
      "2022-08-17 18:07:30 | [trpo_pendulum] epoch #264 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -663.316\n",
      "Evaluation/AverageReturn              -1509.26\n",
      "Evaluation/Iteration                    264\n",
      "Evaluation/MaxReturn                  -1505.58\n",
      "Evaluation/MinReturn                  -1513.47\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      3.27086\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.61547\n",
      "GaussianMLPPolicy/KL                      0.00891687\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              72.9548\n",
      "GaussianMLPPolicy/LossBefore             74.6626\n",
      "GaussianMLPPolicy/dLoss                   1.70787\n",
      "GaussianMLPValueFunction/LossAfter        6.81307\n",
      "GaussianMLPValueFunction/LossBefore       6.82318\n",
      "GaussianMLPValueFunction/dLoss            0.0101118\n",
      "TotalEnvSteps                        318000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:30 | [trpo_pendulum] epoch #265 | Saving snapshot...\n",
      "2022-08-17 18:07:30 | [trpo_pendulum] epoch #265 | Saved\n",
      "2022-08-17 18:07:30 | [trpo_pendulum] epoch #265 | Time 166.48 s\n",
      "2022-08-17 18:07:30 | [trpo_pendulum] epoch #265 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -617.729\n",
      "Evaluation/AverageReturn              -1523.18\n",
      "Evaluation/Iteration                    265\n",
      "Evaluation/MaxReturn                  -1508.76\n",
      "Evaluation/MinReturn                  -1535.4\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     10.2063\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62985\n",
      "GaussianMLPPolicy/KL                      0.00677926\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              86.0594\n",
      "GaussianMLPPolicy/LossBefore             87.414\n",
      "GaussianMLPPolicy/dLoss                   1.35463\n",
      "GaussianMLPValueFunction/LossAfter        6.92166\n",
      "GaussianMLPValueFunction/LossBefore       6.92677\n",
      "GaussianMLPValueFunction/dLoss            0.00510836\n",
      "TotalEnvSteps                        319200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:31 | [trpo_pendulum] epoch #266 | Saving snapshot...\n",
      "2022-08-17 18:07:31 | [trpo_pendulum] epoch #266 | Saved\n",
      "2022-08-17 18:07:31 | [trpo_pendulum] epoch #266 | Time 167.12 s\n",
      "2022-08-17 18:07:31 | [trpo_pendulum] epoch #266 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -609.263\n",
      "Evaluation/AverageReturn              -1523.52\n",
      "Evaluation/Iteration                    266\n",
      "Evaluation/MaxReturn                  -1513.43\n",
      "Evaluation/MinReturn                  -1536.45\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      8.70471\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62609\n",
      "GaussianMLPPolicy/KL                      0.00851123\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              84.2746\n",
      "GaussianMLPPolicy/LossBefore             85.944\n",
      "GaussianMLPPolicy/dLoss                   1.66936\n",
      "GaussianMLPValueFunction/LossAfter        6.91986\n",
      "GaussianMLPValueFunction/LossBefore       6.92429\n",
      "GaussianMLPValueFunction/dLoss            0.00443935\n",
      "TotalEnvSteps                        320400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:31 | [trpo_pendulum] epoch #267 | Saving snapshot...\n",
      "2022-08-17 18:07:31 | [trpo_pendulum] epoch #267 | Saved\n",
      "2022-08-17 18:07:31 | [trpo_pendulum] epoch #267 | Time 167.74 s\n",
      "2022-08-17 18:07:31 | [trpo_pendulum] epoch #267 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -622.106\n",
      "Evaluation/AverageReturn              -1534.39\n",
      "Evaluation/Iteration                    267\n",
      "Evaluation/MaxReturn                  -1463.72\n",
      "Evaluation/MinReturn                  -1607.48\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     45.0591\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.63877\n",
      "GaussianMLPPolicy/KL                      0.00598386\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              82.6909\n",
      "GaussianMLPPolicy/LossBefore             84.2133\n",
      "GaussianMLPPolicy/dLoss                   1.52239\n",
      "GaussianMLPValueFunction/LossAfter        6.88851\n",
      "GaussianMLPValueFunction/LossBefore       6.89274\n",
      "GaussianMLPValueFunction/dLoss            0.00422621\n",
      "TotalEnvSteps                        321600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:32 | [trpo_pendulum] epoch #268 | Saving snapshot...\n",
      "2022-08-17 18:07:32 | [trpo_pendulum] epoch #268 | Saved\n",
      "2022-08-17 18:07:32 | [trpo_pendulum] epoch #268 | Time 168.35 s\n",
      "2022-08-17 18:07:32 | [trpo_pendulum] epoch #268 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -538.918\n",
      "Evaluation/AverageReturn              -1323.27\n",
      "Evaluation/Iteration                    268\n",
      "Evaluation/MaxReturn                  -1263.65\n",
      "Evaluation/MinReturn                  -1350.39\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     28.1616\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.64976\n",
      "GaussianMLPPolicy/KL                      0.00825767\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              50.8054\n",
      "GaussianMLPPolicy/LossBefore             52.6334\n",
      "GaussianMLPPolicy/dLoss                   1.82791\n",
      "GaussianMLPValueFunction/LossAfter        6.64082\n",
      "GaussianMLPValueFunction/LossBefore       6.67883\n",
      "GaussianMLPValueFunction/dLoss            0.038003\n",
      "TotalEnvSteps                        322800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:33 | [trpo_pendulum] epoch #269 | Saving snapshot...\n",
      "2022-08-17 18:07:33 | [trpo_pendulum] epoch #269 | Saved\n",
      "2022-08-17 18:07:33 | [trpo_pendulum] epoch #269 | Time 168.97 s\n",
      "2022-08-17 18:07:33 | [trpo_pendulum] epoch #269 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -663.039\n",
      "Evaluation/AverageReturn              -1612.22\n",
      "Evaluation/Iteration                    269\n",
      "Evaluation/MaxReturn                  -1593.15\n",
      "Evaluation/MinReturn                  -1619.5\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      9.28443\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.65026\n",
      "GaussianMLPPolicy/KL                      0.00961168\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              92.6595\n",
      "GaussianMLPPolicy/LossBefore             94.2251\n",
      "GaussianMLPPolicy/dLoss                   1.56565\n",
      "GaussianMLPValueFunction/LossAfter        6.96717\n",
      "GaussianMLPValueFunction/LossBefore       6.9889\n",
      "GaussianMLPValueFunction/dLoss            0.0217247\n",
      "TotalEnvSteps                        324000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:33 | [trpo_pendulum] epoch #270 | Saving snapshot...\n",
      "2022-08-17 18:07:33 | [trpo_pendulum] epoch #270 | Saved\n",
      "2022-08-17 18:07:33 | [trpo_pendulum] epoch #270 | Time 169.59 s\n",
      "2022-08-17 18:07:33 | [trpo_pendulum] epoch #270 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -642.058\n",
      "Evaluation/AverageReturn              -1574.3\n",
      "Evaluation/Iteration                    270\n",
      "Evaluation/MaxReturn                  -1564.07\n",
      "Evaluation/MinReturn                  -1591\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      8.73121\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.67643\n",
      "GaussianMLPPolicy/KL                      0.00598076\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              87.6653\n",
      "GaussianMLPPolicy/LossBefore             88.8417\n",
      "GaussianMLPPolicy/dLoss                   1.17646\n",
      "GaussianMLPValueFunction/LossAfter        6.93603\n",
      "GaussianMLPValueFunction/LossBefore       6.94432\n",
      "GaussianMLPValueFunction/dLoss            0.00829172\n",
      "TotalEnvSteps                        325200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:34 | [trpo_pendulum] epoch #271 | Saving snapshot...\n",
      "2022-08-17 18:07:34 | [trpo_pendulum] epoch #271 | Saved\n",
      "2022-08-17 18:07:34 | [trpo_pendulum] epoch #271 | Time 170.21 s\n",
      "2022-08-17 18:07:34 | [trpo_pendulum] epoch #271 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -644.396\n",
      "Evaluation/AverageReturn              -1585.91\n",
      "Evaluation/Iteration                    271\n",
      "Evaluation/MaxReturn                  -1564.23\n",
      "Evaluation/MinReturn                  -1604.84\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     12.4372\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.67739\n",
      "GaussianMLPPolicy/KL                      0.00859645\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              88.741\n",
      "GaussianMLPPolicy/LossBefore             90.5654\n",
      "GaussianMLPPolicy/dLoss                   1.82443\n",
      "GaussianMLPValueFunction/LossAfter        6.94109\n",
      "GaussianMLPValueFunction/LossBefore       6.9473\n",
      "GaussianMLPValueFunction/dLoss            0.00621414\n",
      "TotalEnvSteps                        326400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:35 | [trpo_pendulum] epoch #272 | Saving snapshot...\n",
      "2022-08-17 18:07:35 | [trpo_pendulum] epoch #272 | Saved\n",
      "2022-08-17 18:07:35 | [trpo_pendulum] epoch #272 | Time 170.83 s\n",
      "2022-08-17 18:07:35 | [trpo_pendulum] epoch #272 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -650.459\n",
      "Evaluation/AverageReturn              -1498.4\n",
      "Evaluation/Iteration                    272\n",
      "Evaluation/MaxReturn                  -1494.96\n",
      "Evaluation/MinReturn                  -1503.02\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      2.43257\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.64726\n",
      "GaussianMLPPolicy/KL                      0.00937135\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              68.8952\n",
      "GaussianMLPPolicy/LossBefore             69.463\n",
      "GaussianMLPPolicy/dLoss                   0.567787\n",
      "GaussianMLPValueFunction/LossAfter        6.78324\n",
      "GaussianMLPValueFunction/LossBefore       6.79389\n",
      "GaussianMLPValueFunction/dLoss            0.0106411\n",
      "TotalEnvSteps                        327600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:35 | [trpo_pendulum] epoch #273 | Saving snapshot...\n",
      "2022-08-17 18:07:35 | [trpo_pendulum] epoch #273 | Saved\n",
      "2022-08-17 18:07:35 | [trpo_pendulum] epoch #273 | Time 171.45 s\n",
      "2022-08-17 18:07:35 | [trpo_pendulum] epoch #273 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -564.793\n",
      "Evaluation/AverageReturn              -1386.09\n",
      "Evaluation/Iteration                    273\n",
      "Evaluation/MaxReturn                  -1259.53\n",
      "Evaluation/MinReturn                  -1431.29\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     60.5511\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.66363\n",
      "GaussianMLPPolicy/KL                      0.00861044\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              54.1397\n",
      "GaussianMLPPolicy/LossBefore             56.6508\n",
      "GaussianMLPPolicy/dLoss                   2.51105\n",
      "GaussianMLPValueFunction/LossAfter        6.64844\n",
      "GaussianMLPValueFunction/LossBefore       6.6744\n",
      "GaussianMLPValueFunction/dLoss            0.0259523\n",
      "TotalEnvSteps                        328800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:36 | [trpo_pendulum] epoch #274 | Saving snapshot...\n",
      "2022-08-17 18:07:36 | [trpo_pendulum] epoch #274 | Saved\n",
      "2022-08-17 18:07:36 | [trpo_pendulum] epoch #274 | Time 172.07 s\n",
      "2022-08-17 18:07:36 | [trpo_pendulum] epoch #274 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -471.899\n",
      "Evaluation/AverageReturn              -1356.12\n",
      "Evaluation/Iteration                    274\n",
      "Evaluation/MaxReturn                  -1244.97\n",
      "Evaluation/MinReturn                  -1393.36\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     51.0133\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.63735\n",
      "GaussianMLPPolicy/KL                      0.00593905\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              67.8559\n",
      "GaussianMLPPolicy/LossBefore             69.5145\n",
      "GaussianMLPPolicy/dLoss                   1.65858\n",
      "GaussianMLPValueFunction/LossAfter        6.80687\n",
      "GaussianMLPValueFunction/LossBefore       6.81131\n",
      "GaussianMLPValueFunction/dLoss            0.00443792\n",
      "TotalEnvSteps                        330000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:36 | [trpo_pendulum] epoch #275 | Saving snapshot...\n",
      "2022-08-17 18:07:36 | [trpo_pendulum] epoch #275 | Saved\n",
      "2022-08-17 18:07:36 | [trpo_pendulum] epoch #275 | Time 172.70 s\n",
      "2022-08-17 18:07:36 | [trpo_pendulum] epoch #275 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -629.099\n",
      "Evaluation/AverageReturn              -1487.63\n",
      "Evaluation/Iteration                    275\n",
      "Evaluation/MaxReturn                  -1480.1\n",
      "Evaluation/MinReturn                  -1494.5\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.38562\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.63649\n",
      "GaussianMLPPolicy/KL                      0.0078858\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              67.3731\n",
      "GaussianMLPPolicy/LossBefore             69.4979\n",
      "GaussianMLPPolicy/dLoss                   2.1248\n",
      "GaussianMLPValueFunction/LossAfter        6.77614\n",
      "GaussianMLPValueFunction/LossBefore       6.77997\n",
      "GaussianMLPValueFunction/dLoss            0.00382996\n",
      "TotalEnvSteps                        331200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:37 | [trpo_pendulum] epoch #276 | Saving snapshot...\n",
      "2022-08-17 18:07:37 | [trpo_pendulum] epoch #276 | Saved\n",
      "2022-08-17 18:07:37 | [trpo_pendulum] epoch #276 | Time 173.34 s\n",
      "2022-08-17 18:07:37 | [trpo_pendulum] epoch #276 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -597.81\n",
      "Evaluation/AverageReturn              -1530.54\n",
      "Evaluation/Iteration                    276\n",
      "Evaluation/MaxReturn                  -1514.6\n",
      "Evaluation/MinReturn                  -1547.95\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     12.4435\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62498\n",
      "GaussianMLPPolicy/KL                      0.00733943\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              84.6523\n",
      "GaussianMLPPolicy/LossBefore             85.5614\n",
      "GaussianMLPPolicy/dLoss                   0.909088\n",
      "GaussianMLPValueFunction/LossAfter        6.93029\n",
      "GaussianMLPValueFunction/LossBefore       6.94816\n",
      "GaussianMLPValueFunction/dLoss            0.017869\n",
      "TotalEnvSteps                        332400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:38 | [trpo_pendulum] epoch #277 | Saving snapshot...\n",
      "2022-08-17 18:07:38 | [trpo_pendulum] epoch #277 | Saved\n",
      "2022-08-17 18:07:38 | [trpo_pendulum] epoch #277 | Time 173.96 s\n",
      "2022-08-17 18:07:38 | [trpo_pendulum] epoch #277 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -681.245\n",
      "Evaluation/AverageReturn              -1638.53\n",
      "Evaluation/Iteration                    277\n",
      "Evaluation/MaxReturn                  -1631.82\n",
      "Evaluation/MinReturn                  -1645.55\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.54743\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62844\n",
      "GaussianMLPPolicy/KL                      0.00769079\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              90.7595\n",
      "GaussianMLPPolicy/LossBefore             92.1437\n",
      "GaussianMLPPolicy/dLoss                   1.38422\n",
      "GaussianMLPValueFunction/LossAfter        6.95545\n",
      "GaussianMLPValueFunction/LossBefore       6.9687\n",
      "GaussianMLPValueFunction/dLoss            0.013257\n",
      "TotalEnvSteps                        333600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:38 | [trpo_pendulum] epoch #278 | Saving snapshot...\n",
      "2022-08-17 18:07:38 | [trpo_pendulum] epoch #278 | Saved\n",
      "2022-08-17 18:07:38 | [trpo_pendulum] epoch #278 | Time 174.60 s\n",
      "2022-08-17 18:07:38 | [trpo_pendulum] epoch #278 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -660.879\n",
      "Evaluation/AverageReturn              -1506.89\n",
      "Evaluation/Iteration                    278\n",
      "Evaluation/MaxReturn                  -1505.75\n",
      "Evaluation/MinReturn                  -1507.84\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      0.699981\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62343\n",
      "GaussianMLPPolicy/KL                      0.00731491\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              64.1755\n",
      "GaussianMLPPolicy/LossBefore             65.2829\n",
      "GaussianMLPPolicy/dLoss                   1.1074\n",
      "GaussianMLPValueFunction/LossAfter        6.76498\n",
      "GaussianMLPValueFunction/LossBefore       6.77449\n",
      "GaussianMLPValueFunction/dLoss            0.00950909\n",
      "TotalEnvSteps                        334800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:39 | [trpo_pendulum] epoch #279 | Saving snapshot...\n",
      "2022-08-17 18:07:39 | [trpo_pendulum] epoch #279 | Saved\n",
      "2022-08-17 18:07:39 | [trpo_pendulum] epoch #279 | Time 175.24 s\n",
      "2022-08-17 18:07:39 | [trpo_pendulum] epoch #279 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -535.504\n",
      "Evaluation/AverageReturn              -1298.57\n",
      "Evaluation/Iteration                    279\n",
      "Evaluation/MaxReturn                   -778.5\n",
      "Evaluation/MinReturn                  -1545.3\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    280.805\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.63014\n",
      "GaussianMLPPolicy/KL                      0.00863427\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              37.2613\n",
      "GaussianMLPPolicy/LossBefore             38.6441\n",
      "GaussianMLPPolicy/dLoss                   1.38283\n",
      "GaussianMLPValueFunction/LossAfter        6.6619\n",
      "GaussianMLPValueFunction/LossBefore       6.68026\n",
      "GaussianMLPValueFunction/dLoss            0.0183568\n",
      "TotalEnvSteps                        336000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:40 | [trpo_pendulum] epoch #280 | Saving snapshot...\n",
      "2022-08-17 18:07:40 | [trpo_pendulum] epoch #280 | Saved\n",
      "2022-08-17 18:07:40 | [trpo_pendulum] epoch #280 | Time 175.88 s\n",
      "2022-08-17 18:07:40 | [trpo_pendulum] epoch #280 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -691.337\n",
      "Evaluation/AverageReturn              -1646.88\n",
      "Evaluation/Iteration                    280\n",
      "Evaluation/MaxReturn                  -1640.99\n",
      "Evaluation/MinReturn                  -1651.38\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      3.47809\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.6168\n",
      "GaussianMLPPolicy/KL                      0.00884585\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              90.0598\n",
      "GaussianMLPPolicy/LossBefore             90.3362\n",
      "GaussianMLPPolicy/dLoss                   0.276436\n",
      "GaussianMLPValueFunction/LossAfter        6.95422\n",
      "GaussianMLPValueFunction/LossBefore       6.97668\n",
      "GaussianMLPValueFunction/dLoss            0.02246\n",
      "TotalEnvSteps                        337200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:40 | [trpo_pendulum] epoch #281 | Saving snapshot...\n",
      "2022-08-17 18:07:40 | [trpo_pendulum] epoch #281 | Saved\n",
      "2022-08-17 18:07:40 | [trpo_pendulum] epoch #281 | Time 176.54 s\n",
      "2022-08-17 18:07:40 | [trpo_pendulum] epoch #281 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -591.32\n",
      "Evaluation/AverageReturn              -1455.82\n",
      "Evaluation/Iteration                    281\n",
      "Evaluation/MaxReturn                  -1324.37\n",
      "Evaluation/MinReturn                  -1508.45\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     64.7342\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62089\n",
      "GaussianMLPPolicy/KL                      0.00886214\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              60.9468\n",
      "GaussianMLPPolicy/LossBefore             62.6228\n",
      "GaussianMLPPolicy/dLoss                   1.67598\n",
      "GaussianMLPValueFunction/LossAfter        6.73083\n",
      "GaussianMLPValueFunction/LossBefore       6.73928\n",
      "GaussianMLPValueFunction/dLoss            0.00844908\n",
      "TotalEnvSteps                        338400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:41 | [trpo_pendulum] epoch #282 | Saving snapshot...\n",
      "2022-08-17 18:07:41 | [trpo_pendulum] epoch #282 | Saved\n",
      "2022-08-17 18:07:41 | [trpo_pendulum] epoch #282 | Time 177.18 s\n",
      "2022-08-17 18:07:41 | [trpo_pendulum] epoch #282 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -646.577\n",
      "Evaluation/AverageReturn              -1492.7\n",
      "Evaluation/Iteration                    282\n",
      "Evaluation/MaxReturn                  -1491.67\n",
      "Evaluation/MinReturn                  -1494.14\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      0.87334\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62922\n",
      "GaussianMLPPolicy/KL                      0.00852226\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              61.9475\n",
      "GaussianMLPPolicy/LossBefore             62.5974\n",
      "GaussianMLPPolicy/dLoss                   0.649879\n",
      "GaussianMLPValueFunction/LossAfter        6.74025\n",
      "GaussianMLPValueFunction/LossBefore       6.74538\n",
      "GaussianMLPValueFunction/dLoss            0.00513506\n",
      "TotalEnvSteps                        339600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:42 | [trpo_pendulum] epoch #283 | Saving snapshot...\n",
      "2022-08-17 18:07:42 | [trpo_pendulum] epoch #283 | Saved\n",
      "2022-08-17 18:07:42 | [trpo_pendulum] epoch #283 | Time 177.83 s\n",
      "2022-08-17 18:07:42 | [trpo_pendulum] epoch #283 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -674.897\n",
      "Evaluation/AverageReturn              -1632.33\n",
      "Evaluation/Iteration                    283\n",
      "Evaluation/MaxReturn                  -1628.35\n",
      "Evaluation/MinReturn                  -1636.99\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      2.85674\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.64099\n",
      "GaussianMLPPolicy/KL                      0.00550773\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              87.9299\n",
      "GaussianMLPPolicy/LossBefore             88.3532\n",
      "GaussianMLPPolicy/dLoss                   0.423271\n",
      "GaussianMLPValueFunction/LossAfter        6.93847\n",
      "GaussianMLPValueFunction/LossBefore       6.95825\n",
      "GaussianMLPValueFunction/dLoss            0.0197878\n",
      "TotalEnvSteps                        340800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:42 | [trpo_pendulum] epoch #284 | Saving snapshot...\n",
      "2022-08-17 18:07:42 | [trpo_pendulum] epoch #284 | Saved\n",
      "2022-08-17 18:07:42 | [trpo_pendulum] epoch #284 | Time 178.48 s\n",
      "2022-08-17 18:07:42 | [trpo_pendulum] epoch #284 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -601.249\n",
      "Evaluation/AverageReturn              -1448.37\n",
      "Evaluation/Iteration                    284\n",
      "Evaluation/MaxReturn                  -1380.27\n",
      "Evaluation/MinReturn                  -1510.32\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     45.3449\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.6295\n",
      "GaussianMLPPolicy/KL                      0.00913113\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              58.7229\n",
      "GaussianMLPPolicy/LossBefore             59.8541\n",
      "GaussianMLPPolicy/dLoss                   1.13118\n",
      "GaussianMLPValueFunction/LossAfter        6.725\n",
      "GaussianMLPValueFunction/LossBefore       6.73338\n",
      "GaussianMLPValueFunction/dLoss            0.00837612\n",
      "TotalEnvSteps                        342000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:43 | [trpo_pendulum] epoch #285 | Saving snapshot...\n",
      "2022-08-17 18:07:43 | [trpo_pendulum] epoch #285 | Saved\n",
      "2022-08-17 18:07:43 | [trpo_pendulum] epoch #285 | Time 179.09 s\n",
      "2022-08-17 18:07:43 | [trpo_pendulum] epoch #285 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -546.845\n",
      "Evaluation/AverageReturn              -1366.15\n",
      "Evaluation/Iteration                    285\n",
      "Evaluation/MaxReturn                  -1320.08\n",
      "Evaluation/MinReturn                  -1399.84\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     27.7867\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62431\n",
      "GaussianMLPPolicy/KL                      0.0059322\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              48.3109\n",
      "GaussianMLPPolicy/LossBefore             49.8513\n",
      "GaussianMLPPolicy/dLoss                   1.54044\n",
      "GaussianMLPValueFunction/LossAfter        6.66679\n",
      "GaussianMLPValueFunction/LossBefore       6.67831\n",
      "GaussianMLPValueFunction/dLoss            0.0115223\n",
      "TotalEnvSteps                        343200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:07:43 | [trpo_pendulum] epoch #286 | Saving snapshot...\n",
      "2022-08-17 18:07:43 | [trpo_pendulum] epoch #286 | Saved\n",
      "2022-08-17 18:07:43 | [trpo_pendulum] epoch #286 | Time 179.70 s\n",
      "2022-08-17 18:07:43 | [trpo_pendulum] epoch #286 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -574.962\n",
      "Evaluation/AverageReturn              -1394.88\n",
      "Evaluation/Iteration                    286\n",
      "Evaluation/MaxReturn                  -1291.02\n",
      "Evaluation/MinReturn                  -1508.05\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     71.7793\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62192\n",
      "GaussianMLPPolicy/KL                      0.00642585\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              48.2987\n",
      "GaussianMLPPolicy/LossBefore             49.8134\n",
      "GaussianMLPPolicy/dLoss                   1.51471\n",
      "GaussianMLPValueFunction/LossAfter        6.63175\n",
      "GaussianMLPValueFunction/LossBefore       6.64257\n",
      "GaussianMLPValueFunction/dLoss            0.0108256\n",
      "TotalEnvSteps                        344400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:44 | [trpo_pendulum] epoch #287 | Saving snapshot...\n",
      "2022-08-17 18:07:44 | [trpo_pendulum] epoch #287 | Saved\n",
      "2022-08-17 18:07:44 | [trpo_pendulum] epoch #287 | Time 180.33 s\n",
      "2022-08-17 18:07:44 | [trpo_pendulum] epoch #287 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -695.285\n",
      "Evaluation/AverageReturn              -1643.41\n",
      "Evaluation/Iteration                    287\n",
      "Evaluation/MaxReturn                  -1640.51\n",
      "Evaluation/MinReturn                  -1645.59\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      1.717\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.61687\n",
      "GaussianMLPPolicy/KL                      0.00986264\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              82.9813\n",
      "GaussianMLPPolicy/LossBefore             83.8654\n",
      "GaussianMLPPolicy/dLoss                   0.884163\n",
      "GaussianMLPValueFunction/LossAfter        6.92385\n",
      "GaussianMLPValueFunction/LossBefore       6.95507\n",
      "GaussianMLPValueFunction/dLoss            0.0312223\n",
      "TotalEnvSteps                        345600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:45 | [trpo_pendulum] epoch #288 | Saving snapshot...\n",
      "2022-08-17 18:07:45 | [trpo_pendulum] epoch #288 | Saved\n",
      "2022-08-17 18:07:45 | [trpo_pendulum] epoch #288 | Time 180.96 s\n",
      "2022-08-17 18:07:45 | [trpo_pendulum] epoch #288 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -693.788\n",
      "Evaluation/AverageReturn              -1644.76\n",
      "Evaluation/Iteration                    288\n",
      "Evaluation/MaxReturn                  -1641.27\n",
      "Evaluation/MinReturn                  -1648.24\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      2.8426\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.60706\n",
      "GaussianMLPPolicy/KL                      0.00475806\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              83.2742\n",
      "GaussianMLPPolicy/LossBefore             83.5849\n",
      "GaussianMLPPolicy/dLoss                   0.310631\n",
      "GaussianMLPValueFunction/LossAfter        6.91149\n",
      "GaussianMLPValueFunction/LossBefore       6.92618\n",
      "GaussianMLPValueFunction/dLoss            0.0146837\n",
      "TotalEnvSteps                        346800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:45 | [trpo_pendulum] epoch #289 | Saving snapshot...\n",
      "2022-08-17 18:07:45 | [trpo_pendulum] epoch #289 | Saved\n",
      "2022-08-17 18:07:45 | [trpo_pendulum] epoch #289 | Time 181.57 s\n",
      "2022-08-17 18:07:45 | [trpo_pendulum] epoch #289 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -572.967\n",
      "Evaluation/AverageReturn              -1420.82\n",
      "Evaluation/Iteration                    289\n",
      "Evaluation/MaxReturn                  -1145.37\n",
      "Evaluation/MinReturn                  -1600.27\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    179.523\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.61132\n",
      "GaussianMLPPolicy/KL                      0.00751795\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              52.7701\n",
      "GaussianMLPPolicy/LossBefore             54.3828\n",
      "GaussianMLPPolicy/dLoss                   1.61269\n",
      "GaussianMLPValueFunction/LossAfter        6.72609\n",
      "GaussianMLPValueFunction/LossBefore       6.73263\n",
      "GaussianMLPValueFunction/dLoss            0.00653982\n",
      "TotalEnvSteps                        348000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:46 | [trpo_pendulum] epoch #290 | Saving snapshot...\n",
      "2022-08-17 18:07:46 | [trpo_pendulum] epoch #290 | Saved\n",
      "2022-08-17 18:07:46 | [trpo_pendulum] epoch #290 | Time 182.22 s\n",
      "2022-08-17 18:07:46 | [trpo_pendulum] epoch #290 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -453.247\n",
      "Evaluation/AverageReturn              -1277.58\n",
      "Evaluation/Iteration                    290\n",
      "Evaluation/MaxReturn                  -1152.11\n",
      "Evaluation/MinReturn                  -1409.38\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     82.7738\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.61197\n",
      "GaussianMLPPolicy/KL                      0.00729874\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              37.8432\n",
      "GaussianMLPPolicy/LossBefore             39.1672\n",
      "GaussianMLPPolicy/dLoss                   1.32399\n",
      "GaussianMLPValueFunction/LossAfter        6.60691\n",
      "GaussianMLPValueFunction/LossBefore       6.62557\n",
      "GaussianMLPValueFunction/dLoss            0.018661\n",
      "TotalEnvSteps                        349200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:47 | [trpo_pendulum] epoch #291 | Saving snapshot...\n",
      "2022-08-17 18:07:47 | [trpo_pendulum] epoch #291 | Saved\n",
      "2022-08-17 18:07:47 | [trpo_pendulum] epoch #291 | Time 182.86 s\n",
      "2022-08-17 18:07:47 | [trpo_pendulum] epoch #291 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -527.979\n",
      "Evaluation/AverageReturn              -1396.72\n",
      "Evaluation/Iteration                    291\n",
      "Evaluation/MaxReturn                  -1181.21\n",
      "Evaluation/MinReturn                  -1529.47\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    106.675\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.63528\n",
      "GaussianMLPPolicy/KL                      0.00741728\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              52.4194\n",
      "GaussianMLPPolicy/LossBefore             53.8842\n",
      "GaussianMLPPolicy/dLoss                   1.46481\n",
      "GaussianMLPValueFunction/LossAfter        6.70789\n",
      "GaussianMLPValueFunction/LossBefore       6.71188\n",
      "GaussianMLPValueFunction/dLoss            0.00399542\n",
      "TotalEnvSteps                        350400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:47 | [trpo_pendulum] epoch #292 | Saving snapshot...\n",
      "2022-08-17 18:07:47 | [trpo_pendulum] epoch #292 | Saved\n",
      "2022-08-17 18:07:47 | [trpo_pendulum] epoch #292 | Time 183.48 s\n",
      "2022-08-17 18:07:47 | [trpo_pendulum] epoch #292 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -588.677\n",
      "Evaluation/AverageReturn              -1480.55\n",
      "Evaluation/Iteration                    292\n",
      "Evaluation/MaxReturn                  -1268.63\n",
      "Evaluation/MinReturn                  -1609.25\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    124.318\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62533\n",
      "GaussianMLPPolicy/KL                      0.00613563\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              60.8963\n",
      "GaussianMLPPolicy/LossBefore             62.265\n",
      "GaussianMLPPolicy/dLoss                   1.36872\n",
      "GaussianMLPValueFunction/LossAfter        6.77524\n",
      "GaussianMLPValueFunction/LossBefore       6.78053\n",
      "GaussianMLPValueFunction/dLoss            0.00529003\n",
      "TotalEnvSteps                        351600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:48 | [trpo_pendulum] epoch #293 | Saving snapshot...\n",
      "2022-08-17 18:07:48 | [trpo_pendulum] epoch #293 | Saved\n",
      "2022-08-17 18:07:48 | [trpo_pendulum] epoch #293 | Time 184.09 s\n",
      "2022-08-17 18:07:48 | [trpo_pendulum] epoch #293 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -544.207\n",
      "Evaluation/AverageReturn              -1276.13\n",
      "Evaluation/Iteration                    293\n",
      "Evaluation/MaxReturn                  -1176.64\n",
      "Evaluation/MinReturn                  -1343.48\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     66.1224\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.63529\n",
      "GaussianMLPPolicy/KL                      0.00583808\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              26.4378\n",
      "GaussianMLPPolicy/LossBefore             27.4221\n",
      "GaussianMLPPolicy/dLoss                   0.984352\n",
      "GaussianMLPValueFunction/LossAfter        6.50329\n",
      "GaussianMLPValueFunction/LossBefore       6.53074\n",
      "GaussianMLPValueFunction/dLoss            0.0274529\n",
      "TotalEnvSteps                        352800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:48 | [trpo_pendulum] epoch #294 | Saving snapshot...\n",
      "2022-08-17 18:07:48 | [trpo_pendulum] epoch #294 | Saved\n",
      "2022-08-17 18:07:48 | [trpo_pendulum] epoch #294 | Time 184.70 s\n",
      "2022-08-17 18:07:48 | [trpo_pendulum] epoch #294 | EpochTime 0.60 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -677.403\n",
      "Evaluation/AverageReturn              -1619.13\n",
      "Evaluation/Iteration                    294\n",
      "Evaluation/MaxReturn                  -1610.88\n",
      "Evaluation/MinReturn                  -1628.79\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      6.20502\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.67349\n",
      "GaussianMLPPolicy/KL                      0.0074126\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              76.5982\n",
      "GaussianMLPPolicy/LossBefore             78.0541\n",
      "GaussianMLPPolicy/dLoss                   1.45591\n",
      "GaussianMLPValueFunction/LossAfter        6.88516\n",
      "GaussianMLPValueFunction/LossBefore       6.91489\n",
      "GaussianMLPValueFunction/dLoss            0.0297284\n",
      "TotalEnvSteps                        354000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:07:49 | [trpo_pendulum] epoch #295 | Saving snapshot...\n",
      "2022-08-17 18:07:49 | [trpo_pendulum] epoch #295 | Saved\n",
      "2022-08-17 18:07:49 | [trpo_pendulum] epoch #295 | Time 185.32 s\n",
      "2022-08-17 18:07:49 | [trpo_pendulum] epoch #295 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -647.281\n",
      "Evaluation/AverageReturn              -1504.73\n",
      "Evaluation/Iteration                    295\n",
      "Evaluation/MaxReturn                  -1455.91\n",
      "Evaluation/MinReturn                  -1517.56\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     22.1081\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.66256\n",
      "GaussianMLPPolicy/KL                      0.00648832\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              55.5017\n",
      "GaussianMLPPolicy/LossBefore             57.0393\n",
      "GaussianMLPPolicy/dLoss                   1.53757\n",
      "GaussianMLPValueFunction/LossAfter        6.71338\n",
      "GaussianMLPValueFunction/LossBefore       6.71625\n",
      "GaussianMLPValueFunction/dLoss            0.00286579\n",
      "TotalEnvSteps                        355200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:50 | [trpo_pendulum] epoch #296 | Saving snapshot...\n",
      "2022-08-17 18:07:50 | [trpo_pendulum] epoch #296 | Saved\n",
      "2022-08-17 18:07:50 | [trpo_pendulum] epoch #296 | Time 185.94 s\n",
      "2022-08-17 18:07:50 | [trpo_pendulum] epoch #296 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -657.509\n",
      "Evaluation/AverageReturn              -1509.33\n",
      "Evaluation/Iteration                    296\n",
      "Evaluation/MaxReturn                  -1505.19\n",
      "Evaluation/MinReturn                  -1511.09\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      2.10536\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.66044\n",
      "GaussianMLPPolicy/KL                      0.00804067\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              53.789\n",
      "GaussianMLPPolicy/LossBefore             55.483\n",
      "GaussianMLPPolicy/dLoss                   1.69405\n",
      "GaussianMLPValueFunction/LossAfter        6.71786\n",
      "GaussianMLPValueFunction/LossBefore       6.72044\n",
      "GaussianMLPValueFunction/dLoss            0.0025816\n",
      "TotalEnvSteps                        356400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:50 | [trpo_pendulum] epoch #297 | Saving snapshot...\n",
      "2022-08-17 18:07:50 | [trpo_pendulum] epoch #297 | Saved\n",
      "2022-08-17 18:07:50 | [trpo_pendulum] epoch #297 | Time 186.54 s\n",
      "2022-08-17 18:07:50 | [trpo_pendulum] epoch #297 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -547.705\n",
      "Evaluation/AverageReturn              -1384.46\n",
      "Evaluation/Iteration                    297\n",
      "Evaluation/MaxReturn                  -1201.71\n",
      "Evaluation/MinReturn                  -1459.22\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     97.538\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.6379\n",
      "GaussianMLPPolicy/KL                      0.0072114\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              42.9241\n",
      "GaussianMLPPolicy/LossBefore             44.3628\n",
      "GaussianMLPPolicy/dLoss                   1.43868\n",
      "GaussianMLPValueFunction/LossAfter        6.60581\n",
      "GaussianMLPValueFunction/LossBefore       6.61518\n",
      "GaussianMLPValueFunction/dLoss            0.00936508\n",
      "TotalEnvSteps                        357600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:51 | [trpo_pendulum] epoch #298 | Saving snapshot...\n",
      "2022-08-17 18:07:51 | [trpo_pendulum] epoch #298 | Saved\n",
      "2022-08-17 18:07:51 | [trpo_pendulum] epoch #298 | Time 187.16 s\n",
      "2022-08-17 18:07:51 | [trpo_pendulum] epoch #298 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -538.577\n",
      "Evaluation/AverageReturn              -1436.47\n",
      "Evaluation/Iteration                    298\n",
      "Evaluation/MaxReturn                  -1356.12\n",
      "Evaluation/MinReturn                  -1496.08\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     55.523\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.6708\n",
      "GaussianMLPPolicy/KL                      0.00808504\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              59.0615\n",
      "GaussianMLPPolicy/LossBefore             60.9933\n",
      "GaussianMLPPolicy/dLoss                   1.9318\n",
      "GaussianMLPValueFunction/LossAfter        6.75634\n",
      "GaussianMLPValueFunction/LossBefore       6.76322\n",
      "GaussianMLPValueFunction/dLoss            0.00688314\n",
      "TotalEnvSteps                        358800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:51 | [trpo_pendulum] epoch #299 | Saving snapshot...\n",
      "2022-08-17 18:07:52 | [trpo_pendulum] epoch #299 | Saved\n",
      "2022-08-17 18:07:52 | [trpo_pendulum] epoch #299 | Time 187.79 s\n",
      "2022-08-17 18:07:52 | [trpo_pendulum] epoch #299 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -665.656\n",
      "Evaluation/AverageReturn              -1519.17\n",
      "Evaluation/Iteration                    299\n",
      "Evaluation/MaxReturn                  -1513.9\n",
      "Evaluation/MinReturn                  -1526.01\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      4.72708\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.71461\n",
      "GaussianMLPPolicy/KL                      0.00645711\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              52.645\n",
      "GaussianMLPPolicy/LossBefore             53.9506\n",
      "GaussianMLPPolicy/dLoss                   1.30564\n",
      "GaussianMLPValueFunction/LossAfter        6.70939\n",
      "GaussianMLPValueFunction/LossBefore       6.71194\n",
      "GaussianMLPValueFunction/dLoss            0.00255156\n",
      "TotalEnvSteps                        360000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:52 | [trpo_pendulum] epoch #300 | Saving snapshot...\n",
      "2022-08-17 18:07:52 | [trpo_pendulum] epoch #300 | Saved\n",
      "2022-08-17 18:07:52 | [trpo_pendulum] epoch #300 | Time 188.41 s\n",
      "2022-08-17 18:07:52 | [trpo_pendulum] epoch #300 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -607.211\n",
      "Evaluation/AverageReturn              -1435.5\n",
      "Evaluation/Iteration                    300\n",
      "Evaluation/MaxReturn                  -1385.33\n",
      "Evaluation/MinReturn                  -1465.46\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     30.5031\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.74288\n",
      "GaussianMLPPolicy/KL                      0.008145\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              44.9397\n",
      "GaussianMLPPolicy/LossBefore             46.122\n",
      "GaussianMLPPolicy/dLoss                   1.18231\n",
      "GaussianMLPValueFunction/LossAfter        6.63763\n",
      "GaussianMLPValueFunction/LossBefore       6.64253\n",
      "GaussianMLPValueFunction/dLoss            0.00490618\n",
      "TotalEnvSteps                        361200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:53 | [trpo_pendulum] epoch #301 | Saving snapshot...\n",
      "2022-08-17 18:07:53 | [trpo_pendulum] epoch #301 | Saved\n",
      "2022-08-17 18:07:53 | [trpo_pendulum] epoch #301 | Time 189.02 s\n",
      "2022-08-17 18:07:53 | [trpo_pendulum] epoch #301 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -609.257\n",
      "Evaluation/AverageReturn              -1421.13\n",
      "Evaluation/Iteration                    301\n",
      "Evaluation/MaxReturn                  -1333.87\n",
      "Evaluation/MinReturn                  -1470.25\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     49.6115\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.75344\n",
      "GaussianMLPPolicy/KL                      0.00609408\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              41.5898\n",
      "GaussianMLPPolicy/LossBefore             42.6638\n",
      "GaussianMLPPolicy/dLoss                   1.07399\n",
      "GaussianMLPValueFunction/LossAfter        6.63713\n",
      "GaussianMLPValueFunction/LossBefore       6.64005\n",
      "GaussianMLPValueFunction/dLoss            0.0029254\n",
      "TotalEnvSteps                        362400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:53 | [trpo_pendulum] epoch #302 | Saving snapshot...\n",
      "2022-08-17 18:07:53 | [trpo_pendulum] epoch #302 | Saved\n",
      "2022-08-17 18:07:53 | [trpo_pendulum] epoch #302 | Time 189.64 s\n",
      "2022-08-17 18:07:53 | [trpo_pendulum] epoch #302 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -506.797\n",
      "Evaluation/AverageReturn              -1266.55\n",
      "Evaluation/Iteration                    302\n",
      "Evaluation/MaxReturn                  -1157.42\n",
      "Evaluation/MinReturn                  -1330.83\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     74.1688\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.76705\n",
      "GaussianMLPPolicy/KL                      0.0064451\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              24.1898\n",
      "GaussianMLPPolicy/LossBefore             25.2208\n",
      "GaussianMLPPolicy/dLoss                   1.03095\n",
      "GaussianMLPValueFunction/LossAfter        6.47423\n",
      "GaussianMLPValueFunction/LossBefore       6.49463\n",
      "GaussianMLPValueFunction/dLoss            0.0204043\n",
      "TotalEnvSteps                        363600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:07:54 | [trpo_pendulum] epoch #303 | Saving snapshot...\n",
      "2022-08-17 18:07:54 | [trpo_pendulum] epoch #303 | Saved\n",
      "2022-08-17 18:07:54 | [trpo_pendulum] epoch #303 | Time 190.26 s\n",
      "2022-08-17 18:07:54 | [trpo_pendulum] epoch #303 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -657.697\n",
      "Evaluation/AverageReturn              -1522.14\n",
      "Evaluation/Iteration                    303\n",
      "Evaluation/MaxReturn                  -1507.73\n",
      "Evaluation/MinReturn                  -1538.13\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      9.40712\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.7748\n",
      "GaussianMLPPolicy/KL                      0.0073064\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              52.3194\n",
      "GaussianMLPPolicy/LossBefore             54.5729\n",
      "GaussianMLPPolicy/dLoss                   2.25358\n",
      "GaussianMLPValueFunction/LossAfter        6.73145\n",
      "GaussianMLPValueFunction/LossBefore       6.74581\n",
      "GaussianMLPValueFunction/dLoss            0.0143538\n",
      "TotalEnvSteps                        364800\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:07:55 | [trpo_pendulum] epoch #304 | Saving snapshot...\n",
      "2022-08-17 18:07:55 | [trpo_pendulum] epoch #304 | Saved\n",
      "2022-08-17 18:07:55 | [trpo_pendulum] epoch #304 | Time 190.87 s\n",
      "2022-08-17 18:07:55 | [trpo_pendulum] epoch #304 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -439.183\n",
      "Evaluation/AverageReturn              -1106.06\n",
      "Evaluation/Iteration                    304\n",
      "Evaluation/MaxReturn                   -641.128\n",
      "Evaluation/MinReturn                  -1291.24\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    212.484\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.77783\n",
      "GaussianMLPPolicy/KL                      0.00771194\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               1.55698\n",
      "GaussianMLPPolicy/LossBefore              3.44286\n",
      "GaussianMLPPolicy/dLoss                   1.88588\n",
      "GaussianMLPValueFunction/LossAfter        6.55416\n",
      "GaussianMLPValueFunction/LossBefore       6.55878\n",
      "GaussianMLPValueFunction/dLoss            0.00461626\n",
      "TotalEnvSteps                        366000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:55 | [trpo_pendulum] epoch #305 | Saving snapshot...\n",
      "2022-08-17 18:07:55 | [trpo_pendulum] epoch #305 | Saved\n",
      "2022-08-17 18:07:55 | [trpo_pendulum] epoch #305 | Time 191.49 s\n",
      "2022-08-17 18:07:55 | [trpo_pendulum] epoch #305 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -387.48\n",
      "Evaluation/AverageReturn               -996.078\n",
      "Evaluation/Iteration                    305\n",
      "Evaluation/MaxReturn                   -768.332\n",
      "Evaluation/MinReturn                  -1232.55\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    163.594\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.78079\n",
      "GaussianMLPPolicy/KL                      0.00611513\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -14.6382\n",
      "GaussianMLPPolicy/LossBefore            -13.8413\n",
      "GaussianMLPPolicy/dLoss                   0.796866\n",
      "GaussianMLPValueFunction/LossAfter        6.39929\n",
      "GaussianMLPValueFunction/LossBefore       6.42461\n",
      "GaussianMLPValueFunction/dLoss            0.0253263\n",
      "TotalEnvSteps                        367200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:56 | [trpo_pendulum] epoch #306 | Saving snapshot...\n",
      "2022-08-17 18:07:56 | [trpo_pendulum] epoch #306 | Saved\n",
      "2022-08-17 18:07:56 | [trpo_pendulum] epoch #306 | Time 192.11 s\n",
      "2022-08-17 18:07:56 | [trpo_pendulum] epoch #306 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -669.31\n",
      "Evaluation/AverageReturn              -1530.96\n",
      "Evaluation/Iteration                    306\n",
      "Evaluation/MaxReturn                  -1523.24\n",
      "Evaluation/MinReturn                  -1537.41\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.04616\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.76593\n",
      "GaussianMLPPolicy/KL                      0.0078293\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              52.0818\n",
      "GaussianMLPPolicy/LossBefore             54.1797\n",
      "GaussianMLPPolicy/dLoss                   2.09797\n",
      "GaussianMLPValueFunction/LossAfter        6.73415\n",
      "GaussianMLPValueFunction/LossBefore       6.75724\n",
      "GaussianMLPValueFunction/dLoss            0.0230885\n",
      "TotalEnvSteps                        368400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:07:56 | [trpo_pendulum] epoch #307 | Saving snapshot...\n",
      "2022-08-17 18:07:56 | [trpo_pendulum] epoch #307 | Saved\n",
      "2022-08-17 18:07:56 | [trpo_pendulum] epoch #307 | Time 192.73 s\n",
      "2022-08-17 18:07:56 | [trpo_pendulum] epoch #307 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -490.56\n",
      "Evaluation/AverageReturn              -1058.07\n",
      "Evaluation/Iteration                    307\n",
      "Evaluation/MaxReturn                   -624.297\n",
      "Evaluation/MinReturn                  -1195.17\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    200.318\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.77305\n",
      "GaussianMLPPolicy/KL                      0.00867417\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -17.3921\n",
      "GaussianMLPPolicy/LossBefore            -15.3627\n",
      "GaussianMLPPolicy/dLoss                   2.02946\n",
      "GaussianMLPValueFunction/LossAfter        6.64063\n",
      "GaussianMLPValueFunction/LossBefore       6.6449\n",
      "GaussianMLPValueFunction/dLoss            0.00426912\n",
      "TotalEnvSteps                        369600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:57 | [trpo_pendulum] epoch #308 | Saving snapshot...\n",
      "2022-08-17 18:07:57 | [trpo_pendulum] epoch #308 | Saved\n",
      "2022-08-17 18:07:57 | [trpo_pendulum] epoch #308 | Time 193.34 s\n",
      "2022-08-17 18:07:57 | [trpo_pendulum] epoch #308 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -656.758\n",
      "Evaluation/AverageReturn              -1522.69\n",
      "Evaluation/Iteration                    308\n",
      "Evaluation/MaxReturn                  -1425.28\n",
      "Evaluation/MinReturn                  -1554.81\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     44.1941\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.79718\n",
      "GaussianMLPPolicy/KL                      0.00958171\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              52.202\n",
      "GaussianMLPPolicy/LossBefore             54.3869\n",
      "GaussianMLPPolicy/dLoss                   2.18491\n",
      "GaussianMLPValueFunction/LossAfter        6.72795\n",
      "GaussianMLPValueFunction/LossBefore       6.73834\n",
      "GaussianMLPValueFunction/dLoss            0.0103869\n",
      "TotalEnvSteps                        370800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:58 | [trpo_pendulum] epoch #309 | Saving snapshot...\n",
      "2022-08-17 18:07:58 | [trpo_pendulum] epoch #309 | Saved\n",
      "2022-08-17 18:07:58 | [trpo_pendulum] epoch #309 | Time 193.96 s\n",
      "2022-08-17 18:07:58 | [trpo_pendulum] epoch #309 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -328.512\n",
      "Evaluation/AverageReturn               -777.8\n",
      "Evaluation/Iteration                    309\n",
      "Evaluation/MaxReturn                   -617.6\n",
      "Evaluation/MinReturn                   -900.756\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    121.368\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.7826\n",
      "GaussianMLPPolicy/KL                      0.00988823\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -55.2505\n",
      "GaussianMLPPolicy/LossBefore            -51.2557\n",
      "GaussianMLPPolicy/dLoss                   3.99476\n",
      "GaussianMLPValueFunction/LossAfter        6.56383\n",
      "GaussianMLPValueFunction/LossBefore       6.57649\n",
      "GaussianMLPValueFunction/dLoss            0.0126591\n",
      "TotalEnvSteps                        372000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:58 | [trpo_pendulum] epoch #310 | Saving snapshot...\n",
      "2022-08-17 18:07:58 | [trpo_pendulum] epoch #310 | Saved\n",
      "2022-08-17 18:07:58 | [trpo_pendulum] epoch #310 | Time 194.59 s\n",
      "2022-08-17 18:07:58 | [trpo_pendulum] epoch #310 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -684.868\n",
      "Evaluation/AverageReturn              -1573.03\n",
      "Evaluation/Iteration                    310\n",
      "Evaluation/MaxReturn                  -1543.15\n",
      "Evaluation/MinReturn                  -1589.27\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     15.1745\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.7768\n",
      "GaussianMLPPolicy/KL                      0.00609124\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              58.8149\n",
      "GaussianMLPPolicy/LossBefore             60.5115\n",
      "GaussianMLPPolicy/dLoss                   1.69656\n",
      "GaussianMLPValueFunction/LossAfter        6.76141\n",
      "GaussianMLPValueFunction/LossBefore       6.77515\n",
      "GaussianMLPValueFunction/dLoss            0.013742\n",
      "TotalEnvSteps                        373200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:07:59 | [trpo_pendulum] epoch #311 | Saving snapshot...\n",
      "2022-08-17 18:07:59 | [trpo_pendulum] epoch #311 | Saved\n",
      "2022-08-17 18:07:59 | [trpo_pendulum] epoch #311 | Time 195.22 s\n",
      "2022-08-17 18:07:59 | [trpo_pendulum] epoch #311 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -371.053\n",
      "Evaluation/AverageReturn               -705.668\n",
      "Evaluation/Iteration                    311\n",
      "Evaluation/MaxReturn                   -478.575\n",
      "Evaluation/MinReturn                  -1121.59\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    205.554\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.72422\n",
      "GaussianMLPPolicy/KL                      0.00942134\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -74.1709\n",
      "GaussianMLPPolicy/LossBefore            -72.0702\n",
      "GaussianMLPPolicy/dLoss                   2.10072\n",
      "GaussianMLPValueFunction/LossAfter        6.84852\n",
      "GaussianMLPValueFunction/LossBefore       6.87972\n",
      "GaussianMLPValueFunction/dLoss            0.0311995\n",
      "TotalEnvSteps                        374400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:00 | [trpo_pendulum] epoch #312 | Saving snapshot...\n",
      "2022-08-17 18:08:00 | [trpo_pendulum] epoch #312 | Saved\n",
      "2022-08-17 18:08:00 | [trpo_pendulum] epoch #312 | Time 195.85 s\n",
      "2022-08-17 18:08:00 | [trpo_pendulum] epoch #312 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -657.09\n",
      "Evaluation/AverageReturn              -1498.76\n",
      "Evaluation/Iteration                    312\n",
      "Evaluation/MaxReturn                  -1350.13\n",
      "Evaluation/MinReturn                  -1569.25\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     74.6174\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.72964\n",
      "GaussianMLPPolicy/KL                      0.00671618\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              48.5075\n",
      "GaussianMLPPolicy/LossBefore             50.9503\n",
      "GaussianMLPPolicy/dLoss                   2.44279\n",
      "GaussianMLPValueFunction/LossAfter        6.73426\n",
      "GaussianMLPValueFunction/LossBefore       6.73547\n",
      "GaussianMLPValueFunction/dLoss            0.00120878\n",
      "TotalEnvSteps                        375600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:00 | [trpo_pendulum] epoch #313 | Saving snapshot...\n",
      "2022-08-17 18:08:00 | [trpo_pendulum] epoch #313 | Saved\n",
      "2022-08-17 18:08:00 | [trpo_pendulum] epoch #313 | Time 196.48 s\n",
      "2022-08-17 18:08:00 | [trpo_pendulum] epoch #313 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -444.711\n",
      "Evaluation/AverageReturn              -1019.4\n",
      "Evaluation/Iteration                    313\n",
      "Evaluation/MaxReturn                   -745.79\n",
      "Evaluation/MinReturn                  -1147.63\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    155.542\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.74627\n",
      "GaussianMLPPolicy/KL                      0.00771846\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -19.0882\n",
      "GaussianMLPPolicy/LossBefore            -17.6243\n",
      "GaussianMLPPolicy/dLoss                   1.46393\n",
      "GaussianMLPValueFunction/LossAfter        6.48896\n",
      "GaussianMLPValueFunction/LossBefore       6.51678\n",
      "GaussianMLPValueFunction/dLoss            0.0278139\n",
      "TotalEnvSteps                        376800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:01 | [trpo_pendulum] epoch #314 | Saving snapshot...\n",
      "2022-08-17 18:08:01 | [trpo_pendulum] epoch #314 | Saved\n",
      "2022-08-17 18:08:01 | [trpo_pendulum] epoch #314 | Time 197.10 s\n",
      "2022-08-17 18:08:01 | [trpo_pendulum] epoch #314 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -522.675\n",
      "Evaluation/AverageReturn              -1198.68\n",
      "Evaluation/Iteration                    314\n",
      "Evaluation/MaxReturn                  -1090.29\n",
      "Evaluation/MinReturn                  -1254.4\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     60.7035\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.77909\n",
      "GaussianMLPPolicy/KL                      0.00717956\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               6.31381\n",
      "GaussianMLPPolicy/LossBefore              8.61893\n",
      "GaussianMLPPolicy/dLoss                   2.30512\n",
      "GaussianMLPValueFunction/LossAfter        6.44147\n",
      "GaussianMLPValueFunction/LossBefore       6.46341\n",
      "GaussianMLPValueFunction/dLoss            0.0219364\n",
      "TotalEnvSteps                        378000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:01 | [trpo_pendulum] epoch #315 | Saving snapshot...\n",
      "2022-08-17 18:08:01 | [trpo_pendulum] epoch #315 | Saved\n",
      "2022-08-17 18:08:01 | [trpo_pendulum] epoch #315 | Time 197.70 s\n",
      "2022-08-17 18:08:01 | [trpo_pendulum] epoch #315 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -457.529\n",
      "Evaluation/AverageReturn              -1055.33\n",
      "Evaluation/Iteration                    315\n",
      "Evaluation/MaxReturn                   -892.803\n",
      "Evaluation/MinReturn                  -1156.35\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     82.5908\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.78766\n",
      "GaussianMLPPolicy/KL                      0.00643884\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -10.8693\n",
      "GaussianMLPPolicy/LossBefore             -9.08231\n",
      "GaussianMLPPolicy/dLoss                   1.78695\n",
      "GaussianMLPValueFunction/LossAfter        6.48356\n",
      "GaussianMLPValueFunction/LossBefore       6.49222\n",
      "GaussianMLPValueFunction/dLoss            0.00866175\n",
      "TotalEnvSteps                        379200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:02 | [trpo_pendulum] epoch #316 | Saving snapshot...\n",
      "2022-08-17 18:08:02 | [trpo_pendulum] epoch #316 | Saved\n",
      "2022-08-17 18:08:02 | [trpo_pendulum] epoch #316 | Time 198.30 s\n",
      "2022-08-17 18:08:02 | [trpo_pendulum] epoch #316 | EpochTime 0.59 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -455.727\n",
      "Evaluation/AverageReturn              -1014.55\n",
      "Evaluation/Iteration                    316\n",
      "Evaluation/MaxReturn                   -477.73\n",
      "Evaluation/MinReturn                  -1140.51\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    241.012\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.75012\n",
      "GaussianMLPPolicy/KL                      0.0065464\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -20.2577\n",
      "GaussianMLPPolicy/LossBefore            -18.3467\n",
      "GaussianMLPPolicy/dLoss                   1.91099\n",
      "GaussianMLPValueFunction/LossAfter        6.5942\n",
      "GaussianMLPValueFunction/LossBefore       6.59813\n",
      "GaussianMLPValueFunction/dLoss            0.0039258\n",
      "TotalEnvSteps                        380400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:08:03 | [trpo_pendulum] epoch #317 | Saving snapshot...\n",
      "2022-08-17 18:08:03 | [trpo_pendulum] epoch #317 | Saved\n",
      "2022-08-17 18:08:03 | [trpo_pendulum] epoch #317 | Time 198.91 s\n",
      "2022-08-17 18:08:03 | [trpo_pendulum] epoch #317 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -660.569\n",
      "Evaluation/AverageReturn              -1488.11\n",
      "Evaluation/Iteration                    317\n",
      "Evaluation/MaxReturn                  -1438.35\n",
      "Evaluation/MinReturn                  -1536.25\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     39.7437\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.73698\n",
      "GaussianMLPPolicy/KL                      0.0093326\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              46.039\n",
      "GaussianMLPPolicy/LossBefore             49.563\n",
      "GaussianMLPPolicy/dLoss                   3.52407\n",
      "GaussianMLPValueFunction/LossAfter        6.74184\n",
      "GaussianMLPValueFunction/LossBefore       6.75857\n",
      "GaussianMLPValueFunction/dLoss            0.0167327\n",
      "TotalEnvSteps                        381600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:08:03 | [trpo_pendulum] epoch #318 | Saving snapshot...\n",
      "2022-08-17 18:08:03 | [trpo_pendulum] epoch #318 | Saved\n",
      "2022-08-17 18:08:03 | [trpo_pendulum] epoch #318 | Time 199.53 s\n",
      "2022-08-17 18:08:03 | [trpo_pendulum] epoch #318 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -298.218\n",
      "Evaluation/AverageReturn               -609.152\n",
      "Evaluation/Iteration                    318\n",
      "Evaluation/MaxReturn                   -375.384\n",
      "Evaluation/MinReturn                   -893.669\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    172.387\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.72944\n",
      "GaussianMLPPolicy/KL                      0.00641086\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -78.3813\n",
      "GaussianMLPPolicy/LossBefore            -76.1785\n",
      "GaussianMLPPolicy/dLoss                   2.20277\n",
      "GaussianMLPValueFunction/LossAfter        6.85407\n",
      "GaussianMLPValueFunction/LossBefore       6.89815\n",
      "GaussianMLPValueFunction/dLoss            0.0440798\n",
      "TotalEnvSteps                        382800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:04 | [trpo_pendulum] epoch #319 | Saving snapshot...\n",
      "2022-08-17 18:08:04 | [trpo_pendulum] epoch #319 | Saved\n",
      "2022-08-17 18:08:04 | [trpo_pendulum] epoch #319 | Time 200.14 s\n",
      "2022-08-17 18:08:04 | [trpo_pendulum] epoch #319 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -271.424\n",
      "Evaluation/AverageReturn               -694.469\n",
      "Evaluation/Iteration                    319\n",
      "Evaluation/MaxReturn                   -522.072\n",
      "Evaluation/MinReturn                   -873.086\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    139.836\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.68396\n",
      "GaussianMLPPolicy/KL                      0.00948571\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -54.8448\n",
      "GaussianMLPPolicy/LossBefore            -53.0265\n",
      "GaussianMLPPolicy/dLoss                   1.81832\n",
      "GaussianMLPValueFunction/LossAfter        6.6029\n",
      "GaussianMLPValueFunction/LossBefore       6.61263\n",
      "GaussianMLPValueFunction/dLoss            0.00972891\n",
      "TotalEnvSteps                        384000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:04 | [trpo_pendulum] epoch #320 | Saving snapshot...\n",
      "2022-08-17 18:08:04 | [trpo_pendulum] epoch #320 | Saved\n",
      "2022-08-17 18:08:04 | [trpo_pendulum] epoch #320 | Time 200.75 s\n",
      "2022-08-17 18:08:04 | [trpo_pendulum] epoch #320 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -312.356\n",
      "Evaluation/AverageReturn               -644.101\n",
      "Evaluation/Iteration                    320\n",
      "Evaluation/MaxReturn                   -379.843\n",
      "Evaluation/MinReturn                   -906.391\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    170.353\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.70811\n",
      "GaussianMLPPolicy/KL                      0.00675838\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -73.2972\n",
      "GaussianMLPPolicy/LossBefore            -71.6166\n",
      "GaussianMLPPolicy/dLoss                   1.6806\n",
      "GaussianMLPValueFunction/LossAfter        6.76554\n",
      "GaussianMLPValueFunction/LossBefore       6.78075\n",
      "GaussianMLPValueFunction/dLoss            0.0152068\n",
      "TotalEnvSteps                        385200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:05 | [trpo_pendulum] epoch #321 | Saving snapshot...\n",
      "2022-08-17 18:08:05 | [trpo_pendulum] epoch #321 | Saved\n",
      "2022-08-17 18:08:05 | [trpo_pendulum] epoch #321 | Time 201.37 s\n",
      "2022-08-17 18:08:05 | [trpo_pendulum] epoch #321 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -285.083\n",
      "Evaluation/AverageReturn               -682.339\n",
      "Evaluation/Iteration                    321\n",
      "Evaluation/MaxReturn                   -505.012\n",
      "Evaluation/MinReturn                   -878.419\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    157.729\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.70712\n",
      "GaussianMLPPolicy/KL                      0.00717175\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -58.1231\n",
      "GaussianMLPPolicy/LossBefore            -55.9703\n",
      "GaussianMLPPolicy/dLoss                   2.15283\n",
      "GaussianMLPValueFunction/LossAfter        6.61926\n",
      "GaussianMLPValueFunction/LossBefore       6.62846\n",
      "GaussianMLPValueFunction/dLoss            0.00919914\n",
      "TotalEnvSteps                        386400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:06 | [trpo_pendulum] epoch #322 | Saving snapshot...\n",
      "2022-08-17 18:08:06 | [trpo_pendulum] epoch #322 | Saved\n",
      "2022-08-17 18:08:06 | [trpo_pendulum] epoch #322 | Time 201.99 s\n",
      "2022-08-17 18:08:06 | [trpo_pendulum] epoch #322 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -420.457\n",
      "Evaluation/AverageReturn               -831.44\n",
      "Evaluation/Iteration                    322\n",
      "Evaluation/MaxReturn                   -591.583\n",
      "Evaluation/MinReturn                  -1122.16\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    176.112\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.71337\n",
      "GaussianMLPPolicy/KL                      0.00970543\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -47.6996\n",
      "GaussianMLPPolicy/LossBefore            -45.8007\n",
      "GaussianMLPPolicy/dLoss                   1.89891\n",
      "GaussianMLPValueFunction/LossAfter        6.70328\n",
      "GaussianMLPValueFunction/LossBefore       6.70952\n",
      "GaussianMLPValueFunction/dLoss            0.00623989\n",
      "TotalEnvSteps                        387600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:06 | [trpo_pendulum] epoch #323 | Saving snapshot...\n",
      "2022-08-17 18:08:06 | [trpo_pendulum] epoch #323 | Saved\n",
      "2022-08-17 18:08:06 | [trpo_pendulum] epoch #323 | Time 202.61 s\n",
      "2022-08-17 18:08:06 | [trpo_pendulum] epoch #323 | EpochTime 0.61 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -625.211\n",
      "Evaluation/AverageReturn              -1320.32\n",
      "Evaluation/Iteration                    323\n",
      "Evaluation/MaxReturn                  -1115.87\n",
      "Evaluation/MinReturn                  -1544.65\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    163.808\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.74064\n",
      "GaussianMLPPolicy/KL                      0.00915751\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              21.5533\n",
      "GaussianMLPPolicy/LossBefore             25.5691\n",
      "GaussianMLPPolicy/dLoss                   4.01581\n",
      "GaussianMLPValueFunction/LossAfter        6.71992\n",
      "GaussianMLPValueFunction/LossBefore       6.72055\n",
      "GaussianMLPValueFunction/dLoss            0.000634193\n",
      "TotalEnvSteps                        388800\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:08:07 | [trpo_pendulum] epoch #324 | Saving snapshot...\n",
      "2022-08-17 18:08:07 | [trpo_pendulum] epoch #324 | Saved\n",
      "2022-08-17 18:08:07 | [trpo_pendulum] epoch #324 | Time 203.22 s\n",
      "2022-08-17 18:08:07 | [trpo_pendulum] epoch #324 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -331.241\n",
      "Evaluation/AverageReturn               -680.314\n",
      "Evaluation/Iteration                    324\n",
      "Evaluation/MaxReturn                   -371.208\n",
      "Evaluation/MinReturn                  -1124.47\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    299.146\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.7473\n",
      "GaussianMLPPolicy/KL                      0.00688114\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -65.6068\n",
      "GaussianMLPPolicy/LossBefore            -64.5578\n",
      "GaussianMLPPolicy/dLoss                   1.04907\n",
      "GaussianMLPValueFunction/LossAfter        6.80939\n",
      "GaussianMLPValueFunction/LossBefore       6.82483\n",
      "GaussianMLPValueFunction/dLoss            0.0154424\n",
      "TotalEnvSteps                        390000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:08 | [trpo_pendulum] epoch #325 | Saving snapshot...\n",
      "2022-08-17 18:08:08 | [trpo_pendulum] epoch #325 | Saved\n",
      "2022-08-17 18:08:08 | [trpo_pendulum] epoch #325 | Time 203.84 s\n",
      "2022-08-17 18:08:08 | [trpo_pendulum] epoch #325 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -401.409\n",
      "Evaluation/AverageReturn               -800.396\n",
      "Evaluation/Iteration                    325\n",
      "Evaluation/MaxReturn                   -343.657\n",
      "Evaluation/MinReturn                  -1172.59\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    280.331\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.75088\n",
      "GaussianMLPPolicy/KL                      0.00731452\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -51.5274\n",
      "GaussianMLPPolicy/LossBefore            -49.5698\n",
      "GaussianMLPPolicy/dLoss                   1.95761\n",
      "GaussianMLPValueFunction/LossAfter        6.74181\n",
      "GaussianMLPValueFunction/LossBefore       6.74698\n",
      "GaussianMLPValueFunction/dLoss            0.00517035\n",
      "TotalEnvSteps                        391200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:08 | [trpo_pendulum] epoch #326 | Saving snapshot...\n",
      "2022-08-17 18:08:08 | [trpo_pendulum] epoch #326 | Saved\n",
      "2022-08-17 18:08:08 | [trpo_pendulum] epoch #326 | Time 204.47 s\n",
      "2022-08-17 18:08:08 | [trpo_pendulum] epoch #326 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -312.851\n",
      "Evaluation/AverageReturn               -633.048\n",
      "Evaluation/Iteration                    326\n",
      "Evaluation/MaxReturn                   -247.729\n",
      "Evaluation/MinReturn                  -1149.77\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    330.944\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.72632\n",
      "GaussianMLPPolicy/KL                      0.0085091\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -73.1369\n",
      "GaussianMLPPolicy/LossBefore            -70.7429\n",
      "GaussianMLPPolicy/dLoss                   2.39397\n",
      "GaussianMLPValueFunction/LossAfter        6.87078\n",
      "GaussianMLPValueFunction/LossBefore       6.88889\n",
      "GaussianMLPValueFunction/dLoss            0.0181041\n",
      "TotalEnvSteps                        392400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:08:09 | [trpo_pendulum] epoch #327 | Saving snapshot...\n",
      "2022-08-17 18:08:09 | [trpo_pendulum] epoch #327 | Saved\n",
      "2022-08-17 18:08:09 | [trpo_pendulum] epoch #327 | Time 205.11 s\n",
      "2022-08-17 18:08:09 | [trpo_pendulum] epoch #327 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -396.733\n",
      "Evaluation/AverageReturn               -791.122\n",
      "Evaluation/Iteration                    327\n",
      "Evaluation/MaxReturn                   -491.533\n",
      "Evaluation/MinReturn                   -992.389\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    185.197\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.70134\n",
      "GaussianMLPPolicy/KL                      0.00924146\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -49.1252\n",
      "GaussianMLPPolicy/LossBefore            -47.8746\n",
      "GaussianMLPPolicy/dLoss                   1.25063\n",
      "GaussianMLPValueFunction/LossAfter        6.70317\n",
      "GaussianMLPValueFunction/LossBefore       6.71091\n",
      "GaussianMLPValueFunction/dLoss            0.0077405\n",
      "TotalEnvSteps                        393600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:09 | [trpo_pendulum] epoch #328 | Saving snapshot...\n",
      "2022-08-17 18:08:09 | [trpo_pendulum] epoch #328 | Saved\n",
      "2022-08-17 18:08:09 | [trpo_pendulum] epoch #328 | Time 205.73 s\n",
      "2022-08-17 18:08:09 | [trpo_pendulum] epoch #328 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -591.133\n",
      "Evaluation/AverageReturn              -1208.26\n",
      "Evaluation/Iteration                    328\n",
      "Evaluation/MaxReturn                   -945.401\n",
      "Evaluation/MinReturn                  -1338.35\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    124.794\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.7102\n",
      "GaussianMLPPolicy/KL                      0.00647286\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               7.8214\n",
      "GaussianMLPPolicy/LossBefore             10.0552\n",
      "GaussianMLPPolicy/dLoss                   2.23379\n",
      "GaussianMLPValueFunction/LossAfter        6.63015\n",
      "GaussianMLPValueFunction/LossBefore       6.63947\n",
      "GaussianMLPValueFunction/dLoss            0.00931978\n",
      "TotalEnvSteps                        394800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:10 | [trpo_pendulum] epoch #329 | Saving snapshot...\n",
      "2022-08-17 18:08:10 | [trpo_pendulum] epoch #329 | Saved\n",
      "2022-08-17 18:08:10 | [trpo_pendulum] epoch #329 | Time 206.34 s\n",
      "2022-08-17 18:08:10 | [trpo_pendulum] epoch #329 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -429.155\n",
      "Evaluation/AverageReturn               -840.157\n",
      "Evaluation/Iteration                    329\n",
      "Evaluation/MaxReturn                   -617.189\n",
      "Evaluation/MinReturn                  -1127.32\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    201.729\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.70227\n",
      "GaussianMLPPolicy/KL                      0.00667463\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -45.2899\n",
      "GaussianMLPPolicy/LossBefore            -42.9505\n",
      "GaussianMLPPolicy/dLoss                   2.33941\n",
      "GaussianMLPValueFunction/LossAfter        6.68292\n",
      "GaussianMLPValueFunction/LossBefore       6.68851\n",
      "GaussianMLPValueFunction/dLoss            0.00558519\n",
      "TotalEnvSteps                        396000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:11 | [trpo_pendulum] epoch #330 | Saving snapshot...\n",
      "2022-08-17 18:08:11 | [trpo_pendulum] epoch #330 | Saved\n",
      "2022-08-17 18:08:11 | [trpo_pendulum] epoch #330 | Time 206.98 s\n",
      "2022-08-17 18:08:11 | [trpo_pendulum] epoch #330 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -364.185\n",
      "Evaluation/AverageReturn               -794.839\n",
      "Evaluation/Iteration                    330\n",
      "Evaluation/MaxReturn                   -606.933\n",
      "Evaluation/MinReturn                  -1113.99\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    173.458\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.6997\n",
      "GaussianMLPPolicy/KL                      0.00655046\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -43.9859\n",
      "GaussianMLPPolicy/LossBefore            -41.9739\n",
      "GaussianMLPPolicy/dLoss                   2.01195\n",
      "GaussianMLPValueFunction/LossAfter        6.55858\n",
      "GaussianMLPValueFunction/LossBefore       6.57466\n",
      "GaussianMLPValueFunction/dLoss            0.0160823\n",
      "TotalEnvSteps                        397200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:11 | [trpo_pendulum] epoch #331 | Saving snapshot...\n",
      "2022-08-17 18:08:11 | [trpo_pendulum] epoch #331 | Saved\n",
      "2022-08-17 18:08:11 | [trpo_pendulum] epoch #331 | Time 207.61 s\n",
      "2022-08-17 18:08:11 | [trpo_pendulum] epoch #331 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -109.026\n",
      "Evaluation/AverageReturn               -381.323\n",
      "Evaluation/Iteration                    331\n",
      "Evaluation/MaxReturn                   -145.542\n",
      "Evaluation/MinReturn                   -762.675\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    193.703\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.66612\n",
      "GaussianMLPPolicy/KL                      0.00756935\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -88.9607\n",
      "GaussianMLPPolicy/LossBefore            -87.4751\n",
      "GaussianMLPPolicy/dLoss                   1.48569\n",
      "GaussianMLPValueFunction/LossAfter        6.81446\n",
      "GaussianMLPValueFunction/LossBefore       6.84275\n",
      "GaussianMLPValueFunction/dLoss            0.0282946\n",
      "TotalEnvSteps                        398400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:12 | [trpo_pendulum] epoch #332 | Saving snapshot...\n",
      "2022-08-17 18:08:12 | [trpo_pendulum] epoch #332 | Saved\n",
      "2022-08-17 18:08:12 | [trpo_pendulum] epoch #332 | Time 208.24 s\n",
      "2022-08-17 18:08:12 | [trpo_pendulum] epoch #332 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -589.376\n",
      "Evaluation/AverageReturn              -1159.95\n",
      "Evaluation/Iteration                    332\n",
      "Evaluation/MaxReturn                   -879.609\n",
      "Evaluation/MinReturn                  -1460.68\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    215.461\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.64236\n",
      "GaussianMLPPolicy/KL                      0.00678281\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               2.24384\n",
      "GaussianMLPPolicy/LossBefore              4.835\n",
      "GaussianMLPPolicy/dLoss                   2.59117\n",
      "GaussianMLPValueFunction/LossAfter        6.78717\n",
      "GaussianMLPValueFunction/LossBefore       6.79125\n",
      "GaussianMLPValueFunction/dLoss            0.00407839\n",
      "TotalEnvSteps                        399600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:13 | [trpo_pendulum] epoch #333 | Saving snapshot...\n",
      "2022-08-17 18:08:13 | [trpo_pendulum] epoch #333 | Saved\n",
      "2022-08-17 18:08:13 | [trpo_pendulum] epoch #333 | Time 208.86 s\n",
      "2022-08-17 18:08:13 | [trpo_pendulum] epoch #333 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -458.718\n",
      "Evaluation/AverageReturn               -923.822\n",
      "Evaluation/Iteration                    333\n",
      "Evaluation/MaxReturn                   -717.722\n",
      "Evaluation/MinReturn                  -1119.46\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    170.58\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.64947\n",
      "GaussianMLPPolicy/KL                      0.00948938\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -29.7028\n",
      "GaussianMLPPolicy/LossBefore            -27.8229\n",
      "GaussianMLPPolicy/dLoss                   1.87989\n",
      "GaussianMLPValueFunction/LossAfter        6.5465\n",
      "GaussianMLPValueFunction/LossBefore       6.5669\n",
      "GaussianMLPValueFunction/dLoss            0.0203924\n",
      "TotalEnvSteps                        400800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:13 | [trpo_pendulum] epoch #334 | Saving snapshot...\n",
      "2022-08-17 18:08:13 | [trpo_pendulum] epoch #334 | Saved\n",
      "2022-08-17 18:08:13 | [trpo_pendulum] epoch #334 | Time 209.48 s\n",
      "2022-08-17 18:08:13 | [trpo_pendulum] epoch #334 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -386.512\n",
      "Evaluation/AverageReturn               -791.617\n",
      "Evaluation/Iteration                    334\n",
      "Evaluation/MaxReturn                   -628.745\n",
      "Evaluation/MinReturn                  -1014.74\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    125.317\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.66689\n",
      "GaussianMLPPolicy/KL                      0.00832425\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -44.2075\n",
      "GaussianMLPPolicy/LossBefore            -42.2295\n",
      "GaussianMLPPolicy/dLoss                   1.97803\n",
      "GaussianMLPValueFunction/LossAfter        6.59061\n",
      "GaussianMLPValueFunction/LossBefore       6.60036\n",
      "GaussianMLPValueFunction/dLoss            0.00975704\n",
      "TotalEnvSteps                        402000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:14 | [trpo_pendulum] epoch #335 | Saving snapshot...\n",
      "2022-08-17 18:08:14 | [trpo_pendulum] epoch #335 | Saved\n",
      "2022-08-17 18:08:14 | [trpo_pendulum] epoch #335 | Time 210.11 s\n",
      "2022-08-17 18:08:14 | [trpo_pendulum] epoch #335 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -392.216\n",
      "Evaluation/AverageReturn               -730.199\n",
      "Evaluation/Iteration                    335\n",
      "Evaluation/MaxReturn                   -601.72\n",
      "Evaluation/MinReturn                   -980.752\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    144.87\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.64889\n",
      "GaussianMLPPolicy/KL                      0.00835723\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -56.9689\n",
      "GaussianMLPPolicy/LossBefore            -54.971\n",
      "GaussianMLPPolicy/dLoss                   1.99788\n",
      "GaussianMLPValueFunction/LossAfter        6.73358\n",
      "GaussianMLPValueFunction/LossBefore       6.74637\n",
      "GaussianMLPValueFunction/dLoss            0.0127835\n",
      "TotalEnvSteps                        403200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:14 | [trpo_pendulum] epoch #336 | Saving snapshot...\n",
      "2022-08-17 18:08:14 | [trpo_pendulum] epoch #336 | Saved\n",
      "2022-08-17 18:08:14 | [trpo_pendulum] epoch #336 | Time 210.74 s\n",
      "2022-08-17 18:08:14 | [trpo_pendulum] epoch #336 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -647.744\n",
      "Evaluation/AverageReturn              -1397.88\n",
      "Evaluation/Iteration                    336\n",
      "Evaluation/MaxReturn                  -1268.14\n",
      "Evaluation/MinReturn                  -1553.22\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    103.315\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.64316\n",
      "GaussianMLPPolicy/KL                      0.00737656\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              43.5603\n",
      "GaussianMLPPolicy/LossBefore             45.5401\n",
      "GaussianMLPPolicy/dLoss                   1.97981\n",
      "GaussianMLPValueFunction/LossAfter        6.71881\n",
      "GaussianMLPValueFunction/LossBefore       6.72051\n",
      "GaussianMLPValueFunction/dLoss            0.00169992\n",
      "TotalEnvSteps                        404400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:15 | [trpo_pendulum] epoch #337 | Saving snapshot...\n",
      "2022-08-17 18:08:15 | [trpo_pendulum] epoch #337 | Saved\n",
      "2022-08-17 18:08:15 | [trpo_pendulum] epoch #337 | Time 211.36 s\n",
      "2022-08-17 18:08:15 | [trpo_pendulum] epoch #337 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -476.166\n",
      "Evaluation/AverageReturn               -951.158\n",
      "Evaluation/Iteration                    337\n",
      "Evaluation/MaxReturn                   -758.278\n",
      "Evaluation/MinReturn                  -1165.41\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    141.677\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62195\n",
      "GaussianMLPPolicy/KL                      0.00994962\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -24.8313\n",
      "GaussianMLPPolicy/LossBefore            -22.2243\n",
      "GaussianMLPPolicy/dLoss                   2.60702\n",
      "GaussianMLPValueFunction/LossAfter        6.54803\n",
      "GaussianMLPValueFunction/LossBefore       6.56162\n",
      "GaussianMLPValueFunction/dLoss            0.0135889\n",
      "TotalEnvSteps                        405600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:16 | [trpo_pendulum] epoch #338 | Saving snapshot...\n",
      "2022-08-17 18:08:16 | [trpo_pendulum] epoch #338 | Saved\n",
      "2022-08-17 18:08:16 | [trpo_pendulum] epoch #338 | Time 211.98 s\n",
      "2022-08-17 18:08:16 | [trpo_pendulum] epoch #338 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -365.844\n",
      "Evaluation/AverageReturn               -710.556\n",
      "Evaluation/Iteration                    338\n",
      "Evaluation/MaxReturn                   -482.971\n",
      "Evaluation/MinReturn                  -1048.26\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    188.414\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.60136\n",
      "GaussianMLPPolicy/KL                      0.00723536\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -56.5444\n",
      "GaussianMLPPolicy/LossBefore            -54.9951\n",
      "GaussianMLPPolicy/dLoss                   1.54939\n",
      "GaussianMLPValueFunction/LossAfter        6.72071\n",
      "GaussianMLPValueFunction/LossBefore       6.73269\n",
      "GaussianMLPValueFunction/dLoss            0.0119848\n",
      "TotalEnvSteps                        406800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:16 | [trpo_pendulum] epoch #339 | Saving snapshot...\n",
      "2022-08-17 18:08:16 | [trpo_pendulum] epoch #339 | Saved\n",
      "2022-08-17 18:08:16 | [trpo_pendulum] epoch #339 | Time 212.60 s\n",
      "2022-08-17 18:08:16 | [trpo_pendulum] epoch #339 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -330.127\n",
      "Evaluation/AverageReturn               -738.474\n",
      "Evaluation/Iteration                    339\n",
      "Evaluation/MaxReturn                   -504.692\n",
      "Evaluation/MinReturn                  -1012.64\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    200.459\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.60244\n",
      "GaussianMLPPolicy/KL                      0.00900725\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -41.9486\n",
      "GaussianMLPPolicy/LossBefore            -39.6971\n",
      "GaussianMLPPolicy/dLoss                   2.25152\n",
      "GaussianMLPValueFunction/LossAfter        6.5905\n",
      "GaussianMLPValueFunction/LossBefore       6.59906\n",
      "GaussianMLPValueFunction/dLoss            0.00855827\n",
      "TotalEnvSteps                        408000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:17 | [trpo_pendulum] epoch #340 | Saving snapshot...\n",
      "2022-08-17 18:08:17 | [trpo_pendulum] epoch #340 | Saved\n",
      "2022-08-17 18:08:17 | [trpo_pendulum] epoch #340 | Time 213.23 s\n",
      "2022-08-17 18:08:17 | [trpo_pendulum] epoch #340 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -667.409\n",
      "Evaluation/AverageReturn              -1529.84\n",
      "Evaluation/Iteration                    340\n",
      "Evaluation/MaxReturn                  -1505.58\n",
      "Evaluation/MinReturn                  -1569.14\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     19.5846\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.57378\n",
      "GaussianMLPPolicy/KL                      0.00721352\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              68.3308\n",
      "GaussianMLPPolicy/LossBefore             69.9165\n",
      "GaussianMLPPolicy/dLoss                   1.58571\n",
      "GaussianMLPValueFunction/LossAfter        6.79562\n",
      "GaussianMLPValueFunction/LossBefore       6.81359\n",
      "GaussianMLPValueFunction/dLoss            0.0179725\n",
      "TotalEnvSteps                        409200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:18 | [trpo_pendulum] epoch #341 | Saving snapshot...\n",
      "2022-08-17 18:08:18 | [trpo_pendulum] epoch #341 | Saved\n",
      "2022-08-17 18:08:18 | [trpo_pendulum] epoch #341 | Time 213.87 s\n",
      "2022-08-17 18:08:18 | [trpo_pendulum] epoch #341 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -412.071\n",
      "Evaluation/AverageReturn               -834.291\n",
      "Evaluation/Iteration                    341\n",
      "Evaluation/MaxReturn                   -611.645\n",
      "Evaluation/MinReturn                  -1073.71\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    187.202\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.56005\n",
      "GaussianMLPPolicy/KL                      0.00727619\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -36.6767\n",
      "GaussianMLPPolicy/LossBefore            -34.8449\n",
      "GaussianMLPPolicy/dLoss                   1.83172\n",
      "GaussianMLPValueFunction/LossAfter        6.5703\n",
      "GaussianMLPValueFunction/LossBefore       6.5823\n",
      "GaussianMLPValueFunction/dLoss            0.0120001\n",
      "TotalEnvSteps                        410400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:18 | [trpo_pendulum] epoch #342 | Saving snapshot...\n",
      "2022-08-17 18:08:18 | [trpo_pendulum] epoch #342 | Saved\n",
      "2022-08-17 18:08:18 | [trpo_pendulum] epoch #342 | Time 214.51 s\n",
      "2022-08-17 18:08:18 | [trpo_pendulum] epoch #342 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -214.389\n",
      "Evaluation/AverageReturn               -472.926\n",
      "Evaluation/Iteration                    342\n",
      "Evaluation/MaxReturn                   -272.524\n",
      "Evaluation/MinReturn                   -686.112\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    153.597\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.57946\n",
      "GaussianMLPPolicy/KL                      0.00832142\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -83.5404\n",
      "GaussianMLPPolicy/LossBefore            -81.9925\n",
      "GaussianMLPPolicy/dLoss                   1.54794\n",
      "GaussianMLPValueFunction/LossAfter        6.75631\n",
      "GaussianMLPValueFunction/LossBefore       6.77422\n",
      "GaussianMLPValueFunction/dLoss            0.017909\n",
      "TotalEnvSteps                        411600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:19 | [trpo_pendulum] epoch #343 | Saving snapshot...\n",
      "2022-08-17 18:08:19 | [trpo_pendulum] epoch #343 | Saved\n",
      "2022-08-17 18:08:19 | [trpo_pendulum] epoch #343 | Time 215.12 s\n",
      "2022-08-17 18:08:19 | [trpo_pendulum] epoch #343 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -467.28\n",
      "Evaluation/AverageReturn               -872.506\n",
      "Evaluation/Iteration                    343\n",
      "Evaluation/MaxReturn                   -717.729\n",
      "Evaluation/MinReturn                  -1066.96\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    127.992\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.57482\n",
      "GaussianMLPPolicy/KL                      0.00698557\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -34.5566\n",
      "GaussianMLPPolicy/LossBefore            -32.0602\n",
      "GaussianMLPPolicy/dLoss                   2.49646\n",
      "GaussianMLPValueFunction/LossAfter        6.65911\n",
      "GaussianMLPValueFunction/LossBefore       6.66375\n",
      "GaussianMLPValueFunction/dLoss            0.00463724\n",
      "TotalEnvSteps                        412800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:19 | [trpo_pendulum] epoch #344 | Saving snapshot...\n",
      "2022-08-17 18:08:19 | [trpo_pendulum] epoch #344 | Saved\n",
      "2022-08-17 18:08:19 | [trpo_pendulum] epoch #344 | Time 215.75 s\n",
      "2022-08-17 18:08:19 | [trpo_pendulum] epoch #344 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -467.213\n",
      "Evaluation/AverageReturn               -841.068\n",
      "Evaluation/Iteration                    344\n",
      "Evaluation/MaxReturn                   -725.024\n",
      "Evaluation/MinReturn                   -948.903\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     64.8599\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.58144\n",
      "GaussianMLPPolicy/KL                      0.00681701\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -39.4421\n",
      "GaussianMLPPolicy/LossBefore            -36.6742\n",
      "GaussianMLPPolicy/dLoss                   2.76792\n",
      "GaussianMLPValueFunction/LossAfter        6.72544\n",
      "GaussianMLPValueFunction/LossBefore       6.73166\n",
      "GaussianMLPValueFunction/dLoss            0.00621462\n",
      "TotalEnvSteps                        414000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:20 | [trpo_pendulum] epoch #345 | Saving snapshot...\n",
      "2022-08-17 18:08:20 | [trpo_pendulum] epoch #345 | Saved\n",
      "2022-08-17 18:08:20 | [trpo_pendulum] epoch #345 | Time 216.36 s\n",
      "2022-08-17 18:08:20 | [trpo_pendulum] epoch #345 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -543.761\n",
      "Evaluation/AverageReturn              -1099.66\n",
      "Evaluation/Iteration                    345\n",
      "Evaluation/MaxReturn                   -833.985\n",
      "Evaluation/MinReturn                  -1333.59\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    164.798\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.57057\n",
      "GaussianMLPPolicy/KL                      0.00671992\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               1.63646\n",
      "GaussianMLPPolicy/LossBefore              4.1865\n",
      "GaussianMLPPolicy/dLoss                   2.55004\n",
      "GaussianMLPValueFunction/LossAfter        6.60525\n",
      "GaussianMLPValueFunction/LossBefore       6.61074\n",
      "GaussianMLPValueFunction/dLoss            0.00548792\n",
      "TotalEnvSteps                        415200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:21 | [trpo_pendulum] epoch #346 | Saving snapshot...\n",
      "2022-08-17 18:08:21 | [trpo_pendulum] epoch #346 | Saved\n",
      "2022-08-17 18:08:21 | [trpo_pendulum] epoch #346 | Time 216.98 s\n",
      "2022-08-17 18:08:21 | [trpo_pendulum] epoch #346 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -579.504\n",
      "Evaluation/AverageReturn              -1213.65\n",
      "Evaluation/Iteration                    346\n",
      "Evaluation/MaxReturn                   -758.3\n",
      "Evaluation/MinReturn                  -1551.99\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    278.066\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.5678\n",
      "GaussianMLPPolicy/KL                      0.00977375\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              19.8164\n",
      "GaussianMLPPolicy/LossBefore             22.8398\n",
      "GaussianMLPPolicy/dLoss                   3.02337\n",
      "GaussianMLPValueFunction/LossAfter        6.73345\n",
      "GaussianMLPValueFunction/LossBefore       6.73633\n",
      "GaussianMLPValueFunction/dLoss            0.00287771\n",
      "TotalEnvSteps                        416400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:21 | [trpo_pendulum] epoch #347 | Saving snapshot...\n",
      "2022-08-17 18:08:21 | [trpo_pendulum] epoch #347 | Saved\n",
      "2022-08-17 18:08:21 | [trpo_pendulum] epoch #347 | Time 217.61 s\n",
      "2022-08-17 18:08:21 | [trpo_pendulum] epoch #347 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -334.604\n",
      "Evaluation/AverageReturn               -625.181\n",
      "Evaluation/Iteration                    347\n",
      "Evaluation/MaxReturn                   -490.487\n",
      "Evaluation/MinReturn                   -966.265\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    161.644\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.54672\n",
      "GaussianMLPPolicy/KL                      0.00911814\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -64.961\n",
      "GaussianMLPPolicy/LossBefore            -63.2238\n",
      "GaussianMLPPolicy/dLoss                   1.73721\n",
      "GaussianMLPValueFunction/LossAfter        6.73542\n",
      "GaussianMLPValueFunction/LossBefore       6.74605\n",
      "GaussianMLPValueFunction/dLoss            0.0106201\n",
      "TotalEnvSteps                        417600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:22 | [trpo_pendulum] epoch #348 | Saving snapshot...\n",
      "2022-08-17 18:08:22 | [trpo_pendulum] epoch #348 | Saved\n",
      "2022-08-17 18:08:22 | [trpo_pendulum] epoch #348 | Time 218.24 s\n",
      "2022-08-17 18:08:22 | [trpo_pendulum] epoch #348 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -660.421\n",
      "Evaluation/AverageReturn              -1475.75\n",
      "Evaluation/Iteration                    348\n",
      "Evaluation/MaxReturn                  -1305.56\n",
      "Evaluation/MinReturn                  -1536.92\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     83.7464\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.54703\n",
      "GaussianMLPPolicy/KL                      0.00780015\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              59.8548\n",
      "GaussianMLPPolicy/LossBefore             64.1008\n",
      "GaussianMLPPolicy/dLoss                   4.24601\n",
      "GaussianMLPValueFunction/LossAfter        6.79423\n",
      "GaussianMLPValueFunction/LossBefore       6.80145\n",
      "GaussianMLPValueFunction/dLoss            0.00721645\n",
      "TotalEnvSteps                        418800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:23 | [trpo_pendulum] epoch #349 | Saving snapshot...\n",
      "2022-08-17 18:08:23 | [trpo_pendulum] epoch #349 | Saved\n",
      "2022-08-17 18:08:23 | [trpo_pendulum] epoch #349 | Time 218.86 s\n",
      "2022-08-17 18:08:23 | [trpo_pendulum] epoch #349 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -482.056\n",
      "Evaluation/AverageReturn               -939.94\n",
      "Evaluation/Iteration                    349\n",
      "Evaluation/MaxReturn                   -594.467\n",
      "Evaluation/MinReturn                  -1096.11\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    200.661\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.54947\n",
      "GaussianMLPPolicy/KL                      0.00650053\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -20.5842\n",
      "GaussianMLPPolicy/LossBefore            -18.5175\n",
      "GaussianMLPPolicy/dLoss                   2.06675\n",
      "GaussianMLPValueFunction/LossAfter        6.63358\n",
      "GaussianMLPValueFunction/LossBefore       6.64274\n",
      "GaussianMLPValueFunction/dLoss            0.009161\n",
      "TotalEnvSteps                        420000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:23 | [trpo_pendulum] epoch #350 | Saving snapshot...\n",
      "2022-08-17 18:08:23 | [trpo_pendulum] epoch #350 | Saved\n",
      "2022-08-17 18:08:23 | [trpo_pendulum] epoch #350 | Time 219.49 s\n",
      "2022-08-17 18:08:23 | [trpo_pendulum] epoch #350 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -412.067\n",
      "Evaluation/AverageReturn               -790.859\n",
      "Evaluation/Iteration                    350\n",
      "Evaluation/MaxReturn                   -476.413\n",
      "Evaluation/MinReturn                   -992.336\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    175.71\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.54954\n",
      "GaussianMLPPolicy/KL                      0.0065507\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -41.4422\n",
      "GaussianMLPPolicy/LossBefore            -39.2679\n",
      "GaussianMLPPolicy/dLoss                   2.1743\n",
      "GaussianMLPValueFunction/LossAfter        6.64142\n",
      "GaussianMLPValueFunction/LossBefore       6.64902\n",
      "GaussianMLPValueFunction/dLoss            0.00759649\n",
      "TotalEnvSteps                        421200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:24 | [trpo_pendulum] epoch #351 | Saving snapshot...\n",
      "2022-08-17 18:08:24 | [trpo_pendulum] epoch #351 | Saved\n",
      "2022-08-17 18:08:24 | [trpo_pendulum] epoch #351 | Time 220.12 s\n",
      "2022-08-17 18:08:24 | [trpo_pendulum] epoch #351 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -322.726\n",
      "Evaluation/AverageReturn               -543.583\n",
      "Evaluation/Iteration                    351\n",
      "Evaluation/MaxReturn                   -239.055\n",
      "Evaluation/MinReturn                   -943.14\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    222.863\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.58813\n",
      "GaussianMLPPolicy/KL                      0.00793293\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -77.3824\n",
      "GaussianMLPPolicy/LossBefore            -75.4956\n",
      "GaussianMLPPolicy/dLoss                   1.88678\n",
      "GaussianMLPValueFunction/LossAfter        6.91159\n",
      "GaussianMLPValueFunction/LossBefore       6.95889\n",
      "GaussianMLPValueFunction/dLoss            0.0473032\n",
      "TotalEnvSteps                        422400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:24 | [trpo_pendulum] epoch #352 | Saving snapshot...\n",
      "2022-08-17 18:08:24 | [trpo_pendulum] epoch #352 | Saved\n",
      "2022-08-17 18:08:24 | [trpo_pendulum] epoch #352 | Time 220.75 s\n",
      "2022-08-17 18:08:24 | [trpo_pendulum] epoch #352 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -252.559\n",
      "Evaluation/AverageReturn               -386.006\n",
      "Evaluation/Iteration                    352\n",
      "Evaluation/MaxReturn                   -237.935\n",
      "Evaluation/MinReturn                   -865.181\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    221.558\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.57026\n",
      "GaussianMLPPolicy/KL                      0.00943466\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter            -100.096\n",
      "GaussianMLPPolicy/LossBefore            -98.257\n",
      "GaussianMLPPolicy/dLoss                   1.83916\n",
      "GaussianMLPValueFunction/LossAfter        7.01686\n",
      "GaussianMLPValueFunction/LossBefore       7.06514\n",
      "GaussianMLPValueFunction/dLoss            0.0482793\n",
      "TotalEnvSteps                        423600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:25 | [trpo_pendulum] epoch #353 | Saving snapshot...\n",
      "2022-08-17 18:08:25 | [trpo_pendulum] epoch #353 | Saved\n",
      "2022-08-17 18:08:25 | [trpo_pendulum] epoch #353 | Time 221.40 s\n",
      "2022-08-17 18:08:25 | [trpo_pendulum] epoch #353 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -250.373\n",
      "Evaluation/AverageReturn               -463.315\n",
      "Evaluation/Iteration                    353\n",
      "Evaluation/MaxReturn                   -126.612\n",
      "Evaluation/MinReturn                   -886.272\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    269.688\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.56323\n",
      "GaussianMLPPolicy/KL                      0.00798521\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -80.1595\n",
      "GaussianMLPPolicy/LossBefore            -78.3112\n",
      "GaussianMLPPolicy/dLoss                   1.84825\n",
      "GaussianMLPValueFunction/LossAfter        6.89042\n",
      "GaussianMLPValueFunction/LossBefore       6.89796\n",
      "GaussianMLPValueFunction/dLoss            0.00753736\n",
      "TotalEnvSteps                        424800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:26 | [trpo_pendulum] epoch #354 | Saving snapshot...\n",
      "2022-08-17 18:08:26 | [trpo_pendulum] epoch #354 | Saved\n",
      "2022-08-17 18:08:26 | [trpo_pendulum] epoch #354 | Time 222.02 s\n",
      "2022-08-17 18:08:26 | [trpo_pendulum] epoch #354 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -423.369\n",
      "Evaluation/AverageReturn               -843.419\n",
      "Evaluation/Iteration                    354\n",
      "Evaluation/MaxReturn                   -514.669\n",
      "Evaluation/MinReturn                  -1169.98\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    255.074\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.57178\n",
      "GaussianMLPPolicy/KL                      0.00759244\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -27.6436\n",
      "GaussianMLPPolicy/LossBefore            -24.7698\n",
      "GaussianMLPPolicy/dLoss                   2.87379\n",
      "GaussianMLPValueFunction/LossAfter        6.70764\n",
      "GaussianMLPValueFunction/LossBefore       6.71934\n",
      "GaussianMLPValueFunction/dLoss            0.011704\n",
      "TotalEnvSteps                        426000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:26 | [trpo_pendulum] epoch #355 | Saving snapshot...\n",
      "2022-08-17 18:08:26 | [trpo_pendulum] epoch #355 | Saved\n",
      "2022-08-17 18:08:26 | [trpo_pendulum] epoch #355 | Time 222.63 s\n",
      "2022-08-17 18:08:26 | [trpo_pendulum] epoch #355 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -306.348\n",
      "Evaluation/AverageReturn               -554.593\n",
      "Evaluation/Iteration                    355\n",
      "Evaluation/MaxReturn                   -121.068\n",
      "Evaluation/MinReturn                   -860.123\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    257.566\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.56892\n",
      "GaussianMLPPolicy/KL                      0.0096219\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -70.3244\n",
      "GaussianMLPPolicy/LossBefore            -68.1252\n",
      "GaussianMLPPolicy/dLoss                   2.19924\n",
      "GaussianMLPValueFunction/LossAfter        6.83128\n",
      "GaussianMLPValueFunction/LossBefore       6.83719\n",
      "GaussianMLPValueFunction/dLoss            0.00591183\n",
      "TotalEnvSteps                        427200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:27 | [trpo_pendulum] epoch #356 | Saving snapshot...\n",
      "2022-08-17 18:08:27 | [trpo_pendulum] epoch #356 | Saved\n",
      "2022-08-17 18:08:27 | [trpo_pendulum] epoch #356 | Time 223.25 s\n",
      "2022-08-17 18:08:27 | [trpo_pendulum] epoch #356 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -286.344\n",
      "Evaluation/AverageReturn               -504.364\n",
      "Evaluation/Iteration                    356\n",
      "Evaluation/MaxReturn                   -244.876\n",
      "Evaluation/MinReturn                  -1021.91\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    268.168\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.55141\n",
      "GaussianMLPPolicy/KL                      0.00904125\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -76.6874\n",
      "GaussianMLPPolicy/LossBefore            -74.8296\n",
      "GaussianMLPPolicy/dLoss                   1.8578\n",
      "GaussianMLPValueFunction/LossAfter        6.86684\n",
      "GaussianMLPValueFunction/LossBefore       6.87464\n",
      "GaussianMLPValueFunction/dLoss            0.00779533\n",
      "TotalEnvSteps                        428400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:28 | [trpo_pendulum] epoch #357 | Saving snapshot...\n",
      "2022-08-17 18:08:28 | [trpo_pendulum] epoch #357 | Saved\n",
      "2022-08-17 18:08:28 | [trpo_pendulum] epoch #357 | Time 223.86 s\n",
      "2022-08-17 18:08:28 | [trpo_pendulum] epoch #357 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -318.092\n",
      "Evaluation/AverageReturn               -559.461\n",
      "Evaluation/Iteration                    357\n",
      "Evaluation/MaxReturn                   -364.068\n",
      "Evaluation/MinReturn                   -871.54\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    192.764\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.54126\n",
      "GaussianMLPPolicy/KL                      0.0064671\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -69.0339\n",
      "GaussianMLPPolicy/LossBefore            -67.2425\n",
      "GaussianMLPPolicy/dLoss                   1.79142\n",
      "GaussianMLPValueFunction/LossAfter        6.7991\n",
      "GaussianMLPValueFunction/LossBefore       6.80533\n",
      "GaussianMLPValueFunction/dLoss            0.00622559\n",
      "TotalEnvSteps                        429600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:28 | [trpo_pendulum] epoch #358 | Saving snapshot...\n",
      "2022-08-17 18:08:28 | [trpo_pendulum] epoch #358 | Saved\n",
      "2022-08-17 18:08:28 | [trpo_pendulum] epoch #358 | Time 224.47 s\n",
      "2022-08-17 18:08:28 | [trpo_pendulum] epoch #358 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -291.006\n",
      "Evaluation/AverageReturn               -539.863\n",
      "Evaluation/Iteration                    358\n",
      "Evaluation/MaxReturn                   -249.984\n",
      "Evaluation/MinReturn                   -977.157\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    248.889\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.54077\n",
      "GaussianMLPPolicy/KL                      0.00650241\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -65.9414\n",
      "GaussianMLPPolicy/LossBefore            -64.7227\n",
      "GaussianMLPPolicy/dLoss                   1.21865\n",
      "GaussianMLPValueFunction/LossAfter        6.81217\n",
      "GaussianMLPValueFunction/LossBefore       6.81767\n",
      "GaussianMLPValueFunction/dLoss            0.00549555\n",
      "TotalEnvSteps                        430800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:29 | [trpo_pendulum] epoch #359 | Saving snapshot...\n",
      "2022-08-17 18:08:29 | [trpo_pendulum] epoch #359 | Saved\n",
      "2022-08-17 18:08:29 | [trpo_pendulum] epoch #359 | Time 225.10 s\n",
      "2022-08-17 18:08:29 | [trpo_pendulum] epoch #359 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -339.612\n",
      "Evaluation/AverageReturn               -588.613\n",
      "Evaluation/Iteration                    359\n",
      "Evaluation/MaxReturn                   -233.502\n",
      "Evaluation/MinReturn                   -999.388\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    237.45\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.54246\n",
      "GaussianMLPPolicy/KL                      0.00981871\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -65.0064\n",
      "GaussianMLPPolicy/LossBefore            -63.2221\n",
      "GaussianMLPPolicy/dLoss                   1.78436\n",
      "GaussianMLPValueFunction/LossAfter        6.81265\n",
      "GaussianMLPValueFunction/LossBefore       6.81807\n",
      "GaussianMLPValueFunction/dLoss            0.00541639\n",
      "TotalEnvSteps                        432000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:29 | [trpo_pendulum] epoch #360 | Saving snapshot...\n",
      "2022-08-17 18:08:29 | [trpo_pendulum] epoch #360 | Saved\n",
      "2022-08-17 18:08:29 | [trpo_pendulum] epoch #360 | Time 225.72 s\n",
      "2022-08-17 18:08:29 | [trpo_pendulum] epoch #360 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -278.255\n",
      "Evaluation/AverageReturn               -460.273\n",
      "Evaluation/Iteration                    360\n",
      "Evaluation/MaxReturn                   -122.986\n",
      "Evaluation/MinReturn                  -1027.77\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    276.917\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.55755\n",
      "GaussianMLPPolicy/KL                      0.00866318\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -81.6984\n",
      "GaussianMLPPolicy/LossBefore            -80.2428\n",
      "GaussianMLPPolicy/dLoss                   1.45562\n",
      "GaussianMLPValueFunction/LossAfter        6.90907\n",
      "GaussianMLPValueFunction/LossBefore       6.92175\n",
      "GaussianMLPValueFunction/dLoss            0.0126848\n",
      "TotalEnvSteps                        433200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:30 | [trpo_pendulum] epoch #361 | Saving snapshot...\n",
      "2022-08-17 18:08:30 | [trpo_pendulum] epoch #361 | Saved\n",
      "2022-08-17 18:08:30 | [trpo_pendulum] epoch #361 | Time 226.35 s\n",
      "2022-08-17 18:08:30 | [trpo_pendulum] epoch #361 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -442.466\n",
      "Evaluation/AverageReturn               -863.899\n",
      "Evaluation/Iteration                    361\n",
      "Evaluation/MaxReturn                   -727.194\n",
      "Evaluation/MinReturn                   -968.666\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     80.0527\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.53878\n",
      "GaussianMLPPolicy/KL                      0.00657455\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -22.0955\n",
      "GaussianMLPPolicy/LossBefore            -20.4998\n",
      "GaussianMLPPolicy/dLoss                   1.59571\n",
      "GaussianMLPValueFunction/LossAfter        6.55079\n",
      "GaussianMLPValueFunction/LossBefore       6.59609\n",
      "GaussianMLPValueFunction/dLoss            0.0452995\n",
      "TotalEnvSteps                        434400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:31 | [trpo_pendulum] epoch #362 | Saving snapshot...\n",
      "2022-08-17 18:08:31 | [trpo_pendulum] epoch #362 | Saved\n",
      "2022-08-17 18:08:31 | [trpo_pendulum] epoch #362 | Time 226.96 s\n",
      "2022-08-17 18:08:31 | [trpo_pendulum] epoch #362 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -246.635\n",
      "Evaluation/AverageReturn               -391.005\n",
      "Evaluation/Iteration                    362\n",
      "Evaluation/MaxReturn                   -244.887\n",
      "Evaluation/MinReturn                   -623.993\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    135.317\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.49635\n",
      "GaussianMLPPolicy/KL                      0.00671263\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -89.5132\n",
      "GaussianMLPPolicy/LossBefore            -87.9138\n",
      "GaussianMLPPolicy/dLoss                   1.5994\n",
      "GaussianMLPValueFunction/LossAfter        6.90688\n",
      "GaussianMLPValueFunction/LossBefore       6.92804\n",
      "GaussianMLPValueFunction/dLoss            0.0211573\n",
      "TotalEnvSteps                        435600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:31 | [trpo_pendulum] epoch #363 | Saving snapshot...\n",
      "2022-08-17 18:08:31 | [trpo_pendulum] epoch #363 | Saved\n",
      "2022-08-17 18:08:31 | [trpo_pendulum] epoch #363 | Time 227.59 s\n",
      "2022-08-17 18:08:31 | [trpo_pendulum] epoch #363 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -654.025\n",
      "Evaluation/AverageReturn              -1505.45\n",
      "Evaluation/Iteration                    363\n",
      "Evaluation/MaxReturn                  -1497.95\n",
      "Evaluation/MinReturn                  -1511.19\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.17555\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.48336\n",
      "GaussianMLPPolicy/KL                      0.00754466\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              79.3386\n",
      "GaussianMLPPolicy/LossBefore             80.064\n",
      "GaussianMLPPolicy/dLoss                   0.725357\n",
      "GaussianMLPValueFunction/LossAfter        6.83709\n",
      "GaussianMLPValueFunction/LossBefore       6.84067\n",
      "GaussianMLPValueFunction/dLoss            0.003582\n",
      "TotalEnvSteps                        436800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:32 | [trpo_pendulum] epoch #364 | Saving snapshot...\n",
      "2022-08-17 18:08:32 | [trpo_pendulum] epoch #364 | Saved\n",
      "2022-08-17 18:08:32 | [trpo_pendulum] epoch #364 | Time 228.21 s\n",
      "2022-08-17 18:08:32 | [trpo_pendulum] epoch #364 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -634.612\n",
      "Evaluation/AverageReturn              -1426.16\n",
      "Evaluation/Iteration                    364\n",
      "Evaluation/MaxReturn                  -1198.85\n",
      "Evaluation/MinReturn                  -1559.5\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    160.423\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.462\n",
      "GaussianMLPPolicy/KL                      0.00936989\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              63.7066\n",
      "GaussianMLPPolicy/LossBefore             66.6968\n",
      "GaussianMLPPolicy/dLoss                   2.99025\n",
      "GaussianMLPValueFunction/LossAfter        6.78174\n",
      "GaussianMLPValueFunction/LossBefore       6.78448\n",
      "GaussianMLPValueFunction/dLoss            0.00274229\n",
      "TotalEnvSteps                        438000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:33 | [trpo_pendulum] epoch #365 | Saving snapshot...\n",
      "2022-08-17 18:08:33 | [trpo_pendulum] epoch #365 | Saved\n",
      "2022-08-17 18:08:33 | [trpo_pendulum] epoch #365 | Time 228.82 s\n",
      "2022-08-17 18:08:33 | [trpo_pendulum] epoch #365 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -406.652\n",
      "Evaluation/AverageReturn               -875.073\n",
      "Evaluation/Iteration                    365\n",
      "Evaluation/MaxReturn                   -501.752\n",
      "Evaluation/MinReturn                  -1057.13\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    222.255\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.47813\n",
      "GaussianMLPPolicy/KL                      0.0069629\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -14.1789\n",
      "GaussianMLPPolicy/LossBefore            -12.786\n",
      "GaussianMLPPolicy/dLoss                   1.39285\n",
      "GaussianMLPValueFunction/LossAfter        6.5318\n",
      "GaussianMLPValueFunction/LossBefore       6.56648\n",
      "GaussianMLPValueFunction/dLoss            0.0346785\n",
      "TotalEnvSteps                        439200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:08:33 | [trpo_pendulum] epoch #366 | Saving snapshot...\n",
      "2022-08-17 18:08:33 | [trpo_pendulum] epoch #366 | Saved\n",
      "2022-08-17 18:08:33 | [trpo_pendulum] epoch #366 | Time 229.44 s\n",
      "2022-08-17 18:08:33 | [trpo_pendulum] epoch #366 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -386.896\n",
      "Evaluation/AverageReturn               -898.636\n",
      "Evaluation/Iteration                    366\n",
      "Evaluation/MaxReturn                   -489.315\n",
      "Evaluation/MinReturn                  -1185.24\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    250.581\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.47735\n",
      "GaussianMLPPolicy/KL                      0.00789022\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.81888\n",
      "GaussianMLPPolicy/LossBefore             -6.85787\n",
      "GaussianMLPPolicy/dLoss                   0.961009\n",
      "GaussianMLPValueFunction/LossAfter        6.45084\n",
      "GaussianMLPValueFunction/LossBefore       6.4837\n",
      "GaussianMLPValueFunction/dLoss            0.0328541\n",
      "TotalEnvSteps                        440400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:34 | [trpo_pendulum] epoch #367 | Saving snapshot...\n",
      "2022-08-17 18:08:34 | [trpo_pendulum] epoch #367 | Saved\n",
      "2022-08-17 18:08:34 | [trpo_pendulum] epoch #367 | Time 230.05 s\n",
      "2022-08-17 18:08:34 | [trpo_pendulum] epoch #367 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -464.112\n",
      "Evaluation/AverageReturn              -1061.27\n",
      "Evaluation/Iteration                    367\n",
      "Evaluation/MaxReturn                   -752.408\n",
      "Evaluation/MinReturn                  -1253.09\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    218.681\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.48065\n",
      "GaussianMLPPolicy/KL                      0.00836544\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              14.3997\n",
      "GaussianMLPPolicy/LossBefore             16.955\n",
      "GaussianMLPPolicy/dLoss                   2.55525\n",
      "GaussianMLPValueFunction/LossAfter        6.48679\n",
      "GaussianMLPValueFunction/LossBefore       6.49933\n",
      "GaussianMLPValueFunction/dLoss            0.0125318\n",
      "TotalEnvSteps                        441600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:34 | [trpo_pendulum] epoch #368 | Saving snapshot...\n",
      "2022-08-17 18:08:34 | [trpo_pendulum] epoch #368 | Saved\n",
      "2022-08-17 18:08:34 | [trpo_pendulum] epoch #368 | Time 230.67 s\n",
      "2022-08-17 18:08:34 | [trpo_pendulum] epoch #368 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -410.775\n",
      "Evaluation/AverageReturn               -959.185\n",
      "Evaluation/Iteration                    368\n",
      "Evaluation/MaxReturn                   -640.733\n",
      "Evaluation/MinReturn                  -1091.62\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    145.975\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.48673\n",
      "GaussianMLPPolicy/KL                      0.00639746\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               1.80911\n",
      "GaussianMLPPolicy/LossBefore              2.58686\n",
      "GaussianMLPPolicy/dLoss                   0.777749\n",
      "GaussianMLPValueFunction/LossAfter        6.31302\n",
      "GaussianMLPValueFunction/LossBefore       6.34762\n",
      "GaussianMLPValueFunction/dLoss            0.0346069\n",
      "TotalEnvSteps                        442800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:35 | [trpo_pendulum] epoch #369 | Saving snapshot...\n",
      "2022-08-17 18:08:35 | [trpo_pendulum] epoch #369 | Saved\n",
      "2022-08-17 18:08:35 | [trpo_pendulum] epoch #369 | Time 231.31 s\n",
      "2022-08-17 18:08:35 | [trpo_pendulum] epoch #369 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -381.842\n",
      "Evaluation/AverageReturn               -777.134\n",
      "Evaluation/Iteration                    369\n",
      "Evaluation/MaxReturn                   -358.547\n",
      "Evaluation/MinReturn                  -1004.37\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    292.097\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.47037\n",
      "GaussianMLPPolicy/KL                      0.00955586\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -31.8941\n",
      "GaussianMLPPolicy/LossBefore            -30.3885\n",
      "GaussianMLPPolicy/dLoss                   1.50562\n",
      "GaussianMLPValueFunction/LossAfter        6.5862\n",
      "GaussianMLPValueFunction/LossBefore       6.59338\n",
      "GaussianMLPValueFunction/dLoss            0.00717783\n",
      "TotalEnvSteps                        444000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:36 | [trpo_pendulum] epoch #370 | Saving snapshot...\n",
      "2022-08-17 18:08:36 | [trpo_pendulum] epoch #370 | Saved\n",
      "2022-08-17 18:08:36 | [trpo_pendulum] epoch #370 | Time 231.92 s\n",
      "2022-08-17 18:08:36 | [trpo_pendulum] epoch #370 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -405.292\n",
      "Evaluation/AverageReturn               -911.133\n",
      "Evaluation/Iteration                    370\n",
      "Evaluation/MaxReturn                   -507.129\n",
      "Evaluation/MinReturn                  -1150.45\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    221.95\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.48674\n",
      "GaussianMLPPolicy/KL                      0.00642554\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.86403\n",
      "GaussianMLPPolicy/LossBefore             -2.15846\n",
      "GaussianMLPPolicy/dLoss                   1.70557\n",
      "GaussianMLPValueFunction/LossAfter        6.46318\n",
      "GaussianMLPValueFunction/LossBefore       6.46762\n",
      "GaussianMLPValueFunction/dLoss            0.00444698\n",
      "TotalEnvSteps                        445200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:36 | [trpo_pendulum] epoch #371 | Saving snapshot...\n",
      "2022-08-17 18:08:36 | [trpo_pendulum] epoch #371 | Saved\n",
      "2022-08-17 18:08:36 | [trpo_pendulum] epoch #371 | Time 232.57 s\n",
      "2022-08-17 18:08:36 | [trpo_pendulum] epoch #371 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -651.067\n",
      "Evaluation/AverageReturn              -1500.73\n",
      "Evaluation/Iteration                    371\n",
      "Evaluation/MaxReturn                  -1494.22\n",
      "Evaluation/MinReturn                  -1508.37\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.13812\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.46856\n",
      "GaussianMLPPolicy/KL                      0.00506543\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              80.3982\n",
      "GaussianMLPPolicy/LossBefore             80.7477\n",
      "GaussianMLPPolicy/dLoss                   0.349518\n",
      "GaussianMLPValueFunction/LossAfter        6.90148\n",
      "GaussianMLPValueFunction/LossBefore       6.97468\n",
      "GaussianMLPValueFunction/dLoss            0.0732017\n",
      "TotalEnvSteps                        446400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:37 | [trpo_pendulum] epoch #372 | Saving snapshot...\n",
      "2022-08-17 18:08:37 | [trpo_pendulum] epoch #372 | Saved\n",
      "2022-08-17 18:08:37 | [trpo_pendulum] epoch #372 | Time 233.19 s\n",
      "2022-08-17 18:08:37 | [trpo_pendulum] epoch #372 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -652.179\n",
      "Evaluation/AverageReturn              -1511.73\n",
      "Evaluation/Iteration                    372\n",
      "Evaluation/MaxReturn                  -1497.78\n",
      "Evaluation/MinReturn                  -1532.75\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     10.5175\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.42799\n",
      "GaussianMLPPolicy/KL                      0.00934908\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              81.1588\n",
      "GaussianMLPPolicy/LossBefore             82.1526\n",
      "GaussianMLPPolicy/dLoss                   0.993759\n",
      "GaussianMLPValueFunction/LossAfter        6.89741\n",
      "GaussianMLPValueFunction/LossBefore       6.93736\n",
      "GaussianMLPValueFunction/dLoss            0.0399494\n",
      "TotalEnvSteps                        447600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:38 | [trpo_pendulum] epoch #373 | Saving snapshot...\n",
      "2022-08-17 18:08:38 | [trpo_pendulum] epoch #373 | Saved\n",
      "2022-08-17 18:08:38 | [trpo_pendulum] epoch #373 | Time 233.81 s\n",
      "2022-08-17 18:08:38 | [trpo_pendulum] epoch #373 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -531.24\n",
      "Evaluation/AverageReturn              -1267.24\n",
      "Evaluation/Iteration                    373\n",
      "Evaluation/MaxReturn                  -1198.82\n",
      "Evaluation/MinReturn                  -1323.12\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     42.2234\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.42245\n",
      "GaussianMLPPolicy/KL                      0.00730137\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              49.0585\n",
      "GaussianMLPPolicy/LossBefore             50.4666\n",
      "GaussianMLPPolicy/dLoss                   1.40809\n",
      "GaussianMLPValueFunction/LossAfter        6.58888\n",
      "GaussianMLPValueFunction/LossBefore       6.59336\n",
      "GaussianMLPValueFunction/dLoss            0.00447989\n",
      "TotalEnvSteps                        448800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:38 | [trpo_pendulum] epoch #374 | Saving snapshot...\n",
      "2022-08-17 18:08:38 | [trpo_pendulum] epoch #374 | Saved\n",
      "2022-08-17 18:08:38 | [trpo_pendulum] epoch #374 | Time 234.47 s\n",
      "2022-08-17 18:08:38 | [trpo_pendulum] epoch #374 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -529.893\n",
      "Evaluation/AverageReturn              -1300.68\n",
      "Evaluation/Iteration                    374\n",
      "Evaluation/MaxReturn                  -1273.15\n",
      "Evaluation/MinReturn                  -1317.19\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     17.1654\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.43839\n",
      "GaussianMLPPolicy/KL                      0.006105\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              54.2519\n",
      "GaussianMLPPolicy/LossBefore             55.1166\n",
      "GaussianMLPPolicy/dLoss                   0.864708\n",
      "GaussianMLPValueFunction/LossAfter        6.61866\n",
      "GaussianMLPValueFunction/LossBefore       6.62278\n",
      "GaussianMLPValueFunction/dLoss            0.00411844\n",
      "TotalEnvSteps                        450000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:39 | [trpo_pendulum] epoch #375 | Saving snapshot...\n",
      "2022-08-17 18:08:39 | [trpo_pendulum] epoch #375 | Saved\n",
      "2022-08-17 18:08:39 | [trpo_pendulum] epoch #375 | Time 235.10 s\n",
      "2022-08-17 18:08:39 | [trpo_pendulum] epoch #375 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -647.282\n",
      "Evaluation/AverageReturn              -1499.2\n",
      "Evaluation/Iteration                    375\n",
      "Evaluation/MaxReturn                  -1495.25\n",
      "Evaluation/MinReturn                  -1504.4\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      3.0141\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.48396\n",
      "GaussianMLPPolicy/KL                      0.00884056\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              75.8249\n",
      "GaussianMLPPolicy/LossBefore             78.1905\n",
      "GaussianMLPPolicy/dLoss                   2.36562\n",
      "GaussianMLPValueFunction/LossAfter        6.84692\n",
      "GaussianMLPValueFunction/LossBefore       6.86935\n",
      "GaussianMLPValueFunction/dLoss            0.0224247\n",
      "TotalEnvSteps                        451200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:39 | [trpo_pendulum] epoch #376 | Saving snapshot...\n",
      "2022-08-17 18:08:39 | [trpo_pendulum] epoch #376 | Saved\n",
      "2022-08-17 18:08:39 | [trpo_pendulum] epoch #376 | Time 235.72 s\n",
      "2022-08-17 18:08:39 | [trpo_pendulum] epoch #376 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -290.972\n",
      "Evaluation/AverageReturn               -807.221\n",
      "Evaluation/Iteration                    376\n",
      "Evaluation/MaxReturn                   -386.615\n",
      "Evaluation/MinReturn                  -1178.85\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    310.112\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.47702\n",
      "GaussianMLPPolicy/KL                      0.00650574\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -11.0635\n",
      "GaussianMLPPolicy/LossBefore             -9.58611\n",
      "GaussianMLPPolicy/dLoss                   1.47742\n",
      "GaussianMLPValueFunction/LossAfter        6.5416\n",
      "GaussianMLPValueFunction/LossBefore       6.55046\n",
      "GaussianMLPValueFunction/dLoss            0.00886154\n",
      "TotalEnvSteps                        452400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:40 | [trpo_pendulum] epoch #377 | Saving snapshot...\n",
      "2022-08-17 18:08:40 | [trpo_pendulum] epoch #377 | Saved\n",
      "2022-08-17 18:08:40 | [trpo_pendulum] epoch #377 | Time 236.35 s\n",
      "2022-08-17 18:08:40 | [trpo_pendulum] epoch #377 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -494.018\n",
      "Evaluation/AverageReturn              -1151.33\n",
      "Evaluation/Iteration                    377\n",
      "Evaluation/MaxReturn                  -1131.54\n",
      "Evaluation/MinReturn                  -1163.82\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     10.087\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.46354\n",
      "GaussianMLPPolicy/KL                      0.00881613\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              27.6505\n",
      "GaussianMLPPolicy/LossBefore             28.5716\n",
      "GaussianMLPPolicy/dLoss                   0.921078\n",
      "GaussianMLPValueFunction/LossAfter        6.41027\n",
      "GaussianMLPValueFunction/LossBefore       6.43405\n",
      "GaussianMLPValueFunction/dLoss            0.0237713\n",
      "TotalEnvSteps                        453600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:41 | [trpo_pendulum] epoch #378 | Saving snapshot...\n",
      "2022-08-17 18:08:41 | [trpo_pendulum] epoch #378 | Saved\n",
      "2022-08-17 18:08:41 | [trpo_pendulum] epoch #378 | Time 237.00 s\n",
      "2022-08-17 18:08:41 | [trpo_pendulum] epoch #378 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -464.361\n",
      "Evaluation/AverageReturn              -1098.6\n",
      "Evaluation/Iteration                    378\n",
      "Evaluation/MaxReturn                   -651.253\n",
      "Evaluation/MinReturn                  -1240.92\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    201.769\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.47596\n",
      "GaussianMLPPolicy/KL                      0.0087661\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              22.417\n",
      "GaussianMLPPolicy/LossBefore             24.8257\n",
      "GaussianMLPPolicy/dLoss                   2.4087\n",
      "GaussianMLPValueFunction/LossAfter        6.55127\n",
      "GaussianMLPValueFunction/LossBefore       6.55303\n",
      "GaussianMLPValueFunction/dLoss            0.00176287\n",
      "TotalEnvSteps                        454800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:41 | [trpo_pendulum] epoch #379 | Saving snapshot...\n",
      "2022-08-17 18:08:41 | [trpo_pendulum] epoch #379 | Saved\n",
      "2022-08-17 18:08:41 | [trpo_pendulum] epoch #379 | Time 237.66 s\n",
      "2022-08-17 18:08:41 | [trpo_pendulum] epoch #379 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -548.321\n",
      "Evaluation/AverageReturn              -1307.04\n",
      "Evaluation/Iteration                    379\n",
      "Evaluation/MaxReturn                  -1164.28\n",
      "Evaluation/MinReturn                  -1364.76\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     67.0298\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.48686\n",
      "GaussianMLPPolicy/KL                      0.00858087\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              50.5773\n",
      "GaussianMLPPolicy/LossBefore             52.1196\n",
      "GaussianMLPPolicy/dLoss                   1.54225\n",
      "GaussianMLPValueFunction/LossAfter        6.62736\n",
      "GaussianMLPValueFunction/LossBefore       6.63194\n",
      "GaussianMLPValueFunction/dLoss            0.00457621\n",
      "TotalEnvSteps                        456000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:42 | [trpo_pendulum] epoch #380 | Saving snapshot...\n",
      "2022-08-17 18:08:42 | [trpo_pendulum] epoch #380 | Saved\n",
      "2022-08-17 18:08:42 | [trpo_pendulum] epoch #380 | Time 238.30 s\n",
      "2022-08-17 18:08:42 | [trpo_pendulum] epoch #380 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -655.962\n",
      "Evaluation/AverageReturn              -1502.97\n",
      "Evaluation/Iteration                    380\n",
      "Evaluation/MaxReturn                  -1500.57\n",
      "Evaluation/MinReturn                  -1507.17\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      2.33533\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.47779\n",
      "GaussianMLPPolicy/KL                      0.00581812\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              74.3781\n",
      "GaussianMLPPolicy/LossBefore             75.2197\n",
      "GaussianMLPPolicy/dLoss                   0.84156\n",
      "GaussianMLPValueFunction/LossAfter        6.83164\n",
      "GaussianMLPValueFunction/LossBefore       6.86453\n",
      "GaussianMLPValueFunction/dLoss            0.0328951\n",
      "TotalEnvSteps                        457200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:43 | [trpo_pendulum] epoch #381 | Saving snapshot...\n",
      "2022-08-17 18:08:43 | [trpo_pendulum] epoch #381 | Saved\n",
      "2022-08-17 18:08:43 | [trpo_pendulum] epoch #381 | Time 238.93 s\n",
      "2022-08-17 18:08:43 | [trpo_pendulum] epoch #381 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -512.748\n",
      "Evaluation/AverageReturn              -1176.56\n",
      "Evaluation/Iteration                    381\n",
      "Evaluation/MaxReturn                  -1007.77\n",
      "Evaluation/MinReturn                  -1278.71\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     93.9323\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.47632\n",
      "GaussianMLPPolicy/KL                      0.00998127\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              24.492\n",
      "GaussianMLPPolicy/LossBefore             28.4625\n",
      "GaussianMLPPolicy/dLoss                   3.97047\n",
      "GaussianMLPValueFunction/LossAfter        6.46887\n",
      "GaussianMLPValueFunction/LossBefore       6.48296\n",
      "GaussianMLPValueFunction/dLoss            0.0140929\n",
      "TotalEnvSteps                        458400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:43 | [trpo_pendulum] epoch #382 | Saving snapshot...\n",
      "2022-08-17 18:08:43 | [trpo_pendulum] epoch #382 | Saved\n",
      "2022-08-17 18:08:43 | [trpo_pendulum] epoch #382 | Time 239.56 s\n",
      "2022-08-17 18:08:43 | [trpo_pendulum] epoch #382 | EpochTime 0.62 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -473.683\n",
      "Evaluation/AverageReturn              -1076.95\n",
      "Evaluation/Iteration                    382\n",
      "Evaluation/MaxReturn                   -245.906\n",
      "Evaluation/MinReturn                  -1428.21\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    384.632\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.46453\n",
      "GaussianMLPPolicy/KL                      0.00965521\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              10.3452\n",
      "GaussianMLPPolicy/LossBefore             12.9236\n",
      "GaussianMLPPolicy/dLoss                   2.57842\n",
      "GaussianMLPValueFunction/LossAfter        6.64939\n",
      "GaussianMLPValueFunction/LossBefore       6.64968\n",
      "GaussianMLPValueFunction/dLoss            0.000285625\n",
      "TotalEnvSteps                        459600\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:08:44 | [trpo_pendulum] epoch #383 | Saving snapshot...\n",
      "2022-08-17 18:08:44 | [trpo_pendulum] epoch #383 | Saved\n",
      "2022-08-17 18:08:44 | [trpo_pendulum] epoch #383 | Time 240.20 s\n",
      "2022-08-17 18:08:44 | [trpo_pendulum] epoch #383 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -427.54\n",
      "Evaluation/AverageReturn               -902.777\n",
      "Evaluation/Iteration                    383\n",
      "Evaluation/MaxReturn                   -246.214\n",
      "Evaluation/MinReturn                  -1183.29\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    330.366\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.46485\n",
      "GaussianMLPPolicy/KL                      0.00645402\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -15.5122\n",
      "GaussianMLPPolicy/LossBefore            -13.6552\n",
      "GaussianMLPPolicy/dLoss                   1.85703\n",
      "GaussianMLPValueFunction/LossAfter        6.68279\n",
      "GaussianMLPValueFunction/LossBefore       6.68677\n",
      "GaussianMLPValueFunction/dLoss            0.00397873\n",
      "TotalEnvSteps                        460800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:45 | [trpo_pendulum] epoch #384 | Saving snapshot...\n",
      "2022-08-17 18:08:45 | [trpo_pendulum] epoch #384 | Saved\n",
      "2022-08-17 18:08:45 | [trpo_pendulum] epoch #384 | Time 240.85 s\n",
      "2022-08-17 18:08:45 | [trpo_pendulum] epoch #384 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -660.071\n",
      "Evaluation/AverageReturn              -1508.97\n",
      "Evaluation/Iteration                    384\n",
      "Evaluation/MaxReturn                  -1506.59\n",
      "Evaluation/MinReturn                  -1513.88\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      2.5649\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.47304\n",
      "GaussianMLPPolicy/KL                      0.00634072\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              73.5805\n",
      "GaussianMLPPolicy/LossBefore             74.9321\n",
      "GaussianMLPPolicy/dLoss                   1.3516\n",
      "GaussianMLPValueFunction/LossAfter        6.81741\n",
      "GaussianMLPValueFunction/LossBefore       6.84048\n",
      "GaussianMLPValueFunction/dLoss            0.0230746\n",
      "TotalEnvSteps                        462000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:45 | [trpo_pendulum] epoch #385 | Saving snapshot...\n",
      "2022-08-17 18:08:45 | [trpo_pendulum] epoch #385 | Saved\n",
      "2022-08-17 18:08:45 | [trpo_pendulum] epoch #385 | Time 241.47 s\n",
      "2022-08-17 18:08:45 | [trpo_pendulum] epoch #385 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -528.534\n",
      "Evaluation/AverageReturn              -1278.94\n",
      "Evaluation/Iteration                    385\n",
      "Evaluation/MaxReturn                  -1065.7\n",
      "Evaluation/MinReturn                  -1434.37\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    110.267\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.48905\n",
      "GaussianMLPPolicy/KL                      0.00894895\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              43.0206\n",
      "GaussianMLPPolicy/LossBefore             45.0741\n",
      "GaussianMLPPolicy/dLoss                   2.05355\n",
      "GaussianMLPValueFunction/LossAfter        6.55586\n",
      "GaussianMLPValueFunction/LossBefore       6.56578\n",
      "GaussianMLPValueFunction/dLoss            0.00991201\n",
      "TotalEnvSteps                        463200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:46 | [trpo_pendulum] epoch #386 | Saving snapshot...\n",
      "2022-08-17 18:08:46 | [trpo_pendulum] epoch #386 | Saved\n",
      "2022-08-17 18:08:46 | [trpo_pendulum] epoch #386 | Time 242.11 s\n",
      "2022-08-17 18:08:46 | [trpo_pendulum] epoch #386 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -543.324\n",
      "Evaluation/AverageReturn              -1375.28\n",
      "Evaluation/Iteration                    386\n",
      "Evaluation/MaxReturn                  -1045.25\n",
      "Evaluation/MinReturn                  -1501.14\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    168.09\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.51544\n",
      "GaussianMLPPolicy/KL                      0.00853948\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              61.8462\n",
      "GaussianMLPPolicy/LossBefore             63.4806\n",
      "GaussianMLPPolicy/dLoss                   1.6344\n",
      "GaussianMLPValueFunction/LossAfter        6.73432\n",
      "GaussianMLPValueFunction/LossBefore       6.74301\n",
      "GaussianMLPValueFunction/dLoss            0.00869703\n",
      "TotalEnvSteps                        464400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:46 | [trpo_pendulum] epoch #387 | Saving snapshot...\n",
      "2022-08-17 18:08:46 | [trpo_pendulum] epoch #387 | Saved\n",
      "2022-08-17 18:08:46 | [trpo_pendulum] epoch #387 | Time 242.74 s\n",
      "2022-08-17 18:08:46 | [trpo_pendulum] epoch #387 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -498.359\n",
      "Evaluation/AverageReturn              -1146\n",
      "Evaluation/Iteration                    387\n",
      "Evaluation/MaxReturn                   -121.764\n",
      "Evaluation/MinReturn                  -1391.9\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    459.248\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.5207\n",
      "GaussianMLPPolicy/KL                      0.00653151\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              21.2214\n",
      "GaussianMLPPolicy/LossBefore             22.79\n",
      "GaussianMLPPolicy/dLoss                   1.5686\n",
      "GaussianMLPValueFunction/LossAfter        6.77618\n",
      "GaussianMLPValueFunction/LossBefore       6.78131\n",
      "GaussianMLPValueFunction/dLoss            0.00513268\n",
      "TotalEnvSteps                        465600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:47 | [trpo_pendulum] epoch #388 | Saving snapshot...\n",
      "2022-08-17 18:08:47 | [trpo_pendulum] epoch #388 | Saved\n",
      "2022-08-17 18:08:47 | [trpo_pendulum] epoch #388 | Time 243.37 s\n",
      "2022-08-17 18:08:47 | [trpo_pendulum] epoch #388 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -574.478\n",
      "Evaluation/AverageReturn              -1344.83\n",
      "Evaluation/Iteration                    388\n",
      "Evaluation/MaxReturn                  -1322.41\n",
      "Evaluation/MinReturn                  -1381.05\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     20.6991\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.55528\n",
      "GaussianMLPPolicy/KL                      0.0084868\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              51.2758\n",
      "GaussianMLPPolicy/LossBefore             52.674\n",
      "GaussianMLPPolicy/dLoss                   1.39825\n",
      "GaussianMLPValueFunction/LossAfter        6.64545\n",
      "GaussianMLPValueFunction/LossBefore       6.64989\n",
      "GaussianMLPValueFunction/dLoss            0.00443172\n",
      "TotalEnvSteps                        466800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:48 | [trpo_pendulum] epoch #389 | Saving snapshot...\n",
      "2022-08-17 18:08:48 | [trpo_pendulum] epoch #389 | Saved\n",
      "2022-08-17 18:08:48 | [trpo_pendulum] epoch #389 | Time 244.00 s\n",
      "2022-08-17 18:08:48 | [trpo_pendulum] epoch #389 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -642.693\n",
      "Evaluation/AverageReturn              -1548.29\n",
      "Evaluation/Iteration                    389\n",
      "Evaluation/MaxReturn                  -1531.7\n",
      "Evaluation/MinReturn                  -1592.16\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     21.2398\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.55888\n",
      "GaussianMLPPolicy/KL                      0.00754547\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              84.0909\n",
      "GaussianMLPPolicy/LossBefore             85.6544\n",
      "GaussianMLPPolicy/dLoss                   1.5635\n",
      "GaussianMLPValueFunction/LossAfter        6.94374\n",
      "GaussianMLPValueFunction/LossBefore       6.98656\n",
      "GaussianMLPValueFunction/dLoss            0.0428257\n",
      "TotalEnvSteps                        468000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:48 | [trpo_pendulum] epoch #390 | Saving snapshot...\n",
      "2022-08-17 18:08:48 | [trpo_pendulum] epoch #390 | Saved\n",
      "2022-08-17 18:08:48 | [trpo_pendulum] epoch #390 | Time 244.64 s\n",
      "2022-08-17 18:08:48 | [trpo_pendulum] epoch #390 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -535.714\n",
      "Evaluation/AverageReturn              -1220.97\n",
      "Evaluation/Iteration                    390\n",
      "Evaluation/MaxReturn                   -392.084\n",
      "Evaluation/MinReturn                  -1488.22\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    377.955\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.57573\n",
      "GaussianMLPPolicy/KL                      0.00978412\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              25.209\n",
      "GaussianMLPPolicy/LossBefore             28.6609\n",
      "GaussianMLPPolicy/dLoss                   3.45197\n",
      "GaussianMLPValueFunction/LossAfter        6.72943\n",
      "GaussianMLPValueFunction/LossBefore       6.73028\n",
      "GaussianMLPValueFunction/dLoss            0.00085783\n",
      "TotalEnvSteps                        469200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:49 | [trpo_pendulum] epoch #391 | Saving snapshot...\n",
      "2022-08-17 18:08:49 | [trpo_pendulum] epoch #391 | Saved\n",
      "2022-08-17 18:08:49 | [trpo_pendulum] epoch #391 | Time 245.27 s\n",
      "2022-08-17 18:08:49 | [trpo_pendulum] epoch #391 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -685.727\n",
      "Evaluation/AverageReturn              -1549.14\n",
      "Evaluation/Iteration                    391\n",
      "Evaluation/MaxReturn                  -1502.07\n",
      "Evaluation/MinReturn                  -1588.37\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     30.7945\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.57673\n",
      "GaussianMLPPolicy/KL                      0.00663599\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              72.4653\n",
      "GaussianMLPPolicy/LossBefore             74.6348\n",
      "GaussianMLPPolicy/dLoss                   2.16944\n",
      "GaussianMLPValueFunction/LossAfter        6.8148\n",
      "GaussianMLPValueFunction/LossBefore       6.82132\n",
      "GaussianMLPValueFunction/dLoss            0.00652122\n",
      "TotalEnvSteps                        470400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:50 | [trpo_pendulum] epoch #392 | Saving snapshot...\n",
      "2022-08-17 18:08:50 | [trpo_pendulum] epoch #392 | Saved\n",
      "2022-08-17 18:08:50 | [trpo_pendulum] epoch #392 | Time 245.90 s\n",
      "2022-08-17 18:08:50 | [trpo_pendulum] epoch #392 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -609.59\n",
      "Evaluation/AverageReturn              -1492.92\n",
      "Evaluation/Iteration                    392\n",
      "Evaluation/MaxReturn                  -1482.92\n",
      "Evaluation/MinReturn                  -1505.27\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      7.58263\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.60034\n",
      "GaussianMLPPolicy/KL                      0.00619666\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              73.5795\n",
      "GaussianMLPPolicy/LossBefore             75.5499\n",
      "GaussianMLPPolicy/dLoss                   1.97038\n",
      "GaussianMLPValueFunction/LossAfter        6.84001\n",
      "GaussianMLPValueFunction/LossBefore       6.84751\n",
      "GaussianMLPValueFunction/dLoss            0.00749826\n",
      "TotalEnvSteps                        471600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:50 | [trpo_pendulum] epoch #393 | Saving snapshot...\n",
      "2022-08-17 18:08:50 | [trpo_pendulum] epoch #393 | Saved\n",
      "2022-08-17 18:08:50 | [trpo_pendulum] epoch #393 | Time 246.53 s\n",
      "2022-08-17 18:08:50 | [trpo_pendulum] epoch #393 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -553.659\n",
      "Evaluation/AverageReturn              -1291.84\n",
      "Evaluation/Iteration                    393\n",
      "Evaluation/MaxReturn                  -1215.44\n",
      "Evaluation/MinReturn                  -1351.4\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     39.7439\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.59724\n",
      "GaussianMLPPolicy/KL                      0.00868728\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              40.0993\n",
      "GaussianMLPPolicy/LossBefore             40.7753\n",
      "GaussianMLPPolicy/dLoss                   0.676025\n",
      "GaussianMLPValueFunction/LossAfter        6.55434\n",
      "GaussianMLPValueFunction/LossBefore       6.58122\n",
      "GaussianMLPValueFunction/dLoss            0.0268874\n",
      "TotalEnvSteps                        472800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:51 | [trpo_pendulum] epoch #394 | Saving snapshot...\n",
      "2022-08-17 18:08:51 | [trpo_pendulum] epoch #394 | Saved\n",
      "2022-08-17 18:08:51 | [trpo_pendulum] epoch #394 | Time 247.19 s\n",
      "2022-08-17 18:08:51 | [trpo_pendulum] epoch #394 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn       -3.5977\n",
      "Evaluation/AverageReturn                 -6.57439\n",
      "Evaluation/Iteration                    394\n",
      "Evaluation/MaxReturn                     -5.79532\n",
      "Evaluation/MinReturn                     -7.45557\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      0.608445\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62219\n",
      "GaussianMLPPolicy/KL                      0.00645888\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter            -143.274\n",
      "GaussianMLPPolicy/LossBefore           -141.166\n",
      "GaussianMLPPolicy/dLoss                   2.10825\n",
      "GaussianMLPValueFunction/LossAfter        7.29179\n",
      "GaussianMLPValueFunction/LossBefore       7.44763\n",
      "GaussianMLPValueFunction/dLoss            0.155841\n",
      "TotalEnvSteps                        474000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:52 | [trpo_pendulum] epoch #395 | Saving snapshot...\n",
      "2022-08-17 18:08:52 | [trpo_pendulum] epoch #395 | Saved\n",
      "2022-08-17 18:08:52 | [trpo_pendulum] epoch #395 | Time 247.81 s\n",
      "2022-08-17 18:08:52 | [trpo_pendulum] epoch #395 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -414.922\n",
      "Evaluation/AverageReturn               -981.177\n",
      "Evaluation/Iteration                    395\n",
      "Evaluation/MaxReturn                   -132.88\n",
      "Evaluation/MinReturn                  -1437.25\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    600.016\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.63294\n",
      "GaussianMLPPolicy/KL                      0.00692541\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.35927\n",
      "GaussianMLPPolicy/LossBefore             -1.43207\n",
      "GaussianMLPPolicy/dLoss                   1.9272\n",
      "GaussianMLPValueFunction/LossAfter        6.91734\n",
      "GaussianMLPValueFunction/LossBefore       6.91953\n",
      "GaussianMLPValueFunction/dLoss            0.00219011\n",
      "TotalEnvSteps                        475200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:52 | [trpo_pendulum] epoch #396 | Saving snapshot...\n",
      "2022-08-17 18:08:52 | [trpo_pendulum] epoch #396 | Saved\n",
      "2022-08-17 18:08:52 | [trpo_pendulum] epoch #396 | Time 248.46 s\n",
      "2022-08-17 18:08:52 | [trpo_pendulum] epoch #396 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -430.25\n",
      "Evaluation/AverageReturn               -982.697\n",
      "Evaluation/Iteration                    396\n",
      "Evaluation/MaxReturn                   -257.381\n",
      "Evaluation/MinReturn                  -1184.67\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    328.504\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.61772\n",
      "GaussianMLPPolicy/KL                      0.0064091\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.59801\n",
      "GaussianMLPPolicy/LossBefore             -2.75315\n",
      "GaussianMLPPolicy/dLoss                   1.84486\n",
      "GaussianMLPValueFunction/LossAfter        6.64665\n",
      "GaussianMLPValueFunction/LossBefore       6.66027\n",
      "GaussianMLPValueFunction/dLoss            0.0136247\n",
      "TotalEnvSteps                        476400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:08:53 | [trpo_pendulum] epoch #397 | Saving snapshot...\n",
      "2022-08-17 18:08:53 | [trpo_pendulum] epoch #397 | Saved\n",
      "2022-08-17 18:08:53 | [trpo_pendulum] epoch #397 | Time 249.09 s\n",
      "2022-08-17 18:08:53 | [trpo_pendulum] epoch #397 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -532.46\n",
      "Evaluation/AverageReturn              -1273.31\n",
      "Evaluation/Iteration                    397\n",
      "Evaluation/MaxReturn                  -1077.2\n",
      "Evaluation/MinReturn                  -1461.55\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    142.176\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.60711\n",
      "GaussianMLPPolicy/KL                      0.00779411\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              40.1903\n",
      "GaussianMLPPolicy/LossBefore             42.1551\n",
      "GaussianMLPPolicy/dLoss                   1.96481\n",
      "GaussianMLPValueFunction/LossAfter        6.62508\n",
      "GaussianMLPValueFunction/LossBefore       6.63842\n",
      "GaussianMLPValueFunction/dLoss            0.0133467\n",
      "TotalEnvSteps                        477600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:53 | [trpo_pendulum] epoch #398 | Saving snapshot...\n",
      "2022-08-17 18:08:53 | [trpo_pendulum] epoch #398 | Saved\n",
      "2022-08-17 18:08:53 | [trpo_pendulum] epoch #398 | Time 249.73 s\n",
      "2022-08-17 18:08:53 | [trpo_pendulum] epoch #398 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -487.769\n",
      "Evaluation/AverageReturn              -1085.05\n",
      "Evaluation/Iteration                    398\n",
      "Evaluation/MaxReturn                   -375.602\n",
      "Evaluation/MinReturn                  -1324.37\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    324.902\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.60562\n",
      "GaussianMLPPolicy/KL                      0.00747698\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               5.04066\n",
      "GaussianMLPPolicy/LossBefore              8.18213\n",
      "GaussianMLPPolicy/dLoss                   3.14148\n",
      "GaussianMLPValueFunction/LossAfter        6.64921\n",
      "GaussianMLPValueFunction/LossBefore       6.65592\n",
      "GaussianMLPValueFunction/dLoss            0.00671196\n",
      "TotalEnvSteps                        478800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:54 | [trpo_pendulum] epoch #399 | Saving snapshot...\n",
      "2022-08-17 18:08:54 | [trpo_pendulum] epoch #399 | Saved\n",
      "2022-08-17 18:08:54 | [trpo_pendulum] epoch #399 | Time 250.34 s\n",
      "2022-08-17 18:08:54 | [trpo_pendulum] epoch #399 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -605.276\n",
      "Evaluation/AverageReturn              -1464.89\n",
      "Evaluation/Iteration                    399\n",
      "Evaluation/MaxReturn                  -1419.91\n",
      "Evaluation/MinReturn                  -1479.26\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     21.132\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.57576\n",
      "GaussianMLPPolicy/KL                      0.00689302\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              70.8053\n",
      "GaussianMLPPolicy/LossBefore             71.3679\n",
      "GaussianMLPPolicy/dLoss                   0.562569\n",
      "GaussianMLPValueFunction/LossAfter        6.77448\n",
      "GaussianMLPValueFunction/LossBefore       6.77877\n",
      "GaussianMLPValueFunction/dLoss            0.00428677\n",
      "TotalEnvSteps                        480000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:55 | [trpo_pendulum] epoch #400 | Saving snapshot...\n",
      "2022-08-17 18:08:55 | [trpo_pendulum] epoch #400 | Saved\n",
      "2022-08-17 18:08:55 | [trpo_pendulum] epoch #400 | Time 250.96 s\n",
      "2022-08-17 18:08:55 | [trpo_pendulum] epoch #400 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -666.307\n",
      "Evaluation/AverageReturn              -1516.15\n",
      "Evaluation/Iteration                    400\n",
      "Evaluation/MaxReturn                  -1508.53\n",
      "Evaluation/MinReturn                  -1537.15\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      9.6958\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.58937\n",
      "GaussianMLPPolicy/KL                      0.00692352\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              68.9053\n",
      "GaussianMLPPolicy/LossBefore             70.2241\n",
      "GaussianMLPPolicy/dLoss                   1.31872\n",
      "GaussianMLPValueFunction/LossAfter        6.78379\n",
      "GaussianMLPValueFunction/LossBefore       6.78793\n",
      "GaussianMLPValueFunction/dLoss            0.00414133\n",
      "TotalEnvSteps                        481200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:55 | [trpo_pendulum] epoch #401 | Saving snapshot...\n",
      "2022-08-17 18:08:55 | [trpo_pendulum] epoch #401 | Saved\n",
      "2022-08-17 18:08:55 | [trpo_pendulum] epoch #401 | Time 251.58 s\n",
      "2022-08-17 18:08:55 | [trpo_pendulum] epoch #401 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -668.375\n",
      "Evaluation/AverageReturn              -1517.69\n",
      "Evaluation/Iteration                    401\n",
      "Evaluation/MaxReturn                  -1507.31\n",
      "Evaluation/MinReturn                  -1524.16\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.92516\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.60135\n",
      "GaussianMLPPolicy/KL                      0.00921809\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              67.7892\n",
      "GaussianMLPPolicy/LossBefore             69.207\n",
      "GaussianMLPPolicy/dLoss                   1.41779\n",
      "GaussianMLPValueFunction/LossAfter        6.77231\n",
      "GaussianMLPValueFunction/LossBefore       6.77608\n",
      "GaussianMLPValueFunction/dLoss            0.00377035\n",
      "TotalEnvSteps                        482400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:56 | [trpo_pendulum] epoch #402 | Saving snapshot...\n",
      "2022-08-17 18:08:56 | [trpo_pendulum] epoch #402 | Saved\n",
      "2022-08-17 18:08:56 | [trpo_pendulum] epoch #402 | Time 252.22 s\n",
      "2022-08-17 18:08:56 | [trpo_pendulum] epoch #402 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -543.923\n",
      "Evaluation/AverageReturn              -1319.57\n",
      "Evaluation/Iteration                    402\n",
      "Evaluation/MaxReturn                  -1208.35\n",
      "Evaluation/MinReturn                  -1379.81\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     54.0817\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.59377\n",
      "GaussianMLPPolicy/KL                      0.00625282\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              46.1654\n",
      "GaussianMLPPolicy/LossBefore             47.5956\n",
      "GaussianMLPPolicy/dLoss                   1.4302\n",
      "GaussianMLPValueFunction/LossAfter        6.62301\n",
      "GaussianMLPValueFunction/LossBefore       6.63351\n",
      "GaussianMLPValueFunction/dLoss            0.010498\n",
      "TotalEnvSteps                        483600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:57 | [trpo_pendulum] epoch #403 | Saving snapshot...\n",
      "2022-08-17 18:08:57 | [trpo_pendulum] epoch #403 | Saved\n",
      "2022-08-17 18:08:57 | [trpo_pendulum] epoch #403 | Time 252.86 s\n",
      "2022-08-17 18:08:57 | [trpo_pendulum] epoch #403 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -551.012\n",
      "Evaluation/AverageReturn              -1315.38\n",
      "Evaluation/Iteration                    403\n",
      "Evaluation/MaxReturn                  -1304.16\n",
      "Evaluation/MinReturn                  -1339.18\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     11.7766\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.596\n",
      "GaussianMLPPolicy/KL                      0.00824501\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              43.7716\n",
      "GaussianMLPPolicy/LossBefore             45.1007\n",
      "GaussianMLPPolicy/dLoss                   1.32907\n",
      "GaussianMLPValueFunction/LossAfter        6.5886\n",
      "GaussianMLPValueFunction/LossBefore       6.59949\n",
      "GaussianMLPValueFunction/dLoss            0.0108857\n",
      "TotalEnvSteps                        484800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:57 | [trpo_pendulum] epoch #404 | Saving snapshot...\n",
      "2022-08-17 18:08:57 | [trpo_pendulum] epoch #404 | Saved\n",
      "2022-08-17 18:08:57 | [trpo_pendulum] epoch #404 | Time 253.50 s\n",
      "2022-08-17 18:08:57 | [trpo_pendulum] epoch #404 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -105.836\n",
      "Evaluation/AverageReturn               -220.906\n",
      "Evaluation/Iteration                    404\n",
      "Evaluation/MaxReturn                    -12.1777\n",
      "Evaluation/MinReturn                   -653.614\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    229.398\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.59892\n",
      "GaussianMLPPolicy/KL                      0.00713409\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter            -115.018\n",
      "GaussianMLPPolicy/LossBefore           -113.515\n",
      "GaussianMLPPolicy/dLoss                   1.50299\n",
      "GaussianMLPValueFunction/LossAfter        7.118\n",
      "GaussianMLPValueFunction/LossBefore       7.2165\n",
      "GaussianMLPValueFunction/dLoss            0.0985041\n",
      "TotalEnvSteps                        486000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:58 | [trpo_pendulum] epoch #405 | Saving snapshot...\n",
      "2022-08-17 18:08:58 | [trpo_pendulum] epoch #405 | Saved\n",
      "2022-08-17 18:08:58 | [trpo_pendulum] epoch #405 | Time 254.12 s\n",
      "2022-08-17 18:08:58 | [trpo_pendulum] epoch #405 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -445.316\n",
      "Evaluation/AverageReturn               -997.23\n",
      "Evaluation/Iteration                    405\n",
      "Evaluation/MaxReturn                   -246.726\n",
      "Evaluation/MinReturn                  -1303.23\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    383.808\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.60504\n",
      "GaussianMLPPolicy/KL                      0.00910687\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.71256\n",
      "GaussianMLPPolicy/LossBefore             -3.91738\n",
      "GaussianMLPPolicy/dLoss                   1.79517\n",
      "GaussianMLPValueFunction/LossAfter        6.70219\n",
      "GaussianMLPValueFunction/LossBefore       6.70499\n",
      "GaussianMLPValueFunction/dLoss            0.00280809\n",
      "TotalEnvSteps                        487200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:58 | [trpo_pendulum] epoch #406 | Saving snapshot...\n",
      "2022-08-17 18:08:58 | [trpo_pendulum] epoch #406 | Saved\n",
      "2022-08-17 18:08:58 | [trpo_pendulum] epoch #406 | Time 254.75 s\n",
      "2022-08-17 18:08:58 | [trpo_pendulum] epoch #406 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -644.91\n",
      "Evaluation/AverageReturn              -1492.79\n",
      "Evaluation/Iteration                    406\n",
      "Evaluation/MaxReturn                  -1492.49\n",
      "Evaluation/MinReturn                  -1493.3\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      0.254276\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62284\n",
      "GaussianMLPPolicy/KL                      0.00685256\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              67.9912\n",
      "GaussianMLPPolicy/LossBefore             68.4061\n",
      "GaussianMLPPolicy/dLoss                   0.414841\n",
      "GaussianMLPValueFunction/LossAfter        6.76596\n",
      "GaussianMLPValueFunction/LossBefore       6.76891\n",
      "GaussianMLPValueFunction/dLoss            0.00294352\n",
      "TotalEnvSteps                        488400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:08:59 | [trpo_pendulum] epoch #407 | Saving snapshot...\n",
      "2022-08-17 18:08:59 | [trpo_pendulum] epoch #407 | Saved\n",
      "2022-08-17 18:08:59 | [trpo_pendulum] epoch #407 | Time 255.38 s\n",
      "2022-08-17 18:08:59 | [trpo_pendulum] epoch #407 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -437.993\n",
      "Evaluation/AverageReturn              -1041.54\n",
      "Evaluation/Iteration                    407\n",
      "Evaluation/MaxReturn                   -388.285\n",
      "Evaluation/MinReturn                  -1208.01\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    293.663\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.6169\n",
      "GaussianMLPPolicy/KL                      0.00713102\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               5.61081\n",
      "GaussianMLPPolicy/LossBefore              6.74866\n",
      "GaussianMLPPolicy/dLoss                   1.13785\n",
      "GaussianMLPValueFunction/LossAfter        6.61167\n",
      "GaussianMLPValueFunction/LossBefore       6.62159\n",
      "GaussianMLPValueFunction/dLoss            0.00991964\n",
      "TotalEnvSteps                        489600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:00 | [trpo_pendulum] epoch #408 | Saving snapshot...\n",
      "2022-08-17 18:09:00 | [trpo_pendulum] epoch #408 | Saved\n",
      "2022-08-17 18:09:00 | [trpo_pendulum] epoch #408 | Time 256.02 s\n",
      "2022-08-17 18:09:00 | [trpo_pendulum] epoch #408 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -497.485\n",
      "Evaluation/AverageReturn              -1122.18\n",
      "Evaluation/Iteration                    408\n",
      "Evaluation/MaxReturn                   -735.05\n",
      "Evaluation/MinReturn                  -1226.31\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    174.386\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.63713\n",
      "GaussianMLPPolicy/KL                      0.00977274\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              10.9702\n",
      "GaussianMLPPolicy/LossBefore             14.9724\n",
      "GaussianMLPPolicy/dLoss                   4.00215\n",
      "GaussianMLPValueFunction/LossAfter        6.53262\n",
      "GaussianMLPValueFunction/LossBefore       6.54882\n",
      "GaussianMLPValueFunction/dLoss            0.0161963\n",
      "TotalEnvSteps                        490800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:00 | [trpo_pendulum] epoch #409 | Saving snapshot...\n",
      "2022-08-17 18:09:00 | [trpo_pendulum] epoch #409 | Saved\n",
      "2022-08-17 18:09:00 | [trpo_pendulum] epoch #409 | Time 256.66 s\n",
      "2022-08-17 18:09:00 | [trpo_pendulum] epoch #409 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -635.735\n",
      "Evaluation/AverageReturn              -1490.1\n",
      "Evaluation/Iteration                    409\n",
      "Evaluation/MaxReturn                  -1477.35\n",
      "Evaluation/MinReturn                  -1511.66\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     10.6465\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62932\n",
      "GaussianMLPPolicy/KL                      0.00858756\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              66.5018\n",
      "GaussianMLPPolicy/LossBefore             69.272\n",
      "GaussianMLPPolicy/dLoss                   2.7702\n",
      "GaussianMLPValueFunction/LossAfter        6.78701\n",
      "GaussianMLPValueFunction/LossBefore       6.79533\n",
      "GaussianMLPValueFunction/dLoss            0.00832558\n",
      "TotalEnvSteps                        492000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:01 | [trpo_pendulum] epoch #410 | Saving snapshot...\n",
      "2022-08-17 18:09:01 | [trpo_pendulum] epoch #410 | Saved\n",
      "2022-08-17 18:09:01 | [trpo_pendulum] epoch #410 | Time 257.29 s\n",
      "2022-08-17 18:09:01 | [trpo_pendulum] epoch #410 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -725.65\n",
      "Evaluation/AverageReturn              -1598.61\n",
      "Evaluation/Iteration                    410\n",
      "Evaluation/MaxReturn                  -1572.21\n",
      "Evaluation/MinReturn                  -1634.6\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     21.8391\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.6361\n",
      "GaussianMLPPolicy/KL                      0.00641225\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              73.8283\n",
      "GaussianMLPPolicy/LossBefore             76.2218\n",
      "GaussianMLPPolicy/dLoss                   2.39349\n",
      "GaussianMLPValueFunction/LossAfter        6.85596\n",
      "GaussianMLPValueFunction/LossBefore       6.87025\n",
      "GaussianMLPValueFunction/dLoss            0.0142956\n",
      "TotalEnvSteps                        493200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:02 | [trpo_pendulum] epoch #411 | Saving snapshot...\n",
      "2022-08-17 18:09:02 | [trpo_pendulum] epoch #411 | Saved\n",
      "2022-08-17 18:09:02 | [trpo_pendulum] epoch #411 | Time 257.92 s\n",
      "2022-08-17 18:09:02 | [trpo_pendulum] epoch #411 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -671.441\n",
      "Evaluation/AverageReturn              -1525.82\n",
      "Evaluation/Iteration                    411\n",
      "Evaluation/MaxReturn                  -1506.92\n",
      "Evaluation/MinReturn                  -1583.5\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     26.9622\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.64328\n",
      "GaussianMLPPolicy/KL                      0.00960098\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              67.0858\n",
      "GaussianMLPPolicy/LossBefore             69.0704\n",
      "GaussianMLPPolicy/dLoss                   1.98454\n",
      "GaussianMLPValueFunction/LossAfter        6.78331\n",
      "GaussianMLPValueFunction/LossBefore       6.78764\n",
      "GaussianMLPValueFunction/dLoss            0.00433588\n",
      "TotalEnvSteps                        494400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:02 | [trpo_pendulum] epoch #412 | Saving snapshot...\n",
      "2022-08-17 18:09:02 | [trpo_pendulum] epoch #412 | Saved\n",
      "2022-08-17 18:09:02 | [trpo_pendulum] epoch #412 | Time 258.56 s\n",
      "2022-08-17 18:09:02 | [trpo_pendulum] epoch #412 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn       -4.25761\n",
      "Evaluation/AverageReturn                -10.7578\n",
      "Evaluation/Iteration                    412\n",
      "Evaluation/MaxReturn                     -9.85373\n",
      "Evaluation/MinReturn                    -11.6919\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      0.723986\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.6434\n",
      "GaussianMLPPolicy/KL                      0.00544515\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter            -143.549\n",
      "GaussianMLPPolicy/LossBefore           -142.817\n",
      "GaussianMLPPolicy/dLoss                   0.732269\n",
      "GaussianMLPValueFunction/LossAfter        7.29394\n",
      "GaussianMLPValueFunction/LossBefore       7.43351\n",
      "GaussianMLPValueFunction/dLoss            0.13957\n",
      "TotalEnvSteps                        495600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:03 | [trpo_pendulum] epoch #413 | Saving snapshot...\n",
      "2022-08-17 18:09:03 | [trpo_pendulum] epoch #413 | Saved\n",
      "2022-08-17 18:09:03 | [trpo_pendulum] epoch #413 | Time 259.19 s\n",
      "2022-08-17 18:09:03 | [trpo_pendulum] epoch #413 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -644.296\n",
      "Evaluation/AverageReturn              -1493.41\n",
      "Evaluation/Iteration                    413\n",
      "Evaluation/MaxReturn                  -1489.8\n",
      "Evaluation/MinReturn                  -1502.84\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      4.59435\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.66397\n",
      "GaussianMLPPolicy/KL                      0.00638805\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              65.5341\n",
      "GaussianMLPPolicy/LossBefore             67.6126\n",
      "GaussianMLPPolicy/dLoss                   2.07844\n",
      "GaussianMLPValueFunction/LossAfter        6.77417\n",
      "GaussianMLPValueFunction/LossBefore       6.77787\n",
      "GaussianMLPValueFunction/dLoss            0.00369596\n",
      "TotalEnvSteps                        496800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:04 | [trpo_pendulum] epoch #414 | Saving snapshot...\n",
      "2022-08-17 18:09:04 | [trpo_pendulum] epoch #414 | Saved\n",
      "2022-08-17 18:09:04 | [trpo_pendulum] epoch #414 | Time 259.81 s\n",
      "2022-08-17 18:09:04 | [trpo_pendulum] epoch #414 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -700.874\n",
      "Evaluation/AverageReturn              -1596.26\n",
      "Evaluation/Iteration                    414\n",
      "Evaluation/MaxReturn                  -1544.91\n",
      "Evaluation/MinReturn                  -1678.39\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     46.7144\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.6755\n",
      "GaussianMLPPolicy/KL                      0.007564\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              77.9611\n",
      "GaussianMLPPolicy/LossBefore             80.0964\n",
      "GaussianMLPPolicy/dLoss                   2.13535\n",
      "GaussianMLPValueFunction/LossAfter        6.88725\n",
      "GaussianMLPValueFunction/LossBefore       6.89029\n",
      "GaussianMLPValueFunction/dLoss            0.00304508\n",
      "TotalEnvSteps                        498000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:04 | [trpo_pendulum] epoch #415 | Saving snapshot...\n",
      "2022-08-17 18:09:04 | [trpo_pendulum] epoch #415 | Saved\n",
      "2022-08-17 18:09:04 | [trpo_pendulum] epoch #415 | Time 260.44 s\n",
      "2022-08-17 18:09:04 | [trpo_pendulum] epoch #415 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -685.665\n",
      "Evaluation/AverageReturn              -1582.45\n",
      "Evaluation/Iteration                    415\n",
      "Evaluation/MaxReturn                  -1492.07\n",
      "Evaluation/MinReturn                  -1656.67\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     57.3948\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.65034\n",
      "GaussianMLPPolicy/KL                      0.00966956\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              77.5674\n",
      "GaussianMLPPolicy/LossBefore             79.5629\n",
      "GaussianMLPPolicy/dLoss                   1.99556\n",
      "GaussianMLPValueFunction/LossAfter        6.88896\n",
      "GaussianMLPValueFunction/LossBefore       6.89208\n",
      "GaussianMLPValueFunction/dLoss            0.00311804\n",
      "TotalEnvSteps                        499200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:05 | [trpo_pendulum] epoch #416 | Saving snapshot...\n",
      "2022-08-17 18:09:05 | [trpo_pendulum] epoch #416 | Saved\n",
      "2022-08-17 18:09:05 | [trpo_pendulum] epoch #416 | Time 261.17 s\n",
      "2022-08-17 18:09:05 | [trpo_pendulum] epoch #416 | EpochTime 0.73 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -579.076\n",
      "Evaluation/AverageReturn              -1386.29\n",
      "Evaluation/Iteration                    416\n",
      "Evaluation/MaxReturn                  -1137.16\n",
      "Evaluation/MinReturn                  -1484.74\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    123.034\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.6611\n",
      "GaussianMLPPolicy/KL                      0.00960964\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              50.1584\n",
      "GaussianMLPPolicy/LossBefore             53.7194\n",
      "GaussianMLPPolicy/dLoss                   3.56102\n",
      "GaussianMLPValueFunction/LossAfter        6.69887\n",
      "GaussianMLPValueFunction/LossBefore       6.7101\n",
      "GaussianMLPValueFunction/dLoss            0.0112371\n",
      "TotalEnvSteps                        500400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:06 | [trpo_pendulum] epoch #417 | Saving snapshot...\n",
      "2022-08-17 18:09:06 | [trpo_pendulum] epoch #417 | Saved\n",
      "2022-08-17 18:09:06 | [trpo_pendulum] epoch #417 | Time 261.81 s\n",
      "2022-08-17 18:09:06 | [trpo_pendulum] epoch #417 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -465.133\n",
      "Evaluation/AverageReturn              -1158.87\n",
      "Evaluation/Iteration                    417\n",
      "Evaluation/MaxReturn                   -977.224\n",
      "Evaluation/MinReturn                  -1357.25\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    146.534\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.67274\n",
      "GaussianMLPPolicy/KL                      0.00885976\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              20.4768\n",
      "GaussianMLPPolicy/LossBefore             23.2927\n",
      "GaussianMLPPolicy/dLoss                   2.81591\n",
      "GaussianMLPValueFunction/LossAfter        6.51134\n",
      "GaussianMLPValueFunction/LossBefore       6.54609\n",
      "GaussianMLPValueFunction/dLoss            0.0347505\n",
      "TotalEnvSteps                        501600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:06 | [trpo_pendulum] epoch #418 | Saving snapshot...\n",
      "2022-08-17 18:09:06 | [trpo_pendulum] epoch #418 | Saved\n",
      "2022-08-17 18:09:06 | [trpo_pendulum] epoch #418 | Time 262.44 s\n",
      "2022-08-17 18:09:06 | [trpo_pendulum] epoch #418 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -615.618\n",
      "Evaluation/AverageReturn              -1499.66\n",
      "Evaluation/Iteration                    418\n",
      "Evaluation/MaxReturn                  -1336.49\n",
      "Evaluation/MinReturn                  -1636.66\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     93.1602\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.68838\n",
      "GaussianMLPPolicy/KL                      0.00999695\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              67.9069\n",
      "GaussianMLPPolicy/LossBefore             70.2311\n",
      "GaussianMLPPolicy/dLoss                   2.32426\n",
      "GaussianMLPValueFunction/LossAfter        6.77966\n",
      "GaussianMLPValueFunction/LossBefore       6.78374\n",
      "GaussianMLPValueFunction/dLoss            0.00407505\n",
      "TotalEnvSteps                        502800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:07 | [trpo_pendulum] epoch #419 | Saving snapshot...\n",
      "2022-08-17 18:09:07 | [trpo_pendulum] epoch #419 | Saved\n",
      "2022-08-17 18:09:07 | [trpo_pendulum] epoch #419 | Time 263.09 s\n",
      "2022-08-17 18:09:07 | [trpo_pendulum] epoch #419 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -394.878\n",
      "Evaluation/AverageReturn               -899.376\n",
      "Evaluation/Iteration                    419\n",
      "Evaluation/MaxReturn                   -130.082\n",
      "Evaluation/MinReturn                  -1370.71\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    377.991\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.68892\n",
      "GaussianMLPPolicy/KL                      0.00962906\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -23.0052\n",
      "GaussianMLPPolicy/LossBefore            -20.2891\n",
      "GaussianMLPPolicy/dLoss                   2.71603\n",
      "GaussianMLPValueFunction/LossAfter        6.65323\n",
      "GaussianMLPValueFunction/LossBefore       6.65979\n",
      "GaussianMLPValueFunction/dLoss            0.00655365\n",
      "TotalEnvSteps                        504000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:07 | [trpo_pendulum] epoch #420 | Saving snapshot...\n",
      "2022-08-17 18:09:07 | [trpo_pendulum] epoch #420 | Saved\n",
      "2022-08-17 18:09:07 | [trpo_pendulum] epoch #420 | Time 263.71 s\n",
      "2022-08-17 18:09:07 | [trpo_pendulum] epoch #420 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -320.083\n",
      "Evaluation/AverageReturn               -710.288\n",
      "Evaluation/Iteration                    420\n",
      "Evaluation/MaxReturn                   -133.064\n",
      "Evaluation/MinReturn                  -1012.15\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    330.402\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.71507\n",
      "GaussianMLPPolicy/KL                      0.00737137\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -48.6419\n",
      "GaussianMLPPolicy/LossBefore            -46.0799\n",
      "GaussianMLPPolicy/dLoss                   2.562\n",
      "GaussianMLPValueFunction/LossAfter        6.71153\n",
      "GaussianMLPValueFunction/LossBefore       6.71746\n",
      "GaussianMLPValueFunction/dLoss            0.00593328\n",
      "TotalEnvSteps                        505200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:08 | [trpo_pendulum] epoch #421 | Saving snapshot...\n",
      "2022-08-17 18:09:08 | [trpo_pendulum] epoch #421 | Saved\n",
      "2022-08-17 18:09:08 | [trpo_pendulum] epoch #421 | Time 264.35 s\n",
      "2022-08-17 18:09:08 | [trpo_pendulum] epoch #421 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -716.83\n",
      "Evaluation/AverageReturn              -1604.35\n",
      "Evaluation/Iteration                    421\n",
      "Evaluation/MaxReturn                  -1560.76\n",
      "Evaluation/MinReturn                  -1716.98\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     55.2161\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.68592\n",
      "GaussianMLPPolicy/KL                      0.00905096\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              75.2113\n",
      "GaussianMLPPolicy/LossBefore             76.8545\n",
      "GaussianMLPPolicy/dLoss                   1.64323\n",
      "GaussianMLPValueFunction/LossAfter        6.86047\n",
      "GaussianMLPValueFunction/LossBefore       6.87169\n",
      "GaussianMLPValueFunction/dLoss            0.0112157\n",
      "TotalEnvSteps                        506400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:09 | [trpo_pendulum] epoch #422 | Saving snapshot...\n",
      "2022-08-17 18:09:09 | [trpo_pendulum] epoch #422 | Saved\n",
      "2022-08-17 18:09:09 | [trpo_pendulum] epoch #422 | Time 264.97 s\n",
      "2022-08-17 18:09:09 | [trpo_pendulum] epoch #422 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -507.47\n",
      "Evaluation/AverageReturn              -1175.38\n",
      "Evaluation/Iteration                    422\n",
      "Evaluation/MaxReturn                   -875.778\n",
      "Evaluation/MinReturn                  -1520.95\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    223.742\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.70049\n",
      "GaussianMLPPolicy/KL                      0.00976559\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              17.3074\n",
      "GaussianMLPPolicy/LossBefore             19.9601\n",
      "GaussianMLPPolicy/dLoss                   2.65273\n",
      "GaussianMLPValueFunction/LossAfter        6.55143\n",
      "GaussianMLPValueFunction/LossBefore       6.56971\n",
      "GaussianMLPValueFunction/dLoss            0.0182805\n",
      "TotalEnvSteps                        507600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:09 | [trpo_pendulum] epoch #423 | Saving snapshot...\n",
      "2022-08-17 18:09:09 | [trpo_pendulum] epoch #423 | Saved\n",
      "2022-08-17 18:09:09 | [trpo_pendulum] epoch #423 | Time 265.59 s\n",
      "2022-08-17 18:09:09 | [trpo_pendulum] epoch #423 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -530.145\n",
      "Evaluation/AverageReturn              -1252.55\n",
      "Evaluation/Iteration                    423\n",
      "Evaluation/MaxReturn                  -1105.6\n",
      "Evaluation/MinReturn                  -1498.79\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    128.27\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.70025\n",
      "GaussianMLPPolicy/KL                      0.00704563\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              29.2159\n",
      "GaussianMLPPolicy/LossBefore             32.8671\n",
      "GaussianMLPPolicy/dLoss                   3.65122\n",
      "GaussianMLPValueFunction/LossAfter        6.53838\n",
      "GaussianMLPValueFunction/LossBefore       6.55243\n",
      "GaussianMLPValueFunction/dLoss            0.0140567\n",
      "TotalEnvSteps                        508800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:10 | [trpo_pendulum] epoch #424 | Saving snapshot...\n",
      "2022-08-17 18:09:10 | [trpo_pendulum] epoch #424 | Saved\n",
      "2022-08-17 18:09:10 | [trpo_pendulum] epoch #424 | Time 266.22 s\n",
      "2022-08-17 18:09:10 | [trpo_pendulum] epoch #424 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -656.399\n",
      "Evaluation/AverageReturn              -1505.28\n",
      "Evaluation/Iteration                    424\n",
      "Evaluation/MaxReturn                  -1501.54\n",
      "Evaluation/MinReturn                  -1512.04\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      3.26458\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.72461\n",
      "GaussianMLPPolicy/KL                      0.00695479\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              63.5593\n",
      "GaussianMLPPolicy/LossBefore             65.0263\n",
      "GaussianMLPPolicy/dLoss                   1.46695\n",
      "GaussianMLPValueFunction/LossAfter        6.75326\n",
      "GaussianMLPValueFunction/LossBefore       6.76073\n",
      "GaussianMLPValueFunction/dLoss            0.00746536\n",
      "TotalEnvSteps                        510000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:11 | [trpo_pendulum] epoch #425 | Saving snapshot...\n",
      "2022-08-17 18:09:11 | [trpo_pendulum] epoch #425 | Saved\n",
      "2022-08-17 18:09:11 | [trpo_pendulum] epoch #425 | Time 266.85 s\n",
      "2022-08-17 18:09:11 | [trpo_pendulum] epoch #425 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -375.259\n",
      "Evaluation/AverageReturn               -833.725\n",
      "Evaluation/Iteration                    425\n",
      "Evaluation/MaxReturn                   -312.902\n",
      "Evaluation/MinReturn                  -1050.08\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    270.155\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.71576\n",
      "GaussianMLPPolicy/KL                      0.00992224\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -31.2759\n",
      "GaussianMLPPolicy/LossBefore            -28.5623\n",
      "GaussianMLPPolicy/dLoss                   2.71359\n",
      "GaussianMLPValueFunction/LossAfter        6.67068\n",
      "GaussianMLPValueFunction/LossBefore       6.67462\n",
      "GaussianMLPValueFunction/dLoss            0.00394249\n",
      "TotalEnvSteps                        511200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:11 | [trpo_pendulum] epoch #426 | Saving snapshot...\n",
      "2022-08-17 18:09:11 | [trpo_pendulum] epoch #426 | Saved\n",
      "2022-08-17 18:09:11 | [trpo_pendulum] epoch #426 | Time 267.49 s\n",
      "2022-08-17 18:09:11 | [trpo_pendulum] epoch #426 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -415.431\n",
      "Evaluation/AverageReturn               -837.213\n",
      "Evaluation/Iteration                    426\n",
      "Evaluation/MaxReturn                   -491.494\n",
      "Evaluation/MinReturn                  -1194.34\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    342.864\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.72304\n",
      "GaussianMLPPolicy/KL                      0.00851749\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -37.5628\n",
      "GaussianMLPPolicy/LossBefore            -35.7812\n",
      "GaussianMLPPolicy/dLoss                   1.78167\n",
      "GaussianMLPValueFunction/LossAfter        6.78181\n",
      "GaussianMLPValueFunction/LossBefore       6.79168\n",
      "GaussianMLPValueFunction/dLoss            0.00986767\n",
      "TotalEnvSteps                        512400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:12 | [trpo_pendulum] epoch #427 | Saving snapshot...\n",
      "2022-08-17 18:09:12 | [trpo_pendulum] epoch #427 | Saved\n",
      "2022-08-17 18:09:12 | [trpo_pendulum] epoch #427 | Time 268.12 s\n",
      "2022-08-17 18:09:12 | [trpo_pendulum] epoch #427 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -45.4561\n",
      "Evaluation/AverageReturn               -199.178\n",
      "Evaluation/Iteration                    427\n",
      "Evaluation/MaxReturn                    -16.8905\n",
      "Evaluation/MinReturn                   -391.568\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    142.787\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.71383\n",
      "GaussianMLPPolicy/KL                      0.00844305\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter            -114.365\n",
      "GaussianMLPPolicy/LossBefore           -112.097\n",
      "GaussianMLPPolicy/dLoss                   2.26816\n",
      "GaussianMLPValueFunction/LossAfter        6.98936\n",
      "GaussianMLPValueFunction/LossBefore       7.04607\n",
      "GaussianMLPValueFunction/dLoss            0.0567131\n",
      "TotalEnvSteps                        513600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:12 | [trpo_pendulum] epoch #428 | Saving snapshot...\n",
      "2022-08-17 18:09:12 | [trpo_pendulum] epoch #428 | Saved\n",
      "2022-08-17 18:09:12 | [trpo_pendulum] epoch #428 | Time 268.73 s\n",
      "2022-08-17 18:09:12 | [trpo_pendulum] epoch #428 | EpochTime 0.60 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -417.51\n",
      "Evaluation/AverageReturn               -952.468\n",
      "Evaluation/Iteration                    428\n",
      "Evaluation/MaxReturn                   -255.301\n",
      "Evaluation/MinReturn                  -1308.71\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    490.859\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.73462\n",
      "GaussianMLPPolicy/KL                      0.0071311\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -13.4718\n",
      "GaussianMLPPolicy/LossBefore            -11.869\n",
      "GaussianMLPPolicy/dLoss                   1.6028\n",
      "GaussianMLPValueFunction/LossAfter        6.80122\n",
      "GaussianMLPValueFunction/LossBefore       6.80198\n",
      "GaussianMLPValueFunction/dLoss            0.000762463\n",
      "TotalEnvSteps                        514800\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:09:13 | [trpo_pendulum] epoch #429 | Saving snapshot...\n",
      "2022-08-17 18:09:13 | [trpo_pendulum] epoch #429 | Saved\n",
      "2022-08-17 18:09:13 | [trpo_pendulum] epoch #429 | Time 269.36 s\n",
      "2022-08-17 18:09:13 | [trpo_pendulum] epoch #429 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -470.949\n",
      "Evaluation/AverageReturn              -1118.66\n",
      "Evaluation/Iteration                    429\n",
      "Evaluation/MaxReturn                   -252.749\n",
      "Evaluation/MinReturn                  -1320.74\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    389.656\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.76066\n",
      "GaussianMLPPolicy/KL                      0.00809935\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              12.9345\n",
      "GaussianMLPPolicy/LossBefore             15.6163\n",
      "GaussianMLPPolicy/dLoss                   2.68181\n",
      "GaussianMLPValueFunction/LossAfter        6.69931\n",
      "GaussianMLPValueFunction/LossBefore       6.70359\n",
      "GaussianMLPValueFunction/dLoss            0.00427818\n",
      "TotalEnvSteps                        516000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:14 | [trpo_pendulum] epoch #430 | Saving snapshot...\n",
      "2022-08-17 18:09:14 | [trpo_pendulum] epoch #430 | Saved\n",
      "2022-08-17 18:09:14 | [trpo_pendulum] epoch #430 | Time 270.01 s\n",
      "2022-08-17 18:09:14 | [trpo_pendulum] epoch #430 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -548.257\n",
      "Evaluation/AverageReturn              -1337.18\n",
      "Evaluation/Iteration                    430\n",
      "Evaluation/MaxReturn                  -1285.42\n",
      "Evaluation/MinReturn                  -1358.47\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     23.9937\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.7489\n",
      "GaussianMLPPolicy/KL                      0.00500796\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              50.6845\n",
      "GaussianMLPPolicy/LossBefore             51.2461\n",
      "GaussianMLPPolicy/dLoss                   0.561562\n",
      "GaussianMLPValueFunction/LossAfter        6.63691\n",
      "GaussianMLPValueFunction/LossBefore       6.64684\n",
      "GaussianMLPValueFunction/dLoss            0.0099287\n",
      "TotalEnvSteps                        517200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:14 | [trpo_pendulum] epoch #431 | Saving snapshot...\n",
      "2022-08-17 18:09:14 | [trpo_pendulum] epoch #431 | Saved\n",
      "2022-08-17 18:09:14 | [trpo_pendulum] epoch #431 | Time 270.63 s\n",
      "2022-08-17 18:09:14 | [trpo_pendulum] epoch #431 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -374.363\n",
      "Evaluation/AverageReturn               -830.841\n",
      "Evaluation/Iteration                    431\n",
      "Evaluation/MaxReturn                   -257.072\n",
      "Evaluation/MinReturn                  -1328.59\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    421.161\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.72908\n",
      "GaussianMLPPolicy/KL                      0.00928839\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -31.5864\n",
      "GaussianMLPPolicy/LossBefore            -30.0479\n",
      "GaussianMLPPolicy/dLoss                   1.53849\n",
      "GaussianMLPValueFunction/LossAfter        6.7351\n",
      "GaussianMLPValueFunction/LossBefore       6.73776\n",
      "GaussianMLPValueFunction/dLoss            0.00266123\n",
      "TotalEnvSteps                        518400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:15 | [trpo_pendulum] epoch #432 | Saving snapshot...\n",
      "2022-08-17 18:09:15 | [trpo_pendulum] epoch #432 | Saved\n",
      "2022-08-17 18:09:15 | [trpo_pendulum] epoch #432 | Time 271.27 s\n",
      "2022-08-17 18:09:15 | [trpo_pendulum] epoch #432 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -296.873\n",
      "Evaluation/AverageReturn               -674.768\n",
      "Evaluation/Iteration                    432\n",
      "Evaluation/MaxReturn                   -168.43\n",
      "Evaluation/MinReturn                  -1187.15\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    446.123\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.73718\n",
      "GaussianMLPPolicy/KL                      0.00963448\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -53.3027\n",
      "GaussianMLPPolicy/LossBefore            -50.3802\n",
      "GaussianMLPPolicy/dLoss                   2.92247\n",
      "GaussianMLPValueFunction/LossAfter        6.78498\n",
      "GaussianMLPValueFunction/LossBefore       6.79207\n",
      "GaussianMLPValueFunction/dLoss            0.00709438\n",
      "TotalEnvSteps                        519600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:16 | [trpo_pendulum] epoch #433 | Saving snapshot...\n",
      "2022-08-17 18:09:16 | [trpo_pendulum] epoch #433 | Saved\n",
      "2022-08-17 18:09:16 | [trpo_pendulum] epoch #433 | Time 271.90 s\n",
      "2022-08-17 18:09:16 | [trpo_pendulum] epoch #433 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -77.5441\n",
      "Evaluation/AverageReturn               -308.122\n",
      "Evaluation/Iteration                    433\n",
      "Evaluation/MaxReturn                   -123.147\n",
      "Evaluation/MinReturn                   -805.139\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    240.046\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.73172\n",
      "GaussianMLPPolicy/KL                      0.00816645\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -95.607\n",
      "GaussianMLPPolicy/LossBefore            -92.0752\n",
      "GaussianMLPPolicy/dLoss                   3.53182\n",
      "GaussianMLPValueFunction/LossAfter        6.83937\n",
      "GaussianMLPValueFunction/LossBefore       6.85555\n",
      "GaussianMLPValueFunction/dLoss            0.0161824\n",
      "TotalEnvSteps                        520800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:16 | [trpo_pendulum] epoch #434 | Saving snapshot...\n",
      "2022-08-17 18:09:16 | [trpo_pendulum] epoch #434 | Saved\n",
      "2022-08-17 18:09:16 | [trpo_pendulum] epoch #434 | Time 272.54 s\n",
      "2022-08-17 18:09:16 | [trpo_pendulum] epoch #434 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -343.754\n",
      "Evaluation/AverageReturn               -749.498\n",
      "Evaluation/Iteration                    434\n",
      "Evaluation/MaxReturn                   -257.449\n",
      "Evaluation/MinReturn                  -1169.56\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    322.923\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.74007\n",
      "GaussianMLPPolicy/KL                      0.00674474\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -40.508\n",
      "GaussianMLPPolicy/LossBefore            -37.9392\n",
      "GaussianMLPPolicy/dLoss                   2.56878\n",
      "GaussianMLPValueFunction/LossAfter        6.6882\n",
      "GaussianMLPValueFunction/LossBefore       6.69596\n",
      "GaussianMLPValueFunction/dLoss            0.0077548\n",
      "TotalEnvSteps                        522000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:17 | [trpo_pendulum] epoch #435 | Saving snapshot...\n",
      "2022-08-17 18:09:17 | [trpo_pendulum] epoch #435 | Saved\n",
      "2022-08-17 18:09:17 | [trpo_pendulum] epoch #435 | Time 273.16 s\n",
      "2022-08-17 18:09:17 | [trpo_pendulum] epoch #435 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -368.618\n",
      "Evaluation/AverageReturn               -760.517\n",
      "Evaluation/Iteration                    435\n",
      "Evaluation/MaxReturn                   -489.07\n",
      "Evaluation/MinReturn                  -1160.13\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    280.996\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.74306\n",
      "GaussianMLPPolicy/KL                      0.00933226\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -42.68\n",
      "GaussianMLPPolicy/LossBefore            -40.402\n",
      "GaussianMLPPolicy/dLoss                   2.27801\n",
      "GaussianMLPValueFunction/LossAfter        6.65381\n",
      "GaussianMLPValueFunction/LossBefore       6.66309\n",
      "GaussianMLPValueFunction/dLoss            0.00927925\n",
      "TotalEnvSteps                        523200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:17 | [trpo_pendulum] epoch #436 | Saving snapshot...\n",
      "2022-08-17 18:09:18 | [trpo_pendulum] epoch #436 | Saved\n",
      "2022-08-17 18:09:18 | [trpo_pendulum] epoch #436 | Time 273.79 s\n",
      "2022-08-17 18:09:18 | [trpo_pendulum] epoch #436 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -374.516\n",
      "Evaluation/AverageReturn               -724.716\n",
      "Evaluation/Iteration                    436\n",
      "Evaluation/MaxReturn                   -493.57\n",
      "Evaluation/MinReturn                  -1009.5\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    194.345\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.75269\n",
      "GaussianMLPPolicy/KL                      0.00655764\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -48.2521\n",
      "GaussianMLPPolicy/LossBefore            -45.964\n",
      "GaussianMLPPolicy/dLoss                   2.28807\n",
      "GaussianMLPValueFunction/LossAfter        6.68226\n",
      "GaussianMLPValueFunction/LossBefore       6.689\n",
      "GaussianMLPValueFunction/dLoss            0.00673819\n",
      "TotalEnvSteps                        524400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:18 | [trpo_pendulum] epoch #437 | Saving snapshot...\n",
      "2022-08-17 18:09:18 | [trpo_pendulum] epoch #437 | Saved\n",
      "2022-08-17 18:09:18 | [trpo_pendulum] epoch #437 | Time 274.41 s\n",
      "2022-08-17 18:09:18 | [trpo_pendulum] epoch #437 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -365.388\n",
      "Evaluation/AverageReturn               -648.155\n",
      "Evaluation/Iteration                    437\n",
      "Evaluation/MaxReturn                   -486.174\n",
      "Evaluation/MinReturn                   -963.638\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    163.991\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.73343\n",
      "GaussianMLPPolicy/KL                      0.00680668\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -61.4595\n",
      "GaussianMLPPolicy/LossBefore            -59.6688\n",
      "GaussianMLPPolicy/dLoss                   1.7907\n",
      "GaussianMLPValueFunction/LossAfter        6.77105\n",
      "GaussianMLPValueFunction/LossBefore       6.78248\n",
      "GaussianMLPValueFunction/dLoss            0.0114293\n",
      "TotalEnvSteps                        525600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:19 | [trpo_pendulum] epoch #438 | Saving snapshot...\n",
      "2022-08-17 18:09:19 | [trpo_pendulum] epoch #438 | Saved\n",
      "2022-08-17 18:09:19 | [trpo_pendulum] epoch #438 | Time 275.04 s\n",
      "2022-08-17 18:09:19 | [trpo_pendulum] epoch #438 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -233.241\n",
      "Evaluation/AverageReturn               -523.059\n",
      "Evaluation/Iteration                    438\n",
      "Evaluation/MaxReturn                   -190.553\n",
      "Evaluation/MinReturn                  -1044.09\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    270.946\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.73906\n",
      "GaussianMLPPolicy/KL                      0.00955501\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -69.6703\n",
      "GaussianMLPPolicy/LossBefore            -67.5907\n",
      "GaussianMLPPolicy/dLoss                   2.07957\n",
      "GaussianMLPValueFunction/LossAfter        6.73457\n",
      "GaussianMLPValueFunction/LossBefore       6.74186\n",
      "GaussianMLPValueFunction/dLoss            0.00728655\n",
      "TotalEnvSteps                        526800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:19 | [trpo_pendulum] epoch #439 | Saving snapshot...\n",
      "2022-08-17 18:09:19 | [trpo_pendulum] epoch #439 | Saved\n",
      "2022-08-17 18:09:19 | [trpo_pendulum] epoch #439 | Time 275.66 s\n",
      "2022-08-17 18:09:19 | [trpo_pendulum] epoch #439 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -713.636\n",
      "Evaluation/AverageReturn              -1599.99\n",
      "Evaluation/Iteration                    439\n",
      "Evaluation/MaxReturn                  -1573.13\n",
      "Evaluation/MinReturn                  -1630.97\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     18.3655\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.71819\n",
      "GaussianMLPPolicy/KL                      0.00977652\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              81.7386\n",
      "GaussianMLPPolicy/LossBefore             85.3312\n",
      "GaussianMLPPolicy/dLoss                   3.59254\n",
      "GaussianMLPValueFunction/LossAfter        6.9193\n",
      "GaussianMLPValueFunction/LossBefore       6.94587\n",
      "GaussianMLPValueFunction/dLoss            0.0265698\n",
      "TotalEnvSteps                        528000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:20 | [trpo_pendulum] epoch #440 | Saving snapshot...\n",
      "2022-08-17 18:09:20 | [trpo_pendulum] epoch #440 | Saved\n",
      "2022-08-17 18:09:20 | [trpo_pendulum] epoch #440 | Time 276.28 s\n",
      "2022-08-17 18:09:20 | [trpo_pendulum] epoch #440 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -403.855\n",
      "Evaluation/AverageReturn               -909.453\n",
      "Evaluation/Iteration                    440\n",
      "Evaluation/MaxReturn                   -628.568\n",
      "Evaluation/MinReturn                  -1168.46\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    221.353\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.72179\n",
      "GaussianMLPPolicy/KL                      0.00759877\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -15.168\n",
      "GaussianMLPPolicy/LossBefore            -12.7688\n",
      "GaussianMLPPolicy/dLoss                   2.39928\n",
      "GaussianMLPValueFunction/LossAfter        6.50852\n",
      "GaussianMLPValueFunction/LossBefore       6.54785\n",
      "GaussianMLPValueFunction/dLoss            0.0393295\n",
      "TotalEnvSteps                        529200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:21 | [trpo_pendulum] epoch #441 | Saving snapshot...\n",
      "2022-08-17 18:09:21 | [trpo_pendulum] epoch #441 | Saved\n",
      "2022-08-17 18:09:21 | [trpo_pendulum] epoch #441 | Time 276.91 s\n",
      "2022-08-17 18:09:21 | [trpo_pendulum] epoch #441 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -464.098\n",
      "Evaluation/AverageReturn               -912.073\n",
      "Evaluation/Iteration                    441\n",
      "Evaluation/MaxReturn                   -769.09\n",
      "Evaluation/MinReturn                  -1181.58\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    184.417\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.72079\n",
      "GaussianMLPPolicy/KL                      0.00751759\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -21.1759\n",
      "GaussianMLPPolicy/LossBefore            -18.7722\n",
      "GaussianMLPPolicy/dLoss                   2.40364\n",
      "GaussianMLPValueFunction/LossAfter        6.6104\n",
      "GaussianMLPValueFunction/LossBefore       6.61878\n",
      "GaussianMLPValueFunction/dLoss            0.00837612\n",
      "TotalEnvSteps                        530400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:21 | [trpo_pendulum] epoch #442 | Saving snapshot...\n",
      "2022-08-17 18:09:21 | [trpo_pendulum] epoch #442 | Saved\n",
      "2022-08-17 18:09:21 | [trpo_pendulum] epoch #442 | Time 277.52 s\n",
      "2022-08-17 18:09:21 | [trpo_pendulum] epoch #442 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -409.961\n",
      "Evaluation/AverageReturn               -791.74\n",
      "Evaluation/Iteration                    442\n",
      "Evaluation/MaxReturn                   -494.85\n",
      "Evaluation/MinReturn                  -1186.08\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    277.052\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.69956\n",
      "GaussianMLPPolicy/KL                      0.00646008\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -37.8259\n",
      "GaussianMLPPolicy/LossBefore            -36.1708\n",
      "GaussianMLPPolicy/dLoss                   1.65513\n",
      "GaussianMLPValueFunction/LossAfter        6.67381\n",
      "GaussianMLPValueFunction/LossBefore       6.67866\n",
      "GaussianMLPValueFunction/dLoss            0.00484705\n",
      "TotalEnvSteps                        531600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:22 | [trpo_pendulum] epoch #443 | Saving snapshot...\n",
      "2022-08-17 18:09:22 | [trpo_pendulum] epoch #443 | Saved\n",
      "2022-08-17 18:09:22 | [trpo_pendulum] epoch #443 | Time 278.16 s\n",
      "2022-08-17 18:09:22 | [trpo_pendulum] epoch #443 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -406.81\n",
      "Evaluation/AverageReturn               -813.41\n",
      "Evaluation/Iteration                    443\n",
      "Evaluation/MaxReturn                   -501.193\n",
      "Evaluation/MinReturn                  -1178.45\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    239.763\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.70585\n",
      "GaussianMLPPolicy/KL                      0.00642346\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -31.4164\n",
      "GaussianMLPPolicy/LossBefore            -29.5614\n",
      "GaussianMLPPolicy/dLoss                   1.85494\n",
      "GaussianMLPValueFunction/LossAfter        6.64144\n",
      "GaussianMLPValueFunction/LossBefore       6.64623\n",
      "GaussianMLPValueFunction/dLoss            0.00478315\n",
      "TotalEnvSteps                        532800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:22 | [trpo_pendulum] epoch #444 | Saving snapshot...\n",
      "2022-08-17 18:09:23 | [trpo_pendulum] epoch #444 | Saved\n",
      "2022-08-17 18:09:23 | [trpo_pendulum] epoch #444 | Time 278.79 s\n",
      "2022-08-17 18:09:23 | [trpo_pendulum] epoch #444 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -350.984\n",
      "Evaluation/AverageReturn               -655.208\n",
      "Evaluation/Iteration                    444\n",
      "Evaluation/MaxReturn                   -369.87\n",
      "Evaluation/MinReturn                  -1085.66\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    246.051\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.6816\n",
      "GaussianMLPPolicy/KL                      0.00659733\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -56.1279\n",
      "GaussianMLPPolicy/LossBefore            -54.1026\n",
      "GaussianMLPPolicy/dLoss                   2.02531\n",
      "GaussianMLPValueFunction/LossAfter        6.72977\n",
      "GaussianMLPValueFunction/LossBefore       6.74001\n",
      "GaussianMLPValueFunction/dLoss            0.0102396\n",
      "TotalEnvSteps                        534000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:23 | [trpo_pendulum] epoch #445 | Saving snapshot...\n",
      "2022-08-17 18:09:23 | [trpo_pendulum] epoch #445 | Saved\n",
      "2022-08-17 18:09:23 | [trpo_pendulum] epoch #445 | Time 279.42 s\n",
      "2022-08-17 18:09:23 | [trpo_pendulum] epoch #445 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -311.196\n",
      "Evaluation/AverageReturn               -664.522\n",
      "Evaluation/Iteration                    445\n",
      "Evaluation/MaxReturn                   -256.235\n",
      "Evaluation/MinReturn                  -1059.52\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    296.812\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.6993\n",
      "GaussianMLPPolicy/KL                      0.00903746\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -48.9798\n",
      "GaussianMLPPolicy/LossBefore            -46.4213\n",
      "GaussianMLPPolicy/dLoss                   2.55848\n",
      "GaussianMLPValueFunction/LossAfter        6.60617\n",
      "GaussianMLPValueFunction/LossBefore       6.61542\n",
      "GaussianMLPValueFunction/dLoss            0.00924587\n",
      "TotalEnvSteps                        535200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:24 | [trpo_pendulum] epoch #446 | Saving snapshot...\n",
      "2022-08-17 18:09:24 | [trpo_pendulum] epoch #446 | Saved\n",
      "2022-08-17 18:09:24 | [trpo_pendulum] epoch #446 | Time 280.07 s\n",
      "2022-08-17 18:09:24 | [trpo_pendulum] epoch #446 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -323.233\n",
      "Evaluation/AverageReturn               -649.427\n",
      "Evaluation/Iteration                    446\n",
      "Evaluation/MaxReturn                   -498.095\n",
      "Evaluation/MinReturn                  -1030.26\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    179.183\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.70073\n",
      "GaussianMLPPolicy/KL                      0.00682161\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -51.9647\n",
      "GaussianMLPPolicy/LossBefore            -50.2919\n",
      "GaussianMLPPolicy/dLoss                   1.67279\n",
      "GaussianMLPValueFunction/LossAfter        6.5847\n",
      "GaussianMLPValueFunction/LossBefore       6.59516\n",
      "GaussianMLPValueFunction/dLoss            0.0104651\n",
      "TotalEnvSteps                        536400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:24 | [trpo_pendulum] epoch #447 | Saving snapshot...\n",
      "2022-08-17 18:09:24 | [trpo_pendulum] epoch #447 | Saved\n",
      "2022-08-17 18:09:24 | [trpo_pendulum] epoch #447 | Time 280.71 s\n",
      "2022-08-17 18:09:24 | [trpo_pendulum] epoch #447 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -435.08\n",
      "Evaluation/AverageReturn               -834.719\n",
      "Evaluation/Iteration                    447\n",
      "Evaluation/MaxReturn                   -632.167\n",
      "Evaluation/MinReturn                  -1128.81\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    183.179\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.72979\n",
      "GaussianMLPPolicy/KL                      0.00966962\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -29.7144\n",
      "GaussianMLPPolicy/LossBefore            -27.293\n",
      "GaussianMLPPolicy/dLoss                   2.42142\n",
      "GaussianMLPValueFunction/LossAfter        6.53709\n",
      "GaussianMLPValueFunction/LossBefore       6.54671\n",
      "GaussianMLPValueFunction/dLoss            0.0096159\n",
      "TotalEnvSteps                        537600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:25 | [trpo_pendulum] epoch #448 | Saving snapshot...\n",
      "2022-08-17 18:09:25 | [trpo_pendulum] epoch #448 | Saved\n",
      "2022-08-17 18:09:25 | [trpo_pendulum] epoch #448 | Time 281.34 s\n",
      "2022-08-17 18:09:25 | [trpo_pendulum] epoch #448 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -89.761\n",
      "Evaluation/AverageReturn               -310.214\n",
      "Evaluation/Iteration                    448\n",
      "Evaluation/MaxReturn                   -240.869\n",
      "Evaluation/MinReturn                   -464.452\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     83.6616\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.73454\n",
      "GaussianMLPPolicy/KL                      0.00759967\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -84.8462\n",
      "GaussianMLPPolicy/LossBefore            -82.7783\n",
      "GaussianMLPPolicy/dLoss                   2.06796\n",
      "GaussianMLPValueFunction/LossAfter        6.69012\n",
      "GaussianMLPValueFunction/LossBefore       6.70943\n",
      "GaussianMLPValueFunction/dLoss            0.0193148\n",
      "TotalEnvSteps                        538800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:26 | [trpo_pendulum] epoch #449 | Saving snapshot...\n",
      "2022-08-17 18:09:26 | [trpo_pendulum] epoch #449 | Saved\n",
      "2022-08-17 18:09:26 | [trpo_pendulum] epoch #449 | Time 281.99 s\n",
      "2022-08-17 18:09:26 | [trpo_pendulum] epoch #449 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -233.947\n",
      "Evaluation/AverageReturn               -554.003\n",
      "Evaluation/Iteration                    449\n",
      "Evaluation/MaxReturn                   -257.467\n",
      "Evaluation/MinReturn                   -781.595\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    192.016\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.74597\n",
      "GaussianMLPPolicy/KL                      0.00889044\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -56.1931\n",
      "GaussianMLPPolicy/LossBefore            -54.254\n",
      "GaussianMLPPolicy/dLoss                   1.93912\n",
      "GaussianMLPValueFunction/LossAfter        6.53751\n",
      "GaussianMLPValueFunction/LossBefore       6.54947\n",
      "GaussianMLPValueFunction/dLoss            0.0119615\n",
      "TotalEnvSteps                        540000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:26 | [trpo_pendulum] epoch #450 | Saving snapshot...\n",
      "2022-08-17 18:09:26 | [trpo_pendulum] epoch #450 | Saved\n",
      "2022-08-17 18:09:26 | [trpo_pendulum] epoch #450 | Time 282.61 s\n",
      "2022-08-17 18:09:26 | [trpo_pendulum] epoch #450 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -110.133\n",
      "Evaluation/AverageReturn               -295.729\n",
      "Evaluation/Iteration                    450\n",
      "Evaluation/MaxReturn                   -138.284\n",
      "Evaluation/MinReturn                   -610.255\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    147.359\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.75449\n",
      "GaussianMLPPolicy/KL                      0.00707331\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -87.9055\n",
      "GaussianMLPPolicy/LossBefore            -86.1108\n",
      "GaussianMLPPolicy/dLoss                   1.79475\n",
      "GaussianMLPValueFunction/LossAfter        6.78281\n",
      "GaussianMLPValueFunction/LossBefore       6.81748\n",
      "GaussianMLPValueFunction/dLoss            0.0346732\n",
      "TotalEnvSteps                        541200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:27 | [trpo_pendulum] epoch #451 | Saving snapshot...\n",
      "2022-08-17 18:09:27 | [trpo_pendulum] epoch #451 | Saved\n",
      "2022-08-17 18:09:27 | [trpo_pendulum] epoch #451 | Time 283.25 s\n",
      "2022-08-17 18:09:27 | [trpo_pendulum] epoch #451 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -540.375\n",
      "Evaluation/AverageReturn              -1151.82\n",
      "Evaluation/Iteration                    451\n",
      "Evaluation/MaxReturn                  -1002.24\n",
      "Evaluation/MinReturn                  -1308.65\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     89.9767\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.77207\n",
      "GaussianMLPPolicy/KL                      0.00652619\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              23.1478\n",
      "GaussianMLPPolicy/LossBefore             26.8016\n",
      "GaussianMLPPolicy/dLoss                   3.65382\n",
      "GaussianMLPValueFunction/LossAfter        6.54142\n",
      "GaussianMLPValueFunction/LossBefore       6.54962\n",
      "GaussianMLPValueFunction/dLoss            0.00819254\n",
      "TotalEnvSteps                        542400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:28 | [trpo_pendulum] epoch #452 | Saving snapshot...\n",
      "2022-08-17 18:09:28 | [trpo_pendulum] epoch #452 | Saved\n",
      "2022-08-17 18:09:28 | [trpo_pendulum] epoch #452 | Time 283.91 s\n",
      "2022-08-17 18:09:28 | [trpo_pendulum] epoch #452 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -201.665\n",
      "Evaluation/AverageReturn               -368.64\n",
      "Evaluation/Iteration                    452\n",
      "Evaluation/MaxReturn                   -257.733\n",
      "Evaluation/MinReturn                   -618.669\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    122.519\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.75914\n",
      "GaussianMLPPolicy/KL                      0.00657107\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -86.673\n",
      "GaussianMLPPolicy/LossBefore            -85.3407\n",
      "GaussianMLPPolicy/dLoss                   1.33228\n",
      "GaussianMLPValueFunction/LossAfter        6.82036\n",
      "GaussianMLPValueFunction/LossBefore       6.85442\n",
      "GaussianMLPValueFunction/dLoss            0.0340652\n",
      "TotalEnvSteps                        543600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:28 | [trpo_pendulum] epoch #453 | Saving snapshot...\n",
      "2022-08-17 18:09:28 | [trpo_pendulum] epoch #453 | Saved\n",
      "2022-08-17 18:09:28 | [trpo_pendulum] epoch #453 | Time 284.57 s\n",
      "2022-08-17 18:09:28 | [trpo_pendulum] epoch #453 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -347.396\n",
      "Evaluation/AverageReturn               -632.884\n",
      "Evaluation/Iteration                    453\n",
      "Evaluation/MaxReturn                   -378.104\n",
      "Evaluation/MinReturn                   -857.268\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    187.066\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.73463\n",
      "GaussianMLPPolicy/KL                      0.00694446\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -52.7893\n",
      "GaussianMLPPolicy/LossBefore            -51.0619\n",
      "GaussianMLPPolicy/dLoss                   1.72739\n",
      "GaussianMLPValueFunction/LossAfter        6.65384\n",
      "GaussianMLPValueFunction/LossBefore       6.65992\n",
      "GaussianMLPValueFunction/dLoss            0.00607872\n",
      "TotalEnvSteps                        544800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:29 | [trpo_pendulum] epoch #454 | Saving snapshot...\n",
      "2022-08-17 18:09:29 | [trpo_pendulum] epoch #454 | Saved\n",
      "2022-08-17 18:09:29 | [trpo_pendulum] epoch #454 | Time 285.20 s\n",
      "2022-08-17 18:09:29 | [trpo_pendulum] epoch #454 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -79.7937\n",
      "Evaluation/AverageReturn               -301.352\n",
      "Evaluation/Iteration                    454\n",
      "Evaluation/MaxReturn                   -133.994\n",
      "Evaluation/MinReturn                   -503.724\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    116.134\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.75051\n",
      "GaussianMLPPolicy/KL                      0.00645083\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -81.3539\n",
      "GaussianMLPPolicy/LossBefore            -79.1821\n",
      "GaussianMLPPolicy/dLoss                   2.17174\n",
      "GaussianMLPValueFunction/LossAfter        6.67046\n",
      "GaussianMLPValueFunction/LossBefore       6.67866\n",
      "GaussianMLPValueFunction/dLoss            0.00819921\n",
      "TotalEnvSteps                        546000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:30 | [trpo_pendulum] epoch #455 | Saving snapshot...\n",
      "2022-08-17 18:09:30 | [trpo_pendulum] epoch #455 | Saved\n",
      "2022-08-17 18:09:30 | [trpo_pendulum] epoch #455 | Time 285.85 s\n",
      "2022-08-17 18:09:30 | [trpo_pendulum] epoch #455 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -648.217\n",
      "Evaluation/AverageReturn              -1496.98\n",
      "Evaluation/Iteration                    455\n",
      "Evaluation/MaxReturn                  -1494.78\n",
      "Evaluation/MinReturn                  -1498.65\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      1.33563\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.73858\n",
      "GaussianMLPPolicy/KL                      0.00638971\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              82.5172\n",
      "GaussianMLPPolicy/LossBefore             82.5884\n",
      "GaussianMLPPolicy/dLoss                   0.0712357\n",
      "GaussianMLPValueFunction/LossAfter        6.86254\n",
      "GaussianMLPValueFunction/LossBefore       6.88696\n",
      "GaussianMLPValueFunction/dLoss            0.0244198\n",
      "TotalEnvSteps                        547200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:30 | [trpo_pendulum] epoch #456 | Saving snapshot...\n",
      "2022-08-17 18:09:30 | [trpo_pendulum] epoch #456 | Saved\n",
      "2022-08-17 18:09:30 | [trpo_pendulum] epoch #456 | Time 286.46 s\n",
      "2022-08-17 18:09:30 | [trpo_pendulum] epoch #456 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -187.049\n",
      "Evaluation/AverageReturn               -701.815\n",
      "Evaluation/Iteration                    456\n",
      "Evaluation/MaxReturn                   -503.929\n",
      "Evaluation/MinReturn                  -1097.54\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    198.132\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.72818\n",
      "GaussianMLPPolicy/KL                      0.00645872\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -16.1741\n",
      "GaussianMLPPolicy/LossBefore            -14.1362\n",
      "GaussianMLPPolicy/dLoss                   2.03794\n",
      "GaussianMLPValueFunction/LossAfter        6.35151\n",
      "GaussianMLPValueFunction/LossBefore       6.4099\n",
      "GaussianMLPValueFunction/dLoss            0.0583916\n",
      "TotalEnvSteps                        548400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:31 | [trpo_pendulum] epoch #457 | Saving snapshot...\n",
      "2022-08-17 18:09:31 | [trpo_pendulum] epoch #457 | Saved\n",
      "2022-08-17 18:09:31 | [trpo_pendulum] epoch #457 | Time 287.11 s\n",
      "2022-08-17 18:09:31 | [trpo_pendulum] epoch #457 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -658.501\n",
      "Evaluation/AverageReturn              -1506.25\n",
      "Evaluation/Iteration                    457\n",
      "Evaluation/MaxReturn                  -1500.9\n",
      "Evaluation/MinReturn                  -1509.71\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      2.99363\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.71115\n",
      "GaussianMLPPolicy/KL                      0.0077042\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              80.142\n",
      "GaussianMLPPolicy/LossBefore             82.3214\n",
      "GaussianMLPPolicy/dLoss                   2.17942\n",
      "GaussianMLPValueFunction/LossAfter        6.87972\n",
      "GaussianMLPValueFunction/LossBefore       6.90792\n",
      "GaussianMLPValueFunction/dLoss            0.028203\n",
      "TotalEnvSteps                        549600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:09:31 | [trpo_pendulum] epoch #458 | Saving snapshot...\n",
      "2022-08-17 18:09:31 | [trpo_pendulum] epoch #458 | Saved\n",
      "2022-08-17 18:09:31 | [trpo_pendulum] epoch #458 | Time 287.77 s\n",
      "2022-08-17 18:09:31 | [trpo_pendulum] epoch #458 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -298.265\n",
      "Evaluation/AverageReturn               -602.179\n",
      "Evaluation/Iteration                    458\n",
      "Evaluation/MaxReturn                   -280.831\n",
      "Evaluation/MinReturn                   -888.476\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    225.546\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.713\n",
      "GaussianMLPPolicy/KL                      0.00935194\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -52.7973\n",
      "GaussianMLPPolicy/LossBefore            -50.3199\n",
      "GaussianMLPPolicy/dLoss                   2.47743\n",
      "GaussianMLPValueFunction/LossAfter        6.61401\n",
      "GaussianMLPValueFunction/LossBefore       6.62123\n",
      "GaussianMLPValueFunction/dLoss            0.00722075\n",
      "TotalEnvSteps                        550800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:32 | [trpo_pendulum] epoch #459 | Saving snapshot...\n",
      "2022-08-17 18:09:32 | [trpo_pendulum] epoch #459 | Saved\n",
      "2022-08-17 18:09:32 | [trpo_pendulum] epoch #459 | Time 288.39 s\n",
      "2022-08-17 18:09:32 | [trpo_pendulum] epoch #459 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -591.261\n",
      "Evaluation/AverageReturn              -1281.38\n",
      "Evaluation/Iteration                    459\n",
      "Evaluation/MaxReturn                   -899.936\n",
      "Evaluation/MinReturn                  -1514.95\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    190.746\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.71703\n",
      "GaussianMLPPolicy/KL                      0.00992172\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              44.2025\n",
      "GaussianMLPPolicy/LossBefore             47.6281\n",
      "GaussianMLPPolicy/dLoss                   3.4256\n",
      "GaussianMLPValueFunction/LossAfter        6.69263\n",
      "GaussianMLPValueFunction/LossBefore       6.69363\n",
      "GaussianMLPValueFunction/dLoss            0.00100136\n",
      "TotalEnvSteps                        552000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:33 | [trpo_pendulum] epoch #460 | Saving snapshot...\n",
      "2022-08-17 18:09:33 | [trpo_pendulum] epoch #460 | Saved\n",
      "2022-08-17 18:09:33 | [trpo_pendulum] epoch #460 | Time 289.03 s\n",
      "2022-08-17 18:09:33 | [trpo_pendulum] epoch #460 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -490.754\n",
      "Evaluation/AverageReturn              -1015.16\n",
      "Evaluation/Iteration                    460\n",
      "Evaluation/MaxReturn                   -747.561\n",
      "Evaluation/MinReturn                  -1223.53\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    145.989\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.7152\n",
      "GaussianMLPPolicy/KL                      0.00658165\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               5.89055\n",
      "GaussianMLPPolicy/LossBefore              8.63009\n",
      "GaussianMLPPolicy/dLoss                   2.73954\n",
      "GaussianMLPValueFunction/LossAfter        6.5476\n",
      "GaussianMLPValueFunction/LossBefore       6.55579\n",
      "GaussianMLPValueFunction/dLoss            0.0081811\n",
      "TotalEnvSteps                        553200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:33 | [trpo_pendulum] epoch #461 | Saving snapshot...\n",
      "2022-08-17 18:09:33 | [trpo_pendulum] epoch #461 | Saved\n",
      "2022-08-17 18:09:33 | [trpo_pendulum] epoch #461 | Time 289.66 s\n",
      "2022-08-17 18:09:33 | [trpo_pendulum] epoch #461 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -450.878\n",
      "Evaluation/AverageReturn               -854.082\n",
      "Evaluation/Iteration                    461\n",
      "Evaluation/MaxReturn                   -637.289\n",
      "Evaluation/MinReturn                  -1016.78\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    147.27\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.72476\n",
      "GaussianMLPPolicy/KL                      0.00987694\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -21.3765\n",
      "GaussianMLPPolicy/LossBefore            -18.8601\n",
      "GaussianMLPPolicy/dLoss                   2.51643\n",
      "GaussianMLPValueFunction/LossAfter        6.56349\n",
      "GaussianMLPValueFunction/LossBefore       6.56979\n",
      "GaussianMLPValueFunction/dLoss            0.00630236\n",
      "TotalEnvSteps                        554400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:34 | [trpo_pendulum] epoch #462 | Saving snapshot...\n",
      "2022-08-17 18:09:34 | [trpo_pendulum] epoch #462 | Saved\n",
      "2022-08-17 18:09:34 | [trpo_pendulum] epoch #462 | Time 290.28 s\n",
      "2022-08-17 18:09:34 | [trpo_pendulum] epoch #462 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -373.941\n",
      "Evaluation/AverageReturn               -720.36\n",
      "Evaluation/Iteration                    462\n",
      "Evaluation/MaxReturn                   -609.588\n",
      "Evaluation/MinReturn                   -871.674\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    114.12\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.73916\n",
      "GaussianMLPPolicy/KL                      0.00962298\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -38.0065\n",
      "GaussianMLPPolicy/LossBefore            -35.7805\n",
      "GaussianMLPPolicy/dLoss                   2.22602\n",
      "GaussianMLPValueFunction/LossAfter        6.51604\n",
      "GaussianMLPValueFunction/LossBefore       6.52722\n",
      "GaussianMLPValueFunction/dLoss            0.0111742\n",
      "TotalEnvSteps                        555600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:35 | [trpo_pendulum] epoch #463 | Saving snapshot...\n",
      "2022-08-17 18:09:35 | [trpo_pendulum] epoch #463 | Saved\n",
      "2022-08-17 18:09:35 | [trpo_pendulum] epoch #463 | Time 290.91 s\n",
      "2022-08-17 18:09:35 | [trpo_pendulum] epoch #463 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -356.927\n",
      "Evaluation/AverageReturn               -685.161\n",
      "Evaluation/Iteration                    463\n",
      "Evaluation/MaxReturn                   -372.048\n",
      "Evaluation/MinReturn                  -1100.86\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    246.575\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.74777\n",
      "GaussianMLPPolicy/KL                      0.00940958\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -43.2236\n",
      "GaussianMLPPolicy/LossBefore            -40.4977\n",
      "GaussianMLPPolicy/dLoss                   2.72593\n",
      "GaussianMLPValueFunction/LossAfter        6.58667\n",
      "GaussianMLPValueFunction/LossBefore       6.59353\n",
      "GaussianMLPValueFunction/dLoss            0.00686264\n",
      "TotalEnvSteps                        556800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:35 | [trpo_pendulum] epoch #464 | Saving snapshot...\n",
      "2022-08-17 18:09:35 | [trpo_pendulum] epoch #464 | Saved\n",
      "2022-08-17 18:09:35 | [trpo_pendulum] epoch #464 | Time 291.52 s\n",
      "2022-08-17 18:09:35 | [trpo_pendulum] epoch #464 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -495.949\n",
      "Evaluation/AverageReturn              -1008.05\n",
      "Evaluation/Iteration                    464\n",
      "Evaluation/MaxReturn                   -642.095\n",
      "Evaluation/MinReturn                  -1303.2\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    227.808\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.75414\n",
      "GaussianMLPPolicy/KL                      0.00669909\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               5.31913\n",
      "GaussianMLPPolicy/LossBefore              7.78237\n",
      "GaussianMLPPolicy/dLoss                   2.46324\n",
      "GaussianMLPValueFunction/LossAfter        6.55223\n",
      "GaussianMLPValueFunction/LossBefore       6.55349\n",
      "GaussianMLPValueFunction/dLoss            0.00125885\n",
      "TotalEnvSteps                        558000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:36 | [trpo_pendulum] epoch #465 | Saving snapshot...\n",
      "2022-08-17 18:09:36 | [trpo_pendulum] epoch #465 | Saved\n",
      "2022-08-17 18:09:36 | [trpo_pendulum] epoch #465 | Time 292.16 s\n",
      "2022-08-17 18:09:36 | [trpo_pendulum] epoch #465 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -318.574\n",
      "Evaluation/AverageReturn               -691.34\n",
      "Evaluation/Iteration                    465\n",
      "Evaluation/MaxReturn                   -258.629\n",
      "Evaluation/MinReturn                  -1049.43\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    257.086\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.74318\n",
      "GaussianMLPPolicy/KL                      0.00727348\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -32.4077\n",
      "GaussianMLPPolicy/LossBefore            -30.7128\n",
      "GaussianMLPPolicy/dLoss                   1.69495\n",
      "GaussianMLPValueFunction/LossAfter        6.51183\n",
      "GaussianMLPValueFunction/LossBefore       6.51915\n",
      "GaussianMLPValueFunction/dLoss            0.00731993\n",
      "TotalEnvSteps                        559200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:36 | [trpo_pendulum] epoch #466 | Saving snapshot...\n",
      "2022-08-17 18:09:37 | [trpo_pendulum] epoch #466 | Saved\n",
      "2022-08-17 18:09:37 | [trpo_pendulum] epoch #466 | Time 292.78 s\n",
      "2022-08-17 18:09:37 | [trpo_pendulum] epoch #466 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -333.319\n",
      "Evaluation/AverageReturn               -724.134\n",
      "Evaluation/Iteration                    466\n",
      "Evaluation/MaxReturn                   -383.686\n",
      "Evaluation/MinReturn                  -1098.61\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    261.498\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.72389\n",
      "GaussianMLPPolicy/KL                      0.00678894\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -29.6012\n",
      "GaussianMLPPolicy/LossBefore            -27.8368\n",
      "GaussianMLPPolicy/dLoss                   1.76436\n",
      "GaussianMLPValueFunction/LossAfter        6.45702\n",
      "GaussianMLPValueFunction/LossBefore       6.4669\n",
      "GaussianMLPValueFunction/dLoss            0.00987101\n",
      "TotalEnvSteps                        560400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:37 | [trpo_pendulum] epoch #467 | Saving snapshot...\n",
      "2022-08-17 18:09:37 | [trpo_pendulum] epoch #467 | Saved\n",
      "2022-08-17 18:09:37 | [trpo_pendulum] epoch #467 | Time 293.41 s\n",
      "2022-08-17 18:09:37 | [trpo_pendulum] epoch #467 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -320.148\n",
      "Evaluation/AverageReturn               -676.676\n",
      "Evaluation/Iteration                    467\n",
      "Evaluation/MaxReturn                   -258.931\n",
      "Evaluation/MinReturn                  -1062.52\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    311.178\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.71762\n",
      "GaussianMLPPolicy/KL                      0.00684214\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -36.4561\n",
      "GaussianMLPPolicy/LossBefore            -34.8215\n",
      "GaussianMLPPolicy/dLoss                   1.63459\n",
      "GaussianMLPValueFunction/LossAfter        6.56446\n",
      "GaussianMLPValueFunction/LossBefore       6.57183\n",
      "GaussianMLPValueFunction/dLoss            0.00736809\n",
      "TotalEnvSteps                        561600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:38 | [trpo_pendulum] epoch #468 | Saving snapshot...\n",
      "2022-08-17 18:09:38 | [trpo_pendulum] epoch #468 | Saved\n",
      "2022-08-17 18:09:38 | [trpo_pendulum] epoch #468 | Time 294.03 s\n",
      "2022-08-17 18:09:38 | [trpo_pendulum] epoch #468 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -396.143\n",
      "Evaluation/AverageReturn               -726.39\n",
      "Evaluation/Iteration                    468\n",
      "Evaluation/MaxReturn                   -498.572\n",
      "Evaluation/MinReturn                   -878.544\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    151.324\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.72231\n",
      "GaussianMLPPolicy/KL                      0.00642281\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -34.9346\n",
      "GaussianMLPPolicy/LossBefore            -32.4196\n",
      "GaussianMLPPolicy/dLoss                   2.51495\n",
      "GaussianMLPValueFunction/LossAfter        6.5853\n",
      "GaussianMLPValueFunction/LossBefore       6.59395\n",
      "GaussianMLPValueFunction/dLoss            0.0086565\n",
      "TotalEnvSteps                        562800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:38 | [trpo_pendulum] epoch #469 | Saving snapshot...\n",
      "2022-08-17 18:09:38 | [trpo_pendulum] epoch #469 | Saved\n",
      "2022-08-17 18:09:38 | [trpo_pendulum] epoch #469 | Time 294.67 s\n",
      "2022-08-17 18:09:38 | [trpo_pendulum] epoch #469 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -276.704\n",
      "Evaluation/AverageReturn               -670.836\n",
      "Evaluation/Iteration                    469\n",
      "Evaluation/MaxReturn                   -264.458\n",
      "Evaluation/MinReturn                   -935.225\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    231.424\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.72226\n",
      "GaussianMLPPolicy/KL                      0.00576352\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -26.1023\n",
      "GaussianMLPPolicy/LossBefore            -24.7761\n",
      "GaussianMLPPolicy/dLoss                   1.32623\n",
      "GaussianMLPValueFunction/LossAfter        6.46105\n",
      "GaussianMLPValueFunction/LossBefore       6.46989\n",
      "GaussianMLPValueFunction/dLoss            0.00883865\n",
      "TotalEnvSteps                        564000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:39 | [trpo_pendulum] epoch #470 | Saving snapshot...\n",
      "2022-08-17 18:09:39 | [trpo_pendulum] epoch #470 | Saved\n",
      "2022-08-17 18:09:39 | [trpo_pendulum] epoch #470 | Time 295.29 s\n",
      "2022-08-17 18:09:39 | [trpo_pendulum] epoch #470 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -71.9723\n",
      "Evaluation/AverageReturn               -284.927\n",
      "Evaluation/Iteration                    470\n",
      "Evaluation/MaxReturn                   -135.001\n",
      "Evaluation/MinReturn                   -390.808\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     80.7015\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.72452\n",
      "GaussianMLPPolicy/KL                      0.00777772\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -77.9251\n",
      "GaussianMLPPolicy/LossBefore            -75.7537\n",
      "GaussianMLPPolicy/dLoss                   2.17139\n",
      "GaussianMLPValueFunction/LossAfter        6.60231\n",
      "GaussianMLPValueFunction/LossBefore       6.62213\n",
      "GaussianMLPValueFunction/dLoss            0.019824\n",
      "TotalEnvSteps                        565200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:40 | [trpo_pendulum] epoch #471 | Saving snapshot...\n",
      "2022-08-17 18:09:40 | [trpo_pendulum] epoch #471 | Saved\n",
      "2022-08-17 18:09:40 | [trpo_pendulum] epoch #471 | Time 295.93 s\n",
      "2022-08-17 18:09:40 | [trpo_pendulum] epoch #471 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -308.937\n",
      "Evaluation/AverageReturn               -680.515\n",
      "Evaluation/Iteration                    471\n",
      "Evaluation/MaxReturn                   -510.417\n",
      "Evaluation/MinReturn                   -878.361\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    136.977\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.70249\n",
      "GaussianMLPPolicy/KL                      0.00723277\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -27.356\n",
      "GaussianMLPPolicy/LossBefore            -25.9084\n",
      "GaussianMLPPolicy/dLoss                   1.4476\n",
      "GaussianMLPValueFunction/LossAfter        6.39007\n",
      "GaussianMLPValueFunction/LossBefore       6.40859\n",
      "GaussianMLPValueFunction/dLoss            0.0185246\n",
      "TotalEnvSteps                        566400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:40 | [trpo_pendulum] epoch #472 | Saving snapshot...\n",
      "2022-08-17 18:09:40 | [trpo_pendulum] epoch #472 | Saved\n",
      "2022-08-17 18:09:40 | [trpo_pendulum] epoch #472 | Time 296.55 s\n",
      "2022-08-17 18:09:40 | [trpo_pendulum] epoch #472 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -409.251\n",
      "Evaluation/AverageReturn               -840.858\n",
      "Evaluation/Iteration                    472\n",
      "Evaluation/MaxReturn                   -497.332\n",
      "Evaluation/MinReturn                  -1103.25\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    193.454\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.70326\n",
      "GaussianMLPPolicy/KL                      0.00995777\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -11.8443\n",
      "GaussianMLPPolicy/LossBefore             -8.8101\n",
      "GaussianMLPPolicy/dLoss                   3.03421\n",
      "GaussianMLPValueFunction/LossAfter        6.43255\n",
      "GaussianMLPValueFunction/LossBefore       6.43709\n",
      "GaussianMLPValueFunction/dLoss            0.00453615\n",
      "TotalEnvSteps                        567600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:41 | [trpo_pendulum] epoch #473 | Saving snapshot...\n",
      "2022-08-17 18:09:41 | [trpo_pendulum] epoch #473 | Saved\n",
      "2022-08-17 18:09:41 | [trpo_pendulum] epoch #473 | Time 297.19 s\n",
      "2022-08-17 18:09:41 | [trpo_pendulum] epoch #473 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -381.524\n",
      "Evaluation/AverageReturn               -763.935\n",
      "Evaluation/Iteration                    473\n",
      "Evaluation/MaxReturn                   -498.352\n",
      "Evaluation/MinReturn                  -1013.32\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    172.292\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.69628\n",
      "GaussianMLPPolicy/KL                      0.00650762\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -21.392\n",
      "GaussianMLPPolicy/LossBefore            -19.5728\n",
      "GaussianMLPPolicy/dLoss                   1.81918\n",
      "GaussianMLPValueFunction/LossAfter        6.44737\n",
      "GaussianMLPValueFunction/LossBefore       6.45205\n",
      "GaussianMLPValueFunction/dLoss            0.00467968\n",
      "TotalEnvSteps                        568800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:42 | [trpo_pendulum] epoch #474 | Saving snapshot...\n",
      "2022-08-17 18:09:42 | [trpo_pendulum] epoch #474 | Saved\n",
      "2022-08-17 18:09:42 | [trpo_pendulum] epoch #474 | Time 297.81 s\n",
      "2022-08-17 18:09:42 | [trpo_pendulum] epoch #474 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -274.526\n",
      "Evaluation/AverageReturn               -549.165\n",
      "Evaluation/Iteration                    474\n",
      "Evaluation/MaxReturn                   -377.578\n",
      "Evaluation/MinReturn                   -887.007\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    188.095\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.69561\n",
      "GaussianMLPPolicy/KL                      0.0064772\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -48.7347\n",
      "GaussianMLPPolicy/LossBefore            -46.8462\n",
      "GaussianMLPPolicy/dLoss                   1.88858\n",
      "GaussianMLPValueFunction/LossAfter        6.5836\n",
      "GaussianMLPValueFunction/LossBefore       6.60453\n",
      "GaussianMLPValueFunction/dLoss            0.0209308\n",
      "TotalEnvSteps                        570000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:09:42 | [trpo_pendulum] epoch #475 | Saving snapshot...\n",
      "2022-08-17 18:09:42 | [trpo_pendulum] epoch #475 | Saved\n",
      "2022-08-17 18:09:42 | [trpo_pendulum] epoch #475 | Time 298.45 s\n",
      "2022-08-17 18:09:42 | [trpo_pendulum] epoch #475 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -669.057\n",
      "Evaluation/AverageReturn              -1536.35\n",
      "Evaluation/Iteration                    475\n",
      "Evaluation/MaxReturn                  -1522.37\n",
      "Evaluation/MinReturn                  -1545.76\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      8.61413\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.69452\n",
      "GaussianMLPPolicy/KL                      0.00820062\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              94.7612\n",
      "GaussianMLPPolicy/LossBefore             96.2434\n",
      "GaussianMLPPolicy/dLoss                   1.4822\n",
      "GaussianMLPValueFunction/LossAfter        7.04885\n",
      "GaussianMLPValueFunction/LossBefore       7.19956\n",
      "GaussianMLPValueFunction/dLoss            0.150705\n",
      "TotalEnvSteps                        571200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:43 | [trpo_pendulum] epoch #476 | Saving snapshot...\n",
      "2022-08-17 18:09:43 | [trpo_pendulum] epoch #476 | Saved\n",
      "2022-08-17 18:09:43 | [trpo_pendulum] epoch #476 | Time 299.10 s\n",
      "2022-08-17 18:09:43 | [trpo_pendulum] epoch #476 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -602.094\n",
      "Evaluation/AverageReturn              -1432.76\n",
      "Evaluation/Iteration                    476\n",
      "Evaluation/MaxReturn                  -1307.12\n",
      "Evaluation/MinReturn                  -1497.3\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     64.72\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.65653\n",
      "GaussianMLPPolicy/KL                      0.00668324\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              82.668\n",
      "GaussianMLPPolicy/LossBefore             84.7763\n",
      "GaussianMLPPolicy/dLoss                   2.10828\n",
      "GaussianMLPValueFunction/LossAfter        6.87968\n",
      "GaussianMLPValueFunction/LossBefore       6.90769\n",
      "GaussianMLPValueFunction/dLoss            0.0280108\n",
      "TotalEnvSteps                        572400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:43 | [trpo_pendulum] epoch #477 | Saving snapshot...\n",
      "2022-08-17 18:09:43 | [trpo_pendulum] epoch #477 | Saved\n",
      "2022-08-17 18:09:43 | [trpo_pendulum] epoch #477 | Time 299.72 s\n",
      "2022-08-17 18:09:43 | [trpo_pendulum] epoch #477 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -132.959\n",
      "Evaluation/AverageReturn               -526.361\n",
      "Evaluation/Iteration                    477\n",
      "Evaluation/MaxReturn                   -248.923\n",
      "Evaluation/MinReturn                   -645.657\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    133.591\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.66131\n",
      "GaussianMLPPolicy/KL                      0.00661678\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -36.1425\n",
      "GaussianMLPPolicy/LossBefore            -34.1597\n",
      "GaussianMLPPolicy/dLoss                   1.98276\n",
      "GaussianMLPValueFunction/LossAfter        6.32958\n",
      "GaussianMLPValueFunction/LossBefore       6.36558\n",
      "GaussianMLPValueFunction/dLoss            0.0360026\n",
      "TotalEnvSteps                        573600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:44 | [trpo_pendulum] epoch #478 | Saving snapshot...\n",
      "2022-08-17 18:09:44 | [trpo_pendulum] epoch #478 | Saved\n",
      "2022-08-17 18:09:44 | [trpo_pendulum] epoch #478 | Time 300.35 s\n",
      "2022-08-17 18:09:44 | [trpo_pendulum] epoch #478 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -573.643\n",
      "Evaluation/AverageReturn              -1395.24\n",
      "Evaluation/Iteration                    478\n",
      "Evaluation/MaxReturn                  -1328.3\n",
      "Evaluation/MinReturn                  -1490.97\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     50.738\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.66646\n",
      "GaussianMLPPolicy/KL                      0.00975669\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              76.8754\n",
      "GaussianMLPPolicy/LossBefore             80.1614\n",
      "GaussianMLPPolicy/dLoss                   3.28595\n",
      "GaussianMLPValueFunction/LossAfter        6.81758\n",
      "GaussianMLPValueFunction/LossBefore       6.83489\n",
      "GaussianMLPValueFunction/dLoss            0.0173125\n",
      "TotalEnvSteps                        574800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:45 | [trpo_pendulum] epoch #479 | Saving snapshot...\n",
      "2022-08-17 18:09:45 | [trpo_pendulum] epoch #479 | Saved\n",
      "2022-08-17 18:09:45 | [trpo_pendulum] epoch #479 | Time 300.98 s\n",
      "2022-08-17 18:09:45 | [trpo_pendulum] epoch #479 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -515.282\n",
      "Evaluation/AverageReturn              -1256.23\n",
      "Evaluation/Iteration                    479\n",
      "Evaluation/MaxReturn                  -1093.18\n",
      "Evaluation/MinReturn                  -1396.67\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     97.7991\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.65598\n",
      "GaussianMLPPolicy/KL                      0.0099839\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              57.3148\n",
      "GaussianMLPPolicy/LossBefore             60.1637\n",
      "GaussianMLPPolicy/dLoss                   2.84894\n",
      "GaussianMLPValueFunction/LossAfter        6.61918\n",
      "GaussianMLPValueFunction/LossBefore       6.62306\n",
      "GaussianMLPValueFunction/dLoss            0.00388479\n",
      "TotalEnvSteps                        576000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:45 | [trpo_pendulum] epoch #480 | Saving snapshot...\n",
      "2022-08-17 18:09:45 | [trpo_pendulum] epoch #480 | Saved\n",
      "2022-08-17 18:09:45 | [trpo_pendulum] epoch #480 | Time 301.59 s\n",
      "2022-08-17 18:09:45 | [trpo_pendulum] epoch #480 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -656.227\n",
      "Evaluation/AverageReturn              -1506.18\n",
      "Evaluation/Iteration                    480\n",
      "Evaluation/MaxReturn                  -1497.24\n",
      "Evaluation/MinReturn                  -1520.65\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      7.30133\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.69493\n",
      "GaussianMLPPolicy/KL                      0.00728634\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              87.4193\n",
      "GaussianMLPPolicy/LossBefore             89.5421\n",
      "GaussianMLPPolicy/dLoss                   2.12273\n",
      "GaussianMLPValueFunction/LossAfter        6.9363\n",
      "GaussianMLPValueFunction/LossBefore       6.97205\n",
      "GaussianMLPValueFunction/dLoss            0.0357561\n",
      "TotalEnvSteps                        577200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:46 | [trpo_pendulum] epoch #481 | Saving snapshot...\n",
      "2022-08-17 18:09:46 | [trpo_pendulum] epoch #481 | Saved\n",
      "2022-08-17 18:09:46 | [trpo_pendulum] epoch #481 | Time 302.22 s\n",
      "2022-08-17 18:09:46 | [trpo_pendulum] epoch #481 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -523.873\n",
      "Evaluation/AverageReturn              -1348.41\n",
      "Evaluation/Iteration                    481\n",
      "Evaluation/MaxReturn                  -1297.82\n",
      "Evaluation/MinReturn                  -1400.98\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     35.6943\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.68032\n",
      "GaussianMLPPolicy/KL                      0.00945328\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              74.7355\n",
      "GaussianMLPPolicy/LossBefore             78.0933\n",
      "GaussianMLPPolicy/dLoss                   3.35779\n",
      "GaussianMLPValueFunction/LossAfter        6.8104\n",
      "GaussianMLPValueFunction/LossBefore       6.81948\n",
      "GaussianMLPValueFunction/dLoss            0.00907898\n",
      "TotalEnvSteps                        578400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:47 | [trpo_pendulum] epoch #482 | Saving snapshot...\n",
      "2022-08-17 18:09:47 | [trpo_pendulum] epoch #482 | Saved\n",
      "2022-08-17 18:09:47 | [trpo_pendulum] epoch #482 | Time 302.87 s\n",
      "2022-08-17 18:09:47 | [trpo_pendulum] epoch #482 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -586.845\n",
      "Evaluation/AverageReturn              -1434.29\n",
      "Evaluation/Iteration                    482\n",
      "Evaluation/MaxReturn                  -1383.81\n",
      "Evaluation/MinReturn                  -1464.28\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     32.0596\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.66778\n",
      "GaussianMLPPolicy/KL                      0.00683172\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              82.0578\n",
      "GaussianMLPPolicy/LossBefore             84.9588\n",
      "GaussianMLPPolicy/dLoss                   2.90104\n",
      "GaussianMLPValueFunction/LossAfter        6.87422\n",
      "GaussianMLPValueFunction/LossBefore       6.88756\n",
      "GaussianMLPValueFunction/dLoss            0.0133438\n",
      "TotalEnvSteps                        579600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:47 | [trpo_pendulum] epoch #483 | Saving snapshot...\n",
      "2022-08-17 18:09:47 | [trpo_pendulum] epoch #483 | Saved\n",
      "2022-08-17 18:09:47 | [trpo_pendulum] epoch #483 | Time 303.51 s\n",
      "2022-08-17 18:09:47 | [trpo_pendulum] epoch #483 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -662.112\n",
      "Evaluation/AverageReturn              -1533.53\n",
      "Evaluation/Iteration                    483\n",
      "Evaluation/MaxReturn                  -1492.97\n",
      "Evaluation/MinReturn                  -1573.18\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     23.6699\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.68479\n",
      "GaussianMLPPolicy/KL                      0.00979233\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              91.0482\n",
      "GaussianMLPPolicy/LossBefore             93.8443\n",
      "GaussianMLPPolicy/dLoss                   2.79611\n",
      "GaussianMLPValueFunction/LossAfter        6.961\n",
      "GaussianMLPValueFunction/LossBefore       6.98251\n",
      "GaussianMLPValueFunction/dLoss            0.0215054\n",
      "TotalEnvSteps                        580800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:48 | [trpo_pendulum] epoch #484 | Saving snapshot...\n",
      "2022-08-17 18:09:48 | [trpo_pendulum] epoch #484 | Saved\n",
      "2022-08-17 18:09:48 | [trpo_pendulum] epoch #484 | Time 304.17 s\n",
      "2022-08-17 18:09:48 | [trpo_pendulum] epoch #484 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -351.214\n",
      "Evaluation/AverageReturn              -1080.18\n",
      "Evaluation/Iteration                    484\n",
      "Evaluation/MaxReturn                   -811.335\n",
      "Evaluation/MinReturn                  -1340.96\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    195.351\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.66132\n",
      "GaussianMLPPolicy/KL                      0.00970756\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              42.6942\n",
      "GaussianMLPPolicy/LossBefore             45.28\n",
      "GaussianMLPPolicy/dLoss                   2.58579\n",
      "GaussianMLPValueFunction/LossAfter        6.59539\n",
      "GaussianMLPValueFunction/LossBefore       6.61102\n",
      "GaussianMLPValueFunction/dLoss            0.0156336\n",
      "TotalEnvSteps                        582000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:49 | [trpo_pendulum] epoch #485 | Saving snapshot...\n",
      "2022-08-17 18:09:49 | [trpo_pendulum] epoch #485 | Saved\n",
      "2022-08-17 18:09:49 | [trpo_pendulum] epoch #485 | Time 304.82 s\n",
      "2022-08-17 18:09:49 | [trpo_pendulum] epoch #485 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -395.891\n",
      "Evaluation/AverageReturn              -1183.56\n",
      "Evaluation/Iteration                    485\n",
      "Evaluation/MaxReturn                  -1055.45\n",
      "Evaluation/MinReturn                  -1308.48\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     88.0132\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.65454\n",
      "GaussianMLPPolicy/KL                      0.00938559\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              58.0033\n",
      "GaussianMLPPolicy/LossBefore             60.9356\n",
      "GaussianMLPPolicy/dLoss                   2.93227\n",
      "GaussianMLPValueFunction/LossAfter        6.67887\n",
      "GaussianMLPValueFunction/LossBefore       6.68492\n",
      "GaussianMLPValueFunction/dLoss            0.00604582\n",
      "TotalEnvSteps                        583200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:49 | [trpo_pendulum] epoch #486 | Saving snapshot...\n",
      "2022-08-17 18:09:49 | [trpo_pendulum] epoch #486 | Saved\n",
      "2022-08-17 18:09:49 | [trpo_pendulum] epoch #486 | Time 305.48 s\n",
      "2022-08-17 18:09:49 | [trpo_pendulum] epoch #486 | EpochTime 0.66 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -644.053\n",
      "Evaluation/AverageReturn              -1499.46\n",
      "Evaluation/Iteration                    486\n",
      "Evaluation/MaxReturn                  -1494.99\n",
      "Evaluation/MinReturn                  -1505.92\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      3.43639\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.70364\n",
      "GaussianMLPPolicy/KL                      0.0093816\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              84.0556\n",
      "GaussianMLPPolicy/LossBefore             87.2967\n",
      "GaussianMLPPolicy/dLoss                   3.24107\n",
      "GaussianMLPValueFunction/LossAfter        6.89765\n",
      "GaussianMLPValueFunction/LossBefore       6.91285\n",
      "GaussianMLPValueFunction/dLoss            0.0151963\n",
      "TotalEnvSteps                        584400\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:09:50 | [trpo_pendulum] epoch #487 | Saving snapshot...\n",
      "2022-08-17 18:09:50 | [trpo_pendulum] epoch #487 | Saved\n",
      "2022-08-17 18:09:50 | [trpo_pendulum] epoch #487 | Time 306.16 s\n",
      "2022-08-17 18:09:50 | [trpo_pendulum] epoch #487 | EpochTime 0.67 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -625.593\n",
      "Evaluation/AverageReturn              -1527.06\n",
      "Evaluation/Iteration                    487\n",
      "Evaluation/MaxReturn                  -1404.95\n",
      "Evaluation/MinReturn                  -1686.75\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     99.0075\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.69145\n",
      "GaussianMLPPolicy/KL                      0.00970546\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              92.8153\n",
      "GaussianMLPPolicy/LossBefore             96.1242\n",
      "GaussianMLPPolicy/dLoss                   3.30894\n",
      "GaussianMLPValueFunction/LossAfter        7.00807\n",
      "GaussianMLPValueFunction/LossBefore       7.037\n",
      "GaussianMLPValueFunction/dLoss            0.0289254\n",
      "TotalEnvSteps                        585600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:51 | [trpo_pendulum] epoch #488 | Saving snapshot...\n",
      "2022-08-17 18:09:51 | [trpo_pendulum] epoch #488 | Saved\n",
      "2022-08-17 18:09:51 | [trpo_pendulum] epoch #488 | Time 306.87 s\n",
      "2022-08-17 18:09:51 | [trpo_pendulum] epoch #488 | EpochTime 0.70 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -664.743\n",
      "Evaluation/AverageReturn              -1525.92\n",
      "Evaluation/Iteration                    488\n",
      "Evaluation/MaxReturn                  -1513.23\n",
      "Evaluation/MinReturn                  -1540.75\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      8.51092\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.67337\n",
      "GaussianMLPPolicy/KL                      0.00781602\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              85.2827\n",
      "GaussianMLPPolicy/LossBefore             87.478\n",
      "GaussianMLPPolicy/dLoss                   2.19527\n",
      "GaussianMLPValueFunction/LossAfter        6.88972\n",
      "GaussianMLPValueFunction/LossBefore       6.89528\n",
      "GaussianMLPValueFunction/dLoss            0.00555182\n",
      "TotalEnvSteps                        586800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:51 | [trpo_pendulum] epoch #489 | Saving snapshot...\n",
      "2022-08-17 18:09:51 | [trpo_pendulum] epoch #489 | Saved\n",
      "2022-08-17 18:09:51 | [trpo_pendulum] epoch #489 | Time 307.51 s\n",
      "2022-08-17 18:09:51 | [trpo_pendulum] epoch #489 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -655.476\n",
      "Evaluation/AverageReturn              -1512.01\n",
      "Evaluation/Iteration                    489\n",
      "Evaluation/MaxReturn                  -1506.69\n",
      "Evaluation/MinReturn                  -1524.73\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      6.07103\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.63713\n",
      "GaussianMLPPolicy/KL                      0.00740152\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              83.6549\n",
      "GaussianMLPPolicy/LossBefore             86.0803\n",
      "GaussianMLPPolicy/dLoss                   2.42542\n",
      "GaussianMLPValueFunction/LossAfter        6.88216\n",
      "GaussianMLPValueFunction/LossBefore       6.88646\n",
      "GaussianMLPValueFunction/dLoss            0.00429487\n",
      "TotalEnvSteps                        588000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:52 | [trpo_pendulum] epoch #490 | Saving snapshot...\n",
      "2022-08-17 18:09:52 | [trpo_pendulum] epoch #490 | Saved\n",
      "2022-08-17 18:09:52 | [trpo_pendulum] epoch #490 | Time 308.15 s\n",
      "2022-08-17 18:09:52 | [trpo_pendulum] epoch #490 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -443.021\n",
      "Evaluation/AverageReturn              -1251.55\n",
      "Evaluation/Iteration                    490\n",
      "Evaluation/MaxReturn                  -1064.26\n",
      "Evaluation/MinReturn                  -1367.71\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    108.554\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.64083\n",
      "GaussianMLPPolicy/KL                      0.00919843\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              63.0118\n",
      "GaussianMLPPolicy/LossBefore             65.7662\n",
      "GaussianMLPPolicy/dLoss                   2.75436\n",
      "GaussianMLPValueFunction/LossAfter        6.74558\n",
      "GaussianMLPValueFunction/LossBefore       6.75337\n",
      "GaussianMLPValueFunction/dLoss            0.00779057\n",
      "TotalEnvSteps                        589200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:53 | [trpo_pendulum] epoch #491 | Saving snapshot...\n",
      "2022-08-17 18:09:53 | [trpo_pendulum] epoch #491 | Saved\n",
      "2022-08-17 18:09:53 | [trpo_pendulum] epoch #491 | Time 308.81 s\n",
      "2022-08-17 18:09:53 | [trpo_pendulum] epoch #491 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -620.396\n",
      "Evaluation/AverageReturn              -1471.92\n",
      "Evaluation/Iteration                    491\n",
      "Evaluation/MaxReturn                  -1461.71\n",
      "Evaluation/MinReturn                  -1478.96\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.94282\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.66396\n",
      "GaussianMLPPolicy/KL                      0.00888818\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              79.7434\n",
      "GaussianMLPPolicy/LossBefore             82.6529\n",
      "GaussianMLPPolicy/dLoss                   2.90955\n",
      "GaussianMLPValueFunction/LossAfter        6.85932\n",
      "GaussianMLPValueFunction/LossBefore       6.86368\n",
      "GaussianMLPValueFunction/dLoss            0.00435686\n",
      "TotalEnvSteps                        590400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:53 | [trpo_pendulum] epoch #492 | Saving snapshot...\n",
      "2022-08-17 18:09:53 | [trpo_pendulum] epoch #492 | Saved\n",
      "2022-08-17 18:09:53 | [trpo_pendulum] epoch #492 | Time 309.45 s\n",
      "2022-08-17 18:09:53 | [trpo_pendulum] epoch #492 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -669.136\n",
      "Evaluation/AverageReturn              -1532.99\n",
      "Evaluation/Iteration                    492\n",
      "Evaluation/MaxReturn                  -1510.64\n",
      "Evaluation/MinReturn                  -1621.12\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     39.5412\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.65334\n",
      "GaussianMLPPolicy/KL                      0.00873062\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              84.4724\n",
      "GaussianMLPPolicy/LossBefore             86.6703\n",
      "GaussianMLPPolicy/dLoss                   2.19791\n",
      "GaussianMLPValueFunction/LossAfter        6.89374\n",
      "GaussianMLPValueFunction/LossBefore       6.89954\n",
      "GaussianMLPValueFunction/dLoss            0.00579739\n",
      "TotalEnvSteps                        591600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:54 | [trpo_pendulum] epoch #493 | Saving snapshot...\n",
      "2022-08-17 18:09:54 | [trpo_pendulum] epoch #493 | Saved\n",
      "2022-08-17 18:09:54 | [trpo_pendulum] epoch #493 | Time 310.08 s\n",
      "2022-08-17 18:09:54 | [trpo_pendulum] epoch #493 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -562.078\n",
      "Evaluation/AverageReturn              -1408.25\n",
      "Evaluation/Iteration                    493\n",
      "Evaluation/MaxReturn                  -1389.65\n",
      "Evaluation/MinReturn                  -1423.56\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     10.6881\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.65056\n",
      "GaussianMLPPolicy/KL                      0.0064727\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              74.7852\n",
      "GaussianMLPPolicy/LossBefore             77.3868\n",
      "GaussianMLPPolicy/dLoss                   2.60158\n",
      "GaussianMLPValueFunction/LossAfter        6.80755\n",
      "GaussianMLPValueFunction/LossBefore       6.81212\n",
      "GaussianMLPValueFunction/dLoss            0.00456905\n",
      "TotalEnvSteps                        592800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:54 | [trpo_pendulum] epoch #494 | Saving snapshot...\n",
      "2022-08-17 18:09:54 | [trpo_pendulum] epoch #494 | Saved\n",
      "2022-08-17 18:09:54 | [trpo_pendulum] epoch #494 | Time 310.71 s\n",
      "2022-08-17 18:09:54 | [trpo_pendulum] epoch #494 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -599.043\n",
      "Evaluation/AverageReturn              -1420.1\n",
      "Evaluation/Iteration                    494\n",
      "Evaluation/MaxReturn                  -1371.52\n",
      "Evaluation/MinReturn                  -1453.78\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     28.3168\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.65688\n",
      "GaussianMLPPolicy/KL                      0.00644904\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              69.4505\n",
      "GaussianMLPPolicy/LossBefore             72.1803\n",
      "GaussianMLPPolicy/dLoss                   2.7298\n",
      "GaussianMLPValueFunction/LossAfter        6.76598\n",
      "GaussianMLPValueFunction/LossBefore       6.77203\n",
      "GaussianMLPValueFunction/dLoss            0.00605345\n",
      "TotalEnvSteps                        594000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:55 | [trpo_pendulum] epoch #495 | Saving snapshot...\n",
      "2022-08-17 18:09:55 | [trpo_pendulum] epoch #495 | Saved\n",
      "2022-08-17 18:09:55 | [trpo_pendulum] epoch #495 | Time 311.35 s\n",
      "2022-08-17 18:09:55 | [trpo_pendulum] epoch #495 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -656.085\n",
      "Evaluation/AverageReturn              -1505.92\n",
      "Evaluation/Iteration                    495\n",
      "Evaluation/MaxReturn                  -1500.18\n",
      "Evaluation/MinReturn                  -1513.48\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      4.57813\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.6484\n",
      "GaussianMLPPolicy/KL                      0.0081626\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              78.5398\n",
      "GaussianMLPPolicy/LossBefore             80.2821\n",
      "GaussianMLPPolicy/dLoss                   1.74232\n",
      "GaussianMLPValueFunction/LossAfter        6.84254\n",
      "GaussianMLPValueFunction/LossBefore       6.84701\n",
      "GaussianMLPValueFunction/dLoss            0.00447178\n",
      "TotalEnvSteps                        595200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:56 | [trpo_pendulum] epoch #496 | Saving snapshot...\n",
      "2022-08-17 18:09:56 | [trpo_pendulum] epoch #496 | Saved\n",
      "2022-08-17 18:09:56 | [trpo_pendulum] epoch #496 | Time 311.98 s\n",
      "2022-08-17 18:09:56 | [trpo_pendulum] epoch #496 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -660.663\n",
      "Evaluation/AverageReturn              -1532.79\n",
      "Evaluation/Iteration                    496\n",
      "Evaluation/MaxReturn                  -1520.46\n",
      "Evaluation/MinReturn                  -1544.75\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      8.80172\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.64898\n",
      "GaussianMLPPolicy/KL                      0.00662806\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              82.9457\n",
      "GaussianMLPPolicy/LossBefore             85.3621\n",
      "GaussianMLPPolicy/dLoss                   2.41635\n",
      "GaussianMLPValueFunction/LossAfter        6.88922\n",
      "GaussianMLPValueFunction/LossBefore       6.89616\n",
      "GaussianMLPValueFunction/dLoss            0.00693417\n",
      "TotalEnvSteps                        596400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:56 | [trpo_pendulum] epoch #497 | Saving snapshot...\n",
      "2022-08-17 18:09:56 | [trpo_pendulum] epoch #497 | Saved\n",
      "2022-08-17 18:09:56 | [trpo_pendulum] epoch #497 | Time 312.60 s\n",
      "2022-08-17 18:09:56 | [trpo_pendulum] epoch #497 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -649.502\n",
      "Evaluation/AverageReturn              -1548.52\n",
      "Evaluation/Iteration                    497\n",
      "Evaluation/MaxReturn                  -1491.89\n",
      "Evaluation/MinReturn                  -1598.25\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     43.4555\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.64654\n",
      "GaussianMLPPolicy/KL                      0.00661607\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              87.8367\n",
      "GaussianMLPPolicy/LossBefore             89.888\n",
      "GaussianMLPPolicy/dLoss                   2.05135\n",
      "GaussianMLPValueFunction/LossAfter        6.93327\n",
      "GaussianMLPValueFunction/LossBefore       6.9425\n",
      "GaussianMLPValueFunction/dLoss            0.0092268\n",
      "TotalEnvSteps                        597600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:57 | [trpo_pendulum] epoch #498 | Saving snapshot...\n",
      "2022-08-17 18:09:57 | [trpo_pendulum] epoch #498 | Saved\n",
      "2022-08-17 18:09:57 | [trpo_pendulum] epoch #498 | Time 313.25 s\n",
      "2022-08-17 18:09:57 | [trpo_pendulum] epoch #498 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -598.914\n",
      "Evaluation/AverageReturn              -1468.59\n",
      "Evaluation/Iteration                    498\n",
      "Evaluation/MaxReturn                  -1432\n",
      "Evaluation/MinReturn                  -1492.49\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     19.4753\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.65195\n",
      "GaussianMLPPolicy/KL                      0.00959372\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              78.4272\n",
      "GaussianMLPPolicy/LossBefore             80.8481\n",
      "GaussianMLPPolicy/dLoss                   2.42093\n",
      "GaussianMLPValueFunction/LossAfter        6.84302\n",
      "GaussianMLPValueFunction/LossBefore       6.84743\n",
      "GaussianMLPValueFunction/dLoss            0.00441122\n",
      "TotalEnvSteps                        598800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:58 | [trpo_pendulum] epoch #499 | Saving snapshot...\n",
      "2022-08-17 18:09:58 | [trpo_pendulum] epoch #499 | Saved\n",
      "2022-08-17 18:09:58 | [trpo_pendulum] epoch #499 | Time 313.87 s\n",
      "2022-08-17 18:09:58 | [trpo_pendulum] epoch #499 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -599.613\n",
      "Evaluation/AverageReturn              -1477.75\n",
      "Evaluation/Iteration                    499\n",
      "Evaluation/MaxReturn                  -1450.99\n",
      "Evaluation/MinReturn                  -1531.08\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     27.5339\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.65101\n",
      "GaussianMLPPolicy/KL                      0.0094219\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              79.0504\n",
      "GaussianMLPPolicy/LossBefore             82.0459\n",
      "GaussianMLPPolicy/dLoss                   2.99548\n",
      "GaussianMLPValueFunction/LossAfter        6.8688\n",
      "GaussianMLPValueFunction/LossBefore       6.87266\n",
      "GaussianMLPValueFunction/dLoss            0.00386667\n",
      "TotalEnvSteps                        600000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:58 | [trpo_pendulum] epoch #500 | Saving snapshot...\n",
      "2022-08-17 18:09:58 | [trpo_pendulum] epoch #500 | Saved\n",
      "2022-08-17 18:09:58 | [trpo_pendulum] epoch #500 | Time 314.51 s\n",
      "2022-08-17 18:09:58 | [trpo_pendulum] epoch #500 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -623.203\n",
      "Evaluation/AverageReturn              -1502.61\n",
      "Evaluation/Iteration                    500\n",
      "Evaluation/MaxReturn                  -1476.63\n",
      "Evaluation/MinReturn                  -1537.7\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     19.2765\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.65844\n",
      "GaussianMLPPolicy/KL                      0.0069598\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              79.6289\n",
      "GaussianMLPPolicy/LossBefore             81.967\n",
      "GaussianMLPPolicy/dLoss                   2.33812\n",
      "GaussianMLPValueFunction/LossAfter        6.86481\n",
      "GaussianMLPValueFunction/LossBefore       6.86869\n",
      "GaussianMLPValueFunction/dLoss            0.00388241\n",
      "TotalEnvSteps                        601200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:59 | [trpo_pendulum] epoch #501 | Saving snapshot...\n",
      "2022-08-17 18:09:59 | [trpo_pendulum] epoch #501 | Saved\n",
      "2022-08-17 18:09:59 | [trpo_pendulum] epoch #501 | Time 315.15 s\n",
      "2022-08-17 18:09:59 | [trpo_pendulum] epoch #501 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -587.704\n",
      "Evaluation/AverageReturn              -1441.94\n",
      "Evaluation/Iteration                    501\n",
      "Evaluation/MaxReturn                  -1432.55\n",
      "Evaluation/MinReturn                  -1468.18\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     12.0164\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.63207\n",
      "GaussianMLPPolicy/KL                      0.00689503\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              72.7385\n",
      "GaussianMLPPolicy/LossBefore             75.0319\n",
      "GaussianMLPPolicy/dLoss                   2.29331\n",
      "GaussianMLPValueFunction/LossAfter        6.80558\n",
      "GaussianMLPValueFunction/LossBefore       6.81138\n",
      "GaussianMLPValueFunction/dLoss            0.00580359\n",
      "TotalEnvSteps                        602400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:09:59 | [trpo_pendulum] epoch #502 | Saving snapshot...\n",
      "2022-08-17 18:10:00 | [trpo_pendulum] epoch #502 | Saved\n",
      "2022-08-17 18:10:00 | [trpo_pendulum] epoch #502 | Time 315.78 s\n",
      "2022-08-17 18:10:00 | [trpo_pendulum] epoch #502 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -644.906\n",
      "Evaluation/AverageReturn              -1515.09\n",
      "Evaluation/Iteration                    502\n",
      "Evaluation/MaxReturn                  -1489.13\n",
      "Evaluation/MinReturn                  -1544.11\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     17.4085\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.64143\n",
      "GaussianMLPPolicy/KL                      0.00665744\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              77.8335\n",
      "GaussianMLPPolicy/LossBefore             79.9672\n",
      "GaussianMLPPolicy/dLoss                   2.13367\n",
      "GaussianMLPValueFunction/LossAfter        6.84905\n",
      "GaussianMLPValueFunction/LossBefore       6.85304\n",
      "GaussianMLPValueFunction/dLoss            0.00398827\n",
      "TotalEnvSteps                        603600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:00 | [trpo_pendulum] epoch #503 | Saving snapshot...\n",
      "2022-08-17 18:10:00 | [trpo_pendulum] epoch #503 | Saved\n",
      "2022-08-17 18:10:00 | [trpo_pendulum] epoch #503 | Time 316.42 s\n",
      "2022-08-17 18:10:00 | [trpo_pendulum] epoch #503 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -660.585\n",
      "Evaluation/AverageReturn              -1532.96\n",
      "Evaluation/Iteration                    503\n",
      "Evaluation/MaxReturn                  -1516.24\n",
      "Evaluation/MinReturn                  -1557.64\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     14.9437\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.63649\n",
      "GaussianMLPPolicy/KL                      0.00761058\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              78.5056\n",
      "GaussianMLPPolicy/LossBefore             80.4648\n",
      "GaussianMLPPolicy/dLoss                   1.95923\n",
      "GaussianMLPValueFunction/LossAfter        6.85855\n",
      "GaussianMLPValueFunction/LossBefore       6.86258\n",
      "GaussianMLPValueFunction/dLoss            0.00402737\n",
      "TotalEnvSteps                        604800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:01 | [trpo_pendulum] epoch #504 | Saving snapshot...\n",
      "2022-08-17 18:10:01 | [trpo_pendulum] epoch #504 | Saved\n",
      "2022-08-17 18:10:01 | [trpo_pendulum] epoch #504 | Time 317.05 s\n",
      "2022-08-17 18:10:01 | [trpo_pendulum] epoch #504 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -589.555\n",
      "Evaluation/AverageReturn              -1446.93\n",
      "Evaluation/Iteration                    504\n",
      "Evaluation/MaxReturn                  -1415.9\n",
      "Evaluation/MinReturn                  -1472.4\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     22.4302\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62365\n",
      "GaussianMLPPolicy/KL                      0.00815169\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              70.6421\n",
      "GaussianMLPPolicy/LossBefore             73.0113\n",
      "GaussianMLPPolicy/dLoss                   2.36919\n",
      "GaussianMLPValueFunction/LossAfter        6.79649\n",
      "GaussianMLPValueFunction/LossBefore       6.80209\n",
      "GaussianMLPValueFunction/dLoss            0.00560331\n",
      "TotalEnvSteps                        606000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:01 | [trpo_pendulum] epoch #505 | Saving snapshot...\n",
      "2022-08-17 18:10:01 | [trpo_pendulum] epoch #505 | Saved\n",
      "2022-08-17 18:10:01 | [trpo_pendulum] epoch #505 | Time 317.68 s\n",
      "2022-08-17 18:10:01 | [trpo_pendulum] epoch #505 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -393.29\n",
      "Evaluation/AverageReturn              -1051.99\n",
      "Evaluation/Iteration                    505\n",
      "Evaluation/MaxReturn                   -618.234\n",
      "Evaluation/MinReturn                  -1314.1\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    245.299\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62997\n",
      "GaussianMLPPolicy/KL                      0.00696373\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              18.4484\n",
      "GaussianMLPPolicy/LossBefore             20.3583\n",
      "GaussianMLPPolicy/dLoss                   1.9099\n",
      "GaussianMLPValueFunction/LossAfter        6.49694\n",
      "GaussianMLPValueFunction/LossBefore       6.55317\n",
      "GaussianMLPValueFunction/dLoss            0.056231\n",
      "TotalEnvSteps                        607200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:02 | [trpo_pendulum] epoch #506 | Saving snapshot...\n",
      "2022-08-17 18:10:02 | [trpo_pendulum] epoch #506 | Saved\n",
      "2022-08-17 18:10:02 | [trpo_pendulum] epoch #506 | Time 318.31 s\n",
      "2022-08-17 18:10:02 | [trpo_pendulum] epoch #506 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -661.811\n",
      "Evaluation/AverageReturn              -1527.54\n",
      "Evaluation/Iteration                    506\n",
      "Evaluation/MaxReturn                  -1512.33\n",
      "Evaluation/MinReturn                  -1543.55\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     12.319\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.63839\n",
      "GaussianMLPPolicy/KL                      0.00936059\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              74.6473\n",
      "GaussianMLPPolicy/LossBefore             77.3397\n",
      "GaussianMLPPolicy/dLoss                   2.69234\n",
      "GaussianMLPValueFunction/LossAfter        6.83578\n",
      "GaussianMLPValueFunction/LossBefore       6.85011\n",
      "GaussianMLPValueFunction/dLoss            0.0143294\n",
      "TotalEnvSteps                        608400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:03 | [trpo_pendulum] epoch #507 | Saving snapshot...\n",
      "2022-08-17 18:10:03 | [trpo_pendulum] epoch #507 | Saved\n",
      "2022-08-17 18:10:03 | [trpo_pendulum] epoch #507 | Time 318.96 s\n",
      "2022-08-17 18:10:03 | [trpo_pendulum] epoch #507 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -406.717\n",
      "Evaluation/AverageReturn              -1025.21\n",
      "Evaluation/Iteration                    507\n",
      "Evaluation/MaxReturn                   -871.51\n",
      "Evaluation/MinReturn                  -1124.94\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    105.463\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.65827\n",
      "GaussianMLPPolicy/KL                      0.00758949\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              10.3273\n",
      "GaussianMLPPolicy/LossBefore             12.2593\n",
      "GaussianMLPPolicy/dLoss                   1.93202\n",
      "GaussianMLPValueFunction/LossAfter        6.38524\n",
      "GaussianMLPValueFunction/LossBefore       6.43829\n",
      "GaussianMLPValueFunction/dLoss            0.0530581\n",
      "TotalEnvSteps                        609600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:03 | [trpo_pendulum] epoch #508 | Saving snapshot...\n",
      "2022-08-17 18:10:03 | [trpo_pendulum] epoch #508 | Saved\n",
      "2022-08-17 18:10:03 | [trpo_pendulum] epoch #508 | Time 319.60 s\n",
      "2022-08-17 18:10:03 | [trpo_pendulum] epoch #508 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -654.911\n",
      "Evaluation/AverageReturn              -1529.45\n",
      "Evaluation/Iteration                    508\n",
      "Evaluation/MaxReturn                  -1517.31\n",
      "Evaluation/MinReturn                  -1551.69\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     12.3122\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.67247\n",
      "GaussianMLPPolicy/KL                      0.00977626\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              75.8776\n",
      "GaussianMLPPolicy/LossBefore             78.6261\n",
      "GaussianMLPPolicy/dLoss                   2.74853\n",
      "GaussianMLPValueFunction/LossAfter        6.85785\n",
      "GaussianMLPValueFunction/LossBefore       6.88251\n",
      "GaussianMLPValueFunction/dLoss            0.0246654\n",
      "TotalEnvSteps                        610800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:04 | [trpo_pendulum] epoch #509 | Saving snapshot...\n",
      "2022-08-17 18:10:04 | [trpo_pendulum] epoch #509 | Saved\n",
      "2022-08-17 18:10:04 | [trpo_pendulum] epoch #509 | Time 320.25 s\n",
      "2022-08-17 18:10:04 | [trpo_pendulum] epoch #509 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -404.567\n",
      "Evaluation/AverageReturn               -939.768\n",
      "Evaluation/Iteration                    509\n",
      "Evaluation/MaxReturn                   -752.523\n",
      "Evaluation/MinReturn                  -1105.59\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    109.408\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.66957\n",
      "GaussianMLPPolicy/KL                      0.00990712\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -9.65238\n",
      "GaussianMLPPolicy/LossBefore             -6.67637\n",
      "GaussianMLPPolicy/dLoss                   2.97601\n",
      "GaussianMLPValueFunction/LossAfter        6.37301\n",
      "GaussianMLPValueFunction/LossBefore       6.41167\n",
      "GaussianMLPValueFunction/dLoss            0.03866\n",
      "TotalEnvSteps                        612000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:05 | [trpo_pendulum] epoch #510 | Saving snapshot...\n",
      "2022-08-17 18:10:05 | [trpo_pendulum] epoch #510 | Saved\n",
      "2022-08-17 18:10:05 | [trpo_pendulum] epoch #510 | Time 320.90 s\n",
      "2022-08-17 18:10:05 | [trpo_pendulum] epoch #510 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -402.534\n",
      "Evaluation/AverageReturn               -938.732\n",
      "Evaluation/Iteration                    510\n",
      "Evaluation/MaxReturn                   -783.67\n",
      "Evaluation/MinReturn                  -1004.88\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     78.5217\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.67802\n",
      "GaussianMLPPolicy/KL                      0.00661549\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -8.67525\n",
      "GaussianMLPPolicy/LossBefore             -6.44516\n",
      "GaussianMLPPolicy/dLoss                   2.23009\n",
      "GaussianMLPValueFunction/LossAfter        6.34229\n",
      "GaussianMLPValueFunction/LossBefore       6.37352\n",
      "GaussianMLPValueFunction/dLoss            0.0312266\n",
      "TotalEnvSteps                        613200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:05 | [trpo_pendulum] epoch #511 | Saving snapshot...\n",
      "2022-08-17 18:10:05 | [trpo_pendulum] epoch #511 | Saved\n",
      "2022-08-17 18:10:05 | [trpo_pendulum] epoch #511 | Time 321.55 s\n",
      "2022-08-17 18:10:05 | [trpo_pendulum] epoch #511 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -418.805\n",
      "Evaluation/AverageReturn               -954.615\n",
      "Evaluation/Iteration                    511\n",
      "Evaluation/MaxReturn                   -875.623\n",
      "Evaluation/MinReturn                  -1114.71\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     87.2831\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.65187\n",
      "GaussianMLPPolicy/KL                      0.00768592\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.52549\n",
      "GaussianMLPPolicy/LossBefore             -4.84565\n",
      "GaussianMLPPolicy/dLoss                   1.67984\n",
      "GaussianMLPValueFunction/LossAfter        6.3394\n",
      "GaussianMLPValueFunction/LossBefore       6.3604\n",
      "GaussianMLPValueFunction/dLoss            0.0210009\n",
      "TotalEnvSteps                        614400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:06 | [trpo_pendulum] epoch #512 | Saving snapshot...\n",
      "2022-08-17 18:10:06 | [trpo_pendulum] epoch #512 | Saved\n",
      "2022-08-17 18:10:06 | [trpo_pendulum] epoch #512 | Time 322.22 s\n",
      "2022-08-17 18:10:06 | [trpo_pendulum] epoch #512 | EpochTime 0.67 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -580.577\n",
      "Evaluation/AverageReturn              -1266.45\n",
      "Evaluation/Iteration                    512\n",
      "Evaluation/MaxReturn                  -1209.16\n",
      "Evaluation/MinReturn                  -1340.28\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     52.1653\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.65742\n",
      "GaussianMLPPolicy/KL                      0.00691532\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              32.347\n",
      "GaussianMLPPolicy/LossBefore             35.2296\n",
      "GaussianMLPPolicy/dLoss                   2.88253\n",
      "GaussianMLPValueFunction/LossAfter        6.52373\n",
      "GaussianMLPValueFunction/LossBefore       6.52496\n",
      "GaussianMLPValueFunction/dLoss            0.00123549\n",
      "TotalEnvSteps                        615600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:07 | [trpo_pendulum] epoch #513 | Saving snapshot...\n",
      "2022-08-17 18:10:07 | [trpo_pendulum] epoch #513 | Saved\n",
      "2022-08-17 18:10:07 | [trpo_pendulum] epoch #513 | Time 322.88 s\n",
      "2022-08-17 18:10:07 | [trpo_pendulum] epoch #513 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -403.178\n",
      "Evaluation/AverageReturn               -951.987\n",
      "Evaluation/Iteration                    513\n",
      "Evaluation/MaxReturn                   -790.92\n",
      "Evaluation/MinReturn                  -1066.39\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     92.0352\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.6381\n",
      "GaussianMLPPolicy/KL                      0.00882097\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.67808\n",
      "GaussianMLPPolicy/LossBefore             -4.24129\n",
      "GaussianMLPPolicy/dLoss                   1.43679\n",
      "GaussianMLPValueFunction/LossAfter        6.2641\n",
      "GaussianMLPValueFunction/LossBefore       6.28912\n",
      "GaussianMLPValueFunction/dLoss            0.0250168\n",
      "TotalEnvSteps                        616800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:07 | [trpo_pendulum] epoch #514 | Saving snapshot...\n",
      "2022-08-17 18:10:07 | [trpo_pendulum] epoch #514 | Saved\n",
      "2022-08-17 18:10:07 | [trpo_pendulum] epoch #514 | Time 323.53 s\n",
      "2022-08-17 18:10:07 | [trpo_pendulum] epoch #514 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -438.57\n",
      "Evaluation/AverageReturn              -1001.07\n",
      "Evaluation/Iteration                    514\n",
      "Evaluation/MaxReturn                   -904.698\n",
      "Evaluation/MinReturn                  -1071.91\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     54.8363\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.63477\n",
      "GaussianMLPPolicy/KL                      0.00670278\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.363815\n",
      "GaussianMLPPolicy/LossBefore              1.50867\n",
      "GaussianMLPPolicy/dLoss                   1.14485\n",
      "GaussianMLPValueFunction/LossAfter        6.26718\n",
      "GaussianMLPValueFunction/LossBefore       6.28377\n",
      "GaussianMLPValueFunction/dLoss            0.0165901\n",
      "TotalEnvSteps                        618000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:08 | [trpo_pendulum] epoch #515 | Saving snapshot...\n",
      "2022-08-17 18:10:08 | [trpo_pendulum] epoch #515 | Saved\n",
      "2022-08-17 18:10:08 | [trpo_pendulum] epoch #515 | Time 324.19 s\n",
      "2022-08-17 18:10:08 | [trpo_pendulum] epoch #515 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -413.451\n",
      "Evaluation/AverageReturn               -959.476\n",
      "Evaluation/Iteration                    515\n",
      "Evaluation/MaxReturn                   -805.705\n",
      "Evaluation/MinReturn                  -1031.35\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     85.6065\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.61369\n",
      "GaussianMLPPolicy/KL                      0.00759252\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.9503\n",
      "GaussianMLPPolicy/LossBefore             -3.01461\n",
      "GaussianMLPPolicy/dLoss                   0.935695\n",
      "GaussianMLPValueFunction/LossAfter        6.24181\n",
      "GaussianMLPValueFunction/LossBefore       6.25679\n",
      "GaussianMLPValueFunction/dLoss            0.0149803\n",
      "TotalEnvSteps                        619200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:09 | [trpo_pendulum] epoch #516 | Saving snapshot...\n",
      "2022-08-17 18:10:09 | [trpo_pendulum] epoch #516 | Saved\n",
      "2022-08-17 18:10:09 | [trpo_pendulum] epoch #516 | Time 324.84 s\n",
      "2022-08-17 18:10:09 | [trpo_pendulum] epoch #516 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -599.474\n",
      "Evaluation/AverageReturn              -1258.43\n",
      "Evaluation/Iteration                    516\n",
      "Evaluation/MaxReturn                  -1156.3\n",
      "Evaluation/MinReturn                  -1349.41\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     65.8291\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.63712\n",
      "GaussianMLPPolicy/KL                      0.00830771\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              28.7973\n",
      "GaussianMLPPolicy/LossBefore             32.1171\n",
      "GaussianMLPPolicy/dLoss                   3.31984\n",
      "GaussianMLPValueFunction/LossAfter        6.59054\n",
      "GaussianMLPValueFunction/LossBefore       6.607\n",
      "GaussianMLPValueFunction/dLoss            0.016458\n",
      "TotalEnvSteps                        620400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:09 | [trpo_pendulum] epoch #517 | Saving snapshot...\n",
      "2022-08-17 18:10:09 | [trpo_pendulum] epoch #517 | Saved\n",
      "2022-08-17 18:10:09 | [trpo_pendulum] epoch #517 | Time 325.58 s\n",
      "2022-08-17 18:10:09 | [trpo_pendulum] epoch #517 | EpochTime 0.74 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -510.537\n",
      "Evaluation/AverageReturn              -1094.6\n",
      "Evaluation/Iteration                    517\n",
      "Evaluation/MaxReturn                  -1037.33\n",
      "Evaluation/MinReturn                  -1164.9\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     49.8355\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.63161\n",
      "GaussianMLPPolicy/KL                      0.0077011\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               8.87002\n",
      "GaussianMLPPolicy/LossBefore             10.485\n",
      "GaussianMLPPolicy/dLoss                   1.615\n",
      "GaussianMLPValueFunction/LossAfter        6.34211\n",
      "GaussianMLPValueFunction/LossBefore       6.34532\n",
      "GaussianMLPValueFunction/dLoss            0.00320864\n",
      "TotalEnvSteps                        621600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:10 | [trpo_pendulum] epoch #518 | Saving snapshot...\n",
      "2022-08-17 18:10:10 | [trpo_pendulum] epoch #518 | Saved\n",
      "2022-08-17 18:10:10 | [trpo_pendulum] epoch #518 | Time 326.26 s\n",
      "2022-08-17 18:10:10 | [trpo_pendulum] epoch #518 | EpochTime 0.67 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -512.773\n",
      "Evaluation/AverageReturn              -1090.72\n",
      "Evaluation/Iteration                    518\n",
      "Evaluation/MaxReturn                  -1015.4\n",
      "Evaluation/MinReturn                  -1193.31\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     63.2913\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62473\n",
      "GaussianMLPPolicy/KL                      0.00689252\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               7.7091\n",
      "GaussianMLPPolicy/LossBefore             10.1333\n",
      "GaussianMLPPolicy/dLoss                   2.42422\n",
      "GaussianMLPValueFunction/LossAfter        6.39909\n",
      "GaussianMLPValueFunction/LossBefore       6.39971\n",
      "GaussianMLPValueFunction/dLoss            0.000617981\n",
      "TotalEnvSteps                        622800\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:10:11 | [trpo_pendulum] epoch #519 | Saving snapshot...\n",
      "2022-08-17 18:10:11 | [trpo_pendulum] epoch #519 | Saved\n",
      "2022-08-17 18:10:11 | [trpo_pendulum] epoch #519 | Time 326.95 s\n",
      "2022-08-17 18:10:11 | [trpo_pendulum] epoch #519 | EpochTime 0.69 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -438.041\n",
      "Evaluation/AverageReturn              -1033.64\n",
      "Evaluation/Iteration                    519\n",
      "Evaluation/MaxReturn                   -949.278\n",
      "Evaluation/MinReturn                  -1113.23\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     53.7326\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62268\n",
      "GaussianMLPPolicy/KL                      0.00990924\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              10.5418\n",
      "GaussianMLPPolicy/LossBefore             11.6002\n",
      "GaussianMLPPolicy/dLoss                   1.05839\n",
      "GaussianMLPValueFunction/LossAfter        6.32977\n",
      "GaussianMLPValueFunction/LossBefore       6.33266\n",
      "GaussianMLPValueFunction/dLoss            0.00289488\n",
      "TotalEnvSteps                        624000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:11 | [trpo_pendulum] epoch #520 | Saving snapshot...\n",
      "2022-08-17 18:10:11 | [trpo_pendulum] epoch #520 | Saved\n",
      "2022-08-17 18:10:11 | [trpo_pendulum] epoch #520 | Time 327.61 s\n",
      "2022-08-17 18:10:11 | [trpo_pendulum] epoch #520 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -419.588\n",
      "Evaluation/AverageReturn               -978.172\n",
      "Evaluation/Iteration                    520\n",
      "Evaluation/MaxReturn                   -789.414\n",
      "Evaluation/MinReturn                  -1056.89\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    106.419\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62318\n",
      "GaussianMLPPolicy/KL                      0.00747094\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.866506\n",
      "GaussianMLPPolicy/LossBefore              2.38748\n",
      "GaussianMLPPolicy/dLoss                   1.52097\n",
      "GaussianMLPValueFunction/LossAfter        6.32658\n",
      "GaussianMLPValueFunction/LossBefore       6.32992\n",
      "GaussianMLPValueFunction/dLoss            0.00333643\n",
      "TotalEnvSteps                        625200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:12 | [trpo_pendulum] epoch #521 | Saving snapshot...\n",
      "2022-08-17 18:10:12 | [trpo_pendulum] epoch #521 | Saved\n",
      "2022-08-17 18:10:12 | [trpo_pendulum] epoch #521 | Time 328.31 s\n",
      "2022-08-17 18:10:12 | [trpo_pendulum] epoch #521 | EpochTime 0.70 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -466.807\n",
      "Evaluation/AverageReturn              -1009.09\n",
      "Evaluation/Iteration                    521\n",
      "Evaluation/MaxReturn                   -870.479\n",
      "Evaluation/MinReturn                  -1114.91\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     81.34\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.63356\n",
      "GaussianMLPPolicy/KL                      0.00689001\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -1.367\n",
      "GaussianMLPPolicy/LossBefore              1.0038\n",
      "GaussianMLPPolicy/dLoss                   2.3708\n",
      "GaussianMLPValueFunction/LossAfter        6.32634\n",
      "GaussianMLPValueFunction/LossBefore       6.3299\n",
      "GaussianMLPValueFunction/dLoss            0.00356197\n",
      "TotalEnvSteps                        626400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:13 | [trpo_pendulum] epoch #522 | Saving snapshot...\n",
      "2022-08-17 18:10:13 | [trpo_pendulum] epoch #522 | Saved\n",
      "2022-08-17 18:10:13 | [trpo_pendulum] epoch #522 | Time 329.01 s\n",
      "2022-08-17 18:10:13 | [trpo_pendulum] epoch #522 | EpochTime 0.70 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -411.22\n",
      "Evaluation/AverageReturn               -960.573\n",
      "Evaluation/Iteration                    522\n",
      "Evaluation/MaxReturn                   -754.283\n",
      "Evaluation/MinReturn                  -1071.1\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    111.113\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.63339\n",
      "GaussianMLPPolicy/KL                      0.00644613\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -2.94945\n",
      "GaussianMLPPolicy/LossBefore             -1.40204\n",
      "GaussianMLPPolicy/dLoss                   1.54741\n",
      "GaussianMLPValueFunction/LossAfter        6.23914\n",
      "GaussianMLPValueFunction/LossBefore       6.24786\n",
      "GaussianMLPValueFunction/dLoss            0.00872898\n",
      "TotalEnvSteps                        627600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:13 | [trpo_pendulum] epoch #523 | Saving snapshot...\n",
      "2022-08-17 18:10:13 | [trpo_pendulum] epoch #523 | Saved\n",
      "2022-08-17 18:10:13 | [trpo_pendulum] epoch #523 | Time 329.67 s\n",
      "2022-08-17 18:10:13 | [trpo_pendulum] epoch #523 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -459.085\n",
      "Evaluation/AverageReturn              -1009.03\n",
      "Evaluation/Iteration                    523\n",
      "Evaluation/MaxReturn                   -926.609\n",
      "Evaluation/MinReturn                  -1038.77\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     38.5351\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.63596\n",
      "GaussianMLPPolicy/KL                      0.00915042\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               1.88801\n",
      "GaussianMLPPolicy/LossBefore              3.14263\n",
      "GaussianMLPPolicy/dLoss                   1.25462\n",
      "GaussianMLPValueFunction/LossAfter        6.26014\n",
      "GaussianMLPValueFunction/LossBefore       6.26423\n",
      "GaussianMLPValueFunction/dLoss            0.00408697\n",
      "TotalEnvSteps                        628800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:14 | [trpo_pendulum] epoch #524 | Saving snapshot...\n",
      "2022-08-17 18:10:14 | [trpo_pendulum] epoch #524 | Saved\n",
      "2022-08-17 18:10:14 | [trpo_pendulum] epoch #524 | Time 330.31 s\n",
      "2022-08-17 18:10:14 | [trpo_pendulum] epoch #524 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -397.437\n",
      "Evaluation/AverageReturn               -911.88\n",
      "Evaluation/Iteration                    524\n",
      "Evaluation/MaxReturn                   -773.344\n",
      "Evaluation/MinReturn                  -1075.17\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     89.8165\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.61075\n",
      "GaussianMLPPolicy/KL                      0.00710651\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -8.81849\n",
      "GaussianMLPPolicy/LossBefore             -7.15232\n",
      "GaussianMLPPolicy/dLoss                   1.66618\n",
      "GaussianMLPValueFunction/LossAfter        6.26142\n",
      "GaussianMLPValueFunction/LossBefore       6.26744\n",
      "GaussianMLPValueFunction/dLoss            0.00602102\n",
      "TotalEnvSteps                        630000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:15 | [trpo_pendulum] epoch #525 | Saving snapshot...\n",
      "2022-08-17 18:10:15 | [trpo_pendulum] epoch #525 | Saved\n",
      "2022-08-17 18:10:15 | [trpo_pendulum] epoch #525 | Time 330.95 s\n",
      "2022-08-17 18:10:15 | [trpo_pendulum] epoch #525 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -660.57\n",
      "Evaluation/AverageReturn              -1513.03\n",
      "Evaluation/Iteration                    525\n",
      "Evaluation/MaxReturn                  -1502.88\n",
      "Evaluation/MinReturn                  -1529.5\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      8.57383\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.63614\n",
      "GaussianMLPPolicy/KL                      0.00812061\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              76.8887\n",
      "GaussianMLPPolicy/LossBefore             78.0398\n",
      "GaussianMLPPolicy/dLoss                   1.1511\n",
      "GaussianMLPValueFunction/LossAfter        7.0243\n",
      "GaussianMLPValueFunction/LossBefore       7.2537\n",
      "GaussianMLPValueFunction/dLoss            0.229399\n",
      "TotalEnvSteps                        631200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:15 | [trpo_pendulum] epoch #526 | Saving snapshot...\n",
      "2022-08-17 18:10:15 | [trpo_pendulum] epoch #526 | Saved\n",
      "2022-08-17 18:10:15 | [trpo_pendulum] epoch #526 | Time 331.60 s\n",
      "2022-08-17 18:10:15 | [trpo_pendulum] epoch #526 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -676.907\n",
      "Evaluation/AverageReturn              -1563.91\n",
      "Evaluation/Iteration                    526\n",
      "Evaluation/MaxReturn                  -1503\n",
      "Evaluation/MinReturn                  -1644.9\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     50.2276\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.62674\n",
      "GaussianMLPPolicy/KL                      0.00975253\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              83.4988\n",
      "GaussianMLPPolicy/LossBefore             86.3733\n",
      "GaussianMLPPolicy/dLoss                   2.87453\n",
      "GaussianMLPValueFunction/LossAfter        7.13491\n",
      "GaussianMLPValueFunction/LossBefore       7.27931\n",
      "GaussianMLPValueFunction/dLoss            0.144403\n",
      "TotalEnvSteps                        632400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:16 | [trpo_pendulum] epoch #527 | Saving snapshot...\n",
      "2022-08-17 18:10:16 | [trpo_pendulum] epoch #527 | Saved\n",
      "2022-08-17 18:10:16 | [trpo_pendulum] epoch #527 | Time 332.24 s\n",
      "2022-08-17 18:10:16 | [trpo_pendulum] epoch #527 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -212.391\n",
      "Evaluation/AverageReturn               -665.554\n",
      "Evaluation/Iteration                    527\n",
      "Evaluation/MaxReturn                   -396.099\n",
      "Evaluation/MinReturn                   -863.096\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    160.118\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.61144\n",
      "GaussianMLPPolicy/KL                      0.00718585\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -32.6574\n",
      "GaussianMLPPolicy/LossBefore            -30.7523\n",
      "GaussianMLPPolicy/dLoss                   1.90515\n",
      "GaussianMLPValueFunction/LossAfter        6.35453\n",
      "GaussianMLPValueFunction/LossBefore       6.36162\n",
      "GaussianMLPValueFunction/dLoss            0.00709295\n",
      "TotalEnvSteps                        633600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:17 | [trpo_pendulum] epoch #528 | Saving snapshot...\n",
      "2022-08-17 18:10:17 | [trpo_pendulum] epoch #528 | Saved\n",
      "2022-08-17 18:10:17 | [trpo_pendulum] epoch #528 | Time 332.92 s\n",
      "2022-08-17 18:10:17 | [trpo_pendulum] epoch #528 | EpochTime 0.68 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -468.13\n",
      "Evaluation/AverageReturn              -1108.14\n",
      "Evaluation/Iteration                    528\n",
      "Evaluation/MaxReturn                  -1061.82\n",
      "Evaluation/MinReturn                  -1133.01\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     23.4968\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.59699\n",
      "GaussianMLPPolicy/KL                      0.00708366\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              19.5717\n",
      "GaussianMLPPolicy/LossBefore             21.683\n",
      "GaussianMLPPolicy/dLoss                   2.11125\n",
      "GaussianMLPValueFunction/LossAfter        6.33481\n",
      "GaussianMLPValueFunction/LossBefore       6.34094\n",
      "GaussianMLPValueFunction/dLoss            0.00612688\n",
      "TotalEnvSteps                        634800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:17 | [trpo_pendulum] epoch #529 | Saving snapshot...\n",
      "2022-08-17 18:10:17 | [trpo_pendulum] epoch #529 | Saved\n",
      "2022-08-17 18:10:17 | [trpo_pendulum] epoch #529 | Time 333.54 s\n",
      "2022-08-17 18:10:17 | [trpo_pendulum] epoch #529 | EpochTime 0.62 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -457.512\n",
      "Evaluation/AverageReturn              -1078.48\n",
      "Evaluation/Iteration                    529\n",
      "Evaluation/MaxReturn                   -744.555\n",
      "Evaluation/MinReturn                  -1408.09\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    207.725\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.58\n",
      "GaussianMLPPolicy/KL                      0.00867666\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              15.1297\n",
      "GaussianMLPPolicy/LossBefore             17.6621\n",
      "GaussianMLPPolicy/dLoss                   2.53241\n",
      "GaussianMLPValueFunction/LossAfter        6.46151\n",
      "GaussianMLPValueFunction/LossBefore       6.4617\n",
      "GaussianMLPValueFunction/dLoss            0.000189781\n",
      "TotalEnvSteps                        636000\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:10:18 | [trpo_pendulum] epoch #530 | Saving snapshot...\n",
      "2022-08-17 18:10:18 | [trpo_pendulum] epoch #530 | Saved\n",
      "2022-08-17 18:10:18 | [trpo_pendulum] epoch #530 | Time 334.17 s\n",
      "2022-08-17 18:10:18 | [trpo_pendulum] epoch #530 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -665.191\n",
      "Evaluation/AverageReturn              -1524.63\n",
      "Evaluation/Iteration                    530\n",
      "Evaluation/MaxReturn                  -1517.62\n",
      "Evaluation/MinReturn                  -1530.82\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      4.54515\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.63685\n",
      "GaussianMLPPolicy/KL                      0.0093164\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              75.1382\n",
      "GaussianMLPPolicy/LossBefore             77.1379\n",
      "GaussianMLPPolicy/dLoss                   1.99966\n",
      "GaussianMLPValueFunction/LossAfter        6.91672\n",
      "GaussianMLPValueFunction/LossBefore       6.97753\n",
      "GaussianMLPValueFunction/dLoss            0.0608044\n",
      "TotalEnvSteps                        637200\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:10:19 | [trpo_pendulum] epoch #531 | Saving snapshot...\n",
      "2022-08-17 18:10:19 | [trpo_pendulum] epoch #531 | Saved\n",
      "2022-08-17 18:10:19 | [trpo_pendulum] epoch #531 | Time 334.80 s\n",
      "2022-08-17 18:10:19 | [trpo_pendulum] epoch #531 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -527.438\n",
      "Evaluation/AverageReturn              -1314.15\n",
      "Evaluation/Iteration                    531\n",
      "Evaluation/MaxReturn                  -1125.36\n",
      "Evaluation/MinReturn                  -1443.3\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    102.35\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.65264\n",
      "GaussianMLPPolicy/KL                      0.00634875\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              51.6072\n",
      "GaussianMLPPolicy/LossBefore             54.1655\n",
      "GaussianMLPPolicy/dLoss                   2.55827\n",
      "GaussianMLPValueFunction/LossAfter        6.63202\n",
      "GaussianMLPValueFunction/LossBefore       6.63932\n",
      "GaussianMLPValueFunction/dLoss            0.00729656\n",
      "TotalEnvSteps                        638400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:19 | [trpo_pendulum] epoch #532 | Saving snapshot...\n",
      "2022-08-17 18:10:19 | [trpo_pendulum] epoch #532 | Saved\n",
      "2022-08-17 18:10:19 | [trpo_pendulum] epoch #532 | Time 335.45 s\n",
      "2022-08-17 18:10:19 | [trpo_pendulum] epoch #532 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -561.802\n",
      "Evaluation/AverageReturn              -1385.55\n",
      "Evaluation/Iteration                    532\n",
      "Evaluation/MaxReturn                  -1131.58\n",
      "Evaluation/MinReturn                  -1508.98\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    126.715\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.64819\n",
      "GaussianMLPPolicy/KL                      0.00670951\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              59.7752\n",
      "GaussianMLPPolicy/LossBefore             62.3206\n",
      "GaussianMLPPolicy/dLoss                   2.54541\n",
      "GaussianMLPValueFunction/LossAfter        6.71826\n",
      "GaussianMLPValueFunction/LossBefore       6.73187\n",
      "GaussianMLPValueFunction/dLoss            0.0136161\n",
      "TotalEnvSteps                        639600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:20 | [trpo_pendulum] epoch #533 | Saving snapshot...\n",
      "2022-08-17 18:10:20 | [trpo_pendulum] epoch #533 | Saved\n",
      "2022-08-17 18:10:20 | [trpo_pendulum] epoch #533 | Time 336.10 s\n",
      "2022-08-17 18:10:20 | [trpo_pendulum] epoch #533 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -550.184\n",
      "Evaluation/AverageReturn              -1355.33\n",
      "Evaluation/Iteration                    533\n",
      "Evaluation/MaxReturn                  -1303.81\n",
      "Evaluation/MinReturn                  -1460.47\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     51.8559\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.65974\n",
      "GaussianMLPPolicy/KL                      0.00665832\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              55.0844\n",
      "GaussianMLPPolicy/LossBefore             57.3806\n",
      "GaussianMLPPolicy/dLoss                   2.29628\n",
      "GaussianMLPValueFunction/LossAfter        6.63657\n",
      "GaussianMLPValueFunction/LossBefore       6.64229\n",
      "GaussianMLPValueFunction/dLoss            0.00571823\n",
      "TotalEnvSteps                        640800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:20 | [trpo_pendulum] epoch #534 | Saving snapshot...\n",
      "2022-08-17 18:10:21 | [trpo_pendulum] epoch #534 | Saved\n",
      "2022-08-17 18:10:21 | [trpo_pendulum] epoch #534 | Time 336.79 s\n",
      "2022-08-17 18:10:21 | [trpo_pendulum] epoch #534 | EpochTime 0.69 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -656.04\n",
      "Evaluation/AverageReturn              -1517.82\n",
      "Evaluation/Iteration                    534\n",
      "Evaluation/MaxReturn                  -1508.67\n",
      "Evaluation/MinReturn                  -1528.32\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      6.76817\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.67701\n",
      "GaussianMLPPolicy/KL                      0.00943428\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              73.7847\n",
      "GaussianMLPPolicy/LossBefore             74.7607\n",
      "GaussianMLPPolicy/dLoss                   0.975967\n",
      "GaussianMLPValueFunction/LossAfter        6.85332\n",
      "GaussianMLPValueFunction/LossBefore       6.88222\n",
      "GaussianMLPValueFunction/dLoss            0.0288997\n",
      "TotalEnvSteps                        642000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:21 | [trpo_pendulum] epoch #535 | Saving snapshot...\n",
      "2022-08-17 18:10:21 | [trpo_pendulum] epoch #535 | Saved\n",
      "2022-08-17 18:10:21 | [trpo_pendulum] epoch #535 | Time 337.42 s\n",
      "2022-08-17 18:10:21 | [trpo_pendulum] epoch #535 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -356.071\n",
      "Evaluation/AverageReturn               -936.372\n",
      "Evaluation/Iteration                    535\n",
      "Evaluation/MaxReturn                   -714.993\n",
      "Evaluation/MinReturn                  -1132.86\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    165.493\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.68397\n",
      "GaussianMLPPolicy/KL                      0.00911271\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.87283\n",
      "GaussianMLPPolicy/LossBefore              0.523197\n",
      "GaussianMLPPolicy/dLoss                   1.39603\n",
      "GaussianMLPValueFunction/LossAfter        6.34554\n",
      "GaussianMLPValueFunction/LossBefore       6.36564\n",
      "GaussianMLPValueFunction/dLoss            0.020102\n",
      "TotalEnvSteps                        643200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:22 | [trpo_pendulum] epoch #536 | Saving snapshot...\n",
      "2022-08-17 18:10:22 | [trpo_pendulum] epoch #536 | Saved\n",
      "2022-08-17 18:10:22 | [trpo_pendulum] epoch #536 | Time 338.06 s\n",
      "2022-08-17 18:10:22 | [trpo_pendulum] epoch #536 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -456.682\n",
      "Evaluation/AverageReturn              -1079.07\n",
      "Evaluation/Iteration                    536\n",
      "Evaluation/MaxReturn                  -1000.28\n",
      "Evaluation/MinReturn                  -1156.77\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     53.9993\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.71705\n",
      "GaussianMLPPolicy/KL                      0.00711102\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              11.7564\n",
      "GaussianMLPPolicy/LossBefore             13.2546\n",
      "GaussianMLPPolicy/dLoss                   1.49812\n",
      "GaussianMLPValueFunction/LossAfter        6.34116\n",
      "GaussianMLPValueFunction/LossBefore       6.35807\n",
      "GaussianMLPValueFunction/dLoss            0.0169096\n",
      "TotalEnvSteps                        644400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:22 | [trpo_pendulum] epoch #537 | Saving snapshot...\n",
      "2022-08-17 18:10:22 | [trpo_pendulum] epoch #537 | Saved\n",
      "2022-08-17 18:10:22 | [trpo_pendulum] epoch #537 | Time 338.72 s\n",
      "2022-08-17 18:10:22 | [trpo_pendulum] epoch #537 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -474.579\n",
      "Evaluation/AverageReturn              -1074.45\n",
      "Evaluation/Iteration                    537\n",
      "Evaluation/MaxReturn                   -905.195\n",
      "Evaluation/MinReturn                  -1165.82\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     88.1813\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.73108\n",
      "GaussianMLPPolicy/KL                      0.00682137\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               6.64967\n",
      "GaussianMLPPolicy/LossBefore              8.61953\n",
      "GaussianMLPPolicy/dLoss                   1.96986\n",
      "GaussianMLPValueFunction/LossAfter        6.29371\n",
      "GaussianMLPValueFunction/LossBefore       6.31215\n",
      "GaussianMLPValueFunction/dLoss            0.0184402\n",
      "TotalEnvSteps                        645600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:23 | [trpo_pendulum] epoch #538 | Saving snapshot...\n",
      "2022-08-17 18:10:23 | [trpo_pendulum] epoch #538 | Saved\n",
      "2022-08-17 18:10:23 | [trpo_pendulum] epoch #538 | Time 339.40 s\n",
      "2022-08-17 18:10:23 | [trpo_pendulum] epoch #538 | EpochTime 0.67 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -462.182\n",
      "Evaluation/AverageReturn              -1133.44\n",
      "Evaluation/Iteration                    538\n",
      "Evaluation/MaxReturn                  -1055.36\n",
      "Evaluation/MinReturn                  -1188.97\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     51.0838\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.73825\n",
      "GaussianMLPPolicy/KL                      0.00839463\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              22.6551\n",
      "GaussianMLPPolicy/LossBefore             24.2425\n",
      "GaussianMLPPolicy/dLoss                   1.58739\n",
      "GaussianMLPValueFunction/LossAfter        6.38381\n",
      "GaussianMLPValueFunction/LossBefore       6.38922\n",
      "GaussianMLPValueFunction/dLoss            0.00541544\n",
      "TotalEnvSteps                        646800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:24 | [trpo_pendulum] epoch #539 | Saving snapshot...\n",
      "2022-08-17 18:10:24 | [trpo_pendulum] epoch #539 | Saved\n",
      "2022-08-17 18:10:24 | [trpo_pendulum] epoch #539 | Time 340.08 s\n",
      "2022-08-17 18:10:24 | [trpo_pendulum] epoch #539 | EpochTime 0.68 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -658.111\n",
      "Evaluation/AverageReturn              -1518.77\n",
      "Evaluation/Iteration                    539\n",
      "Evaluation/MaxReturn                  -1512.05\n",
      "Evaluation/MinReturn                  -1526.4\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.25739\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.77862\n",
      "GaussianMLPPolicy/KL                      0.00742717\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              72.4116\n",
      "GaussianMLPPolicy/LossBefore             73.4589\n",
      "GaussianMLPPolicy/dLoss                   1.04729\n",
      "GaussianMLPValueFunction/LossAfter        6.87355\n",
      "GaussianMLPValueFunction/LossBefore       6.93467\n",
      "GaussianMLPValueFunction/dLoss            0.0611157\n",
      "TotalEnvSteps                        648000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:24 | [trpo_pendulum] epoch #540 | Saving snapshot...\n",
      "2022-08-17 18:10:24 | [trpo_pendulum] epoch #540 | Saved\n",
      "2022-08-17 18:10:24 | [trpo_pendulum] epoch #540 | Time 340.72 s\n",
      "2022-08-17 18:10:24 | [trpo_pendulum] epoch #540 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -544.734\n",
      "Evaluation/AverageReturn              -1291.37\n",
      "Evaluation/Iteration                    540\n",
      "Evaluation/MaxReturn                  -1216.08\n",
      "Evaluation/MinReturn                  -1339.53\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     38.0642\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.79023\n",
      "GaussianMLPPolicy/KL                      0.00661507\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              41.1296\n",
      "GaussianMLPPolicy/LossBefore             42.7008\n",
      "GaussianMLPPolicy/dLoss                   1.57114\n",
      "GaussianMLPValueFunction/LossAfter        6.50794\n",
      "GaussianMLPValueFunction/LossBefore       6.51084\n",
      "GaussianMLPValueFunction/dLoss            0.0028944\n",
      "TotalEnvSteps                        649200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:25 | [trpo_pendulum] epoch #541 | Saving snapshot...\n",
      "2022-08-17 18:10:25 | [trpo_pendulum] epoch #541 | Saved\n",
      "2022-08-17 18:10:25 | [trpo_pendulum] epoch #541 | Time 341.35 s\n",
      "2022-08-17 18:10:25 | [trpo_pendulum] epoch #541 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -547.689\n",
      "Evaluation/AverageReturn              -1325.64\n",
      "Evaluation/Iteration                    541\n",
      "Evaluation/MaxReturn                  -1296.09\n",
      "Evaluation/MinReturn                  -1342.68\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     14.2183\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.78654\n",
      "GaussianMLPPolicy/KL                      0.00931673\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              49.5389\n",
      "GaussianMLPPolicy/LossBefore             50.2953\n",
      "GaussianMLPPolicy/dLoss                   0.756393\n",
      "GaussianMLPValueFunction/LossAfter        6.59271\n",
      "GaussianMLPValueFunction/LossBefore       6.59712\n",
      "GaussianMLPValueFunction/dLoss            0.00441217\n",
      "TotalEnvSteps                        650400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:26 | [trpo_pendulum] epoch #542 | Saving snapshot...\n",
      "2022-08-17 18:10:26 | [trpo_pendulum] epoch #542 | Saved\n",
      "2022-08-17 18:10:26 | [trpo_pendulum] epoch #542 | Time 341.98 s\n",
      "2022-08-17 18:10:26 | [trpo_pendulum] epoch #542 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -431.644\n",
      "Evaluation/AverageReturn              -1078.57\n",
      "Evaluation/Iteration                    542\n",
      "Evaluation/MaxReturn                  -1017.38\n",
      "Evaluation/MinReturn                  -1214.58\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     65.3793\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.82454\n",
      "GaussianMLPPolicy/KL                      0.00816794\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              13.878\n",
      "GaussianMLPPolicy/LossBefore             16.1627\n",
      "GaussianMLPPolicy/dLoss                   2.28466\n",
      "GaussianMLPValueFunction/LossAfter        6.37739\n",
      "GaussianMLPValueFunction/LossBefore       6.3874\n",
      "GaussianMLPValueFunction/dLoss            0.0100169\n",
      "TotalEnvSteps                        651600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:26 | [trpo_pendulum] epoch #543 | Saving snapshot...\n",
      "2022-08-17 18:10:26 | [trpo_pendulum] epoch #543 | Saved\n",
      "2022-08-17 18:10:26 | [trpo_pendulum] epoch #543 | Time 342.61 s\n",
      "2022-08-17 18:10:26 | [trpo_pendulum] epoch #543 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -448.298\n",
      "Evaluation/AverageReturn              -1064.06\n",
      "Evaluation/Iteration                    543\n",
      "Evaluation/MaxReturn                   -913.995\n",
      "Evaluation/MinReturn                  -1303.61\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    117.121\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.82727\n",
      "GaussianMLPPolicy/KL                      0.00846377\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               8.09107\n",
      "GaussianMLPPolicy/LossBefore              9.56413\n",
      "GaussianMLPPolicy/dLoss                   1.47307\n",
      "GaussianMLPValueFunction/LossAfter        6.36812\n",
      "GaussianMLPValueFunction/LossBefore       6.37649\n",
      "GaussianMLPValueFunction/dLoss            0.0083704\n",
      "TotalEnvSteps                        652800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:27 | [trpo_pendulum] epoch #544 | Saving snapshot...\n",
      "2022-08-17 18:10:27 | [trpo_pendulum] epoch #544 | Saved\n",
      "2022-08-17 18:10:27 | [trpo_pendulum] epoch #544 | Time 343.25 s\n",
      "2022-08-17 18:10:27 | [trpo_pendulum] epoch #544 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -544.382\n",
      "Evaluation/AverageReturn              -1342.12\n",
      "Evaluation/Iteration                    544\n",
      "Evaluation/MaxReturn                  -1317.61\n",
      "Evaluation/MinReturn                  -1367.52\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     15.3619\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.80931\n",
      "GaussianMLPPolicy/KL                      0.00536022\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              52.2737\n",
      "GaussianMLPPolicy/LossBefore             53.4787\n",
      "GaussianMLPPolicy/dLoss                   1.20497\n",
      "GaussianMLPValueFunction/LossAfter        6.65234\n",
      "GaussianMLPValueFunction/LossBefore       6.66795\n",
      "GaussianMLPValueFunction/dLoss            0.0156069\n",
      "TotalEnvSteps                        654000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:28 | [trpo_pendulum] epoch #545 | Saving snapshot...\n",
      "2022-08-17 18:10:28 | [trpo_pendulum] epoch #545 | Saved\n",
      "2022-08-17 18:10:28 | [trpo_pendulum] epoch #545 | Time 343.90 s\n",
      "2022-08-17 18:10:28 | [trpo_pendulum] epoch #545 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -513.663\n",
      "Evaluation/AverageReturn              -1285.93\n",
      "Evaluation/Iteration                    545\n",
      "Evaluation/MaxReturn                  -1175.09\n",
      "Evaluation/MinReturn                  -1345.68\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     53.5083\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.78931\n",
      "GaussianMLPPolicy/KL                      0.00603104\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              44.9995\n",
      "GaussianMLPPolicy/LossBefore             46.4633\n",
      "GaussianMLPPolicy/dLoss                   1.46385\n",
      "GaussianMLPValueFunction/LossAfter        6.55957\n",
      "GaussianMLPValueFunction/LossBefore       6.56396\n",
      "GaussianMLPValueFunction/dLoss            0.00439119\n",
      "TotalEnvSteps                        655200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:28 | [trpo_pendulum] epoch #546 | Saving snapshot...\n",
      "2022-08-17 18:10:28 | [trpo_pendulum] epoch #546 | Saved\n",
      "2022-08-17 18:10:28 | [trpo_pendulum] epoch #546 | Time 344.55 s\n",
      "2022-08-17 18:10:28 | [trpo_pendulum] epoch #546 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -679.829\n",
      "Evaluation/AverageReturn              -1565.4\n",
      "Evaluation/Iteration                    546\n",
      "Evaluation/MaxReturn                  -1535.48\n",
      "Evaluation/MinReturn                  -1592.46\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     18.9111\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.79176\n",
      "GaussianMLPPolicy/KL                      0.00762296\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              75.0665\n",
      "GaussianMLPPolicy/LossBefore             76.0229\n",
      "GaussianMLPPolicy/dLoss                   0.956375\n",
      "GaussianMLPValueFunction/LossAfter        6.89384\n",
      "GaussianMLPValueFunction/LossBefore       6.95693\n",
      "GaussianMLPValueFunction/dLoss            0.0630946\n",
      "TotalEnvSteps                        656400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:29 | [trpo_pendulum] epoch #547 | Saving snapshot...\n",
      "2022-08-17 18:10:29 | [trpo_pendulum] epoch #547 | Saved\n",
      "2022-08-17 18:10:29 | [trpo_pendulum] epoch #547 | Time 345.21 s\n",
      "2022-08-17 18:10:29 | [trpo_pendulum] epoch #547 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -675.875\n",
      "Evaluation/AverageReturn              -1556.88\n",
      "Evaluation/Iteration                    547\n",
      "Evaluation/MaxReturn                  -1545.43\n",
      "Evaluation/MinReturn                  -1569.03\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      7.90699\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.78628\n",
      "GaussianMLPPolicy/KL                      0.00806998\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              72.3527\n",
      "GaussianMLPPolicy/LossBefore             73.8484\n",
      "GaussianMLPPolicy/dLoss                   1.49566\n",
      "GaussianMLPValueFunction/LossAfter        6.84819\n",
      "GaussianMLPValueFunction/LossBefore       6.87659\n",
      "GaussianMLPValueFunction/dLoss            0.0283942\n",
      "TotalEnvSteps                        657600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:30 | [trpo_pendulum] epoch #548 | Saving snapshot...\n",
      "2022-08-17 18:10:30 | [trpo_pendulum] epoch #548 | Saved\n",
      "2022-08-17 18:10:30 | [trpo_pendulum] epoch #548 | Time 345.88 s\n",
      "2022-08-17 18:10:30 | [trpo_pendulum] epoch #548 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -628.801\n",
      "Evaluation/AverageReturn              -1501.07\n",
      "Evaluation/Iteration                    548\n",
      "Evaluation/MaxReturn                  -1464.24\n",
      "Evaluation/MinReturn                  -1535.18\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     20.782\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.7947\n",
      "GaussianMLPPolicy/KL                      0.00928394\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              68.947\n",
      "GaussianMLPPolicy/LossBefore             70.3685\n",
      "GaussianMLPPolicy/dLoss                   1.42151\n",
      "GaussianMLPValueFunction/LossAfter        6.81098\n",
      "GaussianMLPValueFunction/LossBefore       6.82488\n",
      "GaussianMLPValueFunction/dLoss            0.0139012\n",
      "TotalEnvSteps                        658800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:30 | [trpo_pendulum] epoch #549 | Saving snapshot...\n",
      "2022-08-17 18:10:30 | [trpo_pendulum] epoch #549 | Saved\n",
      "2022-08-17 18:10:30 | [trpo_pendulum] epoch #549 | Time 346.52 s\n",
      "2022-08-17 18:10:30 | [trpo_pendulum] epoch #549 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -617.794\n",
      "Evaluation/AverageReturn              -1457.86\n",
      "Evaluation/Iteration                    549\n",
      "Evaluation/MaxReturn                  -1408.08\n",
      "Evaluation/MinReturn                  -1498.06\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     37.5593\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.78792\n",
      "GaussianMLPPolicy/KL                      0.00594617\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              62.2966\n",
      "GaussianMLPPolicy/LossBefore             62.3302\n",
      "GaussianMLPPolicy/dLoss                   0.0335922\n",
      "GaussianMLPValueFunction/LossAfter        6.73482\n",
      "GaussianMLPValueFunction/LossBefore       6.73895\n",
      "GaussianMLPValueFunction/dLoss            0.00413036\n",
      "TotalEnvSteps                        660000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:31 | [trpo_pendulum] epoch #550 | Saving snapshot...\n",
      "2022-08-17 18:10:31 | [trpo_pendulum] epoch #550 | Saved\n",
      "2022-08-17 18:10:31 | [trpo_pendulum] epoch #550 | Time 347.18 s\n",
      "2022-08-17 18:10:31 | [trpo_pendulum] epoch #550 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -639.92\n",
      "Evaluation/AverageReturn              -1467.91\n",
      "Evaluation/Iteration                    550\n",
      "Evaluation/MaxReturn                  -1355.86\n",
      "Evaluation/MinReturn                  -1573.18\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     88.0579\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.80281\n",
      "GaussianMLPPolicy/KL                      0.00690158\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              55.5329\n",
      "GaussianMLPPolicy/LossBefore             57.9836\n",
      "GaussianMLPPolicy/dLoss                   2.45073\n",
      "GaussianMLPValueFunction/LossAfter        6.69442\n",
      "GaussianMLPValueFunction/LossBefore       6.69724\n",
      "GaussianMLPValueFunction/dLoss            0.00281477\n",
      "TotalEnvSteps                        661200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:32 | [trpo_pendulum] epoch #551 | Saving snapshot...\n",
      "2022-08-17 18:10:32 | [trpo_pendulum] epoch #551 | Saved\n",
      "2022-08-17 18:10:32 | [trpo_pendulum] epoch #551 | Time 347.82 s\n",
      "2022-08-17 18:10:32 | [trpo_pendulum] epoch #551 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -670.504\n",
      "Evaluation/AverageReturn              -1515.94\n",
      "Evaluation/Iteration                    551\n",
      "Evaluation/MaxReturn                  -1420.27\n",
      "Evaluation/MinReturn                  -1562.22\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     47.7002\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.79472\n",
      "GaussianMLPPolicy/KL                      0.0090231\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              59.704\n",
      "GaussianMLPPolicy/LossBefore             63.2772\n",
      "GaussianMLPPolicy/dLoss                   3.57315\n",
      "GaussianMLPValueFunction/LossAfter        6.75113\n",
      "GaussianMLPValueFunction/LossBefore       6.75563\n",
      "GaussianMLPValueFunction/dLoss            0.00449657\n",
      "TotalEnvSteps                        662400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:32 | [trpo_pendulum] epoch #552 | Saving snapshot...\n",
      "2022-08-17 18:10:32 | [trpo_pendulum] epoch #552 | Saved\n",
      "2022-08-17 18:10:32 | [trpo_pendulum] epoch #552 | Time 348.47 s\n",
      "2022-08-17 18:10:32 | [trpo_pendulum] epoch #552 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -673.601\n",
      "Evaluation/AverageReturn              -1517.58\n",
      "Evaluation/Iteration                    552\n",
      "Evaluation/MaxReturn                  -1361.99\n",
      "Evaluation/MinReturn                  -1609.71\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     84.2309\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.8059\n",
      "GaussianMLPPolicy/KL                      0.00674311\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              61.1408\n",
      "GaussianMLPPolicy/LossBefore             63.1795\n",
      "GaussianMLPPolicy/dLoss                   2.03863\n",
      "GaussianMLPValueFunction/LossAfter        6.76435\n",
      "GaussianMLPValueFunction/LossBefore       6.76874\n",
      "GaussianMLPValueFunction/dLoss            0.00438976\n",
      "TotalEnvSteps                        663600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:33 | [trpo_pendulum] epoch #553 | Saving snapshot...\n",
      "2022-08-17 18:10:33 | [trpo_pendulum] epoch #553 | Saved\n",
      "2022-08-17 18:10:33 | [trpo_pendulum] epoch #553 | Time 349.14 s\n",
      "2022-08-17 18:10:33 | [trpo_pendulum] epoch #553 | EpochTime 0.67 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -555.248\n",
      "Evaluation/AverageReturn              -1354.07\n",
      "Evaluation/Iteration                    553\n",
      "Evaluation/MaxReturn                  -1309.58\n",
      "Evaluation/MinReturn                  -1402.46\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     33.3141\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.80494\n",
      "GaussianMLPPolicy/KL                      0.00578046\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              43.2371\n",
      "GaussianMLPPolicy/LossBefore             45.0164\n",
      "GaussianMLPPolicy/dLoss                   1.77929\n",
      "GaussianMLPValueFunction/LossAfter        6.57126\n",
      "GaussianMLPValueFunction/LossBefore       6.58294\n",
      "GaussianMLPValueFunction/dLoss            0.011683\n",
      "TotalEnvSteps                        664800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:33 | [trpo_pendulum] epoch #554 | Saving snapshot...\n",
      "2022-08-17 18:10:34 | [trpo_pendulum] epoch #554 | Saved\n",
      "2022-08-17 18:10:34 | [trpo_pendulum] epoch #554 | Time 349.79 s\n",
      "2022-08-17 18:10:34 | [trpo_pendulum] epoch #554 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -557.803\n",
      "Evaluation/AverageReturn              -1380.07\n",
      "Evaluation/Iteration                    554\n",
      "Evaluation/MaxReturn                  -1358.38\n",
      "Evaluation/MinReturn                  -1409.23\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     22.0116\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.81999\n",
      "GaussianMLPPolicy/KL                      0.00748273\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              53.3932\n",
      "GaussianMLPPolicy/LossBefore             53.9277\n",
      "GaussianMLPPolicy/dLoss                   0.534489\n",
      "GaussianMLPValueFunction/LossAfter        6.687\n",
      "GaussianMLPValueFunction/LossBefore       6.68972\n",
      "GaussianMLPValueFunction/dLoss            0.00272512\n",
      "TotalEnvSteps                        666000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:34 | [trpo_pendulum] epoch #555 | Saving snapshot...\n",
      "2022-08-17 18:10:34 | [trpo_pendulum] epoch #555 | Saved\n",
      "2022-08-17 18:10:34 | [trpo_pendulum] epoch #555 | Time 350.41 s\n",
      "2022-08-17 18:10:34 | [trpo_pendulum] epoch #555 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -584.96\n",
      "Evaluation/AverageReturn              -1437.87\n",
      "Evaluation/Iteration                    555\n",
      "Evaluation/MaxReturn                  -1367.69\n",
      "Evaluation/MinReturn                  -1495.64\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     40.4582\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.82881\n",
      "GaussianMLPPolicy/KL                      0.00587917\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              58.64\n",
      "GaussianMLPPolicy/LossBefore             59.3267\n",
      "GaussianMLPPolicy/dLoss                   0.68668\n",
      "GaussianMLPValueFunction/LossAfter        6.71119\n",
      "GaussianMLPValueFunction/LossBefore       6.7153\n",
      "GaussianMLPValueFunction/dLoss            0.004107\n",
      "TotalEnvSteps                        667200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:35 | [trpo_pendulum] epoch #556 | Saving snapshot...\n",
      "2022-08-17 18:10:35 | [trpo_pendulum] epoch #556 | Saved\n",
      "2022-08-17 18:10:35 | [trpo_pendulum] epoch #556 | Time 351.06 s\n",
      "2022-08-17 18:10:35 | [trpo_pendulum] epoch #556 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -657.465\n",
      "Evaluation/AverageReturn              -1494.85\n",
      "Evaluation/Iteration                    556\n",
      "Evaluation/MaxReturn                  -1385.4\n",
      "Evaluation/MinReturn                  -1606.08\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     77.7054\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.84159\n",
      "GaussianMLPPolicy/KL                      0.00744466\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              55.5013\n",
      "GaussianMLPPolicy/LossBefore             58.8304\n",
      "GaussianMLPPolicy/dLoss                   3.32911\n",
      "GaussianMLPValueFunction/LossAfter        6.73202\n",
      "GaussianMLPValueFunction/LossBefore       6.73585\n",
      "GaussianMLPValueFunction/dLoss            0.00383091\n",
      "TotalEnvSteps                        668400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:35 | [trpo_pendulum] epoch #557 | Saving snapshot...\n",
      "2022-08-17 18:10:35 | [trpo_pendulum] epoch #557 | Saved\n",
      "2022-08-17 18:10:35 | [trpo_pendulum] epoch #557 | Time 351.68 s\n",
      "2022-08-17 18:10:35 | [trpo_pendulum] epoch #557 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -533.778\n",
      "Evaluation/AverageReturn              -1299.05\n",
      "Evaluation/Iteration                    557\n",
      "Evaluation/MaxReturn                  -1217.46\n",
      "Evaluation/MinReturn                  -1343.51\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     47.2733\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.84291\n",
      "GaussianMLPPolicy/KL                      0.00906056\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              36.1144\n",
      "GaussianMLPPolicy/LossBefore             36.2636\n",
      "GaussianMLPPolicy/dLoss                   0.149235\n",
      "GaussianMLPValueFunction/LossAfter        6.54082\n",
      "GaussianMLPValueFunction/LossBefore       6.5551\n",
      "GaussianMLPValueFunction/dLoss            0.0142856\n",
      "TotalEnvSteps                        669600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:36 | [trpo_pendulum] epoch #558 | Saving snapshot...\n",
      "2022-08-17 18:10:36 | [trpo_pendulum] epoch #558 | Saved\n",
      "2022-08-17 18:10:36 | [trpo_pendulum] epoch #558 | Time 352.33 s\n",
      "2022-08-17 18:10:36 | [trpo_pendulum] epoch #558 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -515.26\n",
      "Evaluation/AverageReturn              -1253.66\n",
      "Evaluation/Iteration                    558\n",
      "Evaluation/MaxReturn                  -1187.31\n",
      "Evaluation/MinReturn                  -1351.6\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     55.3155\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.82952\n",
      "GaussianMLPPolicy/KL                      0.00725528\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              30.2316\n",
      "GaussianMLPPolicy/LossBefore             31.3554\n",
      "GaussianMLPPolicy/dLoss                   1.12382\n",
      "GaussianMLPValueFunction/LossAfter        6.52533\n",
      "GaussianMLPValueFunction/LossBefore       6.53483\n",
      "GaussianMLPValueFunction/dLoss            0.00950575\n",
      "TotalEnvSteps                        670800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:37 | [trpo_pendulum] epoch #559 | Saving snapshot...\n",
      "2022-08-17 18:10:37 | [trpo_pendulum] epoch #559 | Saved\n",
      "2022-08-17 18:10:37 | [trpo_pendulum] epoch #559 | Time 352.95 s\n",
      "2022-08-17 18:10:37 | [trpo_pendulum] epoch #559 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -497.629\n",
      "Evaluation/AverageReturn              -1204.25\n",
      "Evaluation/Iteration                    559\n",
      "Evaluation/MaxReturn                  -1122.31\n",
      "Evaluation/MinReturn                  -1316.45\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     60.1969\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.82389\n",
      "GaussianMLPPolicy/KL                      0.00841726\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              19.1428\n",
      "GaussianMLPPolicy/LossBefore             20.616\n",
      "GaussianMLPPolicy/dLoss                   1.47314\n",
      "GaussianMLPValueFunction/LossAfter        6.44827\n",
      "GaussianMLPValueFunction/LossBefore       6.4623\n",
      "GaussianMLPValueFunction/dLoss            0.01403\n",
      "TotalEnvSteps                        672000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:37 | [trpo_pendulum] epoch #560 | Saving snapshot...\n",
      "2022-08-17 18:10:37 | [trpo_pendulum] epoch #560 | Saved\n",
      "2022-08-17 18:10:37 | [trpo_pendulum] epoch #560 | Time 353.59 s\n",
      "2022-08-17 18:10:37 | [trpo_pendulum] epoch #560 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -488.226\n",
      "Evaluation/AverageReturn              -1176.93\n",
      "Evaluation/Iteration                    560\n",
      "Evaluation/MaxReturn                  -1060.48\n",
      "Evaluation/MinReturn                  -1241.28\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     55.8851\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.82063\n",
      "GaussianMLPPolicy/KL                      0.00541177\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              17.3748\n",
      "GaussianMLPPolicy/LossBefore             18.2106\n",
      "GaussianMLPPolicy/dLoss                   0.835716\n",
      "GaussianMLPValueFunction/LossAfter        6.43189\n",
      "GaussianMLPValueFunction/LossBefore       6.44082\n",
      "GaussianMLPValueFunction/dLoss            0.00893307\n",
      "TotalEnvSteps                        673200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:38 | [trpo_pendulum] epoch #561 | Saving snapshot...\n",
      "2022-08-17 18:10:38 | [trpo_pendulum] epoch #561 | Saved\n",
      "2022-08-17 18:10:38 | [trpo_pendulum] epoch #561 | Time 354.21 s\n",
      "2022-08-17 18:10:38 | [trpo_pendulum] epoch #561 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -497.596\n",
      "Evaluation/AverageReturn              -1223.24\n",
      "Evaluation/Iteration                    561\n",
      "Evaluation/MaxReturn                  -1030.11\n",
      "Evaluation/MinReturn                  -1346.18\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    125.736\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.8349\n",
      "GaussianMLPPolicy/KL                      0.00837202\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              23.938\n",
      "GaussianMLPPolicy/LossBefore             25.261\n",
      "GaussianMLPPolicy/dLoss                   1.32301\n",
      "GaussianMLPValueFunction/LossAfter        6.4978\n",
      "GaussianMLPValueFunction/LossBefore       6.49892\n",
      "GaussianMLPValueFunction/dLoss            0.00111151\n",
      "TotalEnvSteps                        674400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:39 | [trpo_pendulum] epoch #562 | Saving snapshot...\n",
      "2022-08-17 18:10:39 | [trpo_pendulum] epoch #562 | Saved\n",
      "2022-08-17 18:10:39 | [trpo_pendulum] epoch #562 | Time 354.84 s\n",
      "2022-08-17 18:10:39 | [trpo_pendulum] epoch #562 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -411.015\n",
      "Evaluation/AverageReturn              -1009.94\n",
      "Evaluation/Iteration                    562\n",
      "Evaluation/MaxReturn                   -941.542\n",
      "Evaluation/MinReturn                  -1050.42\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     41.921\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.81194\n",
      "GaussianMLPPolicy/KL                      0.00565266\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.06836\n",
      "GaussianMLPPolicy/LossBefore             -4.1962\n",
      "GaussianMLPPolicy/dLoss                   0.872159\n",
      "GaussianMLPValueFunction/LossAfter        6.34558\n",
      "GaussianMLPValueFunction/LossBefore       6.3615\n",
      "GaussianMLPValueFunction/dLoss            0.0159202\n",
      "TotalEnvSteps                        675600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:39 | [trpo_pendulum] epoch #563 | Saving snapshot...\n",
      "2022-08-17 18:10:39 | [trpo_pendulum] epoch #563 | Saved\n",
      "2022-08-17 18:10:39 | [trpo_pendulum] epoch #563 | Time 355.46 s\n",
      "2022-08-17 18:10:39 | [trpo_pendulum] epoch #563 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -510.351\n",
      "Evaluation/AverageReturn              -1240.04\n",
      "Evaluation/Iteration                    563\n",
      "Evaluation/MaxReturn                  -1194.6\n",
      "Evaluation/MinReturn                  -1302.1\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     41.5745\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.8186\n",
      "GaussianMLPPolicy/KL                      0.00917504\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              23.795\n",
      "GaussianMLPPolicy/LossBefore             25.4659\n",
      "GaussianMLPPolicy/dLoss                   1.67087\n",
      "GaussianMLPValueFunction/LossAfter        6.38485\n",
      "GaussianMLPValueFunction/LossBefore       6.38929\n",
      "GaussianMLPValueFunction/dLoss            0.00443411\n",
      "TotalEnvSteps                        676800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:40 | [trpo_pendulum] epoch #564 | Saving snapshot...\n",
      "2022-08-17 18:10:40 | [trpo_pendulum] epoch #564 | Saved\n",
      "2022-08-17 18:10:40 | [trpo_pendulum] epoch #564 | Time 356.10 s\n",
      "2022-08-17 18:10:40 | [trpo_pendulum] epoch #564 | EpochTime 0.63 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -490.681\n",
      "Evaluation/AverageReturn              -1190.23\n",
      "Evaluation/Iteration                    564\n",
      "Evaluation/MaxReturn                  -1031.45\n",
      "Evaluation/MinReturn                  -1384.26\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    158.496\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.8319\n",
      "GaussianMLPPolicy/KL                      0.00771533\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              17.7584\n",
      "GaussianMLPPolicy/LossBefore             19.065\n",
      "GaussianMLPPolicy/dLoss                   1.3066\n",
      "GaussianMLPValueFunction/LossAfter        6.46419\n",
      "GaussianMLPValueFunction/LossBefore       6.46485\n",
      "GaussianMLPValueFunction/dLoss            0.000659943\n",
      "TotalEnvSteps                        678000\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:10:40 | [trpo_pendulum] epoch #565 | Saving snapshot...\n",
      "2022-08-17 18:10:40 | [trpo_pendulum] epoch #565 | Saved\n",
      "2022-08-17 18:10:40 | [trpo_pendulum] epoch #565 | Time 356.73 s\n",
      "2022-08-17 18:10:40 | [trpo_pendulum] epoch #565 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -670.056\n",
      "Evaluation/AverageReturn              -1460.37\n",
      "Evaluation/Iteration                    565\n",
      "Evaluation/MaxReturn                  -1203.99\n",
      "Evaluation/MinReturn                  -1628.54\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    147.927\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.83659\n",
      "GaussianMLPPolicy/KL                      0.00649843\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              44.8334\n",
      "GaussianMLPPolicy/LossBefore             47.2834\n",
      "GaussianMLPPolicy/dLoss                   2.44999\n",
      "GaussianMLPValueFunction/LossAfter        6.74523\n",
      "GaussianMLPValueFunction/LossBefore       6.79994\n",
      "GaussianMLPValueFunction/dLoss            0.0547166\n",
      "TotalEnvSteps                        679200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:41 | [trpo_pendulum] epoch #566 | Saving snapshot...\n",
      "2022-08-17 18:10:41 | [trpo_pendulum] epoch #566 | Saved\n",
      "2022-08-17 18:10:41 | [trpo_pendulum] epoch #566 | Time 357.37 s\n",
      "2022-08-17 18:10:41 | [trpo_pendulum] epoch #566 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -485.814\n",
      "Evaluation/AverageReturn              -1195.74\n",
      "Evaluation/Iteration                    566\n",
      "Evaluation/MaxReturn                  -1008.19\n",
      "Evaluation/MinReturn                  -1358.51\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    153.163\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.82749\n",
      "GaussianMLPPolicy/KL                      0.00953678\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              18.4791\n",
      "GaussianMLPPolicy/LossBefore             20.1296\n",
      "GaussianMLPPolicy/dLoss                   1.65047\n",
      "GaussianMLPValueFunction/LossAfter        6.49128\n",
      "GaussianMLPValueFunction/LossBefore       6.49229\n",
      "GaussianMLPValueFunction/dLoss            0.00101185\n",
      "TotalEnvSteps                        680400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:42 | [trpo_pendulum] epoch #567 | Saving snapshot...\n",
      "2022-08-17 18:10:42 | [trpo_pendulum] epoch #567 | Saved\n",
      "2022-08-17 18:10:42 | [trpo_pendulum] epoch #567 | Time 358.00 s\n",
      "2022-08-17 18:10:42 | [trpo_pendulum] epoch #567 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -472.915\n",
      "Evaluation/AverageReturn              -1122.08\n",
      "Evaluation/Iteration                    567\n",
      "Evaluation/MaxReturn                  -1033.7\n",
      "Evaluation/MinReturn                  -1314.1\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     96.3375\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.85108\n",
      "GaussianMLPPolicy/KL                      0.00963718\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               5.25153\n",
      "GaussianMLPPolicy/LossBefore              6.69288\n",
      "GaussianMLPPolicy/dLoss                   1.44134\n",
      "GaussianMLPValueFunction/LossAfter        6.38327\n",
      "GaussianMLPValueFunction/LossBefore       6.39276\n",
      "GaussianMLPValueFunction/dLoss            0.00949383\n",
      "TotalEnvSteps                        681600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:42 | [trpo_pendulum] epoch #568 | Saving snapshot...\n",
      "2022-08-17 18:10:42 | [trpo_pendulum] epoch #568 | Saved\n",
      "2022-08-17 18:10:42 | [trpo_pendulum] epoch #568 | Time 358.63 s\n",
      "2022-08-17 18:10:42 | [trpo_pendulum] epoch #568 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -468.26\n",
      "Evaluation/AverageReturn              -1118.74\n",
      "Evaluation/Iteration                    568\n",
      "Evaluation/MaxReturn                  -1031.3\n",
      "Evaluation/MinReturn                  -1328.34\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    113.157\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.85361\n",
      "GaussianMLPPolicy/KL                      0.00736476\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               5.20522\n",
      "GaussianMLPPolicy/LossBefore              6.79396\n",
      "GaussianMLPPolicy/dLoss                   1.58874\n",
      "GaussianMLPValueFunction/LossAfter        6.4024\n",
      "GaussianMLPValueFunction/LossBefore       6.40639\n",
      "GaussianMLPValueFunction/dLoss            0.00398827\n",
      "TotalEnvSteps                        682800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:43 | [trpo_pendulum] epoch #569 | Saving snapshot...\n",
      "2022-08-17 18:10:43 | [trpo_pendulum] epoch #569 | Saved\n",
      "2022-08-17 18:10:43 | [trpo_pendulum] epoch #569 | Time 359.27 s\n",
      "2022-08-17 18:10:43 | [trpo_pendulum] epoch #569 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -497.86\n",
      "Evaluation/AverageReturn              -1239.9\n",
      "Evaluation/Iteration                    569\n",
      "Evaluation/MaxReturn                  -1055.03\n",
      "Evaluation/MinReturn                  -1355.89\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    105.551\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.84926\n",
      "GaussianMLPPolicy/KL                      0.00722843\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              29.2568\n",
      "GaussianMLPPolicy/LossBefore             30.2036\n",
      "GaussianMLPPolicy/dLoss                   0.946827\n",
      "GaussianMLPValueFunction/LossAfter        6.53447\n",
      "GaussianMLPValueFunction/LossBefore       6.53865\n",
      "GaussianMLPValueFunction/dLoss            0.00418043\n",
      "TotalEnvSteps                        684000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:44 | [trpo_pendulum] epoch #570 | Saving snapshot...\n",
      "2022-08-17 18:10:44 | [trpo_pendulum] epoch #570 | Saved\n",
      "2022-08-17 18:10:44 | [trpo_pendulum] epoch #570 | Time 359.92 s\n",
      "2022-08-17 18:10:44 | [trpo_pendulum] epoch #570 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -402.804\n",
      "Evaluation/AverageReturn               -997.205\n",
      "Evaluation/Iteration                    570\n",
      "Evaluation/MaxReturn                   -797.998\n",
      "Evaluation/MinReturn                  -1082.55\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     91.8962\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.82242\n",
      "GaussianMLPPolicy/KL                      0.00879902\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -9.47858\n",
      "GaussianMLPPolicy/LossBefore             -8.71902\n",
      "GaussianMLPPolicy/dLoss                   0.759564\n",
      "GaussianMLPValueFunction/LossAfter        6.28502\n",
      "GaussianMLPValueFunction/LossBefore       6.30576\n",
      "GaussianMLPValueFunction/dLoss            0.0207386\n",
      "TotalEnvSteps                        685200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:44 | [trpo_pendulum] epoch #571 | Saving snapshot...\n",
      "2022-08-17 18:10:44 | [trpo_pendulum] epoch #571 | Saved\n",
      "2022-08-17 18:10:44 | [trpo_pendulum] epoch #571 | Time 360.54 s\n",
      "2022-08-17 18:10:44 | [trpo_pendulum] epoch #571 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -416.995\n",
      "Evaluation/AverageReturn               -992.411\n",
      "Evaluation/Iteration                    571\n",
      "Evaluation/MaxReturn                   -895.871\n",
      "Evaluation/MinReturn                  -1045.8\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     51.8972\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.86914\n",
      "GaussianMLPPolicy/KL                      0.00675017\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -12.8169\n",
      "GaussianMLPPolicy/LossBefore            -11.4837\n",
      "GaussianMLPPolicy/dLoss                   1.33318\n",
      "GaussianMLPValueFunction/LossAfter        6.32092\n",
      "GaussianMLPValueFunction/LossBefore       6.33161\n",
      "GaussianMLPValueFunction/dLoss            0.010695\n",
      "TotalEnvSteps                        686400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:45 | [trpo_pendulum] epoch #572 | Saving snapshot...\n",
      "2022-08-17 18:10:45 | [trpo_pendulum] epoch #572 | Saved\n",
      "2022-08-17 18:10:45 | [trpo_pendulum] epoch #572 | Time 361.25 s\n",
      "2022-08-17 18:10:45 | [trpo_pendulum] epoch #572 | EpochTime 0.70 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -553.812\n",
      "Evaluation/AverageReturn              -1256.15\n",
      "Evaluation/Iteration                    572\n",
      "Evaluation/MaxReturn                   -882.394\n",
      "Evaluation/MinReturn                  -1484.28\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    208.146\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.85427\n",
      "GaussianMLPPolicy/KL                      0.00887082\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              20.5721\n",
      "GaussianMLPPolicy/LossBefore             23.1843\n",
      "GaussianMLPPolicy/dLoss                   2.61218\n",
      "GaussianMLPValueFunction/LossAfter        6.57565\n",
      "GaussianMLPValueFunction/LossBefore       6.59187\n",
      "GaussianMLPValueFunction/dLoss            0.0162191\n",
      "TotalEnvSteps                        687600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:46 | [trpo_pendulum] epoch #573 | Saving snapshot...\n",
      "2022-08-17 18:10:46 | [trpo_pendulum] epoch #573 | Saved\n",
      "2022-08-17 18:10:46 | [trpo_pendulum] epoch #573 | Time 361.92 s\n",
      "2022-08-17 18:10:46 | [trpo_pendulum] epoch #573 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -631.835\n",
      "Evaluation/AverageReturn              -1471.99\n",
      "Evaluation/Iteration                    573\n",
      "Evaluation/MaxReturn                  -1454.89\n",
      "Evaluation/MinReturn                  -1488.85\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     12.0192\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.83323\n",
      "GaussianMLPPolicy/KL                      0.00737744\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              54.6218\n",
      "GaussianMLPPolicy/LossBefore             56.529\n",
      "GaussianMLPPolicy/dLoss                   1.90717\n",
      "GaussianMLPValueFunction/LossAfter        6.73816\n",
      "GaussianMLPValueFunction/LossBefore       6.78898\n",
      "GaussianMLPValueFunction/dLoss            0.0508151\n",
      "TotalEnvSteps                        688800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:46 | [trpo_pendulum] epoch #574 | Saving snapshot...\n",
      "2022-08-17 18:10:46 | [trpo_pendulum] epoch #574 | Saved\n",
      "2022-08-17 18:10:46 | [trpo_pendulum] epoch #574 | Time 362.55 s\n",
      "2022-08-17 18:10:46 | [trpo_pendulum] epoch #574 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -470.094\n",
      "Evaluation/AverageReturn              -1108.5\n",
      "Evaluation/Iteration                    574\n",
      "Evaluation/MaxReturn                   -841.763\n",
      "Evaluation/MinReturn                  -1353.81\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    200.859\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.84165\n",
      "GaussianMLPPolicy/KL                      0.00619185\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               2.08339\n",
      "GaussianMLPPolicy/LossBefore              3.4298\n",
      "GaussianMLPPolicy/dLoss                   1.34642\n",
      "GaussianMLPValueFunction/LossAfter        6.44931\n",
      "GaussianMLPValueFunction/LossBefore       6.45181\n",
      "GaussianMLPValueFunction/dLoss            0.00249815\n",
      "TotalEnvSteps                        690000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:47 | [trpo_pendulum] epoch #575 | Saving snapshot...\n",
      "2022-08-17 18:10:47 | [trpo_pendulum] epoch #575 | Saved\n",
      "2022-08-17 18:10:47 | [trpo_pendulum] epoch #575 | Time 363.19 s\n",
      "2022-08-17 18:10:47 | [trpo_pendulum] epoch #575 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -527.365\n",
      "Evaluation/AverageReturn              -1203.01\n",
      "Evaluation/Iteration                    575\n",
      "Evaluation/MaxReturn                  -1017.04\n",
      "Evaluation/MinReturn                  -1422.71\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    128.606\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.86689\n",
      "GaussianMLPPolicy/KL                      0.00843855\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              11.4703\n",
      "GaussianMLPPolicy/LossBefore             14.5023\n",
      "GaussianMLPPolicy/dLoss                   3.03198\n",
      "GaussianMLPValueFunction/LossAfter        6.41934\n",
      "GaussianMLPValueFunction/LossBefore       6.42295\n",
      "GaussianMLPValueFunction/dLoss            0.00360441\n",
      "TotalEnvSteps                        691200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:48 | [trpo_pendulum] epoch #576 | Saving snapshot...\n",
      "2022-08-17 18:10:48 | [trpo_pendulum] epoch #576 | Saved\n",
      "2022-08-17 18:10:48 | [trpo_pendulum] epoch #576 | Time 363.85 s\n",
      "2022-08-17 18:10:48 | [trpo_pendulum] epoch #576 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -430.295\n",
      "Evaluation/AverageReturn              -1025.45\n",
      "Evaluation/Iteration                    576\n",
      "Evaluation/MaxReturn                   -833.277\n",
      "Evaluation/MinReturn                  -1320.24\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    207.134\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.87812\n",
      "GaussianMLPPolicy/KL                      0.00598118\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -11.4142\n",
      "GaussianMLPPolicy/LossBefore             -7.10268\n",
      "GaussianMLPPolicy/dLoss                   4.31153\n",
      "GaussianMLPValueFunction/LossAfter        6.43101\n",
      "GaussianMLPValueFunction/LossBefore       6.43479\n",
      "GaussianMLPValueFunction/dLoss            0.00378084\n",
      "TotalEnvSteps                        692400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:48 | [trpo_pendulum] epoch #577 | Saving snapshot...\n",
      "2022-08-17 18:10:48 | [trpo_pendulum] epoch #577 | Saved\n",
      "2022-08-17 18:10:48 | [trpo_pendulum] epoch #577 | Time 364.48 s\n",
      "2022-08-17 18:10:48 | [trpo_pendulum] epoch #577 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -411.132\n",
      "Evaluation/AverageReturn               -976.492\n",
      "Evaluation/Iteration                    577\n",
      "Evaluation/MaxReturn                   -850.183\n",
      "Evaluation/MinReturn                  -1274.43\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    145.6\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.87746\n",
      "GaussianMLPPolicy/KL                      0.00911425\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -13.4823\n",
      "GaussianMLPPolicy/LossBefore            -12.6747\n",
      "GaussianMLPPolicy/dLoss                   0.80758\n",
      "GaussianMLPValueFunction/LossAfter        6.37741\n",
      "GaussianMLPValueFunction/LossBefore       6.38583\n",
      "GaussianMLPValueFunction/dLoss            0.00842142\n",
      "TotalEnvSteps                        693600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:49 | [trpo_pendulum] epoch #578 | Saving snapshot...\n",
      "2022-08-17 18:10:49 | [trpo_pendulum] epoch #578 | Saved\n",
      "2022-08-17 18:10:49 | [trpo_pendulum] epoch #578 | Time 365.14 s\n",
      "2022-08-17 18:10:49 | [trpo_pendulum] epoch #578 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -505.544\n",
      "Evaluation/AverageReturn              -1102.32\n",
      "Evaluation/Iteration                    578\n",
      "Evaluation/MaxReturn                  -1006.03\n",
      "Evaluation/MinReturn                  -1314.2\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    111.822\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.87229\n",
      "GaussianMLPPolicy/KL                      0.00771652\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -1.94639\n",
      "GaussianMLPPolicy/LossBefore             -0.702586\n",
      "GaussianMLPPolicy/dLoss                   1.24381\n",
      "GaussianMLPValueFunction/LossAfter        6.41218\n",
      "GaussianMLPValueFunction/LossBefore       6.41498\n",
      "GaussianMLPValueFunction/dLoss            0.00279284\n",
      "TotalEnvSteps                        694800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:49 | [trpo_pendulum] epoch #579 | Saving snapshot...\n",
      "2022-08-17 18:10:49 | [trpo_pendulum] epoch #579 | Saved\n",
      "2022-08-17 18:10:49 | [trpo_pendulum] epoch #579 | Time 365.77 s\n",
      "2022-08-17 18:10:49 | [trpo_pendulum] epoch #579 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -616.239\n",
      "Evaluation/AverageReturn              -1340.28\n",
      "Evaluation/Iteration                    579\n",
      "Evaluation/MaxReturn                  -1236.06\n",
      "Evaluation/MinReturn                  -1435.37\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     70.7348\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.87757\n",
      "GaussianMLPPolicy/KL                      0.00996439\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              27.4818\n",
      "GaussianMLPPolicy/LossBefore             32.3402\n",
      "GaussianMLPPolicy/dLoss                   4.85832\n",
      "GaussianMLPValueFunction/LossAfter        6.58232\n",
      "GaussianMLPValueFunction/LossBefore       6.59468\n",
      "GaussianMLPValueFunction/dLoss            0.0123606\n",
      "TotalEnvSteps                        696000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:50 | [trpo_pendulum] epoch #580 | Saving snapshot...\n",
      "2022-08-17 18:10:50 | [trpo_pendulum] epoch #580 | Saved\n",
      "2022-08-17 18:10:50 | [trpo_pendulum] epoch #580 | Time 366.43 s\n",
      "2022-08-17 18:10:50 | [trpo_pendulum] epoch #580 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -559.111\n",
      "Evaluation/AverageReturn              -1335.68\n",
      "Evaluation/Iteration                    580\n",
      "Evaluation/MaxReturn                  -1279.17\n",
      "Evaluation/MinReturn                  -1380.83\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     31.943\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.85346\n",
      "GaussianMLPPolicy/KL                      0.0059228\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              40.2272\n",
      "GaussianMLPPolicy/LossBefore             40.6258\n",
      "GaussianMLPPolicy/dLoss                   0.398582\n",
      "GaussianMLPValueFunction/LossAfter        6.56542\n",
      "GaussianMLPValueFunction/LossBefore       6.57299\n",
      "GaussianMLPValueFunction/dLoss            0.00756454\n",
      "TotalEnvSteps                        697200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:51 | [trpo_pendulum] epoch #581 | Saving snapshot...\n",
      "2022-08-17 18:10:51 | [trpo_pendulum] epoch #581 | Saved\n",
      "2022-08-17 18:10:51 | [trpo_pendulum] epoch #581 | Time 367.08 s\n",
      "2022-08-17 18:10:51 | [trpo_pendulum] epoch #581 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -424.886\n",
      "Evaluation/AverageReturn               -994.731\n",
      "Evaluation/Iteration                    581\n",
      "Evaluation/MaxReturn                   -887.391\n",
      "Evaluation/MinReturn                  -1170.39\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     97.7881\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.85534\n",
      "GaussianMLPPolicy/KL                      0.00889604\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -12.9963\n",
      "GaussianMLPPolicy/LossBefore            -11.9432\n",
      "GaussianMLPPolicy/dLoss                   1.05313\n",
      "GaussianMLPValueFunction/LossAfter        6.33715\n",
      "GaussianMLPValueFunction/LossBefore       6.35356\n",
      "GaussianMLPValueFunction/dLoss            0.0164089\n",
      "TotalEnvSteps                        698400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:51 | [trpo_pendulum] epoch #582 | Saving snapshot...\n",
      "2022-08-17 18:10:51 | [trpo_pendulum] epoch #582 | Saved\n",
      "2022-08-17 18:10:51 | [trpo_pendulum] epoch #582 | Time 367.70 s\n",
      "2022-08-17 18:10:51 | [trpo_pendulum] epoch #582 | EpochTime 0.62 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -464.357\n",
      "Evaluation/AverageReturn              -1176.69\n",
      "Evaluation/Iteration                    582\n",
      "Evaluation/MaxReturn                   -895.768\n",
      "Evaluation/MinReturn                  -1336.47\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    161.076\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.83832\n",
      "GaussianMLPPolicy/KL                      0.00689076\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              20.9221\n",
      "GaussianMLPPolicy/LossBefore             21.9527\n",
      "GaussianMLPPolicy/dLoss                   1.03068\n",
      "GaussianMLPValueFunction/LossAfter        6.45956\n",
      "GaussianMLPValueFunction/LossBefore       6.46005\n",
      "GaussianMLPValueFunction/dLoss            0.000488281\n",
      "TotalEnvSteps                        699600\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:10:52 | [trpo_pendulum] epoch #583 | Saving snapshot...\n",
      "2022-08-17 18:10:52 | [trpo_pendulum] epoch #583 | Saved\n",
      "2022-08-17 18:10:52 | [trpo_pendulum] epoch #583 | Time 368.36 s\n",
      "2022-08-17 18:10:52 | [trpo_pendulum] epoch #583 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -426.999\n",
      "Evaluation/AverageReturn              -1043.94\n",
      "Evaluation/Iteration                    583\n",
      "Evaluation/MaxReturn                  -1020.42\n",
      "Evaluation/MinReturn                  -1077.9\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     17.7194\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.83932\n",
      "GaussianMLPPolicy/KL                      0.00415264\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.146742\n",
      "GaussianMLPPolicy/LossBefore              0.317312\n",
      "GaussianMLPPolicy/dLoss                   0.464054\n",
      "GaussianMLPValueFunction/LossAfter        6.29484\n",
      "GaussianMLPValueFunction/LossBefore       6.30884\n",
      "GaussianMLPValueFunction/dLoss            0.0139952\n",
      "TotalEnvSteps                        700800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:53 | [trpo_pendulum] epoch #584 | Saving snapshot...\n",
      "2022-08-17 18:10:53 | [trpo_pendulum] epoch #584 | Saved\n",
      "2022-08-17 18:10:53 | [trpo_pendulum] epoch #584 | Time 368.99 s\n",
      "2022-08-17 18:10:53 | [trpo_pendulum] epoch #584 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -534.357\n",
      "Evaluation/AverageReturn              -1305.59\n",
      "Evaluation/Iteration                    584\n",
      "Evaluation/MaxReturn                  -1227.54\n",
      "Evaluation/MinReturn                  -1340.05\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     41.1933\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.87337\n",
      "GaussianMLPPolicy/KL                      0.0096465\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              38.5656\n",
      "GaussianMLPPolicy/LossBefore             38.7032\n",
      "GaussianMLPPolicy/dLoss                   0.137592\n",
      "GaussianMLPValueFunction/LossAfter        6.53278\n",
      "GaussianMLPValueFunction/LossBefore       6.54476\n",
      "GaussianMLPValueFunction/dLoss            0.0119786\n",
      "TotalEnvSteps                        702000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:10:53 | [trpo_pendulum] epoch #585 | Saving snapshot...\n",
      "2022-08-17 18:10:53 | [trpo_pendulum] epoch #585 | Saved\n",
      "2022-08-17 18:10:53 | [trpo_pendulum] epoch #585 | Time 369.63 s\n",
      "2022-08-17 18:10:53 | [trpo_pendulum] epoch #585 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -633.713\n",
      "Evaluation/AverageReturn              -1395.74\n",
      "Evaluation/Iteration                    585\n",
      "Evaluation/MaxReturn                  -1143.85\n",
      "Evaluation/MinReturn                  -1472.3\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    116.825\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.87505\n",
      "GaussianMLPPolicy/KL                      0.00662258\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              37.8488\n",
      "GaussianMLPPolicy/LossBefore             40.3271\n",
      "GaussianMLPPolicy/dLoss                   2.47826\n",
      "GaussianMLPValueFunction/LossAfter        6.66927\n",
      "GaussianMLPValueFunction/LossBefore       6.6988\n",
      "GaussianMLPValueFunction/dLoss            0.0295272\n",
      "TotalEnvSteps                        703200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:54 | [trpo_pendulum] epoch #586 | Saving snapshot...\n",
      "2022-08-17 18:10:54 | [trpo_pendulum] epoch #586 | Saved\n",
      "2022-08-17 18:10:54 | [trpo_pendulum] epoch #586 | Time 370.29 s\n",
      "2022-08-17 18:10:54 | [trpo_pendulum] epoch #586 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -586.649\n",
      "Evaluation/AverageReturn              -1285.94\n",
      "Evaluation/Iteration                    586\n",
      "Evaluation/MaxReturn                  -1224.53\n",
      "Evaluation/MinReturn                  -1398.44\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     57.7237\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.86212\n",
      "GaussianMLPPolicy/KL                      0.00699348\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              21.5567\n",
      "GaussianMLPPolicy/LossBefore             23.8162\n",
      "GaussianMLPPolicy/dLoss                   2.25949\n",
      "GaussianMLPValueFunction/LossAfter        6.46515\n",
      "GaussianMLPValueFunction/LossBefore       6.46632\n",
      "GaussianMLPValueFunction/dLoss            0.00117159\n",
      "TotalEnvSteps                        704400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:55 | [trpo_pendulum] epoch #587 | Saving snapshot...\n",
      "2022-08-17 18:10:55 | [trpo_pendulum] epoch #587 | Saved\n",
      "2022-08-17 18:10:55 | [trpo_pendulum] epoch #587 | Time 370.92 s\n",
      "2022-08-17 18:10:55 | [trpo_pendulum] epoch #587 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -618.937\n",
      "Evaluation/AverageReturn              -1355.83\n",
      "Evaluation/Iteration                    587\n",
      "Evaluation/MaxReturn                  -1229.89\n",
      "Evaluation/MinReturn                  -1480.1\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     83.2477\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.843\n",
      "GaussianMLPPolicy/KL                      0.00668604\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              30.568\n",
      "GaussianMLPPolicy/LossBefore             32.9718\n",
      "GaussianMLPPolicy/dLoss                   2.40381\n",
      "GaussianMLPValueFunction/LossAfter        6.59221\n",
      "GaussianMLPValueFunction/LossBefore       6.59745\n",
      "GaussianMLPValueFunction/dLoss            0.00524044\n",
      "TotalEnvSteps                        705600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:55 | [trpo_pendulum] epoch #588 | Saving snapshot...\n",
      "2022-08-17 18:10:55 | [trpo_pendulum] epoch #588 | Saved\n",
      "2022-08-17 18:10:55 | [trpo_pendulum] epoch #588 | Time 371.55 s\n",
      "2022-08-17 18:10:55 | [trpo_pendulum] epoch #588 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -498.931\n",
      "Evaluation/AverageReturn              -1209.16\n",
      "Evaluation/Iteration                    588\n",
      "Evaluation/MaxReturn                  -1135.96\n",
      "Evaluation/MinReturn                  -1323.91\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     57.8161\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.83229\n",
      "GaussianMLPPolicy/KL                      0.00636587\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              17.5374\n",
      "GaussianMLPPolicy/LossBefore             18.8853\n",
      "GaussianMLPPolicy/dLoss                   1.34787\n",
      "GaussianMLPValueFunction/LossAfter        6.36362\n",
      "GaussianMLPValueFunction/LossBefore       6.37639\n",
      "GaussianMLPValueFunction/dLoss            0.0127697\n",
      "TotalEnvSteps                        706800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:56 | [trpo_pendulum] epoch #589 | Saving snapshot...\n",
      "2022-08-17 18:10:56 | [trpo_pendulum] epoch #589 | Saved\n",
      "2022-08-17 18:10:56 | [trpo_pendulum] epoch #589 | Time 372.20 s\n",
      "2022-08-17 18:10:56 | [trpo_pendulum] epoch #589 | EpochTime 0.65 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -572.608\n",
      "Evaluation/AverageReturn              -1285.92\n",
      "Evaluation/Iteration                    589\n",
      "Evaluation/MaxReturn                  -1153.8\n",
      "Evaluation/MinReturn                  -1393.54\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     81.2\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.82809\n",
      "GaussianMLPPolicy/KL                      0.00715901\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              22.2483\n",
      "GaussianMLPPolicy/LossBefore             23.8792\n",
      "GaussianMLPPolicy/dLoss                   1.63093\n",
      "GaussianMLPValueFunction/LossAfter        6.45473\n",
      "GaussianMLPValueFunction/LossBefore       6.45564\n",
      "GaussianMLPValueFunction/dLoss            0.000903606\n",
      "TotalEnvSteps                        708000\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:10:57 | [trpo_pendulum] epoch #590 | Saving snapshot...\n",
      "2022-08-17 18:10:57 | [trpo_pendulum] epoch #590 | Saved\n",
      "2022-08-17 18:10:57 | [trpo_pendulum] epoch #590 | Time 372.90 s\n",
      "2022-08-17 18:10:57 | [trpo_pendulum] epoch #590 | EpochTime 0.69 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -517.867\n",
      "Evaluation/AverageReturn              -1281.45\n",
      "Evaluation/Iteration                    590\n",
      "Evaluation/MaxReturn                  -1224.05\n",
      "Evaluation/MinReturn                  -1346.14\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     54.042\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.84417\n",
      "GaussianMLPPolicy/KL                      0.00980568\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              30.1139\n",
      "GaussianMLPPolicy/LossBefore             31.701\n",
      "GaussianMLPPolicy/dLoss                   1.5871\n",
      "GaussianMLPValueFunction/LossAfter        6.49286\n",
      "GaussianMLPValueFunction/LossBefore       6.49569\n",
      "GaussianMLPValueFunction/dLoss            0.00282431\n",
      "TotalEnvSteps                        709200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:57 | [trpo_pendulum] epoch #591 | Saving snapshot...\n",
      "2022-08-17 18:10:57 | [trpo_pendulum] epoch #591 | Saved\n",
      "2022-08-17 18:10:57 | [trpo_pendulum] epoch #591 | Time 373.56 s\n",
      "2022-08-17 18:10:57 | [trpo_pendulum] epoch #591 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -514.98\n",
      "Evaluation/AverageReturn              -1274.37\n",
      "Evaluation/Iteration                    591\n",
      "Evaluation/MaxReturn                  -1187.54\n",
      "Evaluation/MinReturn                  -1326\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     44.3866\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.85856\n",
      "GaussianMLPPolicy/KL                      0.00759339\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              30.9678\n",
      "GaussianMLPPolicy/LossBefore             31.4718\n",
      "GaussianMLPPolicy/dLoss                   0.504063\n",
      "GaussianMLPValueFunction/LossAfter        6.46375\n",
      "GaussianMLPValueFunction/LossBefore       6.46604\n",
      "GaussianMLPValueFunction/dLoss            0.00229836\n",
      "TotalEnvSteps                        710400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:58 | [trpo_pendulum] epoch #592 | Saving snapshot...\n",
      "2022-08-17 18:10:58 | [trpo_pendulum] epoch #592 | Saved\n",
      "2022-08-17 18:10:58 | [trpo_pendulum] epoch #592 | Time 374.25 s\n",
      "2022-08-17 18:10:58 | [trpo_pendulum] epoch #592 | EpochTime 0.69 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -537.605\n",
      "Evaluation/AverageReturn              -1293.06\n",
      "Evaluation/Iteration                    592\n",
      "Evaluation/MaxReturn                  -1210.08\n",
      "Evaluation/MinReturn                  -1351.84\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     59.8032\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.88125\n",
      "GaussianMLPPolicy/KL                      0.00994134\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              31.6815\n",
      "GaussianMLPPolicy/LossBefore             32.2748\n",
      "GaussianMLPPolicy/dLoss                   0.593376\n",
      "GaussianMLPValueFunction/LossAfter        6.53981\n",
      "GaussianMLPValueFunction/LossBefore       6.5441\n",
      "GaussianMLPValueFunction/dLoss            0.00429201\n",
      "TotalEnvSteps                        711600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:59 | [trpo_pendulum] epoch #593 | Saving snapshot...\n",
      "2022-08-17 18:10:59 | [trpo_pendulum] epoch #593 | Saved\n",
      "2022-08-17 18:10:59 | [trpo_pendulum] epoch #593 | Time 374.92 s\n",
      "2022-08-17 18:10:59 | [trpo_pendulum] epoch #593 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -446.225\n",
      "Evaluation/AverageReturn              -1101.88\n",
      "Evaluation/Iteration                    593\n",
      "Evaluation/MaxReturn                   -896.277\n",
      "Evaluation/MinReturn                  -1217.83\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    104.992\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.89008\n",
      "GaussianMLPPolicy/KL                      0.00727932\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               4.10552\n",
      "GaussianMLPPolicy/LossBefore              5.56529\n",
      "GaussianMLPPolicy/dLoss                   1.45978\n",
      "GaussianMLPValueFunction/LossAfter        6.39756\n",
      "GaussianMLPValueFunction/LossBefore       6.40352\n",
      "GaussianMLPValueFunction/dLoss            0.00595951\n",
      "TotalEnvSteps                        712800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:10:59 | [trpo_pendulum] epoch #594 | Saving snapshot...\n",
      "2022-08-17 18:10:59 | [trpo_pendulum] epoch #594 | Saved\n",
      "2022-08-17 18:10:59 | [trpo_pendulum] epoch #594 | Time 375.59 s\n",
      "2022-08-17 18:10:59 | [trpo_pendulum] epoch #594 | EpochTime 0.66 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -498.47\n",
      "Evaluation/AverageReturn              -1268.54\n",
      "Evaluation/Iteration                    594\n",
      "Evaluation/MaxReturn                  -1205.76\n",
      "Evaluation/MinReturn                  -1375.46\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     63.3751\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.88785\n",
      "GaussianMLPPolicy/KL                      0.0061828\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              28.8412\n",
      "GaussianMLPPolicy/LossBefore             30.1407\n",
      "GaussianMLPPolicy/dLoss                   1.29949\n",
      "GaussianMLPValueFunction/LossAfter        6.47674\n",
      "GaussianMLPValueFunction/LossBefore       6.47937\n",
      "GaussianMLPValueFunction/dLoss            0.002635\n",
      "TotalEnvSteps                        714000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:11:00 | [trpo_pendulum] epoch #595 | Saving snapshot...\n",
      "2022-08-17 18:11:00 | [trpo_pendulum] epoch #595 | Saved\n",
      "2022-08-17 18:11:00 | [trpo_pendulum] epoch #595 | Time 376.22 s\n",
      "2022-08-17 18:11:00 | [trpo_pendulum] epoch #595 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -688.772\n",
      "Evaluation/AverageReturn              -1599.49\n",
      "Evaluation/Iteration                    595\n",
      "Evaluation/MaxReturn                  -1543.77\n",
      "Evaluation/MinReturn                  -1653.69\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     34.1819\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.89976\n",
      "GaussianMLPPolicy/KL                      0.00936974\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              67.3674\n",
      "GaussianMLPPolicy/LossBefore             70.2566\n",
      "GaussianMLPPolicy/dLoss                   2.88921\n",
      "GaussianMLPValueFunction/LossAfter        6.90159\n",
      "GaussianMLPValueFunction/LossBefore       7.01442\n",
      "GaussianMLPValueFunction/dLoss            0.112831\n",
      "TotalEnvSteps                        715200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:01 | [trpo_pendulum] epoch #596 | Saving snapshot...\n",
      "2022-08-17 18:11:01 | [trpo_pendulum] epoch #596 | Saved\n",
      "2022-08-17 18:11:01 | [trpo_pendulum] epoch #596 | Time 376.91 s\n",
      "2022-08-17 18:11:01 | [trpo_pendulum] epoch #596 | EpochTime 0.68 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -548.742\n",
      "Evaluation/AverageReturn              -1347.2\n",
      "Evaluation/Iteration                    596\n",
      "Evaluation/MaxReturn                  -1333.13\n",
      "Evaluation/MinReturn                  -1368.4\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     11.7629\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.92031\n",
      "GaussianMLPPolicy/KL                      0.00699438\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              38.6012\n",
      "GaussianMLPPolicy/LossBefore             38.9247\n",
      "GaussianMLPPolicy/dLoss                   0.323467\n",
      "GaussianMLPValueFunction/LossAfter        6.56024\n",
      "GaussianMLPValueFunction/LossBefore       6.56233\n",
      "GaussianMLPValueFunction/dLoss            0.00208998\n",
      "TotalEnvSteps                        716400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:01 | [trpo_pendulum] epoch #597 | Saving snapshot...\n",
      "2022-08-17 18:11:01 | [trpo_pendulum] epoch #597 | Saved\n",
      "2022-08-17 18:11:01 | [trpo_pendulum] epoch #597 | Time 377.56 s\n",
      "2022-08-17 18:11:01 | [trpo_pendulum] epoch #597 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -518.561\n",
      "Evaluation/AverageReturn              -1300.66\n",
      "Evaluation/Iteration                    597\n",
      "Evaluation/MaxReturn                  -1186.32\n",
      "Evaluation/MinReturn                  -1342\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     53.3146\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.93969\n",
      "GaussianMLPPolicy/KL                      0.00703803\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              29.5098\n",
      "GaussianMLPPolicy/LossBefore             30.7249\n",
      "GaussianMLPPolicy/dLoss                   1.21511\n",
      "GaussianMLPValueFunction/LossAfter        6.48889\n",
      "GaussianMLPValueFunction/LossBefore       6.4937\n",
      "GaussianMLPValueFunction/dLoss            0.00480938\n",
      "TotalEnvSteps                        717600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:02 | [trpo_pendulum] epoch #598 | Saving snapshot...\n",
      "2022-08-17 18:11:02 | [trpo_pendulum] epoch #598 | Saved\n",
      "2022-08-17 18:11:02 | [trpo_pendulum] epoch #598 | Time 378.23 s\n",
      "2022-08-17 18:11:02 | [trpo_pendulum] epoch #598 | EpochTime 0.67 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -682.603\n",
      "Evaluation/AverageReturn              -1539.05\n",
      "Evaluation/Iteration                    598\n",
      "Evaluation/MaxReturn                  -1239.38\n",
      "Evaluation/MinReturn                  -1631.75\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    136.032\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.91972\n",
      "GaussianMLPPolicy/KL                      0.00664649\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              53.8064\n",
      "GaussianMLPPolicy/LossBefore             56.2005\n",
      "GaussianMLPPolicy/dLoss                   2.3941\n",
      "GaussianMLPValueFunction/LossAfter        6.79948\n",
      "GaussianMLPValueFunction/LossBefore       6.82881\n",
      "GaussianMLPValueFunction/dLoss            0.0293283\n",
      "TotalEnvSteps                        718800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:03 | [trpo_pendulum] epoch #599 | Saving snapshot...\n",
      "2022-08-17 18:11:03 | [trpo_pendulum] epoch #599 | Saved\n",
      "2022-08-17 18:11:03 | [trpo_pendulum] epoch #599 | Time 378.89 s\n",
      "2022-08-17 18:11:03 | [trpo_pendulum] epoch #599 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -533.414\n",
      "Evaluation/AverageReturn              -1242.89\n",
      "Evaluation/Iteration                    599\n",
      "Evaluation/MaxReturn                  -1064.68\n",
      "Evaluation/MinReturn                  -1528.46\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    146.75\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.90809\n",
      "GaussianMLPPolicy/KL                      0.00969119\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              12.2131\n",
      "GaussianMLPPolicy/LossBefore             14.5284\n",
      "GaussianMLPPolicy/dLoss                   2.31524\n",
      "GaussianMLPValueFunction/LossAfter        6.42619\n",
      "GaussianMLPValueFunction/LossBefore       6.43914\n",
      "GaussianMLPValueFunction/dLoss            0.0129576\n",
      "TotalEnvSteps                        720000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:03 | [trpo_pendulum] epoch #600 | Saving snapshot...\n",
      "2022-08-17 18:11:03 | [trpo_pendulum] epoch #600 | Saved\n",
      "2022-08-17 18:11:03 | [trpo_pendulum] epoch #600 | Time 379.54 s\n",
      "2022-08-17 18:11:03 | [trpo_pendulum] epoch #600 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -512.534\n",
      "Evaluation/AverageReturn              -1291.63\n",
      "Evaluation/Iteration                    600\n",
      "Evaluation/MaxReturn                  -1186.08\n",
      "Evaluation/MinReturn                  -1428.5\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     83.7333\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.89127\n",
      "GaussianMLPPolicy/KL                      0.00883165\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              30.596\n",
      "GaussianMLPPolicy/LossBefore             32.3186\n",
      "GaussianMLPPolicy/dLoss                   1.72266\n",
      "GaussianMLPValueFunction/LossAfter        6.55729\n",
      "GaussianMLPValueFunction/LossBefore       6.5586\n",
      "GaussianMLPValueFunction/dLoss            0.00131512\n",
      "TotalEnvSteps                        721200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:04 | [trpo_pendulum] epoch #601 | Saving snapshot...\n",
      "2022-08-17 18:11:04 | [trpo_pendulum] epoch #601 | Saved\n",
      "2022-08-17 18:11:04 | [trpo_pendulum] epoch #601 | Time 380.22 s\n",
      "2022-08-17 18:11:04 | [trpo_pendulum] epoch #601 | EpochTime 0.68 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -542.358\n",
      "Evaluation/AverageReturn              -1266.17\n",
      "Evaluation/Iteration                    601\n",
      "Evaluation/MaxReturn                  -1184.85\n",
      "Evaluation/MinReturn                  -1524.86\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    117.788\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.91739\n",
      "GaussianMLPPolicy/KL                      0.00676734\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              16.0291\n",
      "GaussianMLPPolicy/LossBefore             18.3337\n",
      "GaussianMLPPolicy/dLoss                   2.30469\n",
      "GaussianMLPValueFunction/LossAfter        6.45959\n",
      "GaussianMLPValueFunction/LossBefore       6.46491\n",
      "GaussianMLPValueFunction/dLoss            0.00532103\n",
      "TotalEnvSteps                        722400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:05 | [trpo_pendulum] epoch #602 | Saving snapshot...\n",
      "2022-08-17 18:11:05 | [trpo_pendulum] epoch #602 | Saved\n",
      "2022-08-17 18:11:05 | [trpo_pendulum] epoch #602 | Time 380.88 s\n",
      "2022-08-17 18:11:05 | [trpo_pendulum] epoch #602 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -516.231\n",
      "Evaluation/AverageReturn              -1294.31\n",
      "Evaluation/Iteration                    602\n",
      "Evaluation/MaxReturn                  -1087.01\n",
      "Evaluation/MinReturn                  -1359.47\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     94.9996\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.91065\n",
      "GaussianMLPPolicy/KL                      0.00861131\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              30.5081\n",
      "GaussianMLPPolicy/LossBefore             30.6143\n",
      "GaussianMLPPolicy/dLoss                   0.106161\n",
      "GaussianMLPValueFunction/LossAfter        6.52094\n",
      "GaussianMLPValueFunction/LossBefore       6.52248\n",
      "GaussianMLPValueFunction/dLoss            0.00153971\n",
      "TotalEnvSteps                        723600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:05 | [trpo_pendulum] epoch #603 | Saving snapshot...\n",
      "2022-08-17 18:11:05 | [trpo_pendulum] epoch #603 | Saved\n",
      "2022-08-17 18:11:05 | [trpo_pendulum] epoch #603 | Time 381.50 s\n",
      "2022-08-17 18:11:05 | [trpo_pendulum] epoch #603 | EpochTime 0.62 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -572.094\n",
      "Evaluation/AverageReturn              -1290.93\n",
      "Evaluation/Iteration                    603\n",
      "Evaluation/MaxReturn                  -1087.29\n",
      "Evaluation/MinReturn                  -1477.22\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    155.011\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.9402\n",
      "GaussianMLPPolicy/KL                      0.00957736\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              16.184\n",
      "GaussianMLPPolicy/LossBefore             18.8839\n",
      "GaussianMLPPolicy/dLoss                   2.69994\n",
      "GaussianMLPValueFunction/LossAfter        6.52761\n",
      "GaussianMLPValueFunction/LossBefore       6.5277\n",
      "GaussianMLPValueFunction/dLoss            8.39233e-05\n",
      "TotalEnvSteps                        724800\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:11:06 | [trpo_pendulum] epoch #604 | Saving snapshot...\n",
      "2022-08-17 18:11:06 | [trpo_pendulum] epoch #604 | Saved\n",
      "2022-08-17 18:11:06 | [trpo_pendulum] epoch #604 | Time 382.19 s\n",
      "2022-08-17 18:11:06 | [trpo_pendulum] epoch #604 | EpochTime 0.68 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -580.215\n",
      "Evaluation/AverageReturn              -1279.54\n",
      "Evaluation/Iteration                    604\n",
      "Evaluation/MaxReturn                  -1147\n",
      "Evaluation/MinReturn                  -1607.71\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    158.04\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.93702\n",
      "GaussianMLPPolicy/KL                      0.00812641\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              12.583\n",
      "GaussianMLPPolicy/LossBefore             15.6909\n",
      "GaussianMLPPolicy/dLoss                   3.10782\n",
      "GaussianMLPValueFunction/LossAfter        6.5169\n",
      "GaussianMLPValueFunction/LossBefore       6.51711\n",
      "GaussianMLPValueFunction/dLoss            0.000215054\n",
      "TotalEnvSteps                        726000\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:11:07 | [trpo_pendulum] epoch #605 | Saving snapshot...\n",
      "2022-08-17 18:11:07 | [trpo_pendulum] epoch #605 | Saved\n",
      "2022-08-17 18:11:07 | [trpo_pendulum] epoch #605 | Time 382.85 s\n",
      "2022-08-17 18:11:07 | [trpo_pendulum] epoch #605 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -479.793\n",
      "Evaluation/AverageReturn              -1160.86\n",
      "Evaluation/Iteration                    605\n",
      "Evaluation/MaxReturn                  -1050.83\n",
      "Evaluation/MinReturn                  -1230.85\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     57.7725\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.93426\n",
      "GaussianMLPPolicy/KL                      0.00620869\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               6.84291\n",
      "GaussianMLPPolicy/LossBefore              7.89133\n",
      "GaussianMLPPolicy/dLoss                   1.04842\n",
      "GaussianMLPValueFunction/LossAfter        6.43256\n",
      "GaussianMLPValueFunction/LossBefore       6.43761\n",
      "GaussianMLPValueFunction/dLoss            0.00504732\n",
      "TotalEnvSteps                        727200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:07 | [trpo_pendulum] epoch #606 | Saving snapshot...\n",
      "2022-08-17 18:11:07 | [trpo_pendulum] epoch #606 | Saved\n",
      "2022-08-17 18:11:07 | [trpo_pendulum] epoch #606 | Time 383.53 s\n",
      "2022-08-17 18:11:07 | [trpo_pendulum] epoch #606 | EpochTime 0.68 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -470.764\n",
      "Evaluation/AverageReturn              -1130.81\n",
      "Evaluation/Iteration                    606\n",
      "Evaluation/MaxReturn                  -1039.12\n",
      "Evaluation/MinReturn                  -1221.29\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     66.6521\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.921\n",
      "GaussianMLPPolicy/KL                      0.00756159\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -1.30663\n",
      "GaussianMLPPolicy/LossBefore              0.128782\n",
      "GaussianMLPPolicy/dLoss                   1.43541\n",
      "GaussianMLPValueFunction/LossAfter        6.32133\n",
      "GaussianMLPValueFunction/LossBefore       6.33775\n",
      "GaussianMLPValueFunction/dLoss            0.0164204\n",
      "TotalEnvSteps                        728400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:08 | [trpo_pendulum] epoch #607 | Saving snapshot...\n",
      "2022-08-17 18:11:08 | [trpo_pendulum] epoch #607 | Saved\n",
      "2022-08-17 18:11:08 | [trpo_pendulum] epoch #607 | Time 384.19 s\n",
      "2022-08-17 18:11:08 | [trpo_pendulum] epoch #607 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -486.34\n",
      "Evaluation/AverageReturn              -1173.96\n",
      "Evaluation/Iteration                    607\n",
      "Evaluation/MaxReturn                  -1113.81\n",
      "Evaluation/MinReturn                  -1192.71\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     27.3621\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.91916\n",
      "GaussianMLPPolicy/KL                      0.00668378\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               9.64163\n",
      "GaussianMLPPolicy/LossBefore             10.4556\n",
      "GaussianMLPPolicy/dLoss                   0.813978\n",
      "GaussianMLPValueFunction/LossAfter        6.38656\n",
      "GaussianMLPValueFunction/LossBefore       6.38883\n",
      "GaussianMLPValueFunction/dLoss            0.00227261\n",
      "TotalEnvSteps                        729600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:09 | [trpo_pendulum] epoch #608 | Saving snapshot...\n",
      "2022-08-17 18:11:09 | [trpo_pendulum] epoch #608 | Saved\n",
      "2022-08-17 18:11:09 | [trpo_pendulum] epoch #608 | Time 384.89 s\n",
      "2022-08-17 18:11:09 | [trpo_pendulum] epoch #608 | EpochTime 0.69 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -442.948\n",
      "Evaluation/AverageReturn              -1089.03\n",
      "Evaluation/Iteration                    608\n",
      "Evaluation/MaxReturn                  -1054.77\n",
      "Evaluation/MinReturn                  -1198.74\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     50.4118\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.89703\n",
      "GaussianMLPPolicy/KL                      0.00855744\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.0589935\n",
      "GaussianMLPPolicy/LossBefore              0.467373\n",
      "GaussianMLPPolicy/dLoss                   0.408379\n",
      "GaussianMLPValueFunction/LossAfter        6.3897\n",
      "GaussianMLPValueFunction/LossBefore       6.39261\n",
      "GaussianMLPValueFunction/dLoss            0.00291204\n",
      "TotalEnvSteps                        730800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:09 | [trpo_pendulum] epoch #609 | Saving snapshot...\n",
      "2022-08-17 18:11:09 | [trpo_pendulum] epoch #609 | Saved\n",
      "2022-08-17 18:11:09 | [trpo_pendulum] epoch #609 | Time 385.54 s\n",
      "2022-08-17 18:11:09 | [trpo_pendulum] epoch #609 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -689.33\n",
      "Evaluation/AverageReturn              -1614.57\n",
      "Evaluation/Iteration                    609\n",
      "Evaluation/MaxReturn                  -1589.77\n",
      "Evaluation/MinReturn                  -1644.11\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     17.9726\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.89777\n",
      "GaussianMLPPolicy/KL                      0.00799961\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              68.3244\n",
      "GaussianMLPPolicy/LossBefore             70.4495\n",
      "GaussianMLPPolicy/dLoss                   2.12505\n",
      "GaussianMLPValueFunction/LossAfter        6.94323\n",
      "GaussianMLPValueFunction/LossBefore       7.08651\n",
      "GaussianMLPValueFunction/dLoss            0.143282\n",
      "TotalEnvSteps                        732000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:10 | [trpo_pendulum] epoch #610 | Saving snapshot...\n",
      "2022-08-17 18:11:10 | [trpo_pendulum] epoch #610 | Saved\n",
      "2022-08-17 18:11:10 | [trpo_pendulum] epoch #610 | Time 386.16 s\n",
      "2022-08-17 18:11:10 | [trpo_pendulum] epoch #610 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -372.874\n",
      "Evaluation/AverageReturn               -976.483\n",
      "Evaluation/Iteration                    610\n",
      "Evaluation/MaxReturn                   -917.078\n",
      "Evaluation/MinReturn                  -1045.11\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     48.2134\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.89659\n",
      "GaussianMLPPolicy/KL                      0.00830299\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -13.699\n",
      "GaussianMLPPolicy/LossBefore            -13.2343\n",
      "GaussianMLPPolicy/dLoss                   0.464615\n",
      "GaussianMLPValueFunction/LossAfter        6.36699\n",
      "GaussianMLPValueFunction/LossBefore       6.377\n",
      "GaussianMLPValueFunction/dLoss            0.0100045\n",
      "TotalEnvSteps                        733200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:11 | [trpo_pendulum] epoch #611 | Saving snapshot...\n",
      "2022-08-17 18:11:11 | [trpo_pendulum] epoch #611 | Saved\n",
      "2022-08-17 18:11:11 | [trpo_pendulum] epoch #611 | Time 386.82 s\n",
      "2022-08-17 18:11:11 | [trpo_pendulum] epoch #611 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -717.224\n",
      "Evaluation/AverageReturn              -1647.37\n",
      "Evaluation/Iteration                    611\n",
      "Evaluation/MaxReturn                  -1597.58\n",
      "Evaluation/MinReturn                  -1702.81\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     32.9985\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.87591\n",
      "GaussianMLPPolicy/KL                      0.00984948\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              69.2725\n",
      "GaussianMLPPolicy/LossBefore             71.1993\n",
      "GaussianMLPPolicy/dLoss                   1.92675\n",
      "GaussianMLPValueFunction/LossAfter        6.92678\n",
      "GaussianMLPValueFunction/LossBefore       6.99434\n",
      "GaussianMLPValueFunction/dLoss            0.0675569\n",
      "TotalEnvSteps                        734400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:11 | [trpo_pendulum] epoch #612 | Saving snapshot...\n",
      "2022-08-17 18:11:11 | [trpo_pendulum] epoch #612 | Saved\n",
      "2022-08-17 18:11:11 | [trpo_pendulum] epoch #612 | Time 387.52 s\n",
      "2022-08-17 18:11:11 | [trpo_pendulum] epoch #612 | EpochTime 0.69 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -450.779\n",
      "Evaluation/AverageReturn              -1137.46\n",
      "Evaluation/Iteration                    612\n",
      "Evaluation/MaxReturn                   -772.668\n",
      "Evaluation/MinReturn                  -1365.16\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    214.235\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.85082\n",
      "GaussianMLPPolicy/KL                      0.00719737\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               3.83715\n",
      "GaussianMLPPolicy/LossBefore              5.21527\n",
      "GaussianMLPPolicy/dLoss                   1.37812\n",
      "GaussianMLPValueFunction/LossAfter        6.48779\n",
      "GaussianMLPValueFunction/LossBefore       6.48997\n",
      "GaussianMLPValueFunction/dLoss            0.00218201\n",
      "TotalEnvSteps                        735600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:12 | [trpo_pendulum] epoch #613 | Saving snapshot...\n",
      "2022-08-17 18:11:12 | [trpo_pendulum] epoch #613 | Saved\n",
      "2022-08-17 18:11:12 | [trpo_pendulum] epoch #613 | Time 388.19 s\n",
      "2022-08-17 18:11:12 | [trpo_pendulum] epoch #613 | EpochTime 0.67 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -668.738\n",
      "Evaluation/AverageReturn              -1562.73\n",
      "Evaluation/Iteration                    613\n",
      "Evaluation/MaxReturn                  -1497.58\n",
      "Evaluation/MinReturn                  -1604.88\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     39.8499\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.85896\n",
      "GaussianMLPPolicy/KL                      0.00869885\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              58.2461\n",
      "GaussianMLPPolicy/LossBefore             60.6819\n",
      "GaussianMLPPolicy/dLoss                   2.43573\n",
      "GaussianMLPValueFunction/LossAfter        6.77854\n",
      "GaussianMLPValueFunction/LossBefore       6.79799\n",
      "GaussianMLPValueFunction/dLoss            0.019443\n",
      "TotalEnvSteps                        736800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:13 | [trpo_pendulum] epoch #614 | Saving snapshot...\n",
      "2022-08-17 18:11:13 | [trpo_pendulum] epoch #614 | Saved\n",
      "2022-08-17 18:11:13 | [trpo_pendulum] epoch #614 | Time 388.86 s\n",
      "2022-08-17 18:11:13 | [trpo_pendulum] epoch #614 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -682.687\n",
      "Evaluation/AverageReturn              -1585.46\n",
      "Evaluation/Iteration                    614\n",
      "Evaluation/MaxReturn                  -1498.85\n",
      "Evaluation/MinReturn                  -1634.96\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     51.008\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.8615\n",
      "GaussianMLPPolicy/KL                      0.00633465\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              59.9412\n",
      "GaussianMLPPolicy/LossBefore             62.2324\n",
      "GaussianMLPPolicy/dLoss                   2.29123\n",
      "GaussianMLPValueFunction/LossAfter        6.79589\n",
      "GaussianMLPValueFunction/LossBefore       6.8136\n",
      "GaussianMLPValueFunction/dLoss            0.017714\n",
      "TotalEnvSteps                        738000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:13 | [trpo_pendulum] epoch #615 | Saving snapshot...\n",
      "2022-08-17 18:11:13 | [trpo_pendulum] epoch #615 | Saved\n",
      "2022-08-17 18:11:13 | [trpo_pendulum] epoch #615 | Time 389.51 s\n",
      "2022-08-17 18:11:13 | [trpo_pendulum] epoch #615 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -378.843\n",
      "Evaluation/AverageReturn               -953.199\n",
      "Evaluation/Iteration                    615\n",
      "Evaluation/MaxReturn                   -858.815\n",
      "Evaluation/MinReturn                  -1155.07\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     98.7534\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.86777\n",
      "GaussianMLPPolicy/KL                      0.00625266\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -22.9739\n",
      "GaussianMLPPolicy/LossBefore            -21.5513\n",
      "GaussianMLPPolicy/dLoss                   1.42264\n",
      "GaussianMLPValueFunction/LossAfter        6.41428\n",
      "GaussianMLPValueFunction/LossBefore       6.43162\n",
      "GaussianMLPValueFunction/dLoss            0.0173368\n",
      "TotalEnvSteps                        739200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:14 | [trpo_pendulum] epoch #616 | Saving snapshot...\n",
      "2022-08-17 18:11:14 | [trpo_pendulum] epoch #616 | Saved\n",
      "2022-08-17 18:11:14 | [trpo_pendulum] epoch #616 | Time 390.16 s\n",
      "2022-08-17 18:11:14 | [trpo_pendulum] epoch #616 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -538.591\n",
      "Evaluation/AverageReturn              -1234.23\n",
      "Evaluation/Iteration                    616\n",
      "Evaluation/MaxReturn                  -1132.37\n",
      "Evaluation/MinReturn                  -1436.63\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    112.071\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.84945\n",
      "GaussianMLPPolicy/KL                      0.00945341\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               8.57547\n",
      "GaussianMLPPolicy/LossBefore             11.9721\n",
      "GaussianMLPPolicy/dLoss                   3.39666\n",
      "GaussianMLPValueFunction/LossAfter        6.51534\n",
      "GaussianMLPValueFunction/LossBefore       6.51822\n",
      "GaussianMLPValueFunction/dLoss            0.00287437\n",
      "TotalEnvSteps                        740400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:14 | [trpo_pendulum] epoch #617 | Saving snapshot...\n",
      "2022-08-17 18:11:15 | [trpo_pendulum] epoch #617 | Saved\n",
      "2022-08-17 18:11:15 | [trpo_pendulum] epoch #617 | Time 390.80 s\n",
      "2022-08-17 18:11:15 | [trpo_pendulum] epoch #617 | EpochTime 0.63 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -572.944\n",
      "Evaluation/AverageReturn              -1327.04\n",
      "Evaluation/Iteration                    617\n",
      "Evaluation/MaxReturn                  -1061.74\n",
      "Evaluation/MinReturn                  -1618.74\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    208.308\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.87979\n",
      "GaussianMLPPolicy/KL                      0.00922975\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              19.6135\n",
      "GaussianMLPPolicy/LossBefore             24.7805\n",
      "GaussianMLPPolicy/dLoss                   5.167\n",
      "GaussianMLPValueFunction/LossAfter        6.57487\n",
      "GaussianMLPValueFunction/LossBefore       6.57516\n",
      "GaussianMLPValueFunction/dLoss            0.000289917\n",
      "TotalEnvSteps                        741600\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:11:15 | [trpo_pendulum] epoch #618 | Saving snapshot...\n",
      "2022-08-17 18:11:15 | [trpo_pendulum] epoch #618 | Saved\n",
      "2022-08-17 18:11:15 | [trpo_pendulum] epoch #618 | Time 391.45 s\n",
      "2022-08-17 18:11:15 | [trpo_pendulum] epoch #618 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -518.86\n",
      "Evaluation/AverageReturn              -1307.38\n",
      "Evaluation/Iteration                    618\n",
      "Evaluation/MaxReturn                  -1085.03\n",
      "Evaluation/MinReturn                  -1422.66\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    120.026\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.90174\n",
      "GaussianMLPPolicy/KL                      0.00585056\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              28.358\n",
      "GaussianMLPPolicy/LossBefore             29.4208\n",
      "GaussianMLPPolicy/dLoss                   1.0628\n",
      "GaussianMLPValueFunction/LossAfter        6.54305\n",
      "GaussianMLPValueFunction/LossBefore       6.54464\n",
      "GaussianMLPValueFunction/dLoss            0.00159025\n",
      "TotalEnvSteps                        742800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:16 | [trpo_pendulum] epoch #619 | Saving snapshot...\n",
      "2022-08-17 18:11:16 | [trpo_pendulum] epoch #619 | Saved\n",
      "2022-08-17 18:11:16 | [trpo_pendulum] epoch #619 | Time 392.11 s\n",
      "2022-08-17 18:11:16 | [trpo_pendulum] epoch #619 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -411.711\n",
      "Evaluation/AverageReturn              -1054.38\n",
      "Evaluation/Iteration                    619\n",
      "Evaluation/MaxReturn                   -758.774\n",
      "Evaluation/MinReturn                  -1201.38\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    168.077\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.92212\n",
      "GaussianMLPPolicy/KL                      0.00701298\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -10.8588\n",
      "GaussianMLPPolicy/LossBefore             -8.94961\n",
      "GaussianMLPPolicy/dLoss                   1.9092\n",
      "GaussianMLPValueFunction/LossAfter        6.42594\n",
      "GaussianMLPValueFunction/LossBefore       6.43563\n",
      "GaussianMLPValueFunction/dLoss            0.00969267\n",
      "TotalEnvSteps                        744000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:16 | [trpo_pendulum] epoch #620 | Saving snapshot...\n",
      "2022-08-17 18:11:16 | [trpo_pendulum] epoch #620 | Saved\n",
      "2022-08-17 18:11:16 | [trpo_pendulum] epoch #620 | Time 392.77 s\n",
      "2022-08-17 18:11:16 | [trpo_pendulum] epoch #620 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -337.33\n",
      "Evaluation/AverageReturn               -861.604\n",
      "Evaluation/Iteration                    620\n",
      "Evaluation/MaxReturn                   -760.827\n",
      "Evaluation/MinReturn                   -985.035\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     98.0856\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.90878\n",
      "GaussianMLPPolicy/KL                      0.00571561\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -35.5772\n",
      "GaussianMLPPolicy/LossBefore            -34.1318\n",
      "GaussianMLPPolicy/dLoss                   1.44539\n",
      "GaussianMLPValueFunction/LossAfter        6.40655\n",
      "GaussianMLPValueFunction/LossBefore       6.42234\n",
      "GaussianMLPValueFunction/dLoss            0.0157962\n",
      "TotalEnvSteps                        745200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:17 | [trpo_pendulum] epoch #621 | Saving snapshot...\n",
      "2022-08-17 18:11:17 | [trpo_pendulum] epoch #621 | Saved\n",
      "2022-08-17 18:11:17 | [trpo_pendulum] epoch #621 | Time 393.43 s\n",
      "2022-08-17 18:11:17 | [trpo_pendulum] epoch #621 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -537.379\n",
      "Evaluation/AverageReturn              -1328.96\n",
      "Evaluation/Iteration                    621\n",
      "Evaluation/MaxReturn                  -1181.9\n",
      "Evaluation/MinReturn                  -1430.03\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     79.67\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.94041\n",
      "GaussianMLPPolicy/KL                      0.00643465\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              31.381\n",
      "GaussianMLPPolicy/LossBefore             32.1606\n",
      "GaussianMLPPolicy/dLoss                   0.779625\n",
      "GaussianMLPValueFunction/LossAfter        6.52046\n",
      "GaussianMLPValueFunction/LossBefore       6.52176\n",
      "GaussianMLPValueFunction/dLoss            0.00130558\n",
      "TotalEnvSteps                        746400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:18 | [trpo_pendulum] epoch #622 | Saving snapshot...\n",
      "2022-08-17 18:11:18 | [trpo_pendulum] epoch #622 | Saved\n",
      "2022-08-17 18:11:18 | [trpo_pendulum] epoch #622 | Time 394.08 s\n",
      "2022-08-17 18:11:18 | [trpo_pendulum] epoch #622 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -374.374\n",
      "Evaluation/AverageReturn              -1048.1\n",
      "Evaluation/Iteration                    622\n",
      "Evaluation/MaxReturn                   -773.875\n",
      "Evaluation/MinReturn                  -1252.16\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    142.81\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.92556\n",
      "GaussianMLPPolicy/KL                      0.00547864\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -1.71848\n",
      "GaussianMLPPolicy/LossBefore             -0.977689\n",
      "GaussianMLPPolicy/dLoss                   0.740792\n",
      "GaussianMLPValueFunction/LossAfter        6.36158\n",
      "GaussianMLPValueFunction/LossBefore       6.37151\n",
      "GaussianMLPValueFunction/dLoss            0.00992298\n",
      "TotalEnvSteps                        747600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:18 | [trpo_pendulum] epoch #623 | Saving snapshot...\n",
      "2022-08-17 18:11:18 | [trpo_pendulum] epoch #623 | Saved\n",
      "2022-08-17 18:11:18 | [trpo_pendulum] epoch #623 | Time 394.73 s\n",
      "2022-08-17 18:11:18 | [trpo_pendulum] epoch #623 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -644.312\n",
      "Evaluation/AverageReturn              -1492.87\n",
      "Evaluation/Iteration                    623\n",
      "Evaluation/MaxReturn                  -1132.22\n",
      "Evaluation/MinReturn                  -1609.28\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    163.772\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.91725\n",
      "GaussianMLPPolicy/KL                      0.00986691\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              47.293\n",
      "GaussianMLPPolicy/LossBefore             49.9209\n",
      "GaussianMLPPolicy/dLoss                   2.62798\n",
      "GaussianMLPValueFunction/LossAfter        6.76612\n",
      "GaussianMLPValueFunction/LossBefore       6.80961\n",
      "GaussianMLPValueFunction/dLoss            0.0434937\n",
      "TotalEnvSteps                        748800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:19 | [trpo_pendulum] epoch #624 | Saving snapshot...\n",
      "2022-08-17 18:11:19 | [trpo_pendulum] epoch #624 | Saved\n",
      "2022-08-17 18:11:19 | [trpo_pendulum] epoch #624 | Time 395.38 s\n",
      "2022-08-17 18:11:19 | [trpo_pendulum] epoch #624 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -688.279\n",
      "Evaluation/AverageReturn              -1594.17\n",
      "Evaluation/Iteration                    624\n",
      "Evaluation/MaxReturn                  -1575.82\n",
      "Evaluation/MinReturn                  -1610.86\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     13.7964\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.92262\n",
      "GaussianMLPPolicy/KL                      0.00642256\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              61.198\n",
      "GaussianMLPPolicy/LossBefore             63.2968\n",
      "GaussianMLPPolicy/dLoss                   2.09885\n",
      "GaussianMLPValueFunction/LossAfter        6.82134\n",
      "GaussianMLPValueFunction/LossBefore       6.86117\n",
      "GaussianMLPValueFunction/dLoss            0.0398259\n",
      "TotalEnvSteps                        750000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:20 | [trpo_pendulum] epoch #625 | Saving snapshot...\n",
      "2022-08-17 18:11:20 | [trpo_pendulum] epoch #625 | Saved\n",
      "2022-08-17 18:11:20 | [trpo_pendulum] epoch #625 | Time 396.01 s\n",
      "2022-08-17 18:11:20 | [trpo_pendulum] epoch #625 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -490.144\n",
      "Evaluation/AverageReturn              -1277.07\n",
      "Evaluation/Iteration                    625\n",
      "Evaluation/MaxReturn                  -1214.38\n",
      "Evaluation/MinReturn                  -1358.6\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     54.0329\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.93539\n",
      "GaussianMLPPolicy/KL                      0.00654962\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              24.1572\n",
      "GaussianMLPPolicy/LossBefore             25.4517\n",
      "GaussianMLPPolicy/dLoss                   1.2945\n",
      "GaussianMLPValueFunction/LossAfter        6.48643\n",
      "GaussianMLPValueFunction/LossBefore       6.49223\n",
      "GaussianMLPValueFunction/dLoss            0.00580311\n",
      "TotalEnvSteps                        751200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:20 | [trpo_pendulum] epoch #626 | Saving snapshot...\n",
      "2022-08-17 18:11:20 | [trpo_pendulum] epoch #626 | Saved\n",
      "2022-08-17 18:11:20 | [trpo_pendulum] epoch #626 | Time 396.64 s\n",
      "2022-08-17 18:11:20 | [trpo_pendulum] epoch #626 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -564.806\n",
      "Evaluation/AverageReturn              -1396.44\n",
      "Evaluation/Iteration                    626\n",
      "Evaluation/MaxReturn                  -1282.97\n",
      "Evaluation/MinReturn                  -1490.02\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     79.0551\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.92672\n",
      "GaussianMLPPolicy/KL                      0.00986017\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              37.4314\n",
      "GaussianMLPPolicy/LossBefore             38.7659\n",
      "GaussianMLPPolicy/dLoss                   1.33458\n",
      "GaussianMLPValueFunction/LossAfter        6.57093\n",
      "GaussianMLPValueFunction/LossBefore       6.57323\n",
      "GaussianMLPValueFunction/dLoss            0.00229359\n",
      "TotalEnvSteps                        752400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:21 | [trpo_pendulum] epoch #627 | Saving snapshot...\n",
      "2022-08-17 18:11:21 | [trpo_pendulum] epoch #627 | Saved\n",
      "2022-08-17 18:11:21 | [trpo_pendulum] epoch #627 | Time 397.30 s\n",
      "2022-08-17 18:11:21 | [trpo_pendulum] epoch #627 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -581.532\n",
      "Evaluation/AverageReturn              -1434.28\n",
      "Evaluation/Iteration                    627\n",
      "Evaluation/MaxReturn                  -1122.84\n",
      "Evaluation/MinReturn                  -1527.16\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    140.558\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.89242\n",
      "GaussianMLPPolicy/KL                      0.00626855\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              45.819\n",
      "GaussianMLPPolicy/LossBefore             47.0295\n",
      "GaussianMLPPolicy/dLoss                   1.21054\n",
      "GaussianMLPValueFunction/LossAfter        6.69539\n",
      "GaussianMLPValueFunction/LossBefore       6.70408\n",
      "GaussianMLPValueFunction/dLoss            0.00869226\n",
      "TotalEnvSteps                        753600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:22 | [trpo_pendulum] epoch #628 | Saving snapshot...\n",
      "2022-08-17 18:11:22 | [trpo_pendulum] epoch #628 | Saved\n",
      "2022-08-17 18:11:22 | [trpo_pendulum] epoch #628 | Time 398.07 s\n",
      "2022-08-17 18:11:22 | [trpo_pendulum] epoch #628 | EpochTime 0.77 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -674.056\n",
      "Evaluation/AverageReturn              -1528.92\n",
      "Evaluation/Iteration                    628\n",
      "Evaluation/MaxReturn                  -1309.59\n",
      "Evaluation/MinReturn                  -1641.38\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    137.924\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.90843\n",
      "GaussianMLPPolicy/KL                      0.00635356\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              46.4534\n",
      "GaussianMLPPolicy/LossBefore             49.0437\n",
      "GaussianMLPPolicy/dLoss                   2.59029\n",
      "GaussianMLPValueFunction/LossAfter        6.74358\n",
      "GaussianMLPValueFunction/LossBefore       6.75474\n",
      "GaussianMLPValueFunction/dLoss            0.0111566\n",
      "TotalEnvSteps                        754800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:22 | [trpo_pendulum] epoch #629 | Saving snapshot...\n",
      "2022-08-17 18:11:22 | [trpo_pendulum] epoch #629 | Saved\n",
      "2022-08-17 18:11:22 | [trpo_pendulum] epoch #629 | Time 398.71 s\n",
      "2022-08-17 18:11:22 | [trpo_pendulum] epoch #629 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -648.49\n",
      "Evaluation/AverageReturn              -1494.66\n",
      "Evaluation/Iteration                    629\n",
      "Evaluation/MaxReturn                  -1164.38\n",
      "Evaluation/MinReturn                  -1625.02\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    170.305\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.89428\n",
      "GaussianMLPPolicy/KL                      0.00974712\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              43.209\n",
      "GaussianMLPPolicy/LossBefore             45.5635\n",
      "GaussianMLPPolicy/dLoss                   2.35449\n",
      "GaussianMLPValueFunction/LossAfter        6.7085\n",
      "GaussianMLPValueFunction/LossBefore       6.71251\n",
      "GaussianMLPValueFunction/dLoss            0.00401211\n",
      "TotalEnvSteps                        756000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:23 | [trpo_pendulum] epoch #630 | Saving snapshot...\n",
      "2022-08-17 18:11:23 | [trpo_pendulum] epoch #630 | Saved\n",
      "2022-08-17 18:11:23 | [trpo_pendulum] epoch #630 | Time 399.37 s\n",
      "2022-08-17 18:11:23 | [trpo_pendulum] epoch #630 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -638.859\n",
      "Evaluation/AverageReturn              -1511.06\n",
      "Evaluation/Iteration                    630\n",
      "Evaluation/MaxReturn                  -1499.86\n",
      "Evaluation/MinReturn                  -1521.04\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      7.01216\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.90337\n",
      "GaussianMLPPolicy/KL                      0.00946147\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              51.0692\n",
      "GaussianMLPPolicy/LossBefore             51.3658\n",
      "GaussianMLPPolicy/dLoss                   0.296612\n",
      "GaussianMLPValueFunction/LossAfter        6.72856\n",
      "GaussianMLPValueFunction/LossBefore       6.73354\n",
      "GaussianMLPValueFunction/dLoss            0.00497484\n",
      "TotalEnvSteps                        757200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:24 | [trpo_pendulum] epoch #631 | Saving snapshot...\n",
      "2022-08-17 18:11:24 | [trpo_pendulum] epoch #631 | Saved\n",
      "2022-08-17 18:11:24 | [trpo_pendulum] epoch #631 | Time 400.03 s\n",
      "2022-08-17 18:11:24 | [trpo_pendulum] epoch #631 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -738.211\n",
      "Evaluation/AverageReturn              -1710.72\n",
      "Evaluation/Iteration                    631\n",
      "Evaluation/MaxReturn                  -1680.64\n",
      "Evaluation/MinReturn                  -1730.5\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     17.1363\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.90253\n",
      "GaussianMLPPolicy/KL                      0.00835884\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              73.0549\n",
      "GaussianMLPPolicy/LossBefore             75.5274\n",
      "GaussianMLPPolicy/dLoss                   2.47248\n",
      "GaussianMLPValueFunction/LossAfter        6.91411\n",
      "GaussianMLPValueFunction/LossBefore       6.94823\n",
      "GaussianMLPValueFunction/dLoss            0.0341229\n",
      "TotalEnvSteps                        758400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:24 | [trpo_pendulum] epoch #632 | Saving snapshot...\n",
      "2022-08-17 18:11:24 | [trpo_pendulum] epoch #632 | Saved\n",
      "2022-08-17 18:11:24 | [trpo_pendulum] epoch #632 | Time 400.66 s\n",
      "2022-08-17 18:11:24 | [trpo_pendulum] epoch #632 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -708.414\n",
      "Evaluation/AverageReturn              -1654.26\n",
      "Evaluation/Iteration                    632\n",
      "Evaluation/MaxReturn                  -1581.31\n",
      "Evaluation/MinReturn                  -1727.74\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     53.8302\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.88417\n",
      "GaussianMLPPolicy/KL                      0.00916053\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              65.7383\n",
      "GaussianMLPPolicy/LossBefore             68.1869\n",
      "GaussianMLPPolicy/dLoss                   2.44863\n",
      "GaussianMLPValueFunction/LossAfter        6.85094\n",
      "GaussianMLPValueFunction/LossBefore       6.86047\n",
      "GaussianMLPValueFunction/dLoss            0.00952959\n",
      "TotalEnvSteps                        759600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:25 | [trpo_pendulum] epoch #633 | Saving snapshot...\n",
      "2022-08-17 18:11:25 | [trpo_pendulum] epoch #633 | Saved\n",
      "2022-08-17 18:11:25 | [trpo_pendulum] epoch #633 | Time 401.36 s\n",
      "2022-08-17 18:11:25 | [trpo_pendulum] epoch #633 | EpochTime 0.69 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -646.141\n",
      "Evaluation/AverageReturn              -1543.37\n",
      "Evaluation/Iteration                    633\n",
      "Evaluation/MaxReturn                  -1526.07\n",
      "Evaluation/MinReturn                  -1580.16\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     17.3527\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.89527\n",
      "GaussianMLPPolicy/KL                      0.00582117\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              54.3663\n",
      "GaussianMLPPolicy/LossBefore             55.2639\n",
      "GaussianMLPPolicy/dLoss                   0.897663\n",
      "GaussianMLPValueFunction/LossAfter        6.76683\n",
      "GaussianMLPValueFunction/LossBefore       6.76892\n",
      "GaussianMLPValueFunction/dLoss            0.00208712\n",
      "TotalEnvSteps                        760800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:26 | [trpo_pendulum] epoch #634 | Saving snapshot...\n",
      "2022-08-17 18:11:26 | [trpo_pendulum] epoch #634 | Saved\n",
      "2022-08-17 18:11:26 | [trpo_pendulum] epoch #634 | Time 401.99 s\n",
      "2022-08-17 18:11:26 | [trpo_pendulum] epoch #634 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -651.334\n",
      "Evaluation/AverageReturn              -1529.46\n",
      "Evaluation/Iteration                    634\n",
      "Evaluation/MaxReturn                  -1507.47\n",
      "Evaluation/MinReturn                  -1548.35\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     14.0784\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.91212\n",
      "GaussianMLPPolicy/KL                      0.00437768\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              49.6194\n",
      "GaussianMLPPolicy/LossBefore             50.6753\n",
      "GaussianMLPPolicy/dLoss                   1.05589\n",
      "GaussianMLPValueFunction/LossAfter        6.74712\n",
      "GaussianMLPValueFunction/LossBefore       6.74909\n",
      "GaussianMLPValueFunction/dLoss            0.00196981\n",
      "TotalEnvSteps                        762000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:26 | [trpo_pendulum] epoch #635 | Saving snapshot...\n",
      "2022-08-17 18:11:26 | [trpo_pendulum] epoch #635 | Saved\n",
      "2022-08-17 18:11:26 | [trpo_pendulum] epoch #635 | Time 402.63 s\n",
      "2022-08-17 18:11:26 | [trpo_pendulum] epoch #635 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -513.22\n",
      "Evaluation/AverageReturn              -1246.29\n",
      "Evaluation/Iteration                    635\n",
      "Evaluation/MaxReturn                   -900.58\n",
      "Evaluation/MinReturn                  -1360.32\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    158.248\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.9424\n",
      "GaussianMLPPolicy/KL                      0.00828351\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               6.3887\n",
      "GaussianMLPPolicy/LossBefore              9.07587\n",
      "GaussianMLPPolicy/dLoss                   2.68717\n",
      "GaussianMLPValueFunction/LossAfter        6.49475\n",
      "GaussianMLPValueFunction/LossBefore       6.52642\n",
      "GaussianMLPValueFunction/dLoss            0.0316753\n",
      "TotalEnvSteps                        763200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:27 | [trpo_pendulum] epoch #636 | Saving snapshot...\n",
      "2022-08-17 18:11:27 | [trpo_pendulum] epoch #636 | Saved\n",
      "2022-08-17 18:11:27 | [trpo_pendulum] epoch #636 | Time 403.28 s\n",
      "2022-08-17 18:11:27 | [trpo_pendulum] epoch #636 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -763.574\n",
      "Evaluation/AverageReturn              -1766.38\n",
      "Evaluation/Iteration                    636\n",
      "Evaluation/MaxReturn                  -1753.06\n",
      "Evaluation/MinReturn                  -1790.53\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     12.1839\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.94628\n",
      "GaussianMLPPolicy/KL                      0.00819761\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              77.6556\n",
      "GaussianMLPPolicy/LossBefore             79.8001\n",
      "GaussianMLPPolicy/dLoss                   2.14445\n",
      "GaussianMLPValueFunction/LossAfter        6.94788\n",
      "GaussianMLPValueFunction/LossBefore       6.9854\n",
      "GaussianMLPValueFunction/dLoss            0.0375156\n",
      "TotalEnvSteps                        764400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:28 | [trpo_pendulum] epoch #637 | Saving snapshot...\n",
      "2022-08-17 18:11:28 | [trpo_pendulum] epoch #637 | Saved\n",
      "2022-08-17 18:11:28 | [trpo_pendulum] epoch #637 | Time 403.96 s\n",
      "2022-08-17 18:11:28 | [trpo_pendulum] epoch #637 | EpochTime 0.68 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -618.15\n",
      "Evaluation/AverageReturn              -1504.39\n",
      "Evaluation/Iteration                    637\n",
      "Evaluation/MaxReturn                  -1492.15\n",
      "Evaluation/MinReturn                  -1516.06\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      8.53839\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.9469\n",
      "GaussianMLPPolicy/KL                      0.00501748\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              49.3981\n",
      "GaussianMLPPolicy/LossBefore             49.6923\n",
      "GaussianMLPPolicy/dLoss                   0.294197\n",
      "GaussianMLPValueFunction/LossAfter        6.71088\n",
      "GaussianMLPValueFunction/LossBefore       6.7135\n",
      "GaussianMLPValueFunction/dLoss            0.00262499\n",
      "TotalEnvSteps                        765600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:28 | [trpo_pendulum] epoch #638 | Saving snapshot...\n",
      "2022-08-17 18:11:28 | [trpo_pendulum] epoch #638 | Saved\n",
      "2022-08-17 18:11:28 | [trpo_pendulum] epoch #638 | Time 404.65 s\n",
      "2022-08-17 18:11:28 | [trpo_pendulum] epoch #638 | EpochTime 0.68 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -744.59\n",
      "Evaluation/AverageReturn              -1731.03\n",
      "Evaluation/Iteration                    638\n",
      "Evaluation/MaxReturn                  -1677.66\n",
      "Evaluation/MinReturn                  -1767.84\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     31.0663\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.9435\n",
      "GaussianMLPPolicy/KL                      0.00709202\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              72.2402\n",
      "GaussianMLPPolicy/LossBefore             74.5288\n",
      "GaussianMLPPolicy/dLoss                   2.28866\n",
      "GaussianMLPValueFunction/LossAfter        6.90848\n",
      "GaussianMLPValueFunction/LossBefore       6.92546\n",
      "GaussianMLPValueFunction/dLoss            0.0169764\n",
      "TotalEnvSteps                        766800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:29 | [trpo_pendulum] epoch #639 | Saving snapshot...\n",
      "2022-08-17 18:11:29 | [trpo_pendulum] epoch #639 | Saved\n",
      "2022-08-17 18:11:29 | [trpo_pendulum] epoch #639 | Time 405.31 s\n",
      "2022-08-17 18:11:29 | [trpo_pendulum] epoch #639 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -642.575\n",
      "Evaluation/AverageReturn              -1534.8\n",
      "Evaluation/Iteration                    639\n",
      "Evaluation/MaxReturn                  -1515.06\n",
      "Evaluation/MinReturn                  -1562.21\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     16.5211\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.94953\n",
      "GaussianMLPPolicy/KL                      0.00692701\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              49.3733\n",
      "GaussianMLPPolicy/LossBefore             50.4145\n",
      "GaussianMLPPolicy/dLoss                   1.04118\n",
      "GaussianMLPValueFunction/LossAfter        6.75363\n",
      "GaussianMLPValueFunction/LossBefore       6.75574\n",
      "GaussianMLPValueFunction/dLoss            0.00211525\n",
      "TotalEnvSteps                        768000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:30 | [trpo_pendulum] epoch #640 | Saving snapshot...\n",
      "2022-08-17 18:11:30 | [trpo_pendulum] epoch #640 | Saved\n",
      "2022-08-17 18:11:30 | [trpo_pendulum] epoch #640 | Time 405.96 s\n",
      "2022-08-17 18:11:30 | [trpo_pendulum] epoch #640 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -547.303\n",
      "Evaluation/AverageReturn              -1367.39\n",
      "Evaluation/Iteration                    640\n",
      "Evaluation/MaxReturn                   -812.734\n",
      "Evaluation/MinReturn                  -1518.63\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    252.712\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.94226\n",
      "GaussianMLPPolicy/KL                      0.00715184\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              29.9579\n",
      "GaussianMLPPolicy/LossBefore             30.9604\n",
      "GaussianMLPPolicy/dLoss                   1.00249\n",
      "GaussianMLPValueFunction/LossAfter        6.70344\n",
      "GaussianMLPValueFunction/LossBefore       6.70673\n",
      "GaussianMLPValueFunction/dLoss            0.0032835\n",
      "TotalEnvSteps                        769200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:30 | [trpo_pendulum] epoch #641 | Saving snapshot...\n",
      "2022-08-17 18:11:30 | [trpo_pendulum] epoch #641 | Saved\n",
      "2022-08-17 18:11:30 | [trpo_pendulum] epoch #641 | Time 406.61 s\n",
      "2022-08-17 18:11:30 | [trpo_pendulum] epoch #641 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -557.482\n",
      "Evaluation/AverageReturn              -1375.42\n",
      "Evaluation/Iteration                    641\n",
      "Evaluation/MaxReturn                   -850.404\n",
      "Evaluation/MinReturn                  -1512.52\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    235.977\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.89779\n",
      "GaussianMLPPolicy/KL                      0.00757097\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              26.9797\n",
      "GaussianMLPPolicy/LossBefore             28.4152\n",
      "GaussianMLPPolicy/dLoss                   1.43555\n",
      "GaussianMLPValueFunction/LossAfter        6.6542\n",
      "GaussianMLPValueFunction/LossBefore       6.65998\n",
      "GaussianMLPValueFunction/dLoss            0.00578403\n",
      "TotalEnvSteps                        770400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:31 | [trpo_pendulum] epoch #642 | Saving snapshot...\n",
      "2022-08-17 18:11:31 | [trpo_pendulum] epoch #642 | Saved\n",
      "2022-08-17 18:11:31 | [trpo_pendulum] epoch #642 | Time 407.23 s\n",
      "2022-08-17 18:11:31 | [trpo_pendulum] epoch #642 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -609.504\n",
      "Evaluation/AverageReturn              -1470.55\n",
      "Evaluation/Iteration                    642\n",
      "Evaluation/MaxReturn                  -1286.84\n",
      "Evaluation/MinReturn                  -1581.59\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    105.475\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.90089\n",
      "GaussianMLPPolicy/KL                      0.00643659\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              36.1745\n",
      "GaussianMLPPolicy/LossBefore             39.0046\n",
      "GaussianMLPPolicy/dLoss                   2.83007\n",
      "GaussianMLPValueFunction/LossAfter        6.63545\n",
      "GaussianMLPValueFunction/LossBefore       6.64119\n",
      "GaussianMLPValueFunction/dLoss            0.00574064\n",
      "TotalEnvSteps                        771600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:32 | [trpo_pendulum] epoch #643 | Saving snapshot...\n",
      "2022-08-17 18:11:32 | [trpo_pendulum] epoch #643 | Saved\n",
      "2022-08-17 18:11:32 | [trpo_pendulum] epoch #643 | Time 407.88 s\n",
      "2022-08-17 18:11:32 | [trpo_pendulum] epoch #643 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -709.964\n",
      "Evaluation/AverageReturn              -1649.13\n",
      "Evaluation/Iteration                    643\n",
      "Evaluation/MaxReturn                  -1620.11\n",
      "Evaluation/MinReturn                  -1671.02\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     16.0142\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.9081\n",
      "GaussianMLPPolicy/KL                      0.00670738\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              58.6915\n",
      "GaussianMLPPolicy/LossBefore             60.2372\n",
      "GaussianMLPPolicy/dLoss                   1.54573\n",
      "GaussianMLPValueFunction/LossAfter        6.79564\n",
      "GaussianMLPValueFunction/LossBefore       6.80472\n",
      "GaussianMLPValueFunction/dLoss            0.00908375\n",
      "TotalEnvSteps                        772800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:32 | [trpo_pendulum] epoch #644 | Saving snapshot...\n",
      "2022-08-17 18:11:32 | [trpo_pendulum] epoch #644 | Saved\n",
      "2022-08-17 18:11:32 | [trpo_pendulum] epoch #644 | Time 408.51 s\n",
      "2022-08-17 18:11:32 | [trpo_pendulum] epoch #644 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -693.797\n",
      "Evaluation/AverageReturn              -1611.66\n",
      "Evaluation/Iteration                    644\n",
      "Evaluation/MaxReturn                  -1522.79\n",
      "Evaluation/MinReturn                  -1671.57\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     57.1195\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.88638\n",
      "GaussianMLPPolicy/KL                      0.0070443\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              53.258\n",
      "GaussianMLPPolicy/LossBefore             54.8034\n",
      "GaussianMLPPolicy/dLoss                   1.54539\n",
      "GaussianMLPValueFunction/LossAfter        6.7688\n",
      "GaussianMLPValueFunction/LossBefore       6.77244\n",
      "GaussianMLPValueFunction/dLoss            0.00363874\n",
      "TotalEnvSteps                        774000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:33 | [trpo_pendulum] epoch #645 | Saving snapshot...\n",
      "2022-08-17 18:11:33 | [trpo_pendulum] epoch #645 | Saved\n",
      "2022-08-17 18:11:33 | [trpo_pendulum] epoch #645 | Time 409.14 s\n",
      "2022-08-17 18:11:33 | [trpo_pendulum] epoch #645 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -586.881\n",
      "Evaluation/AverageReturn              -1472.39\n",
      "Evaluation/Iteration                    645\n",
      "Evaluation/MaxReturn                  -1388.51\n",
      "Evaluation/MinReturn                  -1495.31\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     37.686\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.87208\n",
      "GaussianMLPPolicy/KL                      0.00871767\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              39.7628\n",
      "GaussianMLPPolicy/LossBefore             41.2393\n",
      "GaussianMLPPolicy/dLoss                   1.47652\n",
      "GaussianMLPValueFunction/LossAfter        6.65597\n",
      "GaussianMLPValueFunction/LossBefore       6.66182\n",
      "GaussianMLPValueFunction/dLoss            0.00584936\n",
      "TotalEnvSteps                        775200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:33 | [trpo_pendulum] epoch #646 | Saving snapshot...\n",
      "2022-08-17 18:11:34 | [trpo_pendulum] epoch #646 | Saved\n",
      "2022-08-17 18:11:34 | [trpo_pendulum] epoch #646 | Time 409.79 s\n",
      "2022-08-17 18:11:34 | [trpo_pendulum] epoch #646 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -411.947\n",
      "Evaluation/AverageReturn              -1067.38\n",
      "Evaluation/Iteration                    646\n",
      "Evaluation/MaxReturn                   -946.261\n",
      "Evaluation/MinReturn                  -1182.66\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     82.261\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.86596\n",
      "GaussianMLPPolicy/KL                      0.00909733\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -14.9615\n",
      "GaussianMLPPolicy/LossBefore            -14.259\n",
      "GaussianMLPPolicy/dLoss                   0.702522\n",
      "GaussianMLPValueFunction/LossAfter        6.46212\n",
      "GaussianMLPValueFunction/LossBefore       6.49439\n",
      "GaussianMLPValueFunction/dLoss            0.0322738\n",
      "TotalEnvSteps                        776400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:34 | [trpo_pendulum] epoch #647 | Saving snapshot...\n",
      "2022-08-17 18:11:34 | [trpo_pendulum] epoch #647 | Saved\n",
      "2022-08-17 18:11:34 | [trpo_pendulum] epoch #647 | Time 410.44 s\n",
      "2022-08-17 18:11:34 | [trpo_pendulum] epoch #647 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -591.778\n",
      "Evaluation/AverageReturn              -1486.31\n",
      "Evaluation/Iteration                    647\n",
      "Evaluation/MaxReturn                  -1379.08\n",
      "Evaluation/MinReturn                  -1520.4\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     48.8203\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.86354\n",
      "GaussianMLPPolicy/KL                      0.00751847\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              42.5076\n",
      "GaussianMLPPolicy/LossBefore             43.9351\n",
      "GaussianMLPPolicy/dLoss                   1.42744\n",
      "GaussianMLPValueFunction/LossAfter        6.69543\n",
      "GaussianMLPValueFunction/LossBefore       6.69939\n",
      "GaussianMLPValueFunction/dLoss            0.00395679\n",
      "TotalEnvSteps                        777600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:35 | [trpo_pendulum] epoch #648 | Saving snapshot...\n",
      "2022-08-17 18:11:35 | [trpo_pendulum] epoch #648 | Saved\n",
      "2022-08-17 18:11:35 | [trpo_pendulum] epoch #648 | Time 411.08 s\n",
      "2022-08-17 18:11:35 | [trpo_pendulum] epoch #648 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -646.637\n",
      "Evaluation/AverageReturn              -1570.32\n",
      "Evaluation/Iteration                    648\n",
      "Evaluation/MaxReturn                  -1549.64\n",
      "Evaluation/MinReturn                  -1588.15\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     13.7021\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.86157\n",
      "GaussianMLPPolicy/KL                      0.00581392\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              52.6547\n",
      "GaussianMLPPolicy/LossBefore             53.9244\n",
      "GaussianMLPPolicy/dLoss                   1.26962\n",
      "GaussianMLPValueFunction/LossAfter        6.77135\n",
      "GaussianMLPValueFunction/LossBefore       6.78263\n",
      "GaussianMLPValueFunction/dLoss            0.0112834\n",
      "TotalEnvSteps                        778800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:35 | [trpo_pendulum] epoch #649 | Saving snapshot...\n",
      "2022-08-17 18:11:35 | [trpo_pendulum] epoch #649 | Saved\n",
      "2022-08-17 18:11:35 | [trpo_pendulum] epoch #649 | Time 411.72 s\n",
      "2022-08-17 18:11:35 | [trpo_pendulum] epoch #649 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -502.289\n",
      "Evaluation/AverageReturn              -1234.94\n",
      "Evaluation/Iteration                    649\n",
      "Evaluation/MaxReturn                  -1011.06\n",
      "Evaluation/MinReturn                  -1466.98\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    139.049\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.85439\n",
      "GaussianMLPPolicy/KL                      0.0066721\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.676641\n",
      "GaussianMLPPolicy/LossBefore              2.21549\n",
      "GaussianMLPPolicy/dLoss                   1.53885\n",
      "GaussianMLPValueFunction/LossAfter        6.46781\n",
      "GaussianMLPValueFunction/LossBefore       6.49101\n",
      "GaussianMLPValueFunction/dLoss            0.0232062\n",
      "TotalEnvSteps                        780000\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:11:36 | [trpo_pendulum] epoch #650 | Saving snapshot...\n",
      "2022-08-17 18:11:36 | [trpo_pendulum] epoch #650 | Saved\n",
      "2022-08-17 18:11:36 | [trpo_pendulum] epoch #650 | Time 412.38 s\n",
      "2022-08-17 18:11:36 | [trpo_pendulum] epoch #650 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -619.43\n",
      "Evaluation/AverageReturn              -1534.58\n",
      "Evaluation/Iteration                    650\n",
      "Evaluation/MaxReturn                  -1514.8\n",
      "Evaluation/MinReturn                  -1553.96\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     13.5234\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.8759\n",
      "GaussianMLPPolicy/KL                      0.00766858\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              49.6778\n",
      "GaussianMLPPolicy/LossBefore             51.1809\n",
      "GaussianMLPPolicy/dLoss                   1.50308\n",
      "GaussianMLPValueFunction/LossAfter        6.77009\n",
      "GaussianMLPValueFunction/LossBefore       6.78322\n",
      "GaussianMLPValueFunction/dLoss            0.0131283\n",
      "TotalEnvSteps                        781200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:37 | [trpo_pendulum] epoch #651 | Saving snapshot...\n",
      "2022-08-17 18:11:37 | [trpo_pendulum] epoch #651 | Saved\n",
      "2022-08-17 18:11:37 | [trpo_pendulum] epoch #651 | Time 413.02 s\n",
      "2022-08-17 18:11:37 | [trpo_pendulum] epoch #651 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -735.437\n",
      "Evaluation/AverageReturn              -1670.02\n",
      "Evaluation/Iteration                    651\n",
      "Evaluation/MaxReturn                  -1624.73\n",
      "Evaluation/MinReturn                  -1733.08\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     35.6759\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.85879\n",
      "GaussianMLPPolicy/KL                      0.00653177\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              55.4379\n",
      "GaussianMLPPolicy/LossBefore             57.0443\n",
      "GaussianMLPPolicy/dLoss                   1.60638\n",
      "GaussianMLPValueFunction/LossAfter        6.80685\n",
      "GaussianMLPValueFunction/LossBefore       6.82053\n",
      "GaussianMLPValueFunction/dLoss            0.0136814\n",
      "TotalEnvSteps                        782400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:37 | [trpo_pendulum] epoch #652 | Saving snapshot...\n",
      "2022-08-17 18:11:37 | [trpo_pendulum] epoch #652 | Saved\n",
      "2022-08-17 18:11:37 | [trpo_pendulum] epoch #652 | Time 413.68 s\n",
      "2022-08-17 18:11:37 | [trpo_pendulum] epoch #652 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -549.219\n",
      "Evaluation/AverageReturn              -1308.47\n",
      "Evaluation/Iteration                    652\n",
      "Evaluation/MaxReturn                  -1242.54\n",
      "Evaluation/MinReturn                  -1348.02\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     40.1039\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.84439\n",
      "GaussianMLPPolicy/KL                      0.0054896\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              11.7002\n",
      "GaussianMLPPolicy/LossBefore             12.1734\n",
      "GaussianMLPPolicy/dLoss                   0.473231\n",
      "GaussianMLPValueFunction/LossAfter        6.54174\n",
      "GaussianMLPValueFunction/LossBefore       6.55448\n",
      "GaussianMLPValueFunction/dLoss            0.0127306\n",
      "TotalEnvSteps                        783600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:11:38 | [trpo_pendulum] epoch #653 | Saving snapshot...\n",
      "2022-08-17 18:11:38 | [trpo_pendulum] epoch #653 | Saved\n",
      "2022-08-17 18:11:38 | [trpo_pendulum] epoch #653 | Time 414.32 s\n",
      "2022-08-17 18:11:38 | [trpo_pendulum] epoch #653 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -520.815\n",
      "Evaluation/AverageReturn              -1276.26\n",
      "Evaluation/Iteration                    653\n",
      "Evaluation/MaxReturn                  -1188.33\n",
      "Evaluation/MinReturn                  -1347.58\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     61.1145\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.84234\n",
      "GaussianMLPPolicy/KL                      0.00745227\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               7.87145\n",
      "GaussianMLPPolicy/LossBefore              8.71031\n",
      "GaussianMLPPolicy/dLoss                   0.838858\n",
      "GaussianMLPValueFunction/LossAfter        6.51411\n",
      "GaussianMLPValueFunction/LossBefore       6.52509\n",
      "GaussianMLPValueFunction/dLoss            0.0109801\n",
      "TotalEnvSteps                        784800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:39 | [trpo_pendulum] epoch #654 | Saving snapshot...\n",
      "2022-08-17 18:11:39 | [trpo_pendulum] epoch #654 | Saved\n",
      "2022-08-17 18:11:39 | [trpo_pendulum] epoch #654 | Time 414.97 s\n",
      "2022-08-17 18:11:39 | [trpo_pendulum] epoch #654 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -682.394\n",
      "Evaluation/AverageReturn              -1605.99\n",
      "Evaluation/Iteration                    654\n",
      "Evaluation/MaxReturn                  -1561.94\n",
      "Evaluation/MinReturn                  -1690.27\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     43.4507\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.81368\n",
      "GaussianMLPPolicy/KL                      0.00919008\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              50.4215\n",
      "GaussianMLPPolicy/LossBefore             52.4413\n",
      "GaussianMLPPolicy/dLoss                   2.01977\n",
      "GaussianMLPValueFunction/LossAfter        6.76535\n",
      "GaussianMLPValueFunction/LossBefore       6.77928\n",
      "GaussianMLPValueFunction/dLoss            0.0139236\n",
      "TotalEnvSteps                        786000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:39 | [trpo_pendulum] epoch #655 | Saving snapshot...\n",
      "2022-08-17 18:11:39 | [trpo_pendulum] epoch #655 | Saved\n",
      "2022-08-17 18:11:39 | [trpo_pendulum] epoch #655 | Time 415.62 s\n",
      "2022-08-17 18:11:39 | [trpo_pendulum] epoch #655 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -668.041\n",
      "Evaluation/AverageReturn              -1617.18\n",
      "Evaluation/Iteration                    655\n",
      "Evaluation/MaxReturn                  -1607.38\n",
      "Evaluation/MinReturn                  -1623.35\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.70377\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.77552\n",
      "GaussianMLPPolicy/KL                      0.00990116\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              56.886\n",
      "GaussianMLPPolicy/LossBefore             57.3273\n",
      "GaussianMLPPolicy/dLoss                   0.441383\n",
      "GaussianMLPValueFunction/LossAfter        6.78147\n",
      "GaussianMLPValueFunction/LossBefore       6.79323\n",
      "GaussianMLPValueFunction/dLoss            0.0117607\n",
      "TotalEnvSteps                        787200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:40 | [trpo_pendulum] epoch #656 | Saving snapshot...\n",
      "2022-08-17 18:11:40 | [trpo_pendulum] epoch #656 | Saved\n",
      "2022-08-17 18:11:40 | [trpo_pendulum] epoch #656 | Time 416.27 s\n",
      "2022-08-17 18:11:40 | [trpo_pendulum] epoch #656 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -603.237\n",
      "Evaluation/AverageReturn              -1443.14\n",
      "Evaluation/Iteration                    656\n",
      "Evaluation/MaxReturn                  -1199.74\n",
      "Evaluation/MinReturn                  -1714.56\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    183.1\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.79731\n",
      "GaussianMLPPolicy/KL                      0.00962005\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              25.1548\n",
      "GaussianMLPPolicy/LossBefore             27.647\n",
      "GaussianMLPPolicy/dLoss                   2.49214\n",
      "GaussianMLPValueFunction/LossAfter        6.62197\n",
      "GaussianMLPValueFunction/LossBefore       6.6252\n",
      "GaussianMLPValueFunction/dLoss            0.00322533\n",
      "TotalEnvSteps                        788400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:41 | [trpo_pendulum] epoch #657 | Saving snapshot...\n",
      "2022-08-17 18:11:41 | [trpo_pendulum] epoch #657 | Saved\n",
      "2022-08-17 18:11:41 | [trpo_pendulum] epoch #657 | Time 416.91 s\n",
      "2022-08-17 18:11:41 | [trpo_pendulum] epoch #657 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -562.885\n",
      "Evaluation/AverageReturn              -1389.06\n",
      "Evaluation/Iteration                    657\n",
      "Evaluation/MaxReturn                  -1197.99\n",
      "Evaluation/MinReturn                  -1488.58\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    110.19\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.80909\n",
      "GaussianMLPPolicy/KL                      0.00901218\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              20.4402\n",
      "GaussianMLPPolicy/LossBefore             21.7385\n",
      "GaussianMLPPolicy/dLoss                   1.29828\n",
      "GaussianMLPValueFunction/LossAfter        6.53956\n",
      "GaussianMLPValueFunction/LossBefore       6.54915\n",
      "GaussianMLPValueFunction/dLoss            0.0095892\n",
      "TotalEnvSteps                        789600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:41 | [trpo_pendulum] epoch #658 | Saving snapshot...\n",
      "2022-08-17 18:11:41 | [trpo_pendulum] epoch #658 | Saved\n",
      "2022-08-17 18:11:41 | [trpo_pendulum] epoch #658 | Time 417.56 s\n",
      "2022-08-17 18:11:41 | [trpo_pendulum] epoch #658 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -608.172\n",
      "Evaluation/AverageReturn              -1514.47\n",
      "Evaluation/Iteration                    658\n",
      "Evaluation/MaxReturn                  -1498.79\n",
      "Evaluation/MinReturn                  -1526.89\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      9.21397\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.81857\n",
      "GaussianMLPPolicy/KL                      0.00812678\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              41.1792\n",
      "GaussianMLPPolicy/LossBefore             42.8535\n",
      "GaussianMLPPolicy/dLoss                   1.67428\n",
      "GaussianMLPValueFunction/LossAfter        6.6973\n",
      "GaussianMLPValueFunction/LossBefore       6.70176\n",
      "GaussianMLPValueFunction/dLoss            0.0044651\n",
      "TotalEnvSteps                        790800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:42 | [trpo_pendulum] epoch #659 | Saving snapshot...\n",
      "2022-08-17 18:11:42 | [trpo_pendulum] epoch #659 | Saved\n",
      "2022-08-17 18:11:42 | [trpo_pendulum] epoch #659 | Time 418.20 s\n",
      "2022-08-17 18:11:42 | [trpo_pendulum] epoch #659 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -424.336\n",
      "Evaluation/AverageReturn              -1189.61\n",
      "Evaluation/Iteration                    659\n",
      "Evaluation/MaxReturn                  -1063.91\n",
      "Evaluation/MinReturn                  -1239.18\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     59.3688\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.81599\n",
      "GaussianMLPPolicy/KL                      0.00681615\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               3.93842\n",
      "GaussianMLPPolicy/LossBefore              5.12784\n",
      "GaussianMLPPolicy/dLoss                   1.18942\n",
      "GaussianMLPValueFunction/LossAfter        6.50654\n",
      "GaussianMLPValueFunction/LossBefore       6.51747\n",
      "GaussianMLPValueFunction/dLoss            0.0109339\n",
      "TotalEnvSteps                        792000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:43 | [trpo_pendulum] epoch #660 | Saving snapshot...\n",
      "2022-08-17 18:11:43 | [trpo_pendulum] epoch #660 | Saved\n",
      "2022-08-17 18:11:43 | [trpo_pendulum] epoch #660 | Time 418.87 s\n",
      "2022-08-17 18:11:43 | [trpo_pendulum] epoch #660 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -709.508\n",
      "Evaluation/AverageReturn              -1614.84\n",
      "Evaluation/Iteration                    660\n",
      "Evaluation/MaxReturn                  -1571.7\n",
      "Evaluation/MinReturn                  -1661.82\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     33.8263\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.81621\n",
      "GaussianMLPPolicy/KL                      0.00673531\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              44.794\n",
      "GaussianMLPPolicy/LossBefore             46.6158\n",
      "GaussianMLPPolicy/dLoss                   1.8218\n",
      "GaussianMLPValueFunction/LossAfter        6.72971\n",
      "GaussianMLPValueFunction/LossBefore       6.74004\n",
      "GaussianMLPValueFunction/dLoss            0.0103364\n",
      "TotalEnvSteps                        793200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:43 | [trpo_pendulum] epoch #661 | Saving snapshot...\n",
      "2022-08-17 18:11:43 | [trpo_pendulum] epoch #661 | Saved\n",
      "2022-08-17 18:11:43 | [trpo_pendulum] epoch #661 | Time 419.51 s\n",
      "2022-08-17 18:11:43 | [trpo_pendulum] epoch #661 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -666.587\n",
      "Evaluation/AverageReturn              -1604.43\n",
      "Evaluation/Iteration                    661\n",
      "Evaluation/MaxReturn                  -1585.51\n",
      "Evaluation/MinReturn                  -1621.51\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     13.5912\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.82728\n",
      "GaussianMLPPolicy/KL                      0.00583571\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              50.0323\n",
      "GaussianMLPPolicy/LossBefore             51.4034\n",
      "GaussianMLPPolicy/dLoss                   1.37107\n",
      "GaussianMLPValueFunction/LossAfter        6.74849\n",
      "GaussianMLPValueFunction/LossBefore       6.75811\n",
      "GaussianMLPValueFunction/dLoss            0.00961494\n",
      "TotalEnvSteps                        794400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:44 | [trpo_pendulum] epoch #662 | Saving snapshot...\n",
      "2022-08-17 18:11:44 | [trpo_pendulum] epoch #662 | Saved\n",
      "2022-08-17 18:11:44 | [trpo_pendulum] epoch #662 | Time 420.15 s\n",
      "2022-08-17 18:11:44 | [trpo_pendulum] epoch #662 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -537.391\n",
      "Evaluation/AverageReturn              -1335.99\n",
      "Evaluation/Iteration                    662\n",
      "Evaluation/MaxReturn                  -1189.31\n",
      "Evaluation/MinReturn                  -1506.8\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    129.249\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.8175\n",
      "GaussianMLPPolicy/KL                      0.00682486\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              13.3871\n",
      "GaussianMLPPolicy/LossBefore             14.7464\n",
      "GaussianMLPPolicy/dLoss                   1.35926\n",
      "GaussianMLPValueFunction/LossAfter        6.56888\n",
      "GaussianMLPValueFunction/LossBefore       6.57512\n",
      "GaussianMLPValueFunction/dLoss            0.00624275\n",
      "TotalEnvSteps                        795600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:44 | [trpo_pendulum] epoch #663 | Saving snapshot...\n",
      "2022-08-17 18:11:45 | [trpo_pendulum] epoch #663 | Saved\n",
      "2022-08-17 18:11:45 | [trpo_pendulum] epoch #663 | Time 420.78 s\n",
      "2022-08-17 18:11:45 | [trpo_pendulum] epoch #663 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -714.975\n",
      "Evaluation/AverageReturn              -1623.55\n",
      "Evaluation/Iteration                    663\n",
      "Evaluation/MaxReturn                  -1560.02\n",
      "Evaluation/MinReturn                  -1680.22\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     50.3417\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.81122\n",
      "GaussianMLPPolicy/KL                      0.008872\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              43.8176\n",
      "GaussianMLPPolicy/LossBefore             45.9201\n",
      "GaussianMLPPolicy/dLoss                   2.10241\n",
      "GaussianMLPValueFunction/LossAfter        6.73701\n",
      "GaussianMLPValueFunction/LossBefore       6.74371\n",
      "GaussianMLPValueFunction/dLoss            0.00669861\n",
      "TotalEnvSteps                        796800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:45 | [trpo_pendulum] epoch #664 | Saving snapshot...\n",
      "2022-08-17 18:11:45 | [trpo_pendulum] epoch #664 | Saved\n",
      "2022-08-17 18:11:45 | [trpo_pendulum] epoch #664 | Time 421.40 s\n",
      "2022-08-17 18:11:45 | [trpo_pendulum] epoch #664 | EpochTime 0.62 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -696.353\n",
      "Evaluation/AverageReturn              -1567.36\n",
      "Evaluation/Iteration                    664\n",
      "Evaluation/MaxReturn                  -1532.3\n",
      "Evaluation/MinReturn                  -1643.85\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     35.6549\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.8023\n",
      "GaussianMLPPolicy/KL                      0.00621556\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              35.0176\n",
      "GaussianMLPPolicy/LossBefore             36.3946\n",
      "GaussianMLPPolicy/dLoss                   1.37691\n",
      "GaussianMLPValueFunction/LossAfter        6.68328\n",
      "GaussianMLPValueFunction/LossBefore       6.68421\n",
      "GaussianMLPValueFunction/dLoss            0.000923157\n",
      "TotalEnvSteps                        798000\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:11:46 | [trpo_pendulum] epoch #665 | Saving snapshot...\n",
      "2022-08-17 18:11:46 | [trpo_pendulum] epoch #665 | Saved\n",
      "2022-08-17 18:11:46 | [trpo_pendulum] epoch #665 | Time 422.04 s\n",
      "2022-08-17 18:11:46 | [trpo_pendulum] epoch #665 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -602.702\n",
      "Evaluation/AverageReturn              -1489.59\n",
      "Evaluation/Iteration                    665\n",
      "Evaluation/MaxReturn                  -1477.78\n",
      "Evaluation/MinReturn                  -1529.73\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     18.3982\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.82196\n",
      "GaussianMLPPolicy/KL                      0.00541936\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              33.6865\n",
      "GaussianMLPPolicy/LossBefore             34.8864\n",
      "GaussianMLPPolicy/dLoss                   1.19989\n",
      "GaussianMLPValueFunction/LossAfter        6.63022\n",
      "GaussianMLPValueFunction/LossBefore       6.63287\n",
      "GaussianMLPValueFunction/dLoss            0.00264788\n",
      "TotalEnvSteps                        799200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:46 | [trpo_pendulum] epoch #666 | Saving snapshot...\n",
      "2022-08-17 18:11:46 | [trpo_pendulum] epoch #666 | Saved\n",
      "2022-08-17 18:11:46 | [trpo_pendulum] epoch #666 | Time 422.72 s\n",
      "2022-08-17 18:11:46 | [trpo_pendulum] epoch #666 | EpochTime 0.67 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -608.289\n",
      "Evaluation/AverageReturn              -1491.84\n",
      "Evaluation/Iteration                    666\n",
      "Evaluation/MaxReturn                  -1460.03\n",
      "Evaluation/MinReturn                  -1521.26\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     20.9467\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.83176\n",
      "GaussianMLPPolicy/KL                      0.0068584\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              35.1847\n",
      "GaussianMLPPolicy/LossBefore             35.8574\n",
      "GaussianMLPPolicy/dLoss                   0.672653\n",
      "GaussianMLPValueFunction/LossAfter        6.6551\n",
      "GaussianMLPValueFunction/LossBefore       6.65633\n",
      "GaussianMLPValueFunction/dLoss            0.00122881\n",
      "TotalEnvSteps                        800400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:47 | [trpo_pendulum] epoch #667 | Saving snapshot...\n",
      "2022-08-17 18:11:47 | [trpo_pendulum] epoch #667 | Saved\n",
      "2022-08-17 18:11:47 | [trpo_pendulum] epoch #667 | Time 423.41 s\n",
      "2022-08-17 18:11:47 | [trpo_pendulum] epoch #667 | EpochTime 0.68 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -585.839\n",
      "Evaluation/AverageReturn              -1434.87\n",
      "Evaluation/Iteration                    667\n",
      "Evaluation/MaxReturn                  -1385.28\n",
      "Evaluation/MinReturn                  -1481.9\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     40.1962\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.85303\n",
      "GaussianMLPPolicy/KL                      0.00668787\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              24.0051\n",
      "GaussianMLPPolicy/LossBefore             25.5058\n",
      "GaussianMLPPolicy/dLoss                   1.50077\n",
      "GaussianMLPValueFunction/LossAfter        6.60185\n",
      "GaussianMLPValueFunction/LossBefore       6.6042\n",
      "GaussianMLPValueFunction/dLoss            0.00235415\n",
      "TotalEnvSteps                        801600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:48 | [trpo_pendulum] epoch #668 | Saving snapshot...\n",
      "2022-08-17 18:11:48 | [trpo_pendulum] epoch #668 | Saved\n",
      "2022-08-17 18:11:48 | [trpo_pendulum] epoch #668 | Time 424.06 s\n",
      "2022-08-17 18:11:48 | [trpo_pendulum] epoch #668 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -503.767\n",
      "Evaluation/AverageReturn              -1348.18\n",
      "Evaluation/Iteration                    668\n",
      "Evaluation/MaxReturn                  -1301.25\n",
      "Evaluation/MinReturn                  -1378.69\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     27.2801\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.84052\n",
      "GaussianMLPPolicy/KL                      0.00833922\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              21.685\n",
      "GaussianMLPPolicy/LossBefore             22.397\n",
      "GaussianMLPPolicy/dLoss                   0.712091\n",
      "GaussianMLPValueFunction/LossAfter        6.58034\n",
      "GaussianMLPValueFunction/LossBefore       6.58263\n",
      "GaussianMLPValueFunction/dLoss            0.0022831\n",
      "TotalEnvSteps                        802800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:48 | [trpo_pendulum] epoch #669 | Saving snapshot...\n",
      "2022-08-17 18:11:48 | [trpo_pendulum] epoch #669 | Saved\n",
      "2022-08-17 18:11:48 | [trpo_pendulum] epoch #669 | Time 424.71 s\n",
      "2022-08-17 18:11:48 | [trpo_pendulum] epoch #669 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -601.038\n",
      "Evaluation/AverageReturn              -1483.12\n",
      "Evaluation/Iteration                    669\n",
      "Evaluation/MaxReturn                  -1384.32\n",
      "Evaluation/MinReturn                  -1561.33\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     69.2679\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.87566\n",
      "GaussianMLPPolicy/KL                      0.00818356\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              30.8529\n",
      "GaussianMLPPolicy/LossBefore             32.7393\n",
      "GaussianMLPPolicy/dLoss                   1.88645\n",
      "GaussianMLPValueFunction/LossAfter        6.67034\n",
      "GaussianMLPValueFunction/LossBefore       6.67373\n",
      "GaussianMLPValueFunction/dLoss            0.00338554\n",
      "TotalEnvSteps                        804000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:49 | [trpo_pendulum] epoch #670 | Saving snapshot...\n",
      "2022-08-17 18:11:49 | [trpo_pendulum] epoch #670 | Saved\n",
      "2022-08-17 18:11:49 | [trpo_pendulum] epoch #670 | Time 425.37 s\n",
      "2022-08-17 18:11:49 | [trpo_pendulum] epoch #670 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -702.231\n",
      "Evaluation/AverageReturn              -1617.55\n",
      "Evaluation/Iteration                    670\n",
      "Evaluation/MaxReturn                  -1555.49\n",
      "Evaluation/MinReturn                  -1661.26\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     31.7354\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.8493\n",
      "GaussianMLPPolicy/KL                      0.00762806\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              41.5354\n",
      "GaussianMLPPolicy/LossBefore             43.7868\n",
      "GaussianMLPPolicy/dLoss                   2.25142\n",
      "GaussianMLPValueFunction/LossAfter        6.73767\n",
      "GaussianMLPValueFunction/LossBefore       6.74703\n",
      "GaussianMLPValueFunction/dLoss            0.00935745\n",
      "TotalEnvSteps                        805200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:50 | [trpo_pendulum] epoch #671 | Saving snapshot...\n",
      "2022-08-17 18:11:50 | [trpo_pendulum] epoch #671 | Saved\n",
      "2022-08-17 18:11:50 | [trpo_pendulum] epoch #671 | Time 426.02 s\n",
      "2022-08-17 18:11:50 | [trpo_pendulum] epoch #671 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -667.482\n",
      "Evaluation/AverageReturn              -1570.82\n",
      "Evaluation/Iteration                    671\n",
      "Evaluation/MaxReturn                  -1519.63\n",
      "Evaluation/MinReturn                  -1622.68\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     40.3082\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.8868\n",
      "GaussianMLPPolicy/KL                      0.00669412\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              36.3121\n",
      "GaussianMLPPolicy/LossBefore             39.0524\n",
      "GaussianMLPPolicy/dLoss                   2.74029\n",
      "GaussianMLPValueFunction/LossAfter        6.68464\n",
      "GaussianMLPValueFunction/LossBefore       6.68622\n",
      "GaussianMLPValueFunction/dLoss            0.00158167\n",
      "TotalEnvSteps                        806400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:50 | [trpo_pendulum] epoch #672 | Saving snapshot...\n",
      "2022-08-17 18:11:50 | [trpo_pendulum] epoch #672 | Saved\n",
      "2022-08-17 18:11:50 | [trpo_pendulum] epoch #672 | Time 426.66 s\n",
      "2022-08-17 18:11:50 | [trpo_pendulum] epoch #672 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -492.135\n",
      "Evaluation/AverageReturn              -1284.81\n",
      "Evaluation/Iteration                    672\n",
      "Evaluation/MaxReturn                  -1213.05\n",
      "Evaluation/MinReturn                  -1337.75\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     41.857\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.85081\n",
      "GaussianMLPPolicy/KL                      0.00813156\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               7.99476\n",
      "GaussianMLPPolicy/LossBefore              8.58594\n",
      "GaussianMLPPolicy/dLoss                   0.591179\n",
      "GaussianMLPValueFunction/LossAfter        6.53218\n",
      "GaussianMLPValueFunction/LossBefore       6.54566\n",
      "GaussianMLPValueFunction/dLoss            0.0134807\n",
      "TotalEnvSteps                        807600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:51 | [trpo_pendulum] epoch #673 | Saving snapshot...\n",
      "2022-08-17 18:11:51 | [trpo_pendulum] epoch #673 | Saved\n",
      "2022-08-17 18:11:51 | [trpo_pendulum] epoch #673 | Time 427.29 s\n",
      "2022-08-17 18:11:51 | [trpo_pendulum] epoch #673 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -526.968\n",
      "Evaluation/AverageReturn              -1292.88\n",
      "Evaluation/Iteration                    673\n",
      "Evaluation/MaxReturn                  -1197.48\n",
      "Evaluation/MinReturn                  -1353.63\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     52.7386\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.8409\n",
      "GaussianMLPPolicy/KL                      0.00995027\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               1.40693\n",
      "GaussianMLPPolicy/LossBefore              3.09548\n",
      "GaussianMLPPolicy/dLoss                   1.68855\n",
      "GaussianMLPValueFunction/LossAfter        6.52604\n",
      "GaussianMLPValueFunction/LossBefore       6.53288\n",
      "GaussianMLPValueFunction/dLoss            0.00683928\n",
      "TotalEnvSteps                        808800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:52 | [trpo_pendulum] epoch #674 | Saving snapshot...\n",
      "2022-08-17 18:11:52 | [trpo_pendulum] epoch #674 | Saved\n",
      "2022-08-17 18:11:52 | [trpo_pendulum] epoch #674 | Time 427.94 s\n",
      "2022-08-17 18:11:52 | [trpo_pendulum] epoch #674 | EpochTime 0.65 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -539.717\n",
      "Evaluation/AverageReturn              -1373.49\n",
      "Evaluation/Iteration                    674\n",
      "Evaluation/MaxReturn                  -1278.76\n",
      "Evaluation/MinReturn                  -1444.56\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     54.3064\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.85685\n",
      "GaussianMLPPolicy/KL                      0.00909569\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              16.0908\n",
      "GaussianMLPPolicy/LossBefore             17.7851\n",
      "GaussianMLPPolicy/dLoss                   1.69429\n",
      "GaussianMLPValueFunction/LossAfter        6.5557\n",
      "GaussianMLPValueFunction/LossBefore       6.5564\n",
      "GaussianMLPValueFunction/dLoss            0.000697613\n",
      "TotalEnvSteps                        810000\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:11:52 | [trpo_pendulum] epoch #675 | Saving snapshot...\n",
      "2022-08-17 18:11:52 | [trpo_pendulum] epoch #675 | Saved\n",
      "2022-08-17 18:11:52 | [trpo_pendulum] epoch #675 | Time 428.63 s\n",
      "2022-08-17 18:11:52 | [trpo_pendulum] epoch #675 | EpochTime 0.69 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -559.508\n",
      "Evaluation/AverageReturn              -1441.27\n",
      "Evaluation/Iteration                    675\n",
      "Evaluation/MaxReturn                  -1319.35\n",
      "Evaluation/MinReturn                  -1511.87\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     72.4665\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.83541\n",
      "GaussianMLPPolicy/KL                      0.00648248\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              29.6319\n",
      "GaussianMLPPolicy/LossBefore             30.86\n",
      "GaussianMLPPolicy/dLoss                   1.22815\n",
      "GaussianMLPValueFunction/LossAfter        6.62943\n",
      "GaussianMLPValueFunction/LossBefore       6.63275\n",
      "GaussianMLPValueFunction/dLoss            0.00332022\n",
      "TotalEnvSteps                        811200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:53 | [trpo_pendulum] epoch #676 | Saving snapshot...\n",
      "2022-08-17 18:11:53 | [trpo_pendulum] epoch #676 | Saved\n",
      "2022-08-17 18:11:53 | [trpo_pendulum] epoch #676 | Time 429.29 s\n",
      "2022-08-17 18:11:53 | [trpo_pendulum] epoch #676 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -493.964\n",
      "Evaluation/AverageReturn              -1221.62\n",
      "Evaluation/Iteration                    676\n",
      "Evaluation/MaxReturn                  -1131.52\n",
      "Evaluation/MinReturn                  -1384.09\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     80.7107\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.82659\n",
      "GaussianMLPPolicy/KL                      0.00712343\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -10.6763\n",
      "GaussianMLPPolicy/LossBefore             -9.76755\n",
      "GaussianMLPPolicy/dLoss                   0.908759\n",
      "GaussianMLPValueFunction/LossAfter        6.4412\n",
      "GaussianMLPValueFunction/LossBefore       6.45724\n",
      "GaussianMLPValueFunction/dLoss            0.0160418\n",
      "TotalEnvSteps                        812400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:54 | [trpo_pendulum] epoch #677 | Saving snapshot...\n",
      "2022-08-17 18:11:54 | [trpo_pendulum] epoch #677 | Saved\n",
      "2022-08-17 18:11:54 | [trpo_pendulum] epoch #677 | Time 429.94 s\n",
      "2022-08-17 18:11:54 | [trpo_pendulum] epoch #677 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -598.712\n",
      "Evaluation/AverageReturn              -1474.9\n",
      "Evaluation/Iteration                    677\n",
      "Evaluation/MaxReturn                  -1253\n",
      "Evaluation/MinReturn                  -1528.78\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     99.498\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.85325\n",
      "GaussianMLPPolicy/KL                      0.00739554\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              28.8647\n",
      "GaussianMLPPolicy/LossBefore             30.8607\n",
      "GaussianMLPPolicy/dLoss                   1.996\n",
      "GaussianMLPValueFunction/LossAfter        6.66452\n",
      "GaussianMLPValueFunction/LossBefore       6.67485\n",
      "GaussianMLPValueFunction/dLoss            0.0103264\n",
      "TotalEnvSteps                        813600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:54 | [trpo_pendulum] epoch #678 | Saving snapshot...\n",
      "2022-08-17 18:11:54 | [trpo_pendulum] epoch #678 | Saved\n",
      "2022-08-17 18:11:54 | [trpo_pendulum] epoch #678 | Time 430.60 s\n",
      "2022-08-17 18:11:54 | [trpo_pendulum] epoch #678 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -505.968\n",
      "Evaluation/AverageReturn              -1271.21\n",
      "Evaluation/Iteration                    678\n",
      "Evaluation/MaxReturn                  -1188.97\n",
      "Evaluation/MinReturn                  -1349.42\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     59.962\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.83821\n",
      "GaussianMLPPolicy/KL                      0.00778939\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               1.31196\n",
      "GaussianMLPPolicy/LossBefore              1.91493\n",
      "GaussianMLPPolicy/dLoss                   0.602972\n",
      "GaussianMLPValueFunction/LossAfter        6.49583\n",
      "GaussianMLPValueFunction/LossBefore       6.50104\n",
      "GaussianMLPValueFunction/dLoss            0.00521183\n",
      "TotalEnvSteps                        814800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:55 | [trpo_pendulum] epoch #679 | Saving snapshot...\n",
      "2022-08-17 18:11:55 | [trpo_pendulum] epoch #679 | Saved\n",
      "2022-08-17 18:11:55 | [trpo_pendulum] epoch #679 | Time 431.26 s\n",
      "2022-08-17 18:11:55 | [trpo_pendulum] epoch #679 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -509.27\n",
      "Evaluation/AverageReturn              -1285.34\n",
      "Evaluation/Iteration                    679\n",
      "Evaluation/MaxReturn                  -1199.61\n",
      "Evaluation/MinReturn                  -1375.44\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     70.5682\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.82217\n",
      "GaussianMLPPolicy/KL                      0.00766369\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               3.89175\n",
      "GaussianMLPPolicy/LossBefore              5.08639\n",
      "GaussianMLPPolicy/dLoss                   1.19464\n",
      "GaussianMLPValueFunction/LossAfter        6.52886\n",
      "GaussianMLPValueFunction/LossBefore       6.53\n",
      "GaussianMLPValueFunction/dLoss            0.00113297\n",
      "TotalEnvSteps                        816000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:56 | [trpo_pendulum] epoch #680 | Saving snapshot...\n",
      "2022-08-17 18:11:56 | [trpo_pendulum] epoch #680 | Saved\n",
      "2022-08-17 18:11:56 | [trpo_pendulum] epoch #680 | Time 431.91 s\n",
      "2022-08-17 18:11:56 | [trpo_pendulum] epoch #680 | EpochTime 0.64 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -563.243\n",
      "Evaluation/AverageReturn              -1395.92\n",
      "Evaluation/Iteration                    680\n",
      "Evaluation/MaxReturn                  -1190.86\n",
      "Evaluation/MinReturn                  -1739.02\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    181.248\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.83998\n",
      "GaussianMLPPolicy/KL                      0.00879095\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              15.3147\n",
      "GaussianMLPPolicy/LossBefore             17.9359\n",
      "GaussianMLPPolicy/dLoss                   2.62126\n",
      "GaussianMLPValueFunction/LossAfter        6.58078\n",
      "GaussianMLPValueFunction/LossBefore       6.58158\n",
      "GaussianMLPValueFunction/dLoss            0.000804424\n",
      "TotalEnvSteps                        817200\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:11:56 | [trpo_pendulum] epoch #681 | Saving snapshot...\n",
      "2022-08-17 18:11:56 | [trpo_pendulum] epoch #681 | Saved\n",
      "2022-08-17 18:11:56 | [trpo_pendulum] epoch #681 | Time 432.57 s\n",
      "2022-08-17 18:11:56 | [trpo_pendulum] epoch #681 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -709.505\n",
      "Evaluation/AverageReturn              -1633\n",
      "Evaluation/Iteration                    681\n",
      "Evaluation/MaxReturn                  -1522.93\n",
      "Evaluation/MinReturn                  -1773.29\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     87.4256\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.83531\n",
      "GaussianMLPPolicy/KL                      0.00742091\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              44.0652\n",
      "GaussianMLPPolicy/LossBefore             46.1363\n",
      "GaussianMLPPolicy/dLoss                   2.07119\n",
      "GaussianMLPValueFunction/LossAfter        6.7988\n",
      "GaussianMLPValueFunction/LossBefore       6.83737\n",
      "GaussianMLPValueFunction/dLoss            0.0385723\n",
      "TotalEnvSteps                        818400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:57 | [trpo_pendulum] epoch #682 | Saving snapshot...\n",
      "2022-08-17 18:11:57 | [trpo_pendulum] epoch #682 | Saved\n",
      "2022-08-17 18:11:57 | [trpo_pendulum] epoch #682 | Time 433.21 s\n",
      "2022-08-17 18:11:57 | [trpo_pendulum] epoch #682 | EpochTime 0.64 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -581.758\n",
      "Evaluation/AverageReturn              -1433.55\n",
      "Evaluation/Iteration                    682\n",
      "Evaluation/MaxReturn                  -1179.25\n",
      "Evaluation/MinReturn                  -1540.58\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    129.828\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.82775\n",
      "GaussianMLPPolicy/KL                      0.00855077\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              22.0268\n",
      "GaussianMLPPolicy/LossBefore             23.1592\n",
      "GaussianMLPPolicy/dLoss                   1.13245\n",
      "GaussianMLPValueFunction/LossAfter        6.6136\n",
      "GaussianMLPValueFunction/LossBefore       6.61414\n",
      "GaussianMLPValueFunction/dLoss            0.000539303\n",
      "TotalEnvSteps                        819600\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:11:58 | [trpo_pendulum] epoch #683 | Saving snapshot...\n",
      "2022-08-17 18:11:58 | [trpo_pendulum] epoch #683 | Saved\n",
      "2022-08-17 18:11:58 | [trpo_pendulum] epoch #683 | Time 433.86 s\n",
      "2022-08-17 18:11:58 | [trpo_pendulum] epoch #683 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -717.161\n",
      "Evaluation/AverageReturn              -1694.31\n",
      "Evaluation/Iteration                    683\n",
      "Evaluation/MaxReturn                  -1641.65\n",
      "Evaluation/MinReturn                  -1790.36\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     49.9247\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.83082\n",
      "GaussianMLPPolicy/KL                      0.00793343\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              53.9179\n",
      "GaussianMLPPolicy/LossBefore             56.4755\n",
      "GaussianMLPPolicy/dLoss                   2.55767\n",
      "GaussianMLPValueFunction/LossAfter        6.83745\n",
      "GaussianMLPValueFunction/LossBefore       6.86581\n",
      "GaussianMLPValueFunction/dLoss            0.0283608\n",
      "TotalEnvSteps                        820800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:58 | [trpo_pendulum] epoch #684 | Saving snapshot...\n",
      "2022-08-17 18:11:58 | [trpo_pendulum] epoch #684 | Saved\n",
      "2022-08-17 18:11:58 | [trpo_pendulum] epoch #684 | Time 434.49 s\n",
      "2022-08-17 18:11:58 | [trpo_pendulum] epoch #684 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -559.501\n",
      "Evaluation/AverageReturn              -1369.91\n",
      "Evaluation/Iteration                    684\n",
      "Evaluation/MaxReturn                  -1192.59\n",
      "Evaluation/MinReturn                  -1632.54\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    130.921\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.82327\n",
      "GaussianMLPPolicy/KL                      0.00839232\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               9.41605\n",
      "GaussianMLPPolicy/LossBefore             11.5093\n",
      "GaussianMLPPolicy/dLoss                   2.09325\n",
      "GaussianMLPValueFunction/LossAfter        6.57308\n",
      "GaussianMLPValueFunction/LossBefore       6.57975\n",
      "GaussianMLPValueFunction/dLoss            0.00667143\n",
      "TotalEnvSteps                        822000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:11:59 | [trpo_pendulum] epoch #685 | Saving snapshot...\n",
      "2022-08-17 18:11:59 | [trpo_pendulum] epoch #685 | Saved\n",
      "2022-08-17 18:11:59 | [trpo_pendulum] epoch #685 | Time 435.14 s\n",
      "2022-08-17 18:11:59 | [trpo_pendulum] epoch #685 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -702.597\n",
      "Evaluation/AverageReturn              -1609.87\n",
      "Evaluation/Iteration                    685\n",
      "Evaluation/MaxReturn                  -1527.25\n",
      "Evaluation/MinReturn                  -1696.1\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     64.1467\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.81056\n",
      "GaussianMLPPolicy/KL                      0.00691077\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              37.3662\n",
      "GaussianMLPPolicy/LossBefore             39.7432\n",
      "GaussianMLPPolicy/dLoss                   2.37702\n",
      "GaussianMLPValueFunction/LossAfter        6.72921\n",
      "GaussianMLPValueFunction/LossBefore       6.73267\n",
      "GaussianMLPValueFunction/dLoss            0.00345373\n",
      "TotalEnvSteps                        823200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:00 | [trpo_pendulum] epoch #686 | Saving snapshot...\n",
      "2022-08-17 18:12:00 | [trpo_pendulum] epoch #686 | Saved\n",
      "2022-08-17 18:12:00 | [trpo_pendulum] epoch #686 | Time 435.81 s\n",
      "2022-08-17 18:12:00 | [trpo_pendulum] epoch #686 | EpochTime 0.67 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -504.332\n",
      "Evaluation/AverageReturn              -1244.85\n",
      "Evaluation/Iteration                    686\n",
      "Evaluation/MaxReturn                  -1144.44\n",
      "Evaluation/MinReturn                  -1407.98\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    109.895\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.79622\n",
      "GaussianMLPPolicy/KL                      0.00854895\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -8.83282\n",
      "GaussianMLPPolicy/LossBefore             -7.27962\n",
      "GaussianMLPPolicy/dLoss                   1.55321\n",
      "GaussianMLPValueFunction/LossAfter        6.50426\n",
      "GaussianMLPValueFunction/LossBefore       6.52025\n",
      "GaussianMLPValueFunction/dLoss            0.0159883\n",
      "TotalEnvSteps                        824400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:00 | [trpo_pendulum] epoch #687 | Saving snapshot...\n",
      "2022-08-17 18:12:00 | [trpo_pendulum] epoch #687 | Saved\n",
      "2022-08-17 18:12:00 | [trpo_pendulum] epoch #687 | Time 436.44 s\n",
      "2022-08-17 18:12:00 | [trpo_pendulum] epoch #687 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -723.51\n",
      "Evaluation/AverageReturn              -1678.96\n",
      "Evaluation/Iteration                    687\n",
      "Evaluation/MaxReturn                  -1571.29\n",
      "Evaluation/MinReturn                  -1757.79\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     56.9216\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.8238\n",
      "GaussianMLPPolicy/KL                      0.00836131\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              49.1202\n",
      "GaussianMLPPolicy/LossBefore             50.6975\n",
      "GaussianMLPPolicy/dLoss                   1.57724\n",
      "GaussianMLPValueFunction/LossAfter        6.79454\n",
      "GaussianMLPValueFunction/LossBefore       6.81132\n",
      "GaussianMLPValueFunction/dLoss            0.0167847\n",
      "TotalEnvSteps                        825600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:01 | [trpo_pendulum] epoch #688 | Saving snapshot...\n",
      "2022-08-17 18:12:01 | [trpo_pendulum] epoch #688 | Saved\n",
      "2022-08-17 18:12:01 | [trpo_pendulum] epoch #688 | Time 437.10 s\n",
      "2022-08-17 18:12:01 | [trpo_pendulum] epoch #688 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -540.249\n",
      "Evaluation/AverageReturn              -1349.69\n",
      "Evaluation/Iteration                    688\n",
      "Evaluation/MaxReturn                  -1289.94\n",
      "Evaluation/MinReturn                  -1469.63\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     63.2116\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.81601\n",
      "GaussianMLPPolicy/KL                      0.00639951\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               7.12804\n",
      "GaussianMLPPolicy/LossBefore              8.52022\n",
      "GaussianMLPPolicy/dLoss                   1.39218\n",
      "GaussianMLPValueFunction/LossAfter        6.5112\n",
      "GaussianMLPValueFunction/LossBefore       6.52357\n",
      "GaussianMLPValueFunction/dLoss            0.0123663\n",
      "TotalEnvSteps                        826800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:01 | [trpo_pendulum] epoch #689 | Saving snapshot...\n",
      "2022-08-17 18:12:01 | [trpo_pendulum] epoch #689 | Saved\n",
      "2022-08-17 18:12:01 | [trpo_pendulum] epoch #689 | Time 437.74 s\n",
      "2022-08-17 18:12:01 | [trpo_pendulum] epoch #689 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -551.435\n",
      "Evaluation/AverageReturn              -1378.86\n",
      "Evaluation/Iteration                    689\n",
      "Evaluation/MaxReturn                  -1224.75\n",
      "Evaluation/MinReturn                  -1527.37\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    105.963\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.81836\n",
      "GaussianMLPPolicy/KL                      0.00983619\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              13.0751\n",
      "GaussianMLPPolicy/LossBefore             14.7125\n",
      "GaussianMLPPolicy/dLoss                   1.63742\n",
      "GaussianMLPValueFunction/LossAfter        6.56666\n",
      "GaussianMLPValueFunction/LossBefore       6.56908\n",
      "GaussianMLPValueFunction/dLoss            0.00242043\n",
      "TotalEnvSteps                        828000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:02 | [trpo_pendulum] epoch #690 | Saving snapshot...\n",
      "2022-08-17 18:12:02 | [trpo_pendulum] epoch #690 | Saved\n",
      "2022-08-17 18:12:02 | [trpo_pendulum] epoch #690 | Time 438.39 s\n",
      "2022-08-17 18:12:02 | [trpo_pendulum] epoch #690 | EpochTime 0.65 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -571.581\n",
      "Evaluation/AverageReturn              -1421.67\n",
      "Evaluation/Iteration                    690\n",
      "Evaluation/MaxReturn                  -1227.86\n",
      "Evaluation/MinReturn                  -1525.69\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    127.502\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.80667\n",
      "GaussianMLPPolicy/KL                      0.00816232\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              18.5215\n",
      "GaussianMLPPolicy/LossBefore             20.2509\n",
      "GaussianMLPPolicy/dLoss                   1.72941\n",
      "GaussianMLPValueFunction/LossAfter        6.60517\n",
      "GaussianMLPValueFunction/LossBefore       6.60535\n",
      "GaussianMLPValueFunction/dLoss            0.000175476\n",
      "TotalEnvSteps                        829200\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:03 | [trpo_pendulum] epoch #691 | Saving snapshot...\n",
      "2022-08-17 18:12:03 | [trpo_pendulum] epoch #691 | Saved\n",
      "2022-08-17 18:12:03 | [trpo_pendulum] epoch #691 | Time 439.04 s\n",
      "2022-08-17 18:12:03 | [trpo_pendulum] epoch #691 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -634.284\n",
      "Evaluation/AverageReturn              -1536.41\n",
      "Evaluation/Iteration                    691\n",
      "Evaluation/MaxReturn                  -1499.67\n",
      "Evaluation/MinReturn                  -1572.85\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     24.4178\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.78521\n",
      "GaussianMLPPolicy/KL                      0.00663676\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              34.5349\n",
      "GaussianMLPPolicy/LossBefore             36.0502\n",
      "GaussianMLPPolicy/dLoss                   1.51531\n",
      "GaussianMLPValueFunction/LossAfter        6.70363\n",
      "GaussianMLPValueFunction/LossBefore       6.70977\n",
      "GaussianMLPValueFunction/dLoss            0.00613356\n",
      "TotalEnvSteps                        830400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:03 | [trpo_pendulum] epoch #692 | Saving snapshot...\n",
      "2022-08-17 18:12:03 | [trpo_pendulum] epoch #692 | Saved\n",
      "2022-08-17 18:12:03 | [trpo_pendulum] epoch #692 | Time 439.69 s\n",
      "2022-08-17 18:12:03 | [trpo_pendulum] epoch #692 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -553.879\n",
      "Evaluation/AverageReturn              -1372.98\n",
      "Evaluation/Iteration                    692\n",
      "Evaluation/MaxReturn                  -1037.73\n",
      "Evaluation/MinReturn                  -1493.65\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    161.77\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.77934\n",
      "GaussianMLPPolicy/KL                      0.00917984\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               8.65864\n",
      "GaussianMLPPolicy/LossBefore             10.8253\n",
      "GaussianMLPPolicy/dLoss                   2.16667\n",
      "GaussianMLPValueFunction/LossAfter        6.56693\n",
      "GaussianMLPValueFunction/LossBefore       6.56971\n",
      "GaussianMLPValueFunction/dLoss            0.00278091\n",
      "TotalEnvSteps                        831600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:04 | [trpo_pendulum] epoch #693 | Saving snapshot...\n",
      "2022-08-17 18:12:04 | [trpo_pendulum] epoch #693 | Saved\n",
      "2022-08-17 18:12:04 | [trpo_pendulum] epoch #693 | Time 440.34 s\n",
      "2022-08-17 18:12:04 | [trpo_pendulum] epoch #693 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -597.809\n",
      "Evaluation/AverageReturn              -1511.29\n",
      "Evaluation/Iteration                    693\n",
      "Evaluation/MaxReturn                  -1484.87\n",
      "Evaluation/MinReturn                  -1534.87\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     18.7853\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.80277\n",
      "GaussianMLPPolicy/KL                      0.009182\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              35.4326\n",
      "GaussianMLPPolicy/LossBefore             36.7022\n",
      "GaussianMLPPolicy/dLoss                   1.26958\n",
      "GaussianMLPValueFunction/LossAfter        6.68398\n",
      "GaussianMLPValueFunction/LossBefore       6.68819\n",
      "GaussianMLPValueFunction/dLoss            0.00421238\n",
      "TotalEnvSteps                        832800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:05 | [trpo_pendulum] epoch #694 | Saving snapshot...\n",
      "2022-08-17 18:12:05 | [trpo_pendulum] epoch #694 | Saved\n",
      "2022-08-17 18:12:05 | [trpo_pendulum] epoch #694 | Time 441.00 s\n",
      "2022-08-17 18:12:05 | [trpo_pendulum] epoch #694 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -705.906\n",
      "Evaluation/AverageReturn              -1618.84\n",
      "Evaluation/Iteration                    694\n",
      "Evaluation/MaxReturn                  -1575.15\n",
      "Evaluation/MinReturn                  -1700.84\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     42.1739\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.79778\n",
      "GaussianMLPPolicy/KL                      0.00665412\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              37.3646\n",
      "GaussianMLPPolicy/LossBefore             38.933\n",
      "GaussianMLPPolicy/dLoss                   1.56831\n",
      "GaussianMLPValueFunction/LossAfter        6.72696\n",
      "GaussianMLPValueFunction/LossBefore       6.73308\n",
      "GaussianMLPValueFunction/dLoss            0.00612736\n",
      "TotalEnvSteps                        834000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:05 | [trpo_pendulum] epoch #695 | Saving snapshot...\n",
      "2022-08-17 18:12:05 | [trpo_pendulum] epoch #695 | Saved\n",
      "2022-08-17 18:12:05 | [trpo_pendulum] epoch #695 | Time 441.63 s\n",
      "2022-08-17 18:12:05 | [trpo_pendulum] epoch #695 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -588.87\n",
      "Evaluation/AverageReturn              -1464.43\n",
      "Evaluation/Iteration                    695\n",
      "Evaluation/MaxReturn                  -1379.62\n",
      "Evaluation/MinReturn                  -1503.03\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     40.4045\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.74324\n",
      "GaussianMLPPolicy/KL                      0.00871237\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              22.4069\n",
      "GaussianMLPPolicy/LossBefore             24.067\n",
      "GaussianMLPPolicy/dLoss                   1.66001\n",
      "GaussianMLPValueFunction/LossAfter        6.59088\n",
      "GaussianMLPValueFunction/LossBefore       6.59464\n",
      "GaussianMLPValueFunction/dLoss            0.00375891\n",
      "TotalEnvSteps                        835200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:06 | [trpo_pendulum] epoch #696 | Saving snapshot...\n",
      "2022-08-17 18:12:06 | [trpo_pendulum] epoch #696 | Saved\n",
      "2022-08-17 18:12:06 | [trpo_pendulum] epoch #696 | Time 442.28 s\n",
      "2022-08-17 18:12:06 | [trpo_pendulum] epoch #696 | EpochTime 0.65 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -649.369\n",
      "Evaluation/AverageReturn              -1498.12\n",
      "Evaluation/Iteration                    696\n",
      "Evaluation/MaxReturn                  -1491.99\n",
      "Evaluation/MinReturn                  -1507.37\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.13814\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.74422\n",
      "GaussianMLPPolicy/KL                      0.00964504\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              19.6011\n",
      "GaussianMLPPolicy/LossBefore             21.4975\n",
      "GaussianMLPPolicy/dLoss                   1.89631\n",
      "GaussianMLPValueFunction/LossAfter        6.62185\n",
      "GaussianMLPValueFunction/LossBefore       6.6222\n",
      "GaussianMLPValueFunction/dLoss            0.000348568\n",
      "TotalEnvSteps                        836400\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:07 | [trpo_pendulum] epoch #697 | Saving snapshot...\n",
      "2022-08-17 18:12:07 | [trpo_pendulum] epoch #697 | Saved\n",
      "2022-08-17 18:12:07 | [trpo_pendulum] epoch #697 | Time 442.97 s\n",
      "2022-08-17 18:12:07 | [trpo_pendulum] epoch #697 | EpochTime 0.68 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -595.2\n",
      "Evaluation/AverageReturn              -1484.61\n",
      "Evaluation/Iteration                    697\n",
      "Evaluation/MaxReturn                  -1460.25\n",
      "Evaluation/MinReturn                  -1498.59\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     13.0721\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.75448\n",
      "GaussianMLPPolicy/KL                      0.00665481\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              26.1495\n",
      "GaussianMLPPolicy/LossBefore             28.0361\n",
      "GaussianMLPPolicy/dLoss                   1.8866\n",
      "GaussianMLPValueFunction/LossAfter        6.6209\n",
      "GaussianMLPValueFunction/LossBefore       6.62177\n",
      "GaussianMLPValueFunction/dLoss            0.000864506\n",
      "TotalEnvSteps                        837600\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:07 | [trpo_pendulum] epoch #698 | Saving snapshot...\n",
      "2022-08-17 18:12:07 | [trpo_pendulum] epoch #698 | Saved\n",
      "2022-08-17 18:12:07 | [trpo_pendulum] epoch #698 | Time 443.61 s\n",
      "2022-08-17 18:12:07 | [trpo_pendulum] epoch #698 | EpochTime 0.64 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -649.203\n",
      "Evaluation/AverageReturn              -1495.09\n",
      "Evaluation/Iteration                    698\n",
      "Evaluation/MaxReturn                  -1493.72\n",
      "Evaluation/MinReturn                  -1496.26\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      0.801425\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.75253\n",
      "GaussianMLPPolicy/KL                      0.00846731\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              19.433\n",
      "GaussianMLPPolicy/LossBefore             20.2336\n",
      "GaussianMLPPolicy/dLoss                   0.800653\n",
      "GaussianMLPValueFunction/LossAfter        6.61299\n",
      "GaussianMLPValueFunction/LossBefore       6.61317\n",
      "GaussianMLPValueFunction/dLoss            0.000181198\n",
      "TotalEnvSteps                        838800\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:08 | [trpo_pendulum] epoch #699 | Saving snapshot...\n",
      "2022-08-17 18:12:08 | [trpo_pendulum] epoch #699 | Saved\n",
      "2022-08-17 18:12:08 | [trpo_pendulum] epoch #699 | Time 444.26 s\n",
      "2022-08-17 18:12:08 | [trpo_pendulum] epoch #699 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -532.298\n",
      "Evaluation/AverageReturn              -1360.96\n",
      "Evaluation/Iteration                    699\n",
      "Evaluation/MaxReturn                  -1327.94\n",
      "Evaluation/MinReturn                  -1386.92\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     20.7819\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.74196\n",
      "GaussianMLPPolicy/KL                      0.00720115\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               8.00394\n",
      "GaussianMLPPolicy/LossBefore              9.14698\n",
      "GaussianMLPPolicy/dLoss                   1.14304\n",
      "GaussianMLPValueFunction/LossAfter        6.51524\n",
      "GaussianMLPValueFunction/LossBefore       6.52229\n",
      "GaussianMLPValueFunction/dLoss            0.00704479\n",
      "TotalEnvSteps                        840000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:09 | [trpo_pendulum] epoch #700 | Saving snapshot...\n",
      "2022-08-17 18:12:09 | [trpo_pendulum] epoch #700 | Saved\n",
      "2022-08-17 18:12:09 | [trpo_pendulum] epoch #700 | Time 444.90 s\n",
      "2022-08-17 18:12:09 | [trpo_pendulum] epoch #700 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -671.758\n",
      "Evaluation/AverageReturn              -1529.93\n",
      "Evaluation/Iteration                    700\n",
      "Evaluation/MaxReturn                  -1524.91\n",
      "Evaluation/MinReturn                  -1537.69\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      4.64754\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.72813\n",
      "GaussianMLPPolicy/KL                      0.00679467\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              22.1761\n",
      "GaussianMLPPolicy/LossBefore             23.811\n",
      "GaussianMLPPolicy/dLoss                   1.63489\n",
      "GaussianMLPValueFunction/LossAfter        6.62274\n",
      "GaussianMLPValueFunction/LossBefore       6.62385\n",
      "GaussianMLPValueFunction/dLoss            0.00111246\n",
      "TotalEnvSteps                        841200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:09 | [trpo_pendulum] epoch #701 | Saving snapshot...\n",
      "2022-08-17 18:12:09 | [trpo_pendulum] epoch #701 | Saved\n",
      "2022-08-17 18:12:09 | [trpo_pendulum] epoch #701 | Time 445.57 s\n",
      "2022-08-17 18:12:09 | [trpo_pendulum] epoch #701 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -562.682\n",
      "Evaluation/AverageReturn              -1351.94\n",
      "Evaluation/Iteration                    701\n",
      "Evaluation/MaxReturn                  -1308.2\n",
      "Evaluation/MinReturn                  -1390.8\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     24.8442\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.71512\n",
      "GaussianMLPPolicy/KL                      0.00615\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               4.519\n",
      "GaussianMLPPolicy/LossBefore              5.4474\n",
      "GaussianMLPPolicy/dLoss                   0.928401\n",
      "GaussianMLPValueFunction/LossAfter        6.55927\n",
      "GaussianMLPValueFunction/LossBefore       6.56129\n",
      "GaussianMLPValueFunction/dLoss            0.00201416\n",
      "TotalEnvSteps                        842400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:10 | [trpo_pendulum] epoch #702 | Saving snapshot...\n",
      "2022-08-17 18:12:10 | [trpo_pendulum] epoch #702 | Saved\n",
      "2022-08-17 18:12:10 | [trpo_pendulum] epoch #702 | Time 446.22 s\n",
      "2022-08-17 18:12:10 | [trpo_pendulum] epoch #702 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -657.591\n",
      "Evaluation/AverageReturn              -1578.31\n",
      "Evaluation/Iteration                    702\n",
      "Evaluation/MaxReturn                  -1548.71\n",
      "Evaluation/MinReturn                  -1604.2\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     18.3996\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.73279\n",
      "GaussianMLPPolicy/KL                      0.00782056\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              38.1316\n",
      "GaussianMLPPolicy/LossBefore             38.9815\n",
      "GaussianMLPPolicy/dLoss                   0.849857\n",
      "GaussianMLPValueFunction/LossAfter        6.73478\n",
      "GaussianMLPValueFunction/LossBefore       6.75241\n",
      "GaussianMLPValueFunction/dLoss            0.0176311\n",
      "TotalEnvSteps                        843600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:11 | [trpo_pendulum] epoch #703 | Saving snapshot...\n",
      "2022-08-17 18:12:11 | [trpo_pendulum] epoch #703 | Saved\n",
      "2022-08-17 18:12:11 | [trpo_pendulum] epoch #703 | Time 446.88 s\n",
      "2022-08-17 18:12:11 | [trpo_pendulum] epoch #703 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -533.522\n",
      "Evaluation/AverageReturn              -1310.88\n",
      "Evaluation/Iteration                    703\n",
      "Evaluation/MaxReturn                  -1166.37\n",
      "Evaluation/MinReturn                  -1426.84\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    107.021\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.76758\n",
      "GaussianMLPPolicy/KL                      0.00668579\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.02693\n",
      "GaussianMLPPolicy/LossBefore             -1.12802\n",
      "GaussianMLPPolicy/dLoss                   1.89891\n",
      "GaussianMLPValueFunction/LossAfter        6.51272\n",
      "GaussianMLPValueFunction/LossBefore       6.52274\n",
      "GaussianMLPValueFunction/dLoss            0.0100245\n",
      "TotalEnvSteps                        844800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:11 | [trpo_pendulum] epoch #704 | Saving snapshot...\n",
      "2022-08-17 18:12:11 | [trpo_pendulum] epoch #704 | Saved\n",
      "2022-08-17 18:12:11 | [trpo_pendulum] epoch #704 | Time 447.54 s\n",
      "2022-08-17 18:12:11 | [trpo_pendulum] epoch #704 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -636.843\n",
      "Evaluation/AverageReturn              -1546.13\n",
      "Evaluation/Iteration                    704\n",
      "Evaluation/MaxReturn                  -1503.54\n",
      "Evaluation/MinReturn                  -1586.2\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     24.9808\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.77836\n",
      "GaussianMLPPolicy/KL                      0.00780322\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              34.2159\n",
      "GaussianMLPPolicy/LossBefore             34.4278\n",
      "GaussianMLPPolicy/dLoss                   0.211895\n",
      "GaussianMLPValueFunction/LossAfter        6.69951\n",
      "GaussianMLPValueFunction/LossBefore       6.70684\n",
      "GaussianMLPValueFunction/dLoss            0.00733471\n",
      "TotalEnvSteps                        846000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:12 | [trpo_pendulum] epoch #705 | Saving snapshot...\n",
      "2022-08-17 18:12:12 | [trpo_pendulum] epoch #705 | Saved\n",
      "2022-08-17 18:12:12 | [trpo_pendulum] epoch #705 | Time 448.21 s\n",
      "2022-08-17 18:12:12 | [trpo_pendulum] epoch #705 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -595.234\n",
      "Evaluation/AverageReturn              -1467.17\n",
      "Evaluation/Iteration                    705\n",
      "Evaluation/MaxReturn                  -1226.34\n",
      "Evaluation/MinReturn                  -1522.6\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    107.831\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.78628\n",
      "GaussianMLPPolicy/KL                      0.00781864\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              21.858\n",
      "GaussianMLPPolicy/LossBefore             22.9119\n",
      "GaussianMLPPolicy/dLoss                   1.05389\n",
      "GaussianMLPValueFunction/LossAfter        6.62709\n",
      "GaussianMLPValueFunction/LossBefore       6.62736\n",
      "GaussianMLPValueFunction/dLoss            0.00027132\n",
      "TotalEnvSteps                        847200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:13 | [trpo_pendulum] epoch #706 | Saving snapshot...\n",
      "2022-08-17 18:12:13 | [trpo_pendulum] epoch #706 | Saved\n",
      "2022-08-17 18:12:13 | [trpo_pendulum] epoch #706 | Time 448.85 s\n",
      "2022-08-17 18:12:13 | [trpo_pendulum] epoch #706 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -634.221\n",
      "Evaluation/AverageReturn              -1542.56\n",
      "Evaluation/Iteration                    706\n",
      "Evaluation/MaxReturn                  -1521.92\n",
      "Evaluation/MinReturn                  -1560.27\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     11.7752\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.77748\n",
      "GaussianMLPPolicy/KL                      0.00917989\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              34.5841\n",
      "GaussianMLPPolicy/LossBefore             34.7747\n",
      "GaussianMLPPolicy/dLoss                   0.19062\n",
      "GaussianMLPValueFunction/LossAfter        6.71905\n",
      "GaussianMLPValueFunction/LossBefore       6.72492\n",
      "GaussianMLPValueFunction/dLoss            0.00586987\n",
      "TotalEnvSteps                        848400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:13 | [trpo_pendulum] epoch #707 | Saving snapshot...\n",
      "2022-08-17 18:12:13 | [trpo_pendulum] epoch #707 | Saved\n",
      "2022-08-17 18:12:13 | [trpo_pendulum] epoch #707 | Time 449.48 s\n",
      "2022-08-17 18:12:13 | [trpo_pendulum] epoch #707 | EpochTime 0.63 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -651.685\n",
      "Evaluation/AverageReturn              -1498.77\n",
      "Evaluation/Iteration                    707\n",
      "Evaluation/MaxReturn                  -1496.21\n",
      "Evaluation/MinReturn                  -1503.31\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      2.32339\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.7923\n",
      "GaussianMLPPolicy/KL                      0.00800165\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              17.5595\n",
      "GaussianMLPPolicy/LossBefore             19.5417\n",
      "GaussianMLPPolicy/dLoss                   1.98219\n",
      "GaussianMLPValueFunction/LossAfter        6.62638\n",
      "GaussianMLPValueFunction/LossBefore       6.62723\n",
      "GaussianMLPValueFunction/dLoss            0.000855446\n",
      "TotalEnvSteps                        849600\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:14 | [trpo_pendulum] epoch #708 | Saving snapshot...\n",
      "2022-08-17 18:12:14 | [trpo_pendulum] epoch #708 | Saved\n",
      "2022-08-17 18:12:14 | [trpo_pendulum] epoch #708 | Time 450.12 s\n",
      "2022-08-17 18:12:14 | [trpo_pendulum] epoch #708 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -541.741\n",
      "Evaluation/AverageReturn              -1310.21\n",
      "Evaluation/Iteration                    708\n",
      "Evaluation/MaxReturn                  -1246.79\n",
      "Evaluation/MinReturn                  -1354.77\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     34.0329\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.80652\n",
      "GaussianMLPPolicy/KL                      0.00780002\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.58127\n",
      "GaussianMLPPolicy/LossBefore             -4.47406\n",
      "GaussianMLPPolicy/dLoss                   2.10722\n",
      "GaussianMLPValueFunction/LossAfter        6.47492\n",
      "GaussianMLPValueFunction/LossBefore       6.49339\n",
      "GaussianMLPValueFunction/dLoss            0.0184674\n",
      "TotalEnvSteps                        850800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:14 | [trpo_pendulum] epoch #709 | Saving snapshot...\n",
      "2022-08-17 18:12:14 | [trpo_pendulum] epoch #709 | Saved\n",
      "2022-08-17 18:12:14 | [trpo_pendulum] epoch #709 | Time 450.77 s\n",
      "2022-08-17 18:12:14 | [trpo_pendulum] epoch #709 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -524.867\n",
      "Evaluation/AverageReturn              -1289.51\n",
      "Evaluation/Iteration                    709\n",
      "Evaluation/MaxReturn                  -1141\n",
      "Evaluation/MinReturn                  -1398.79\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     90.3865\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.81776\n",
      "GaussianMLPPolicy/KL                      0.00817547\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.6312\n",
      "GaussianMLPPolicy/LossBefore             -4.2995\n",
      "GaussianMLPPolicy/dLoss                   2.3317\n",
      "GaussianMLPValueFunction/LossAfter        6.48177\n",
      "GaussianMLPValueFunction/LossBefore       6.49063\n",
      "GaussianMLPValueFunction/dLoss            0.00886202\n",
      "TotalEnvSteps                        852000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:15 | [trpo_pendulum] epoch #710 | Saving snapshot...\n",
      "2022-08-17 18:12:15 | [trpo_pendulum] epoch #710 | Saved\n",
      "2022-08-17 18:12:15 | [trpo_pendulum] epoch #710 | Time 451.45 s\n",
      "2022-08-17 18:12:15 | [trpo_pendulum] epoch #710 | EpochTime 0.67 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -567.828\n",
      "Evaluation/AverageReturn              -1410.09\n",
      "Evaluation/Iteration                    710\n",
      "Evaluation/MaxReturn                  -1366.43\n",
      "Evaluation/MinReturn                  -1453.27\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     35.3439\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.82716\n",
      "GaussianMLPPolicy/KL                      0.00757929\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              17.3918\n",
      "GaussianMLPPolicy/LossBefore             18.5284\n",
      "GaussianMLPPolicy/dLoss                   1.13665\n",
      "GaussianMLPValueFunction/LossAfter        6.61765\n",
      "GaussianMLPValueFunction/LossBefore       6.61996\n",
      "GaussianMLPValueFunction/dLoss            0.00230503\n",
      "TotalEnvSteps                        853200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:16 | [trpo_pendulum] epoch #711 | Saving snapshot...\n",
      "2022-08-17 18:12:16 | [trpo_pendulum] epoch #711 | Saved\n",
      "2022-08-17 18:12:16 | [trpo_pendulum] epoch #711 | Time 452.09 s\n",
      "2022-08-17 18:12:16 | [trpo_pendulum] epoch #711 | EpochTime 0.64 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -558.607\n",
      "Evaluation/AverageReturn              -1385.87\n",
      "Evaluation/Iteration                    711\n",
      "Evaluation/MaxReturn                  -1330.17\n",
      "Evaluation/MinReturn                  -1412.57\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     29.7993\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.8118\n",
      "GaussianMLPPolicy/KL                      0.00912614\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              10.1459\n",
      "GaussianMLPPolicy/LossBefore             11.9964\n",
      "GaussianMLPPolicy/dLoss                   1.85047\n",
      "GaussianMLPValueFunction/LossAfter        6.54629\n",
      "GaussianMLPValueFunction/LossBefore       6.5468\n",
      "GaussianMLPValueFunction/dLoss            0.000506401\n",
      "TotalEnvSteps                        854400\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:16 | [trpo_pendulum] epoch #712 | Saving snapshot...\n",
      "2022-08-17 18:12:16 | [trpo_pendulum] epoch #712 | Saved\n",
      "2022-08-17 18:12:16 | [trpo_pendulum] epoch #712 | Time 452.72 s\n",
      "2022-08-17 18:12:16 | [trpo_pendulum] epoch #712 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -622.366\n",
      "Evaluation/AverageReturn              -1503\n",
      "Evaluation/Iteration                    712\n",
      "Evaluation/MaxReturn                  -1474.42\n",
      "Evaluation/MinReturn                  -1514.56\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     14.0183\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.80799\n",
      "GaussianMLPPolicy/KL                      0.00825314\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              27.2881\n",
      "GaussianMLPPolicy/LossBefore             28.3517\n",
      "GaussianMLPPolicy/dLoss                   1.06362\n",
      "GaussianMLPValueFunction/LossAfter        6.64638\n",
      "GaussianMLPValueFunction/LossBefore       6.651\n",
      "GaussianMLPValueFunction/dLoss            0.00462008\n",
      "TotalEnvSteps                        855600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:17 | [trpo_pendulum] epoch #713 | Saving snapshot...\n",
      "2022-08-17 18:12:17 | [trpo_pendulum] epoch #713 | Saved\n",
      "2022-08-17 18:12:17 | [trpo_pendulum] epoch #713 | Time 453.34 s\n",
      "2022-08-17 18:12:17 | [trpo_pendulum] epoch #713 | EpochTime 0.61 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -588.733\n",
      "Evaluation/AverageReturn              -1403.43\n",
      "Evaluation/Iteration                    713\n",
      "Evaluation/MaxReturn                  -1200\n",
      "Evaluation/MinReturn                  -1571.68\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    137.819\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.79384\n",
      "GaussianMLPPolicy/KL                      0.00684116\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               8.76028\n",
      "GaussianMLPPolicy/LossBefore             10.3147\n",
      "GaussianMLPPolicy/dLoss                   1.55438\n",
      "GaussianMLPValueFunction/LossAfter        6.56434\n",
      "GaussianMLPValueFunction/LossBefore       6.56509\n",
      "GaussianMLPValueFunction/dLoss            0.000745773\n",
      "TotalEnvSteps                        856800\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:18 | [trpo_pendulum] epoch #714 | Saving snapshot...\n",
      "2022-08-17 18:12:18 | [trpo_pendulum] epoch #714 | Saved\n",
      "2022-08-17 18:12:18 | [trpo_pendulum] epoch #714 | Time 453.97 s\n",
      "2022-08-17 18:12:18 | [trpo_pendulum] epoch #714 | EpochTime 0.63 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -582.867\n",
      "Evaluation/AverageReturn              -1447.38\n",
      "Evaluation/Iteration                    714\n",
      "Evaluation/MaxReturn                  -1417.73\n",
      "Evaluation/MinReturn                  -1470.47\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     16.6373\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.81892\n",
      "GaussianMLPPolicy/KL                      0.00492548\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              22.7221\n",
      "GaussianMLPPolicy/LossBefore             23.7793\n",
      "GaussianMLPPolicy/dLoss                   1.05713\n",
      "GaussianMLPValueFunction/LossAfter        6.61616\n",
      "GaussianMLPValueFunction/LossBefore       6.61697\n",
      "GaussianMLPValueFunction/dLoss            0.000809669\n",
      "TotalEnvSteps                        858000\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:18 | [trpo_pendulum] epoch #715 | Saving snapshot...\n",
      "2022-08-17 18:12:18 | [trpo_pendulum] epoch #715 | Saved\n",
      "2022-08-17 18:12:18 | [trpo_pendulum] epoch #715 | Time 454.62 s\n",
      "2022-08-17 18:12:18 | [trpo_pendulum] epoch #715 | EpochTime 0.65 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -650.09\n",
      "Evaluation/AverageReturn              -1503.22\n",
      "Evaluation/Iteration                    715\n",
      "Evaluation/MaxReturn                  -1502.05\n",
      "Evaluation/MinReturn                  -1506.14\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      1.43182\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.81284\n",
      "GaussianMLPPolicy/KL                      0.00599059\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              20.5389\n",
      "GaussianMLPPolicy/LossBefore             22.0737\n",
      "GaussianMLPPolicy/dLoss                   1.53487\n",
      "GaussianMLPValueFunction/LossAfter        6.61458\n",
      "GaussianMLPValueFunction/LossBefore       6.61485\n",
      "GaussianMLPValueFunction/dLoss            0.000274658\n",
      "TotalEnvSteps                        859200\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:19 | [trpo_pendulum] epoch #716 | Saving snapshot...\n",
      "2022-08-17 18:12:19 | [trpo_pendulum] epoch #716 | Saved\n",
      "2022-08-17 18:12:19 | [trpo_pendulum] epoch #716 | Time 455.26 s\n",
      "2022-08-17 18:12:19 | [trpo_pendulum] epoch #716 | EpochTime 0.63 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -668.467\n",
      "Evaluation/AverageReturn              -1521.55\n",
      "Evaluation/Iteration                    716\n",
      "Evaluation/MaxReturn                  -1504.39\n",
      "Evaluation/MinReturn                  -1544.46\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     16.6205\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.83042\n",
      "GaussianMLPPolicy/KL                      0.00628213\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              20.4438\n",
      "GaussianMLPPolicy/LossBefore             22.3779\n",
      "GaussianMLPPolicy/dLoss                   1.93413\n",
      "GaussianMLPValueFunction/LossAfter        6.62786\n",
      "GaussianMLPValueFunction/LossBefore       6.62829\n",
      "GaussianMLPValueFunction/dLoss            0.000434399\n",
      "TotalEnvSteps                        860400\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:20 | [trpo_pendulum] epoch #717 | Saving snapshot...\n",
      "2022-08-17 18:12:20 | [trpo_pendulum] epoch #717 | Saved\n",
      "2022-08-17 18:12:20 | [trpo_pendulum] epoch #717 | Time 455.90 s\n",
      "2022-08-17 18:12:20 | [trpo_pendulum] epoch #717 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -554.548\n",
      "Evaluation/AverageReturn              -1383.7\n",
      "Evaluation/Iteration                    717\n",
      "Evaluation/MaxReturn                  -1326.33\n",
      "Evaluation/MinReturn                  -1427.27\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     34.6233\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.85478\n",
      "GaussianMLPPolicy/KL                      0.00782404\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               9.34473\n",
      "GaussianMLPPolicy/LossBefore             11.2437\n",
      "GaussianMLPPolicy/dLoss                   1.89892\n",
      "GaussianMLPValueFunction/LossAfter        6.53571\n",
      "GaussianMLPValueFunction/LossBefore       6.5395\n",
      "GaussianMLPValueFunction/dLoss            0.00378323\n",
      "TotalEnvSteps                        861600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:20 | [trpo_pendulum] epoch #718 | Saving snapshot...\n",
      "2022-08-17 18:12:20 | [trpo_pendulum] epoch #718 | Saved\n",
      "2022-08-17 18:12:20 | [trpo_pendulum] epoch #718 | Time 456.53 s\n",
      "2022-08-17 18:12:20 | [trpo_pendulum] epoch #718 | EpochTime 0.63 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -576.76\n",
      "Evaluation/AverageReturn              -1437.63\n",
      "Evaluation/Iteration                    718\n",
      "Evaluation/MaxReturn                  -1356.81\n",
      "Evaluation/MinReturn                  -1518\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     64.648\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.85602\n",
      "GaussianMLPPolicy/KL                      0.00753231\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              18.685\n",
      "GaussianMLPPolicy/LossBefore             20.4106\n",
      "GaussianMLPPolicy/dLoss                   1.72558\n",
      "GaussianMLPValueFunction/LossAfter        6.60619\n",
      "GaussianMLPValueFunction/LossBefore       6.60667\n",
      "GaussianMLPValueFunction/dLoss            0.000483513\n",
      "TotalEnvSteps                        862800\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:21 | [trpo_pendulum] epoch #719 | Saving snapshot...\n",
      "2022-08-17 18:12:21 | [trpo_pendulum] epoch #719 | Saved\n",
      "2022-08-17 18:12:21 | [trpo_pendulum] epoch #719 | Time 457.17 s\n",
      "2022-08-17 18:12:21 | [trpo_pendulum] epoch #719 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -661.734\n",
      "Evaluation/AverageReturn              -1526.44\n",
      "Evaluation/Iteration                    719\n",
      "Evaluation/MaxReturn                  -1486.55\n",
      "Evaluation/MinReturn                  -1561.86\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     25.3891\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.83475\n",
      "GaussianMLPPolicy/KL                      0.00961111\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              23.324\n",
      "GaussianMLPPolicy/LossBefore             25.5372\n",
      "GaussianMLPPolicy/dLoss                   2.21318\n",
      "GaussianMLPValueFunction/LossAfter        6.65137\n",
      "GaussianMLPValueFunction/LossBefore       6.65399\n",
      "GaussianMLPValueFunction/dLoss            0.00261784\n",
      "TotalEnvSteps                        864000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:22 | [trpo_pendulum] epoch #720 | Saving snapshot...\n",
      "2022-08-17 18:12:22 | [trpo_pendulum] epoch #720 | Saved\n",
      "2022-08-17 18:12:22 | [trpo_pendulum] epoch #720 | Time 457.80 s\n",
      "2022-08-17 18:12:22 | [trpo_pendulum] epoch #720 | EpochTime 0.63 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -653.764\n",
      "Evaluation/AverageReturn              -1512.58\n",
      "Evaluation/Iteration                    720\n",
      "Evaluation/MaxReturn                  -1508.86\n",
      "Evaluation/MinReturn                  -1517.16\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      2.86093\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.86411\n",
      "GaussianMLPPolicy/KL                      0.00681365\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              21.9239\n",
      "GaussianMLPPolicy/LossBefore             23.2468\n",
      "GaussianMLPPolicy/dLoss                   1.32293\n",
      "GaussianMLPValueFunction/LossAfter        6.6287\n",
      "GaussianMLPValueFunction/LossBefore       6.62889\n",
      "GaussianMLPValueFunction/dLoss            0.000195026\n",
      "TotalEnvSteps                        865200\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:22 | [trpo_pendulum] epoch #721 | Saving snapshot...\n",
      "2022-08-17 18:12:22 | [trpo_pendulum] epoch #721 | Saved\n",
      "2022-08-17 18:12:22 | [trpo_pendulum] epoch #721 | Time 458.43 s\n",
      "2022-08-17 18:12:22 | [trpo_pendulum] epoch #721 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -544.226\n",
      "Evaluation/AverageReturn              -1398.49\n",
      "Evaluation/Iteration                    721\n",
      "Evaluation/MaxReturn                  -1273.28\n",
      "Evaluation/MinReturn                  -1488.29\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     87.8432\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.89491\n",
      "GaussianMLPPolicy/KL                      0.00764809\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              12.3118\n",
      "GaussianMLPPolicy/LossBefore             15.1024\n",
      "GaussianMLPPolicy/dLoss                   2.79057\n",
      "GaussianMLPValueFunction/LossAfter        6.54228\n",
      "GaussianMLPValueFunction/LossBefore       6.54645\n",
      "GaussianMLPValueFunction/dLoss            0.00416899\n",
      "TotalEnvSteps                        866400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:23 | [trpo_pendulum] epoch #722 | Saving snapshot...\n",
      "2022-08-17 18:12:23 | [trpo_pendulum] epoch #722 | Saved\n",
      "2022-08-17 18:12:23 | [trpo_pendulum] epoch #722 | Time 459.06 s\n",
      "2022-08-17 18:12:23 | [trpo_pendulum] epoch #722 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -590.227\n",
      "Evaluation/AverageReturn              -1468.03\n",
      "Evaluation/Iteration                    722\n",
      "Evaluation/MaxReturn                  -1406.2\n",
      "Evaluation/MinReturn                  -1514.15\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     36.215\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.91916\n",
      "GaussianMLPPolicy/KL                      0.00683064\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              22.2099\n",
      "GaussianMLPPolicy/LossBefore             24.086\n",
      "GaussianMLPPolicy/dLoss                   1.87615\n",
      "GaussianMLPValueFunction/LossAfter        6.61133\n",
      "GaussianMLPValueFunction/LossBefore       6.61212\n",
      "GaussianMLPValueFunction/dLoss            0.00079155\n",
      "TotalEnvSteps                        867600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:23 | [trpo_pendulum] epoch #723 | Saving snapshot...\n",
      "2022-08-17 18:12:23 | [trpo_pendulum] epoch #723 | Saved\n",
      "2022-08-17 18:12:23 | [trpo_pendulum] epoch #723 | Time 459.71 s\n",
      "2022-08-17 18:12:23 | [trpo_pendulum] epoch #723 | EpochTime 0.64 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -673.434\n",
      "Evaluation/AverageReturn              -1528.71\n",
      "Evaluation/Iteration                    723\n",
      "Evaluation/MaxReturn                  -1519.9\n",
      "Evaluation/MinReturn                  -1540.75\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      7.81836\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.94283\n",
      "GaussianMLPPolicy/KL                      0.00941746\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              20.055\n",
      "GaussianMLPPolicy/LossBefore             22.0108\n",
      "GaussianMLPPolicy/dLoss                   1.95571\n",
      "GaussianMLPValueFunction/LossAfter        6.6298\n",
      "GaussianMLPValueFunction/LossBefore       6.63054\n",
      "GaussianMLPValueFunction/dLoss            0.000737667\n",
      "TotalEnvSteps                        868800\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:24 | [trpo_pendulum] epoch #724 | Saving snapshot...\n",
      "2022-08-17 18:12:24 | [trpo_pendulum] epoch #724 | Saved\n",
      "2022-08-17 18:12:24 | [trpo_pendulum] epoch #724 | Time 460.34 s\n",
      "2022-08-17 18:12:24 | [trpo_pendulum] epoch #724 | EpochTime 0.63 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -640.64\n",
      "Evaluation/AverageReturn              -1497.96\n",
      "Evaluation/Iteration                    724\n",
      "Evaluation/MaxReturn                  -1373.93\n",
      "Evaluation/MinReturn                  -1527.61\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     55.5881\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.91819\n",
      "GaussianMLPPolicy/KL                      0.00963278\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              19.3566\n",
      "GaussianMLPPolicy/LossBefore             21.797\n",
      "GaussianMLPPolicy/dLoss                   2.44041\n",
      "GaussianMLPValueFunction/LossAfter        6.6441\n",
      "GaussianMLPValueFunction/LossBefore       6.64482\n",
      "GaussianMLPValueFunction/dLoss            0.000716209\n",
      "TotalEnvSteps                        870000\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:25 | [trpo_pendulum] epoch #725 | Saving snapshot...\n",
      "2022-08-17 18:12:25 | [trpo_pendulum] epoch #725 | Saved\n",
      "2022-08-17 18:12:25 | [trpo_pendulum] epoch #725 | Time 461.01 s\n",
      "2022-08-17 18:12:25 | [trpo_pendulum] epoch #725 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -642.951\n",
      "Evaluation/AverageReturn              -1529.92\n",
      "Evaluation/Iteration                    725\n",
      "Evaluation/MaxReturn                  -1512.2\n",
      "Evaluation/MinReturn                  -1549.6\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     12.9768\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.92302\n",
      "GaussianMLPPolicy/KL                      0.00980969\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              27.8453\n",
      "GaussianMLPPolicy/LossBefore             29.2721\n",
      "GaussianMLPPolicy/dLoss                   1.42674\n",
      "GaussianMLPValueFunction/LossAfter        6.69875\n",
      "GaussianMLPValueFunction/LossBefore       6.7031\n",
      "GaussianMLPValueFunction/dLoss            0.00435829\n",
      "TotalEnvSteps                        871200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:25 | [trpo_pendulum] epoch #726 | Saving snapshot...\n",
      "2022-08-17 18:12:25 | [trpo_pendulum] epoch #726 | Saved\n",
      "2022-08-17 18:12:25 | [trpo_pendulum] epoch #726 | Time 461.68 s\n",
      "2022-08-17 18:12:25 | [trpo_pendulum] epoch #726 | EpochTime 0.66 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -655.731\n",
      "Evaluation/AverageReturn              -1558.47\n",
      "Evaluation/Iteration                    726\n",
      "Evaluation/MaxReturn                  -1524.13\n",
      "Evaluation/MinReturn                  -1599.57\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     25.2021\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.92\n",
      "GaussianMLPPolicy/KL                      0.000408865\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              32.5332\n",
      "GaussianMLPPolicy/LossBefore             32.5617\n",
      "GaussianMLPPolicy/dLoss                   0.028511\n",
      "GaussianMLPValueFunction/LossAfter        6.71397\n",
      "GaussianMLPValueFunction/LossBefore       6.71716\n",
      "GaussianMLPValueFunction/dLoss            0.00319052\n",
      "TotalEnvSteps                        872400\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:26 | [trpo_pendulum] epoch #727 | Saving snapshot...\n",
      "2022-08-17 18:12:26 | [trpo_pendulum] epoch #727 | Saved\n",
      "2022-08-17 18:12:26 | [trpo_pendulum] epoch #727 | Time 462.34 s\n",
      "2022-08-17 18:12:26 | [trpo_pendulum] epoch #727 | EpochTime 0.66 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -629.4\n",
      "Evaluation/AverageReturn              -1514.03\n",
      "Evaluation/Iteration                    727\n",
      "Evaluation/MaxReturn                  -1495.96\n",
      "Evaluation/MinReturn                  -1550.83\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     18.0924\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.92823\n",
      "GaussianMLPPolicy/KL                      0.00495958\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              25.2915\n",
      "GaussianMLPPolicy/LossBefore             25.9929\n",
      "GaussianMLPPolicy/dLoss                   0.701351\n",
      "GaussianMLPValueFunction/LossAfter        6.65951\n",
      "GaussianMLPValueFunction/LossBefore       6.66023\n",
      "GaussianMLPValueFunction/dLoss            0.000722408\n",
      "TotalEnvSteps                        873600\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:27 | [trpo_pendulum] epoch #728 | Saving snapshot...\n",
      "2022-08-17 18:12:27 | [trpo_pendulum] epoch #728 | Saved\n",
      "2022-08-17 18:12:27 | [trpo_pendulum] epoch #728 | Time 462.99 s\n",
      "2022-08-17 18:12:27 | [trpo_pendulum] epoch #728 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -576.66\n",
      "Evaluation/AverageReturn              -1428.68\n",
      "Evaluation/Iteration                    728\n",
      "Evaluation/MaxReturn                  -1357.36\n",
      "Evaluation/MinReturn                  -1495.94\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     52.2252\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.94403\n",
      "GaussianMLPPolicy/KL                      0.00628595\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              12.7314\n",
      "GaussianMLPPolicy/LossBefore             14.1904\n",
      "GaussianMLPPolicy/dLoss                   1.45901\n",
      "GaussianMLPValueFunction/LossAfter        6.54916\n",
      "GaussianMLPValueFunction/LossBefore       6.57284\n",
      "GaussianMLPValueFunction/dLoss            0.0236835\n",
      "TotalEnvSteps                        874800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:27 | [trpo_pendulum] epoch #729 | Saving snapshot...\n",
      "2022-08-17 18:12:27 | [trpo_pendulum] epoch #729 | Saved\n",
      "2022-08-17 18:12:27 | [trpo_pendulum] epoch #729 | Time 463.61 s\n",
      "2022-08-17 18:12:27 | [trpo_pendulum] epoch #729 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -596.728\n",
      "Evaluation/AverageReturn              -1479.1\n",
      "Evaluation/Iteration                    729\n",
      "Evaluation/MaxReturn                  -1431.79\n",
      "Evaluation/MinReturn                  -1523.75\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     28.0534\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.92485\n",
      "GaussianMLPPolicy/KL                      0.00910652\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              25.3955\n",
      "GaussianMLPPolicy/LossBefore             26.8786\n",
      "GaussianMLPPolicy/dLoss                   1.48313\n",
      "GaussianMLPValueFunction/LossAfter        6.60476\n",
      "GaussianMLPValueFunction/LossBefore       6.60598\n",
      "GaussianMLPValueFunction/dLoss            0.00121641\n",
      "TotalEnvSteps                        876000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:28 | [trpo_pendulum] epoch #730 | Saving snapshot...\n",
      "2022-08-17 18:12:28 | [trpo_pendulum] epoch #730 | Saved\n",
      "2022-08-17 18:12:28 | [trpo_pendulum] epoch #730 | Time 464.26 s\n",
      "2022-08-17 18:12:28 | [trpo_pendulum] epoch #730 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -575.735\n",
      "Evaluation/AverageReturn              -1461.47\n",
      "Evaluation/Iteration                    730\n",
      "Evaluation/MaxReturn                  -1378.02\n",
      "Evaluation/MinReturn                  -1519.96\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     56.8632\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.94253\n",
      "GaussianMLPPolicy/KL                      0.00814259\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              22.4122\n",
      "GaussianMLPPolicy/LossBefore             23.5613\n",
      "GaussianMLPPolicy/dLoss                   1.14915\n",
      "GaussianMLPValueFunction/LossAfter        6.61693\n",
      "GaussianMLPValueFunction/LossBefore       6.61779\n",
      "GaussianMLPValueFunction/dLoss            0.0008564\n",
      "TotalEnvSteps                        877200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:29 | [trpo_pendulum] epoch #731 | Saving snapshot...\n",
      "2022-08-17 18:12:29 | [trpo_pendulum] epoch #731 | Saved\n",
      "2022-08-17 18:12:29 | [trpo_pendulum] epoch #731 | Time 464.88 s\n",
      "2022-08-17 18:12:29 | [trpo_pendulum] epoch #731 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -580.142\n",
      "Evaluation/AverageReturn              -1466.67\n",
      "Evaluation/Iteration                    731\n",
      "Evaluation/MaxReturn                  -1399.56\n",
      "Evaluation/MinReturn                  -1505.73\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     37.2575\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.95187\n",
      "GaussianMLPPolicy/KL                      0.00900644\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              21.4225\n",
      "GaussianMLPPolicy/LossBefore             23.7219\n",
      "GaussianMLPPolicy/dLoss                   2.29944\n",
      "GaussianMLPValueFunction/LossAfter        6.5883\n",
      "GaussianMLPValueFunction/LossBefore       6.59748\n",
      "GaussianMLPValueFunction/dLoss            0.0091753\n",
      "TotalEnvSteps                        878400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:29 | [trpo_pendulum] epoch #732 | Saving snapshot...\n",
      "2022-08-17 18:12:29 | [trpo_pendulum] epoch #732 | Saved\n",
      "2022-08-17 18:12:29 | [trpo_pendulum] epoch #732 | Time 465.51 s\n",
      "2022-08-17 18:12:29 | [trpo_pendulum] epoch #732 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -653.491\n",
      "Evaluation/AverageReturn              -1514.48\n",
      "Evaluation/Iteration                    732\n",
      "Evaluation/MaxReturn                  -1481.62\n",
      "Evaluation/MinReturn                  -1554.37\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     24.3113\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.95544\n",
      "GaussianMLPPolicy/KL                      0.00817779\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              18.0659\n",
      "GaussianMLPPolicy/LossBefore             20.1801\n",
      "GaussianMLPPolicy/dLoss                   2.11419\n",
      "GaussianMLPValueFunction/LossAfter        6.65887\n",
      "GaussianMLPValueFunction/LossBefore       6.66091\n",
      "GaussianMLPValueFunction/dLoss            0.00204134\n",
      "TotalEnvSteps                        879600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:30 | [trpo_pendulum] epoch #733 | Saving snapshot...\n",
      "2022-08-17 18:12:30 | [trpo_pendulum] epoch #733 | Saved\n",
      "2022-08-17 18:12:30 | [trpo_pendulum] epoch #733 | Time 466.17 s\n",
      "2022-08-17 18:12:30 | [trpo_pendulum] epoch #733 | EpochTime 0.65 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -688.919\n",
      "Evaluation/AverageReturn              -1546.33\n",
      "Evaluation/Iteration                    733\n",
      "Evaluation/MaxReturn                  -1538.64\n",
      "Evaluation/MinReturn                  -1556.15\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.27691\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.97281\n",
      "GaussianMLPPolicy/KL                      0.00905671\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              16.7288\n",
      "GaussianMLPPolicy/LossBefore             19.4131\n",
      "GaussianMLPPolicy/dLoss                   2.68431\n",
      "GaussianMLPValueFunction/LossAfter        6.63564\n",
      "GaussianMLPValueFunction/LossBefore       6.63568\n",
      "GaussianMLPValueFunction/dLoss            4.24385e-05\n",
      "TotalEnvSteps                        880800\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:31 | [trpo_pendulum] epoch #734 | Saving snapshot...\n",
      "2022-08-17 18:12:31 | [trpo_pendulum] epoch #734 | Saved\n",
      "2022-08-17 18:12:31 | [trpo_pendulum] epoch #734 | Time 466.82 s\n",
      "2022-08-17 18:12:31 | [trpo_pendulum] epoch #734 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -680.073\n",
      "Evaluation/AverageReturn              -1627.88\n",
      "Evaluation/Iteration                    734\n",
      "Evaluation/MaxReturn                  -1614.13\n",
      "Evaluation/MinReturn                  -1644.65\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     10.3412\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.98004\n",
      "GaussianMLPPolicy/KL                      0.00569569\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              38.694\n",
      "GaussianMLPPolicy/LossBefore             39.7939\n",
      "GaussianMLPPolicy/dLoss                   1.0999\n",
      "GaussianMLPValueFunction/LossAfter        6.71601\n",
      "GaussianMLPValueFunction/LossBefore       6.7236\n",
      "GaussianMLPValueFunction/dLoss            0.00759125\n",
      "TotalEnvSteps                        882000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:31 | [trpo_pendulum] epoch #735 | Saving snapshot...\n",
      "2022-08-17 18:12:31 | [trpo_pendulum] epoch #735 | Saved\n",
      "2022-08-17 18:12:31 | [trpo_pendulum] epoch #735 | Time 467.47 s\n",
      "2022-08-17 18:12:31 | [trpo_pendulum] epoch #735 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -593.96\n",
      "Evaluation/AverageReturn              -1461.18\n",
      "Evaluation/Iteration                    735\n",
      "Evaluation/MaxReturn                  -1338.5\n",
      "Evaluation/MinReturn                  -1516.98\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     65.2952\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.99603\n",
      "GaussianMLPPolicy/KL                      0.00904765\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              13.8781\n",
      "GaussianMLPPolicy/LossBefore             17.6449\n",
      "GaussianMLPPolicy/dLoss                   3.76674\n",
      "GaussianMLPValueFunction/LossAfter        6.59603\n",
      "GaussianMLPValueFunction/LossBefore       6.6004\n",
      "GaussianMLPValueFunction/dLoss            0.00436354\n",
      "TotalEnvSteps                        883200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:32 | [trpo_pendulum] epoch #736 | Saving snapshot...\n",
      "2022-08-17 18:12:32 | [trpo_pendulum] epoch #736 | Saved\n",
      "2022-08-17 18:12:32 | [trpo_pendulum] epoch #736 | Time 468.09 s\n",
      "2022-08-17 18:12:32 | [trpo_pendulum] epoch #736 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -659.485\n",
      "Evaluation/AverageReturn              -1577.94\n",
      "Evaluation/Iteration                    736\n",
      "Evaluation/MaxReturn                  -1554.72\n",
      "Evaluation/MinReturn                  -1603.26\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     14.7599\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.00886\n",
      "GaussianMLPPolicy/KL                      0.00498015\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              32.0139\n",
      "GaussianMLPPolicy/LossBefore             32.4604\n",
      "GaussianMLPPolicy/dLoss                   0.446499\n",
      "GaussianMLPValueFunction/LossAfter        6.71892\n",
      "GaussianMLPValueFunction/LossBefore       6.72417\n",
      "GaussianMLPValueFunction/dLoss            0.00524998\n",
      "TotalEnvSteps                        884400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:32 | [trpo_pendulum] epoch #737 | Saving snapshot...\n",
      "2022-08-17 18:12:32 | [trpo_pendulum] epoch #737 | Saved\n",
      "2022-08-17 18:12:32 | [trpo_pendulum] epoch #737 | Time 468.73 s\n",
      "2022-08-17 18:12:32 | [trpo_pendulum] epoch #737 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -597.893\n",
      "Evaluation/AverageReturn              -1523.61\n",
      "Evaluation/Iteration                    737\n",
      "Evaluation/MaxReturn                  -1514.76\n",
      "Evaluation/MinReturn                  -1533.09\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      6.23031\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.00335\n",
      "GaussianMLPPolicy/KL                      0.00653025\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              30.1215\n",
      "GaussianMLPPolicy/LossBefore             31.2811\n",
      "GaussianMLPPolicy/dLoss                   1.15956\n",
      "GaussianMLPValueFunction/LossAfter        6.68741\n",
      "GaussianMLPValueFunction/LossBefore       6.68848\n",
      "GaussianMLPValueFunction/dLoss            0.0010705\n",
      "TotalEnvSteps                        885600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:33 | [trpo_pendulum] epoch #738 | Saving snapshot...\n",
      "2022-08-17 18:12:33 | [trpo_pendulum] epoch #738 | Saved\n",
      "2022-08-17 18:12:33 | [trpo_pendulum] epoch #738 | Time 469.36 s\n",
      "2022-08-17 18:12:33 | [trpo_pendulum] epoch #738 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -627.964\n",
      "Evaluation/AverageReturn              -1498.75\n",
      "Evaluation/Iteration                    738\n",
      "Evaluation/MaxReturn                  -1432.26\n",
      "Evaluation/MinReturn                  -1520.55\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     30.1296\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.98611\n",
      "GaussianMLPPolicy/KL                      0.00830004\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              30.2134\n",
      "GaussianMLPPolicy/LossBefore             30.671\n",
      "GaussianMLPPolicy/dLoss                   0.457615\n",
      "GaussianMLPValueFunction/LossAfter        6.6405\n",
      "GaussianMLPValueFunction/LossBefore       6.65282\n",
      "GaussianMLPValueFunction/dLoss            0.0123248\n",
      "TotalEnvSteps                        886800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:34 | [trpo_pendulum] epoch #739 | Saving snapshot...\n",
      "2022-08-17 18:12:34 | [trpo_pendulum] epoch #739 | Saved\n",
      "2022-08-17 18:12:34 | [trpo_pendulum] epoch #739 | Time 469.99 s\n",
      "2022-08-17 18:12:34 | [trpo_pendulum] epoch #739 | EpochTime 0.62 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -617.414\n",
      "Evaluation/AverageReturn              -1503.23\n",
      "Evaluation/Iteration                    739\n",
      "Evaluation/MaxReturn                  -1477.13\n",
      "Evaluation/MinReturn                  -1525.34\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     16.6017\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.97404\n",
      "GaussianMLPPolicy/KL                      0.00924866\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              23.2813\n",
      "GaussianMLPPolicy/LossBefore             25.1659\n",
      "GaussianMLPPolicy/dLoss                   1.8846\n",
      "GaussianMLPValueFunction/LossAfter        6.64268\n",
      "GaussianMLPValueFunction/LossBefore       6.64363\n",
      "GaussianMLPValueFunction/dLoss            0.000957966\n",
      "TotalEnvSteps                        888000\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:34 | [trpo_pendulum] epoch #740 | Saving snapshot...\n",
      "2022-08-17 18:12:34 | [trpo_pendulum] epoch #740 | Saved\n",
      "2022-08-17 18:12:34 | [trpo_pendulum] epoch #740 | Time 470.63 s\n",
      "2022-08-17 18:12:34 | [trpo_pendulum] epoch #740 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -566.992\n",
      "Evaluation/AverageReturn              -1423.94\n",
      "Evaluation/Iteration                    740\n",
      "Evaluation/MaxReturn                  -1335.94\n",
      "Evaluation/MinReturn                  -1501.1\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     61.7864\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.96919\n",
      "GaussianMLPPolicy/KL                      0.00690234\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               7.65127\n",
      "GaussianMLPPolicy/LossBefore             11.2289\n",
      "GaussianMLPPolicy/dLoss                   3.57765\n",
      "GaussianMLPValueFunction/LossAfter        6.55961\n",
      "GaussianMLPValueFunction/LossBefore       6.56687\n",
      "GaussianMLPValueFunction/dLoss            0.00726748\n",
      "TotalEnvSteps                        889200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:35 | [trpo_pendulum] epoch #741 | Saving snapshot...\n",
      "2022-08-17 18:12:35 | [trpo_pendulum] epoch #741 | Saved\n",
      "2022-08-17 18:12:35 | [trpo_pendulum] epoch #741 | Time 471.26 s\n",
      "2022-08-17 18:12:35 | [trpo_pendulum] epoch #741 | EpochTime 0.62 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -654.156\n",
      "Evaluation/AverageReturn              -1513.13\n",
      "Evaluation/Iteration                    741\n",
      "Evaluation/MaxReturn                  -1510.05\n",
      "Evaluation/MinReturn                  -1516.48\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      2.468\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.98325\n",
      "GaussianMLPPolicy/KL                      0.00727272\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              14.79\n",
      "GaussianMLPPolicy/LossBefore             16.433\n",
      "GaussianMLPPolicy/dLoss                   1.64294\n",
      "GaussianMLPValueFunction/LossAfter        6.61747\n",
      "GaussianMLPValueFunction/LossBefore       6.61756\n",
      "GaussianMLPValueFunction/dLoss            9.01222e-05\n",
      "TotalEnvSteps                        890400\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:36 | [trpo_pendulum] epoch #742 | Saving snapshot...\n",
      "2022-08-17 18:12:36 | [trpo_pendulum] epoch #742 | Saved\n",
      "2022-08-17 18:12:36 | [trpo_pendulum] epoch #742 | Time 471.92 s\n",
      "2022-08-17 18:12:36 | [trpo_pendulum] epoch #742 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -671.89\n",
      "Evaluation/AverageReturn              -1546.74\n",
      "Evaluation/Iteration                    742\n",
      "Evaluation/MaxReturn                  -1530.76\n",
      "Evaluation/MinReturn                  -1570.44\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     15.5245\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.96271\n",
      "GaussianMLPPolicy/KL                      0.00688219\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              19.5121\n",
      "GaussianMLPPolicy/LossBefore             21.8672\n",
      "GaussianMLPPolicy/dLoss                   2.35513\n",
      "GaussianMLPValueFunction/LossAfter        6.67689\n",
      "GaussianMLPValueFunction/LossBefore       6.67969\n",
      "GaussianMLPValueFunction/dLoss            0.00279713\n",
      "TotalEnvSteps                        891600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:36 | [trpo_pendulum] epoch #743 | Saving snapshot...\n",
      "2022-08-17 18:12:36 | [trpo_pendulum] epoch #743 | Saved\n",
      "2022-08-17 18:12:36 | [trpo_pendulum] epoch #743 | Time 472.57 s\n",
      "2022-08-17 18:12:36 | [trpo_pendulum] epoch #743 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -653.707\n",
      "Evaluation/AverageReturn              -1502.31\n",
      "Evaluation/Iteration                    743\n",
      "Evaluation/MaxReturn                  -1494.75\n",
      "Evaluation/MinReturn                  -1513.44\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.72736\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.96504\n",
      "GaussianMLPPolicy/KL                      0.00546044\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              12.5505\n",
      "GaussianMLPPolicy/LossBefore             14.0764\n",
      "GaussianMLPPolicy/dLoss                   1.52589\n",
      "GaussianMLPValueFunction/LossAfter        6.62181\n",
      "GaussianMLPValueFunction/LossBefore       6.62228\n",
      "GaussianMLPValueFunction/dLoss            0.00047493\n",
      "TotalEnvSteps                        892800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:37 | [trpo_pendulum] epoch #744 | Saving snapshot...\n",
      "2022-08-17 18:12:37 | [trpo_pendulum] epoch #744 | Saved\n",
      "2022-08-17 18:12:37 | [trpo_pendulum] epoch #744 | Time 473.22 s\n",
      "2022-08-17 18:12:37 | [trpo_pendulum] epoch #744 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -667.964\n",
      "Evaluation/AverageReturn              -1578.22\n",
      "Evaluation/Iteration                    744\n",
      "Evaluation/MaxReturn                  -1536.19\n",
      "Evaluation/MinReturn                  -1614.87\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     29.7804\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.96787\n",
      "GaussianMLPPolicy/KL                      0.00667266\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              27.3918\n",
      "GaussianMLPPolicy/LossBefore             29.5798\n",
      "GaussianMLPPolicy/dLoss                   2.18802\n",
      "GaussianMLPValueFunction/LossAfter        6.72247\n",
      "GaussianMLPValueFunction/LossBefore       6.72866\n",
      "GaussianMLPValueFunction/dLoss            0.00618219\n",
      "TotalEnvSteps                        894000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:38 | [trpo_pendulum] epoch #745 | Saving snapshot...\n",
      "2022-08-17 18:12:38 | [trpo_pendulum] epoch #745 | Saved\n",
      "2022-08-17 18:12:38 | [trpo_pendulum] epoch #745 | Time 473.85 s\n",
      "2022-08-17 18:12:38 | [trpo_pendulum] epoch #745 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -551.691\n",
      "Evaluation/AverageReturn              -1380.88\n",
      "Evaluation/Iteration                    745\n",
      "Evaluation/MaxReturn                  -1354.29\n",
      "Evaluation/MinReturn                  -1410.55\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     19.7045\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.99672\n",
      "GaussianMLPPolicy/KL                      0.00564519\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               5.12504\n",
      "GaussianMLPPolicy/LossBefore              5.96632\n",
      "GaussianMLPPolicy/dLoss                   0.841274\n",
      "GaussianMLPValueFunction/LossAfter        6.57114\n",
      "GaussianMLPValueFunction/LossBefore       6.57993\n",
      "GaussianMLPValueFunction/dLoss            0.00879574\n",
      "TotalEnvSteps                        895200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:38 | [trpo_pendulum] epoch #746 | Saving snapshot...\n",
      "2022-08-17 18:12:38 | [trpo_pendulum] epoch #746 | Saved\n",
      "2022-08-17 18:12:38 | [trpo_pendulum] epoch #746 | Time 474.50 s\n",
      "2022-08-17 18:12:38 | [trpo_pendulum] epoch #746 | EpochTime 0.65 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -678.577\n",
      "Evaluation/AverageReturn              -1544.39\n",
      "Evaluation/Iteration                    746\n",
      "Evaluation/MaxReturn                  -1533.22\n",
      "Evaluation/MinReturn                  -1561.34\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     11.1751\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.00803\n",
      "GaussianMLPPolicy/KL                      0.00947378\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              17.9875\n",
      "GaussianMLPPolicy/LossBefore             19.3049\n",
      "GaussianMLPPolicy/dLoss                   1.31739\n",
      "GaussianMLPValueFunction/LossAfter        6.65152\n",
      "GaussianMLPValueFunction/LossBefore       6.65175\n",
      "GaussianMLPValueFunction/dLoss            0.000226498\n",
      "TotalEnvSteps                        896400\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:39 | [trpo_pendulum] epoch #747 | Saving snapshot...\n",
      "2022-08-17 18:12:39 | [trpo_pendulum] epoch #747 | Saved\n",
      "2022-08-17 18:12:39 | [trpo_pendulum] epoch #747 | Time 475.14 s\n",
      "2022-08-17 18:12:39 | [trpo_pendulum] epoch #747 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -613.152\n",
      "Evaluation/AverageReturn              -1516.79\n",
      "Evaluation/Iteration                    747\n",
      "Evaluation/MaxReturn                  -1326\n",
      "Evaluation/MinReturn                  -1595.71\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     91.0707\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.0271\n",
      "GaussianMLPPolicy/KL                      0.00996445\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              21.4169\n",
      "GaussianMLPPolicy/LossBefore             24.2671\n",
      "GaussianMLPPolicy/dLoss                   2.85016\n",
      "GaussianMLPValueFunction/LossAfter        6.67831\n",
      "GaussianMLPValueFunction/LossBefore       6.67974\n",
      "GaussianMLPValueFunction/dLoss            0.00142908\n",
      "TotalEnvSteps                        897600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:39 | [trpo_pendulum] epoch #748 | Saving snapshot...\n",
      "2022-08-17 18:12:40 | [trpo_pendulum] epoch #748 | Saved\n",
      "2022-08-17 18:12:40 | [trpo_pendulum] epoch #748 | Time 475.78 s\n",
      "2022-08-17 18:12:40 | [trpo_pendulum] epoch #748 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -716.25\n",
      "Evaluation/AverageReturn              -1622.25\n",
      "Evaluation/Iteration                    748\n",
      "Evaluation/MaxReturn                  -1589.88\n",
      "Evaluation/MinReturn                  -1653.29\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     23.1162\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.02367\n",
      "GaussianMLPPolicy/KL                      0.00787212\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              29.6928\n",
      "GaussianMLPPolicy/LossBefore             31.2825\n",
      "GaussianMLPPolicy/dLoss                   1.58967\n",
      "GaussianMLPValueFunction/LossAfter        6.75277\n",
      "GaussianMLPValueFunction/LossBefore       6.75969\n",
      "GaussianMLPValueFunction/dLoss            0.00691414\n",
      "TotalEnvSteps                        898800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:40 | [trpo_pendulum] epoch #749 | Saving snapshot...\n",
      "2022-08-17 18:12:40 | [trpo_pendulum] epoch #749 | Saved\n",
      "2022-08-17 18:12:40 | [trpo_pendulum] epoch #749 | Time 476.39 s\n",
      "2022-08-17 18:12:40 | [trpo_pendulum] epoch #749 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -617.042\n",
      "Evaluation/AverageReturn              -1500.42\n",
      "Evaluation/Iteration                    749\n",
      "Evaluation/MaxReturn                  -1492.42\n",
      "Evaluation/MinReturn                  -1511.5\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      7.48406\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.00326\n",
      "GaussianMLPPolicy/KL                      0.00911497\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              18.9409\n",
      "GaussianMLPPolicy/LossBefore             19.7934\n",
      "GaussianMLPPolicy/dLoss                   0.852528\n",
      "GaussianMLPValueFunction/LossAfter        6.62163\n",
      "GaussianMLPValueFunction/LossBefore       6.62517\n",
      "GaussianMLPValueFunction/dLoss            0.0035367\n",
      "TotalEnvSteps                        900000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:41 | [trpo_pendulum] epoch #750 | Saving snapshot...\n",
      "2022-08-17 18:12:41 | [trpo_pendulum] epoch #750 | Saved\n",
      "2022-08-17 18:12:41 | [trpo_pendulum] epoch #750 | Time 477.03 s\n",
      "2022-08-17 18:12:41 | [trpo_pendulum] epoch #750 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -707.855\n",
      "Evaluation/AverageReturn              -1610.57\n",
      "Evaluation/Iteration                    750\n",
      "Evaluation/MaxReturn                  -1563.77\n",
      "Evaluation/MinReturn                  -1725.84\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     53.2836\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.95548\n",
      "GaussianMLPPolicy/KL                      0.00818742\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              26.9963\n",
      "GaussianMLPPolicy/LossBefore             29.1567\n",
      "GaussianMLPPolicy/dLoss                   2.16043\n",
      "GaussianMLPValueFunction/LossAfter        6.73008\n",
      "GaussianMLPValueFunction/LossBefore       6.73287\n",
      "GaussianMLPValueFunction/dLoss            0.00278616\n",
      "TotalEnvSteps                        901200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:41 | [trpo_pendulum] epoch #751 | Saving snapshot...\n",
      "2022-08-17 18:12:41 | [trpo_pendulum] epoch #751 | Saved\n",
      "2022-08-17 18:12:41 | [trpo_pendulum] epoch #751 | Time 477.70 s\n",
      "2022-08-17 18:12:41 | [trpo_pendulum] epoch #751 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -555.128\n",
      "Evaluation/AverageReturn              -1399.65\n",
      "Evaluation/Iteration                    751\n",
      "Evaluation/MaxReturn                  -1350.08\n",
      "Evaluation/MinReturn                  -1477.66\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     43.7976\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.94623\n",
      "GaussianMLPPolicy/KL                      0.00758625\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              13.8533\n",
      "GaussianMLPPolicy/LossBefore             15.1958\n",
      "GaussianMLPPolicy/dLoss                   1.34253\n",
      "GaussianMLPValueFunction/LossAfter        6.55111\n",
      "GaussianMLPValueFunction/LossBefore       6.56593\n",
      "GaussianMLPValueFunction/dLoss            0.0148177\n",
      "TotalEnvSteps                        902400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:42 | [trpo_pendulum] epoch #752 | Saving snapshot...\n",
      "2022-08-17 18:12:42 | [trpo_pendulum] epoch #752 | Saved\n",
      "2022-08-17 18:12:42 | [trpo_pendulum] epoch #752 | Time 478.33 s\n",
      "2022-08-17 18:12:42 | [trpo_pendulum] epoch #752 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -603.106\n",
      "Evaluation/AverageReturn              -1467.25\n",
      "Evaluation/Iteration                    752\n",
      "Evaluation/MaxReturn                  -1365.53\n",
      "Evaluation/MinReturn                  -1510.76\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     49.9231\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.95866\n",
      "GaussianMLPPolicy/KL                      0.00487294\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              36.1623\n",
      "GaussianMLPPolicy/LossBefore             36.8238\n",
      "GaussianMLPPolicy/dLoss                   0.661499\n",
      "GaussianMLPValueFunction/LossAfter        6.62472\n",
      "GaussianMLPValueFunction/LossBefore       6.66185\n",
      "GaussianMLPValueFunction/dLoss            0.0371308\n",
      "TotalEnvSteps                        903600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:43 | [trpo_pendulum] epoch #753 | Saving snapshot...\n",
      "2022-08-17 18:12:43 | [trpo_pendulum] epoch #753 | Saved\n",
      "2022-08-17 18:12:43 | [trpo_pendulum] epoch #753 | Time 478.98 s\n",
      "2022-08-17 18:12:43 | [trpo_pendulum] epoch #753 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -606.519\n",
      "Evaluation/AverageReturn              -1496.22\n",
      "Evaluation/Iteration                    753\n",
      "Evaluation/MaxReturn                  -1461.64\n",
      "Evaluation/MinReturn                  -1514.61\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     18.0443\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.97702\n",
      "GaussianMLPPolicy/KL                      0.00933334\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              19.9325\n",
      "GaussianMLPPolicy/LossBefore             21.2912\n",
      "GaussianMLPPolicy/dLoss                   1.35871\n",
      "GaussianMLPValueFunction/LossAfter        6.6292\n",
      "GaussianMLPValueFunction/LossBefore       6.62927\n",
      "GaussianMLPValueFunction/dLoss            6.7234e-05\n",
      "TotalEnvSteps                        904800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:43 | [trpo_pendulum] epoch #754 | Saving snapshot...\n",
      "2022-08-17 18:12:43 | [trpo_pendulum] epoch #754 | Saved\n",
      "2022-08-17 18:12:43 | [trpo_pendulum] epoch #754 | Time 479.64 s\n",
      "2022-08-17 18:12:43 | [trpo_pendulum] epoch #754 | EpochTime 0.66 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -632.242\n",
      "Evaluation/AverageReturn              -1506.57\n",
      "Evaluation/Iteration                    754\n",
      "Evaluation/MaxReturn                  -1486.51\n",
      "Evaluation/MinReturn                  -1521.83\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     11.1992\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.98073\n",
      "GaussianMLPPolicy/KL                      0.00536399\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              18.1806\n",
      "GaussianMLPPolicy/LossBefore             18.6084\n",
      "GaussianMLPPolicy/dLoss                   0.427811\n",
      "GaussianMLPValueFunction/LossAfter        6.64632\n",
      "GaussianMLPValueFunction/LossBefore       6.64647\n",
      "GaussianMLPValueFunction/dLoss            0.000151157\n",
      "TotalEnvSteps                        906000\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:44 | [trpo_pendulum] epoch #755 | Saving snapshot...\n",
      "2022-08-17 18:12:44 | [trpo_pendulum] epoch #755 | Saved\n",
      "2022-08-17 18:12:44 | [trpo_pendulum] epoch #755 | Time 480.31 s\n",
      "2022-08-17 18:12:44 | [trpo_pendulum] epoch #755 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -629.464\n",
      "Evaluation/AverageReturn              -1554.72\n",
      "Evaluation/Iteration                    755\n",
      "Evaluation/MaxReturn                  -1543.05\n",
      "Evaluation/MinReturn                  -1576.58\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     10.9633\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.98267\n",
      "GaussianMLPPolicy/KL                      0.00475904\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              36.3756\n",
      "GaussianMLPPolicy/LossBefore             36.9645\n",
      "GaussianMLPPolicy/dLoss                   0.588951\n",
      "GaussianMLPValueFunction/LossAfter        6.7302\n",
      "GaussianMLPValueFunction/LossBefore       6.74234\n",
      "GaussianMLPValueFunction/dLoss            0.0121441\n",
      "TotalEnvSteps                        907200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:45 | [trpo_pendulum] epoch #756 | Saving snapshot...\n",
      "2022-08-17 18:12:45 | [trpo_pendulum] epoch #756 | Saved\n",
      "2022-08-17 18:12:45 | [trpo_pendulum] epoch #756 | Time 480.98 s\n",
      "2022-08-17 18:12:45 | [trpo_pendulum] epoch #756 | EpochTime 0.67 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -614.793\n",
      "Evaluation/AverageReturn              -1516.6\n",
      "Evaluation/Iteration                    756\n",
      "Evaluation/MaxReturn                  -1477.95\n",
      "Evaluation/MinReturn                  -1551.86\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     24.7221\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.01639\n",
      "GaussianMLPPolicy/KL                      0.00692499\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              20.9592\n",
      "GaussianMLPPolicy/LossBefore             22.6752\n",
      "GaussianMLPPolicy/dLoss                   1.71601\n",
      "GaussianMLPValueFunction/LossAfter        6.64723\n",
      "GaussianMLPValueFunction/LossBefore       6.65518\n",
      "GaussianMLPValueFunction/dLoss            0.0079546\n",
      "TotalEnvSteps                        908400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:45 | [trpo_pendulum] epoch #757 | Saving snapshot...\n",
      "2022-08-17 18:12:45 | [trpo_pendulum] epoch #757 | Saved\n",
      "2022-08-17 18:12:45 | [trpo_pendulum] epoch #757 | Time 481.64 s\n",
      "2022-08-17 18:12:45 | [trpo_pendulum] epoch #757 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -551.32\n",
      "Evaluation/AverageReturn              -1399.72\n",
      "Evaluation/Iteration                    757\n",
      "Evaluation/MaxReturn                  -1323.36\n",
      "Evaluation/MinReturn                  -1487.43\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     63.2082\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.02563\n",
      "GaussianMLPPolicy/KL                      0.00724349\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               5.06261\n",
      "GaussianMLPPolicy/LossBefore              6.4705\n",
      "GaussianMLPPolicy/dLoss                   1.40789\n",
      "GaussianMLPValueFunction/LossAfter        6.52414\n",
      "GaussianMLPValueFunction/LossBefore       6.5406\n",
      "GaussianMLPValueFunction/dLoss            0.0164614\n",
      "TotalEnvSteps                        909600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:46 | [trpo_pendulum] epoch #758 | Saving snapshot...\n",
      "2022-08-17 18:12:46 | [trpo_pendulum] epoch #758 | Saved\n",
      "2022-08-17 18:12:46 | [trpo_pendulum] epoch #758 | Time 482.30 s\n",
      "2022-08-17 18:12:46 | [trpo_pendulum] epoch #758 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -728.611\n",
      "Evaluation/AverageReturn              -1606.9\n",
      "Evaluation/Iteration                    758\n",
      "Evaluation/MaxReturn                  -1568.55\n",
      "Evaluation/MinReturn                  -1652.43\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     31.9989\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.00278\n",
      "GaussianMLPPolicy/KL                      0.00853153\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              20.0822\n",
      "GaussianMLPPolicy/LossBefore             21.6369\n",
      "GaussianMLPPolicy/dLoss                   1.55474\n",
      "GaussianMLPValueFunction/LossAfter        6.6896\n",
      "GaussianMLPValueFunction/LossBefore       6.69332\n",
      "GaussianMLPValueFunction/dLoss            0.00371838\n",
      "TotalEnvSteps                        910800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:47 | [trpo_pendulum] epoch #759 | Saving snapshot...\n",
      "2022-08-17 18:12:47 | [trpo_pendulum] epoch #759 | Saved\n",
      "2022-08-17 18:12:47 | [trpo_pendulum] epoch #759 | Time 482.94 s\n",
      "2022-08-17 18:12:47 | [trpo_pendulum] epoch #759 | EpochTime 0.64 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -598.243\n",
      "Evaluation/AverageReturn              -1439.13\n",
      "Evaluation/Iteration                    759\n",
      "Evaluation/MaxReturn                  -1362.1\n",
      "Evaluation/MinReturn                  -1499.15\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     51.5081\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.00778\n",
      "GaussianMLPPolicy/KL                      0.000617826\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               8.64174\n",
      "GaussianMLPPolicy/LossBefore              8.70534\n",
      "GaussianMLPPolicy/dLoss                   0.0636015\n",
      "GaussianMLPValueFunction/LossAfter        6.60578\n",
      "GaussianMLPValueFunction/LossBefore       6.6072\n",
      "GaussianMLPValueFunction/dLoss            0.00141573\n",
      "TotalEnvSteps                        912000\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:47 | [trpo_pendulum] epoch #760 | Saving snapshot...\n",
      "2022-08-17 18:12:47 | [trpo_pendulum] epoch #760 | Saved\n",
      "2022-08-17 18:12:47 | [trpo_pendulum] epoch #760 | Time 483.58 s\n",
      "2022-08-17 18:12:47 | [trpo_pendulum] epoch #760 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -580.027\n",
      "Evaluation/AverageReturn              -1415.68\n",
      "Evaluation/Iteration                    760\n",
      "Evaluation/MaxReturn                  -1380.32\n",
      "Evaluation/MinReturn                  -1498.1\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     39.6693\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.00608\n",
      "GaussianMLPPolicy/KL                      0.00932962\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               9.79868\n",
      "GaussianMLPPolicy/LossBefore             10.618\n",
      "GaussianMLPPolicy/dLoss                   0.819274\n",
      "GaussianMLPValueFunction/LossAfter        6.61429\n",
      "GaussianMLPValueFunction/LossBefore       6.62167\n",
      "GaussianMLPValueFunction/dLoss            0.00738096\n",
      "TotalEnvSteps                        913200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:48 | [trpo_pendulum] epoch #761 | Saving snapshot...\n",
      "2022-08-17 18:12:48 | [trpo_pendulum] epoch #761 | Saved\n",
      "2022-08-17 18:12:48 | [trpo_pendulum] epoch #761 | Time 484.20 s\n",
      "2022-08-17 18:12:48 | [trpo_pendulum] epoch #761 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -703.059\n",
      "Evaluation/AverageReturn              -1589.78\n",
      "Evaluation/Iteration                    761\n",
      "Evaluation/MaxReturn                  -1534.18\n",
      "Evaluation/MinReturn                  -1618.45\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     28.2595\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.01432\n",
      "GaussianMLPPolicy/KL                      0.00917071\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              20.9429\n",
      "GaussianMLPPolicy/LossBefore             24.3599\n",
      "GaussianMLPPolicy/dLoss                   3.41703\n",
      "GaussianMLPValueFunction/LossAfter        6.69956\n",
      "GaussianMLPValueFunction/LossBefore       6.70348\n",
      "GaussianMLPValueFunction/dLoss            0.0039134\n",
      "TotalEnvSteps                        914400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:49 | [trpo_pendulum] epoch #762 | Saving snapshot...\n",
      "2022-08-17 18:12:49 | [trpo_pendulum] epoch #762 | Saved\n",
      "2022-08-17 18:12:49 | [trpo_pendulum] epoch #762 | Time 484.84 s\n",
      "2022-08-17 18:12:49 | [trpo_pendulum] epoch #762 | EpochTime 0.63 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -694.636\n",
      "Evaluation/AverageReturn              -1570.26\n",
      "Evaluation/Iteration                    762\n",
      "Evaluation/MaxReturn                  -1523.87\n",
      "Evaluation/MinReturn                  -1597.39\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     26.1825\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.00603\n",
      "GaussianMLPPolicy/KL                      0.00831892\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              19.9504\n",
      "GaussianMLPPolicy/LossBefore             21.3639\n",
      "GaussianMLPPolicy/dLoss                   1.41348\n",
      "GaussianMLPValueFunction/LossAfter        6.68784\n",
      "GaussianMLPValueFunction/LossBefore       6.68863\n",
      "GaussianMLPValueFunction/dLoss            0.000787258\n",
      "TotalEnvSteps                        915600\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:49 | [trpo_pendulum] epoch #763 | Saving snapshot...\n",
      "2022-08-17 18:12:49 | [trpo_pendulum] epoch #763 | Saved\n",
      "2022-08-17 18:12:49 | [trpo_pendulum] epoch #763 | Time 485.47 s\n",
      "2022-08-17 18:12:49 | [trpo_pendulum] epoch #763 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -607.927\n",
      "Evaluation/AverageReturn              -1494.75\n",
      "Evaluation/Iteration                    763\n",
      "Evaluation/MaxReturn                  -1468.58\n",
      "Evaluation/MinReturn                  -1519.46\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     17.7014\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.00498\n",
      "GaussianMLPPolicy/KL                      0.00548527\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              19.7689\n",
      "GaussianMLPPolicy/LossBefore             20.9746\n",
      "GaussianMLPPolicy/dLoss                   1.2057\n",
      "GaussianMLPValueFunction/LossAfter        6.63676\n",
      "GaussianMLPValueFunction/LossBefore       6.63739\n",
      "GaussianMLPValueFunction/dLoss            0.00063467\n",
      "TotalEnvSteps                        916800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:50 | [trpo_pendulum] epoch #764 | Saving snapshot...\n",
      "2022-08-17 18:12:50 | [trpo_pendulum] epoch #764 | Saved\n",
      "2022-08-17 18:12:50 | [trpo_pendulum] epoch #764 | Time 486.11 s\n",
      "2022-08-17 18:12:50 | [trpo_pendulum] epoch #764 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -645.151\n",
      "Evaluation/AverageReturn              -1559.03\n",
      "Evaluation/Iteration                    764\n",
      "Evaluation/MaxReturn                  -1547.68\n",
      "Evaluation/MinReturn                  -1584.28\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     13.2098\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.95457\n",
      "GaussianMLPPolicy/KL                      0.00733069\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              34.583\n",
      "GaussianMLPPolicy/LossBefore             35.8956\n",
      "GaussianMLPPolicy/dLoss                   1.31255\n",
      "GaussianMLPValueFunction/LossAfter        6.69128\n",
      "GaussianMLPValueFunction/LossBefore       6.6957\n",
      "GaussianMLPValueFunction/dLoss            0.00441551\n",
      "TotalEnvSteps                        918000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:50 | [trpo_pendulum] epoch #765 | Saving snapshot...\n",
      "2022-08-17 18:12:50 | [trpo_pendulum] epoch #765 | Saved\n",
      "2022-08-17 18:12:50 | [trpo_pendulum] epoch #765 | Time 486.73 s\n",
      "2022-08-17 18:12:50 | [trpo_pendulum] epoch #765 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -593.598\n",
      "Evaluation/AverageReturn              -1374.84\n",
      "Evaluation/Iteration                    765\n",
      "Evaluation/MaxReturn                  -1173.39\n",
      "Evaluation/MinReturn                  -1546.23\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    108.614\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.96017\n",
      "GaussianMLPPolicy/KL                      0.00634523\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.84756\n",
      "GaussianMLPPolicy/LossBefore             -6.12915\n",
      "GaussianMLPPolicy/dLoss                   1.71841\n",
      "GaussianMLPValueFunction/LossAfter        6.51037\n",
      "GaussianMLPValueFunction/LossBefore       6.55463\n",
      "GaussianMLPValueFunction/dLoss            0.0442634\n",
      "TotalEnvSteps                        919200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:51 | [trpo_pendulum] epoch #766 | Saving snapshot...\n",
      "2022-08-17 18:12:51 | [trpo_pendulum] epoch #766 | Saved\n",
      "2022-08-17 18:12:51 | [trpo_pendulum] epoch #766 | Time 487.35 s\n",
      "2022-08-17 18:12:51 | [trpo_pendulum] epoch #766 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -591.324\n",
      "Evaluation/AverageReturn              -1457.51\n",
      "Evaluation/Iteration                    766\n",
      "Evaluation/MaxReturn                  -1381.88\n",
      "Evaluation/MinReturn                  -1496.61\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     39.4354\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.94309\n",
      "GaussianMLPPolicy/KL                      0.00662018\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              33.2902\n",
      "GaussianMLPPolicy/LossBefore             34.3376\n",
      "GaussianMLPPolicy/dLoss                   1.04742\n",
      "GaussianMLPValueFunction/LossAfter        6.60262\n",
      "GaussianMLPValueFunction/LossBefore       6.75226\n",
      "GaussianMLPValueFunction/dLoss            0.149638\n",
      "TotalEnvSteps                        920400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:52 | [trpo_pendulum] epoch #767 | Saving snapshot...\n",
      "2022-08-17 18:12:52 | [trpo_pendulum] epoch #767 | Saved\n",
      "2022-08-17 18:12:52 | [trpo_pendulum] epoch #767 | Time 487.99 s\n",
      "2022-08-17 18:12:52 | [trpo_pendulum] epoch #767 | EpochTime 0.63 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -609.609\n",
      "Evaluation/AverageReturn              -1481.58\n",
      "Evaluation/Iteration                    767\n",
      "Evaluation/MaxReturn                  -1451.36\n",
      "Evaluation/MinReturn                  -1504.29\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     16.4733\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.96181\n",
      "GaussianMLPPolicy/KL                      0.00539823\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              16.5933\n",
      "GaussianMLPPolicy/LossBefore             17.169\n",
      "GaussianMLPPolicy/dLoss                   0.575722\n",
      "GaussianMLPValueFunction/LossAfter        6.61371\n",
      "GaussianMLPValueFunction/LossBefore       6.61374\n",
      "GaussianMLPValueFunction/dLoss            2.95639e-05\n",
      "TotalEnvSteps                        921600\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:52 | [trpo_pendulum] epoch #768 | Saving snapshot...\n",
      "2022-08-17 18:12:52 | [trpo_pendulum] epoch #768 | Saved\n",
      "2022-08-17 18:12:52 | [trpo_pendulum] epoch #768 | Time 488.62 s\n",
      "2022-08-17 18:12:52 | [trpo_pendulum] epoch #768 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -596.884\n",
      "Evaluation/AverageReturn              -1425.68\n",
      "Evaluation/Iteration                    768\n",
      "Evaluation/MaxReturn                  -1366.95\n",
      "Evaluation/MinReturn                  -1473.48\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     35.5548\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.95165\n",
      "GaussianMLPPolicy/KL                      0.00556616\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               6.88973\n",
      "GaussianMLPPolicy/LossBefore              7.50434\n",
      "GaussianMLPPolicy/dLoss                   0.614607\n",
      "GaussianMLPValueFunction/LossAfter        6.59229\n",
      "GaussianMLPValueFunction/LossBefore       6.59346\n",
      "GaussianMLPValueFunction/dLoss            0.00116539\n",
      "TotalEnvSteps                        922800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:53 | [trpo_pendulum] epoch #769 | Saving snapshot...\n",
      "2022-08-17 18:12:53 | [trpo_pendulum] epoch #769 | Saved\n",
      "2022-08-17 18:12:53 | [trpo_pendulum] epoch #769 | Time 489.26 s\n",
      "2022-08-17 18:12:53 | [trpo_pendulum] epoch #769 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -643.517\n",
      "Evaluation/AverageReturn              -1492.84\n",
      "Evaluation/Iteration                    769\n",
      "Evaluation/MaxReturn                  -1284.39\n",
      "Evaluation/MinReturn                  -1579.41\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     96.5264\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.96291\n",
      "GaussianMLPPolicy/KL                      0.00849345\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              11.6517\n",
      "GaussianMLPPolicy/LossBefore             13.6202\n",
      "GaussianMLPPolicy/dLoss                   1.96855\n",
      "GaussianMLPValueFunction/LossAfter        6.64039\n",
      "GaussianMLPValueFunction/LossBefore       6.64156\n",
      "GaussianMLPValueFunction/dLoss            0.00117826\n",
      "TotalEnvSteps                        924000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:54 | [trpo_pendulum] epoch #770 | Saving snapshot...\n",
      "2022-08-17 18:12:54 | [trpo_pendulum] epoch #770 | Saved\n",
      "2022-08-17 18:12:54 | [trpo_pendulum] epoch #770 | Time 489.93 s\n",
      "2022-08-17 18:12:54 | [trpo_pendulum] epoch #770 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -702.883\n",
      "Evaluation/AverageReturn              -1598.74\n",
      "Evaluation/Iteration                    770\n",
      "Evaluation/MaxReturn                  -1517.29\n",
      "Evaluation/MinReturn                  -1679.46\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     55.5269\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.96996\n",
      "GaussianMLPPolicy/KL                      0.00643811\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              25.1219\n",
      "GaussianMLPPolicy/LossBefore             27.2379\n",
      "GaussianMLPPolicy/dLoss                   2.11599\n",
      "GaussianMLPValueFunction/LossAfter        6.73495\n",
      "GaussianMLPValueFunction/LossBefore       6.74436\n",
      "GaussianMLPValueFunction/dLoss            0.0094018\n",
      "TotalEnvSteps                        925200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:54 | [trpo_pendulum] epoch #771 | Saving snapshot...\n",
      "2022-08-17 18:12:54 | [trpo_pendulum] epoch #771 | Saved\n",
      "2022-08-17 18:12:54 | [trpo_pendulum] epoch #771 | Time 490.59 s\n",
      "2022-08-17 18:12:54 | [trpo_pendulum] epoch #771 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -580.24\n",
      "Evaluation/AverageReturn              -1449.69\n",
      "Evaluation/Iteration                    771\n",
      "Evaluation/MaxReturn                  -1406.86\n",
      "Evaluation/MinReturn                  -1503.12\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     31.8157\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.00713\n",
      "GaussianMLPPolicy/KL                      0.00701355\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              13.0198\n",
      "GaussianMLPPolicy/LossBefore             14.4308\n",
      "GaussianMLPPolicy/dLoss                   1.41094\n",
      "GaussianMLPValueFunction/LossAfter        6.60212\n",
      "GaussianMLPValueFunction/LossBefore       6.6046\n",
      "GaussianMLPValueFunction/dLoss            0.00247622\n",
      "TotalEnvSteps                        926400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:55 | [trpo_pendulum] epoch #772 | Saving snapshot...\n",
      "2022-08-17 18:12:55 | [trpo_pendulum] epoch #772 | Saved\n",
      "2022-08-17 18:12:55 | [trpo_pendulum] epoch #772 | Time 491.25 s\n",
      "2022-08-17 18:12:55 | [trpo_pendulum] epoch #772 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -718.071\n",
      "Evaluation/AverageReturn              -1684.35\n",
      "Evaluation/Iteration                    772\n",
      "Evaluation/MaxReturn                  -1555.69\n",
      "Evaluation/MinReturn                  -1743.2\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     63.3256\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.00193\n",
      "GaussianMLPPolicy/KL                      0.009517\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              41.0502\n",
      "GaussianMLPPolicy/LossBefore             43.7663\n",
      "GaussianMLPPolicy/dLoss                   2.71608\n",
      "GaussianMLPValueFunction/LossAfter        6.85071\n",
      "GaussianMLPValueFunction/LossBefore       6.88088\n",
      "GaussianMLPValueFunction/dLoss            0.0301757\n",
      "TotalEnvSteps                        927600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:12:56 | [trpo_pendulum] epoch #773 | Saving snapshot...\n",
      "2022-08-17 18:12:56 | [trpo_pendulum] epoch #773 | Saved\n",
      "2022-08-17 18:12:56 | [trpo_pendulum] epoch #773 | Time 491.92 s\n",
      "2022-08-17 18:12:56 | [trpo_pendulum] epoch #773 | EpochTime 0.67 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -680.276\n",
      "Evaluation/AverageReturn              -1602.91\n",
      "Evaluation/Iteration                    773\n",
      "Evaluation/MaxReturn                  -1586.81\n",
      "Evaluation/MinReturn                  -1621.25\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     12.8658\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.96361\n",
      "GaussianMLPPolicy/KL                      0.00852108\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              38.5792\n",
      "GaussianMLPPolicy/LossBefore             39.1934\n",
      "GaussianMLPPolicy/dLoss                   0.614193\n",
      "GaussianMLPValueFunction/LossAfter        6.68666\n",
      "GaussianMLPValueFunction/LossBefore       6.7021\n",
      "GaussianMLPValueFunction/dLoss            0.0154467\n",
      "TotalEnvSteps                        928800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:56 | [trpo_pendulum] epoch #774 | Saving snapshot...\n",
      "2022-08-17 18:12:56 | [trpo_pendulum] epoch #774 | Saved\n",
      "2022-08-17 18:12:56 | [trpo_pendulum] epoch #774 | Time 492.56 s\n",
      "2022-08-17 18:12:56 | [trpo_pendulum] epoch #774 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -627.396\n",
      "Evaluation/AverageReturn              -1520.96\n",
      "Evaluation/Iteration                    774\n",
      "Evaluation/MaxReturn                  -1498.84\n",
      "Evaluation/MinReturn                  -1567.52\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     22.8191\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.95555\n",
      "GaussianMLPPolicy/KL                      0.00711628\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              21.4462\n",
      "GaussianMLPPolicy/LossBefore             22.1881\n",
      "GaussianMLPPolicy/dLoss                   0.741829\n",
      "GaussianMLPValueFunction/LossAfter        6.65821\n",
      "GaussianMLPValueFunction/LossBefore       6.66586\n",
      "GaussianMLPValueFunction/dLoss            0.00765371\n",
      "TotalEnvSteps                        930000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:57 | [trpo_pendulum] epoch #775 | Saving snapshot...\n",
      "2022-08-17 18:12:57 | [trpo_pendulum] epoch #775 | Saved\n",
      "2022-08-17 18:12:57 | [trpo_pendulum] epoch #775 | Time 493.25 s\n",
      "2022-08-17 18:12:57 | [trpo_pendulum] epoch #775 | EpochTime 0.68 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -667.723\n",
      "Evaluation/AverageReturn              -1573.66\n",
      "Evaluation/Iteration                    775\n",
      "Evaluation/MaxReturn                  -1542.82\n",
      "Evaluation/MinReturn                  -1589.91\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     15.4878\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.94991\n",
      "GaussianMLPPolicy/KL                      0.00947901\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              25.5903\n",
      "GaussianMLPPolicy/LossBefore             26.0743\n",
      "GaussianMLPPolicy/dLoss                   0.483984\n",
      "GaussianMLPValueFunction/LossAfter        6.68424\n",
      "GaussianMLPValueFunction/LossBefore       6.68447\n",
      "GaussianMLPValueFunction/dLoss            0.000235081\n",
      "TotalEnvSteps                        931200\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:58 | [trpo_pendulum] epoch #776 | Saving snapshot...\n",
      "2022-08-17 18:12:58 | [trpo_pendulum] epoch #776 | Saved\n",
      "2022-08-17 18:12:58 | [trpo_pendulum] epoch #776 | Time 493.92 s\n",
      "2022-08-17 18:12:58 | [trpo_pendulum] epoch #776 | EpochTime 0.67 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -690.103\n",
      "Evaluation/AverageReturn              -1563.76\n",
      "Evaluation/Iteration                    776\n",
      "Evaluation/MaxReturn                  -1540.98\n",
      "Evaluation/MinReturn                  -1586.53\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     16.2908\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.96497\n",
      "GaussianMLPPolicy/KL                      0.0077903\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              18.3765\n",
      "GaussianMLPPolicy/LossBefore             20.3986\n",
      "GaussianMLPPolicy/dLoss                   2.02207\n",
      "GaussianMLPValueFunction/LossAfter        6.68556\n",
      "GaussianMLPValueFunction/LossBefore       6.68559\n",
      "GaussianMLPValueFunction/dLoss            2.52724e-05\n",
      "TotalEnvSteps                        932400\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:12:58 | [trpo_pendulum] epoch #777 | Saving snapshot...\n",
      "2022-08-17 18:12:58 | [trpo_pendulum] epoch #777 | Saved\n",
      "2022-08-17 18:12:58 | [trpo_pendulum] epoch #777 | Time 494.56 s\n",
      "2022-08-17 18:12:58 | [trpo_pendulum] epoch #777 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -566.712\n",
      "Evaluation/AverageReturn              -1431.33\n",
      "Evaluation/Iteration                    777\n",
      "Evaluation/MaxReturn                  -1378.81\n",
      "Evaluation/MinReturn                  -1484.93\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     42.421\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.9617\n",
      "GaussianMLPPolicy/KL                      0.00973822\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              11.5482\n",
      "GaussianMLPPolicy/LossBefore             12.8625\n",
      "GaussianMLPPolicy/dLoss                   1.31426\n",
      "GaussianMLPValueFunction/LossAfter        6.57269\n",
      "GaussianMLPValueFunction/LossBefore       6.59202\n",
      "GaussianMLPValueFunction/dLoss            0.0193262\n",
      "TotalEnvSteps                        933600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:12:59 | [trpo_pendulum] epoch #778 | Saving snapshot...\n",
      "2022-08-17 18:12:59 | [trpo_pendulum] epoch #778 | Saved\n",
      "2022-08-17 18:12:59 | [trpo_pendulum] epoch #778 | Time 495.21 s\n",
      "2022-08-17 18:12:59 | [trpo_pendulum] epoch #778 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -615.295\n",
      "Evaluation/AverageReturn              -1503.98\n",
      "Evaluation/Iteration                    778\n",
      "Evaluation/MaxReturn                  -1492.81\n",
      "Evaluation/MinReturn                  -1520.32\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      9.39456\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.95066\n",
      "GaussianMLPPolicy/KL                      0.00922679\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              43.2174\n",
      "GaussianMLPPolicy/LossBefore             44.6208\n",
      "GaussianMLPPolicy/dLoss                   1.40339\n",
      "GaussianMLPValueFunction/LossAfter        6.641\n",
      "GaussianMLPValueFunction/LossBefore       6.68542\n",
      "GaussianMLPValueFunction/dLoss            0.0444212\n",
      "TotalEnvSteps                        934800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:00 | [trpo_pendulum] epoch #779 | Saving snapshot...\n",
      "2022-08-17 18:13:00 | [trpo_pendulum] epoch #779 | Saved\n",
      "2022-08-17 18:13:00 | [trpo_pendulum] epoch #779 | Time 495.84 s\n",
      "2022-08-17 18:13:00 | [trpo_pendulum] epoch #779 | EpochTime 0.63 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -637.801\n",
      "Evaluation/AverageReturn              -1521.49\n",
      "Evaluation/Iteration                    779\n",
      "Evaluation/MaxReturn                  -1507.91\n",
      "Evaluation/MinReturn                  -1540.91\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     10.6493\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.91297\n",
      "GaussianMLPPolicy/KL                      0.00759058\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              19.3996\n",
      "GaussianMLPPolicy/LossBefore             19.8755\n",
      "GaussianMLPPolicy/dLoss                   0.475904\n",
      "GaussianMLPValueFunction/LossAfter        6.68145\n",
      "GaussianMLPValueFunction/LossBefore       6.68235\n",
      "GaussianMLPValueFunction/dLoss            0.000895023\n",
      "TotalEnvSteps                        936000\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:13:00 | [trpo_pendulum] epoch #780 | Saving snapshot...\n",
      "2022-08-17 18:13:00 | [trpo_pendulum] epoch #780 | Saved\n",
      "2022-08-17 18:13:00 | [trpo_pendulum] epoch #780 | Time 496.51 s\n",
      "2022-08-17 18:13:00 | [trpo_pendulum] epoch #780 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -582.969\n",
      "Evaluation/AverageReturn              -1459.56\n",
      "Evaluation/Iteration                    780\n",
      "Evaluation/MaxReturn                  -1361.67\n",
      "Evaluation/MinReturn                  -1503.65\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     45.6753\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.8982\n",
      "GaussianMLPPolicy/KL                      0.00711423\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              13.0475\n",
      "GaussianMLPPolicy/LossBefore             14.4167\n",
      "GaussianMLPPolicy/dLoss                   1.36919\n",
      "GaussianMLPValueFunction/LossAfter        6.5745\n",
      "GaussianMLPValueFunction/LossBefore       6.5838\n",
      "GaussianMLPValueFunction/dLoss            0.0092988\n",
      "TotalEnvSteps                        937200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:01 | [trpo_pendulum] epoch #781 | Saving snapshot...\n",
      "2022-08-17 18:13:01 | [trpo_pendulum] epoch #781 | Saved\n",
      "2022-08-17 18:13:01 | [trpo_pendulum] epoch #781 | Time 497.14 s\n",
      "2022-08-17 18:13:01 | [trpo_pendulum] epoch #781 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -662.49\n",
      "Evaluation/AverageReturn              -1550.19\n",
      "Evaluation/Iteration                    781\n",
      "Evaluation/MaxReturn                  -1524.46\n",
      "Evaluation/MinReturn                  -1573.71\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     17.9635\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.89683\n",
      "GaussianMLPPolicy/KL                      0.00776384\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              20.1911\n",
      "GaussianMLPPolicy/LossBefore             21.1184\n",
      "GaussianMLPPolicy/dLoss                   0.927322\n",
      "GaussianMLPValueFunction/LossAfter        6.67809\n",
      "GaussianMLPValueFunction/LossBefore       6.67974\n",
      "GaussianMLPValueFunction/dLoss            0.00164843\n",
      "TotalEnvSteps                        938400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:01 | [trpo_pendulum] epoch #782 | Saving snapshot...\n",
      "2022-08-17 18:13:01 | [trpo_pendulum] epoch #782 | Saved\n",
      "2022-08-17 18:13:01 | [trpo_pendulum] epoch #782 | Time 497.76 s\n",
      "2022-08-17 18:13:01 | [trpo_pendulum] epoch #782 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -624.004\n",
      "Evaluation/AverageReturn              -1510.59\n",
      "Evaluation/Iteration                    782\n",
      "Evaluation/MaxReturn                  -1495.76\n",
      "Evaluation/MinReturn                  -1534.2\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     11.8256\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.8842\n",
      "GaussianMLPPolicy/KL                      0.00981336\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              18.1438\n",
      "GaussianMLPPolicy/LossBefore             20.0911\n",
      "GaussianMLPPolicy/dLoss                   1.94732\n",
      "GaussianMLPValueFunction/LossAfter        6.66996\n",
      "GaussianMLPValueFunction/LossBefore       6.67035\n",
      "GaussianMLPValueFunction/dLoss            0.0003829\n",
      "TotalEnvSteps                        939600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:02 | [trpo_pendulum] epoch #783 | Saving snapshot...\n",
      "2022-08-17 18:13:02 | [trpo_pendulum] epoch #783 | Saved\n",
      "2022-08-17 18:13:02 | [trpo_pendulum] epoch #783 | Time 498.38 s\n",
      "2022-08-17 18:13:02 | [trpo_pendulum] epoch #783 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -603.683\n",
      "Evaluation/AverageReturn              -1464.78\n",
      "Evaluation/Iteration                    783\n",
      "Evaluation/MaxReturn                  -1408.42\n",
      "Evaluation/MinReturn                  -1499.7\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     33.9758\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.88246\n",
      "GaussianMLPPolicy/KL                      0.00692072\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              28.6398\n",
      "GaussianMLPPolicy/LossBefore             30.2476\n",
      "GaussianMLPPolicy/dLoss                   1.60775\n",
      "GaussianMLPValueFunction/LossAfter        6.59118\n",
      "GaussianMLPValueFunction/LossBefore       6.60105\n",
      "GaussianMLPValueFunction/dLoss            0.00987577\n",
      "TotalEnvSteps                        940800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:03 | [trpo_pendulum] epoch #784 | Saving snapshot...\n",
      "2022-08-17 18:13:03 | [trpo_pendulum] epoch #784 | Saved\n",
      "2022-08-17 18:13:03 | [trpo_pendulum] epoch #784 | Time 499.00 s\n",
      "2022-08-17 18:13:03 | [trpo_pendulum] epoch #784 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -641.507\n",
      "Evaluation/AverageReturn              -1524.72\n",
      "Evaluation/Iteration                    784\n",
      "Evaluation/MaxReturn                  -1515.12\n",
      "Evaluation/MinReturn                  -1531.96\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      6.56839\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.91776\n",
      "GaussianMLPPolicy/KL                      0.00958536\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              17.9151\n",
      "GaussianMLPPolicy/LossBefore             19.236\n",
      "GaussianMLPPolicy/dLoss                   1.32092\n",
      "GaussianMLPValueFunction/LossAfter        6.68523\n",
      "GaussianMLPValueFunction/LossBefore       6.68724\n",
      "GaussianMLPValueFunction/dLoss            0.00201082\n",
      "TotalEnvSteps                        942000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:03 | [trpo_pendulum] epoch #785 | Saving snapshot...\n",
      "2022-08-17 18:13:03 | [trpo_pendulum] epoch #785 | Saved\n",
      "2022-08-17 18:13:03 | [trpo_pendulum] epoch #785 | Time 499.65 s\n",
      "2022-08-17 18:13:03 | [trpo_pendulum] epoch #785 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -599.61\n",
      "Evaluation/AverageReturn              -1483.87\n",
      "Evaluation/Iteration                    785\n",
      "Evaluation/MaxReturn                  -1461.94\n",
      "Evaluation/MinReturn                  -1499.59\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     12.0534\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.91064\n",
      "GaussianMLPPolicy/KL                      0.00706207\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              19.7836\n",
      "GaussianMLPPolicy/LossBefore             21.12\n",
      "GaussianMLPPolicy/dLoss                   1.33638\n",
      "GaussianMLPValueFunction/LossAfter        6.60091\n",
      "GaussianMLPValueFunction/LossBefore       6.60328\n",
      "GaussianMLPValueFunction/dLoss            0.00236607\n",
      "TotalEnvSteps                        943200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:04 | [trpo_pendulum] epoch #786 | Saving snapshot...\n",
      "2022-08-17 18:13:04 | [trpo_pendulum] epoch #786 | Saved\n",
      "2022-08-17 18:13:04 | [trpo_pendulum] epoch #786 | Time 500.29 s\n",
      "2022-08-17 18:13:04 | [trpo_pendulum] epoch #786 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -608.116\n",
      "Evaluation/AverageReturn              -1487.05\n",
      "Evaluation/Iteration                    786\n",
      "Evaluation/MaxReturn                  -1450.28\n",
      "Evaluation/MinReturn                  -1541.24\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     30.8925\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.9202\n",
      "GaussianMLPPolicy/KL                      0.00646608\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              16.3903\n",
      "GaussianMLPPolicy/LossBefore             18.2482\n",
      "GaussianMLPPolicy/dLoss                   1.85795\n",
      "GaussianMLPValueFunction/LossAfter        6.59218\n",
      "GaussianMLPValueFunction/LossBefore       6.59479\n",
      "GaussianMLPValueFunction/dLoss            0.00261021\n",
      "TotalEnvSteps                        944400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:05 | [trpo_pendulum] epoch #787 | Saving snapshot...\n",
      "2022-08-17 18:13:05 | [trpo_pendulum] epoch #787 | Saved\n",
      "2022-08-17 18:13:05 | [trpo_pendulum] epoch #787 | Time 500.91 s\n",
      "2022-08-17 18:13:05 | [trpo_pendulum] epoch #787 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -667.976\n",
      "Evaluation/AverageReturn              -1561.05\n",
      "Evaluation/Iteration                    787\n",
      "Evaluation/MaxReturn                  -1529.03\n",
      "Evaluation/MinReturn                  -1609.63\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     28.195\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.93014\n",
      "GaussianMLPPolicy/KL                      0.00510821\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              21.0524\n",
      "GaussianMLPPolicy/LossBefore             21.248\n",
      "GaussianMLPPolicy/dLoss                   0.195616\n",
      "GaussianMLPValueFunction/LossAfter        6.6765\n",
      "GaussianMLPValueFunction/LossBefore       6.67908\n",
      "GaussianMLPValueFunction/dLoss            0.00258064\n",
      "TotalEnvSteps                        945600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:05 | [trpo_pendulum] epoch #788 | Saving snapshot...\n",
      "2022-08-17 18:13:05 | [trpo_pendulum] epoch #788 | Saved\n",
      "2022-08-17 18:13:05 | [trpo_pendulum] epoch #788 | Time 501.54 s\n",
      "2022-08-17 18:13:05 | [trpo_pendulum] epoch #788 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -675.197\n",
      "Evaluation/AverageReturn              -1621.11\n",
      "Evaluation/Iteration                    788\n",
      "Evaluation/MaxReturn                  -1608.32\n",
      "Evaluation/MinReturn                  -1636.61\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     11.4137\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.95104\n",
      "GaussianMLPPolicy/KL                      0.00718103\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              58.0494\n",
      "GaussianMLPPolicy/LossBefore             59.0351\n",
      "GaussianMLPPolicy/dLoss                   0.985767\n",
      "GaussianMLPValueFunction/LossAfter        6.71066\n",
      "GaussianMLPValueFunction/LossBefore       6.81371\n",
      "GaussianMLPValueFunction/dLoss            0.103053\n",
      "TotalEnvSteps                        946800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:06 | [trpo_pendulum] epoch #789 | Saving snapshot...\n",
      "2022-08-17 18:13:06 | [trpo_pendulum] epoch #789 | Saved\n",
      "2022-08-17 18:13:06 | [trpo_pendulum] epoch #789 | Time 502.20 s\n",
      "2022-08-17 18:13:06 | [trpo_pendulum] epoch #789 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -635.434\n",
      "Evaluation/AverageReturn              -1509.88\n",
      "Evaluation/Iteration                    789\n",
      "Evaluation/MaxReturn                  -1450.08\n",
      "Evaluation/MinReturn                  -1554.28\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     35.0995\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.96943\n",
      "GaussianMLPPolicy/KL                      0.00716005\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              11.8789\n",
      "GaussianMLPPolicy/LossBefore             14.4832\n",
      "GaussianMLPPolicy/dLoss                   2.60427\n",
      "GaussianMLPValueFunction/LossAfter        6.62357\n",
      "GaussianMLPValueFunction/LossBefore       6.62659\n",
      "GaussianMLPValueFunction/dLoss            0.00302887\n",
      "TotalEnvSteps                        948000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:07 | [trpo_pendulum] epoch #790 | Saving snapshot...\n",
      "2022-08-17 18:13:07 | [trpo_pendulum] epoch #790 | Saved\n",
      "2022-08-17 18:13:07 | [trpo_pendulum] epoch #790 | Time 502.81 s\n",
      "2022-08-17 18:13:07 | [trpo_pendulum] epoch #790 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -683.922\n",
      "Evaluation/AverageReturn              -1635.37\n",
      "Evaluation/Iteration                    790\n",
      "Evaluation/MaxReturn                  -1630.66\n",
      "Evaluation/MinReturn                  -1640.3\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      3.89468\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.99345\n",
      "GaussianMLPPolicy/KL                      0.00500266\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              35.0701\n",
      "GaussianMLPPolicy/LossBefore             35.9884\n",
      "GaussianMLPPolicy/dLoss                   0.918316\n",
      "GaussianMLPValueFunction/LossAfter        6.70978\n",
      "GaussianMLPValueFunction/LossBefore       6.7151\n",
      "GaussianMLPValueFunction/dLoss            0.00531864\n",
      "TotalEnvSteps                        949200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:07 | [trpo_pendulum] epoch #791 | Saving snapshot...\n",
      "2022-08-17 18:13:07 | [trpo_pendulum] epoch #791 | Saved\n",
      "2022-08-17 18:13:07 | [trpo_pendulum] epoch #791 | Time 503.42 s\n",
      "2022-08-17 18:13:07 | [trpo_pendulum] epoch #791 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -600.962\n",
      "Evaluation/AverageReturn              -1488.71\n",
      "Evaluation/Iteration                    791\n",
      "Evaluation/MaxReturn                  -1345.23\n",
      "Evaluation/MinReturn                  -1523.19\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     64.2674\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.9806\n",
      "GaussianMLPPolicy/KL                      0.0096943\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              13.824\n",
      "GaussianMLPPolicy/LossBefore             15.6592\n",
      "GaussianMLPPolicy/dLoss                   1.83516\n",
      "GaussianMLPValueFunction/LossAfter        6.64776\n",
      "GaussianMLPValueFunction/LossBefore       6.65087\n",
      "GaussianMLPValueFunction/dLoss            0.00310612\n",
      "TotalEnvSteps                        950400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:08 | [trpo_pendulum] epoch #792 | Saving snapshot...\n",
      "2022-08-17 18:13:08 | [trpo_pendulum] epoch #792 | Saved\n",
      "2022-08-17 18:13:08 | [trpo_pendulum] epoch #792 | Time 504.04 s\n",
      "2022-08-17 18:13:08 | [trpo_pendulum] epoch #792 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -571.681\n",
      "Evaluation/AverageReturn              -1387.71\n",
      "Evaluation/Iteration                    792\n",
      "Evaluation/MaxReturn                  -1348.28\n",
      "Evaluation/MinReturn                  -1432.55\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     28.5654\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.97095\n",
      "GaussianMLPPolicy/KL                      0.00564323\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.00842\n",
      "GaussianMLPPolicy/LossBefore             -1.73101\n",
      "GaussianMLPPolicy/dLoss                   1.2774\n",
      "GaussianMLPValueFunction/LossAfter        6.59454\n",
      "GaussianMLPValueFunction/LossBefore       6.59991\n",
      "GaussianMLPValueFunction/dLoss            0.00536919\n",
      "TotalEnvSteps                        951600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:08 | [trpo_pendulum] epoch #793 | Saving snapshot...\n",
      "2022-08-17 18:13:08 | [trpo_pendulum] epoch #793 | Saved\n",
      "2022-08-17 18:13:08 | [trpo_pendulum] epoch #793 | Time 504.65 s\n",
      "2022-08-17 18:13:08 | [trpo_pendulum] epoch #793 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -582.348\n",
      "Evaluation/AverageReturn              -1447.24\n",
      "Evaluation/Iteration                    793\n",
      "Evaluation/MaxReturn                  -1331.08\n",
      "Evaluation/MinReturn                  -1534.42\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     68.4593\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.9613\n",
      "GaussianMLPPolicy/KL                      0.00913147\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               9.1804\n",
      "GaussianMLPPolicy/LossBefore             10.598\n",
      "GaussianMLPPolicy/dLoss                   1.41761\n",
      "GaussianMLPValueFunction/LossAfter        6.59469\n",
      "GaussianMLPValueFunction/LossBefore       6.59765\n",
      "GaussianMLPValueFunction/dLoss            0.00296211\n",
      "TotalEnvSteps                        952800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:09 | [trpo_pendulum] epoch #794 | Saving snapshot...\n",
      "2022-08-17 18:13:09 | [trpo_pendulum] epoch #794 | Saved\n",
      "2022-08-17 18:13:09 | [trpo_pendulum] epoch #794 | Time 505.27 s\n",
      "2022-08-17 18:13:09 | [trpo_pendulum] epoch #794 | EpochTime 0.61 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -656.935\n",
      "Evaluation/AverageReturn              -1510.35\n",
      "Evaluation/Iteration                    794\n",
      "Evaluation/MaxReturn                  -1502.28\n",
      "Evaluation/MinReturn                  -1524.35\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      7.13284\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.95945\n",
      "GaussianMLPPolicy/KL                      0.0077571\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               9.88854\n",
      "GaussianMLPPolicy/LossBefore             11.1569\n",
      "GaussianMLPPolicy/dLoss                   1.26838\n",
      "GaussianMLPValueFunction/LossAfter        6.62506\n",
      "GaussianMLPValueFunction/LossBefore       6.62561\n",
      "GaussianMLPValueFunction/dLoss            0.000549316\n",
      "TotalEnvSteps                        954000\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:13:10 | [trpo_pendulum] epoch #795 | Saving snapshot...\n",
      "2022-08-17 18:13:10 | [trpo_pendulum] epoch #795 | Saved\n",
      "2022-08-17 18:13:10 | [trpo_pendulum] epoch #795 | Time 505.92 s\n",
      "2022-08-17 18:13:10 | [trpo_pendulum] epoch #795 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -609.143\n",
      "Evaluation/AverageReturn              -1489.77\n",
      "Evaluation/Iteration                    795\n",
      "Evaluation/MaxReturn                  -1439.64\n",
      "Evaluation/MinReturn                  -1521.6\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     25.4446\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.96701\n",
      "GaussianMLPPolicy/KL                      0.00458531\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              17.2266\n",
      "GaussianMLPPolicy/LossBefore             17.3915\n",
      "GaussianMLPPolicy/dLoss                   0.164907\n",
      "GaussianMLPValueFunction/LossAfter        6.63557\n",
      "GaussianMLPValueFunction/LossBefore       6.63574\n",
      "GaussianMLPValueFunction/dLoss            0.0001688\n",
      "TotalEnvSteps                        955200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:10 | [trpo_pendulum] epoch #796 | Saving snapshot...\n",
      "2022-08-17 18:13:10 | [trpo_pendulum] epoch #796 | Saved\n",
      "2022-08-17 18:13:10 | [trpo_pendulum] epoch #796 | Time 506.53 s\n",
      "2022-08-17 18:13:10 | [trpo_pendulum] epoch #796 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -688.922\n",
      "Evaluation/AverageReturn              -1600.63\n",
      "Evaluation/Iteration                    796\n",
      "Evaluation/MaxReturn                  -1374.99\n",
      "Evaluation/MinReturn                  -1713.74\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    114.11\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.94052\n",
      "GaussianMLPPolicy/KL                      0.00981774\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              24.3894\n",
      "GaussianMLPPolicy/LossBefore             27.0791\n",
      "GaussianMLPPolicy/dLoss                   2.6897\n",
      "GaussianMLPValueFunction/LossAfter        6.77199\n",
      "GaussianMLPValueFunction/LossBefore       6.78673\n",
      "GaussianMLPValueFunction/dLoss            0.0147452\n",
      "TotalEnvSteps                        956400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:11 | [trpo_pendulum] epoch #797 | Saving snapshot...\n",
      "2022-08-17 18:13:11 | [trpo_pendulum] epoch #797 | Saved\n",
      "2022-08-17 18:13:11 | [trpo_pendulum] epoch #797 | Time 507.17 s\n",
      "2022-08-17 18:13:11 | [trpo_pendulum] epoch #797 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -729.08\n",
      "Evaluation/AverageReturn              -1693.87\n",
      "Evaluation/Iteration                    797\n",
      "Evaluation/MaxReturn                  -1534.42\n",
      "Evaluation/MinReturn                  -1756.51\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     74.227\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.95119\n",
      "GaussianMLPPolicy/KL                      0.00784378\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              37.2529\n",
      "GaussianMLPPolicy/LossBefore             39.6219\n",
      "GaussianMLPPolicy/dLoss                   2.36898\n",
      "GaussianMLPValueFunction/LossAfter        6.79614\n",
      "GaussianMLPValueFunction/LossBefore       6.80571\n",
      "GaussianMLPValueFunction/dLoss            0.00956821\n",
      "TotalEnvSteps                        957600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:12 | [trpo_pendulum] epoch #798 | Saving snapshot...\n",
      "2022-08-17 18:13:12 | [trpo_pendulum] epoch #798 | Saved\n",
      "2022-08-17 18:13:12 | [trpo_pendulum] epoch #798 | Time 507.80 s\n",
      "2022-08-17 18:13:12 | [trpo_pendulum] epoch #798 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -647\n",
      "Evaluation/AverageReturn              -1536.79\n",
      "Evaluation/Iteration                    798\n",
      "Evaluation/MaxReturn                  -1506.38\n",
      "Evaluation/MinReturn                  -1562.32\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     19.4848\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.94395\n",
      "GaussianMLPPolicy/KL                      0.00570542\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              19.9528\n",
      "GaussianMLPPolicy/LossBefore             20.024\n",
      "GaussianMLPPolicy/dLoss                   0.0712013\n",
      "GaussianMLPValueFunction/LossAfter        6.68388\n",
      "GaussianMLPValueFunction/LossBefore       6.68524\n",
      "GaussianMLPValueFunction/dLoss            0.00136137\n",
      "TotalEnvSteps                        958800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:12 | [trpo_pendulum] epoch #799 | Saving snapshot...\n",
      "2022-08-17 18:13:12 | [trpo_pendulum] epoch #799 | Saved\n",
      "2022-08-17 18:13:12 | [trpo_pendulum] epoch #799 | Time 508.43 s\n",
      "2022-08-17 18:13:12 | [trpo_pendulum] epoch #799 | EpochTime 0.63 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -646.534\n",
      "Evaluation/AverageReturn              -1531.65\n",
      "Evaluation/Iteration                    799\n",
      "Evaluation/MaxReturn                  -1513.76\n",
      "Evaluation/MinReturn                  -1552.84\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     11.9838\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.93654\n",
      "GaussianMLPPolicy/KL                      0.0060613\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              17.6413\n",
      "GaussianMLPPolicy/LossBefore             18.7204\n",
      "GaussianMLPPolicy/dLoss                   1.07908\n",
      "GaussianMLPValueFunction/LossAfter        6.68188\n",
      "GaussianMLPValueFunction/LossBefore       6.68257\n",
      "GaussianMLPValueFunction/dLoss            0.000693321\n",
      "TotalEnvSteps                        960000\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:13:13 | [trpo_pendulum] epoch #800 | Saving snapshot...\n",
      "2022-08-17 18:13:13 | [trpo_pendulum] epoch #800 | Saved\n",
      "2022-08-17 18:13:13 | [trpo_pendulum] epoch #800 | Time 509.07 s\n",
      "2022-08-17 18:13:13 | [trpo_pendulum] epoch #800 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -675.419\n",
      "Evaluation/AverageReturn              -1627.21\n",
      "Evaluation/Iteration                    800\n",
      "Evaluation/MaxReturn                  -1617.2\n",
      "Evaluation/MinReturn                  -1635.11\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      6.44945\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.94807\n",
      "GaussianMLPPolicy/KL                      0.00780639\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              40.6906\n",
      "GaussianMLPPolicy/LossBefore             41.2402\n",
      "GaussianMLPPolicy/dLoss                   0.549637\n",
      "GaussianMLPValueFunction/LossAfter        6.70091\n",
      "GaussianMLPValueFunction/LossBefore       6.7109\n",
      "GaussianMLPValueFunction/dLoss            0.00998306\n",
      "TotalEnvSteps                        961200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:13 | [trpo_pendulum] epoch #801 | Saving snapshot...\n",
      "2022-08-17 18:13:13 | [trpo_pendulum] epoch #801 | Saved\n",
      "2022-08-17 18:13:13 | [trpo_pendulum] epoch #801 | Time 509.70 s\n",
      "2022-08-17 18:13:13 | [trpo_pendulum] epoch #801 | EpochTime 0.62 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -646.14\n",
      "Evaluation/AverageReturn              -1585.76\n",
      "Evaluation/Iteration                    801\n",
      "Evaluation/MaxReturn                  -1574.3\n",
      "Evaluation/MinReturn                  -1596.2\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      8.10824\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.99895\n",
      "GaussianMLPPolicy/KL                      0.00737669\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              29.3057\n",
      "GaussianMLPPolicy/LossBefore             31.1497\n",
      "GaussianMLPPolicy/dLoss                   1.84403\n",
      "GaussianMLPValueFunction/LossAfter        6.71833\n",
      "GaussianMLPValueFunction/LossBefore       6.71923\n",
      "GaussianMLPValueFunction/dLoss            0.000902176\n",
      "TotalEnvSteps                        962400\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:13:14 | [trpo_pendulum] epoch #802 | Saving snapshot...\n",
      "2022-08-17 18:13:14 | [trpo_pendulum] epoch #802 | Saved\n",
      "2022-08-17 18:13:14 | [trpo_pendulum] epoch #802 | Time 510.33 s\n",
      "2022-08-17 18:13:14 | [trpo_pendulum] epoch #802 | EpochTime 0.62 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -593.566\n",
      "Evaluation/AverageReturn              -1514.68\n",
      "Evaluation/Iteration                    802\n",
      "Evaluation/MaxReturn                  -1483.18\n",
      "Evaluation/MinReturn                  -1524.68\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     14.337\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.01711\n",
      "GaussianMLPPolicy/KL                      0.00817464\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              23.4371\n",
      "GaussianMLPPolicy/LossBefore             24.1313\n",
      "GaussianMLPPolicy/dLoss                   0.694187\n",
      "GaussianMLPValueFunction/LossAfter        6.68553\n",
      "GaussianMLPValueFunction/LossBefore       6.68605\n",
      "GaussianMLPValueFunction/dLoss            0.000516891\n",
      "TotalEnvSteps                        963600\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:13:15 | [trpo_pendulum] epoch #803 | Saving snapshot...\n",
      "2022-08-17 18:13:15 | [trpo_pendulum] epoch #803 | Saved\n",
      "2022-08-17 18:13:15 | [trpo_pendulum] epoch #803 | Time 510.95 s\n",
      "2022-08-17 18:13:15 | [trpo_pendulum] epoch #803 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -654.9\n",
      "Evaluation/AverageReturn              -1507.78\n",
      "Evaluation/Iteration                    803\n",
      "Evaluation/MaxReturn                  -1500.2\n",
      "Evaluation/MinReturn                  -1513.53\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      4.3642\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.00714\n",
      "GaussianMLPPolicy/KL                      0.00957403\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               7.73175\n",
      "GaussianMLPPolicy/LossBefore              9.25914\n",
      "GaussianMLPPolicy/dLoss                   1.52739\n",
      "GaussianMLPValueFunction/LossAfter        6.62851\n",
      "GaussianMLPValueFunction/LossBefore       6.63243\n",
      "GaussianMLPValueFunction/dLoss            0.00391388\n",
      "TotalEnvSteps                        964800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:15 | [trpo_pendulum] epoch #804 | Saving snapshot...\n",
      "2022-08-17 18:13:15 | [trpo_pendulum] epoch #804 | Saved\n",
      "2022-08-17 18:13:15 | [trpo_pendulum] epoch #804 | Time 511.57 s\n",
      "2022-08-17 18:13:15 | [trpo_pendulum] epoch #804 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -655.328\n",
      "Evaluation/AverageReturn              -1581.69\n",
      "Evaluation/Iteration                    804\n",
      "Evaluation/MaxReturn                  -1455.89\n",
      "Evaluation/MinReturn                  -1726.1\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     90.6903\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.99184\n",
      "GaussianMLPPolicy/KL                      0.00714193\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              23.0815\n",
      "GaussianMLPPolicy/LossBefore             25.2884\n",
      "GaussianMLPPolicy/dLoss                   2.20694\n",
      "GaussianMLPValueFunction/LossAfter        6.67869\n",
      "GaussianMLPValueFunction/LossBefore       6.68857\n",
      "GaussianMLPValueFunction/dLoss            0.00988245\n",
      "TotalEnvSteps                        966000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:16 | [trpo_pendulum] epoch #805 | Saving snapshot...\n",
      "2022-08-17 18:13:16 | [trpo_pendulum] epoch #805 | Saved\n",
      "2022-08-17 18:13:16 | [trpo_pendulum] epoch #805 | Time 512.23 s\n",
      "2022-08-17 18:13:16 | [trpo_pendulum] epoch #805 | EpochTime 0.66 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -664.415\n",
      "Evaluation/AverageReturn              -1581.56\n",
      "Evaluation/Iteration                    805\n",
      "Evaluation/MaxReturn                  -1557.31\n",
      "Evaluation/MinReturn                  -1619.72\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     20.412\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.00079\n",
      "GaussianMLPPolicy/KL                      0.00974083\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              24.0163\n",
      "GaussianMLPPolicy/LossBefore             24.4924\n",
      "GaussianMLPPolicy/dLoss                   0.476004\n",
      "GaussianMLPValueFunction/LossAfter        6.68867\n",
      "GaussianMLPValueFunction/LossBefore       6.68891\n",
      "GaussianMLPValueFunction/dLoss            0.000244141\n",
      "TotalEnvSteps                        967200\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:13:17 | [trpo_pendulum] epoch #806 | Saving snapshot...\n",
      "2022-08-17 18:13:17 | [trpo_pendulum] epoch #806 | Saved\n",
      "2022-08-17 18:13:17 | [trpo_pendulum] epoch #806 | Time 512.86 s\n",
      "2022-08-17 18:13:17 | [trpo_pendulum] epoch #806 | EpochTime 0.62 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -626.476\n",
      "Evaluation/AverageReturn              -1513.86\n",
      "Evaluation/Iteration                    806\n",
      "Evaluation/MaxReturn                  -1496.19\n",
      "Evaluation/MinReturn                  -1543.29\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     15.1276\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.99443\n",
      "GaussianMLPPolicy/KL                      0.00693617\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              16.3456\n",
      "GaussianMLPPolicy/LossBefore             17.0064\n",
      "GaussianMLPPolicy/dLoss                   0.660851\n",
      "GaussianMLPValueFunction/LossAfter        6.66451\n",
      "GaussianMLPValueFunction/LossBefore       6.66476\n",
      "GaussianMLPValueFunction/dLoss            0.000248432\n",
      "TotalEnvSteps                        968400\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:13:17 | [trpo_pendulum] epoch #807 | Saving snapshot...\n",
      "2022-08-17 18:13:17 | [trpo_pendulum] epoch #807 | Saved\n",
      "2022-08-17 18:13:17 | [trpo_pendulum] epoch #807 | Time 513.48 s\n",
      "2022-08-17 18:13:17 | [trpo_pendulum] epoch #807 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -607.093\n",
      "Evaluation/AverageReturn              -1522.12\n",
      "Evaluation/Iteration                    807\n",
      "Evaluation/MaxReturn                  -1513.55\n",
      "Evaluation/MinReturn                  -1527.16\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      4.33453\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.01427\n",
      "GaussianMLPPolicy/KL                      0.00844478\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              38.5043\n",
      "GaussianMLPPolicy/LossBefore             39.1306\n",
      "GaussianMLPPolicy/dLoss                   0.62635\n",
      "GaussianMLPValueFunction/LossAfter        6.65673\n",
      "GaussianMLPValueFunction/LossBefore       6.6724\n",
      "GaussianMLPValueFunction/dLoss            0.0156674\n",
      "TotalEnvSteps                        969600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:18 | [trpo_pendulum] epoch #808 | Saving snapshot...\n",
      "2022-08-17 18:13:18 | [trpo_pendulum] epoch #808 | Saved\n",
      "2022-08-17 18:13:18 | [trpo_pendulum] epoch #808 | Time 514.14 s\n",
      "2022-08-17 18:13:18 | [trpo_pendulum] epoch #808 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -629.231\n",
      "Evaluation/AverageReturn              -1522.61\n",
      "Evaluation/Iteration                    808\n",
      "Evaluation/MaxReturn                  -1400.57\n",
      "Evaluation/MinReturn                  -1656.8\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     79.3398\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.99309\n",
      "GaussianMLPPolicy/KL                      0.00791708\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              14.6114\n",
      "GaussianMLPPolicy/LossBefore             16.7753\n",
      "GaussianMLPPolicy/dLoss                   2.1639\n",
      "GaussianMLPValueFunction/LossAfter        6.6454\n",
      "GaussianMLPValueFunction/LossBefore       6.64645\n",
      "GaussianMLPValueFunction/dLoss            0.00104475\n",
      "TotalEnvSteps                        970800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:18 | [trpo_pendulum] epoch #809 | Saving snapshot...\n",
      "2022-08-17 18:13:18 | [trpo_pendulum] epoch #809 | Saved\n",
      "2022-08-17 18:13:18 | [trpo_pendulum] epoch #809 | Time 514.77 s\n",
      "2022-08-17 18:13:18 | [trpo_pendulum] epoch #809 | EpochTime 0.63 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -625.141\n",
      "Evaluation/AverageReturn              -1531.54\n",
      "Evaluation/Iteration                    809\n",
      "Evaluation/MaxReturn                  -1489.59\n",
      "Evaluation/MinReturn                  -1551.72\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     21.1442\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.99057\n",
      "GaussianMLPPolicy/KL                      0.00705234\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              18.1111\n",
      "GaussianMLPPolicy/LossBefore             19.0217\n",
      "GaussianMLPPolicy/dLoss                   0.910629\n",
      "GaussianMLPValueFunction/LossAfter        6.66309\n",
      "GaussianMLPValueFunction/LossBefore       6.66312\n",
      "GaussianMLPValueFunction/dLoss            3.67165e-05\n",
      "TotalEnvSteps                        972000\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:13:19 | [trpo_pendulum] epoch #810 | Saving snapshot...\n",
      "2022-08-17 18:13:19 | [trpo_pendulum] epoch #810 | Saved\n",
      "2022-08-17 18:13:19 | [trpo_pendulum] epoch #810 | Time 515.43 s\n",
      "2022-08-17 18:13:19 | [trpo_pendulum] epoch #810 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -604.894\n",
      "Evaluation/AverageReturn              -1514.01\n",
      "Evaluation/Iteration                    810\n",
      "Evaluation/MaxReturn                  -1493.12\n",
      "Evaluation/MinReturn                  -1538.79\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     14.2494\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.97005\n",
      "GaussianMLPPolicy/KL                      0.00640627\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              19.3314\n",
      "GaussianMLPPolicy/LossBefore             20.843\n",
      "GaussianMLPPolicy/dLoss                   1.51158\n",
      "GaussianMLPValueFunction/LossAfter        6.64954\n",
      "GaussianMLPValueFunction/LossBefore       6.65115\n",
      "GaussianMLPValueFunction/dLoss            0.00160837\n",
      "TotalEnvSteps                        973200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:20 | [trpo_pendulum] epoch #811 | Saving snapshot...\n",
      "2022-08-17 18:13:20 | [trpo_pendulum] epoch #811 | Saved\n",
      "2022-08-17 18:13:20 | [trpo_pendulum] epoch #811 | Time 516.08 s\n",
      "2022-08-17 18:13:20 | [trpo_pendulum] epoch #811 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -616.611\n",
      "Evaluation/AverageReturn              -1533.13\n",
      "Evaluation/Iteration                    811\n",
      "Evaluation/MaxReturn                  -1521.48\n",
      "Evaluation/MinReturn                  -1539.88\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      6.43121\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.97188\n",
      "GaussianMLPPolicy/KL                      0.00967101\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              22.4382\n",
      "GaussianMLPPolicy/LossBefore             22.9616\n",
      "GaussianMLPPolicy/dLoss                   0.523405\n",
      "GaussianMLPValueFunction/LossAfter        6.70627\n",
      "GaussianMLPValueFunction/LossBefore       6.70826\n",
      "GaussianMLPValueFunction/dLoss            0.00198793\n",
      "TotalEnvSteps                        974400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:20 | [trpo_pendulum] epoch #812 | Saving snapshot...\n",
      "2022-08-17 18:13:20 | [trpo_pendulum] epoch #812 | Saved\n",
      "2022-08-17 18:13:20 | [trpo_pendulum] epoch #812 | Time 516.74 s\n",
      "2022-08-17 18:13:20 | [trpo_pendulum] epoch #812 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -655.393\n",
      "Evaluation/AverageReturn              -1598.6\n",
      "Evaluation/Iteration                    812\n",
      "Evaluation/MaxReturn                  -1585.64\n",
      "Evaluation/MinReturn                  -1612.21\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      9.26289\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.99247\n",
      "GaussianMLPPolicy/KL                      0.00684272\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              36.5193\n",
      "GaussianMLPPolicy/LossBefore             37.3495\n",
      "GaussianMLPPolicy/dLoss                   0.830219\n",
      "GaussianMLPValueFunction/LossAfter        6.70099\n",
      "GaussianMLPValueFunction/LossBefore       6.70684\n",
      "GaussianMLPValueFunction/dLoss            0.00584984\n",
      "TotalEnvSteps                        975600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:21 | [trpo_pendulum] epoch #813 | Saving snapshot...\n",
      "2022-08-17 18:13:21 | [trpo_pendulum] epoch #813 | Saved\n",
      "2022-08-17 18:13:21 | [trpo_pendulum] epoch #813 | Time 517.35 s\n",
      "2022-08-17 18:13:21 | [trpo_pendulum] epoch #813 | EpochTime 0.61 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -637.011\n",
      "Evaluation/AverageReturn              -1550.8\n",
      "Evaluation/Iteration                    813\n",
      "Evaluation/MaxReturn                  -1534.32\n",
      "Evaluation/MinReturn                  -1563.77\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      9.74563\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.01335\n",
      "GaussianMLPPolicy/KL                      0.00973114\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              20.5227\n",
      "GaussianMLPPolicy/LossBefore             22.2616\n",
      "GaussianMLPPolicy/dLoss                   1.73891\n",
      "GaussianMLPValueFunction/LossAfter        6.71424\n",
      "GaussianMLPValueFunction/LossBefore       6.71468\n",
      "GaussianMLPValueFunction/dLoss            0.000443459\n",
      "TotalEnvSteps                        976800\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:13:22 | [trpo_pendulum] epoch #814 | Saving snapshot...\n",
      "2022-08-17 18:13:22 | [trpo_pendulum] epoch #814 | Saved\n",
      "2022-08-17 18:13:22 | [trpo_pendulum] epoch #814 | Time 517.96 s\n",
      "2022-08-17 18:13:22 | [trpo_pendulum] epoch #814 | EpochTime 0.61 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -666.452\n",
      "Evaluation/AverageReturn              -1579.64\n",
      "Evaluation/Iteration                    814\n",
      "Evaluation/MaxReturn                  -1525.73\n",
      "Evaluation/MinReturn                  -1637.02\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     33.0513\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.06361\n",
      "GaussianMLPPolicy/KL                      0.00634339\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              21.5347\n",
      "GaussianMLPPolicy/LossBefore             22.4649\n",
      "GaussianMLPPolicy/dLoss                   0.930267\n",
      "GaussianMLPValueFunction/LossAfter        6.70089\n",
      "GaussianMLPValueFunction/LossBefore       6.7009\n",
      "GaussianMLPValueFunction/dLoss            1.43051e-05\n",
      "TotalEnvSteps                        978000\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:13:22 | [trpo_pendulum] epoch #815 | Saving snapshot...\n",
      "2022-08-17 18:13:22 | [trpo_pendulum] epoch #815 | Saved\n",
      "2022-08-17 18:13:22 | [trpo_pendulum] epoch #815 | Time 518.58 s\n",
      "2022-08-17 18:13:22 | [trpo_pendulum] epoch #815 | EpochTime 0.61 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -621.453\n",
      "Evaluation/AverageReturn              -1518.2\n",
      "Evaluation/Iteration                    815\n",
      "Evaluation/MaxReturn                  -1504.68\n",
      "Evaluation/MinReturn                  -1540.99\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     11.7169\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.09684\n",
      "GaussianMLPPolicy/KL                      0.00652132\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              16.3503\n",
      "GaussianMLPPolicy/LossBefore             17.7092\n",
      "GaussianMLPPolicy/dLoss                   1.35893\n",
      "GaussianMLPValueFunction/LossAfter        6.68361\n",
      "GaussianMLPValueFunction/LossBefore       6.68389\n",
      "GaussianMLPValueFunction/dLoss            0.000277996\n",
      "TotalEnvSteps                        979200\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:13:23 | [trpo_pendulum] epoch #816 | Saving snapshot...\n",
      "2022-08-17 18:13:23 | [trpo_pendulum] epoch #816 | Saved\n",
      "2022-08-17 18:13:23 | [trpo_pendulum] epoch #816 | Time 519.24 s\n",
      "2022-08-17 18:13:23 | [trpo_pendulum] epoch #816 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -638.902\n",
      "Evaluation/AverageReturn              -1532.01\n",
      "Evaluation/Iteration                    816\n",
      "Evaluation/MaxReturn                  -1509.15\n",
      "Evaluation/MinReturn                  -1573.82\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     20.7464\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.09481\n",
      "GaussianMLPPolicy/KL                      0.00586273\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              15.0759\n",
      "GaussianMLPPolicy/LossBefore             16.9077\n",
      "GaussianMLPPolicy/dLoss                   1.83185\n",
      "GaussianMLPValueFunction/LossAfter        6.68326\n",
      "GaussianMLPValueFunction/LossBefore       6.68339\n",
      "GaussianMLPValueFunction/dLoss            0.0001297\n",
      "TotalEnvSteps                        980400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:24 | [trpo_pendulum] epoch #817 | Saving snapshot...\n",
      "2022-08-17 18:13:24 | [trpo_pendulum] epoch #817 | Saved\n",
      "2022-08-17 18:13:24 | [trpo_pendulum] epoch #817 | Time 519.85 s\n",
      "2022-08-17 18:13:24 | [trpo_pendulum] epoch #817 | EpochTime 0.60 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -677.528\n",
      "Evaluation/AverageReturn              -1634.8\n",
      "Evaluation/Iteration                    817\n",
      "Evaluation/MaxReturn                  -1624.92\n",
      "Evaluation/MinReturn                  -1638.68\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      4.83504\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.10229\n",
      "GaussianMLPPolicy/KL                      0.00749576\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              34.9672\n",
      "GaussianMLPPolicy/LossBefore             35.6535\n",
      "GaussianMLPPolicy/dLoss                   0.686325\n",
      "GaussianMLPValueFunction/LossAfter        6.7067\n",
      "GaussianMLPValueFunction/LossBefore       6.71063\n",
      "GaussianMLPValueFunction/dLoss            0.00392056\n",
      "TotalEnvSteps                        981600\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:24 | [trpo_pendulum] epoch #818 | Saving snapshot...\n",
      "2022-08-17 18:13:24 | [trpo_pendulum] epoch #818 | Saved\n",
      "2022-08-17 18:13:24 | [trpo_pendulum] epoch #818 | Time 520.48 s\n",
      "2022-08-17 18:13:24 | [trpo_pendulum] epoch #818 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -604.443\n",
      "Evaluation/AverageReturn              -1471.36\n",
      "Evaluation/Iteration                    818\n",
      "Evaluation/MaxReturn                  -1374.48\n",
      "Evaluation/MinReturn                  -1510.77\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     45.3696\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.08082\n",
      "GaussianMLPPolicy/KL                      0.00973186\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               6.80682\n",
      "GaussianMLPPolicy/LossBefore              8.34302\n",
      "GaussianMLPPolicy/dLoss                   1.53619\n",
      "GaussianMLPValueFunction/LossAfter        6.61531\n",
      "GaussianMLPValueFunction/LossBefore       6.62045\n",
      "GaussianMLPValueFunction/dLoss            0.00513649\n",
      "TotalEnvSteps                        982800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:25 | [trpo_pendulum] epoch #819 | Saving snapshot...\n",
      "2022-08-17 18:13:25 | [trpo_pendulum] epoch #819 | Saved\n",
      "2022-08-17 18:13:25 | [trpo_pendulum] epoch #819 | Time 521.12 s\n",
      "2022-08-17 18:13:25 | [trpo_pendulum] epoch #819 | EpochTime 0.63 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -634.672\n",
      "Evaluation/AverageReturn              -1510.8\n",
      "Evaluation/Iteration                    819\n",
      "Evaluation/MaxReturn                  -1489.52\n",
      "Evaluation/MinReturn                  -1527\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     11.9178\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.0759\n",
      "GaussianMLPPolicy/KL                      0.00429926\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              12.846\n",
      "GaussianMLPPolicy/LossBefore             13.05\n",
      "GaussianMLPPolicy/dLoss                   0.204023\n",
      "GaussianMLPValueFunction/LossAfter        6.66704\n",
      "GaussianMLPValueFunction/LossBefore       6.66745\n",
      "GaussianMLPValueFunction/dLoss            0.000405788\n",
      "TotalEnvSteps                        984000\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:13:25 | [trpo_pendulum] epoch #820 | Saving snapshot...\n",
      "2022-08-17 18:13:25 | [trpo_pendulum] epoch #820 | Saved\n",
      "2022-08-17 18:13:25 | [trpo_pendulum] epoch #820 | Time 521.74 s\n",
      "2022-08-17 18:13:25 | [trpo_pendulum] epoch #820 | EpochTime 0.61 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -643.636\n",
      "Evaluation/AverageReturn              -1519.13\n",
      "Evaluation/Iteration                    820\n",
      "Evaluation/MaxReturn                  -1509.22\n",
      "Evaluation/MinReturn                  -1532.12\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      7.96832\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.13922\n",
      "GaussianMLPPolicy/KL                      0.0072915\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              12.6375\n",
      "GaussianMLPPolicy/LossBefore             13.869\n",
      "GaussianMLPPolicy/dLoss                   1.2315\n",
      "GaussianMLPValueFunction/LossAfter        6.68068\n",
      "GaussianMLPValueFunction/LossBefore       6.68121\n",
      "GaussianMLPValueFunction/dLoss            0.000529766\n",
      "TotalEnvSteps                        985200\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:13:26 | [trpo_pendulum] epoch #821 | Saving snapshot...\n",
      "2022-08-17 18:13:26 | [trpo_pendulum] epoch #821 | Saved\n",
      "2022-08-17 18:13:26 | [trpo_pendulum] epoch #821 | Time 522.36 s\n",
      "2022-08-17 18:13:26 | [trpo_pendulum] epoch #821 | EpochTime 0.62 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -629.742\n",
      "Evaluation/AverageReturn              -1510.15\n",
      "Evaluation/Iteration                    821\n",
      "Evaluation/MaxReturn                  -1497.81\n",
      "Evaluation/MinReturn                  -1528.47\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     10.101\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.16176\n",
      "GaussianMLPPolicy/KL                      0.00552869\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              13.4492\n",
      "GaussianMLPPolicy/LossBefore             14.6245\n",
      "GaussianMLPPolicy/dLoss                   1.17525\n",
      "GaussianMLPValueFunction/LossAfter        6.66612\n",
      "GaussianMLPValueFunction/LossBefore       6.66633\n",
      "GaussianMLPValueFunction/dLoss            0.000217438\n",
      "TotalEnvSteps                        986400\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:13:27 | [trpo_pendulum] epoch #822 | Saving snapshot...\n",
      "2022-08-17 18:13:27 | [trpo_pendulum] epoch #822 | Saved\n",
      "2022-08-17 18:13:27 | [trpo_pendulum] epoch #822 | Time 523.00 s\n",
      "2022-08-17 18:13:27 | [trpo_pendulum] epoch #822 | EpochTime 0.64 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -627.03\n",
      "Evaluation/AverageReturn              -1506.41\n",
      "Evaluation/Iteration                    822\n",
      "Evaluation/MaxReturn                  -1491.93\n",
      "Evaluation/MinReturn                  -1519.53\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      9.9355\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.16301\n",
      "GaussianMLPPolicy/KL                      0.00558153\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              13.9112\n",
      "GaussianMLPPolicy/LossBefore             14.7996\n",
      "GaussianMLPPolicy/dLoss                   0.888394\n",
      "GaussianMLPValueFunction/LossAfter        6.66253\n",
      "GaussianMLPValueFunction/LossBefore       6.66275\n",
      "GaussianMLPValueFunction/dLoss            0.000223637\n",
      "TotalEnvSteps                        987600\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:13:27 | [trpo_pendulum] epoch #823 | Saving snapshot...\n",
      "2022-08-17 18:13:27 | [trpo_pendulum] epoch #823 | Saved\n",
      "2022-08-17 18:13:27 | [trpo_pendulum] epoch #823 | Time 523.63 s\n",
      "2022-08-17 18:13:27 | [trpo_pendulum] epoch #823 | EpochTime 0.62 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -677.149\n",
      "Evaluation/AverageReturn              -1573.6\n",
      "Evaluation/Iteration                    823\n",
      "Evaluation/MaxReturn                  -1459.24\n",
      "Evaluation/MinReturn                  -1677.08\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     67.774\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.13854\n",
      "GaussianMLPPolicy/KL                      0.00735567\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              18.4202\n",
      "GaussianMLPPolicy/LossBefore             19.8311\n",
      "GaussianMLPPolicy/dLoss                   1.4109\n",
      "GaussianMLPValueFunction/LossAfter        6.70017\n",
      "GaussianMLPValueFunction/LossBefore       6.70105\n",
      "GaussianMLPValueFunction/dLoss            0.000881195\n",
      "TotalEnvSteps                        988800\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:13:28 | [trpo_pendulum] epoch #824 | Saving snapshot...\n",
      "2022-08-17 18:13:28 | [trpo_pendulum] epoch #824 | Saved\n",
      "2022-08-17 18:13:28 | [trpo_pendulum] epoch #824 | Time 524.28 s\n",
      "2022-08-17 18:13:28 | [trpo_pendulum] epoch #824 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -615.711\n",
      "Evaluation/AverageReturn              -1524.81\n",
      "Evaluation/Iteration                    824\n",
      "Evaluation/MaxReturn                  -1502.22\n",
      "Evaluation/MinReturn                  -1548.43\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     17.0243\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.15027\n",
      "GaussianMLPPolicy/KL                      0.00718229\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              17.7599\n",
      "GaussianMLPPolicy/LossBefore             19.1771\n",
      "GaussianMLPPolicy/dLoss                   1.41717\n",
      "GaussianMLPValueFunction/LossAfter        6.62436\n",
      "GaussianMLPValueFunction/LossBefore       6.64991\n",
      "GaussianMLPValueFunction/dLoss            0.0255537\n",
      "TotalEnvSteps                        990000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:29 | [trpo_pendulum] epoch #825 | Saving snapshot...\n",
      "2022-08-17 18:13:29 | [trpo_pendulum] epoch #825 | Saved\n",
      "2022-08-17 18:13:29 | [trpo_pendulum] epoch #825 | Time 524.90 s\n",
      "2022-08-17 18:13:29 | [trpo_pendulum] epoch #825 | EpochTime 0.61 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn     -696.517\n",
      "Evaluation/AverageReturn              -1585.38\n",
      "Evaluation/Iteration                    825\n",
      "Evaluation/MaxReturn                  -1552.66\n",
      "Evaluation/MinReturn                  -1625.1\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     24.6313\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.13903\n",
      "GaussianMLPPolicy/KL                      0.00653392\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              17.0462\n",
      "GaussianMLPPolicy/LossBefore             18.4187\n",
      "GaussianMLPPolicy/dLoss                   1.37254\n",
      "GaussianMLPValueFunction/LossAfter        6.68476\n",
      "GaussianMLPValueFunction/LossBefore       6.68527\n",
      "GaussianMLPValueFunction/dLoss            0.000502586\n",
      "TotalEnvSteps                        991200\n",
      "-----------------------------------  ----------------\n",
      "2022-08-17 18:13:29 | [trpo_pendulum] epoch #826 | Saving snapshot...\n",
      "2022-08-17 18:13:29 | [trpo_pendulum] epoch #826 | Saved\n",
      "2022-08-17 18:13:29 | [trpo_pendulum] epoch #826 | Time 525.53 s\n",
      "2022-08-17 18:13:29 | [trpo_pendulum] epoch #826 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -502.706\n",
      "Evaluation/AverageReturn              -1188.7\n",
      "Evaluation/Iteration                    826\n",
      "Evaluation/MaxReturn                  -1035.68\n",
      "Evaluation/MinReturn                  -1515.87\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    161.06\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.14694\n",
      "GaussianMLPPolicy/KL                      0.00705399\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter             -33.1815\n",
      "GaussianMLPPolicy/LossBefore            -30.5921\n",
      "GaussianMLPPolicy/dLoss                   2.58939\n",
      "GaussianMLPValueFunction/LossAfter        6.69175\n",
      "GaussianMLPValueFunction/LossBefore       6.70269\n",
      "GaussianMLPValueFunction/dLoss            0.0109406\n",
      "TotalEnvSteps                        992400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:30 | [trpo_pendulum] epoch #827 | Saving snapshot...\n",
      "2022-08-17 18:13:30 | [trpo_pendulum] epoch #827 | Saved\n",
      "2022-08-17 18:13:30 | [trpo_pendulum] epoch #827 | Time 526.17 s\n",
      "2022-08-17 18:13:30 | [trpo_pendulum] epoch #827 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -597.258\n",
      "Evaluation/AverageReturn              -1435.31\n",
      "Evaluation/Iteration                    827\n",
      "Evaluation/MaxReturn                  -1108.24\n",
      "Evaluation/MinReturn                  -1599.86\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    173.186\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.15769\n",
      "GaussianMLPPolicy/KL                      0.0086288\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               2.96497\n",
      "GaussianMLPPolicy/LossBefore              5.59544\n",
      "GaussianMLPPolicy/dLoss                   2.63047\n",
      "GaussianMLPValueFunction/LossAfter        6.5871\n",
      "GaussianMLPValueFunction/LossBefore       6.60992\n",
      "GaussianMLPValueFunction/dLoss            0.0228195\n",
      "TotalEnvSteps                        993600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:31 | [trpo_pendulum] epoch #828 | Saving snapshot...\n",
      "2022-08-17 18:13:31 | [trpo_pendulum] epoch #828 | Saved\n",
      "2022-08-17 18:13:31 | [trpo_pendulum] epoch #828 | Time 526.81 s\n",
      "2022-08-17 18:13:31 | [trpo_pendulum] epoch #828 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -694.763\n",
      "Evaluation/AverageReturn              -1600.21\n",
      "Evaluation/Iteration                    828\n",
      "Evaluation/MaxReturn                  -1548.47\n",
      "Evaluation/MinReturn                  -1637.55\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     38.579\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.15155\n",
      "GaussianMLPPolicy/KL                      0.006639\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              22.7873\n",
      "GaussianMLPPolicy/LossBefore             24.3564\n",
      "GaussianMLPPolicy/dLoss                   1.5691\n",
      "GaussianMLPValueFunction/LossAfter        6.72187\n",
      "GaussianMLPValueFunction/LossBefore       6.72619\n",
      "GaussianMLPValueFunction/dLoss            0.00431681\n",
      "TotalEnvSteps                        994800\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:31 | [trpo_pendulum] epoch #829 | Saving snapshot...\n",
      "2022-08-17 18:13:31 | [trpo_pendulum] epoch #829 | Saved\n",
      "2022-08-17 18:13:31 | [trpo_pendulum] epoch #829 | Time 527.44 s\n",
      "2022-08-17 18:13:31 | [trpo_pendulum] epoch #829 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -660.841\n",
      "Evaluation/AverageReturn              -1586.31\n",
      "Evaluation/Iteration                    829\n",
      "Evaluation/MaxReturn                  -1408.92\n",
      "Evaluation/MinReturn                  -1732.97\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                    127.89\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.17564\n",
      "GaussianMLPPolicy/KL                      0.00964128\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              29.3778\n",
      "GaussianMLPPolicy/LossBefore             32.5448\n",
      "GaussianMLPPolicy/dLoss                   3.167\n",
      "GaussianMLPValueFunction/LossAfter        6.66874\n",
      "GaussianMLPValueFunction/LossBefore       6.67083\n",
      "GaussianMLPValueFunction/dLoss            0.00208759\n",
      "TotalEnvSteps                        996000\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:32 | [trpo_pendulum] epoch #830 | Saving snapshot...\n",
      "2022-08-17 18:13:32 | [trpo_pendulum] epoch #830 | Saved\n",
      "2022-08-17 18:13:32 | [trpo_pendulum] epoch #830 | Time 528.09 s\n",
      "2022-08-17 18:13:32 | [trpo_pendulum] epoch #830 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -684.871\n",
      "Evaluation/AverageReturn              -1636.4\n",
      "Evaluation/Iteration                    830\n",
      "Evaluation/MaxReturn                  -1629.72\n",
      "Evaluation/MinReturn                  -1645.25\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                      5.46356\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.18946\n",
      "GaussianMLPPolicy/KL                      0.00620981\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              75.9157\n",
      "GaussianMLPPolicy/LossBefore             76.2377\n",
      "GaussianMLPPolicy/dLoss                   0.322037\n",
      "GaussianMLPValueFunction/LossAfter        6.70729\n",
      "GaussianMLPValueFunction/LossBefore       6.91433\n",
      "GaussianMLPValueFunction/dLoss            0.207037\n",
      "TotalEnvSteps                        997200\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:32 | [trpo_pendulum] epoch #831 | Saving snapshot...\n",
      "2022-08-17 18:13:32 | [trpo_pendulum] epoch #831 | Saved\n",
      "2022-08-17 18:13:32 | [trpo_pendulum] epoch #831 | Time 528.72 s\n",
      "2022-08-17 18:13:32 | [trpo_pendulum] epoch #831 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -723.726\n",
      "Evaluation/AverageReturn              -1686.87\n",
      "Evaluation/Iteration                    831\n",
      "Evaluation/MaxReturn                  -1618.04\n",
      "Evaluation/MinReturn                  -1746.03\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     53.6596\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.19559\n",
      "GaussianMLPPolicy/KL                      0.00712476\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              34.4808\n",
      "GaussianMLPPolicy/LossBefore             36.888\n",
      "GaussianMLPPolicy/dLoss                   2.40713\n",
      "GaussianMLPValueFunction/LossAfter        6.79499\n",
      "GaussianMLPValueFunction/LossBefore       6.80359\n",
      "GaussianMLPValueFunction/dLoss            0.00860262\n",
      "TotalEnvSteps                        998400\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:33 | [trpo_pendulum] epoch #832 | Saving snapshot...\n",
      "2022-08-17 18:13:33 | [trpo_pendulum] epoch #832 | Saved\n",
      "2022-08-17 18:13:33 | [trpo_pendulum] epoch #832 | Time 529.34 s\n",
      "2022-08-17 18:13:33 | [trpo_pendulum] epoch #832 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -550.067\n",
      "Evaluation/AverageReturn              -1354.24\n",
      "Evaluation/Iteration                    832\n",
      "Evaluation/MaxReturn                  -1320.07\n",
      "Evaluation/MinReturn                  -1393.31\n",
      "Evaluation/NumEpisodes                    6\n",
      "Evaluation/StdReturn                     22.1041\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 2.15463\n",
      "GaussianMLPPolicy/KL                      0.0067117\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.61669\n",
      "GaussianMLPPolicy/LossBefore             -5.34271\n",
      "GaussianMLPPolicy/dLoss                   0.273982\n",
      "GaussianMLPValueFunction/LossAfter        6.59987\n",
      "GaussianMLPValueFunction/LossBefore       6.61267\n",
      "GaussianMLPValueFunction/dLoss            0.0127983\n",
      "TotalEnvSteps                        999600\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:34 | [trpo_pendulum] epoch #833 | Saving snapshot...\n",
      "2022-08-17 18:13:34 | [trpo_pendulum] epoch #833 | Saved\n",
      "2022-08-17 18:13:34 | [trpo_pendulum] epoch #833 | Time 529.99 s\n",
      "2022-08-17 18:13:34 | [trpo_pendulum] epoch #833 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -584.198\n",
      "Evaluation/AverageReturn             -1453.36\n",
      "Evaluation/Iteration                   833\n",
      "Evaluation/MaxReturn                 -1345.08\n",
      "Evaluation/MinReturn                 -1536.29\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    72.9132\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.16125\n",
      "GaussianMLPPolicy/KL                     0.00654155\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              8.11067\n",
      "GaussianMLPPolicy/LossBefore             8.71834\n",
      "GaussianMLPPolicy/dLoss                  0.607668\n",
      "GaussianMLPValueFunction/LossAfter       6.53768\n",
      "GaussianMLPValueFunction/LossBefore      6.577\n",
      "GaussianMLPValueFunction/dLoss           0.0393167\n",
      "TotalEnvSteps                            1.0008e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:34 | [trpo_pendulum] epoch #834 | Saving snapshot...\n",
      "2022-08-17 18:13:34 | [trpo_pendulum] epoch #834 | Saved\n",
      "2022-08-17 18:13:34 | [trpo_pendulum] epoch #834 | Time 530.63 s\n",
      "2022-08-17 18:13:34 | [trpo_pendulum] epoch #834 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -662.62\n",
      "Evaluation/AverageReturn             -1531.23\n",
      "Evaluation/Iteration                   834\n",
      "Evaluation/MaxReturn                 -1524.12\n",
      "Evaluation/MinReturn                 -1549.3\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     8.49619\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.15639\n",
      "GaussianMLPPolicy/KL                     0.00666665\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             12.0322\n",
      "GaussianMLPPolicy/LossBefore            13.1215\n",
      "GaussianMLPPolicy/dLoss                  1.08928\n",
      "GaussianMLPValueFunction/LossAfter       6.64184\n",
      "GaussianMLPValueFunction/LossBefore      6.6421\n",
      "GaussianMLPValueFunction/dLoss           0.000254631\n",
      "TotalEnvSteps                            1.002e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:35 | [trpo_pendulum] epoch #835 | Saving snapshot...\n",
      "2022-08-17 18:13:35 | [trpo_pendulum] epoch #835 | Saved\n",
      "2022-08-17 18:13:35 | [trpo_pendulum] epoch #835 | Time 531.27 s\n",
      "2022-08-17 18:13:35 | [trpo_pendulum] epoch #835 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -659.496\n",
      "Evaluation/AverageReturn             -1530.37\n",
      "Evaluation/Iteration                   835\n",
      "Evaluation/MaxReturn                 -1521.56\n",
      "Evaluation/MinReturn                 -1546.1\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     8.34026\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.18444\n",
      "GaussianMLPPolicy/KL                     0.00634022\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             12.4257\n",
      "GaussianMLPPolicy/LossBefore            13.9218\n",
      "GaussianMLPPolicy/dLoss                  1.4961\n",
      "GaussianMLPValueFunction/LossAfter       6.6426\n",
      "GaussianMLPValueFunction/LossBefore      6.64284\n",
      "GaussianMLPValueFunction/dLoss           0.000240803\n",
      "TotalEnvSteps                            1.0032e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:36 | [trpo_pendulum] epoch #836 | Saving snapshot...\n",
      "2022-08-17 18:13:36 | [trpo_pendulum] epoch #836 | Saved\n",
      "2022-08-17 18:13:36 | [trpo_pendulum] epoch #836 | Time 531.91 s\n",
      "2022-08-17 18:13:36 | [trpo_pendulum] epoch #836 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -728.013\n",
      "Evaluation/AverageReturn             -1686.89\n",
      "Evaluation/Iteration                   836\n",
      "Evaluation/MaxReturn                 -1659.73\n",
      "Evaluation/MinReturn                 -1718.21\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    17.4236\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.17396\n",
      "GaussianMLPPolicy/KL                     0.00740494\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             33.782\n",
      "GaussianMLPPolicy/LossBefore            35.63\n",
      "GaussianMLPPolicy/dLoss                  1.84797\n",
      "GaussianMLPValueFunction/LossAfter       6.7508\n",
      "GaussianMLPValueFunction/LossBefore      6.76016\n",
      "GaussianMLPValueFunction/dLoss           0.00935411\n",
      "TotalEnvSteps                            1.0044e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:36 | [trpo_pendulum] epoch #837 | Saving snapshot...\n",
      "2022-08-17 18:13:36 | [trpo_pendulum] epoch #837 | Saved\n",
      "2022-08-17 18:13:36 | [trpo_pendulum] epoch #837 | Time 532.55 s\n",
      "2022-08-17 18:13:36 | [trpo_pendulum] epoch #837 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -650.229\n",
      "Evaluation/AverageReturn             -1569.57\n",
      "Evaluation/Iteration                   837\n",
      "Evaluation/MaxReturn                 -1537.12\n",
      "Evaluation/MinReturn                 -1588.41\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    16.9961\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.16194\n",
      "GaussianMLPPolicy/KL                     0.00507218\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             45.3018\n",
      "GaussianMLPPolicy/LossBefore            46.0345\n",
      "GaussianMLPPolicy/dLoss                  0.732658\n",
      "GaussianMLPValueFunction/LossAfter       6.69572\n",
      "GaussianMLPValueFunction/LossBefore      6.72546\n",
      "GaussianMLPValueFunction/dLoss           0.0297437\n",
      "TotalEnvSteps                            1.0056e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:37 | [trpo_pendulum] epoch #838 | Saving snapshot...\n",
      "2022-08-17 18:13:37 | [trpo_pendulum] epoch #838 | Saved\n",
      "2022-08-17 18:13:37 | [trpo_pendulum] epoch #838 | Time 533.20 s\n",
      "2022-08-17 18:13:37 | [trpo_pendulum] epoch #838 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -635.87\n",
      "Evaluation/AverageReturn             -1544.19\n",
      "Evaluation/Iteration                   838\n",
      "Evaluation/MaxReturn                 -1356.59\n",
      "Evaluation/MinReturn                 -1732.6\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                   150.544\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.17483\n",
      "GaussianMLPPolicy/KL                     0.00745485\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             17.227\n",
      "GaussianMLPPolicy/LossBefore            19.5747\n",
      "GaussianMLPPolicy/dLoss                  2.34775\n",
      "GaussianMLPValueFunction/LossAfter       6.66814\n",
      "GaussianMLPValueFunction/LossBefore      6.67183\n",
      "GaussianMLPValueFunction/dLoss           0.00369644\n",
      "TotalEnvSteps                            1.0068e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:38 | [trpo_pendulum] epoch #839 | Saving snapshot...\n",
      "2022-08-17 18:13:38 | [trpo_pendulum] epoch #839 | Saved\n",
      "2022-08-17 18:13:38 | [trpo_pendulum] epoch #839 | Time 533.86 s\n",
      "2022-08-17 18:13:38 | [trpo_pendulum] epoch #839 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -657.935\n",
      "Evaluation/AverageReturn             -1516.41\n",
      "Evaluation/Iteration                   839\n",
      "Evaluation/MaxReturn                 -1511.09\n",
      "Evaluation/MinReturn                 -1528.43\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     5.5742\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.17065\n",
      "GaussianMLPPolicy/KL                     0.00776915\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              9.03138\n",
      "GaussianMLPPolicy/LossBefore             9.98708\n",
      "GaussianMLPPolicy/dLoss                  0.955692\n",
      "GaussianMLPValueFunction/LossAfter       6.63222\n",
      "GaussianMLPValueFunction/LossBefore      6.63428\n",
      "GaussianMLPValueFunction/dLoss           0.00206852\n",
      "TotalEnvSteps                            1.008e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:38 | [trpo_pendulum] epoch #840 | Saving snapshot...\n",
      "2022-08-17 18:13:38 | [trpo_pendulum] epoch #840 | Saved\n",
      "2022-08-17 18:13:38 | [trpo_pendulum] epoch #840 | Time 534.48 s\n",
      "2022-08-17 18:13:38 | [trpo_pendulum] epoch #840 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -700.83\n",
      "Evaluation/AverageReturn             -1593.52\n",
      "Evaluation/Iteration                   840\n",
      "Evaluation/MaxReturn                 -1555.86\n",
      "Evaluation/MinReturn                 -1640.88\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    27.2084\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.18747\n",
      "GaussianMLPPolicy/KL                     0.00901188\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             18.444\n",
      "GaussianMLPPolicy/LossBefore            21.1064\n",
      "GaussianMLPPolicy/dLoss                  2.6624\n",
      "GaussianMLPValueFunction/LossAfter       6.70499\n",
      "GaussianMLPValueFunction/LossBefore      6.70622\n",
      "GaussianMLPValueFunction/dLoss           0.00123215\n",
      "TotalEnvSteps                            1.0092e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:39 | [trpo_pendulum] epoch #841 | Saving snapshot...\n",
      "2022-08-17 18:13:39 | [trpo_pendulum] epoch #841 | Saved\n",
      "2022-08-17 18:13:39 | [trpo_pendulum] epoch #841 | Time 535.23 s\n",
      "2022-08-17 18:13:39 | [trpo_pendulum] epoch #841 | EpochTime 0.74 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -628.244\n",
      "Evaluation/AverageReturn             -1533.84\n",
      "Evaluation/Iteration                   841\n",
      "Evaluation/MaxReturn                 -1505.04\n",
      "Evaluation/MinReturn                 -1556.05\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    20.4284\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.16979\n",
      "GaussianMLPPolicy/KL                     0.00665494\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             35.3365\n",
      "GaussianMLPPolicy/LossBefore            35.9311\n",
      "GaussianMLPPolicy/dLoss                  0.59462\n",
      "GaussianMLPValueFunction/LossAfter       6.69061\n",
      "GaussianMLPValueFunction/LossBefore      6.70093\n",
      "GaussianMLPValueFunction/dLoss           0.0103135\n",
      "TotalEnvSteps                            1.0104e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:40 | [trpo_pendulum] epoch #842 | Saving snapshot...\n",
      "2022-08-17 18:13:40 | [trpo_pendulum] epoch #842 | Saved\n",
      "2022-08-17 18:13:40 | [trpo_pendulum] epoch #842 | Time 535.85 s\n",
      "2022-08-17 18:13:40 | [trpo_pendulum] epoch #842 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -663.718\n",
      "Evaluation/AverageReturn             -1565.01\n",
      "Evaluation/Iteration                   842\n",
      "Evaluation/MaxReturn                 -1530.85\n",
      "Evaluation/MinReturn                 -1605.69\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    23.6471\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.18812\n",
      "GaussianMLPPolicy/KL                     0.00639399\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             26.0133\n",
      "GaussianMLPPolicy/LossBefore            26.1372\n",
      "GaussianMLPPolicy/dLoss                  0.123987\n",
      "GaussianMLPValueFunction/LossAfter       6.6912\n",
      "GaussianMLPValueFunction/LossBefore      6.6919\n",
      "GaussianMLPValueFunction/dLoss           0.000696659\n",
      "TotalEnvSteps                            1.0116e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:40 | [trpo_pendulum] epoch #843 | Saving snapshot...\n",
      "2022-08-17 18:13:40 | [trpo_pendulum] epoch #843 | Saved\n",
      "2022-08-17 18:13:40 | [trpo_pendulum] epoch #843 | Time 536.49 s\n",
      "2022-08-17 18:13:40 | [trpo_pendulum] epoch #843 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -551.56\n",
      "Evaluation/AverageReturn             -1410.85\n",
      "Evaluation/Iteration                   843\n",
      "Evaluation/MaxReturn                 -1327.66\n",
      "Evaluation/MinReturn                 -1458.23\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    50.469\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.15642\n",
      "GaussianMLPPolicy/KL                     0.00630355\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              4.73652\n",
      "GaussianMLPPolicy/LossBefore             5.93679\n",
      "GaussianMLPPolicy/dLoss                  1.20028\n",
      "GaussianMLPValueFunction/LossAfter       6.49684\n",
      "GaussianMLPValueFunction/LossBefore      6.55343\n",
      "GaussianMLPValueFunction/dLoss           0.0565906\n",
      "TotalEnvSteps                            1.0128e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:41 | [trpo_pendulum] epoch #844 | Saving snapshot...\n",
      "2022-08-17 18:13:41 | [trpo_pendulum] epoch #844 | Saved\n",
      "2022-08-17 18:13:41 | [trpo_pendulum] epoch #844 | Time 537.13 s\n",
      "2022-08-17 18:13:41 | [trpo_pendulum] epoch #844 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -661.716\n",
      "Evaluation/AverageReturn             -1566.5\n",
      "Evaluation/Iteration                   844\n",
      "Evaluation/MaxReturn                 -1533.97\n",
      "Evaluation/MinReturn                 -1595.82\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    21.9887\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.16275\n",
      "GaussianMLPPolicy/KL                     0.00184083\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             48.2031\n",
      "GaussianMLPPolicy/LossBefore            48.3942\n",
      "GaussianMLPPolicy/dLoss                  0.191158\n",
      "GaussianMLPValueFunction/LossAfter       6.69533\n",
      "GaussianMLPValueFunction/LossBefore      6.7571\n",
      "GaussianMLPValueFunction/dLoss           0.0617743\n",
      "TotalEnvSteps                            1.014e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:41 | [trpo_pendulum] epoch #845 | Saving snapshot...\n",
      "2022-08-17 18:13:41 | [trpo_pendulum] epoch #845 | Saved\n",
      "2022-08-17 18:13:41 | [trpo_pendulum] epoch #845 | Time 537.75 s\n",
      "2022-08-17 18:13:41 | [trpo_pendulum] epoch #845 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -526.658\n",
      "Evaluation/AverageReturn             -1368.75\n",
      "Evaluation/Iteration                   845\n",
      "Evaluation/MaxReturn                 -1354.84\n",
      "Evaluation/MinReturn                 -1378.63\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     8.73442\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.14853\n",
      "GaussianMLPPolicy/KL                     0.00397703\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.690313\n",
      "GaussianMLPPolicy/LossBefore             0.771862\n",
      "GaussianMLPPolicy/dLoss                  0.0815489\n",
      "GaussianMLPValueFunction/LossAfter       6.58075\n",
      "GaussianMLPValueFunction/LossBefore      6.58469\n",
      "GaussianMLPValueFunction/dLoss           0.00394249\n",
      "TotalEnvSteps                            1.0152e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:42 | [trpo_pendulum] epoch #846 | Saving snapshot...\n",
      "2022-08-17 18:13:42 | [trpo_pendulum] epoch #846 | Saved\n",
      "2022-08-17 18:13:42 | [trpo_pendulum] epoch #846 | Time 538.38 s\n",
      "2022-08-17 18:13:42 | [trpo_pendulum] epoch #846 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -734.446\n",
      "Evaluation/AverageReturn             -1664.15\n",
      "Evaluation/Iteration                   846\n",
      "Evaluation/MaxReturn                 -1549.04\n",
      "Evaluation/MinReturn                 -1746.61\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    71.8016\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.15167\n",
      "GaussianMLPPolicy/KL                     0.0068944\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             27.3824\n",
      "GaussianMLPPolicy/LossBefore            29.5059\n",
      "GaussianMLPPolicy/dLoss                  2.12353\n",
      "GaussianMLPValueFunction/LossAfter       6.7705\n",
      "GaussianMLPValueFunction/LossBefore      6.78456\n",
      "GaussianMLPValueFunction/dLoss           0.0140576\n",
      "TotalEnvSteps                            1.0164e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:43 | [trpo_pendulum] epoch #847 | Saving snapshot...\n",
      "2022-08-17 18:13:43 | [trpo_pendulum] epoch #847 | Saved\n",
      "2022-08-17 18:13:43 | [trpo_pendulum] epoch #847 | Time 539.00 s\n",
      "2022-08-17 18:13:43 | [trpo_pendulum] epoch #847 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -576.347\n",
      "Evaluation/AverageReturn             -1443.55\n",
      "Evaluation/Iteration                   847\n",
      "Evaluation/MaxReturn                 -1273.34\n",
      "Evaluation/MinReturn                 -1525.21\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    88.8106\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.15123\n",
      "GaussianMLPPolicy/KL                     0.00654185\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              8.80788\n",
      "GaussianMLPPolicy/LossBefore             9.46712\n",
      "GaussianMLPPolicy/dLoss                  0.659245\n",
      "GaussianMLPValueFunction/LossAfter       6.54591\n",
      "GaussianMLPValueFunction/LossBefore      6.59018\n",
      "GaussianMLPValueFunction/dLoss           0.0442653\n",
      "TotalEnvSteps                            1.0176e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:43 | [trpo_pendulum] epoch #848 | Saving snapshot...\n",
      "2022-08-17 18:13:43 | [trpo_pendulum] epoch #848 | Saved\n",
      "2022-08-17 18:13:43 | [trpo_pendulum] epoch #848 | Time 539.65 s\n",
      "2022-08-17 18:13:43 | [trpo_pendulum] epoch #848 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -542.725\n",
      "Evaluation/AverageReturn             -1407.16\n",
      "Evaluation/Iteration                   848\n",
      "Evaluation/MaxReturn                 -1370.22\n",
      "Evaluation/MinReturn                 -1517.62\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    50.7009\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.17723\n",
      "GaussianMLPPolicy/KL                     0.00689384\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             10.8329\n",
      "GaussianMLPPolicy/LossBefore            12.0138\n",
      "GaussianMLPPolicy/dLoss                  1.18089\n",
      "GaussianMLPValueFunction/LossAfter       6.63952\n",
      "GaussianMLPValueFunction/LossBefore      6.64574\n",
      "GaussianMLPValueFunction/dLoss           0.00621891\n",
      "TotalEnvSteps                            1.0188e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:44 | [trpo_pendulum] epoch #849 | Saving snapshot...\n",
      "2022-08-17 18:13:44 | [trpo_pendulum] epoch #849 | Saved\n",
      "2022-08-17 18:13:44 | [trpo_pendulum] epoch #849 | Time 540.28 s\n",
      "2022-08-17 18:13:44 | [trpo_pendulum] epoch #849 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -703.63\n",
      "Evaluation/AverageReturn             -1607.93\n",
      "Evaluation/Iteration                   849\n",
      "Evaluation/MaxReturn                 -1569.47\n",
      "Evaluation/MinReturn                 -1678.14\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    35.7901\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.14563\n",
      "GaussianMLPPolicy/KL                     0.00749835\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             20.6274\n",
      "GaussianMLPPolicy/LossBefore            22.1323\n",
      "GaussianMLPPolicy/dLoss                  1.50488\n",
      "GaussianMLPValueFunction/LossAfter       6.70314\n",
      "GaussianMLPValueFunction/LossBefore      6.70584\n",
      "GaussianMLPValueFunction/dLoss           0.00269318\n",
      "TotalEnvSteps                            1.02e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:45 | [trpo_pendulum] epoch #850 | Saving snapshot...\n",
      "2022-08-17 18:13:45 | [trpo_pendulum] epoch #850 | Saved\n",
      "2022-08-17 18:13:45 | [trpo_pendulum] epoch #850 | Time 540.90 s\n",
      "2022-08-17 18:13:45 | [trpo_pendulum] epoch #850 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -603.877\n",
      "Evaluation/AverageReturn             -1504.88\n",
      "Evaluation/Iteration                   850\n",
      "Evaluation/MaxReturn                 -1353.51\n",
      "Evaluation/MinReturn                 -1572.48\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    70.9968\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.16075\n",
      "GaussianMLPPolicy/KL                     0.00610563\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             25.2694\n",
      "GaussianMLPPolicy/LossBefore            26.4439\n",
      "GaussianMLPPolicy/dLoss                  1.17452\n",
      "GaussianMLPValueFunction/LossAfter       6.68127\n",
      "GaussianMLPValueFunction/LossBefore      6.68508\n",
      "GaussianMLPValueFunction/dLoss           0.00380611\n",
      "TotalEnvSteps                            1.0212e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:45 | [trpo_pendulum] epoch #851 | Saving snapshot...\n",
      "2022-08-17 18:13:45 | [trpo_pendulum] epoch #851 | Saved\n",
      "2022-08-17 18:13:45 | [trpo_pendulum] epoch #851 | Time 541.51 s\n",
      "2022-08-17 18:13:45 | [trpo_pendulum] epoch #851 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -677.434\n",
      "Evaluation/AverageReturn             -1596.83\n",
      "Evaluation/Iteration                   851\n",
      "Evaluation/MaxReturn                 -1558.24\n",
      "Evaluation/MinReturn                 -1622.29\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    25.0963\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.16559\n",
      "GaussianMLPPolicy/KL                     0.00641634\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             21.596\n",
      "GaussianMLPPolicy/LossBefore            23.6109\n",
      "GaussianMLPPolicy/dLoss                  2.0149\n",
      "GaussianMLPValueFunction/LossAfter       6.69687\n",
      "GaussianMLPValueFunction/LossBefore      6.69742\n",
      "GaussianMLPValueFunction/dLoss           0.000551701\n",
      "TotalEnvSteps                            1.0224e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:46 | [trpo_pendulum] epoch #852 | Saving snapshot...\n",
      "2022-08-17 18:13:46 | [trpo_pendulum] epoch #852 | Saved\n",
      "2022-08-17 18:13:46 | [trpo_pendulum] epoch #852 | Time 542.13 s\n",
      "2022-08-17 18:13:46 | [trpo_pendulum] epoch #852 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -698.864\n",
      "Evaluation/AverageReturn             -1605.52\n",
      "Evaluation/Iteration                   852\n",
      "Evaluation/MaxReturn                 -1529.94\n",
      "Evaluation/MinReturn                 -1662.49\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    47.4218\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.18349\n",
      "GaussianMLPPolicy/KL                     0.00911305\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             19.6494\n",
      "GaussianMLPPolicy/LossBefore            22.1192\n",
      "GaussianMLPPolicy/dLoss                  2.46979\n",
      "GaussianMLPValueFunction/LossAfter       6.71216\n",
      "GaussianMLPValueFunction/LossBefore      6.71283\n",
      "GaussianMLPValueFunction/dLoss           0.000671864\n",
      "TotalEnvSteps                            1.0236e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:46 | [trpo_pendulum] epoch #853 | Saving snapshot...\n",
      "2022-08-17 18:13:46 | [trpo_pendulum] epoch #853 | Saved\n",
      "2022-08-17 18:13:46 | [trpo_pendulum] epoch #853 | Time 542.75 s\n",
      "2022-08-17 18:13:46 | [trpo_pendulum] epoch #853 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -464.681\n",
      "Evaluation/AverageReturn             -1232.99\n",
      "Evaluation/Iteration                   853\n",
      "Evaluation/MaxReturn                 -1015.93\n",
      "Evaluation/MinReturn                 -1382.4\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                   109.812\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.18802\n",
      "GaussianMLPPolicy/KL                     0.0096403\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -19.3293\n",
      "GaussianMLPPolicy/LossBefore           -18.2757\n",
      "GaussianMLPPolicy/dLoss                  1.05366\n",
      "GaussianMLPValueFunction/LossAfter       6.57467\n",
      "GaussianMLPValueFunction/LossBefore      6.58805\n",
      "GaussianMLPValueFunction/dLoss           0.0133829\n",
      "TotalEnvSteps                            1.0248e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:47 | [trpo_pendulum] epoch #854 | Saving snapshot...\n",
      "2022-08-17 18:13:47 | [trpo_pendulum] epoch #854 | Saved\n",
      "2022-08-17 18:13:47 | [trpo_pendulum] epoch #854 | Time 543.38 s\n",
      "2022-08-17 18:13:47 | [trpo_pendulum] epoch #854 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -692.756\n",
      "Evaluation/AverageReturn             -1600.53\n",
      "Evaluation/Iteration                   854\n",
      "Evaluation/MaxReturn                 -1525.21\n",
      "Evaluation/MinReturn                 -1716.41\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    61.6369\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.17959\n",
      "GaussianMLPPolicy/KL                     0.00672356\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             21.3471\n",
      "GaussianMLPPolicy/LossBefore            23.1614\n",
      "GaussianMLPPolicy/dLoss                  1.8143\n",
      "GaussianMLPValueFunction/LossAfter       6.70492\n",
      "GaussianMLPValueFunction/LossBefore      6.70683\n",
      "GaussianMLPValueFunction/dLoss           0.00190687\n",
      "TotalEnvSteps                            1.026e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:48 | [trpo_pendulum] epoch #855 | Saving snapshot...\n",
      "2022-08-17 18:13:48 | [trpo_pendulum] epoch #855 | Saved\n",
      "2022-08-17 18:13:48 | [trpo_pendulum] epoch #855 | Time 544.03 s\n",
      "2022-08-17 18:13:48 | [trpo_pendulum] epoch #855 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -634.332\n",
      "Evaluation/AverageReturn             -1528.93\n",
      "Evaluation/Iteration                   855\n",
      "Evaluation/MaxReturn                 -1498\n",
      "Evaluation/MinReturn                 -1564.38\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    22.2073\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.19444\n",
      "GaussianMLPPolicy/KL                     0.00396987\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             22.5505\n",
      "GaussianMLPPolicy/LossBefore            22.7566\n",
      "GaussianMLPPolicy/dLoss                  0.206051\n",
      "GaussianMLPValueFunction/LossAfter       6.68147\n",
      "GaussianMLPValueFunction/LossBefore      6.68215\n",
      "GaussianMLPValueFunction/dLoss           0.000676632\n",
      "TotalEnvSteps                            1.0272e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:48 | [trpo_pendulum] epoch #856 | Saving snapshot...\n",
      "2022-08-17 18:13:48 | [trpo_pendulum] epoch #856 | Saved\n",
      "2022-08-17 18:13:48 | [trpo_pendulum] epoch #856 | Time 544.66 s\n",
      "2022-08-17 18:13:48 | [trpo_pendulum] epoch #856 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -517.889\n",
      "Evaluation/AverageReturn             -1315.54\n",
      "Evaluation/Iteration                   856\n",
      "Evaluation/MaxReturn                 -1048.78\n",
      "Evaluation/MinReturn                 -1479.06\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                   145.556\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.20031\n",
      "GaussianMLPPolicy/KL                     0.00914004\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -7.72417\n",
      "GaussianMLPPolicy/LossBefore            -6.07454\n",
      "GaussianMLPPolicy/dLoss                  1.64963\n",
      "GaussianMLPValueFunction/LossAfter       6.59194\n",
      "GaussianMLPValueFunction/LossBefore      6.60587\n",
      "GaussianMLPValueFunction/dLoss           0.0139251\n",
      "TotalEnvSteps                            1.0284e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:49 | [trpo_pendulum] epoch #857 | Saving snapshot...\n",
      "2022-08-17 18:13:49 | [trpo_pendulum] epoch #857 | Saved\n",
      "2022-08-17 18:13:49 | [trpo_pendulum] epoch #857 | Time 545.30 s\n",
      "2022-08-17 18:13:49 | [trpo_pendulum] epoch #857 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -627.285\n",
      "Evaluation/AverageReturn             -1519.88\n",
      "Evaluation/Iteration                   857\n",
      "Evaluation/MaxReturn                 -1504.14\n",
      "Evaluation/MinReturn                 -1545.35\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    13.8092\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.15069\n",
      "GaussianMLPPolicy/KL                     0.00661121\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             38.3194\n",
      "GaussianMLPPolicy/LossBefore            38.4477\n",
      "GaussianMLPPolicy/dLoss                  0.128304\n",
      "GaussianMLPValueFunction/LossAfter       6.67181\n",
      "GaussianMLPValueFunction/LossBefore      6.6889\n",
      "GaussianMLPValueFunction/dLoss           0.0170937\n",
      "TotalEnvSteps                            1.0296e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:50 | [trpo_pendulum] epoch #858 | Saving snapshot...\n",
      "2022-08-17 18:13:50 | [trpo_pendulum] epoch #858 | Saved\n",
      "2022-08-17 18:13:50 | [trpo_pendulum] epoch #858 | Time 545.94 s\n",
      "2022-08-17 18:13:50 | [trpo_pendulum] epoch #858 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -605.312\n",
      "Evaluation/AverageReturn             -1482.52\n",
      "Evaluation/Iteration                   858\n",
      "Evaluation/MaxReturn                 -1396.29\n",
      "Evaluation/MinReturn                 -1529.16\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    44.1632\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.16756\n",
      "GaussianMLPPolicy/KL                     0.00697625\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             13.1958\n",
      "GaussianMLPPolicy/LossBefore            15.3301\n",
      "GaussianMLPPolicy/dLoss                  2.13437\n",
      "GaussianMLPValueFunction/LossAfter       6.60027\n",
      "GaussianMLPValueFunction/LossBefore      6.61028\n",
      "GaussianMLPValueFunction/dLoss           0.010006\n",
      "TotalEnvSteps                            1.0308e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:50 | [trpo_pendulum] epoch #859 | Saving snapshot...\n",
      "2022-08-17 18:13:50 | [trpo_pendulum] epoch #859 | Saved\n",
      "2022-08-17 18:13:50 | [trpo_pendulum] epoch #859 | Time 546.57 s\n",
      "2022-08-17 18:13:50 | [trpo_pendulum] epoch #859 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -645.442\n",
      "Evaluation/AverageReturn             -1541.66\n",
      "Evaluation/Iteration                   859\n",
      "Evaluation/MaxReturn                 -1517.08\n",
      "Evaluation/MinReturn                 -1572.07\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    17.0554\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.15354\n",
      "GaussianMLPPolicy/KL                     0.00544408\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             41.2004\n",
      "GaussianMLPPolicy/LossBefore            41.4002\n",
      "GaussianMLPPolicy/dLoss                  0.199844\n",
      "GaussianMLPValueFunction/LossAfter       6.6841\n",
      "GaussianMLPValueFunction/LossBefore      6.70836\n",
      "GaussianMLPValueFunction/dLoss           0.0242586\n",
      "TotalEnvSteps                            1.032e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:51 | [trpo_pendulum] epoch #860 | Saving snapshot...\n",
      "2022-08-17 18:13:51 | [trpo_pendulum] epoch #860 | Saved\n",
      "2022-08-17 18:13:51 | [trpo_pendulum] epoch #860 | Time 547.19 s\n",
      "2022-08-17 18:13:51 | [trpo_pendulum] epoch #860 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -554.309\n",
      "Evaluation/AverageReturn             -1418.55\n",
      "Evaluation/Iteration                   860\n",
      "Evaluation/MaxReturn                 -1348.45\n",
      "Evaluation/MinReturn                 -1489.18\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    53.916\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.11569\n",
      "GaussianMLPPolicy/KL                     0.00677666\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              9.13389\n",
      "GaussianMLPPolicy/LossBefore            10.2459\n",
      "GaussianMLPPolicy/dLoss                  1.11199\n",
      "GaussianMLPValueFunction/LossAfter       6.5433\n",
      "GaussianMLPValueFunction/LossBefore      6.55714\n",
      "GaussianMLPValueFunction/dLoss           0.0138388\n",
      "TotalEnvSteps                            1.0332e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:52 | [trpo_pendulum] epoch #861 | Saving snapshot...\n",
      "2022-08-17 18:13:52 | [trpo_pendulum] epoch #861 | Saved\n",
      "2022-08-17 18:13:52 | [trpo_pendulum] epoch #861 | Time 547.85 s\n",
      "2022-08-17 18:13:52 | [trpo_pendulum] epoch #861 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -600.511\n",
      "Evaluation/AverageReturn             -1482.46\n",
      "Evaluation/Iteration                   861\n",
      "Evaluation/MaxReturn                 -1378.08\n",
      "Evaluation/MinReturn                 -1513.83\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    47.0805\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.12181\n",
      "GaussianMLPPolicy/KL                     0.00707349\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             12.2542\n",
      "GaussianMLPPolicy/LossBefore            13.5044\n",
      "GaussianMLPPolicy/dLoss                  1.25018\n",
      "GaussianMLPValueFunction/LossAfter       6.64114\n",
      "GaussianMLPValueFunction/LossBefore      6.64181\n",
      "GaussianMLPValueFunction/dLoss           0.000669003\n",
      "TotalEnvSteps                            1.0344e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:52 | [trpo_pendulum] epoch #862 | Saving snapshot...\n",
      "2022-08-17 18:13:52 | [trpo_pendulum] epoch #862 | Saved\n",
      "2022-08-17 18:13:52 | [trpo_pendulum] epoch #862 | Time 548.48 s\n",
      "2022-08-17 18:13:52 | [trpo_pendulum] epoch #862 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -702.66\n",
      "Evaluation/AverageReturn             -1598.77\n",
      "Evaluation/Iteration                   862\n",
      "Evaluation/MaxReturn                 -1575.54\n",
      "Evaluation/MinReturn                 -1619.89\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    13.8527\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.10628\n",
      "GaussianMLPPolicy/KL                     0.00648443\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             18.0797\n",
      "GaussianMLPPolicy/LossBefore            19.8457\n",
      "GaussianMLPPolicy/dLoss                  1.76606\n",
      "GaussianMLPValueFunction/LossAfter       6.68157\n",
      "GaussianMLPValueFunction/LossBefore      6.68393\n",
      "GaussianMLPValueFunction/dLoss           0.00236607\n",
      "TotalEnvSteps                            1.0356e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:53 | [trpo_pendulum] epoch #863 | Saving snapshot...\n",
      "2022-08-17 18:13:53 | [trpo_pendulum] epoch #863 | Saved\n",
      "2022-08-17 18:13:53 | [trpo_pendulum] epoch #863 | Time 549.13 s\n",
      "2022-08-17 18:13:53 | [trpo_pendulum] epoch #863 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -648.881\n",
      "Evaluation/AverageReturn             -1565.54\n",
      "Evaluation/Iteration                   863\n",
      "Evaluation/MaxReturn                 -1540.94\n",
      "Evaluation/MinReturn                 -1596.62\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    20.4811\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.1197\n",
      "GaussianMLPPolicy/KL                     0.00744812\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             43.6707\n",
      "GaussianMLPPolicy/LossBefore            45.2984\n",
      "GaussianMLPPolicy/dLoss                  1.62775\n",
      "GaussianMLPValueFunction/LossAfter       6.70083\n",
      "GaussianMLPValueFunction/LossBefore      6.73482\n",
      "GaussianMLPValueFunction/dLoss           0.0339975\n",
      "TotalEnvSteps                            1.0368e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:53 | [trpo_pendulum] epoch #864 | Saving snapshot...\n",
      "2022-08-17 18:13:53 | [trpo_pendulum] epoch #864 | Saved\n",
      "2022-08-17 18:13:53 | [trpo_pendulum] epoch #864 | Time 549.76 s\n",
      "2022-08-17 18:13:53 | [trpo_pendulum] epoch #864 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -606.256\n",
      "Evaluation/AverageReturn             -1484.7\n",
      "Evaluation/Iteration                   864\n",
      "Evaluation/MaxReturn                 -1462.96\n",
      "Evaluation/MinReturn                 -1502.02\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    14.1746\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.11457\n",
      "GaussianMLPPolicy/KL                     0.00672472\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             11.8711\n",
      "GaussianMLPPolicy/LossBefore            12.6417\n",
      "GaussianMLPPolicy/dLoss                  0.770576\n",
      "GaussianMLPValueFunction/LossAfter       6.61277\n",
      "GaussianMLPValueFunction/LossBefore      6.61505\n",
      "GaussianMLPValueFunction/dLoss           0.0022769\n",
      "TotalEnvSteps                            1.038e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:54 | [trpo_pendulum] epoch #865 | Saving snapshot...\n",
      "2022-08-17 18:13:54 | [trpo_pendulum] epoch #865 | Saved\n",
      "2022-08-17 18:13:54 | [trpo_pendulum] epoch #865 | Time 550.37 s\n",
      "2022-08-17 18:13:54 | [trpo_pendulum] epoch #865 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -589.395\n",
      "Evaluation/AverageReturn             -1474.65\n",
      "Evaluation/Iteration                   865\n",
      "Evaluation/MaxReturn                 -1425.03\n",
      "Evaluation/MinReturn                 -1511.06\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    28.3088\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.131\n",
      "GaussianMLPPolicy/KL                     0.00934228\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             11.5355\n",
      "GaussianMLPPolicy/LossBefore            14.5033\n",
      "GaussianMLPPolicy/dLoss                  2.96783\n",
      "GaussianMLPValueFunction/LossAfter       6.60272\n",
      "GaussianMLPValueFunction/LossBefore      6.61243\n",
      "GaussianMLPValueFunction/dLoss           0.0097084\n",
      "TotalEnvSteps                            1.0392e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:55 | [trpo_pendulum] epoch #866 | Saving snapshot...\n",
      "2022-08-17 18:13:55 | [trpo_pendulum] epoch #866 | Saved\n",
      "2022-08-17 18:13:55 | [trpo_pendulum] epoch #866 | Time 551.02 s\n",
      "2022-08-17 18:13:55 | [trpo_pendulum] epoch #866 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -702.142\n",
      "Evaluation/AverageReturn             -1600.24\n",
      "Evaluation/Iteration                   866\n",
      "Evaluation/MaxReturn                 -1557.78\n",
      "Evaluation/MinReturn                 -1640.42\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    27.9631\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.14643\n",
      "GaussianMLPPolicy/KL                     0.00748912\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             18.3275\n",
      "GaussianMLPPolicy/LossBefore            20.21\n",
      "GaussianMLPPolicy/dLoss                  1.88251\n",
      "GaussianMLPValueFunction/LossAfter       6.68699\n",
      "GaussianMLPValueFunction/LossBefore      6.68922\n",
      "GaussianMLPValueFunction/dLoss           0.00223064\n",
      "TotalEnvSteps                            1.0404e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:55 | [trpo_pendulum] epoch #867 | Saving snapshot...\n",
      "2022-08-17 18:13:55 | [trpo_pendulum] epoch #867 | Saved\n",
      "2022-08-17 18:13:55 | [trpo_pendulum] epoch #867 | Time 551.64 s\n",
      "2022-08-17 18:13:55 | [trpo_pendulum] epoch #867 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -693.206\n",
      "Evaluation/AverageReturn             -1571.7\n",
      "Evaluation/Iteration                   867\n",
      "Evaluation/MaxReturn                 -1540.41\n",
      "Evaluation/MinReturn                 -1595.36\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    16.5736\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.13833\n",
      "GaussianMLPPolicy/KL                     0.00637074\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             13.4663\n",
      "GaussianMLPPolicy/LossBefore            15.9569\n",
      "GaussianMLPPolicy/dLoss                  2.49052\n",
      "GaussianMLPValueFunction/LossAfter       6.67701\n",
      "GaussianMLPValueFunction/LossBefore      6.6776\n",
      "GaussianMLPValueFunction/dLoss           0.000585079\n",
      "TotalEnvSteps                            1.0416e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:56 | [trpo_pendulum] epoch #868 | Saving snapshot...\n",
      "2022-08-17 18:13:56 | [trpo_pendulum] epoch #868 | Saved\n",
      "2022-08-17 18:13:56 | [trpo_pendulum] epoch #868 | Time 552.26 s\n",
      "2022-08-17 18:13:56 | [trpo_pendulum] epoch #868 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -693.425\n",
      "Evaluation/AverageReturn             -1578.03\n",
      "Evaluation/Iteration                   868\n",
      "Evaluation/MaxReturn                 -1552.38\n",
      "Evaluation/MinReturn                 -1598.15\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    17.223\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.15191\n",
      "GaussianMLPPolicy/KL                     0.00850343\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             14.1462\n",
      "GaussianMLPPolicy/LossBefore            16.7651\n",
      "GaussianMLPPolicy/dLoss                  2.61887\n",
      "GaussianMLPValueFunction/LossAfter       6.65541\n",
      "GaussianMLPValueFunction/LossBefore      6.65555\n",
      "GaussianMLPValueFunction/dLoss           0.000139236\n",
      "TotalEnvSteps                            1.0428e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:57 | [trpo_pendulum] epoch #869 | Saving snapshot...\n",
      "2022-08-17 18:13:57 | [trpo_pendulum] epoch #869 | Saved\n",
      "2022-08-17 18:13:57 | [trpo_pendulum] epoch #869 | Time 552.91 s\n",
      "2022-08-17 18:13:57 | [trpo_pendulum] epoch #869 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -551.323\n",
      "Evaluation/AverageReturn             -1466.55\n",
      "Evaluation/Iteration                   869\n",
      "Evaluation/MaxReturn                 -1379.57\n",
      "Evaluation/MinReturn                 -1531.14\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    48.7676\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.1528\n",
      "GaussianMLPPolicy/KL                     0.00614691\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             30.7998\n",
      "GaussianMLPPolicy/LossBefore            31.8339\n",
      "GaussianMLPPolicy/dLoss                  1.03414\n",
      "GaussianMLPValueFunction/LossAfter       6.65622\n",
      "GaussianMLPValueFunction/LossBefore      6.67164\n",
      "GaussianMLPValueFunction/dLoss           0.0154204\n",
      "TotalEnvSteps                            1.044e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:57 | [trpo_pendulum] epoch #870 | Saving snapshot...\n",
      "2022-08-17 18:13:57 | [trpo_pendulum] epoch #870 | Saved\n",
      "2022-08-17 18:13:57 | [trpo_pendulum] epoch #870 | Time 553.56 s\n",
      "2022-08-17 18:13:57 | [trpo_pendulum] epoch #870 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -613.286\n",
      "Evaluation/AverageReturn             -1507.94\n",
      "Evaluation/Iteration                   870\n",
      "Evaluation/MaxReturn                 -1482.41\n",
      "Evaluation/MinReturn                 -1523.9\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    14.2865\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.14444\n",
      "GaussianMLPPolicy/KL                     0.00949953\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             15.0856\n",
      "GaussianMLPPolicy/LossBefore            17.1802\n",
      "GaussianMLPPolicy/dLoss                  2.09457\n",
      "GaussianMLPValueFunction/LossAfter       6.6024\n",
      "GaussianMLPValueFunction/LossBefore      6.61638\n",
      "GaussianMLPValueFunction/dLoss           0.0139799\n",
      "TotalEnvSteps                            1.0452e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:13:58 | [trpo_pendulum] epoch #871 | Saving snapshot...\n",
      "2022-08-17 18:13:58 | [trpo_pendulum] epoch #871 | Saved\n",
      "2022-08-17 18:13:58 | [trpo_pendulum] epoch #871 | Time 554.21 s\n",
      "2022-08-17 18:13:58 | [trpo_pendulum] epoch #871 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -662.636\n",
      "Evaluation/AverageReturn             -1551.19\n",
      "Evaluation/Iteration                   871\n",
      "Evaluation/MaxReturn                 -1533.81\n",
      "Evaluation/MinReturn                 -1571.57\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    13.2376\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.12702\n",
      "GaussianMLPPolicy/KL                     0.00708933\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             15.5861\n",
      "GaussianMLPPolicy/LossBefore            16.8267\n",
      "GaussianMLPPolicy/dLoss                  1.24059\n",
      "GaussianMLPValueFunction/LossAfter       6.65997\n",
      "GaussianMLPValueFunction/LossBefore      6.66047\n",
      "GaussianMLPValueFunction/dLoss           0.000501156\n",
      "TotalEnvSteps                            1.0464e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:59 | [trpo_pendulum] epoch #872 | Saving snapshot...\n",
      "2022-08-17 18:13:59 | [trpo_pendulum] epoch #872 | Saved\n",
      "2022-08-17 18:13:59 | [trpo_pendulum] epoch #872 | Time 554.85 s\n",
      "2022-08-17 18:13:59 | [trpo_pendulum] epoch #872 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -686.558\n",
      "Evaluation/AverageReturn             -1576.34\n",
      "Evaluation/Iteration                   872\n",
      "Evaluation/MaxReturn                 -1555.84\n",
      "Evaluation/MinReturn                 -1585.28\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    11.0586\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.15049\n",
      "GaussianMLPPolicy/KL                     0.00896209\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             15.7627\n",
      "GaussianMLPPolicy/LossBefore            18.3299\n",
      "GaussianMLPPolicy/dLoss                  2.56715\n",
      "GaussianMLPValueFunction/LossAfter       6.6764\n",
      "GaussianMLPValueFunction/LossBefore      6.67713\n",
      "GaussianMLPValueFunction/dLoss           0.000735283\n",
      "TotalEnvSteps                            1.0476e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:13:59 | [trpo_pendulum] epoch #873 | Saving snapshot...\n",
      "2022-08-17 18:13:59 | [trpo_pendulum] epoch #873 | Saved\n",
      "2022-08-17 18:13:59 | [trpo_pendulum] epoch #873 | Time 555.50 s\n",
      "2022-08-17 18:13:59 | [trpo_pendulum] epoch #873 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -703.257\n",
      "Evaluation/AverageReturn             -1604.08\n",
      "Evaluation/Iteration                   873\n",
      "Evaluation/MaxReturn                 -1573.75\n",
      "Evaluation/MinReturn                 -1633.18\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    19.6102\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.15999\n",
      "GaussianMLPPolicy/KL                     0.00660146\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             19.232\n",
      "GaussianMLPPolicy/LossBefore            21.1844\n",
      "GaussianMLPPolicy/dLoss                  1.95233\n",
      "GaussianMLPValueFunction/LossAfter       6.68286\n",
      "GaussianMLPValueFunction/LossBefore      6.68323\n",
      "GaussianMLPValueFunction/dLoss           0.000368118\n",
      "TotalEnvSteps                            1.0488e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:14:00 | [trpo_pendulum] epoch #874 | Saving snapshot...\n",
      "2022-08-17 18:14:00 | [trpo_pendulum] epoch #874 | Saved\n",
      "2022-08-17 18:14:00 | [trpo_pendulum] epoch #874 | Time 556.14 s\n",
      "2022-08-17 18:14:00 | [trpo_pendulum] epoch #874 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -682.66\n",
      "Evaluation/AverageReturn             -1577.63\n",
      "Evaluation/Iteration                   874\n",
      "Evaluation/MaxReturn                 -1555.68\n",
      "Evaluation/MinReturn                 -1589.21\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    11.0801\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.1389\n",
      "GaussianMLPPolicy/KL                     0.0070356\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             17.4215\n",
      "GaussianMLPPolicy/LossBefore            19.2833\n",
      "GaussianMLPPolicy/dLoss                  1.86178\n",
      "GaussianMLPValueFunction/LossAfter       6.67272\n",
      "GaussianMLPValueFunction/LossBefore      6.67273\n",
      "GaussianMLPValueFunction/dLoss           1.7643e-05\n",
      "TotalEnvSteps                            1.05e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:00 | [trpo_pendulum] epoch #875 | Saving snapshot...\n",
      "2022-08-17 18:14:01 | [trpo_pendulum] epoch #875 | Saved\n",
      "2022-08-17 18:14:01 | [trpo_pendulum] epoch #875 | Time 556.79 s\n",
      "2022-08-17 18:14:01 | [trpo_pendulum] epoch #875 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -617.538\n",
      "Evaluation/AverageReturn             -1511.04\n",
      "Evaluation/Iteration                   875\n",
      "Evaluation/MaxReturn                 -1498.85\n",
      "Evaluation/MinReturn                 -1522.23\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     8.03788\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.16087\n",
      "GaussianMLPPolicy/KL                     0.00560869\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             16.1436\n",
      "GaussianMLPPolicy/LossBefore            16.9063\n",
      "GaussianMLPPolicy/dLoss                  0.762697\n",
      "GaussianMLPValueFunction/LossAfter       6.65528\n",
      "GaussianMLPValueFunction/LossBefore      6.6555\n",
      "GaussianMLPValueFunction/dLoss           0.000216484\n",
      "TotalEnvSteps                            1.0512e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:14:01 | [trpo_pendulum] epoch #876 | Saving snapshot...\n",
      "2022-08-17 18:14:01 | [trpo_pendulum] epoch #876 | Saved\n",
      "2022-08-17 18:14:01 | [trpo_pendulum] epoch #876 | Time 557.45 s\n",
      "2022-08-17 18:14:01 | [trpo_pendulum] epoch #876 | EpochTime 0.66 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -666.947\n",
      "Evaluation/AverageReturn             -1536.46\n",
      "Evaluation/Iteration                   876\n",
      "Evaluation/MaxReturn                 -1518.94\n",
      "Evaluation/MinReturn                 -1583.76\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    21.8889\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.18464\n",
      "GaussianMLPPolicy/KL                     0.00781606\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             10.6003\n",
      "GaussianMLPPolicy/LossBefore            12.6068\n",
      "GaussianMLPPolicy/dLoss                  2.00652\n",
      "GaussianMLPValueFunction/LossAfter       6.63745\n",
      "GaussianMLPValueFunction/LossBefore      6.63834\n",
      "GaussianMLPValueFunction/dLoss           0.000894547\n",
      "TotalEnvSteps                            1.0524e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:14:02 | [trpo_pendulum] epoch #877 | Saving snapshot...\n",
      "2022-08-17 18:14:02 | [trpo_pendulum] epoch #877 | Saved\n",
      "2022-08-17 18:14:02 | [trpo_pendulum] epoch #877 | Time 558.09 s\n",
      "2022-08-17 18:14:02 | [trpo_pendulum] epoch #877 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -615.693\n",
      "Evaluation/AverageReturn             -1488.53\n",
      "Evaluation/Iteration                   877\n",
      "Evaluation/MaxReturn                 -1399.06\n",
      "Evaluation/MinReturn                 -1553.15\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    59.5311\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.19318\n",
      "GaussianMLPPolicy/KL                     0.00682732\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             15.0267\n",
      "GaussianMLPPolicy/LossBefore            16.6633\n",
      "GaussianMLPPolicy/dLoss                  1.63668\n",
      "GaussianMLPValueFunction/LossAfter       6.58541\n",
      "GaussianMLPValueFunction/LossBefore      6.59538\n",
      "GaussianMLPValueFunction/dLoss           0.00996971\n",
      "TotalEnvSteps                            1.0536e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:02 | [trpo_pendulum] epoch #878 | Saving snapshot...\n",
      "2022-08-17 18:14:02 | [trpo_pendulum] epoch #878 | Saved\n",
      "2022-08-17 18:14:02 | [trpo_pendulum] epoch #878 | Time 558.71 s\n",
      "2022-08-17 18:14:02 | [trpo_pendulum] epoch #878 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -665.997\n",
      "Evaluation/AverageReturn             -1550.48\n",
      "Evaluation/Iteration                   878\n",
      "Evaluation/MaxReturn                 -1526.73\n",
      "Evaluation/MinReturn                 -1562.93\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    11.8606\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.1877\n",
      "GaussianMLPPolicy/KL                     0.00987408\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             15.3023\n",
      "GaussianMLPPolicy/LossBefore            16.681\n",
      "GaussianMLPPolicy/dLoss                  1.37866\n",
      "GaussianMLPValueFunction/LossAfter       6.65835\n",
      "GaussianMLPValueFunction/LossBefore      6.65929\n",
      "GaussianMLPValueFunction/dLoss           0.000941753\n",
      "TotalEnvSteps                            1.0548e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:14:03 | [trpo_pendulum] epoch #879 | Saving snapshot...\n",
      "2022-08-17 18:14:03 | [trpo_pendulum] epoch #879 | Saved\n",
      "2022-08-17 18:14:03 | [trpo_pendulum] epoch #879 | Time 559.33 s\n",
      "2022-08-17 18:14:03 | [trpo_pendulum] epoch #879 | EpochTime 0.61 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -613.448\n",
      "Evaluation/AverageReturn             -1502.45\n",
      "Evaluation/Iteration                   879\n",
      "Evaluation/MaxReturn                 -1490.89\n",
      "Evaluation/MinReturn                 -1509.28\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     6.59525\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.20868\n",
      "GaussianMLPPolicy/KL                     0.00940544\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             14.4759\n",
      "GaussianMLPPolicy/LossBefore            15.9261\n",
      "GaussianMLPPolicy/dLoss                  1.45015\n",
      "GaussianMLPValueFunction/LossAfter       6.63273\n",
      "GaussianMLPValueFunction/LossBefore      6.6328\n",
      "GaussianMLPValueFunction/dLoss           7.24792e-05\n",
      "TotalEnvSteps                            1.056e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:14:04 | [trpo_pendulum] epoch #880 | Saving snapshot...\n",
      "2022-08-17 18:14:04 | [trpo_pendulum] epoch #880 | Saved\n",
      "2022-08-17 18:14:04 | [trpo_pendulum] epoch #880 | Time 559.97 s\n",
      "2022-08-17 18:14:04 | [trpo_pendulum] epoch #880 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -677.864\n",
      "Evaluation/AverageReturn             -1628.46\n",
      "Evaluation/Iteration                   880\n",
      "Evaluation/MaxReturn                 -1614.07\n",
      "Evaluation/MinReturn                 -1640.36\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     9.50479\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.20727\n",
      "GaussianMLPPolicy/KL                     0.00841708\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             66.3232\n",
      "GaussianMLPPolicy/LossBefore            66.5014\n",
      "GaussianMLPPolicy/dLoss                  0.178276\n",
      "GaussianMLPValueFunction/LossAfter       6.70702\n",
      "GaussianMLPValueFunction/LossBefore      6.85813\n",
      "GaussianMLPValueFunction/dLoss           0.151111\n",
      "TotalEnvSteps                            1.0572e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:04 | [trpo_pendulum] epoch #881 | Saving snapshot...\n",
      "2022-08-17 18:14:04 | [trpo_pendulum] epoch #881 | Saved\n",
      "2022-08-17 18:14:04 | [trpo_pendulum] epoch #881 | Time 560.65 s\n",
      "2022-08-17 18:14:04 | [trpo_pendulum] epoch #881 | EpochTime 0.68 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -611.543\n",
      "Evaluation/AverageReturn             -1510.02\n",
      "Evaluation/Iteration                   881\n",
      "Evaluation/MaxReturn                 -1494.37\n",
      "Evaluation/MinReturn                 -1520.38\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     9.33224\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.16702\n",
      "GaussianMLPPolicy/KL                     0.00713898\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             15.8286\n",
      "GaussianMLPPolicy/LossBefore            16.8628\n",
      "GaussianMLPPolicy/dLoss                  1.03415\n",
      "GaussianMLPValueFunction/LossAfter       6.63554\n",
      "GaussianMLPValueFunction/LossBefore      6.63635\n",
      "GaussianMLPValueFunction/dLoss           0.000807285\n",
      "TotalEnvSteps                            1.0584e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:14:05 | [trpo_pendulum] epoch #882 | Saving snapshot...\n",
      "2022-08-17 18:14:05 | [trpo_pendulum] epoch #882 | Saved\n",
      "2022-08-17 18:14:05 | [trpo_pendulum] epoch #882 | Time 561.28 s\n",
      "2022-08-17 18:14:05 | [trpo_pendulum] epoch #882 | EpochTime 0.63 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -612.832\n",
      "Evaluation/AverageReturn             -1506.82\n",
      "Evaluation/Iteration                   882\n",
      "Evaluation/MaxReturn                 -1493.7\n",
      "Evaluation/MinReturn                 -1521.75\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     9.27306\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.18419\n",
      "GaussianMLPPolicy/KL                     0.00979061\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             16.8401\n",
      "GaussianMLPPolicy/LossBefore            17.2447\n",
      "GaussianMLPPolicy/dLoss                  0.404522\n",
      "GaussianMLPValueFunction/LossAfter       6.64031\n",
      "GaussianMLPValueFunction/LossBefore      6.64049\n",
      "GaussianMLPValueFunction/dLoss           0.000187397\n",
      "TotalEnvSteps                            1.0596e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:14:06 | [trpo_pendulum] epoch #883 | Saving snapshot...\n",
      "2022-08-17 18:14:06 | [trpo_pendulum] epoch #883 | Saved\n",
      "2022-08-17 18:14:06 | [trpo_pendulum] epoch #883 | Time 561.92 s\n",
      "2022-08-17 18:14:06 | [trpo_pendulum] epoch #883 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -517.586\n",
      "Evaluation/AverageReturn             -1406.32\n",
      "Evaluation/Iteration                   883\n",
      "Evaluation/MaxReturn                 -1374.66\n",
      "Evaluation/MinReturn                 -1509.38\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    47.3752\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.17507\n",
      "GaussianMLPPolicy/KL                     0.00778525\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             10.562\n",
      "GaussianMLPPolicy/LossBefore            12.0169\n",
      "GaussianMLPPolicy/dLoss                  1.4549\n",
      "GaussianMLPValueFunction/LossAfter       6.62118\n",
      "GaussianMLPValueFunction/LossBefore      6.62249\n",
      "GaussianMLPValueFunction/dLoss           0.00131083\n",
      "TotalEnvSteps                            1.0608e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:06 | [trpo_pendulum] epoch #884 | Saving snapshot...\n",
      "2022-08-17 18:14:06 | [trpo_pendulum] epoch #884 | Saved\n",
      "2022-08-17 18:14:06 | [trpo_pendulum] epoch #884 | Time 562.59 s\n",
      "2022-08-17 18:14:06 | [trpo_pendulum] epoch #884 | EpochTime 0.67 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -677.297\n",
      "Evaluation/AverageReturn             -1548.87\n",
      "Evaluation/Iteration                   884\n",
      "Evaluation/MaxReturn                 -1540.93\n",
      "Evaluation/MinReturn                 -1568.23\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     9.22684\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.16375\n",
      "GaussianMLPPolicy/KL                     0.0081464\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             11.6956\n",
      "GaussianMLPPolicy/LossBefore            13.4095\n",
      "GaussianMLPPolicy/dLoss                  1.71396\n",
      "GaussianMLPValueFunction/LossAfter       6.64412\n",
      "GaussianMLPValueFunction/LossBefore      6.64453\n",
      "GaussianMLPValueFunction/dLoss           0.000402927\n",
      "TotalEnvSteps                            1.062e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:14:07 | [trpo_pendulum] epoch #885 | Saving snapshot...\n",
      "2022-08-17 18:14:07 | [trpo_pendulum] epoch #885 | Saved\n",
      "2022-08-17 18:14:07 | [trpo_pendulum] epoch #885 | Time 563.23 s\n",
      "2022-08-17 18:14:07 | [trpo_pendulum] epoch #885 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -655.201\n",
      "Evaluation/AverageReturn             -1514.87\n",
      "Evaluation/Iteration                   885\n",
      "Evaluation/MaxReturn                 -1502.43\n",
      "Evaluation/MinReturn                 -1536.29\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    12.0894\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.18654\n",
      "GaussianMLPPolicy/KL                     0.00579834\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              9.03549\n",
      "GaussianMLPPolicy/LossBefore            10.4706\n",
      "GaussianMLPPolicy/dLoss                  1.4351\n",
      "GaussianMLPValueFunction/LossAfter       6.62898\n",
      "GaussianMLPValueFunction/LossBefore      6.62972\n",
      "GaussianMLPValueFunction/dLoss           0.000733376\n",
      "TotalEnvSteps                            1.0632e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:14:08 | [trpo_pendulum] epoch #886 | Saving snapshot...\n",
      "2022-08-17 18:14:08 | [trpo_pendulum] epoch #886 | Saved\n",
      "2022-08-17 18:14:08 | [trpo_pendulum] epoch #886 | Time 563.86 s\n",
      "2022-08-17 18:14:08 | [trpo_pendulum] epoch #886 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -572.745\n",
      "Evaluation/AverageReturn             -1392.4\n",
      "Evaluation/Iteration                   886\n",
      "Evaluation/MaxReturn                 -1365.33\n",
      "Evaluation/MinReturn                 -1448.86\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    26.5459\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.17639\n",
      "GaussianMLPPolicy/KL                     0.00888953\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -1.33906\n",
      "GaussianMLPPolicy/LossBefore             0.132369\n",
      "GaussianMLPPolicy/dLoss                  1.47143\n",
      "GaussianMLPValueFunction/LossAfter       6.61095\n",
      "GaussianMLPValueFunction/LossBefore      6.6137\n",
      "GaussianMLPValueFunction/dLoss           0.00274181\n",
      "TotalEnvSteps                            1.0644e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:08 | [trpo_pendulum] epoch #887 | Saving snapshot...\n",
      "2022-08-17 18:14:08 | [trpo_pendulum] epoch #887 | Saved\n",
      "2022-08-17 18:14:08 | [trpo_pendulum] epoch #887 | Time 564.48 s\n",
      "2022-08-17 18:14:08 | [trpo_pendulum] epoch #887 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -669.614\n",
      "Evaluation/AverageReturn             -1549.71\n",
      "Evaluation/Iteration                   887\n",
      "Evaluation/MaxReturn                 -1535.51\n",
      "Evaluation/MinReturn                 -1561.99\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     8.91296\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.18235\n",
      "GaussianMLPPolicy/KL                     0.00929123\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             15.9204\n",
      "GaussianMLPPolicy/LossBefore            17.8312\n",
      "GaussianMLPPolicy/dLoss                  1.91083\n",
      "GaussianMLPValueFunction/LossAfter       6.67175\n",
      "GaussianMLPValueFunction/LossBefore      6.67335\n",
      "GaussianMLPValueFunction/dLoss           0.00159264\n",
      "TotalEnvSteps                            1.0656e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:09 | [trpo_pendulum] epoch #888 | Saving snapshot...\n",
      "2022-08-17 18:14:09 | [trpo_pendulum] epoch #888 | Saved\n",
      "2022-08-17 18:14:09 | [trpo_pendulum] epoch #888 | Time 565.13 s\n",
      "2022-08-17 18:14:09 | [trpo_pendulum] epoch #888 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -600.699\n",
      "Evaluation/AverageReturn             -1511.45\n",
      "Evaluation/Iteration                   888\n",
      "Evaluation/MaxReturn                 -1495.66\n",
      "Evaluation/MinReturn                 -1523.54\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     8.8191\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.20656\n",
      "GaussianMLPPolicy/KL                     0.00759084\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             21.2893\n",
      "GaussianMLPPolicy/LossBefore            22.9039\n",
      "GaussianMLPPolicy/dLoss                  1.61467\n",
      "GaussianMLPValueFunction/LossAfter       6.65563\n",
      "GaussianMLPValueFunction/LossBefore      6.65582\n",
      "GaussianMLPValueFunction/dLoss           0.000188828\n",
      "TotalEnvSteps                            1.0668e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:14:09 | [trpo_pendulum] epoch #889 | Saving snapshot...\n",
      "2022-08-17 18:14:09 | [trpo_pendulum] epoch #889 | Saved\n",
      "2022-08-17 18:14:09 | [trpo_pendulum] epoch #889 | Time 565.76 s\n",
      "2022-08-17 18:14:09 | [trpo_pendulum] epoch #889 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -607.65\n",
      "Evaluation/AverageReturn             -1539.29\n",
      "Evaluation/Iteration                   889\n",
      "Evaluation/MaxReturn                 -1525.91\n",
      "Evaluation/MinReturn                 -1575.81\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    17.5222\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.21529\n",
      "GaussianMLPPolicy/KL                     0.00896414\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             28.012\n",
      "GaussianMLPPolicy/LossBefore            29.696\n",
      "GaussianMLPPolicy/dLoss                  1.68398\n",
      "GaussianMLPValueFunction/LossAfter       6.70914\n",
      "GaussianMLPValueFunction/LossBefore      6.71302\n",
      "GaussianMLPValueFunction/dLoss           0.0038867\n",
      "TotalEnvSteps                            1.068e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:10 | [trpo_pendulum] epoch #890 | Saving snapshot...\n",
      "2022-08-17 18:14:10 | [trpo_pendulum] epoch #890 | Saved\n",
      "2022-08-17 18:14:10 | [trpo_pendulum] epoch #890 | Time 566.41 s\n",
      "2022-08-17 18:14:10 | [trpo_pendulum] epoch #890 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -652.363\n",
      "Evaluation/AverageReturn             -1518.01\n",
      "Evaluation/Iteration                   890\n",
      "Evaluation/MaxReturn                 -1492.31\n",
      "Evaluation/MinReturn                 -1551.89\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    19.4961\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.20461\n",
      "GaussianMLPPolicy/KL                     0.00677826\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             11.3352\n",
      "GaussianMLPPolicy/LossBefore            13.4523\n",
      "GaussianMLPPolicy/dLoss                  2.11714\n",
      "GaussianMLPValueFunction/LossAfter       6.65225\n",
      "GaussianMLPValueFunction/LossBefore      6.65293\n",
      "GaussianMLPValueFunction/dLoss           0.000678539\n",
      "TotalEnvSteps                            1.0692e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:14:11 | [trpo_pendulum] epoch #891 | Saving snapshot...\n",
      "2022-08-17 18:14:11 | [trpo_pendulum] epoch #891 | Saved\n",
      "2022-08-17 18:14:11 | [trpo_pendulum] epoch #891 | Time 567.03 s\n",
      "2022-08-17 18:14:11 | [trpo_pendulum] epoch #891 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -587.075\n",
      "Evaluation/AverageReturn             -1466.75\n",
      "Evaluation/Iteration                   891\n",
      "Evaluation/MaxReturn                 -1278.17\n",
      "Evaluation/MinReturn                 -1540.38\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    88.0218\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.19573\n",
      "GaussianMLPPolicy/KL                     0.00741511\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             13.0268\n",
      "GaussianMLPPolicy/LossBefore            13.9727\n",
      "GaussianMLPPolicy/dLoss                  0.945912\n",
      "GaussianMLPValueFunction/LossAfter       6.58344\n",
      "GaussianMLPValueFunction/LossBefore      6.60129\n",
      "GaussianMLPValueFunction/dLoss           0.0178466\n",
      "TotalEnvSteps                            1.0704e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:11 | [trpo_pendulum] epoch #892 | Saving snapshot...\n",
      "2022-08-17 18:14:11 | [trpo_pendulum] epoch #892 | Saved\n",
      "2022-08-17 18:14:11 | [trpo_pendulum] epoch #892 | Time 567.67 s\n",
      "2022-08-17 18:14:11 | [trpo_pendulum] epoch #892 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -562.14\n",
      "Evaluation/AverageReturn             -1435.52\n",
      "Evaluation/Iteration                   892\n",
      "Evaluation/MaxReturn                 -1071.05\n",
      "Evaluation/MinReturn                 -1523.52\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                   163.336\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.21444\n",
      "GaussianMLPPolicy/KL                     0.00627337\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             19.0898\n",
      "GaussianMLPPolicy/LossBefore            20.2606\n",
      "GaussianMLPPolicy/dLoss                  1.17084\n",
      "GaussianMLPValueFunction/LossAfter       6.60266\n",
      "GaussianMLPValueFunction/LossBefore      6.60454\n",
      "GaussianMLPValueFunction/dLoss           0.00188208\n",
      "TotalEnvSteps                            1.0716e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:12 | [trpo_pendulum] epoch #893 | Saving snapshot...\n",
      "2022-08-17 18:14:12 | [trpo_pendulum] epoch #893 | Saved\n",
      "2022-08-17 18:14:12 | [trpo_pendulum] epoch #893 | Time 568.33 s\n",
      "2022-08-17 18:14:12 | [trpo_pendulum] epoch #893 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -586.752\n",
      "Evaluation/AverageReturn             -1417.71\n",
      "Evaluation/Iteration                   893\n",
      "Evaluation/MaxReturn                 -1277.38\n",
      "Evaluation/MinReturn                 -1503.98\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    81.2295\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.22318\n",
      "GaussianMLPPolicy/KL                     0.00644794\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              1.57095\n",
      "GaussianMLPPolicy/LossBefore             2.63875\n",
      "GaussianMLPPolicy/dLoss                  1.0678\n",
      "GaussianMLPValueFunction/LossAfter       6.55223\n",
      "GaussianMLPValueFunction/LossBefore      6.55845\n",
      "GaussianMLPValueFunction/dLoss           0.00622272\n",
      "TotalEnvSteps                            1.0728e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:13 | [trpo_pendulum] epoch #894 | Saving snapshot...\n",
      "2022-08-17 18:14:13 | [trpo_pendulum] epoch #894 | Saved\n",
      "2022-08-17 18:14:13 | [trpo_pendulum] epoch #894 | Time 568.95 s\n",
      "2022-08-17 18:14:13 | [trpo_pendulum] epoch #894 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -484.534\n",
      "Evaluation/AverageReturn             -1248.87\n",
      "Evaluation/Iteration                   894\n",
      "Evaluation/MaxReturn                 -1199.47\n",
      "Evaluation/MinReturn                 -1303.33\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    38.1916\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.21337\n",
      "GaussianMLPPolicy/KL                     0.00848852\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -15.4929\n",
      "GaussianMLPPolicy/LossBefore           -14.0577\n",
      "GaussianMLPPolicy/dLoss                  1.43521\n",
      "GaussianMLPValueFunction/LossAfter       6.56879\n",
      "GaussianMLPValueFunction/LossBefore      6.57544\n",
      "GaussianMLPValueFunction/dLoss           0.00664902\n",
      "TotalEnvSteps                            1.074e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:13 | [trpo_pendulum] epoch #895 | Saving snapshot...\n",
      "2022-08-17 18:14:13 | [trpo_pendulum] epoch #895 | Saved\n",
      "2022-08-17 18:14:13 | [trpo_pendulum] epoch #895 | Time 569.57 s\n",
      "2022-08-17 18:14:13 | [trpo_pendulum] epoch #895 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -672.724\n",
      "Evaluation/AverageReturn             -1531.83\n",
      "Evaluation/Iteration                   895\n",
      "Evaluation/MaxReturn                 -1516.27\n",
      "Evaluation/MinReturn                 -1543.74\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     9.39145\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.2185\n",
      "GaussianMLPPolicy/KL                     0.00707683\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             12.3103\n",
      "GaussianMLPPolicy/LossBefore            13.3668\n",
      "GaussianMLPPolicy/dLoss                  1.05645\n",
      "GaussianMLPValueFunction/LossAfter       6.63525\n",
      "GaussianMLPValueFunction/LossBefore      6.63764\n",
      "GaussianMLPValueFunction/dLoss           0.00238848\n",
      "TotalEnvSteps                            1.0752e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:14 | [trpo_pendulum] epoch #896 | Saving snapshot...\n",
      "2022-08-17 18:14:14 | [trpo_pendulum] epoch #896 | Saved\n",
      "2022-08-17 18:14:14 | [trpo_pendulum] epoch #896 | Time 570.20 s\n",
      "2022-08-17 18:14:14 | [trpo_pendulum] epoch #896 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -654.885\n",
      "Evaluation/AverageReturn             -1515.4\n",
      "Evaluation/Iteration                   896\n",
      "Evaluation/MaxReturn                 -1507.65\n",
      "Evaluation/MinReturn                 -1522.94\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     5.04444\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.21824\n",
      "GaussianMLPPolicy/KL                     0.006104\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             12.1706\n",
      "GaussianMLPPolicy/LossBefore            13.7539\n",
      "GaussianMLPPolicy/dLoss                  1.58322\n",
      "GaussianMLPValueFunction/LossAfter       6.62895\n",
      "GaussianMLPValueFunction/LossBefore      6.62959\n",
      "GaussianMLPValueFunction/dLoss           0.000641823\n",
      "TotalEnvSteps                            1.0764e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:14:15 | [trpo_pendulum] epoch #897 | Saving snapshot...\n",
      "2022-08-17 18:14:15 | [trpo_pendulum] epoch #897 | Saved\n",
      "2022-08-17 18:14:15 | [trpo_pendulum] epoch #897 | Time 570.81 s\n",
      "2022-08-17 18:14:15 | [trpo_pendulum] epoch #897 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -551.579\n",
      "Evaluation/AverageReturn             -1438.39\n",
      "Evaluation/Iteration                   897\n",
      "Evaluation/MaxReturn                 -1371.2\n",
      "Evaluation/MinReturn                 -1492.73\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    41.5603\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.23457\n",
      "GaussianMLPPolicy/KL                     0.00894984\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             18.2397\n",
      "GaussianMLPPolicy/LossBefore            20.6898\n",
      "GaussianMLPPolicy/dLoss                  2.45005\n",
      "GaussianMLPValueFunction/LossAfter       6.58188\n",
      "GaussianMLPValueFunction/LossBefore      6.58955\n",
      "GaussianMLPValueFunction/dLoss           0.00766945\n",
      "TotalEnvSteps                            1.0776e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:15 | [trpo_pendulum] epoch #898 | Saving snapshot...\n",
      "2022-08-17 18:14:15 | [trpo_pendulum] epoch #898 | Saved\n",
      "2022-08-17 18:14:15 | [trpo_pendulum] epoch #898 | Time 571.46 s\n",
      "2022-08-17 18:14:15 | [trpo_pendulum] epoch #898 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -667.964\n",
      "Evaluation/AverageReturn             -1595.67\n",
      "Evaluation/Iteration                   898\n",
      "Evaluation/MaxReturn                 -1545.74\n",
      "Evaluation/MinReturn                 -1627.5\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    32.1481\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.2635\n",
      "GaussianMLPPolicy/KL                     0.00886637\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             28.0954\n",
      "GaussianMLPPolicy/LossBefore            29.6745\n",
      "GaussianMLPPolicy/dLoss                  1.57907\n",
      "GaussianMLPValueFunction/LossAfter       6.70473\n",
      "GaussianMLPValueFunction/LossBefore      6.71276\n",
      "GaussianMLPValueFunction/dLoss           0.00803137\n",
      "TotalEnvSteps                            1.0788e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:16 | [trpo_pendulum] epoch #899 | Saving snapshot...\n",
      "2022-08-17 18:14:16 | [trpo_pendulum] epoch #899 | Saved\n",
      "2022-08-17 18:14:16 | [trpo_pendulum] epoch #899 | Time 572.08 s\n",
      "2022-08-17 18:14:16 | [trpo_pendulum] epoch #899 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -656.084\n",
      "Evaluation/AverageReturn             -1514.28\n",
      "Evaluation/Iteration                   899\n",
      "Evaluation/MaxReturn                 -1508.48\n",
      "Evaluation/MinReturn                 -1520.15\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     4.70962\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.25876\n",
      "GaussianMLPPolicy/KL                     0.00550056\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             12.7072\n",
      "GaussianMLPPolicy/LossBefore            13.1329\n",
      "GaussianMLPPolicy/dLoss                  0.425721\n",
      "GaussianMLPValueFunction/LossAfter       6.63628\n",
      "GaussianMLPValueFunction/LossBefore      6.63659\n",
      "GaussianMLPValueFunction/dLoss           0.000309467\n",
      "TotalEnvSteps                            1.08e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:14:16 | [trpo_pendulum] epoch #900 | Saving snapshot...\n",
      "2022-08-17 18:14:16 | [trpo_pendulum] epoch #900 | Saved\n",
      "2022-08-17 18:14:16 | [trpo_pendulum] epoch #900 | Time 572.73 s\n",
      "2022-08-17 18:14:16 | [trpo_pendulum] epoch #900 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -646.856\n",
      "Evaluation/AverageReturn             -1578.21\n",
      "Evaluation/Iteration                   900\n",
      "Evaluation/MaxReturn                 -1552.47\n",
      "Evaluation/MinReturn                 -1599.6\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    15.6808\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.28102\n",
      "GaussianMLPPolicy/KL                     0.00676004\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             27.237\n",
      "GaussianMLPPolicy/LossBefore            29.2841\n",
      "GaussianMLPPolicy/dLoss                  2.04712\n",
      "GaussianMLPValueFunction/LossAfter       6.70415\n",
      "GaussianMLPValueFunction/LossBefore      6.70738\n",
      "GaussianMLPValueFunction/dLoss           0.00322962\n",
      "TotalEnvSteps                            1.0812e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:17 | [trpo_pendulum] epoch #901 | Saving snapshot...\n",
      "2022-08-17 18:14:17 | [trpo_pendulum] epoch #901 | Saved\n",
      "2022-08-17 18:14:17 | [trpo_pendulum] epoch #901 | Time 573.40 s\n",
      "2022-08-17 18:14:17 | [trpo_pendulum] epoch #901 | EpochTime 0.67 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -653.428\n",
      "Evaluation/AverageReturn             -1594.8\n",
      "Evaluation/Iteration                   901\n",
      "Evaluation/MaxReturn                 -1582.15\n",
      "Evaluation/MinReturn                 -1605.52\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     7.93055\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.25782\n",
      "GaussianMLPPolicy/KL                     0.00863306\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             30.8789\n",
      "GaussianMLPPolicy/LossBefore            32.3548\n",
      "GaussianMLPPolicy/dLoss                  1.4759\n",
      "GaussianMLPValueFunction/LossAfter       6.72219\n",
      "GaussianMLPValueFunction/LossBefore      6.72494\n",
      "GaussianMLPValueFunction/dLoss           0.00275946\n",
      "TotalEnvSteps                            1.0824e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:18 | [trpo_pendulum] epoch #902 | Saving snapshot...\n",
      "2022-08-17 18:14:18 | [trpo_pendulum] epoch #902 | Saved\n",
      "2022-08-17 18:14:18 | [trpo_pendulum] epoch #902 | Time 574.04 s\n",
      "2022-08-17 18:14:18 | [trpo_pendulum] epoch #902 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -653.101\n",
      "Evaluation/AverageReturn             -1514.31\n",
      "Evaluation/Iteration                   902\n",
      "Evaluation/MaxReturn                 -1502.91\n",
      "Evaluation/MinReturn                 -1524.27\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     8.67739\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.25323\n",
      "GaussianMLPPolicy/KL                     0.00892316\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             11.3744\n",
      "GaussianMLPPolicy/LossBefore            12.8408\n",
      "GaussianMLPPolicy/dLoss                  1.46641\n",
      "GaussianMLPValueFunction/LossAfter       6.63308\n",
      "GaussianMLPValueFunction/LossBefore      6.6356\n",
      "GaussianMLPValueFunction/dLoss           0.00252008\n",
      "TotalEnvSteps                            1.0836e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:18 | [trpo_pendulum] epoch #903 | Saving snapshot...\n",
      "2022-08-17 18:14:18 | [trpo_pendulum] epoch #903 | Saved\n",
      "2022-08-17 18:14:18 | [trpo_pendulum] epoch #903 | Time 574.68 s\n",
      "2022-08-17 18:14:18 | [trpo_pendulum] epoch #903 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -593.007\n",
      "Evaluation/AverageReturn             -1515.87\n",
      "Evaluation/Iteration                   903\n",
      "Evaluation/MaxReturn                 -1313.18\n",
      "Evaluation/MinReturn                 -1567.3\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    91.211\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.27797\n",
      "GaussianMLPPolicy/KL                     0.00869762\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             36.0583\n",
      "GaussianMLPPolicy/LossBefore            38.1119\n",
      "GaussianMLPPolicy/dLoss                  2.05357\n",
      "GaussianMLPValueFunction/LossAfter       6.70848\n",
      "GaussianMLPValueFunction/LossBefore      6.72428\n",
      "GaussianMLPValueFunction/dLoss           0.0157995\n",
      "TotalEnvSteps                            1.0848e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:19 | [trpo_pendulum] epoch #904 | Saving snapshot...\n",
      "2022-08-17 18:14:19 | [trpo_pendulum] epoch #904 | Saved\n",
      "2022-08-17 18:14:19 | [trpo_pendulum] epoch #904 | Time 575.34 s\n",
      "2022-08-17 18:14:19 | [trpo_pendulum] epoch #904 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -600.644\n",
      "Evaluation/AverageReturn             -1494.63\n",
      "Evaluation/Iteration                   904\n",
      "Evaluation/MaxReturn                 -1420.93\n",
      "Evaluation/MinReturn                 -1537.88\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    40.4872\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.26753\n",
      "GaussianMLPPolicy/KL                     0.00949611\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             12.8497\n",
      "GaussianMLPPolicy/LossBefore            15.8298\n",
      "GaussianMLPPolicy/dLoss                  2.98008\n",
      "GaussianMLPValueFunction/LossAfter       6.58387\n",
      "GaussianMLPValueFunction/LossBefore      6.59642\n",
      "GaussianMLPValueFunction/dLoss           0.0125499\n",
      "TotalEnvSteps                            1.086e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:20 | [trpo_pendulum] epoch #905 | Saving snapshot...\n",
      "2022-08-17 18:14:20 | [trpo_pendulum] epoch #905 | Saved\n",
      "2022-08-17 18:14:20 | [trpo_pendulum] epoch #905 | Time 575.98 s\n",
      "2022-08-17 18:14:20 | [trpo_pendulum] epoch #905 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -563.193\n",
      "Evaluation/AverageReturn             -1413.44\n",
      "Evaluation/Iteration                   905\n",
      "Evaluation/MaxReturn                 -1308.48\n",
      "Evaluation/MinReturn                 -1492.08\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    61.2503\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.26315\n",
      "GaussianMLPPolicy/KL                     0.00934729\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              9.1991\n",
      "GaussianMLPPolicy/LossBefore            11.2024\n",
      "GaussianMLPPolicy/dLoss                  2.00334\n",
      "GaussianMLPValueFunction/LossAfter       6.42248\n",
      "GaussianMLPValueFunction/LossBefore      6.47072\n",
      "GaussianMLPValueFunction/dLoss           0.0482359\n",
      "TotalEnvSteps                            1.0872e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:20 | [trpo_pendulum] epoch #906 | Saving snapshot...\n",
      "2022-08-17 18:14:20 | [trpo_pendulum] epoch #906 | Saved\n",
      "2022-08-17 18:14:20 | [trpo_pendulum] epoch #906 | Time 576.62 s\n",
      "2022-08-17 18:14:20 | [trpo_pendulum] epoch #906 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -660.56\n",
      "Evaluation/AverageReturn             -1607.27\n",
      "Evaluation/Iteration                   906\n",
      "Evaluation/MaxReturn                 -1578.44\n",
      "Evaluation/MinReturn                 -1613.86\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    12.9095\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.28842\n",
      "GaussianMLPPolicy/KL                     0.00811364\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             30.3941\n",
      "GaussianMLPPolicy/LossBefore            32.1081\n",
      "GaussianMLPPolicy/dLoss                  1.71404\n",
      "GaussianMLPValueFunction/LossAfter       6.72912\n",
      "GaussianMLPValueFunction/LossBefore      6.74564\n",
      "GaussianMLPValueFunction/dLoss           0.0165176\n",
      "TotalEnvSteps                            1.0884e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:21 | [trpo_pendulum] epoch #907 | Saving snapshot...\n",
      "2022-08-17 18:14:21 | [trpo_pendulum] epoch #907 | Saved\n",
      "2022-08-17 18:14:21 | [trpo_pendulum] epoch #907 | Time 577.26 s\n",
      "2022-08-17 18:14:21 | [trpo_pendulum] epoch #907 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -621.361\n",
      "Evaluation/AverageReturn             -1543.45\n",
      "Evaluation/Iteration                   907\n",
      "Evaluation/MaxReturn                 -1501.34\n",
      "Evaluation/MinReturn                 -1575.97\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    29.4079\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.27842\n",
      "GaussianMLPPolicy/KL                     0.00733961\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             26.9944\n",
      "GaussianMLPPolicy/LossBefore            28.4147\n",
      "GaussianMLPPolicy/dLoss                  1.42031\n",
      "GaussianMLPValueFunction/LossAfter       6.67598\n",
      "GaussianMLPValueFunction/LossBefore      6.68847\n",
      "GaussianMLPValueFunction/dLoss           0.0124931\n",
      "TotalEnvSteps                            1.0896e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:22 | [trpo_pendulum] epoch #908 | Saving snapshot...\n",
      "2022-08-17 18:14:22 | [trpo_pendulum] epoch #908 | Saved\n",
      "2022-08-17 18:14:22 | [trpo_pendulum] epoch #908 | Time 577.90 s\n",
      "2022-08-17 18:14:22 | [trpo_pendulum] epoch #908 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -672.391\n",
      "Evaluation/AverageReturn             -1623.07\n",
      "Evaluation/Iteration                   908\n",
      "Evaluation/MaxReturn                 -1601.25\n",
      "Evaluation/MinReturn                 -1649.68\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    15.15\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.30886\n",
      "GaussianMLPPolicy/KL                     0.00772699\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             46.8057\n",
      "GaussianMLPPolicy/LossBefore            48.8843\n",
      "GaussianMLPPolicy/dLoss                  2.07857\n",
      "GaussianMLPValueFunction/LossAfter       6.70524\n",
      "GaussianMLPValueFunction/LossBefore      6.74308\n",
      "GaussianMLPValueFunction/dLoss           0.0378418\n",
      "TotalEnvSteps                            1.0908e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:22 | [trpo_pendulum] epoch #909 | Saving snapshot...\n",
      "2022-08-17 18:14:22 | [trpo_pendulum] epoch #909 | Saved\n",
      "2022-08-17 18:14:22 | [trpo_pendulum] epoch #909 | Time 578.53 s\n",
      "2022-08-17 18:14:22 | [trpo_pendulum] epoch #909 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -578.949\n",
      "Evaluation/AverageReturn             -1472.83\n",
      "Evaluation/Iteration                   909\n",
      "Evaluation/MaxReturn                 -1382.22\n",
      "Evaluation/MinReturn                 -1512.84\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    46.5769\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.29962\n",
      "GaussianMLPPolicy/KL                     0.00674141\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             10.9505\n",
      "GaussianMLPPolicy/LossBefore            12.7925\n",
      "GaussianMLPPolicy/dLoss                  1.84195\n",
      "GaussianMLPValueFunction/LossAfter       6.54617\n",
      "GaussianMLPValueFunction/LossBefore      6.57953\n",
      "GaussianMLPValueFunction/dLoss           0.0333667\n",
      "TotalEnvSteps                            1.092e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:23 | [trpo_pendulum] epoch #910 | Saving snapshot...\n",
      "2022-08-17 18:14:23 | [trpo_pendulum] epoch #910 | Saved\n",
      "2022-08-17 18:14:23 | [trpo_pendulum] epoch #910 | Time 579.19 s\n",
      "2022-08-17 18:14:23 | [trpo_pendulum] epoch #910 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -605.293\n",
      "Evaluation/AverageReturn             -1512.9\n",
      "Evaluation/Iteration                   910\n",
      "Evaluation/MaxReturn                 -1457.61\n",
      "Evaluation/MinReturn                 -1557.57\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    30.148\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.30021\n",
      "GaussianMLPPolicy/KL                     0.00854416\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             22.8683\n",
      "GaussianMLPPolicy/LossBefore            25.2174\n",
      "GaussianMLPPolicy/dLoss                  2.34914\n",
      "GaussianMLPValueFunction/LossAfter       6.64096\n",
      "GaussianMLPValueFunction/LossBefore      6.64251\n",
      "GaussianMLPValueFunction/dLoss           0.00154924\n",
      "TotalEnvSteps                            1.0932e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:24 | [trpo_pendulum] epoch #911 | Saving snapshot...\n",
      "2022-08-17 18:14:24 | [trpo_pendulum] epoch #911 | Saved\n",
      "2022-08-17 18:14:24 | [trpo_pendulum] epoch #911 | Time 579.87 s\n",
      "2022-08-17 18:14:24 | [trpo_pendulum] epoch #911 | EpochTime 0.68 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -604.388\n",
      "Evaluation/AverageReturn             -1515.44\n",
      "Evaluation/Iteration                   911\n",
      "Evaluation/MaxReturn                 -1506.85\n",
      "Evaluation/MinReturn                 -1529.37\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     7.61553\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.31065\n",
      "GaussianMLPPolicy/KL                     0.00758302\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             28.694\n",
      "GaussianMLPPolicy/LossBefore            29.6574\n",
      "GaussianMLPPolicy/dLoss                  0.963392\n",
      "GaussianMLPValueFunction/LossAfter       6.60566\n",
      "GaussianMLPValueFunction/LossBefore      6.60992\n",
      "GaussianMLPValueFunction/dLoss           0.00425816\n",
      "TotalEnvSteps                            1.0944e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:24 | [trpo_pendulum] epoch #912 | Saving snapshot...\n",
      "2022-08-17 18:14:24 | [trpo_pendulum] epoch #912 | Saved\n",
      "2022-08-17 18:14:24 | [trpo_pendulum] epoch #912 | Time 580.64 s\n",
      "2022-08-17 18:14:24 | [trpo_pendulum] epoch #912 | EpochTime 0.76 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -628.089\n",
      "Evaluation/AverageReturn             -1504.42\n",
      "Evaluation/Iteration                   912\n",
      "Evaluation/MaxReturn                 -1431.01\n",
      "Evaluation/MinReturn                 -1537.51\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    35.7539\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.31665\n",
      "GaussianMLPPolicy/KL                     0.00696627\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              8.13701\n",
      "GaussianMLPPolicy/LossBefore            10.4075\n",
      "GaussianMLPPolicy/dLoss                  2.27053\n",
      "GaussianMLPValueFunction/LossAfter       6.62192\n",
      "GaussianMLPValueFunction/LossBefore      6.62227\n",
      "GaussianMLPValueFunction/dLoss           0.000347137\n",
      "TotalEnvSteps                            1.0956e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:14:25 | [trpo_pendulum] epoch #913 | Saving snapshot...\n",
      "2022-08-17 18:14:25 | [trpo_pendulum] epoch #913 | Saved\n",
      "2022-08-17 18:14:25 | [trpo_pendulum] epoch #913 | Time 581.31 s\n",
      "2022-08-17 18:14:25 | [trpo_pendulum] epoch #913 | EpochTime 0.67 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -562.632\n",
      "Evaluation/AverageReturn             -1458.41\n",
      "Evaluation/Iteration                   913\n",
      "Evaluation/MaxReturn                 -1369.89\n",
      "Evaluation/MinReturn                 -1512.15\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    48.3956\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.31519\n",
      "GaussianMLPPolicy/KL                     0.00661445\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             21.2432\n",
      "GaussianMLPPolicy/LossBefore            22.5401\n",
      "GaussianMLPPolicy/dLoss                  1.29689\n",
      "GaussianMLPValueFunction/LossAfter       6.56628\n",
      "GaussianMLPValueFunction/LossBefore      6.57019\n",
      "GaussianMLPValueFunction/dLoss           0.00391197\n",
      "TotalEnvSteps                            1.0968e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:26 | [trpo_pendulum] epoch #914 | Saving snapshot...\n",
      "2022-08-17 18:14:26 | [trpo_pendulum] epoch #914 | Saved\n",
      "2022-08-17 18:14:26 | [trpo_pendulum] epoch #914 | Time 582.00 s\n",
      "2022-08-17 18:14:26 | [trpo_pendulum] epoch #914 | EpochTime 0.68 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -595.482\n",
      "Evaluation/AverageReturn             -1490.05\n",
      "Evaluation/Iteration                   914\n",
      "Evaluation/MaxReturn                 -1470.45\n",
      "Evaluation/MinReturn                 -1511.83\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    15.4469\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.33117\n",
      "GaussianMLPPolicy/KL                     0.00745046\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             12.7902\n",
      "GaussianMLPPolicy/LossBefore            14.9935\n",
      "GaussianMLPPolicy/dLoss                  2.20327\n",
      "GaussianMLPValueFunction/LossAfter       6.59717\n",
      "GaussianMLPValueFunction/LossBefore      6.59734\n",
      "GaussianMLPValueFunction/dLoss           0.000165939\n",
      "TotalEnvSteps                            1.098e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:14:26 | [trpo_pendulum] epoch #915 | Saving snapshot...\n",
      "2022-08-17 18:14:26 | [trpo_pendulum] epoch #915 | Saved\n",
      "2022-08-17 18:14:26 | [trpo_pendulum] epoch #915 | Time 582.70 s\n",
      "2022-08-17 18:14:26 | [trpo_pendulum] epoch #915 | EpochTime 0.70 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -560.519\n",
      "Evaluation/AverageReturn             -1451.14\n",
      "Evaluation/Iteration                   915\n",
      "Evaluation/MaxReturn                 -1386.89\n",
      "Evaluation/MinReturn                 -1504.95\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    39.2529\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.35087\n",
      "GaussianMLPPolicy/KL                     0.00616364\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             11.1507\n",
      "GaussianMLPPolicy/LossBefore            12.9642\n",
      "GaussianMLPPolicy/dLoss                  1.81359\n",
      "GaussianMLPValueFunction/LossAfter       6.65145\n",
      "GaussianMLPValueFunction/LossBefore      6.65347\n",
      "GaussianMLPValueFunction/dLoss           0.00201797\n",
      "TotalEnvSteps                            1.0992e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:27 | [trpo_pendulum] epoch #916 | Saving snapshot...\n",
      "2022-08-17 18:14:27 | [trpo_pendulum] epoch #916 | Saved\n",
      "2022-08-17 18:14:27 | [trpo_pendulum] epoch #916 | Time 583.34 s\n",
      "2022-08-17 18:14:27 | [trpo_pendulum] epoch #916 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -583.551\n",
      "Evaluation/AverageReturn             -1441.83\n",
      "Evaluation/Iteration                   916\n",
      "Evaluation/MaxReturn                 -1368.15\n",
      "Evaluation/MinReturn                 -1535.64\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    52.9129\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.34687\n",
      "GaussianMLPPolicy/KL                     0.00702501\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              6.43498\n",
      "GaussianMLPPolicy/LossBefore             8.39293\n",
      "GaussianMLPPolicy/dLoss                  1.95795\n",
      "GaussianMLPValueFunction/LossAfter       6.52896\n",
      "GaussianMLPValueFunction/LossBefore      6.55144\n",
      "GaussianMLPValueFunction/dLoss           0.0224814\n",
      "TotalEnvSteps                            1.1004e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:28 | [trpo_pendulum] epoch #917 | Saving snapshot...\n",
      "2022-08-17 18:14:28 | [trpo_pendulum] epoch #917 | Saved\n",
      "2022-08-17 18:14:28 | [trpo_pendulum] epoch #917 | Time 583.98 s\n",
      "2022-08-17 18:14:28 | [trpo_pendulum] epoch #917 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -648.991\n",
      "Evaluation/AverageReturn             -1500.71\n",
      "Evaluation/Iteration                   917\n",
      "Evaluation/MaxReturn                 -1497.12\n",
      "Evaluation/MinReturn                 -1505.83\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     3.67262\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.34552\n",
      "GaussianMLPPolicy/KL                     0.00712887\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              5.27603\n",
      "GaussianMLPPolicy/LossBefore             6.46544\n",
      "GaussianMLPPolicy/dLoss                  1.1894\n",
      "GaussianMLPValueFunction/LossAfter       6.63537\n",
      "GaussianMLPValueFunction/LossBefore      6.63827\n",
      "GaussianMLPValueFunction/dLoss           0.00289392\n",
      "TotalEnvSteps                            1.1016e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:28 | [trpo_pendulum] epoch #918 | Saving snapshot...\n",
      "2022-08-17 18:14:28 | [trpo_pendulum] epoch #918 | Saved\n",
      "2022-08-17 18:14:28 | [trpo_pendulum] epoch #918 | Time 584.62 s\n",
      "2022-08-17 18:14:28 | [trpo_pendulum] epoch #918 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -623.894\n",
      "Evaluation/AverageReturn             -1528.03\n",
      "Evaluation/Iteration                   918\n",
      "Evaluation/MaxReturn                 -1518.18\n",
      "Evaluation/MinReturn                 -1542.83\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    10.0732\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.33673\n",
      "GaussianMLPPolicy/KL                     0.00848527\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             18.2263\n",
      "GaussianMLPPolicy/LossBefore            19.1029\n",
      "GaussianMLPPolicy/dLoss                  0.876648\n",
      "GaussianMLPValueFunction/LossAfter       6.69132\n",
      "GaussianMLPValueFunction/LossBefore      6.69632\n",
      "GaussianMLPValueFunction/dLoss           0.00499439\n",
      "TotalEnvSteps                            1.1028e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:29 | [trpo_pendulum] epoch #919 | Saving snapshot...\n",
      "2022-08-17 18:14:29 | [trpo_pendulum] epoch #919 | Saved\n",
      "2022-08-17 18:14:29 | [trpo_pendulum] epoch #919 | Time 585.26 s\n",
      "2022-08-17 18:14:29 | [trpo_pendulum] epoch #919 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -582.545\n",
      "Evaluation/AverageReturn             -1498.33\n",
      "Evaluation/Iteration                   919\n",
      "Evaluation/MaxReturn                 -1481.92\n",
      "Evaluation/MinReturn                 -1510.08\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     9.8223\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.33462\n",
      "GaussianMLPPolicy/KL                     0.009791\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             19.5109\n",
      "GaussianMLPPolicy/LossBefore            19.7871\n",
      "GaussianMLPPolicy/dLoss                  0.276148\n",
      "GaussianMLPValueFunction/LossAfter       6.63509\n",
      "GaussianMLPValueFunction/LossBefore      6.63512\n",
      "GaussianMLPValueFunction/dLoss           3.33786e-05\n",
      "TotalEnvSteps                            1.104e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:14:30 | [trpo_pendulum] epoch #920 | Saving snapshot...\n",
      "2022-08-17 18:14:30 | [trpo_pendulum] epoch #920 | Saved\n",
      "2022-08-17 18:14:30 | [trpo_pendulum] epoch #920 | Time 585.90 s\n",
      "2022-08-17 18:14:30 | [trpo_pendulum] epoch #920 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -548.249\n",
      "Evaluation/AverageReturn             -1357.93\n",
      "Evaluation/Iteration                   920\n",
      "Evaluation/MaxReturn                 -1225.63\n",
      "Evaluation/MinReturn                 -1499.33\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                   109.729\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.34689\n",
      "GaussianMLPPolicy/KL                     0.00767203\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -5.35325\n",
      "GaussianMLPPolicy/LossBefore            -3.4212\n",
      "GaussianMLPPolicy/dLoss                  1.93206\n",
      "GaussianMLPValueFunction/LossAfter       6.46737\n",
      "GaussianMLPValueFunction/LossBefore      6.49652\n",
      "GaussianMLPValueFunction/dLoss           0.029151\n",
      "TotalEnvSteps                            1.1052e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:30 | [trpo_pendulum] epoch #921 | Saving snapshot...\n",
      "2022-08-17 18:14:30 | [trpo_pendulum] epoch #921 | Saved\n",
      "2022-08-17 18:14:30 | [trpo_pendulum] epoch #921 | Time 586.54 s\n",
      "2022-08-17 18:14:30 | [trpo_pendulum] epoch #921 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -675.8\n",
      "Evaluation/AverageReturn             -1534.85\n",
      "Evaluation/Iteration                   921\n",
      "Evaluation/MaxReturn                 -1512.04\n",
      "Evaluation/MinReturn                 -1573.7\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    19.9234\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.34832\n",
      "GaussianMLPPolicy/KL                     0.00701114\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              8.22882\n",
      "GaussianMLPPolicy/LossBefore             9.9359\n",
      "GaussianMLPPolicy/dLoss                  1.70709\n",
      "GaussianMLPValueFunction/LossAfter       6.64721\n",
      "GaussianMLPValueFunction/LossBefore      6.65096\n",
      "GaussianMLPValueFunction/dLoss           0.00374556\n",
      "TotalEnvSteps                            1.1064e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:31 | [trpo_pendulum] epoch #922 | Saving snapshot...\n",
      "2022-08-17 18:14:31 | [trpo_pendulum] epoch #922 | Saved\n",
      "2022-08-17 18:14:31 | [trpo_pendulum] epoch #922 | Time 587.19 s\n",
      "2022-08-17 18:14:31 | [trpo_pendulum] epoch #922 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -526.376\n",
      "Evaluation/AverageReturn             -1354.77\n",
      "Evaluation/Iteration                   922\n",
      "Evaluation/MaxReturn                 -1219.89\n",
      "Evaluation/MinReturn                 -1468.01\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    99.0232\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.37585\n",
      "GaussianMLPPolicy/KL                     0.0075312\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              5.2398\n",
      "GaussianMLPPolicy/LossBefore             7.09965\n",
      "GaussianMLPPolicy/dLoss                  1.85985\n",
      "GaussianMLPValueFunction/LossAfter       6.50103\n",
      "GaussianMLPValueFunction/LossBefore      6.51216\n",
      "GaussianMLPValueFunction/dLoss           0.011126\n",
      "TotalEnvSteps                            1.1076e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:32 | [trpo_pendulum] epoch #923 | Saving snapshot...\n",
      "2022-08-17 18:14:32 | [trpo_pendulum] epoch #923 | Saved\n",
      "2022-08-17 18:14:32 | [trpo_pendulum] epoch #923 | Time 587.84 s\n",
      "2022-08-17 18:14:32 | [trpo_pendulum] epoch #923 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -500.141\n",
      "Evaluation/AverageReturn             -1240.2\n",
      "Evaluation/Iteration                   923\n",
      "Evaluation/MaxReturn                 -1183.94\n",
      "Evaluation/MinReturn                 -1392.98\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    70.0952\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.38601\n",
      "GaussianMLPPolicy/KL                     0.00585934\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -22.2923\n",
      "GaussianMLPPolicy/LossBefore           -21.6055\n",
      "GaussianMLPPolicy/dLoss                  0.686796\n",
      "GaussianMLPValueFunction/LossAfter       6.43807\n",
      "GaussianMLPValueFunction/LossBefore      6.45584\n",
      "GaussianMLPValueFunction/dLoss           0.0177755\n",
      "TotalEnvSteps                            1.1088e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:32 | [trpo_pendulum] epoch #924 | Saving snapshot...\n",
      "2022-08-17 18:14:32 | [trpo_pendulum] epoch #924 | Saved\n",
      "2022-08-17 18:14:32 | [trpo_pendulum] epoch #924 | Time 588.48 s\n",
      "2022-08-17 18:14:32 | [trpo_pendulum] epoch #924 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -663.862\n",
      "Evaluation/AverageReturn             -1516.03\n",
      "Evaluation/Iteration                   924\n",
      "Evaluation/MaxReturn                 -1511.12\n",
      "Evaluation/MinReturn                 -1526.07\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     5.37481\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.40949\n",
      "GaussianMLPPolicy/KL                     0.00590118\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              9.43379\n",
      "GaussianMLPPolicy/LossBefore            10.5023\n",
      "GaussianMLPPolicy/dLoss                  1.06852\n",
      "GaussianMLPValueFunction/LossAfter       6.63688\n",
      "GaussianMLPValueFunction/LossBefore      6.6448\n",
      "GaussianMLPValueFunction/dLoss           0.00791645\n",
      "TotalEnvSteps                            1.11e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:33 | [trpo_pendulum] epoch #925 | Saving snapshot...\n",
      "2022-08-17 18:14:33 | [trpo_pendulum] epoch #925 | Saved\n",
      "2022-08-17 18:14:33 | [trpo_pendulum] epoch #925 | Time 589.11 s\n",
      "2022-08-17 18:14:33 | [trpo_pendulum] epoch #925 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -572.684\n",
      "Evaluation/AverageReturn             -1463.09\n",
      "Evaluation/Iteration                   925\n",
      "Evaluation/MaxReturn                 -1388.99\n",
      "Evaluation/MinReturn                 -1513.06\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    40.5146\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.44782\n",
      "GaussianMLPPolicy/KL                     0.00898451\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             58.1648\n",
      "GaussianMLPPolicy/LossBefore            59.5079\n",
      "GaussianMLPPolicy/dLoss                  1.34303\n",
      "GaussianMLPValueFunction/LossAfter       6.58578\n",
      "GaussianMLPValueFunction/LossBefore      6.75064\n",
      "GaussianMLPValueFunction/dLoss           0.164863\n",
      "TotalEnvSteps                            1.1112e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:33 | [trpo_pendulum] epoch #926 | Saving snapshot...\n",
      "2022-08-17 18:14:34 | [trpo_pendulum] epoch #926 | Saved\n",
      "2022-08-17 18:14:34 | [trpo_pendulum] epoch #926 | Time 589.78 s\n",
      "2022-08-17 18:14:34 | [trpo_pendulum] epoch #926 | EpochTime 0.66 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -622.585\n",
      "Evaluation/AverageReturn             -1533.04\n",
      "Evaluation/Iteration                   926\n",
      "Evaluation/MaxReturn                 -1502.52\n",
      "Evaluation/MinReturn                 -1565\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    19.774\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.44456\n",
      "GaussianMLPPolicy/KL                     0.00631572\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             35.5177\n",
      "GaussianMLPPolicy/LossBefore            36.0424\n",
      "GaussianMLPPolicy/dLoss                  0.524727\n",
      "GaussianMLPValueFunction/LossAfter       6.64647\n",
      "GaussianMLPValueFunction/LossBefore      6.65455\n",
      "GaussianMLPValueFunction/dLoss           0.00808573\n",
      "TotalEnvSteps                            1.1124e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:34 | [trpo_pendulum] epoch #927 | Saving snapshot...\n",
      "2022-08-17 18:14:34 | [trpo_pendulum] epoch #927 | Saved\n",
      "2022-08-17 18:14:34 | [trpo_pendulum] epoch #927 | Time 590.42 s\n",
      "2022-08-17 18:14:34 | [trpo_pendulum] epoch #927 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -609.796\n",
      "Evaluation/AverageReturn             -1523.95\n",
      "Evaluation/Iteration                   927\n",
      "Evaluation/MaxReturn                 -1424.82\n",
      "Evaluation/MinReturn                 -1580.9\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    48.6624\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.44537\n",
      "GaussianMLPPolicy/KL                     0.0059732\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             21.1198\n",
      "GaussianMLPPolicy/LossBefore            21.6774\n",
      "GaussianMLPPolicy/dLoss                  0.557556\n",
      "GaussianMLPValueFunction/LossAfter       6.67717\n",
      "GaussianMLPValueFunction/LossBefore      6.68104\n",
      "GaussianMLPValueFunction/dLoss           0.00386667\n",
      "TotalEnvSteps                            1.1136e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:35 | [trpo_pendulum] epoch #928 | Saving snapshot...\n",
      "2022-08-17 18:14:35 | [trpo_pendulum] epoch #928 | Saved\n",
      "2022-08-17 18:14:35 | [trpo_pendulum] epoch #928 | Time 591.05 s\n",
      "2022-08-17 18:14:35 | [trpo_pendulum] epoch #928 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -648.713\n",
      "Evaluation/AverageReturn             -1572.37\n",
      "Evaluation/Iteration                   928\n",
      "Evaluation/MaxReturn                 -1546.75\n",
      "Evaluation/MinReturn                 -1588.73\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    13.8197\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.43134\n",
      "GaussianMLPPolicy/KL                     0.00829326\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             25.9804\n",
      "GaussianMLPPolicy/LossBefore            26.4299\n",
      "GaussianMLPPolicy/dLoss                  0.449505\n",
      "GaussianMLPValueFunction/LossAfter       6.71732\n",
      "GaussianMLPValueFunction/LossBefore      6.72246\n",
      "GaussianMLPValueFunction/dLoss           0.0051446\n",
      "TotalEnvSteps                            1.1148e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:35 | [trpo_pendulum] epoch #929 | Saving snapshot...\n",
      "2022-08-17 18:14:35 | [trpo_pendulum] epoch #929 | Saved\n",
      "2022-08-17 18:14:35 | [trpo_pendulum] epoch #929 | Time 591.70 s\n",
      "2022-08-17 18:14:35 | [trpo_pendulum] epoch #929 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -507.703\n",
      "Evaluation/AverageReturn             -1305.51\n",
      "Evaluation/Iteration                   929\n",
      "Evaluation/MaxReturn                 -1067.72\n",
      "Evaluation/MinReturn                 -1517.81\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                   139.141\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.42699\n",
      "GaussianMLPPolicy/KL                     0.00923807\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -8.1978\n",
      "GaussianMLPPolicy/LossBefore            -6.95144\n",
      "GaussianMLPPolicy/dLoss                  1.24635\n",
      "GaussianMLPValueFunction/LossAfter       6.39881\n",
      "GaussianMLPValueFunction/LossBefore      6.49904\n",
      "GaussianMLPValueFunction/dLoss           0.100226\n",
      "TotalEnvSteps                            1.116e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:36 | [trpo_pendulum] epoch #930 | Saving snapshot...\n",
      "2022-08-17 18:14:36 | [trpo_pendulum] epoch #930 | Saved\n",
      "2022-08-17 18:14:36 | [trpo_pendulum] epoch #930 | Time 592.34 s\n",
      "2022-08-17 18:14:36 | [trpo_pendulum] epoch #930 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -605.512\n",
      "Evaluation/AverageReturn             -1531.12\n",
      "Evaluation/Iteration                   930\n",
      "Evaluation/MaxReturn                 -1520.46\n",
      "Evaluation/MinReturn                 -1538.58\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     5.44761\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.40877\n",
      "GaussianMLPPolicy/KL                     0.00670836\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             24.9309\n",
      "GaussianMLPPolicy/LossBefore            25.0983\n",
      "GaussianMLPPolicy/dLoss                  0.167368\n",
      "GaussianMLPValueFunction/LossAfter       6.69886\n",
      "GaussianMLPValueFunction/LossBefore      6.70563\n",
      "GaussianMLPValueFunction/dLoss           0.00676823\n",
      "TotalEnvSteps                            1.1172e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:37 | [trpo_pendulum] epoch #931 | Saving snapshot...\n",
      "2022-08-17 18:14:37 | [trpo_pendulum] epoch #931 | Saved\n",
      "2022-08-17 18:14:37 | [trpo_pendulum] epoch #931 | Time 592.99 s\n",
      "2022-08-17 18:14:37 | [trpo_pendulum] epoch #931 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -578.388\n",
      "Evaluation/AverageReturn             -1486.38\n",
      "Evaluation/Iteration                   931\n",
      "Evaluation/MaxReturn                 -1418.55\n",
      "Evaluation/MinReturn                 -1532.49\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    36.5035\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.41307\n",
      "GaussianMLPPolicy/KL                     0.00714801\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             65.4849\n",
      "GaussianMLPPolicy/LossBefore            67.1854\n",
      "GaussianMLPPolicy/dLoss                  1.70051\n",
      "GaussianMLPValueFunction/LossAfter       6.62084\n",
      "GaussianMLPValueFunction/LossBefore      6.8106\n",
      "GaussianMLPValueFunction/dLoss           0.189752\n",
      "TotalEnvSteps                            1.1184e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:37 | [trpo_pendulum] epoch #932 | Saving snapshot...\n",
      "2022-08-17 18:14:37 | [trpo_pendulum] epoch #932 | Saved\n",
      "2022-08-17 18:14:37 | [trpo_pendulum] epoch #932 | Time 593.62 s\n",
      "2022-08-17 18:14:37 | [trpo_pendulum] epoch #932 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -675.638\n",
      "Evaluation/AverageReturn             -1537.53\n",
      "Evaluation/Iteration                   932\n",
      "Evaluation/MaxReturn                 -1520.13\n",
      "Evaluation/MinReturn                 -1570.51\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    16.0806\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.40159\n",
      "GaussianMLPPolicy/KL                     0.00681052\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              9.56875\n",
      "GaussianMLPPolicy/LossBefore            11.006\n",
      "GaussianMLPPolicy/dLoss                  1.43723\n",
      "GaussianMLPValueFunction/LossAfter       6.65309\n",
      "GaussianMLPValueFunction/LossBefore      6.65411\n",
      "GaussianMLPValueFunction/dLoss           0.00101233\n",
      "TotalEnvSteps                            1.1196e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:38 | [trpo_pendulum] epoch #933 | Saving snapshot...\n",
      "2022-08-17 18:14:38 | [trpo_pendulum] epoch #933 | Saved\n",
      "2022-08-17 18:14:38 | [trpo_pendulum] epoch #933 | Time 594.25 s\n",
      "2022-08-17 18:14:38 | [trpo_pendulum] epoch #933 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -556.692\n",
      "Evaluation/AverageReturn             -1428.8\n",
      "Evaluation/Iteration                   933\n",
      "Evaluation/MaxReturn                 -1399.21\n",
      "Evaluation/MinReturn                 -1475.08\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    25.2771\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.40429\n",
      "GaussianMLPPolicy/KL                     0.00990784\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             10.9996\n",
      "GaussianMLPPolicy/LossBefore            13.1078\n",
      "GaussianMLPPolicy/dLoss                  2.10824\n",
      "GaussianMLPValueFunction/LossAfter       6.57891\n",
      "GaussianMLPValueFunction/LossBefore      6.58592\n",
      "GaussianMLPValueFunction/dLoss           0.00700569\n",
      "TotalEnvSteps                            1.1208e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:39 | [trpo_pendulum] epoch #934 | Saving snapshot...\n",
      "2022-08-17 18:14:39 | [trpo_pendulum] epoch #934 | Saved\n",
      "2022-08-17 18:14:39 | [trpo_pendulum] epoch #934 | Time 594.88 s\n",
      "2022-08-17 18:14:39 | [trpo_pendulum] epoch #934 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -521.682\n",
      "Evaluation/AverageReturn             -1342.45\n",
      "Evaluation/Iteration                   934\n",
      "Evaluation/MaxReturn                  -983.887\n",
      "Evaluation/MinReturn                 -1437.05\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                   160.897\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.40602\n",
      "GaussianMLPPolicy/KL                     0.00682452\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -3.35184\n",
      "GaussianMLPPolicy/LossBefore            -1.8119\n",
      "GaussianMLPPolicy/dLoss                  1.53994\n",
      "GaussianMLPValueFunction/LossAfter       6.5447\n",
      "GaussianMLPValueFunction/LossBefore      6.56059\n",
      "GaussianMLPValueFunction/dLoss           0.015893\n",
      "TotalEnvSteps                            1.122e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:39 | [trpo_pendulum] epoch #935 | Saving snapshot...\n",
      "2022-08-17 18:14:39 | [trpo_pendulum] epoch #935 | Saved\n",
      "2022-08-17 18:14:39 | [trpo_pendulum] epoch #935 | Time 595.51 s\n",
      "2022-08-17 18:14:39 | [trpo_pendulum] epoch #935 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -549.33\n",
      "Evaluation/AverageReturn             -1436.45\n",
      "Evaluation/Iteration                   935\n",
      "Evaluation/MaxReturn                 -1342.89\n",
      "Evaluation/MinReturn                 -1525.46\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    70.4679\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.39408\n",
      "GaussianMLPPolicy/KL                     0.00561861\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             49.4027\n",
      "GaussianMLPPolicy/LossBefore            50.2938\n",
      "GaussianMLPPolicy/dLoss                  0.89106\n",
      "GaussianMLPValueFunction/LossAfter       6.55605\n",
      "GaussianMLPValueFunction/LossBefore      6.64167\n",
      "GaussianMLPValueFunction/dLoss           0.0856152\n",
      "TotalEnvSteps                            1.1232e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:40 | [trpo_pendulum] epoch #936 | Saving snapshot...\n",
      "2022-08-17 18:14:40 | [trpo_pendulum] epoch #936 | Saved\n",
      "2022-08-17 18:14:40 | [trpo_pendulum] epoch #936 | Time 596.16 s\n",
      "2022-08-17 18:14:40 | [trpo_pendulum] epoch #936 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -645.801\n",
      "Evaluation/AverageReturn             -1492.97\n",
      "Evaluation/Iteration                   936\n",
      "Evaluation/MaxReturn                 -1491.44\n",
      "Evaluation/MinReturn                 -1496.19\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     1.70099\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.39508\n",
      "GaussianMLPPolicy/KL                     0.00854867\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              6.23006\n",
      "GaussianMLPPolicy/LossBefore             6.67064\n",
      "GaussianMLPPolicy/dLoss                  0.440578\n",
      "GaussianMLPValueFunction/LossAfter       6.62413\n",
      "GaussianMLPValueFunction/LossBefore      6.6265\n",
      "GaussianMLPValueFunction/dLoss           0.00236797\n",
      "TotalEnvSteps                            1.1244e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:41 | [trpo_pendulum] epoch #937 | Saving snapshot...\n",
      "2022-08-17 18:14:41 | [trpo_pendulum] epoch #937 | Saved\n",
      "2022-08-17 18:14:41 | [trpo_pendulum] epoch #937 | Time 596.80 s\n",
      "2022-08-17 18:14:41 | [trpo_pendulum] epoch #937 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -643.952\n",
      "Evaluation/AverageReturn             -1580.11\n",
      "Evaluation/Iteration                   937\n",
      "Evaluation/MaxReturn                 -1573.04\n",
      "Evaluation/MinReturn                 -1585.25\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     4.14276\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.40925\n",
      "GaussianMLPPolicy/KL                     0.00652604\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             27.8909\n",
      "GaussianMLPPolicy/LossBefore            28.557\n",
      "GaussianMLPPolicy/dLoss                  0.666103\n",
      "GaussianMLPValueFunction/LossAfter       6.7349\n",
      "GaussianMLPValueFunction/LossBefore      6.74744\n",
      "GaussianMLPValueFunction/dLoss           0.0125408\n",
      "TotalEnvSteps                            1.1256e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:41 | [trpo_pendulum] epoch #938 | Saving snapshot...\n",
      "2022-08-17 18:14:41 | [trpo_pendulum] epoch #938 | Saved\n",
      "2022-08-17 18:14:41 | [trpo_pendulum] epoch #938 | Time 597.45 s\n",
      "2022-08-17 18:14:41 | [trpo_pendulum] epoch #938 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -613.531\n",
      "Evaluation/AverageReturn             -1527.47\n",
      "Evaluation/Iteration                   938\n",
      "Evaluation/MaxReturn                 -1445.24\n",
      "Evaluation/MinReturn                 -1556.67\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    38.7102\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.38206\n",
      "GaussianMLPPolicy/KL                     0.00888701\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             21.0169\n",
      "GaussianMLPPolicy/LossBefore            23\n",
      "GaussianMLPPolicy/dLoss                  1.98313\n",
      "GaussianMLPValueFunction/LossAfter       6.66666\n",
      "GaussianMLPValueFunction/LossBefore      6.66719\n",
      "GaussianMLPValueFunction/dLoss           0.000530243\n",
      "TotalEnvSteps                            1.1268e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:14:42 | [trpo_pendulum] epoch #939 | Saving snapshot...\n",
      "2022-08-17 18:14:42 | [trpo_pendulum] epoch #939 | Saved\n",
      "2022-08-17 18:14:42 | [trpo_pendulum] epoch #939 | Time 598.10 s\n",
      "2022-08-17 18:14:42 | [trpo_pendulum] epoch #939 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -623.661\n",
      "Evaluation/AverageReturn             -1549.12\n",
      "Evaluation/Iteration                   939\n",
      "Evaluation/MaxReturn                 -1536.97\n",
      "Evaluation/MinReturn                 -1566.65\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     9.12033\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.39249\n",
      "GaussianMLPPolicy/KL                     0.00760799\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             45.7719\n",
      "GaussianMLPPolicy/LossBefore            46.7808\n",
      "GaussianMLPPolicy/dLoss                  1.00895\n",
      "GaussianMLPValueFunction/LossAfter       6.69793\n",
      "GaussianMLPValueFunction/LossBefore      6.72924\n",
      "GaussianMLPValueFunction/dLoss           0.0313144\n",
      "TotalEnvSteps                            1.128e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:42 | [trpo_pendulum] epoch #940 | Saving snapshot...\n",
      "2022-08-17 18:14:42 | [trpo_pendulum] epoch #940 | Saved\n",
      "2022-08-17 18:14:42 | [trpo_pendulum] epoch #940 | Time 598.72 s\n",
      "2022-08-17 18:14:42 | [trpo_pendulum] epoch #940 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -573.644\n",
      "Evaluation/AverageReturn             -1444.76\n",
      "Evaluation/Iteration                   940\n",
      "Evaluation/MaxReturn                 -1390.42\n",
      "Evaluation/MinReturn                 -1506.3\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    43.6522\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.38496\n",
      "GaussianMLPPolicy/KL                     0.00717509\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              7.51539\n",
      "GaussianMLPPolicy/LossBefore             9.26023\n",
      "GaussianMLPPolicy/dLoss                  1.74484\n",
      "GaussianMLPValueFunction/LossAfter       6.5096\n",
      "GaussianMLPValueFunction/LossBefore      6.53939\n",
      "GaussianMLPValueFunction/dLoss           0.0297866\n",
      "TotalEnvSteps                            1.1292e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:43 | [trpo_pendulum] epoch #941 | Saving snapshot...\n",
      "2022-08-17 18:14:43 | [trpo_pendulum] epoch #941 | Saved\n",
      "2022-08-17 18:14:43 | [trpo_pendulum] epoch #941 | Time 599.36 s\n",
      "2022-08-17 18:14:43 | [trpo_pendulum] epoch #941 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -609.319\n",
      "Evaluation/AverageReturn             -1539.86\n",
      "Evaluation/Iteration                   941\n",
      "Evaluation/MaxReturn                 -1532.56\n",
      "Evaluation/MinReturn                 -1549.4\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     5.40497\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.3744\n",
      "GaussianMLPPolicy/KL                     0.00954934\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             49.4131\n",
      "GaussianMLPPolicy/LossBefore            50.7507\n",
      "GaussianMLPPolicy/dLoss                  1.33762\n",
      "GaussianMLPValueFunction/LossAfter       6.69362\n",
      "GaussianMLPValueFunction/LossBefore      6.74377\n",
      "GaussianMLPValueFunction/dLoss           0.0501533\n",
      "TotalEnvSteps                            1.1304e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:44 | [trpo_pendulum] epoch #942 | Saving snapshot...\n",
      "2022-08-17 18:14:44 | [trpo_pendulum] epoch #942 | Saved\n",
      "2022-08-17 18:14:44 | [trpo_pendulum] epoch #942 | Time 600.00 s\n",
      "2022-08-17 18:14:44 | [trpo_pendulum] epoch #942 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -657.68\n",
      "Evaluation/AverageReturn             -1516.63\n",
      "Evaluation/Iteration                   942\n",
      "Evaluation/MaxReturn                 -1420.85\n",
      "Evaluation/MinReturn                 -1592.2\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    51.4626\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.36128\n",
      "GaussianMLPPolicy/KL                     0.00729187\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              6.46889\n",
      "GaussianMLPPolicy/LossBefore             8.29612\n",
      "GaussianMLPPolicy/dLoss                  1.82722\n",
      "GaussianMLPValueFunction/LossAfter       6.64735\n",
      "GaussianMLPValueFunction/LossBefore      6.64809\n",
      "GaussianMLPValueFunction/dLoss           0.000747204\n",
      "TotalEnvSteps                            1.1316e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:14:44 | [trpo_pendulum] epoch #943 | Saving snapshot...\n",
      "2022-08-17 18:14:44 | [trpo_pendulum] epoch #943 | Saved\n",
      "2022-08-17 18:14:44 | [trpo_pendulum] epoch #943 | Time 600.63 s\n",
      "2022-08-17 18:14:44 | [trpo_pendulum] epoch #943 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -647.252\n",
      "Evaluation/AverageReturn             -1575.24\n",
      "Evaluation/Iteration                   943\n",
      "Evaluation/MaxReturn                 -1556.23\n",
      "Evaluation/MinReturn                 -1596.43\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    14.0177\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.38218\n",
      "GaussianMLPPolicy/KL                     0.00677355\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             23.5364\n",
      "GaussianMLPPolicy/LossBefore            25.0502\n",
      "GaussianMLPPolicy/dLoss                  1.51384\n",
      "GaussianMLPValueFunction/LossAfter       6.72144\n",
      "GaussianMLPValueFunction/LossBefore      6.72504\n",
      "GaussianMLPValueFunction/dLoss           0.00360394\n",
      "TotalEnvSteps                            1.1328e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:45 | [trpo_pendulum] epoch #944 | Saving snapshot...\n",
      "2022-08-17 18:14:45 | [trpo_pendulum] epoch #944 | Saved\n",
      "2022-08-17 18:14:45 | [trpo_pendulum] epoch #944 | Time 601.27 s\n",
      "2022-08-17 18:14:45 | [trpo_pendulum] epoch #944 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -563.157\n",
      "Evaluation/AverageReturn             -1457.53\n",
      "Evaluation/Iteration                   944\n",
      "Evaluation/MaxReturn                 -1268.25\n",
      "Evaluation/MinReturn                 -1544.57\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    90.5739\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.36728\n",
      "GaussianMLPPolicy/KL                     0.00745358\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             13.8743\n",
      "GaussianMLPPolicy/LossBefore            15.6986\n",
      "GaussianMLPPolicy/dLoss                  1.82427\n",
      "GaussianMLPValueFunction/LossAfter       6.6015\n",
      "GaussianMLPValueFunction/LossBefore      6.6057\n",
      "GaussianMLPValueFunction/dLoss           0.00419188\n",
      "TotalEnvSteps                            1.134e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:46 | [trpo_pendulum] epoch #945 | Saving snapshot...\n",
      "2022-08-17 18:14:46 | [trpo_pendulum] epoch #945 | Saved\n",
      "2022-08-17 18:14:46 | [trpo_pendulum] epoch #945 | Time 601.92 s\n",
      "2022-08-17 18:14:46 | [trpo_pendulum] epoch #945 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -651.478\n",
      "Evaluation/AverageReturn             -1584.74\n",
      "Evaluation/Iteration                   945\n",
      "Evaluation/MaxReturn                 -1532.58\n",
      "Evaluation/MinReturn                 -1625.35\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    27.6508\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.36145\n",
      "GaussianMLPPolicy/KL                     0.00478189\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             25.2961\n",
      "GaussianMLPPolicy/LossBefore            25.7668\n",
      "GaussianMLPPolicy/dLoss                  0.47061\n",
      "GaussianMLPValueFunction/LossAfter       6.71357\n",
      "GaussianMLPValueFunction/LossBefore      6.71639\n",
      "GaussianMLPValueFunction/dLoss           0.00281763\n",
      "TotalEnvSteps                            1.1352e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:46 | [trpo_pendulum] epoch #946 | Saving snapshot...\n",
      "2022-08-17 18:14:46 | [trpo_pendulum] epoch #946 | Saved\n",
      "2022-08-17 18:14:46 | [trpo_pendulum] epoch #946 | Time 602.56 s\n",
      "2022-08-17 18:14:46 | [trpo_pendulum] epoch #946 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -576.61\n",
      "Evaluation/AverageReturn             -1483.56\n",
      "Evaluation/Iteration                   946\n",
      "Evaluation/MaxReturn                 -1408.87\n",
      "Evaluation/MinReturn                 -1541.1\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    45.4821\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.36924\n",
      "GaussianMLPPolicy/KL                     0.00927382\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             24.5541\n",
      "GaussianMLPPolicy/LossBefore            24.9594\n",
      "GaussianMLPPolicy/dLoss                  0.405283\n",
      "GaussianMLPValueFunction/LossAfter       6.61124\n",
      "GaussianMLPValueFunction/LossBefore      6.61468\n",
      "GaussianMLPValueFunction/dLoss           0.00344181\n",
      "TotalEnvSteps                            1.1364e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:47 | [trpo_pendulum] epoch #947 | Saving snapshot...\n",
      "2022-08-17 18:14:47 | [trpo_pendulum] epoch #947 | Saved\n",
      "2022-08-17 18:14:47 | [trpo_pendulum] epoch #947 | Time 603.19 s\n",
      "2022-08-17 18:14:47 | [trpo_pendulum] epoch #947 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -559.661\n",
      "Evaluation/AverageReturn             -1408.92\n",
      "Evaluation/Iteration                   947\n",
      "Evaluation/MaxReturn                 -1355.18\n",
      "Evaluation/MinReturn                 -1492.4\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    52.2353\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.33186\n",
      "GaussianMLPPolicy/KL                     0.00968281\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              1.44744\n",
      "GaussianMLPPolicy/LossBefore             2.91718\n",
      "GaussianMLPPolicy/dLoss                  1.46973\n",
      "GaussianMLPValueFunction/LossAfter       6.49466\n",
      "GaussianMLPValueFunction/LossBefore      6.51786\n",
      "GaussianMLPValueFunction/dLoss           0.0231996\n",
      "TotalEnvSteps                            1.1376e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:48 | [trpo_pendulum] epoch #948 | Saving snapshot...\n",
      "2022-08-17 18:14:48 | [trpo_pendulum] epoch #948 | Saved\n",
      "2022-08-17 18:14:48 | [trpo_pendulum] epoch #948 | Time 603.82 s\n",
      "2022-08-17 18:14:48 | [trpo_pendulum] epoch #948 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -654.569\n",
      "Evaluation/AverageReturn             -1603.92\n",
      "Evaluation/Iteration                   948\n",
      "Evaluation/MaxReturn                 -1599.4\n",
      "Evaluation/MinReturn                 -1606.02\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     2.36455\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.32069\n",
      "GaussianMLPPolicy/KL                     0.00628287\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             59.3838\n",
      "GaussianMLPPolicy/LossBefore            60.4562\n",
      "GaussianMLPPolicy/dLoss                  1.07237\n",
      "GaussianMLPValueFunction/LossAfter       6.72087\n",
      "GaussianMLPValueFunction/LossBefore      6.84109\n",
      "GaussianMLPValueFunction/dLoss           0.120217\n",
      "TotalEnvSteps                            1.1388e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:48 | [trpo_pendulum] epoch #949 | Saving snapshot...\n",
      "2022-08-17 18:14:48 | [trpo_pendulum] epoch #949 | Saved\n",
      "2022-08-17 18:14:48 | [trpo_pendulum] epoch #949 | Time 604.45 s\n",
      "2022-08-17 18:14:48 | [trpo_pendulum] epoch #949 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -658.815\n",
      "Evaluation/AverageReturn             -1517.82\n",
      "Evaluation/Iteration                   949\n",
      "Evaluation/MaxReturn                 -1501.48\n",
      "Evaluation/MinReturn                 -1568.81\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    23.7557\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.30136\n",
      "GaussianMLPPolicy/KL                     0.00791389\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              5.17664\n",
      "GaussianMLPPolicy/LossBefore             7.22532\n",
      "GaussianMLPPolicy/dLoss                  2.04868\n",
      "GaussianMLPValueFunction/LossAfter       6.64901\n",
      "GaussianMLPValueFunction/LossBefore      6.65008\n",
      "GaussianMLPValueFunction/dLoss           0.00106907\n",
      "TotalEnvSteps                            1.14e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:49 | [trpo_pendulum] epoch #950 | Saving snapshot...\n",
      "2022-08-17 18:14:49 | [trpo_pendulum] epoch #950 | Saved\n",
      "2022-08-17 18:14:49 | [trpo_pendulum] epoch #950 | Time 605.09 s\n",
      "2022-08-17 18:14:49 | [trpo_pendulum] epoch #950 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -659.439\n",
      "Evaluation/AverageReturn             -1505.78\n",
      "Evaluation/Iteration                   950\n",
      "Evaluation/MaxReturn                 -1373.24\n",
      "Evaluation/MinReturn                 -1542.26\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    60.1342\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.30782\n",
      "GaussianMLPPolicy/KL                     0.00816068\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              3.16942\n",
      "GaussianMLPPolicy/LossBefore             5.60707\n",
      "GaussianMLPPolicy/dLoss                  2.43765\n",
      "GaussianMLPValueFunction/LossAfter       6.66602\n",
      "GaussianMLPValueFunction/LossBefore      6.66794\n",
      "GaussianMLPValueFunction/dLoss           0.00192356\n",
      "TotalEnvSteps                            1.1412e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:49 | [trpo_pendulum] epoch #951 | Saving snapshot...\n",
      "2022-08-17 18:14:49 | [trpo_pendulum] epoch #951 | Saved\n",
      "2022-08-17 18:14:49 | [trpo_pendulum] epoch #951 | Time 605.71 s\n",
      "2022-08-17 18:14:49 | [trpo_pendulum] epoch #951 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -628.95\n",
      "Evaluation/AverageReturn             -1450.58\n",
      "Evaluation/Iteration                   951\n",
      "Evaluation/MaxReturn                 -1313.35\n",
      "Evaluation/MinReturn                 -1560.17\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    94.1536\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.33309\n",
      "GaussianMLPPolicy/KL                     0.00871351\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -4.48158\n",
      "GaussianMLPPolicy/LossBefore            -1.13896\n",
      "GaussianMLPPolicy/dLoss                  3.34261\n",
      "GaussianMLPValueFunction/LossAfter       6.64388\n",
      "GaussianMLPValueFunction/LossBefore      6.64626\n",
      "GaussianMLPValueFunction/dLoss           0.00238705\n",
      "TotalEnvSteps                            1.1424e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:50 | [trpo_pendulum] epoch #952 | Saving snapshot...\n",
      "2022-08-17 18:14:50 | [trpo_pendulum] epoch #952 | Saved\n",
      "2022-08-17 18:14:50 | [trpo_pendulum] epoch #952 | Time 606.34 s\n",
      "2022-08-17 18:14:50 | [trpo_pendulum] epoch #952 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -639.724\n",
      "Evaluation/AverageReturn             -1482.44\n",
      "Evaluation/Iteration                   952\n",
      "Evaluation/MaxReturn                 -1371.93\n",
      "Evaluation/MinReturn                 -1516.54\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    50.2308\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.35822\n",
      "GaussianMLPPolicy/KL                     0.00948428\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              1.70123\n",
      "GaussianMLPPolicy/LossBefore             4.76082\n",
      "GaussianMLPPolicy/dLoss                  3.05959\n",
      "GaussianMLPValueFunction/LossAfter       6.60799\n",
      "GaussianMLPValueFunction/LossBefore      6.61747\n",
      "GaussianMLPValueFunction/dLoss           0.00948\n",
      "TotalEnvSteps                            1.1436e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:51 | [trpo_pendulum] epoch #953 | Saving snapshot...\n",
      "2022-08-17 18:14:51 | [trpo_pendulum] epoch #953 | Saved\n",
      "2022-08-17 18:14:51 | [trpo_pendulum] epoch #953 | Time 606.97 s\n",
      "2022-08-17 18:14:51 | [trpo_pendulum] epoch #953 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -580.973\n",
      "Evaluation/AverageReturn             -1454.72\n",
      "Evaluation/Iteration                   953\n",
      "Evaluation/MaxReturn                 -1382.14\n",
      "Evaluation/MinReturn                 -1615.02\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    78.701\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.33276\n",
      "GaussianMLPPolicy/KL                     0.00922595\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             12.9016\n",
      "GaussianMLPPolicy/LossBefore            14.1646\n",
      "GaussianMLPPolicy/dLoss                  1.263\n",
      "GaussianMLPValueFunction/LossAfter       6.6565\n",
      "GaussianMLPValueFunction/LossBefore      6.66129\n",
      "GaussianMLPValueFunction/dLoss           0.00479555\n",
      "TotalEnvSteps                            1.1448e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:51 | [trpo_pendulum] epoch #954 | Saving snapshot...\n",
      "2022-08-17 18:14:51 | [trpo_pendulum] epoch #954 | Saved\n",
      "2022-08-17 18:14:51 | [trpo_pendulum] epoch #954 | Time 607.63 s\n",
      "2022-08-17 18:14:51 | [trpo_pendulum] epoch #954 | EpochTime 0.66 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -564.676\n",
      "Evaluation/AverageReturn             -1413.05\n",
      "Evaluation/Iteration                   954\n",
      "Evaluation/MaxReturn                 -1363.4\n",
      "Evaluation/MinReturn                 -1507.58\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    50.3287\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.32185\n",
      "GaussianMLPPolicy/KL                     0.00848383\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              3.58065\n",
      "GaussianMLPPolicy/LossBefore             4.1033\n",
      "GaussianMLPPolicy/dLoss                  0.522651\n",
      "GaussianMLPValueFunction/LossAfter       6.59665\n",
      "GaussianMLPValueFunction/LossBefore      6.60331\n",
      "GaussianMLPValueFunction/dLoss           0.00666714\n",
      "TotalEnvSteps                            1.146e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:52 | [trpo_pendulum] epoch #955 | Saving snapshot...\n",
      "2022-08-17 18:14:52 | [trpo_pendulum] epoch #955 | Saved\n",
      "2022-08-17 18:14:52 | [trpo_pendulum] epoch #955 | Time 608.26 s\n",
      "2022-08-17 18:14:52 | [trpo_pendulum] epoch #955 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -594.945\n",
      "Evaluation/AverageReturn             -1500.87\n",
      "Evaluation/Iteration                   955\n",
      "Evaluation/MaxReturn                 -1363.39\n",
      "Evaluation/MinReturn                 -1548.05\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    70.7536\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.33925\n",
      "GaussianMLPPolicy/KL                     0.00811361\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             28.3454\n",
      "GaussianMLPPolicy/LossBefore            30.3761\n",
      "GaussianMLPPolicy/dLoss                  2.03069\n",
      "GaussianMLPValueFunction/LossAfter       6.69077\n",
      "GaussianMLPValueFunction/LossBefore      6.70505\n",
      "GaussianMLPValueFunction/dLoss           0.0142732\n",
      "TotalEnvSteps                            1.1472e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:53 | [trpo_pendulum] epoch #956 | Saving snapshot...\n",
      "2022-08-17 18:14:53 | [trpo_pendulum] epoch #956 | Saved\n",
      "2022-08-17 18:14:53 | [trpo_pendulum] epoch #956 | Time 608.87 s\n",
      "2022-08-17 18:14:53 | [trpo_pendulum] epoch #956 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -553.011\n",
      "Evaluation/AverageReturn             -1415.01\n",
      "Evaluation/Iteration                   956\n",
      "Evaluation/MaxReturn                 -1153.93\n",
      "Evaluation/MinReturn                 -1531.53\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                   129.378\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.35605\n",
      "GaussianMLPPolicy/KL                     0.00933678\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              5.67948\n",
      "GaussianMLPPolicy/LossBefore             7.09671\n",
      "GaussianMLPPolicy/dLoss                  1.41723\n",
      "GaussianMLPValueFunction/LossAfter       6.59148\n",
      "GaussianMLPValueFunction/LossBefore      6.6012\n",
      "GaussianMLPValueFunction/dLoss           0.00972033\n",
      "TotalEnvSteps                            1.1484e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:53 | [trpo_pendulum] epoch #957 | Saving snapshot...\n",
      "2022-08-17 18:14:53 | [trpo_pendulum] epoch #957 | Saved\n",
      "2022-08-17 18:14:53 | [trpo_pendulum] epoch #957 | Time 609.51 s\n",
      "2022-08-17 18:14:53 | [trpo_pendulum] epoch #957 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -598.485\n",
      "Evaluation/AverageReturn             -1446.85\n",
      "Evaluation/Iteration                   957\n",
      "Evaluation/MaxReturn                 -1341.29\n",
      "Evaluation/MinReturn                 -1495.98\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    51.1715\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.35889\n",
      "GaussianMLPPolicy/KL                     0.00601323\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              5.51587\n",
      "GaussianMLPPolicy/LossBefore             6.51079\n",
      "GaussianMLPPolicy/dLoss                  0.994919\n",
      "GaussianMLPValueFunction/LossAfter       6.61727\n",
      "GaussianMLPValueFunction/LossBefore      6.61837\n",
      "GaussianMLPValueFunction/dLoss           0.00109863\n",
      "TotalEnvSteps                            1.1496e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:54 | [trpo_pendulum] epoch #958 | Saving snapshot...\n",
      "2022-08-17 18:14:54 | [trpo_pendulum] epoch #958 | Saved\n",
      "2022-08-17 18:14:54 | [trpo_pendulum] epoch #958 | Time 610.16 s\n",
      "2022-08-17 18:14:54 | [trpo_pendulum] epoch #958 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -559.699\n",
      "Evaluation/AverageReturn             -1427.24\n",
      "Evaluation/Iteration                   958\n",
      "Evaluation/MaxReturn                 -1188.37\n",
      "Evaluation/MinReturn                 -1570.86\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                   129.129\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.39572\n",
      "GaussianMLPPolicy/KL                     0.00776047\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             14.3334\n",
      "GaussianMLPPolicy/LossBefore            15.7922\n",
      "GaussianMLPPolicy/dLoss                  1.45886\n",
      "GaussianMLPValueFunction/LossAfter       6.60659\n",
      "GaussianMLPValueFunction/LossBefore      6.60853\n",
      "GaussianMLPValueFunction/dLoss           0.00194025\n",
      "TotalEnvSteps                            1.1508e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:54 | [trpo_pendulum] epoch #959 | Saving snapshot...\n",
      "2022-08-17 18:14:55 | [trpo_pendulum] epoch #959 | Saved\n",
      "2022-08-17 18:14:55 | [trpo_pendulum] epoch #959 | Time 610.79 s\n",
      "2022-08-17 18:14:55 | [trpo_pendulum] epoch #959 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -583.965\n",
      "Evaluation/AverageReturn             -1429.81\n",
      "Evaluation/Iteration                   959\n",
      "Evaluation/MaxReturn                 -1374.8\n",
      "Evaluation/MinReturn                 -1483.89\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    44.4903\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.41102\n",
      "GaussianMLPPolicy/KL                     0.00567092\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              6.46808\n",
      "GaussianMLPPolicy/LossBefore             7.04607\n",
      "GaussianMLPPolicy/dLoss                  0.577989\n",
      "GaussianMLPValueFunction/LossAfter       6.62752\n",
      "GaussianMLPValueFunction/LossBefore      6.62921\n",
      "GaussianMLPValueFunction/dLoss           0.00168896\n",
      "TotalEnvSteps                            1.152e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:55 | [trpo_pendulum] epoch #960 | Saving snapshot...\n",
      "2022-08-17 18:14:55 | [trpo_pendulum] epoch #960 | Saved\n",
      "2022-08-17 18:14:55 | [trpo_pendulum] epoch #960 | Time 611.43 s\n",
      "2022-08-17 18:14:55 | [trpo_pendulum] epoch #960 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -594.865\n",
      "Evaluation/AverageReturn             -1441.77\n",
      "Evaluation/Iteration                   960\n",
      "Evaluation/MaxReturn                 -1381.29\n",
      "Evaluation/MinReturn                 -1498.75\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    39.6762\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.40558\n",
      "GaussianMLPPolicy/KL                     0.00543181\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              6.27728\n",
      "GaussianMLPPolicy/LossBefore             7.04899\n",
      "GaussianMLPPolicy/dLoss                  0.771702\n",
      "GaussianMLPValueFunction/LossAfter       6.60039\n",
      "GaussianMLPValueFunction/LossBefore      6.60166\n",
      "GaussianMLPValueFunction/dLoss           0.00126553\n",
      "TotalEnvSteps                            1.1532e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:56 | [trpo_pendulum] epoch #961 | Saving snapshot...\n",
      "2022-08-17 18:14:56 | [trpo_pendulum] epoch #961 | Saved\n",
      "2022-08-17 18:14:56 | [trpo_pendulum] epoch #961 | Time 612.05 s\n",
      "2022-08-17 18:14:56 | [trpo_pendulum] epoch #961 | EpochTime 0.62 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -674.541\n",
      "Evaluation/AverageReturn             -1529.99\n",
      "Evaluation/Iteration                   961\n",
      "Evaluation/MaxReturn                 -1515.25\n",
      "Evaluation/MinReturn                 -1551.83\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    14.4146\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.37353\n",
      "GaussianMLPPolicy/KL                     0.0084339\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              9.87431\n",
      "GaussianMLPPolicy/LossBefore            11.4188\n",
      "GaussianMLPPolicy/dLoss                  1.54449\n",
      "GaussianMLPValueFunction/LossAfter       6.63552\n",
      "GaussianMLPValueFunction/LossBefore      6.63648\n",
      "GaussianMLPValueFunction/dLoss           0.000951767\n",
      "TotalEnvSteps                            1.1544e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:14:56 | [trpo_pendulum] epoch #962 | Saving snapshot...\n",
      "2022-08-17 18:14:56 | [trpo_pendulum] epoch #962 | Saved\n",
      "2022-08-17 18:14:56 | [trpo_pendulum] epoch #962 | Time 612.71 s\n",
      "2022-08-17 18:14:56 | [trpo_pendulum] epoch #962 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -591.77\n",
      "Evaluation/AverageReturn             -1526.16\n",
      "Evaluation/Iteration                   962\n",
      "Evaluation/MaxReturn                 -1523.15\n",
      "Evaluation/MinReturn                 -1530.66\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     2.66206\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.38976\n",
      "GaussianMLPPolicy/KL                     0.0077445\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             42.0864\n",
      "GaussianMLPPolicy/LossBefore            43.0418\n",
      "GaussianMLPPolicy/dLoss                  0.955379\n",
      "GaussianMLPValueFunction/LossAfter       6.69248\n",
      "GaussianMLPValueFunction/LossBefore      6.71366\n",
      "GaussianMLPValueFunction/dLoss           0.0211802\n",
      "TotalEnvSteps                            1.1556e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:57 | [trpo_pendulum] epoch #963 | Saving snapshot...\n",
      "2022-08-17 18:14:57 | [trpo_pendulum] epoch #963 | Saved\n",
      "2022-08-17 18:14:57 | [trpo_pendulum] epoch #963 | Time 613.34 s\n",
      "2022-08-17 18:14:57 | [trpo_pendulum] epoch #963 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -596.05\n",
      "Evaluation/AverageReturn             -1527.45\n",
      "Evaluation/Iteration                   963\n",
      "Evaluation/MaxReturn                 -1524.45\n",
      "Evaluation/MinReturn                 -1531.85\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     2.5343\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.39467\n",
      "GaussianMLPPolicy/KL                     0.00667397\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             30.7315\n",
      "GaussianMLPPolicy/LossBefore            31.6831\n",
      "GaussianMLPPolicy/dLoss                  0.951632\n",
      "GaussianMLPValueFunction/LossAfter       6.68568\n",
      "GaussianMLPValueFunction/LossBefore      6.68895\n",
      "GaussianMLPValueFunction/dLoss           0.00327539\n",
      "TotalEnvSteps                            1.1568e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:58 | [trpo_pendulum] epoch #964 | Saving snapshot...\n",
      "2022-08-17 18:14:58 | [trpo_pendulum] epoch #964 | Saved\n",
      "2022-08-17 18:14:58 | [trpo_pendulum] epoch #964 | Time 613.99 s\n",
      "2022-08-17 18:14:58 | [trpo_pendulum] epoch #964 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -644.263\n",
      "Evaluation/AverageReturn             -1496.41\n",
      "Evaluation/Iteration                   964\n",
      "Evaluation/MaxReturn                 -1493.97\n",
      "Evaluation/MinReturn                 -1498.46\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     1.54427\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.42512\n",
      "GaussianMLPPolicy/KL                     0.00678367\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              7.72336\n",
      "GaussianMLPPolicy/LossBefore             9.043\n",
      "GaussianMLPPolicy/dLoss                  1.31965\n",
      "GaussianMLPValueFunction/LossAfter       6.62425\n",
      "GaussianMLPValueFunction/LossBefore      6.62611\n",
      "GaussianMLPValueFunction/dLoss           0.00185633\n",
      "TotalEnvSteps                            1.158e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:58 | [trpo_pendulum] epoch #965 | Saving snapshot...\n",
      "2022-08-17 18:14:58 | [trpo_pendulum] epoch #965 | Saved\n",
      "2022-08-17 18:14:58 | [trpo_pendulum] epoch #965 | Time 614.64 s\n",
      "2022-08-17 18:14:58 | [trpo_pendulum] epoch #965 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -648.163\n",
      "Evaluation/AverageReturn             -1493.03\n",
      "Evaluation/Iteration                   965\n",
      "Evaluation/MaxReturn                 -1491.74\n",
      "Evaluation/MinReturn                 -1496.41\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     1.54558\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.44181\n",
      "GaussianMLPPolicy/KL                     0.00573017\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              6.7136\n",
      "GaussianMLPPolicy/LossBefore             7.68575\n",
      "GaussianMLPPolicy/dLoss                  0.972149\n",
      "GaussianMLPValueFunction/LossAfter       6.62312\n",
      "GaussianMLPValueFunction/LossBefore      6.62448\n",
      "GaussianMLPValueFunction/dLoss           0.00136471\n",
      "TotalEnvSteps                            1.1592e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:14:59 | [trpo_pendulum] epoch #966 | Saving snapshot...\n",
      "2022-08-17 18:14:59 | [trpo_pendulum] epoch #966 | Saved\n",
      "2022-08-17 18:14:59 | [trpo_pendulum] epoch #966 | Time 615.30 s\n",
      "2022-08-17 18:14:59 | [trpo_pendulum] epoch #966 | EpochTime 0.66 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -590.676\n",
      "Evaluation/AverageReturn             -1447.9\n",
      "Evaluation/Iteration                   966\n",
      "Evaluation/MaxReturn                 -1361.02\n",
      "Evaluation/MinReturn                 -1518.16\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    58.6119\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.45472\n",
      "GaussianMLPPolicy/KL                     0.00659692\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              6.35544\n",
      "GaussianMLPPolicy/LossBefore             7.83949\n",
      "GaussianMLPPolicy/dLoss                  1.48405\n",
      "GaussianMLPValueFunction/LossAfter       6.54128\n",
      "GaussianMLPValueFunction/LossBefore      6.55546\n",
      "GaussianMLPValueFunction/dLoss           0.0141797\n",
      "TotalEnvSteps                            1.1604e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:00 | [trpo_pendulum] epoch #967 | Saving snapshot...\n",
      "2022-08-17 18:15:00 | [trpo_pendulum] epoch #967 | Saved\n",
      "2022-08-17 18:15:00 | [trpo_pendulum] epoch #967 | Time 615.95 s\n",
      "2022-08-17 18:15:00 | [trpo_pendulum] epoch #967 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -654.977\n",
      "Evaluation/AverageReturn             -1502.89\n",
      "Evaluation/Iteration                   967\n",
      "Evaluation/MaxReturn                 -1495.67\n",
      "Evaluation/MinReturn                 -1510.52\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     5.02868\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.46811\n",
      "GaussianMLPPolicy/KL                     0.00757541\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              8.56415\n",
      "GaussianMLPPolicy/LossBefore             9.23725\n",
      "GaussianMLPPolicy/dLoss                  0.673107\n",
      "GaussianMLPValueFunction/LossAfter       6.62291\n",
      "GaussianMLPValueFunction/LossBefore      6.62406\n",
      "GaussianMLPValueFunction/dLoss           0.00114155\n",
      "TotalEnvSteps                            1.1616e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:00 | [trpo_pendulum] epoch #968 | Saving snapshot...\n",
      "2022-08-17 18:15:00 | [trpo_pendulum] epoch #968 | Saved\n",
      "2022-08-17 18:15:00 | [trpo_pendulum] epoch #968 | Time 616.59 s\n",
      "2022-08-17 18:15:00 | [trpo_pendulum] epoch #968 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -633.223\n",
      "Evaluation/AverageReturn             -1564.78\n",
      "Evaluation/Iteration                   968\n",
      "Evaluation/MaxReturn                 -1519.21\n",
      "Evaluation/MinReturn                 -1617.92\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    34.1458\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.48564\n",
      "GaussianMLPPolicy/KL                     0.00852256\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             59.1377\n",
      "GaussianMLPPolicy/LossBefore            59.9026\n",
      "GaussianMLPPolicy/dLoss                  0.764862\n",
      "GaussianMLPValueFunction/LossAfter       6.69071\n",
      "GaussianMLPValueFunction/LossBefore      6.79667\n",
      "GaussianMLPValueFunction/dLoss           0.105962\n",
      "TotalEnvSteps                            1.1628e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:01 | [trpo_pendulum] epoch #969 | Saving snapshot...\n",
      "2022-08-17 18:15:01 | [trpo_pendulum] epoch #969 | Saved\n",
      "2022-08-17 18:15:01 | [trpo_pendulum] epoch #969 | Time 617.25 s\n",
      "2022-08-17 18:15:01 | [trpo_pendulum] epoch #969 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -550.799\n",
      "Evaluation/AverageReturn             -1408.02\n",
      "Evaluation/Iteration                   969\n",
      "Evaluation/MaxReturn                 -1300.58\n",
      "Evaluation/MinReturn                 -1506.7\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    73.9489\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.47221\n",
      "GaussianMLPPolicy/KL                     0.00865191\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              5.09404\n",
      "GaussianMLPPolicy/LossBefore             6.34685\n",
      "GaussianMLPPolicy/dLoss                  1.25282\n",
      "GaussianMLPValueFunction/LossAfter       6.56461\n",
      "GaussianMLPValueFunction/LossBefore      6.57139\n",
      "GaussianMLPValueFunction/dLoss           0.00678158\n",
      "TotalEnvSteps                            1.164e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:02 | [trpo_pendulum] epoch #970 | Saving snapshot...\n",
      "2022-08-17 18:15:02 | [trpo_pendulum] epoch #970 | Saved\n",
      "2022-08-17 18:15:02 | [trpo_pendulum] epoch #970 | Time 617.90 s\n",
      "2022-08-17 18:15:02 | [trpo_pendulum] epoch #970 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -667.59\n",
      "Evaluation/AverageReturn             -1528.98\n",
      "Evaluation/Iteration                   970\n",
      "Evaluation/MaxReturn                 -1511.01\n",
      "Evaluation/MinReturn                 -1558.37\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    15.6375\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.45384\n",
      "GaussianMLPPolicy/KL                     0.00810133\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             11.4756\n",
      "GaussianMLPPolicy/LossBefore            13.2351\n",
      "GaussianMLPPolicy/dLoss                  1.75946\n",
      "GaussianMLPValueFunction/LossAfter       6.64223\n",
      "GaussianMLPValueFunction/LossBefore      6.64309\n",
      "GaussianMLPValueFunction/dLoss           0.000854969\n",
      "TotalEnvSteps                            1.1652e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:15:02 | [trpo_pendulum] epoch #971 | Saving snapshot...\n",
      "2022-08-17 18:15:02 | [trpo_pendulum] epoch #971 | Saved\n",
      "2022-08-17 18:15:02 | [trpo_pendulum] epoch #971 | Time 618.54 s\n",
      "2022-08-17 18:15:02 | [trpo_pendulum] epoch #971 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -613.513\n",
      "Evaluation/AverageReturn             -1462.49\n",
      "Evaluation/Iteration                   971\n",
      "Evaluation/MaxReturn                 -1389.25\n",
      "Evaluation/MinReturn                 -1515.25\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    43.9202\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.45904\n",
      "GaussianMLPPolicy/KL                     0.00719448\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              5.26032\n",
      "GaussianMLPPolicy/LossBefore             7.71423\n",
      "GaussianMLPPolicy/dLoss                  2.45391\n",
      "GaussianMLPValueFunction/LossAfter       6.59047\n",
      "GaussianMLPValueFunction/LossBefore      6.59189\n",
      "GaussianMLPValueFunction/dLoss           0.00142193\n",
      "TotalEnvSteps                            1.1664e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:03 | [trpo_pendulum] epoch #972 | Saving snapshot...\n",
      "2022-08-17 18:15:03 | [trpo_pendulum] epoch #972 | Saved\n",
      "2022-08-17 18:15:03 | [trpo_pendulum] epoch #972 | Time 619.19 s\n",
      "2022-08-17 18:15:03 | [trpo_pendulum] epoch #972 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -645.621\n",
      "Evaluation/AverageReturn             -1491.44\n",
      "Evaluation/Iteration                   972\n",
      "Evaluation/MaxReturn                 -1490.89\n",
      "Evaluation/MinReturn                 -1493.94\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     1.12003\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.45471\n",
      "GaussianMLPPolicy/KL                     0.00446471\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              8.52692\n",
      "GaussianMLPPolicy/LossBefore             9.44995\n",
      "GaussianMLPPolicy/dLoss                  0.923033\n",
      "GaussianMLPValueFunction/LossAfter       6.6171\n",
      "GaussianMLPValueFunction/LossBefore      6.61782\n",
      "GaussianMLPValueFunction/dLoss           0.000720024\n",
      "TotalEnvSteps                            1.1676e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:15:04 | [trpo_pendulum] epoch #973 | Saving snapshot...\n",
      "2022-08-17 18:15:04 | [trpo_pendulum] epoch #973 | Saved\n",
      "2022-08-17 18:15:04 | [trpo_pendulum] epoch #973 | Time 619.84 s\n",
      "2022-08-17 18:15:04 | [trpo_pendulum] epoch #973 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -661.936\n",
      "Evaluation/AverageReturn             -1559.63\n",
      "Evaluation/Iteration                   973\n",
      "Evaluation/MaxReturn                 -1509.69\n",
      "Evaluation/MinReturn                 -1586.78\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    25.9261\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.49239\n",
      "GaussianMLPPolicy/KL                     0.00632428\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             21.6653\n",
      "GaussianMLPPolicy/LossBefore            22.9026\n",
      "GaussianMLPPolicy/dLoss                  1.23733\n",
      "GaussianMLPValueFunction/LossAfter       6.68712\n",
      "GaussianMLPValueFunction/LossBefore      6.69089\n",
      "GaussianMLPValueFunction/dLoss           0.00376892\n",
      "TotalEnvSteps                            1.1688e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:04 | [trpo_pendulum] epoch #974 | Saving snapshot...\n",
      "2022-08-17 18:15:04 | [trpo_pendulum] epoch #974 | Saved\n",
      "2022-08-17 18:15:04 | [trpo_pendulum] epoch #974 | Time 620.47 s\n",
      "2022-08-17 18:15:04 | [trpo_pendulum] epoch #974 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -605.393\n",
      "Evaluation/AverageReturn             -1526.97\n",
      "Evaluation/Iteration                   974\n",
      "Evaluation/MaxReturn                 -1513.18\n",
      "Evaluation/MinReturn                 -1555.95\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    14.3643\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.5049\n",
      "GaussianMLPPolicy/KL                     0.00778588\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             36.4853\n",
      "GaussianMLPPolicy/LossBefore            37.6029\n",
      "GaussianMLPPolicy/dLoss                  1.11766\n",
      "GaussianMLPValueFunction/LossAfter       6.66578\n",
      "GaussianMLPValueFunction/LossBefore      6.67214\n",
      "GaussianMLPValueFunction/dLoss           0.00636482\n",
      "TotalEnvSteps                            1.17e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:05 | [trpo_pendulum] epoch #975 | Saving snapshot...\n",
      "2022-08-17 18:15:05 | [trpo_pendulum] epoch #975 | Saved\n",
      "2022-08-17 18:15:05 | [trpo_pendulum] epoch #975 | Time 621.12 s\n",
      "2022-08-17 18:15:05 | [trpo_pendulum] epoch #975 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -645.368\n",
      "Evaluation/AverageReturn             -1495.13\n",
      "Evaluation/Iteration                   975\n",
      "Evaluation/MaxReturn                 -1493.8\n",
      "Evaluation/MinReturn                 -1496.93\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     0.994438\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.51343\n",
      "GaussianMLPPolicy/KL                     0.00888793\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              8.99625\n",
      "GaussianMLPPolicy/LossBefore            10.132\n",
      "GaussianMLPPolicy/dLoss                  1.13575\n",
      "GaussianMLPValueFunction/LossAfter       6.62113\n",
      "GaussianMLPValueFunction/LossBefore      6.62233\n",
      "GaussianMLPValueFunction/dLoss           0.00120354\n",
      "TotalEnvSteps                            1.1712e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:05 | [trpo_pendulum] epoch #976 | Saving snapshot...\n",
      "2022-08-17 18:15:05 | [trpo_pendulum] epoch #976 | Saved\n",
      "2022-08-17 18:15:05 | [trpo_pendulum] epoch #976 | Time 621.75 s\n",
      "2022-08-17 18:15:05 | [trpo_pendulum] epoch #976 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -555.693\n",
      "Evaluation/AverageReturn             -1444.4\n",
      "Evaluation/Iteration                   976\n",
      "Evaluation/MaxReturn                 -1370.49\n",
      "Evaluation/MinReturn                 -1505.19\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    48.2104\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.54121\n",
      "GaussianMLPPolicy/KL                     0.00880433\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             14.6239\n",
      "GaussianMLPPolicy/LossBefore            16.0786\n",
      "GaussianMLPPolicy/dLoss                  1.45477\n",
      "GaussianMLPValueFunction/LossAfter       6.56472\n",
      "GaussianMLPValueFunction/LossBefore      6.57597\n",
      "GaussianMLPValueFunction/dLoss           0.0112462\n",
      "TotalEnvSteps                            1.1724e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:06 | [trpo_pendulum] epoch #977 | Saving snapshot...\n",
      "2022-08-17 18:15:06 | [trpo_pendulum] epoch #977 | Saved\n",
      "2022-08-17 18:15:06 | [trpo_pendulum] epoch #977 | Time 622.38 s\n",
      "2022-08-17 18:15:06 | [trpo_pendulum] epoch #977 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -538.762\n",
      "Evaluation/AverageReturn             -1438.49\n",
      "Evaluation/Iteration                   977\n",
      "Evaluation/MaxReturn                 -1409.33\n",
      "Evaluation/MinReturn                 -1478.98\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    24.5071\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.53354\n",
      "GaussianMLPPolicy/KL                     0.00620965\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             19.8153\n",
      "GaussianMLPPolicy/LossBefore            21.0916\n",
      "GaussianMLPPolicy/dLoss                  1.27623\n",
      "GaussianMLPValueFunction/LossAfter       6.64957\n",
      "GaussianMLPValueFunction/LossBefore      6.65124\n",
      "GaussianMLPValueFunction/dLoss           0.00167084\n",
      "TotalEnvSteps                            1.1736e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:07 | [trpo_pendulum] epoch #978 | Saving snapshot...\n",
      "2022-08-17 18:15:07 | [trpo_pendulum] epoch #978 | Saved\n",
      "2022-08-17 18:15:07 | [trpo_pendulum] epoch #978 | Time 623.03 s\n",
      "2022-08-17 18:15:07 | [trpo_pendulum] epoch #978 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -601.975\n",
      "Evaluation/AverageReturn             -1498.27\n",
      "Evaluation/Iteration                   978\n",
      "Evaluation/MaxReturn                 -1430.61\n",
      "Evaluation/MinReturn                 -1521.28\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    32.1209\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.53057\n",
      "GaussianMLPPolicy/KL                     0.00950741\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             15.5626\n",
      "GaussianMLPPolicy/LossBefore            17.0084\n",
      "GaussianMLPPolicy/dLoss                  1.44587\n",
      "GaussianMLPValueFunction/LossAfter       6.60938\n",
      "GaussianMLPValueFunction/LossBefore      6.60956\n",
      "GaussianMLPValueFunction/dLoss           0.000179768\n",
      "TotalEnvSteps                            1.1748e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:15:07 | [trpo_pendulum] epoch #979 | Saving snapshot...\n",
      "2022-08-17 18:15:07 | [trpo_pendulum] epoch #979 | Saved\n",
      "2022-08-17 18:15:07 | [trpo_pendulum] epoch #979 | Time 623.68 s\n",
      "2022-08-17 18:15:07 | [trpo_pendulum] epoch #979 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -644.606\n",
      "Evaluation/AverageReturn             -1562.56\n",
      "Evaluation/Iteration                   979\n",
      "Evaluation/MaxReturn                 -1533.98\n",
      "Evaluation/MinReturn                 -1598.14\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    22.8947\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.53648\n",
      "GaussianMLPPolicy/KL                     0.00564148\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             25.6644\n",
      "GaussianMLPPolicy/LossBefore            26.1726\n",
      "GaussianMLPPolicy/dLoss                  0.508221\n",
      "GaussianMLPValueFunction/LossAfter       6.70013\n",
      "GaussianMLPValueFunction/LossBefore      6.70487\n",
      "GaussianMLPValueFunction/dLoss           0.00473833\n",
      "TotalEnvSteps                            1.176e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:08 | [trpo_pendulum] epoch #980 | Saving snapshot...\n",
      "2022-08-17 18:15:08 | [trpo_pendulum] epoch #980 | Saved\n",
      "2022-08-17 18:15:08 | [trpo_pendulum] epoch #980 | Time 624.34 s\n",
      "2022-08-17 18:15:08 | [trpo_pendulum] epoch #980 | EpochTime 0.66 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -485.484\n",
      "Evaluation/AverageReturn             -1390.88\n",
      "Evaluation/Iteration                   980\n",
      "Evaluation/MaxReturn                 -1388.8\n",
      "Evaluation/MinReturn                 -1392.6\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     1.37294\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.54229\n",
      "GaussianMLPPolicy/KL                     0.00698081\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             29.7453\n",
      "GaussianMLPPolicy/LossBefore            30.0912\n",
      "GaussianMLPPolicy/dLoss                  0.345875\n",
      "GaussianMLPValueFunction/LossAfter       6.62059\n",
      "GaussianMLPValueFunction/LossBefore      6.62852\n",
      "GaussianMLPValueFunction/dLoss           0.00792313\n",
      "TotalEnvSteps                            1.1772e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:09 | [trpo_pendulum] epoch #981 | Saving snapshot...\n",
      "2022-08-17 18:15:09 | [trpo_pendulum] epoch #981 | Saved\n",
      "2022-08-17 18:15:09 | [trpo_pendulum] epoch #981 | Time 624.97 s\n",
      "2022-08-17 18:15:09 | [trpo_pendulum] epoch #981 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -684.357\n",
      "Evaluation/AverageReturn             -1620.79\n",
      "Evaluation/Iteration                   981\n",
      "Evaluation/MaxReturn                 -1589.86\n",
      "Evaluation/MinReturn                 -1643.89\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    19.2792\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.60979\n",
      "GaussianMLPPolicy/KL                     0.00764624\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             27.9773\n",
      "GaussianMLPPolicy/LossBefore            29.7297\n",
      "GaussianMLPPolicy/dLoss                  1.75243\n",
      "GaussianMLPValueFunction/LossAfter       6.70195\n",
      "GaussianMLPValueFunction/LossBefore      6.70508\n",
      "GaussianMLPValueFunction/dLoss           0.00313139\n",
      "TotalEnvSteps                            1.1784e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:09 | [trpo_pendulum] epoch #982 | Saving snapshot...\n",
      "2022-08-17 18:15:09 | [trpo_pendulum] epoch #982 | Saved\n",
      "2022-08-17 18:15:09 | [trpo_pendulum] epoch #982 | Time 625.62 s\n",
      "2022-08-17 18:15:09 | [trpo_pendulum] epoch #982 | EpochTime 0.64 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn    -638.027\n",
      "Evaluation/AverageReturn             -1534.3\n",
      "Evaluation/Iteration                   982\n",
      "Evaluation/MaxReturn                 -1524.91\n",
      "Evaluation/MinReturn                 -1562\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    12.6132\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.59794\n",
      "GaussianMLPPolicy/KL                     0.00774923\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             18.6575\n",
      "GaussianMLPPolicy/LossBefore            18.993\n",
      "GaussianMLPPolicy/dLoss                  0.335411\n",
      "GaussianMLPValueFunction/LossAfter       6.68295\n",
      "GaussianMLPValueFunction/LossBefore      6.68312\n",
      "GaussianMLPValueFunction/dLoss           0.000169277\n",
      "TotalEnvSteps                            1.1796e+06\n",
      "-----------------------------------  ---------------\n",
      "2022-08-17 18:15:10 | [trpo_pendulum] epoch #983 | Saving snapshot...\n",
      "2022-08-17 18:15:10 | [trpo_pendulum] epoch #983 | Saved\n",
      "2022-08-17 18:15:10 | [trpo_pendulum] epoch #983 | Time 626.27 s\n",
      "2022-08-17 18:15:10 | [trpo_pendulum] epoch #983 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -587.499\n",
      "Evaluation/AverageReturn             -1486.98\n",
      "Evaluation/Iteration                   983\n",
      "Evaluation/MaxReturn                 -1427.91\n",
      "Evaluation/MinReturn                 -1517.01\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    29.3493\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.59802\n",
      "GaussianMLPPolicy/KL                     0.00568654\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             15.3764\n",
      "GaussianMLPPolicy/LossBefore            15.567\n",
      "GaussianMLPPolicy/dLoss                  0.190669\n",
      "GaussianMLPValueFunction/LossAfter       6.61174\n",
      "GaussianMLPValueFunction/LossBefore      6.61439\n",
      "GaussianMLPValueFunction/dLoss           0.00265074\n",
      "TotalEnvSteps                            1.1808e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:11 | [trpo_pendulum] epoch #984 | Saving snapshot...\n",
      "2022-08-17 18:15:11 | [trpo_pendulum] epoch #984 | Saved\n",
      "2022-08-17 18:15:11 | [trpo_pendulum] epoch #984 | Time 626.91 s\n",
      "2022-08-17 18:15:11 | [trpo_pendulum] epoch #984 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -664.821\n",
      "Evaluation/AverageReturn             -1592.67\n",
      "Evaluation/Iteration                   984\n",
      "Evaluation/MaxReturn                 -1563.58\n",
      "Evaluation/MinReturn                 -1612.69\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    16.1188\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.60084\n",
      "GaussianMLPPolicy/KL                     0.00361122\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             26.7311\n",
      "GaussianMLPPolicy/LossBefore            26.7474\n",
      "GaussianMLPPolicy/dLoss                  0.0163841\n",
      "GaussianMLPValueFunction/LossAfter       6.68542\n",
      "GaussianMLPValueFunction/LossBefore      6.68671\n",
      "GaussianMLPValueFunction/dLoss           0.00129318\n",
      "TotalEnvSteps                            1.182e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:11 | [trpo_pendulum] epoch #985 | Saving snapshot...\n",
      "2022-08-17 18:15:11 | [trpo_pendulum] epoch #985 | Saved\n",
      "2022-08-17 18:15:11 | [trpo_pendulum] epoch #985 | Time 627.57 s\n",
      "2022-08-17 18:15:11 | [trpo_pendulum] epoch #985 | EpochTime 0.66 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -643.597\n",
      "Evaluation/AverageReturn             -1559.69\n",
      "Evaluation/Iteration                   985\n",
      "Evaluation/MaxReturn                 -1536.54\n",
      "Evaluation/MinReturn                 -1588.33\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    15.1607\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.61239\n",
      "GaussianMLPPolicy/KL                     0.00642968\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             23.5347\n",
      "GaussianMLPPolicy/LossBefore            24.2529\n",
      "GaussianMLPPolicy/dLoss                  0.71818\n",
      "GaussianMLPValueFunction/LossAfter       6.70783\n",
      "GaussianMLPValueFunction/LossBefore      6.70929\n",
      "GaussianMLPValueFunction/dLoss           0.00145721\n",
      "TotalEnvSteps                            1.1832e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:12 | [trpo_pendulum] epoch #986 | Saving snapshot...\n",
      "2022-08-17 18:15:12 | [trpo_pendulum] epoch #986 | Saved\n",
      "2022-08-17 18:15:12 | [trpo_pendulum] epoch #986 | Time 628.21 s\n",
      "2022-08-17 18:15:12 | [trpo_pendulum] epoch #986 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -649.894\n",
      "Evaluation/AverageReturn             -1590.61\n",
      "Evaluation/Iteration                   986\n",
      "Evaluation/MaxReturn                 -1581.21\n",
      "Evaluation/MinReturn                 -1605.55\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     8.06072\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.61024\n",
      "GaussianMLPPolicy/KL                     0.00927847\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             38.2069\n",
      "GaussianMLPPolicy/LossBefore            39.6691\n",
      "GaussianMLPPolicy/dLoss                  1.46224\n",
      "GaussianMLPValueFunction/LossAfter       6.71621\n",
      "GaussianMLPValueFunction/LossBefore      6.7294\n",
      "GaussianMLPValueFunction/dLoss           0.0131879\n",
      "TotalEnvSteps                            1.1844e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:13 | [trpo_pendulum] epoch #987 | Saving snapshot...\n",
      "2022-08-17 18:15:13 | [trpo_pendulum] epoch #987 | Saved\n",
      "2022-08-17 18:15:13 | [trpo_pendulum] epoch #987 | Time 628.86 s\n",
      "2022-08-17 18:15:13 | [trpo_pendulum] epoch #987 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -620.125\n",
      "Evaluation/AverageReturn             -1529.35\n",
      "Evaluation/Iteration                   987\n",
      "Evaluation/MaxReturn                 -1515.12\n",
      "Evaluation/MinReturn                 -1542\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     9.94651\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.60729\n",
      "GaussianMLPPolicy/KL                     0.00548008\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             19.2283\n",
      "GaussianMLPPolicy/LossBefore            19.3706\n",
      "GaussianMLPPolicy/dLoss                  0.142242\n",
      "GaussianMLPValueFunction/LossAfter       6.63619\n",
      "GaussianMLPValueFunction/LossBefore      6.66371\n",
      "GaussianMLPValueFunction/dLoss           0.0275202\n",
      "TotalEnvSteps                            1.1856e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:13 | [trpo_pendulum] epoch #988 | Saving snapshot...\n",
      "2022-08-17 18:15:13 | [trpo_pendulum] epoch #988 | Saved\n",
      "2022-08-17 18:15:13 | [trpo_pendulum] epoch #988 | Time 629.51 s\n",
      "2022-08-17 18:15:13 | [trpo_pendulum] epoch #988 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -642.283\n",
      "Evaluation/AverageReturn             -1495.95\n",
      "Evaluation/Iteration                   988\n",
      "Evaluation/MaxReturn                 -1404.97\n",
      "Evaluation/MinReturn                 -1537.71\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    44.3349\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.6099\n",
      "GaussianMLPPolicy/KL                     0.00946863\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              3.08927\n",
      "GaussianMLPPolicy/LossBefore             6.51975\n",
      "GaussianMLPPolicy/dLoss                  3.43048\n",
      "GaussianMLPValueFunction/LossAfter       6.6014\n",
      "GaussianMLPValueFunction/LossBefore      6.60583\n",
      "GaussianMLPValueFunction/dLoss           0.00443125\n",
      "TotalEnvSteps                            1.1868e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:14 | [trpo_pendulum] epoch #989 | Saving snapshot...\n",
      "2022-08-17 18:15:14 | [trpo_pendulum] epoch #989 | Saved\n",
      "2022-08-17 18:15:14 | [trpo_pendulum] epoch #989 | Time 630.14 s\n",
      "2022-08-17 18:15:14 | [trpo_pendulum] epoch #989 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -611.738\n",
      "Evaluation/AverageReturn             -1535.5\n",
      "Evaluation/Iteration                   989\n",
      "Evaluation/MaxReturn                 -1524.13\n",
      "Evaluation/MinReturn                 -1549.13\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     7.49908\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.60927\n",
      "GaussianMLPPolicy/KL                     0.00466909\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             42.1438\n",
      "GaussianMLPPolicy/LossBefore            42.3397\n",
      "GaussianMLPPolicy/dLoss                  0.195892\n",
      "GaussianMLPValueFunction/LossAfter       6.70727\n",
      "GaussianMLPValueFunction/LossBefore      6.73103\n",
      "GaussianMLPValueFunction/dLoss           0.0237551\n",
      "TotalEnvSteps                            1.188e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:14 | [trpo_pendulum] epoch #990 | Saving snapshot...\n",
      "2022-08-17 18:15:15 | [trpo_pendulum] epoch #990 | Saved\n",
      "2022-08-17 18:15:15 | [trpo_pendulum] epoch #990 | Time 630.78 s\n",
      "2022-08-17 18:15:15 | [trpo_pendulum] epoch #990 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -590.328\n",
      "Evaluation/AverageReturn             -1488.44\n",
      "Evaluation/Iteration                   990\n",
      "Evaluation/MaxReturn                 -1383\n",
      "Evaluation/MinReturn                 -1525.39\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    48.792\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.62945\n",
      "GaussianMLPPolicy/KL                     0.00794753\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             12.7579\n",
      "GaussianMLPPolicy/LossBefore            14.1995\n",
      "GaussianMLPPolicy/dLoss                  1.4416\n",
      "GaussianMLPValueFunction/LossAfter       6.62357\n",
      "GaussianMLPValueFunction/LossBefore      6.6255\n",
      "GaussianMLPValueFunction/dLoss           0.00193405\n",
      "TotalEnvSteps                            1.1892e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:15 | [trpo_pendulum] epoch #991 | Saving snapshot...\n",
      "2022-08-17 18:15:15 | [trpo_pendulum] epoch #991 | Saved\n",
      "2022-08-17 18:15:15 | [trpo_pendulum] epoch #991 | Time 631.39 s\n",
      "2022-08-17 18:15:15 | [trpo_pendulum] epoch #991 | EpochTime 0.61 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -647.686\n",
      "Evaluation/AverageReturn             -1495.88\n",
      "Evaluation/Iteration                   991\n",
      "Evaluation/MaxReturn                 -1491.81\n",
      "Evaluation/MinReturn                 -1503.19\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                     4.41135\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.64955\n",
      "GaussianMLPPolicy/KL                     0.00955788\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              4.53449\n",
      "GaussianMLPPolicy/LossBefore             6.45742\n",
      "GaussianMLPPolicy/dLoss                  1.92292\n",
      "GaussianMLPValueFunction/LossAfter       6.62897\n",
      "GaussianMLPValueFunction/LossBefore      6.63044\n",
      "GaussianMLPValueFunction/dLoss           0.001472\n",
      "TotalEnvSteps                            1.1904e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:16 | [trpo_pendulum] epoch #992 | Saving snapshot...\n",
      "2022-08-17 18:15:16 | [trpo_pendulum] epoch #992 | Saved\n",
      "2022-08-17 18:15:16 | [trpo_pendulum] epoch #992 | Time 632.03 s\n",
      "2022-08-17 18:15:16 | [trpo_pendulum] epoch #992 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -672.335\n",
      "Evaluation/AverageReturn             -1541.23\n",
      "Evaluation/Iteration                   992\n",
      "Evaluation/MaxReturn                 -1513.58\n",
      "Evaluation/MinReturn                 -1584.92\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    28.8778\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.62665\n",
      "GaussianMLPPolicy/KL                     0.00809388\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             11.4015\n",
      "GaussianMLPPolicy/LossBefore            13.3548\n",
      "GaussianMLPPolicy/dLoss                  1.95337\n",
      "GaussianMLPValueFunction/LossAfter       6.67239\n",
      "GaussianMLPValueFunction/LossBefore      6.6735\n",
      "GaussianMLPValueFunction/dLoss           0.00111389\n",
      "TotalEnvSteps                            1.1916e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:16 | [trpo_pendulum] epoch #993 | Saving snapshot...\n",
      "2022-08-17 18:15:16 | [trpo_pendulum] epoch #993 | Saved\n",
      "2022-08-17 18:15:16 | [trpo_pendulum] epoch #993 | Time 632.66 s\n",
      "2022-08-17 18:15:16 | [trpo_pendulum] epoch #993 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -608.219\n",
      "Evaluation/AverageReturn             -1530.82\n",
      "Evaluation/Iteration                   993\n",
      "Evaluation/MaxReturn                 -1512.29\n",
      "Evaluation/MinReturn                 -1544.08\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    10.1573\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.63418\n",
      "GaussianMLPPolicy/KL                     0.00695824\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             22.5901\n",
      "GaussianMLPPolicy/LossBefore            24.3227\n",
      "GaussianMLPPolicy/dLoss                  1.73263\n",
      "GaussianMLPValueFunction/LossAfter       6.70439\n",
      "GaussianMLPValueFunction/LossBefore      6.70624\n",
      "GaussianMLPValueFunction/dLoss           0.00185347\n",
      "TotalEnvSteps                            1.1928e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:17 | [trpo_pendulum] epoch #994 | Saving snapshot...\n",
      "2022-08-17 18:15:17 | [trpo_pendulum] epoch #994 | Saved\n",
      "2022-08-17 18:15:17 | [trpo_pendulum] epoch #994 | Time 633.31 s\n",
      "2022-08-17 18:15:17 | [trpo_pendulum] epoch #994 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -603.774\n",
      "Evaluation/AverageReturn             -1513.73\n",
      "Evaluation/Iteration                   994\n",
      "Evaluation/MaxReturn                 -1477.27\n",
      "Evaluation/MinReturn                 -1551.26\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    23.9525\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.62234\n",
      "GaussianMLPPolicy/KL                     0.0070664\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             20.3061\n",
      "GaussianMLPPolicy/LossBefore            21.9113\n",
      "GaussianMLPPolicy/dLoss                  1.60527\n",
      "GaussianMLPValueFunction/LossAfter       6.63199\n",
      "GaussianMLPValueFunction/LossBefore      6.6346\n",
      "GaussianMLPValueFunction/dLoss           0.00260353\n",
      "TotalEnvSteps                            1.194e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:18 | [trpo_pendulum] epoch #995 | Saving snapshot...\n",
      "2022-08-17 18:15:18 | [trpo_pendulum] epoch #995 | Saved\n",
      "2022-08-17 18:15:18 | [trpo_pendulum] epoch #995 | Time 633.95 s\n",
      "2022-08-17 18:15:18 | [trpo_pendulum] epoch #995 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -593.773\n",
      "Evaluation/AverageReturn             -1476.17\n",
      "Evaluation/Iteration                   995\n",
      "Evaluation/MaxReturn                 -1341.41\n",
      "Evaluation/MinReturn                 -1523.4\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    64.1043\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.6215\n",
      "GaussianMLPPolicy/KL                     0.0085545\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             10.1113\n",
      "GaussianMLPPolicy/LossBefore            12.2275\n",
      "GaussianMLPPolicy/dLoss                  2.11628\n",
      "GaussianMLPValueFunction/LossAfter       6.55268\n",
      "GaussianMLPValueFunction/LossBefore      6.57232\n",
      "GaussianMLPValueFunction/dLoss           0.0196438\n",
      "TotalEnvSteps                            1.1952e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:18 | [trpo_pendulum] epoch #996 | Saving snapshot...\n",
      "2022-08-17 18:15:18 | [trpo_pendulum] epoch #996 | Saved\n",
      "2022-08-17 18:15:18 | [trpo_pendulum] epoch #996 | Time 634.58 s\n",
      "2022-08-17 18:15:18 | [trpo_pendulum] epoch #996 | EpochTime 0.63 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -611.025\n",
      "Evaluation/AverageReturn             -1523.22\n",
      "Evaluation/Iteration                   996\n",
      "Evaluation/MaxReturn                 -1500.27\n",
      "Evaluation/MinReturn                 -1536.31\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    11.6716\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.59908\n",
      "GaussianMLPPolicy/KL                     0.00748085\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             52.6323\n",
      "GaussianMLPPolicy/LossBefore            53.2608\n",
      "GaussianMLPPolicy/dLoss                  0.62849\n",
      "GaussianMLPValueFunction/LossAfter       6.66007\n",
      "GaussianMLPValueFunction/LossBefore      6.73349\n",
      "GaussianMLPValueFunction/dLoss           0.0734186\n",
      "TotalEnvSteps                            1.1964e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:19 | [trpo_pendulum] epoch #997 | Saving snapshot...\n",
      "2022-08-17 18:15:19 | [trpo_pendulum] epoch #997 | Saved\n",
      "2022-08-17 18:15:19 | [trpo_pendulum] epoch #997 | Time 635.24 s\n",
      "2022-08-17 18:15:19 | [trpo_pendulum] epoch #997 | EpochTime 0.65 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -602.009\n",
      "Evaluation/AverageReturn             -1506.41\n",
      "Evaluation/Iteration                   997\n",
      "Evaluation/MaxReturn                 -1472.54\n",
      "Evaluation/MinReturn                 -1530.77\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    18.0541\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.5695\n",
      "GaussianMLPPolicy/KL                     0.0093375\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             25.6669\n",
      "GaussianMLPPolicy/LossBefore            26.3526\n",
      "GaussianMLPPolicy/dLoss                  0.685701\n",
      "GaussianMLPValueFunction/LossAfter       6.61746\n",
      "GaussianMLPValueFunction/LossBefore      6.62011\n",
      "GaussianMLPValueFunction/dLoss           0.00264788\n",
      "TotalEnvSteps                            1.1976e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:20 | [trpo_pendulum] epoch #998 | Saving snapshot...\n",
      "2022-08-17 18:15:20 | [trpo_pendulum] epoch #998 | Saved\n",
      "2022-08-17 18:15:20 | [trpo_pendulum] epoch #998 | Time 635.88 s\n",
      "2022-08-17 18:15:20 | [trpo_pendulum] epoch #998 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -601.494\n",
      "Evaluation/AverageReturn             -1457.1\n",
      "Evaluation/Iteration                   998\n",
      "Evaluation/MaxReturn                 -1409.01\n",
      "Evaluation/MinReturn                 -1541.03\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    52.874\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.54775\n",
      "GaussianMLPPolicy/KL                     0.00665077\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              1.27766\n",
      "GaussianMLPPolicy/LossBefore             3.37023\n",
      "GaussianMLPPolicy/dLoss                  2.09257\n",
      "GaussianMLPValueFunction/LossAfter       6.5787\n",
      "GaussianMLPValueFunction/LossBefore      6.58132\n",
      "GaussianMLPValueFunction/dLoss           0.00262213\n",
      "TotalEnvSteps                            1.1988e+06\n",
      "-----------------------------------  --------------\n",
      "2022-08-17 18:15:20 | [trpo_pendulum] epoch #999 | Saving snapshot...\n",
      "2022-08-17 18:15:20 | [trpo_pendulum] epoch #999 | Saved\n",
      "2022-08-17 18:15:20 | [trpo_pendulum] epoch #999 | Time 636.50 s\n",
      "2022-08-17 18:15:20 | [trpo_pendulum] epoch #999 | EpochTime 0.62 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -579.376\n",
      "Evaluation/AverageReturn             -1491.14\n",
      "Evaluation/Iteration                   999\n",
      "Evaluation/MaxReturn                 -1440.52\n",
      "Evaluation/MinReturn                 -1532.29\n",
      "Evaluation/NumEpisodes                   6\n",
      "Evaluation/StdReturn                    28.3105\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                2.54645\n",
      "GaussianMLPPolicy/KL                     0.00806969\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             29.9791\n",
      "GaussianMLPPolicy/LossBefore            30.2664\n",
      "GaussianMLPPolicy/dLoss                  0.287354\n",
      "GaussianMLPValueFunction/LossAfter       6.61658\n",
      "GaussianMLPValueFunction/LossBefore      6.61892\n",
      "GaussianMLPValueFunction/dLoss           0.00233889\n",
      "TotalEnvSteps                            1.2e+06\n",
      "-----------------------------------  --------------\n"
     ]
    }
   ],
   "source": [
    "trpo_pendulum(seed=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
