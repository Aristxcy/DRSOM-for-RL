{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from garage import wrap_experiment\n",
    "from garage.envs import GymEnv\n",
    "from garage.experiment.deterministic import set_seed\n",
    "from garage.sampler import LocalSampler\n",
    "from garage.torch.algos import TRPO\n",
    "from garage.torch.algos import VPG\n",
    "from garage.torch.policies import GaussianMLPPolicy\n",
    "from garage.torch.value_functions import GaussianMLPValueFunction\n",
    "from garage.trainer import Trainer\n",
    "\n",
    "@wrap_experiment\n",
    "def trpo_pendulum(ctxt=None, seed=1):\n",
    "    \"\"\"Train TRPO with InvertedDoublePendulum-v2 environment.\n",
    "    Args:\n",
    "        ctxt (garage.experiment.ExperimentContext): The experiment\n",
    "            configuration used by Trainer to create the snapshotter.\n",
    "        seed (int): Used to seed the random number generator to produce\n",
    "            determinism.\n",
    "    \"\"\"\n",
    "    set_seed(seed)\n",
    "    env = GymEnv('MountainCarContinuous-v0')\n",
    "\n",
    "    trainer = Trainer(ctxt)\n",
    "\n",
    "    policy = GaussianMLPPolicy(env.spec,\n",
    "                               hidden_sizes=[32, 32],\n",
    "                               hidden_nonlinearity=torch.tanh,\n",
    "                               output_nonlinearity=None)\n",
    "\n",
    "    value_function = GaussianMLPValueFunction(env_spec=env.spec,\n",
    "                                              hidden_sizes=(32, 32),\n",
    "                                              hidden_nonlinearity=torch.tanh,\n",
    "                                              output_nonlinearity=None)\n",
    "\n",
    "    sampler = LocalSampler(agents=policy,\n",
    "                           envs=env,\n",
    "                           max_episode_length=env.spec.max_episode_length)\n",
    "\n",
    "    algo = VPG(env_spec=env.spec,\n",
    "                policy=policy,\n",
    "                value_function=value_function,\n",
    "                sampler=sampler,\n",
    "                discount=0.99,\n",
    "                center_adv=False)\n",
    "\n",
    "    trainer.setup(algo, env)\n",
    "    trainer.train(n_epochs=100, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-24 10:11:04 | [trpo_pendulum] Logging to d:\\Github\\DRSOM-for-RL\\data/local/experiment/trpo_pendulum_41\n",
      "2022-08-24 10:11:04 | [trpo_pendulum] Obtaining samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\lib\\site-packages\\garage\\experiment\\deterministic.py:36: UserWarning: Enabeling deterministic mode in PyTorch can have a performance impact when using GPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-24 10:11:05 | [trpo_pendulum] epoch #0 | Saving snapshot...\n",
      "2022-08-24 10:11:05 | [trpo_pendulum] epoch #0 | Saved\n",
      "2022-08-24 10:11:05 | [trpo_pendulum] epoch #0 | Time 0.55 s\n",
      "2022-08-24 10:11:05 | [trpo_pendulum] epoch #0 | EpochTime 0.55 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -10.3502\n",
      "Evaluation/AverageReturn              -96.0921\n",
      "Evaluation/Iteration                    0\n",
      "Evaluation/MaxReturn                  -92.4895\n",
      "Evaluation/MinReturn                  -99.6948\n",
      "Evaluation/NumEpisodes                  2\n",
      "Evaluation/StdReturn                    3.60265\n",
      "Evaluation/TerminationRate              0\n",
      "GaussianMLPPolicy/Entropy               1.41994\n",
      "GaussianMLPPolicy/KL                    0.000822561\n",
      "GaussianMLPPolicy/KLBefore              0\n",
      "GaussianMLPPolicy/LossAfter           -12.2425\n",
      "GaussianMLPPolicy/LossBefore          -12.2239\n",
      "GaussianMLPPolicy/dLoss                 0.0186205\n",
      "GaussianMLPValueFunction/LossAfter     40.6104\n",
      "GaussianMLPValueFunction/LossBefore    41.0757\n",
      "GaussianMLPValueFunction/dLoss          0.46534\n",
      "TotalEnvSteps                        1998\n",
      "-----------------------------------  --------------\n",
      "2022-08-24 10:11:06 | [trpo_pendulum] epoch #1 | Saving snapshot...\n",
      "2022-08-24 10:11:06 | [trpo_pendulum] epoch #1 | Saved\n",
      "2022-08-24 10:11:06 | [trpo_pendulum] epoch #1 | Time 1.31 s\n",
      "2022-08-24 10:11:06 | [trpo_pendulum] epoch #1 | EpochTime 0.76 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -9.62744\n",
      "Evaluation/AverageReturn              -99.1107\n",
      "Evaluation/Iteration                    1\n",
      "Evaluation/MaxReturn                  -92.7108\n",
      "Evaluation/MinReturn                 -105.511\n",
      "Evaluation/NumEpisodes                  2\n",
      "Evaluation/StdReturn                    6.39988\n",
      "Evaluation/TerminationRate              0\n",
      "GaussianMLPPolicy/Entropy               1.41983\n",
      "GaussianMLPPolicy/KL                    0.000592431\n",
      "GaussianMLPPolicy/KLBefore              0\n",
      "GaussianMLPPolicy/LossAfter           -12.8247\n",
      "GaussianMLPPolicy/LossBefore          -12.817\n",
      "GaussianMLPPolicy/dLoss                 0.00774765\n",
      "GaussianMLPValueFunction/LossAfter     43.2931\n",
      "GaussianMLPValueFunction/LossBefore    43.7816\n",
      "GaussianMLPValueFunction/dLoss          0.488464\n",
      "TotalEnvSteps                        3996\n",
      "-----------------------------------  --------------\n",
      "2022-08-24 10:11:06 | [trpo_pendulum] epoch #2 | Saving snapshot...\n",
      "2022-08-24 10:11:06 | [trpo_pendulum] epoch #2 | Saved\n",
      "2022-08-24 10:11:06 | [trpo_pendulum] epoch #2 | Time 1.99 s\n",
      "2022-08-24 10:11:06 | [trpo_pendulum] epoch #2 | EpochTime 0.68 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn     -9.76467\n",
      "Evaluation/AverageReturn              -99.851\n",
      "Evaluation/Iteration                    2\n",
      "Evaluation/MaxReturn                  -97.2891\n",
      "Evaluation/MinReturn                 -102.413\n",
      "Evaluation/NumEpisodes                  2\n",
      "Evaluation/StdReturn                    2.56187\n",
      "Evaluation/TerminationRate              0\n",
      "GaussianMLPPolicy/Entropy               1.41932\n",
      "GaussianMLPPolicy/KL                    0.00066555\n",
      "GaussianMLPPolicy/KLBefore              0\n",
      "GaussianMLPPolicy/LossAfter           -12.8702\n",
      "GaussianMLPPolicy/LossBefore          -12.8572\n",
      "GaussianMLPPolicy/dLoss                 0.0129766\n",
      "GaussianMLPValueFunction/LossAfter     43.1312\n",
      "GaussianMLPValueFunction/LossBefore    43.6181\n",
      "GaussianMLPValueFunction/dLoss          0.486961\n",
      "TotalEnvSteps                        5994\n",
      "-----------------------------------  -------------\n",
      "2022-08-24 10:11:07 | [trpo_pendulum] epoch #3 | Saving snapshot...\n",
      "2022-08-24 10:11:07 | [trpo_pendulum] epoch #3 | Saved\n",
      "2022-08-24 10:11:07 | [trpo_pendulum] epoch #3 | Time 2.64 s\n",
      "2022-08-24 10:11:07 | [trpo_pendulum] epoch #3 | EpochTime 0.64 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn     -9.26305\n",
      "Evaluation/AverageReturn             -101.586\n",
      "Evaluation/Iteration                    3\n",
      "Evaluation/MaxReturn                 -101.135\n",
      "Evaluation/MinReturn                 -102.038\n",
      "Evaluation/NumEpisodes                  2\n",
      "Evaluation/StdReturn                    0.45121\n",
      "Evaluation/TerminationRate              0\n",
      "GaussianMLPPolicy/Entropy               1.41861\n",
      "GaussianMLPPolicy/KL                    0.000378461\n",
      "GaussianMLPPolicy/KLBefore              0\n",
      "GaussianMLPPolicy/LossAfter           -13.1535\n",
      "GaussianMLPPolicy/LossBefore          -13.151\n",
      "GaussianMLPPolicy/dLoss                 0.0025034\n",
      "GaussianMLPValueFunction/LossAfter     44.5468\n",
      "GaussianMLPValueFunction/LossBefore    45.0441\n",
      "GaussianMLPValueFunction/dLoss          0.49733\n",
      "TotalEnvSteps                        7992\n",
      "-----------------------------------  --------------\n",
      "2022-08-24 10:11:07 | [trpo_pendulum] epoch #4 | Saving snapshot...\n",
      "2022-08-24 10:11:07 | [trpo_pendulum] epoch #4 | Saved\n",
      "2022-08-24 10:11:07 | [trpo_pendulum] epoch #4 | Time 3.20 s\n",
      "2022-08-24 10:11:07 | [trpo_pendulum] epoch #4 | EpochTime 0.56 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -10.4877\n",
      "Evaluation/AverageReturn             -103.503\n",
      "Evaluation/Iteration                    4\n",
      "Evaluation/MaxReturn                  -95.5781\n",
      "Evaluation/MinReturn                 -111.427\n",
      "Evaluation/NumEpisodes                  2\n",
      "Evaluation/StdReturn                    7.92465\n",
      "Evaluation/TerminationRate              0\n",
      "GaussianMLPPolicy/Entropy               1.41783\n",
      "GaussianMLPPolicy/KL                    7.24825e-07\n",
      "GaussianMLPPolicy/KLBefore              0\n",
      "GaussianMLPPolicy/LossAfter           -13.3041\n",
      "GaussianMLPPolicy/LossBefore          -13.3039\n",
      "GaussianMLPPolicy/dLoss                 0.000250816\n",
      "GaussianMLPValueFunction/LossAfter     45.3582\n",
      "GaussianMLPValueFunction/LossBefore    45.8652\n",
      "GaussianMLPValueFunction/dLoss          0.507008\n",
      "TotalEnvSteps                        9990\n",
      "-----------------------------------  --------------\n",
      "2022-08-24 10:11:08 | [trpo_pendulum] epoch #5 | Saving snapshot...\n",
      "2022-08-24 10:11:08 | [trpo_pendulum] epoch #5 | Saved\n",
      "2022-08-24 10:11:08 | [trpo_pendulum] epoch #5 | Time 3.74 s\n",
      "2022-08-24 10:11:08 | [trpo_pendulum] epoch #5 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -10.6936\n",
      "Evaluation/AverageReturn              -102.978\n",
      "Evaluation/Iteration                     5\n",
      "Evaluation/MaxReturn                  -101.204\n",
      "Evaluation/MinReturn                  -104.751\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     1.7731\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.41697\n",
      "GaussianMLPPolicy/KL                     4.78014e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -13.0869\n",
      "GaussianMLPPolicy/LossBefore           -13.0862\n",
      "GaussianMLPPolicy/dLoss                  0.000641823\n",
      "GaussianMLPValueFunction/LossAfter      43.6488\n",
      "GaussianMLPValueFunction/LossBefore     44.143\n",
      "GaussianMLPValueFunction/dLoss           0.494186\n",
      "TotalEnvSteps                        11988\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:09 | [trpo_pendulum] epoch #6 | Saving snapshot...\n",
      "2022-08-24 10:11:09 | [trpo_pendulum] epoch #6 | Saved\n",
      "2022-08-24 10:11:09 | [trpo_pendulum] epoch #6 | Time 4.29 s\n",
      "2022-08-24 10:11:09 | [trpo_pendulum] epoch #6 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -11.5164\n",
      "Evaluation/AverageReturn              -100.364\n",
      "Evaluation/Iteration                     6\n",
      "Evaluation/MaxReturn                   -99.4765\n",
      "Evaluation/MinReturn                  -101.252\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.887556\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.4161\n",
      "GaussianMLPPolicy/KL                     5.75864e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -12.4525\n",
      "GaussianMLPPolicy/LossBefore           -12.4514\n",
      "GaussianMLPPolicy/dLoss                  0.00108814\n",
      "GaussianMLPValueFunction/LossAfter      40.0789\n",
      "GaussianMLPValueFunction/LossBefore     40.5435\n",
      "GaussianMLPValueFunction/dLoss           0.464584\n",
      "TotalEnvSteps                        13986\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:09 | [trpo_pendulum] epoch #7 | Saving snapshot...\n",
      "2022-08-24 10:11:09 | [trpo_pendulum] epoch #7 | Saved\n",
      "2022-08-24 10:11:09 | [trpo_pendulum] epoch #7 | Time 4.83 s\n",
      "2022-08-24 10:11:09 | [trpo_pendulum] epoch #7 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -11.3315\n",
      "Evaluation/AverageReturn              -106.474\n",
      "Evaluation/Iteration                     7\n",
      "Evaluation/MaxReturn                  -103.343\n",
      "Evaluation/MinReturn                  -109.604\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     3.1307\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.41521\n",
      "GaussianMLPPolicy/KL                     2.83933e-05\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -13.5878\n",
      "GaussianMLPPolicy/LossBefore           -13.5858\n",
      "GaussianMLPPolicy/dLoss                  0.00203419\n",
      "GaussianMLPValueFunction/LossAfter      45.7439\n",
      "GaussianMLPValueFunction/LossBefore     46.2397\n",
      "GaussianMLPValueFunction/dLoss           0.495777\n",
      "TotalEnvSteps                        15984\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:10 | [trpo_pendulum] epoch #8 | Saving snapshot...\n",
      "2022-08-24 10:11:10 | [trpo_pendulum] epoch #8 | Saved\n",
      "2022-08-24 10:11:10 | [trpo_pendulum] epoch #8 | Time 5.37 s\n",
      "2022-08-24 10:11:10 | [trpo_pendulum] epoch #8 | EpochTime 0.53 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -9.93934\n",
      "Evaluation/AverageReturn              -100.821\n",
      "Evaluation/Iteration                     8\n",
      "Evaluation/MaxReturn                   -96.8314\n",
      "Evaluation/MinReturn                  -104.81\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     3.98953\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.41435\n",
      "GaussianMLPPolicy/KL                     1.27908e-05\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -12.599\n",
      "GaussianMLPPolicy/LossBefore           -12.5989\n",
      "GaussianMLPPolicy/dLoss                  3.8147e-05\n",
      "GaussianMLPValueFunction/LossAfter      41.0633\n",
      "GaussianMLPValueFunction/LossBefore     41.5214\n",
      "GaussianMLPValueFunction/dLoss           0.458035\n",
      "TotalEnvSteps                        17982\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:10 | [trpo_pendulum] epoch #9 | Saving snapshot...\n",
      "2022-08-24 10:11:10 | [trpo_pendulum] epoch #9 | Saved\n",
      "2022-08-24 10:11:10 | [trpo_pendulum] epoch #9 | Time 5.91 s\n",
      "2022-08-24 10:11:10 | [trpo_pendulum] epoch #9 | EpochTime 0.53 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -9.52735\n",
      "Evaluation/AverageReturn               -99.1363\n",
      "Evaluation/Iteration                     9\n",
      "Evaluation/MaxReturn                   -96.9308\n",
      "Evaluation/MinReturn                  -101.342\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     2.20553\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.41354\n",
      "GaussianMLPPolicy/KL                     3.77457e-05\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -12.2503\n",
      "GaussianMLPPolicy/LossBefore           -12.2488\n",
      "GaussianMLPPolicy/dLoss                  0.00144386\n",
      "GaussianMLPValueFunction/LossAfter      39.1536\n",
      "GaussianMLPValueFunction/LossBefore     39.6076\n",
      "GaussianMLPValueFunction/dLoss           0.453953\n",
      "TotalEnvSteps                        19980\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:11 | [trpo_pendulum] epoch #10 | Saving snapshot...\n",
      "2022-08-24 10:11:11 | [trpo_pendulum] epoch #10 | Saved\n",
      "2022-08-24 10:11:11 | [trpo_pendulum] epoch #10 | Time 6.45 s\n",
      "2022-08-24 10:11:11 | [trpo_pendulum] epoch #10 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -9.47081\n",
      "Evaluation/AverageReturn               -97.8966\n",
      "Evaluation/Iteration                    10\n",
      "Evaluation/MaxReturn                   -94.1883\n",
      "Evaluation/MinReturn                  -101.605\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     3.70832\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.41288\n",
      "GaussianMLPPolicy/KL                     1.09601e-05\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -11.9037\n",
      "GaussianMLPPolicy/LossBefore           -11.9041\n",
      "GaussianMLPPolicy/dLoss                 -0.000385284\n",
      "GaussianMLPValueFunction/LossAfter      37.2543\n",
      "GaussianMLPValueFunction/LossBefore     37.6975\n",
      "GaussianMLPValueFunction/dLoss           0.443153\n",
      "TotalEnvSteps                        21978\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:11 | [trpo_pendulum] epoch #11 | Saving snapshot...\n",
      "2022-08-24 10:11:11 | [trpo_pendulum] epoch #11 | Saved\n",
      "2022-08-24 10:11:11 | [trpo_pendulum] epoch #11 | Time 6.98 s\n",
      "2022-08-24 10:11:11 | [trpo_pendulum] epoch #11 | EpochTime 0.53 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -9.70713\n",
      "Evaluation/AverageReturn              -104.906\n",
      "Evaluation/Iteration                    11\n",
      "Evaluation/MaxReturn                  -100.705\n",
      "Evaluation/MinReturn                  -109.107\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     4.20132\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.41212\n",
      "GaussianMLPPolicy/KL                     1.64578e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -13.1765\n",
      "GaussianMLPPolicy/LossBefore           -13.1761\n",
      "GaussianMLPPolicy/dLoss                  0.000401497\n",
      "GaussianMLPValueFunction/LossAfter      43.5006\n",
      "GaussianMLPValueFunction/LossBefore     43.9832\n",
      "GaussianMLPValueFunction/dLoss           0.482571\n",
      "TotalEnvSteps                        23976\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:12 | [trpo_pendulum] epoch #12 | Saving snapshot...\n",
      "2022-08-24 10:11:12 | [trpo_pendulum] epoch #12 | Saved\n",
      "2022-08-24 10:11:12 | [trpo_pendulum] epoch #12 | Time 7.53 s\n",
      "2022-08-24 10:11:12 | [trpo_pendulum] epoch #12 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -11.4766\n",
      "Evaluation/AverageReturn              -108.83\n",
      "Evaluation/Iteration                    12\n",
      "Evaluation/MaxReturn                  -106.628\n",
      "Evaluation/MinReturn                  -111.032\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     2.20176\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.41129\n",
      "GaussianMLPPolicy/KL                     1.69764e-05\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -13.5709\n",
      "GaussianMLPPolicy/LossBefore           -13.5688\n",
      "GaussianMLPPolicy/dLoss                  0.00205326\n",
      "GaussianMLPValueFunction/LossAfter      44.6951\n",
      "GaussianMLPValueFunction/LossBefore     45.1911\n",
      "GaussianMLPValueFunction/dLoss           0.495918\n",
      "TotalEnvSteps                        25974\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:12 | [trpo_pendulum] epoch #13 | Saving snapshot...\n",
      "2022-08-24 10:11:12 | [trpo_pendulum] epoch #13 | Saved\n",
      "2022-08-24 10:11:12 | [trpo_pendulum] epoch #13 | Time 8.07 s\n",
      "2022-08-24 10:11:12 | [trpo_pendulum] epoch #13 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -9.48041\n",
      "Evaluation/AverageReturn               -91.1474\n",
      "Evaluation/Iteration                    13\n",
      "Evaluation/MaxReturn                   -88.2404\n",
      "Evaluation/MinReturn                   -94.0545\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     2.90706\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.41071\n",
      "GaussianMLPPolicy/KL                     5.51359e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -10.5613\n",
      "GaussianMLPPolicy/LossBefore           -10.5617\n",
      "GaussianMLPPolicy/dLoss                 -0.000411034\n",
      "GaussianMLPValueFunction/LossAfter      30.9601\n",
      "GaussianMLPValueFunction/LossBefore     31.3544\n",
      "GaussianMLPValueFunction/dLoss           0.39422\n",
      "TotalEnvSteps                        27972\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:13 | [trpo_pendulum] epoch #14 | Saving snapshot...\n",
      "2022-08-24 10:11:13 | [trpo_pendulum] epoch #14 | Saved\n",
      "2022-08-24 10:11:13 | [trpo_pendulum] epoch #14 | Time 8.61 s\n",
      "2022-08-24 10:11:13 | [trpo_pendulum] epoch #14 | EpochTime 0.53 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -8.94516\n",
      "Evaluation/AverageReturn               -92.2963\n",
      "Evaluation/Iteration                    14\n",
      "Evaluation/MaxReturn                   -91.4765\n",
      "Evaluation/MinReturn                   -93.1162\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.819871\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.4103\n",
      "GaussianMLPPolicy/KL                     1.5226e-05\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -10.7738\n",
      "GaussianMLPPolicy/LossBefore           -10.7734\n",
      "GaussianMLPPolicy/dLoss                  0.000340462\n",
      "GaussianMLPValueFunction/LossAfter      32.051\n",
      "GaussianMLPValueFunction/LossBefore     32.4486\n",
      "GaussianMLPValueFunction/dLoss           0.397587\n",
      "TotalEnvSteps                        29970\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:13 | [trpo_pendulum] epoch #15 | Saving snapshot...\n",
      "2022-08-24 10:11:13 | [trpo_pendulum] epoch #15 | Saved\n",
      "2022-08-24 10:11:13 | [trpo_pendulum] epoch #15 | Time 9.16 s\n",
      "2022-08-24 10:11:13 | [trpo_pendulum] epoch #15 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -9.472\n",
      "Evaluation/AverageReturn              -104.572\n",
      "Evaluation/Iteration                    15\n",
      "Evaluation/MaxReturn                  -104.477\n",
      "Evaluation/MinReturn                  -104.666\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.0943707\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.40979\n",
      "GaussianMLPPolicy/KL                     0.000110741\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -12.8996\n",
      "GaussianMLPPolicy/LossBefore           -12.8933\n",
      "GaussianMLPPolicy/dLoss                  0.00633621\n",
      "GaussianMLPValueFunction/LossAfter      41.7289\n",
      "GaussianMLPValueFunction/LossBefore     42.1993\n",
      "GaussianMLPValueFunction/dLoss           0.470375\n",
      "TotalEnvSteps                        31968\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:14 | [trpo_pendulum] epoch #16 | Saving snapshot...\n",
      "2022-08-24 10:11:14 | [trpo_pendulum] epoch #16 | Saved\n",
      "2022-08-24 10:11:14 | [trpo_pendulum] epoch #16 | Time 9.71 s\n",
      "2022-08-24 10:11:14 | [trpo_pendulum] epoch #16 | EpochTime 0.55 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -9.7584\n",
      "Evaluation/AverageReturn               -98.4957\n",
      "Evaluation/Iteration                    16\n",
      "Evaluation/MaxReturn                   -97.6242\n",
      "Evaluation/MinReturn                   -99.3673\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.871581\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.40926\n",
      "GaussianMLPPolicy/KL                     6.95357e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -11.7251\n",
      "GaussianMLPPolicy/LossBefore           -11.726\n",
      "GaussianMLPPolicy/dLoss                 -0.00090313\n",
      "GaussianMLPValueFunction/LossAfter      35.6991\n",
      "GaussianMLPValueFunction/LossBefore     36.121\n",
      "GaussianMLPValueFunction/dLoss           0.42186\n",
      "TotalEnvSteps                        33966\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:14 | [trpo_pendulum] epoch #17 | Saving snapshot...\n",
      "2022-08-24 10:11:15 | [trpo_pendulum] epoch #17 | Saved\n",
      "2022-08-24 10:11:15 | [trpo_pendulum] epoch #17 | Time 10.27 s\n",
      "2022-08-24 10:11:15 | [trpo_pendulum] epoch #17 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -8.69591\n",
      "Evaluation/AverageReturn               -90.2944\n",
      "Evaluation/Iteration                    17\n",
      "Evaluation/MaxReturn                   -89.757\n",
      "Evaluation/MinReturn                   -90.8319\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.537429\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.40893\n",
      "GaussianMLPPolicy/KL                     4.4273e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -10.2715\n",
      "GaussianMLPPolicy/LossBefore           -10.2717\n",
      "GaussianMLPPolicy/dLoss                 -0.000178337\n",
      "GaussianMLPValueFunction/LossAfter      29.3189\n",
      "GaussianMLPValueFunction/LossBefore     29.6973\n",
      "GaussianMLPValueFunction/dLoss           0.378382\n",
      "TotalEnvSteps                        35964\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:15 | [trpo_pendulum] epoch #18 | Saving snapshot...\n",
      "2022-08-24 10:11:15 | [trpo_pendulum] epoch #18 | Saved\n",
      "2022-08-24 10:11:15 | [trpo_pendulum] epoch #18 | Time 10.81 s\n",
      "2022-08-24 10:11:15 | [trpo_pendulum] epoch #18 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -10.4609\n",
      "Evaluation/AverageReturn              -100.299\n",
      "Evaluation/Iteration                    18\n",
      "Evaluation/MaxReturn                   -96.8875\n",
      "Evaluation/MinReturn                  -103.711\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     3.41181\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.40854\n",
      "GaussianMLPPolicy/KL                     1.34611e-05\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -11.8358\n",
      "GaussianMLPPolicy/LossBefore           -11.834\n",
      "GaussianMLPPolicy/dLoss                  0.00176334\n",
      "GaussianMLPValueFunction/LossAfter      35.7523\n",
      "GaussianMLPValueFunction/LossBefore     36.1687\n",
      "GaussianMLPValueFunction/dLoss           0.416409\n",
      "TotalEnvSteps                        37962\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:16 | [trpo_pendulum] epoch #19 | Saving snapshot...\n",
      "2022-08-24 10:11:16 | [trpo_pendulum] epoch #19 | Saved\n",
      "2022-08-24 10:11:16 | [trpo_pendulum] epoch #19 | Time 11.36 s\n",
      "2022-08-24 10:11:16 | [trpo_pendulum] epoch #19 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -10.401\n",
      "Evaluation/AverageReturn               -98.6998\n",
      "Evaluation/Iteration                    19\n",
      "Evaluation/MaxReturn                   -95.2687\n",
      "Evaluation/MinReturn                  -102.131\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     3.4311\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.40812\n",
      "GaussianMLPPolicy/KL                     2.87314e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -11.4807\n",
      "GaussianMLPPolicy/LossBefore           -11.4808\n",
      "GaussianMLPPolicy/dLoss                 -5.24521e-05\n",
      "GaussianMLPValueFunction/LossAfter      34.219\n",
      "GaussianMLPValueFunction/LossBefore     34.6322\n",
      "GaussianMLPValueFunction/dLoss           0.413155\n",
      "TotalEnvSteps                        39960\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:16 | [trpo_pendulum] epoch #20 | Saving snapshot...\n",
      "2022-08-24 10:11:16 | [trpo_pendulum] epoch #20 | Saved\n",
      "2022-08-24 10:11:16 | [trpo_pendulum] epoch #20 | Time 11.90 s\n",
      "2022-08-24 10:11:16 | [trpo_pendulum] epoch #20 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -9.71592\n",
      "Evaluation/AverageReturn               -94.5774\n",
      "Evaluation/Iteration                    20\n",
      "Evaluation/MaxReturn                   -92.0536\n",
      "Evaluation/MinReturn                   -97.1012\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     2.52378\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.40776\n",
      "GaussianMLPPolicy/KL                     1.41735e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -10.7424\n",
      "GaussianMLPPolicy/LossBefore           -10.7422\n",
      "GaussianMLPPolicy/dLoss                  0.000190735\n",
      "GaussianMLPValueFunction/LossAfter      31.1681\n",
      "GaussianMLPValueFunction/LossBefore     31.5595\n",
      "GaussianMLPValueFunction/dLoss           0.391401\n",
      "TotalEnvSteps                        41958\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:17 | [trpo_pendulum] epoch #21 | Saving snapshot...\n",
      "2022-08-24 10:11:17 | [trpo_pendulum] epoch #21 | Saved\n",
      "2022-08-24 10:11:17 | [trpo_pendulum] epoch #21 | Time 12.45 s\n",
      "2022-08-24 10:11:17 | [trpo_pendulum] epoch #21 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -10.67\n",
      "Evaluation/AverageReturn              -101.435\n",
      "Evaluation/Iteration                    21\n",
      "Evaluation/MaxReturn                   -97.0714\n",
      "Evaluation/MinReturn                  -105.798\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     4.36356\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.40734\n",
      "GaussianMLPPolicy/KL                     6.16082e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -11.7765\n",
      "GaussianMLPPolicy/LossBefore           -11.7756\n",
      "GaussianMLPPolicy/dLoss                  0.000902176\n",
      "GaussianMLPValueFunction/LossAfter      34.9254\n",
      "GaussianMLPValueFunction/LossBefore     35.3505\n",
      "GaussianMLPValueFunction/dLoss           0.425045\n",
      "TotalEnvSteps                        43956\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:17 | [trpo_pendulum] epoch #22 | Saving snapshot...\n",
      "2022-08-24 10:11:17 | [trpo_pendulum] epoch #22 | Saved\n",
      "2022-08-24 10:11:17 | [trpo_pendulum] epoch #22 | Time 12.98 s\n",
      "2022-08-24 10:11:17 | [trpo_pendulum] epoch #22 | EpochTime 0.53 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -9.51237\n",
      "Evaluation/AverageReturn               -99.3\n",
      "Evaluation/Iteration                    22\n",
      "Evaluation/MaxReturn                   -98.5998\n",
      "Evaluation/MinReturn                  -100\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.700181\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.4069\n",
      "GaussianMLPPolicy/KL                     3.69809e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -11.4316\n",
      "GaussianMLPPolicy/LossBefore           -11.4309\n",
      "GaussianMLPPolicy/dLoss                  0.000711441\n",
      "GaussianMLPValueFunction/LossAfter      33.7984\n",
      "GaussianMLPValueFunction/LossBefore     34.2205\n",
      "GaussianMLPValueFunction/dLoss           0.422096\n",
      "TotalEnvSteps                        45954\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:18 | [trpo_pendulum] epoch #23 | Saving snapshot...\n",
      "2022-08-24 10:11:18 | [trpo_pendulum] epoch #23 | Saved\n",
      "2022-08-24 10:11:18 | [trpo_pendulum] epoch #23 | Time 13.52 s\n",
      "2022-08-24 10:11:18 | [trpo_pendulum] epoch #23 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -10.4836\n",
      "Evaluation/AverageReturn              -107.318\n",
      "Evaluation/Iteration                    23\n",
      "Evaluation/MaxReturn                  -106.089\n",
      "Evaluation/MinReturn                  -108.548\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     1.22939\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.40631\n",
      "GaussianMLPPolicy/KL                     3.08085e-05\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -12.7567\n",
      "GaussianMLPPolicy/LossBefore           -12.7542\n",
      "GaussianMLPPolicy/dLoss                  0.00255108\n",
      "GaussianMLPValueFunction/LossAfter      39.3881\n",
      "GaussianMLPValueFunction/LossBefore     39.8561\n",
      "GaussianMLPValueFunction/dLoss           0.467964\n",
      "TotalEnvSteps                        47952\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:18 | [trpo_pendulum] epoch #24 | Saving snapshot...\n",
      "2022-08-24 10:11:18 | [trpo_pendulum] epoch #24 | Saved\n",
      "2022-08-24 10:11:18 | [trpo_pendulum] epoch #24 | Time 14.06 s\n",
      "2022-08-24 10:11:18 | [trpo_pendulum] epoch #24 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -9.92226\n",
      "Evaluation/AverageReturn              -100.296\n",
      "Evaluation/Iteration                    24\n",
      "Evaluation/MaxReturn                  -100.276\n",
      "Evaluation/MinReturn                  -100.315\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.0191372\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.4057\n",
      "GaussianMLPPolicy/KL                     7.28976e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -11.4863\n",
      "GaussianMLPPolicy/LossBefore           -11.4865\n",
      "GaussianMLPPolicy/dLoss                 -0.000184059\n",
      "GaussianMLPValueFunction/LossAfter      33.2813\n",
      "GaussianMLPValueFunction/LossBefore     33.7026\n",
      "GaussianMLPValueFunction/dLoss           0.421314\n",
      "TotalEnvSteps                        49950\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:19 | [trpo_pendulum] epoch #25 | Saving snapshot...\n",
      "2022-08-24 10:11:19 | [trpo_pendulum] epoch #25 | Saved\n",
      "2022-08-24 10:11:19 | [trpo_pendulum] epoch #25 | Time 14.72 s\n",
      "2022-08-24 10:11:19 | [trpo_pendulum] epoch #25 | EpochTime 0.65 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -9.36443\n",
      "Evaluation/AverageReturn              -103.816\n",
      "Evaluation/Iteration                    25\n",
      "Evaluation/MaxReturn                   -99.0023\n",
      "Evaluation/MinReturn                  -108.63\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     4.81406\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.40501\n",
      "GaussianMLPPolicy/KL                     2.91661e-05\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -12.1635\n",
      "GaussianMLPPolicy/LossBefore           -12.1615\n",
      "GaussianMLPPolicy/dLoss                  0.00207329\n",
      "GaussianMLPValueFunction/LossAfter      36.7738\n",
      "GaussianMLPValueFunction/LossBefore     37.2267\n",
      "GaussianMLPValueFunction/dLoss           0.452927\n",
      "TotalEnvSteps                        51948\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:19 | [trpo_pendulum] epoch #26 | Saving snapshot...\n",
      "2022-08-24 10:11:20 | [trpo_pendulum] epoch #26 | Saved\n",
      "2022-08-24 10:11:20 | [trpo_pendulum] epoch #26 | Time 15.26 s\n",
      "2022-08-24 10:11:20 | [trpo_pendulum] epoch #26 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -9.77609\n",
      "Evaluation/AverageReturn              -101.696\n",
      "Evaluation/Iteration                    26\n",
      "Evaluation/MaxReturn                  -101.399\n",
      "Evaluation/MinReturn                  -101.992\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.296434\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.40428\n",
      "GaussianMLPPolicy/KL                     8.99168e-05\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -11.6001\n",
      "GaussianMLPPolicy/LossBefore           -11.5952\n",
      "GaussianMLPPolicy/dLoss                  0.00493431\n",
      "GaussianMLPValueFunction/LossAfter      33.8704\n",
      "GaussianMLPValueFunction/LossBefore     34.3101\n",
      "GaussianMLPValueFunction/dLoss           0.439651\n",
      "TotalEnvSteps                        53946\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:20 | [trpo_pendulum] epoch #27 | Saving snapshot...\n",
      "2022-08-24 10:11:20 | [trpo_pendulum] epoch #27 | Saved\n",
      "2022-08-24 10:11:20 | [trpo_pendulum] epoch #27 | Time 15.81 s\n",
      "2022-08-24 10:11:20 | [trpo_pendulum] epoch #27 | EpochTime 0.55 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -8.90799\n",
      "Evaluation/AverageReturn               -99.5844\n",
      "Evaluation/Iteration                    27\n",
      "Evaluation/MaxReturn                   -99.3556\n",
      "Evaluation/MinReturn                   -99.8132\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.228813\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.40354\n",
      "GaussianMLPPolicy/KL                     3.38664e-05\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -11.2958\n",
      "GaussianMLPPolicy/LossBefore           -11.2966\n",
      "GaussianMLPPolicy/dLoss                 -0.000776291\n",
      "GaussianMLPValueFunction/LossAfter      32.4925\n",
      "GaussianMLPValueFunction/LossBefore     32.9162\n",
      "GaussianMLPValueFunction/dLoss           0.423714\n",
      "TotalEnvSteps                        55944\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:21 | [trpo_pendulum] epoch #28 | Saving snapshot...\n",
      "2022-08-24 10:11:21 | [trpo_pendulum] epoch #28 | Saved\n",
      "2022-08-24 10:11:21 | [trpo_pendulum] epoch #28 | Time 16.37 s\n",
      "2022-08-24 10:11:21 | [trpo_pendulum] epoch #28 | EpochTime 0.55 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -8.92656\n",
      "Evaluation/AverageReturn               -97.3429\n",
      "Evaluation/Iteration                    28\n",
      "Evaluation/MaxReturn                   -95.5483\n",
      "Evaluation/MinReturn                   -99.1375\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     1.79461\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.40282\n",
      "GaussianMLPPolicy/KL                     6.79829e-05\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -10.8158\n",
      "GaussianMLPPolicy/LossBefore           -10.813\n",
      "GaussianMLPPolicy/dLoss                  0.00280094\n",
      "GaussianMLPValueFunction/LossAfter      30.3991\n",
      "GaussianMLPValueFunction/LossBefore     30.8125\n",
      "GaussianMLPValueFunction/dLoss           0.413311\n",
      "TotalEnvSteps                        57942\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:21 | [trpo_pendulum] epoch #29 | Saving snapshot...\n",
      "2022-08-24 10:11:21 | [trpo_pendulum] epoch #29 | Saved\n",
      "2022-08-24 10:11:21 | [trpo_pendulum] epoch #29 | Time 16.91 s\n",
      "2022-08-24 10:11:21 | [trpo_pendulum] epoch #29 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -9.34149\n",
      "Evaluation/AverageReturn               -94.6613\n",
      "Evaluation/Iteration                    29\n",
      "Evaluation/MaxReturn                   -93.2871\n",
      "Evaluation/MinReturn                   -96.0354\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     1.37415\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.40215\n",
      "GaussianMLPPolicy/KL                     4.92762e-05\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -10.2555\n",
      "GaussianMLPPolicy/LossBefore           -10.2553\n",
      "GaussianMLPPolicy/dLoss                  0.000247002\n",
      "GaussianMLPValueFunction/LossAfter      28.1023\n",
      "GaussianMLPValueFunction/LossBefore     28.4928\n",
      "GaussianMLPValueFunction/dLoss           0.390469\n",
      "TotalEnvSteps                        59940\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:22 | [trpo_pendulum] epoch #30 | Saving snapshot...\n",
      "2022-08-24 10:11:22 | [trpo_pendulum] epoch #30 | Saved\n",
      "2022-08-24 10:11:22 | [trpo_pendulum] epoch #30 | Time 17.45 s\n",
      "2022-08-24 10:11:22 | [trpo_pendulum] epoch #30 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -9.68438\n",
      "Evaluation/AverageReturn               -98.0795\n",
      "Evaluation/Iteration                    30\n",
      "Evaluation/MaxReturn                   -94.6949\n",
      "Evaluation/MinReturn                  -101.464\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     3.38459\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.40147\n",
      "GaussianMLPPolicy/KL                     3.61953e-05\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -10.7302\n",
      "GaussianMLPPolicy/LossBefore           -10.7298\n",
      "GaussianMLPPolicy/dLoss                  0.000346184\n",
      "GaussianMLPValueFunction/LossAfter      29.6417\n",
      "GaussianMLPValueFunction/LossBefore     30.0511\n",
      "GaussianMLPValueFunction/dLoss           0.409342\n",
      "TotalEnvSteps                        61938\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:22 | [trpo_pendulum] epoch #31 | Saving snapshot...\n",
      "2022-08-24 10:11:22 | [trpo_pendulum] epoch #31 | Saved\n",
      "2022-08-24 10:11:22 | [trpo_pendulum] epoch #31 | Time 18.01 s\n",
      "2022-08-24 10:11:22 | [trpo_pendulum] epoch #31 | EpochTime 0.55 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -8.78885\n",
      "Evaluation/AverageReturn               -95.9208\n",
      "Evaluation/Iteration                    31\n",
      "Evaluation/MaxReturn                   -91.7864\n",
      "Evaluation/MinReturn                  -100.055\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     4.13438\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.40081\n",
      "GaussianMLPPolicy/KL                     9.223e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -10.4435\n",
      "GaussianMLPPolicy/LossBefore           -10.4439\n",
      "GaussianMLPPolicy/dLoss                 -0.000385284\n",
      "GaussianMLPValueFunction/LossAfter      28.8037\n",
      "GaussianMLPValueFunction/LossBefore     29.2037\n",
      "GaussianMLPValueFunction/dLoss           0.400061\n",
      "TotalEnvSteps                        63936\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:23 | [trpo_pendulum] epoch #32 | Saving snapshot...\n",
      "2022-08-24 10:11:23 | [trpo_pendulum] epoch #32 | Saved\n",
      "2022-08-24 10:11:23 | [trpo_pendulum] epoch #32 | Time 18.56 s\n",
      "2022-08-24 10:11:23 | [trpo_pendulum] epoch #32 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -10.5433\n",
      "Evaluation/AverageReturn               -97.5407\n",
      "Evaluation/Iteration                    32\n",
      "Evaluation/MaxReturn                   -92.6521\n",
      "Evaluation/MinReturn                  -102.429\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     4.88858\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.40014\n",
      "GaussianMLPPolicy/KL                     5.92646e-07\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -10.3577\n",
      "GaussianMLPPolicy/LossBefore           -10.3576\n",
      "GaussianMLPPolicy/dLoss                  0.000102997\n",
      "GaussianMLPValueFunction/LossAfter      27.6044\n",
      "GaussianMLPValueFunction/LossBefore     27.9961\n",
      "GaussianMLPValueFunction/dLoss           0.391693\n",
      "TotalEnvSteps                        65934\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:23 | [trpo_pendulum] epoch #33 | Saving snapshot...\n",
      "2022-08-24 10:11:23 | [trpo_pendulum] epoch #33 | Saved\n",
      "2022-08-24 10:11:23 | [trpo_pendulum] epoch #33 | Time 19.15 s\n",
      "2022-08-24 10:11:23 | [trpo_pendulum] epoch #33 | EpochTime 0.59 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -9.24083\n",
      "Evaluation/AverageReturn               -96.637\n",
      "Evaluation/Iteration                    33\n",
      "Evaluation/MaxReturn                   -94.1948\n",
      "Evaluation/MinReturn                   -99.0792\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     2.44218\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.39951\n",
      "GaussianMLPPolicy/KL                     1.09521e-05\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -10.3075\n",
      "GaussianMLPPolicy/LossBefore           -10.3063\n",
      "GaussianMLPPolicy/dLoss                  0.00119686\n",
      "GaussianMLPValueFunction/LossAfter      27.5024\n",
      "GaussianMLPValueFunction/LossBefore     27.9005\n",
      "GaussianMLPValueFunction/dLoss           0.398054\n",
      "TotalEnvSteps                        67932\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:24 | [trpo_pendulum] epoch #34 | Saving snapshot...\n",
      "2022-08-24 10:11:24 | [trpo_pendulum] epoch #34 | Saved\n",
      "2022-08-24 10:11:24 | [trpo_pendulum] epoch #34 | Time 19.69 s\n",
      "2022-08-24 10:11:24 | [trpo_pendulum] epoch #34 | EpochTime 0.54 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -9.55723\n",
      "Evaluation/AverageReturn               -97.0972\n",
      "Evaluation/Iteration                    34\n",
      "Evaluation/MaxReturn                   -91.166\n",
      "Evaluation/MinReturn                  -103.028\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     5.93117\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.39885\n",
      "GaussianMLPPolicy/KL                     4.2991e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -10.3294\n",
      "GaussianMLPPolicy/LossBefore           -10.3294\n",
      "GaussianMLPPolicy/dLoss                  4.3869e-05\n",
      "GaussianMLPValueFunction/LossAfter      27.6963\n",
      "GaussianMLPValueFunction/LossBefore     28.0904\n",
      "GaussianMLPValueFunction/dLoss           0.394169\n",
      "TotalEnvSteps                        69930\n",
      "-----------------------------------  --------------\n",
      "2022-08-24 10:11:24 | [trpo_pendulum] epoch #35 | Saving snapshot...\n",
      "2022-08-24 10:11:24 | [trpo_pendulum] epoch #35 | Saved\n",
      "2022-08-24 10:11:24 | [trpo_pendulum] epoch #35 | Time 20.23 s\n",
      "2022-08-24 10:11:24 | [trpo_pendulum] epoch #35 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -10.0887\n",
      "Evaluation/AverageReturn               -96.2381\n",
      "Evaluation/Iteration                    35\n",
      "Evaluation/MaxReturn                   -96.0866\n",
      "Evaluation/MinReturn                   -96.3896\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.151472\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.39823\n",
      "GaussianMLPPolicy/KL                     1.52184e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -9.93371\n",
      "GaussianMLPPolicy/LossBefore            -9.93333\n",
      "GaussianMLPPolicy/dLoss                  0.000375748\n",
      "GaussianMLPValueFunction/LossAfter      25.7728\n",
      "GaussianMLPValueFunction/LossBefore     26.1628\n",
      "GaussianMLPValueFunction/dLoss           0.390026\n",
      "TotalEnvSteps                        71928\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:25 | [trpo_pendulum] epoch #36 | Saving snapshot...\n",
      "2022-08-24 10:11:25 | [trpo_pendulum] epoch #36 | Saved\n",
      "2022-08-24 10:11:25 | [trpo_pendulum] epoch #36 | Time 20.77 s\n",
      "2022-08-24 10:11:25 | [trpo_pendulum] epoch #36 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -9.37241\n",
      "Evaluation/AverageReturn               -99.4922\n",
      "Evaluation/Iteration                    36\n",
      "Evaluation/MaxReturn                   -95.5697\n",
      "Evaluation/MinReturn                  -103.415\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     3.92249\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.39755\n",
      "GaussianMLPPolicy/KL                     2.65866e-05\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -10.6022\n",
      "GaussianMLPPolicy/LossBefore           -10.5998\n",
      "GaussianMLPPolicy/dLoss                  0.00238514\n",
      "GaussianMLPValueFunction/LossAfter      28.5178\n",
      "GaussianMLPValueFunction/LossBefore     28.936\n",
      "GaussianMLPValueFunction/dLoss           0.41818\n",
      "TotalEnvSteps                        73926\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:26 | [trpo_pendulum] epoch #37 | Saving snapshot...\n",
      "2022-08-24 10:11:26 | [trpo_pendulum] epoch #37 | Saved\n",
      "2022-08-24 10:11:26 | [trpo_pendulum] epoch #37 | Time 21.32 s\n",
      "2022-08-24 10:11:26 | [trpo_pendulum] epoch #37 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -8.73801\n",
      "Evaluation/AverageReturn               -90.4148\n",
      "Evaluation/Iteration                    37\n",
      "Evaluation/MaxReturn                   -86.5803\n",
      "Evaluation/MinReturn                   -94.2494\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     3.83452\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.39695\n",
      "GaussianMLPPolicy/KL                     5.50147e-05\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -9.02695\n",
      "GaussianMLPPolicy/LossBefore            -9.02496\n",
      "GaussianMLPPolicy/dLoss                  0.00198555\n",
      "GaussianMLPValueFunction/LossAfter      22.4965\n",
      "GaussianMLPValueFunction/LossBefore     22.8551\n",
      "GaussianMLPValueFunction/dLoss           0.358677\n",
      "TotalEnvSteps                        75924\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:26 | [trpo_pendulum] epoch #38 | Saving snapshot...\n",
      "2022-08-24 10:11:26 | [trpo_pendulum] epoch #38 | Saved\n",
      "2022-08-24 10:11:26 | [trpo_pendulum] epoch #38 | Time 21.88 s\n",
      "2022-08-24 10:11:26 | [trpo_pendulum] epoch #38 | EpochTime 0.56 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -8.43487\n",
      "Evaluation/AverageReturn               -93.0707\n",
      "Evaluation/Iteration                    38\n",
      "Evaluation/MaxReturn                   -91.8999\n",
      "Evaluation/MinReturn                   -94.2415\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     1.1708\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.39643\n",
      "GaussianMLPPolicy/KL                     2.20472e-05\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -9.39536\n",
      "GaussianMLPPolicy/LossBefore            -9.39601\n",
      "GaussianMLPPolicy/dLoss                 -0.000647545\n",
      "GaussianMLPValueFunction/LossAfter      23.6788\n",
      "GaussianMLPValueFunction/LossBefore     24.0542\n",
      "GaussianMLPValueFunction/dLoss           0.375429\n",
      "TotalEnvSteps                        77922\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:27 | [trpo_pendulum] epoch #39 | Saving snapshot...\n",
      "2022-08-24 10:11:27 | [trpo_pendulum] epoch #39 | Saved\n",
      "2022-08-24 10:11:27 | [trpo_pendulum] epoch #39 | Time 22.42 s\n",
      "2022-08-24 10:11:27 | [trpo_pendulum] epoch #39 | EpochTime 0.53 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -8.70055\n",
      "Evaluation/AverageReturn               -97.2151\n",
      "Evaluation/Iteration                    39\n",
      "Evaluation/MaxReturn                   -93.489\n",
      "Evaluation/MinReturn                  -100.941\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     3.72612\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.39589\n",
      "GaussianMLPPolicy/KL                     5.96587e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter            -10.0793\n",
      "GaussianMLPPolicy/LossBefore           -10.0794\n",
      "GaussianMLPPolicy/dLoss                 -0.000146866\n",
      "GaussianMLPValueFunction/LossAfter      26.1985\n",
      "GaussianMLPValueFunction/LossBefore     26.5934\n",
      "GaussianMLPValueFunction/dLoss           0.394907\n",
      "TotalEnvSteps                        79920\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:27 | [trpo_pendulum] epoch #40 | Saving snapshot...\n",
      "2022-08-24 10:11:27 | [trpo_pendulum] epoch #40 | Saved\n",
      "2022-08-24 10:11:27 | [trpo_pendulum] epoch #40 | Time 22.94 s\n",
      "2022-08-24 10:11:27 | [trpo_pendulum] epoch #40 | EpochTime 0.52 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -9.77611\n",
      "Evaluation/AverageReturn               -96.0291\n",
      "Evaluation/Iteration                    40\n",
      "Evaluation/MaxReturn                   -92.3575\n",
      "Evaluation/MinReturn                   -99.7007\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     3.67163\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.39532\n",
      "GaussianMLPPolicy/KL                     6.76221e-07\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -9.66428\n",
      "GaussianMLPPolicy/LossBefore            -9.66419\n",
      "GaussianMLPPolicy/dLoss                  8.7738e-05\n",
      "GaussianMLPValueFunction/LossAfter      24.6191\n",
      "GaussianMLPValueFunction/LossBefore     25.0022\n",
      "GaussianMLPValueFunction/dLoss           0.38306\n",
      "TotalEnvSteps                        81918\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:28 | [trpo_pendulum] epoch #41 | Saving snapshot...\n",
      "2022-08-24 10:11:28 | [trpo_pendulum] epoch #41 | Saved\n",
      "2022-08-24 10:11:28 | [trpo_pendulum] epoch #41 | Time 23.48 s\n",
      "2022-08-24 10:11:28 | [trpo_pendulum] epoch #41 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -10.3326\n",
      "Evaluation/AverageReturn               -95.7242\n",
      "Evaluation/Iteration                    41\n",
      "Evaluation/MaxReturn                   -93.954\n",
      "Evaluation/MinReturn                   -97.4944\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     1.77021\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.39475\n",
      "GaussianMLPPolicy/KL                     1.99834e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -9.51982\n",
      "GaussianMLPPolicy/LossBefore            -9.51948\n",
      "GaussianMLPPolicy/dLoss                  0.00033474\n",
      "GaussianMLPValueFunction/LossAfter      23.7696\n",
      "GaussianMLPValueFunction/LossBefore     24.1406\n",
      "GaussianMLPValueFunction/dLoss           0.370962\n",
      "TotalEnvSteps                        83916\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:28 | [trpo_pendulum] epoch #42 | Saving snapshot...\n",
      "2022-08-24 10:11:28 | [trpo_pendulum] epoch #42 | Saved\n",
      "2022-08-24 10:11:28 | [trpo_pendulum] epoch #42 | Time 24.00 s\n",
      "2022-08-24 10:11:28 | [trpo_pendulum] epoch #42 | EpochTime 0.52 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -10.0297\n",
      "Evaluation/AverageReturn               -95.019\n",
      "Evaluation/Iteration                    42\n",
      "Evaluation/MaxReturn                   -94.5334\n",
      "Evaluation/MinReturn                   -95.5045\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.485542\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.39418\n",
      "GaussianMLPPolicy/KL                     2.49092e-05\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -9.35162\n",
      "GaussianMLPPolicy/LossBefore            -9.34976\n",
      "GaussianMLPPolicy/dLoss                  0.00185966\n",
      "GaussianMLPValueFunction/LossAfter      23.1757\n",
      "GaussianMLPValueFunction/LossBefore     23.5418\n",
      "GaussianMLPValueFunction/dLoss           0.366045\n",
      "TotalEnvSteps                        85914\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:29 | [trpo_pendulum] epoch #43 | Saving snapshot...\n",
      "2022-08-24 10:11:29 | [trpo_pendulum] epoch #43 | Saved\n",
      "2022-08-24 10:11:29 | [trpo_pendulum] epoch #43 | Time 24.55 s\n",
      "2022-08-24 10:11:29 | [trpo_pendulum] epoch #43 | EpochTime 0.53 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -8.3115\n",
      "Evaluation/AverageReturn               -92.0824\n",
      "Evaluation/Iteration                    43\n",
      "Evaluation/MaxReturn                   -87.7312\n",
      "Evaluation/MinReturn                   -96.4337\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     4.35126\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.39368\n",
      "GaussianMLPPolicy/KL                     5.84564e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -8.85612\n",
      "GaussianMLPPolicy/LossBefore            -8.85649\n",
      "GaussianMLPPolicy/dLoss                 -0.00037384\n",
      "GaussianMLPValueFunction/LossAfter      21.1625\n",
      "GaussianMLPValueFunction/LossBefore     21.5295\n",
      "GaussianMLPValueFunction/dLoss           0.36697\n",
      "TotalEnvSteps                        87912\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:29 | [trpo_pendulum] epoch #44 | Saving snapshot...\n",
      "2022-08-24 10:11:29 | [trpo_pendulum] epoch #44 | Saved\n",
      "2022-08-24 10:11:29 | [trpo_pendulum] epoch #44 | Time 25.09 s\n",
      "2022-08-24 10:11:29 | [trpo_pendulum] epoch #44 | EpochTime 0.54 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -9.72718\n",
      "Evaluation/AverageReturn               -96.6032\n",
      "Evaluation/Iteration                    44\n",
      "Evaluation/MaxReturn                   -96.3011\n",
      "Evaluation/MinReturn                   -96.9053\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.302103\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.39316\n",
      "GaussianMLPPolicy/KL                     1.00675e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -9.40509\n",
      "GaussianMLPPolicy/LossBefore            -9.40504\n",
      "GaussianMLPPolicy/dLoss                  4.673e-05\n",
      "GaussianMLPValueFunction/LossAfter      22.9348\n",
      "GaussianMLPValueFunction/LossBefore     23.3199\n",
      "GaussianMLPValueFunction/dLoss           0.385098\n",
      "TotalEnvSteps                        89910\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:30 | [trpo_pendulum] epoch #45 | Saving snapshot...\n",
      "2022-08-24 10:11:30 | [trpo_pendulum] epoch #45 | Saved\n",
      "2022-08-24 10:11:30 | [trpo_pendulum] epoch #45 | Time 25.61 s\n",
      "2022-08-24 10:11:30 | [trpo_pendulum] epoch #45 | EpochTime 0.52 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -9.4038\n",
      "Evaluation/AverageReturn               -95.4618\n",
      "Evaluation/Iteration                    45\n",
      "Evaluation/MaxReturn                   -92.0126\n",
      "Evaluation/MinReturn                   -98.911\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     3.44916\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.39264\n",
      "GaussianMLPPolicy/KL                     2.66415e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -9.1622\n",
      "GaussianMLPPolicy/LossBefore            -9.16176\n",
      "GaussianMLPPolicy/dLoss                  0.000432014\n",
      "GaussianMLPValueFunction/LossAfter      22.1538\n",
      "GaussianMLPValueFunction/LossBefore     22.5338\n",
      "GaussianMLPValueFunction/dLoss           0.38006\n",
      "TotalEnvSteps                        91908\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:30 | [trpo_pendulum] epoch #46 | Saving snapshot...\n",
      "2022-08-24 10:11:30 | [trpo_pendulum] epoch #46 | Saved\n",
      "2022-08-24 10:11:30 | [trpo_pendulum] epoch #46 | Time 26.15 s\n",
      "2022-08-24 10:11:30 | [trpo_pendulum] epoch #46 | EpochTime 0.53 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -10.2294\n",
      "Evaluation/AverageReturn               -97.5425\n",
      "Evaluation/Iteration                    46\n",
      "Evaluation/MaxReturn                   -92.0936\n",
      "Evaluation/MinReturn                  -102.991\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     5.44891\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.39206\n",
      "GaussianMLPPolicy/KL                     3.89756e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -9.42526\n",
      "GaussianMLPPolicy/LossBefore            -9.42491\n",
      "GaussianMLPPolicy/dLoss                  0.000347137\n",
      "GaussianMLPValueFunction/LossAfter      22.8924\n",
      "GaussianMLPValueFunction/LossBefore     23.2726\n",
      "GaussianMLPValueFunction/dLoss           0.380262\n",
      "TotalEnvSteps                        93906\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:31 | [trpo_pendulum] epoch #47 | Saving snapshot...\n",
      "2022-08-24 10:11:31 | [trpo_pendulum] epoch #47 | Saved\n",
      "2022-08-24 10:11:31 | [trpo_pendulum] epoch #47 | Time 26.68 s\n",
      "2022-08-24 10:11:31 | [trpo_pendulum] epoch #47 | EpochTime 0.53 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -8.40092\n",
      "Evaluation/AverageReturn               -89.3164\n",
      "Evaluation/Iteration                    47\n",
      "Evaluation/MaxReturn                   -86.899\n",
      "Evaluation/MinReturn                   -91.7337\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     2.41734\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.39158\n",
      "GaussianMLPPolicy/KL                     2.27256e-07\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -8.2018\n",
      "GaussianMLPPolicy/LossBefore            -8.20188\n",
      "GaussianMLPPolicy/dLoss                 -7.62939e-05\n",
      "GaussianMLPValueFunction/LossAfter      18.8645\n",
      "GaussianMLPValueFunction/LossBefore     19.1902\n",
      "GaussianMLPValueFunction/dLoss           0.325691\n",
      "TotalEnvSteps                        95904\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:31 | [trpo_pendulum] epoch #48 | Saving snapshot...\n",
      "2022-08-24 10:11:31 | [trpo_pendulum] epoch #48 | Saved\n",
      "2022-08-24 10:11:31 | [trpo_pendulum] epoch #48 | Time 27.21 s\n",
      "2022-08-24 10:11:31 | [trpo_pendulum] epoch #48 | EpochTime 0.53 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn     -10.2276\n",
      "Evaluation/AverageReturn               -94.8466\n",
      "Evaluation/Iteration                    48\n",
      "Evaluation/MaxReturn                   -94.1791\n",
      "Evaluation/MinReturn                   -95.514\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.667472\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.39107\n",
      "GaussianMLPPolicy/KL                     4.26929e-07\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -8.87413\n",
      "GaussianMLPPolicy/LossBefore            -8.87388\n",
      "GaussianMLPPolicy/dLoss                  0.000244141\n",
      "GaussianMLPValueFunction/LossAfter      21.274\n",
      "GaussianMLPValueFunction/LossBefore     21.6244\n",
      "GaussianMLPValueFunction/dLoss           0.350388\n",
      "TotalEnvSteps                        97902\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:32 | [trpo_pendulum] epoch #49 | Saving snapshot...\n",
      "2022-08-24 10:11:32 | [trpo_pendulum] epoch #49 | Saved\n",
      "2022-08-24 10:11:32 | [trpo_pendulum] epoch #49 | Time 27.74 s\n",
      "2022-08-24 10:11:32 | [trpo_pendulum] epoch #49 | EpochTime 0.53 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -9.1745\n",
      "Evaluation/AverageReturn               -90.7536\n",
      "Evaluation/Iteration                    49\n",
      "Evaluation/MaxReturn                   -90.6246\n",
      "Evaluation/MinReturn                   -90.8825\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.128928\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.39064\n",
      "GaussianMLPPolicy/KL                     5.55583e-06\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -8.06643\n",
      "GaussianMLPPolicy/LossBefore            -8.06598\n",
      "GaussianMLPPolicy/dLoss                  0.000445366\n",
      "GaussianMLPValueFunction/LossAfter      17.9142\n",
      "GaussianMLPValueFunction/LossBefore     18.2526\n",
      "GaussianMLPValueFunction/dLoss           0.338345\n",
      "TotalEnvSteps                        99900\n",
      "-----------------------------------  ---------------\n",
      "2022-08-24 10:11:32 | [trpo_pendulum] epoch #50 | Saving snapshot...\n",
      "2022-08-24 10:11:33 | [trpo_pendulum] epoch #50 | Saved\n",
      "2022-08-24 10:11:33 | [trpo_pendulum] epoch #50 | Time 28.26 s\n",
      "2022-08-24 10:11:33 | [trpo_pendulum] epoch #50 | EpochTime 0.52 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.01\n",
      "Evaluation/AverageReturn                -93.7306\n",
      "Evaluation/Iteration                     50\n",
      "Evaluation/MaxReturn                    -88.5991\n",
      "Evaluation/MinReturn                    -98.8621\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.1315\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.39018\n",
      "GaussianMLPPolicy/KL                      2.90643e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -8.56856\n",
      "GaussianMLPPolicy/LossBefore             -8.56848\n",
      "GaussianMLPPolicy/dLoss                   7.62939e-05\n",
      "GaussianMLPValueFunction/LossAfter       19.9622\n",
      "GaussianMLPValueFunction/LossBefore      20.3225\n",
      "GaussianMLPValueFunction/dLoss            0.360338\n",
      "TotalEnvSteps                        101898\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:33 | [trpo_pendulum] epoch #51 | Saving snapshot...\n",
      "2022-08-24 10:11:33 | [trpo_pendulum] epoch #51 | Saved\n",
      "2022-08-24 10:11:33 | [trpo_pendulum] epoch #51 | Time 28.78 s\n",
      "2022-08-24 10:11:33 | [trpo_pendulum] epoch #51 | EpochTime 0.51 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn      -10.0948\n",
      "Evaluation/AverageReturn                -97.2255\n",
      "Evaluation/Iteration                     51\n",
      "Evaluation/MaxReturn                    -92.4886\n",
      "Evaluation/MinReturn                   -101.962\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.73692\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38964\n",
      "GaussianMLPPolicy/KL                      5.07624e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -8.98421\n",
      "GaussianMLPPolicy/LossBefore             -8.98321\n",
      "GaussianMLPPolicy/dLoss                   0.000994682\n",
      "GaussianMLPValueFunction/LossAfter       21.2946\n",
      "GaussianMLPValueFunction/LossBefore      21.673\n",
      "GaussianMLPValueFunction/dLoss            0.378386\n",
      "TotalEnvSteps                        103896\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:34 | [trpo_pendulum] epoch #52 | Saving snapshot...\n",
      "2022-08-24 10:11:34 | [trpo_pendulum] epoch #52 | Saved\n",
      "2022-08-24 10:11:34 | [trpo_pendulum] epoch #52 | Time 29.42 s\n",
      "2022-08-24 10:11:34 | [trpo_pendulum] epoch #52 | EpochTime 0.63 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn      -10.1075\n",
      "Evaluation/AverageReturn                -92.5592\n",
      "Evaluation/Iteration                     52\n",
      "Evaluation/MaxReturn                    -90.4763\n",
      "Evaluation/MinReturn                    -94.6422\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.08293\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38911\n",
      "GaussianMLPPolicy/KL                      9.17165e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -8.05237\n",
      "GaussianMLPPolicy/LossBefore             -8.05204\n",
      "GaussianMLPPolicy/dLoss                   0.000328064\n",
      "GaussianMLPValueFunction/LossAfter       17.6048\n",
      "GaussianMLPValueFunction/LossBefore      17.9429\n",
      "GaussianMLPValueFunction/dLoss            0.338108\n",
      "TotalEnvSteps                        105894\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:34 | [trpo_pendulum] epoch #53 | Saving snapshot...\n",
      "2022-08-24 10:11:34 | [trpo_pendulum] epoch #53 | Saved\n",
      "2022-08-24 10:11:34 | [trpo_pendulum] epoch #53 | Time 29.98 s\n",
      "2022-08-24 10:11:34 | [trpo_pendulum] epoch #53 | EpochTime 0.54 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.28393\n",
      "Evaluation/AverageReturn                -92.2463\n",
      "Evaluation/Iteration                     53\n",
      "Evaluation/MaxReturn                    -90.1218\n",
      "Evaluation/MinReturn                    -94.3708\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.12452\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38862\n",
      "GaussianMLPPolicy/KL                      8.86235e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.95847\n",
      "GaussianMLPPolicy/LossBefore             -7.9583\n",
      "GaussianMLPPolicy/dLoss                   0.000169277\n",
      "GaussianMLPValueFunction/LossAfter       17.4363\n",
      "GaussianMLPValueFunction/LossBefore      17.7849\n",
      "GaussianMLPValueFunction/dLoss            0.348625\n",
      "TotalEnvSteps                        107892\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:35 | [trpo_pendulum] epoch #54 | Saving snapshot...\n",
      "2022-08-24 10:11:35 | [trpo_pendulum] epoch #54 | Saved\n",
      "2022-08-24 10:11:35 | [trpo_pendulum] epoch #54 | Time 30.51 s\n",
      "2022-08-24 10:11:35 | [trpo_pendulum] epoch #54 | EpochTime 0.53 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.83224\n",
      "Evaluation/AverageReturn                -99.2848\n",
      "Evaluation/Iteration                     54\n",
      "Evaluation/MaxReturn                    -98.019\n",
      "Evaluation/MinReturn                   -100.551\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.26579\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38802\n",
      "GaussianMLPPolicy/KL                      2.50935e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -9.11668\n",
      "GaussianMLPPolicy/LossBefore             -9.11641\n",
      "GaussianMLPPolicy/dLoss                   0.000270844\n",
      "GaussianMLPValueFunction/LossAfter       21.4989\n",
      "GaussianMLPValueFunction/LossBefore      21.8871\n",
      "GaussianMLPValueFunction/dLoss            0.388216\n",
      "TotalEnvSteps                        109890\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:35 | [trpo_pendulum] epoch #55 | Saving snapshot...\n",
      "2022-08-24 10:11:35 | [trpo_pendulum] epoch #55 | Saved\n",
      "2022-08-24 10:11:35 | [trpo_pendulum] epoch #55 | Time 31.03 s\n",
      "2022-08-24 10:11:35 | [trpo_pendulum] epoch #55 | EpochTime 0.52 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.17122\n",
      "Evaluation/AverageReturn                -94.7818\n",
      "Evaluation/Iteration                     55\n",
      "Evaluation/MaxReturn                    -93.3969\n",
      "Evaluation/MinReturn                    -96.1667\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.38488\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.3874\n",
      "GaussianMLPPolicy/KL                      1.99756e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -8.25339\n",
      "GaussianMLPPolicy/LossBefore             -8.2532\n",
      "GaussianMLPPolicy/dLoss                   0.000184059\n",
      "GaussianMLPValueFunction/LossAfter       18.4386\n",
      "GaussianMLPValueFunction/LossBefore      18.804\n",
      "GaussianMLPValueFunction/dLoss            0.365381\n",
      "TotalEnvSteps                        111888\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:36 | [trpo_pendulum] epoch #56 | Saving snapshot...\n",
      "2022-08-24 10:11:36 | [trpo_pendulum] epoch #56 | Saved\n",
      "2022-08-24 10:11:36 | [trpo_pendulum] epoch #56 | Time 31.56 s\n",
      "2022-08-24 10:11:36 | [trpo_pendulum] epoch #56 | EpochTime 0.53 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.63132\n",
      "Evaluation/AverageReturn                -90.41\n",
      "Evaluation/Iteration                     56\n",
      "Evaluation/MaxReturn                    -89.1675\n",
      "Evaluation/MinReturn                    -91.6526\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.24254\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38686\n",
      "GaussianMLPPolicy/KL                      1.24712e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.30676\n",
      "GaussianMLPPolicy/LossBefore             -7.30543\n",
      "GaussianMLPPolicy/dLoss                   0.00133371\n",
      "GaussianMLPValueFunction/LossAfter       14.9192\n",
      "GaussianMLPValueFunction/LossBefore      15.2506\n",
      "GaussianMLPValueFunction/dLoss            0.331389\n",
      "TotalEnvSteps                        113886\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:36 | [trpo_pendulum] epoch #57 | Saving snapshot...\n",
      "2022-08-24 10:11:36 | [trpo_pendulum] epoch #57 | Saved\n",
      "2022-08-24 10:11:36 | [trpo_pendulum] epoch #57 | Time 32.08 s\n",
      "2022-08-24 10:11:36 | [trpo_pendulum] epoch #57 | EpochTime 0.52 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -8.20159\n",
      "Evaluation/AverageReturn                -91.2489\n",
      "Evaluation/Iteration                     57\n",
      "Evaluation/MaxReturn                    -87.6645\n",
      "Evaluation/MinReturn                    -94.8332\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.58433\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38634\n",
      "GaussianMLPPolicy/KL                      2.65889e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.64436\n",
      "GaussianMLPPolicy/LossBefore             -7.64447\n",
      "GaussianMLPPolicy/dLoss                  -0.000110626\n",
      "GaussianMLPValueFunction/LossAfter       16.4785\n",
      "GaussianMLPValueFunction/LossBefore      16.8203\n",
      "GaussianMLPValueFunction/dLoss            0.341852\n",
      "TotalEnvSteps                        115884\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:37 | [trpo_pendulum] epoch #58 | Saving snapshot...\n",
      "2022-08-24 10:11:37 | [trpo_pendulum] epoch #58 | Saved\n",
      "2022-08-24 10:11:37 | [trpo_pendulum] epoch #58 | Time 32.63 s\n",
      "2022-08-24 10:11:37 | [trpo_pendulum] epoch #58 | EpochTime 0.53 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -8.96373\n",
      "Evaluation/AverageReturn                -91.2059\n",
      "Evaluation/Iteration                     58\n",
      "Evaluation/MaxReturn                    -90.7775\n",
      "Evaluation/MinReturn                    -91.6344\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.428407\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38586\n",
      "GaussianMLPPolicy/KL                      6.65533e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.33068\n",
      "GaussianMLPPolicy/LossBefore             -7.32988\n",
      "GaussianMLPPolicy/dLoss                   0.000797749\n",
      "GaussianMLPValueFunction/LossAfter       14.917\n",
      "GaussianMLPValueFunction/LossBefore      15.2485\n",
      "GaussianMLPValueFunction/dLoss            0.331494\n",
      "TotalEnvSteps                        117882\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:37 | [trpo_pendulum] epoch #59 | Saving snapshot...\n",
      "2022-08-24 10:11:37 | [trpo_pendulum] epoch #59 | Saved\n",
      "2022-08-24 10:11:37 | [trpo_pendulum] epoch #59 | Time 33.15 s\n",
      "2022-08-24 10:11:37 | [trpo_pendulum] epoch #59 | EpochTime 0.52 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.6638\n",
      "Evaluation/AverageReturn                -96.4654\n",
      "Evaluation/Iteration                     59\n",
      "Evaluation/MaxReturn                    -93.3248\n",
      "Evaluation/MinReturn                    -99.606\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.14057\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38536\n",
      "GaussianMLPPolicy/KL                      7.62625e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -8.0276\n",
      "GaussianMLPPolicy/LossBefore             -8.02732\n",
      "GaussianMLPPolicy/dLoss                   0.00028038\n",
      "GaussianMLPValueFunction/LossAfter       16.9751\n",
      "GaussianMLPValueFunction/LossBefore      17.3402\n",
      "GaussianMLPValueFunction/dLoss            0.365082\n",
      "TotalEnvSteps                        119880\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:38 | [trpo_pendulum] epoch #60 | Saving snapshot...\n",
      "2022-08-24 10:11:38 | [trpo_pendulum] epoch #60 | Saved\n",
      "2022-08-24 10:11:38 | [trpo_pendulum] epoch #60 | Time 33.68 s\n",
      "2022-08-24 10:11:38 | [trpo_pendulum] epoch #60 | EpochTime 0.52 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.32628\n",
      "Evaluation/AverageReturn                -93.5584\n",
      "Evaluation/Iteration                     60\n",
      "Evaluation/MaxReturn                    -89.6097\n",
      "Evaluation/MinReturn                    -97.5071\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.94872\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38485\n",
      "GaussianMLPPolicy/KL                      1.13747e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.58921\n",
      "GaussianMLPPolicy/LossBefore             -7.58884\n",
      "GaussianMLPPolicy/dLoss                   0.000367641\n",
      "GaussianMLPValueFunction/LossAfter       16.0653\n",
      "GaussianMLPValueFunction/LossBefore      16.4008\n",
      "GaussianMLPValueFunction/dLoss            0.335535\n",
      "TotalEnvSteps                        121878\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:38 | [trpo_pendulum] epoch #61 | Saving snapshot...\n",
      "2022-08-24 10:11:38 | [trpo_pendulum] epoch #61 | Saved\n",
      "2022-08-24 10:11:38 | [trpo_pendulum] epoch #61 | Time 34.22 s\n",
      "2022-08-24 10:11:38 | [trpo_pendulum] epoch #61 | EpochTime 0.52 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.44532\n",
      "Evaluation/AverageReturn                -95.4056\n",
      "Evaluation/Iteration                     61\n",
      "Evaluation/MaxReturn                    -91.1908\n",
      "Evaluation/MinReturn                    -99.6205\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.21487\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38431\n",
      "GaussianMLPPolicy/KL                      2.04467e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.80275\n",
      "GaussianMLPPolicy/LossBefore             -7.80194\n",
      "GaussianMLPPolicy/dLoss                   0.000809669\n",
      "GaussianMLPValueFunction/LossAfter       16.5189\n",
      "GaussianMLPValueFunction/LossBefore      16.866\n",
      "GaussianMLPValueFunction/dLoss            0.347151\n",
      "TotalEnvSteps                        123876\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:39 | [trpo_pendulum] epoch #62 | Saving snapshot...\n",
      "2022-08-24 10:11:39 | [trpo_pendulum] epoch #62 | Saved\n",
      "2022-08-24 10:11:39 | [trpo_pendulum] epoch #62 | Time 34.74 s\n",
      "2022-08-24 10:11:39 | [trpo_pendulum] epoch #62 | EpochTime 0.51 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.2592\n",
      "Evaluation/AverageReturn                -93.103\n",
      "Evaluation/Iteration                     62\n",
      "Evaluation/MaxReturn                    -91.5553\n",
      "Evaluation/MinReturn                    -94.6507\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.54768\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38378\n",
      "GaussianMLPPolicy/KL                      2.24458e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.31712\n",
      "GaussianMLPPolicy/LossBefore             -7.31665\n",
      "GaussianMLPPolicy/dLoss                   0.000467777\n",
      "GaussianMLPValueFunction/LossAfter       14.9925\n",
      "GaussianMLPValueFunction/LossBefore      15.3225\n",
      "GaussianMLPValueFunction/dLoss            0.329996\n",
      "TotalEnvSteps                        125874\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:40 | [trpo_pendulum] epoch #63 | Saving snapshot...\n",
      "2022-08-24 10:11:40 | [trpo_pendulum] epoch #63 | Saved\n",
      "2022-08-24 10:11:40 | [trpo_pendulum] epoch #63 | Time 35.28 s\n",
      "2022-08-24 10:11:40 | [trpo_pendulum] epoch #63 | EpochTime 0.52 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -8.73052\n",
      "Evaluation/AverageReturn                -95.2031\n",
      "Evaluation/Iteration                     63\n",
      "Evaluation/MaxReturn                    -92.502\n",
      "Evaluation/MinReturn                    -97.9041\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.70102\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38324\n",
      "GaussianMLPPolicy/KL                      2.07803e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.5852\n",
      "GaussianMLPPolicy/LossBefore             -7.58488\n",
      "GaussianMLPPolicy/dLoss                   0.000323772\n",
      "GaussianMLPValueFunction/LossAfter       15.5489\n",
      "GaussianMLPValueFunction/LossBefore      15.8987\n",
      "GaussianMLPValueFunction/dLoss            0.349811\n",
      "TotalEnvSteps                        127872\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:40 | [trpo_pendulum] epoch #64 | Saving snapshot...\n",
      "2022-08-24 10:11:40 | [trpo_pendulum] epoch #64 | Saved\n",
      "2022-08-24 10:11:40 | [trpo_pendulum] epoch #64 | Time 35.82 s\n",
      "2022-08-24 10:11:40 | [trpo_pendulum] epoch #64 | EpochTime 0.52 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn      -10.2826\n",
      "Evaluation/AverageReturn                -96.3949\n",
      "Evaluation/Iteration                     64\n",
      "Evaluation/MaxReturn                    -94.594\n",
      "Evaluation/MinReturn                    -98.1957\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.80083\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38267\n",
      "GaussianMLPPolicy/KL                      5.23905e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.49043\n",
      "GaussianMLPPolicy/LossBefore             -7.49051\n",
      "GaussianMLPPolicy/dLoss                  -8.24928e-05\n",
      "GaussianMLPValueFunction/LossAfter       15.1166\n",
      "GaussianMLPValueFunction/LossBefore      15.4679\n",
      "GaussianMLPValueFunction/dLoss            0.351248\n",
      "TotalEnvSteps                        129870\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:41 | [trpo_pendulum] epoch #65 | Saving snapshot...\n",
      "2022-08-24 10:11:41 | [trpo_pendulum] epoch #65 | Saved\n",
      "2022-08-24 10:11:41 | [trpo_pendulum] epoch #65 | Time 36.35 s\n",
      "2022-08-24 10:11:41 | [trpo_pendulum] epoch #65 | EpochTime 0.53 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.39748\n",
      "Evaluation/AverageReturn                -93.2532\n",
      "Evaluation/Iteration                     65\n",
      "Evaluation/MaxReturn                    -90.3767\n",
      "Evaluation/MinReturn                    -96.1298\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.87653\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.3821\n",
      "GaussianMLPPolicy/KL                      2.0597e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.09199\n",
      "GaussianMLPPolicy/LossBefore             -7.09182\n",
      "GaussianMLPPolicy/dLoss                   0.000173569\n",
      "GaussianMLPValueFunction/LossAfter       14.437\n",
      "GaussianMLPValueFunction/LossBefore      14.7576\n",
      "GaussianMLPValueFunction/dLoss            0.320546\n",
      "TotalEnvSteps                        131868\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:41 | [trpo_pendulum] epoch #66 | Saving snapshot...\n",
      "2022-08-24 10:11:41 | [trpo_pendulum] epoch #66 | Saved\n",
      "2022-08-24 10:11:41 | [trpo_pendulum] epoch #66 | Time 36.90 s\n",
      "2022-08-24 10:11:41 | [trpo_pendulum] epoch #66 | EpochTime 0.55 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.48945\n",
      "Evaluation/AverageReturn                -91.9246\n",
      "Evaluation/Iteration                     66\n",
      "Evaluation/MaxReturn                    -89.2773\n",
      "Evaluation/MinReturn                    -94.5719\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.64728\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38156\n",
      "GaussianMLPPolicy/KL                      4.87003e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.73694\n",
      "GaussianMLPPolicy/LossBefore             -6.73641\n",
      "GaussianMLPPolicy/dLoss                   0.000526905\n",
      "GaussianMLPValueFunction/LossAfter       13.1442\n",
      "GaussianMLPValueFunction/LossBefore      13.4491\n",
      "GaussianMLPValueFunction/dLoss            0.304894\n",
      "TotalEnvSteps                        133866\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:42 | [trpo_pendulum] epoch #67 | Saving snapshot...\n",
      "2022-08-24 10:11:42 | [trpo_pendulum] epoch #67 | Saved\n",
      "2022-08-24 10:11:42 | [trpo_pendulum] epoch #67 | Time 37.44 s\n",
      "2022-08-24 10:11:42 | [trpo_pendulum] epoch #67 | EpochTime 0.54 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.93075\n",
      "Evaluation/AverageReturn                -94.7755\n",
      "Evaluation/Iteration                     67\n",
      "Evaluation/MaxReturn                    -92.4603\n",
      "Evaluation/MinReturn                    -97.0907\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.31517\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38099\n",
      "GaussianMLPPolicy/KL                      3.83118e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.96848\n",
      "GaussianMLPPolicy/LossBefore             -6.96832\n",
      "GaussianMLPPolicy/dLoss                   0.000157833\n",
      "GaussianMLPValueFunction/LossAfter       13.6964\n",
      "GaussianMLPValueFunction/LossBefore      14.0238\n",
      "GaussianMLPValueFunction/dLoss            0.327476\n",
      "TotalEnvSteps                        135864\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:42 | [trpo_pendulum] epoch #68 | Saving snapshot...\n",
      "2022-08-24 10:11:42 | [trpo_pendulum] epoch #68 | Saved\n",
      "2022-08-24 10:11:42 | [trpo_pendulum] epoch #68 | Time 37.99 s\n",
      "2022-08-24 10:11:42 | [trpo_pendulum] epoch #68 | EpochTime 0.55 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.76671\n",
      "Evaluation/AverageReturn                -90.1493\n",
      "Evaluation/Iteration                     68\n",
      "Evaluation/MaxReturn                    -89.3322\n",
      "Evaluation/MinReturn                    -90.9663\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.817076\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.38045\n",
      "GaussianMLPPolicy/KL                      6.08336e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.23383\n",
      "GaussianMLPPolicy/LossBefore             -6.2333\n",
      "GaussianMLPPolicy/dLoss                   0.000533104\n",
      "GaussianMLPValueFunction/LossAfter       11.7699\n",
      "GaussianMLPValueFunction/LossBefore      12.0567\n",
      "GaussianMLPValueFunction/dLoss            0.286889\n",
      "TotalEnvSteps                        137862\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:43 | [trpo_pendulum] epoch #69 | Saving snapshot...\n",
      "2022-08-24 10:11:43 | [trpo_pendulum] epoch #69 | Saved\n",
      "2022-08-24 10:11:43 | [trpo_pendulum] epoch #69 | Time 38.54 s\n",
      "2022-08-24 10:11:43 | [trpo_pendulum] epoch #69 | EpochTime 0.54 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.5462\n",
      "Evaluation/AverageReturn                -96.0563\n",
      "Evaluation/Iteration                     69\n",
      "Evaluation/MaxReturn                    -94.3946\n",
      "Evaluation/MinReturn                    -97.7181\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.66177\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37981\n",
      "GaussianMLPPolicy/KL                      4.13138e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -7.23464\n",
      "GaussianMLPPolicy/LossBefore             -7.23199\n",
      "GaussianMLPPolicy/dLoss                   0.00265837\n",
      "GaussianMLPValueFunction/LossAfter       14.9338\n",
      "GaussianMLPValueFunction/LossBefore      15.2613\n",
      "GaussianMLPValueFunction/dLoss            0.327527\n",
      "TotalEnvSteps                        139860\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:43 | [trpo_pendulum] epoch #70 | Saving snapshot...\n",
      "2022-08-24 10:11:43 | [trpo_pendulum] epoch #70 | Saved\n",
      "2022-08-24 10:11:43 | [trpo_pendulum] epoch #70 | Time 39.09 s\n",
      "2022-08-24 10:11:43 | [trpo_pendulum] epoch #70 | EpochTime 0.54 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -8.12628\n",
      "Evaluation/AverageReturn                -93.7231\n",
      "Evaluation/Iteration                     70\n",
      "Evaluation/MaxReturn                    -92.9257\n",
      "Evaluation/MinReturn                    -94.5205\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.797405\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37917\n",
      "GaussianMLPPolicy/KL                      3.75995e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.75047\n",
      "GaussianMLPPolicy/LossBefore             -6.75005\n",
      "GaussianMLPPolicy/dLoss                   0.000423431\n",
      "GaussianMLPValueFunction/LossAfter       12.8454\n",
      "GaussianMLPValueFunction/LossBefore      13.1632\n",
      "GaussianMLPValueFunction/dLoss            0.317803\n",
      "TotalEnvSteps                        141858\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:44 | [trpo_pendulum] epoch #71 | Saving snapshot...\n",
      "2022-08-24 10:11:44 | [trpo_pendulum] epoch #71 | Saved\n",
      "2022-08-24 10:11:44 | [trpo_pendulum] epoch #71 | Time 39.63 s\n",
      "2022-08-24 10:11:44 | [trpo_pendulum] epoch #71 | EpochTime 0.54 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.36307\n",
      "Evaluation/AverageReturn                -89.2331\n",
      "Evaluation/Iteration                     71\n",
      "Evaluation/MaxReturn                    -86.282\n",
      "Evaluation/MinReturn                    -92.1842\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.95106\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37859\n",
      "GaussianMLPPolicy/KL                      3.05654e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.74452\n",
      "GaussianMLPPolicy/LossBefore             -5.7444\n",
      "GaussianMLPPolicy/dLoss                   0.000119686\n",
      "GaussianMLPValueFunction/LossAfter       10.1135\n",
      "GaussianMLPValueFunction/LossBefore      10.3873\n",
      "GaussianMLPValueFunction/dLoss            0.273843\n",
      "TotalEnvSteps                        143856\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:44 | [trpo_pendulum] epoch #72 | Saving snapshot...\n",
      "2022-08-24 10:11:44 | [trpo_pendulum] epoch #72 | Saved\n",
      "2022-08-24 10:11:44 | [trpo_pendulum] epoch #72 | Time 40.18 s\n",
      "2022-08-24 10:11:44 | [trpo_pendulum] epoch #72 | EpochTime 0.54 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.24426\n",
      "Evaluation/AverageReturn                -88.7723\n",
      "Evaluation/Iteration                     72\n",
      "Evaluation/MaxReturn                    -87.4408\n",
      "Evaluation/MinReturn                    -90.1037\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.33147\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37806\n",
      "GaussianMLPPolicy/KL                      2.38686e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.5917\n",
      "GaussianMLPPolicy/LossBefore             -5.59166\n",
      "GaussianMLPPolicy/dLoss                   3.86238e-05\n",
      "GaussianMLPValueFunction/LossAfter        9.59448\n",
      "GaussianMLPValueFunction/LossBefore       9.85954\n",
      "GaussianMLPValueFunction/dLoss            0.265059\n",
      "TotalEnvSteps                        145854\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:45 | [trpo_pendulum] epoch #73 | Saving snapshot...\n",
      "2022-08-24 10:11:45 | [trpo_pendulum] epoch #73 | Saved\n",
      "2022-08-24 10:11:45 | [trpo_pendulum] epoch #73 | Time 40.71 s\n",
      "2022-08-24 10:11:45 | [trpo_pendulum] epoch #73 | EpochTime 0.53 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -8.67284\n",
      "Evaluation/AverageReturn                -89.19\n",
      "Evaluation/Iteration                     73\n",
      "Evaluation/MaxReturn                    -88.5271\n",
      "Evaluation/MinReturn                    -89.8528\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.662844\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37761\n",
      "GaussianMLPPolicy/KL                      2.80662e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.60738\n",
      "GaussianMLPPolicy/LossBefore             -5.60694\n",
      "GaussianMLPPolicy/dLoss                   0.000445843\n",
      "GaussianMLPValueFunction/LossAfter        9.55924\n",
      "GaussianMLPValueFunction/LossBefore       9.82376\n",
      "GaussianMLPValueFunction/dLoss            0.264516\n",
      "TotalEnvSteps                        147852\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:45 | [trpo_pendulum] epoch #74 | Saving snapshot...\n",
      "2022-08-24 10:11:45 | [trpo_pendulum] epoch #74 | Saved\n",
      "2022-08-24 10:11:45 | [trpo_pendulum] epoch #74 | Time 41.25 s\n",
      "2022-08-24 10:11:45 | [trpo_pendulum] epoch #74 | EpochTime 0.53 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.32136\n",
      "Evaluation/AverageReturn                -88.8092\n",
      "Evaluation/Iteration                     74\n",
      "Evaluation/MaxReturn                    -88.4261\n",
      "Evaluation/MinReturn                    -89.1922\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.383047\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37722\n",
      "GaussianMLPPolicy/KL                      2.07479e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.32227\n",
      "GaussianMLPPolicy/LossBefore             -5.32234\n",
      "GaussianMLPPolicy/dLoss                  -6.48499e-05\n",
      "GaussianMLPValueFunction/LossAfter        9.01518\n",
      "GaussianMLPValueFunction/LossBefore       9.26375\n",
      "GaussianMLPValueFunction/dLoss            0.24857\n",
      "TotalEnvSteps                        149850\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:46 | [trpo_pendulum] epoch #75 | Saving snapshot...\n",
      "2022-08-24 10:11:46 | [trpo_pendulum] epoch #75 | Saved\n",
      "2022-08-24 10:11:46 | [trpo_pendulum] epoch #75 | Time 41.77 s\n",
      "2022-08-24 10:11:46 | [trpo_pendulum] epoch #75 | EpochTime 0.52 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.48388\n",
      "Evaluation/AverageReturn                -95.8785\n",
      "Evaluation/Iteration                     75\n",
      "Evaluation/MaxReturn                    -88.2249\n",
      "Evaluation/MinReturn                   -103.532\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.65364\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37675\n",
      "GaussianMLPPolicy/KL                      9.91934e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -6.36467\n",
      "GaussianMLPPolicy/LossBefore             -6.36467\n",
      "GaussianMLPPolicy/dLoss                   7.15256e-06\n",
      "GaussianMLPValueFunction/LossAfter       11.867\n",
      "GaussianMLPValueFunction/LossBefore      12.1621\n",
      "GaussianMLPValueFunction/dLoss            0.295091\n",
      "TotalEnvSteps                        151848\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:47 | [trpo_pendulum] epoch #76 | Saving snapshot...\n",
      "2022-08-24 10:11:47 | [trpo_pendulum] epoch #76 | Saved\n",
      "2022-08-24 10:11:47 | [trpo_pendulum] epoch #76 | Time 42.32 s\n",
      "2022-08-24 10:11:47 | [trpo_pendulum] epoch #76 | EpochTime 0.55 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.16608\n",
      "Evaluation/AverageReturn                -91.5403\n",
      "Evaluation/Iteration                     76\n",
      "Evaluation/MaxReturn                    -89.5471\n",
      "Evaluation/MinReturn                    -93.5335\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.99322\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.3763\n",
      "GaussianMLPPolicy/KL                      2.55838e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.69499\n",
      "GaussianMLPPolicy/LossBefore             -5.69508\n",
      "GaussianMLPPolicy/dLoss                  -8.34465e-05\n",
      "GaussianMLPValueFunction/LossAfter        9.90623\n",
      "GaussianMLPValueFunction/LossBefore      10.1653\n",
      "GaussianMLPValueFunction/dLoss            0.259087\n",
      "TotalEnvSteps                        153846\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:47 | [trpo_pendulum] epoch #77 | Saving snapshot...\n",
      "2022-08-24 10:11:47 | [trpo_pendulum] epoch #77 | Saved\n",
      "2022-08-24 10:11:47 | [trpo_pendulum] epoch #77 | Time 42.87 s\n",
      "2022-08-24 10:11:47 | [trpo_pendulum] epoch #77 | EpochTime 0.54 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -7.72272\n",
      "Evaluation/AverageReturn                -84.5687\n",
      "Evaluation/Iteration                     77\n",
      "Evaluation/MaxReturn                    -82.7978\n",
      "Evaluation/MinReturn                    -86.3396\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.7709\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37595\n",
      "GaussianMLPPolicy/KL                      8.34388e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.69555\n",
      "GaussianMLPPolicy/LossBefore             -4.69549\n",
      "GaussianMLPPolicy/dLoss                   6.53267e-05\n",
      "GaussianMLPValueFunction/LossAfter        7.94974\n",
      "GaussianMLPValueFunction/LossBefore       8.16075\n",
      "GaussianMLPValueFunction/dLoss            0.211009\n",
      "TotalEnvSteps                        155844\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:48 | [trpo_pendulum] epoch #78 | Saving snapshot...\n",
      "2022-08-24 10:11:48 | [trpo_pendulum] epoch #78 | Saved\n",
      "2022-08-24 10:11:48 | [trpo_pendulum] epoch #78 | Time 43.53 s\n",
      "2022-08-24 10:11:48 | [trpo_pendulum] epoch #78 | EpochTime 0.66 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn      -10.2741\n",
      "Evaluation/AverageReturn                -95.7662\n",
      "Evaluation/Iteration                     78\n",
      "Evaluation/MaxReturn                    -91.1908\n",
      "Evaluation/MinReturn                   -100.342\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      4.57537\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37552\n",
      "GaussianMLPPolicy/KL                      3.16245e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.99957\n",
      "GaussianMLPPolicy/LossBefore             -5.99927\n",
      "GaussianMLPPolicy/dLoss                   0.000301361\n",
      "GaussianMLPValueFunction/LossAfter       10.7026\n",
      "GaussianMLPValueFunction/LossBefore      10.9727\n",
      "GaussianMLPValueFunction/dLoss            0.27005\n",
      "TotalEnvSteps                        157842\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:48 | [trpo_pendulum] epoch #79 | Saving snapshot...\n",
      "2022-08-24 10:11:48 | [trpo_pendulum] epoch #79 | Saved\n",
      "2022-08-24 10:11:48 | [trpo_pendulum] epoch #79 | Time 44.08 s\n",
      "2022-08-24 10:11:48 | [trpo_pendulum] epoch #79 | EpochTime 0.54 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.9676\n",
      "Evaluation/AverageReturn                -94.3297\n",
      "Evaluation/Iteration                     79\n",
      "Evaluation/MaxReturn                    -94.1009\n",
      "Evaluation/MinReturn                    -94.5585\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.228838\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37503\n",
      "GaussianMLPPolicy/KL                      7.78881e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.78414\n",
      "GaussianMLPPolicy/LossBefore             -5.78401\n",
      "GaussianMLPPolicy/dLoss                   0.000130177\n",
      "GaussianMLPValueFunction/LossAfter       10.2513\n",
      "GaussianMLPValueFunction/LossBefore      10.508\n",
      "GaussianMLPValueFunction/dLoss            0.256697\n",
      "TotalEnvSteps                        159840\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:49 | [trpo_pendulum] epoch #80 | Saving snapshot...\n",
      "2022-08-24 10:11:49 | [trpo_pendulum] epoch #80 | Saved\n",
      "2022-08-24 10:11:49 | [trpo_pendulum] epoch #80 | Time 44.61 s\n",
      "2022-08-24 10:11:49 | [trpo_pendulum] epoch #80 | EpochTime 0.53 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn      -10.2244\n",
      "Evaluation/AverageReturn                -95.4821\n",
      "Evaluation/Iteration                     80\n",
      "Evaluation/MaxReturn                    -92.7634\n",
      "Evaluation/MinReturn                    -98.2007\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.71862\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37451\n",
      "GaussianMLPPolicy/KL                      2.72412e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.77191\n",
      "GaussianMLPPolicy/LossBefore             -5.77175\n",
      "GaussianMLPPolicy/dLoss                   0.000163555\n",
      "GaussianMLPValueFunction/LossAfter        9.91674\n",
      "GaussianMLPValueFunction/LossBefore      10.1773\n",
      "GaussianMLPValueFunction/dLoss            0.260566\n",
      "TotalEnvSteps                        161838\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:49 | [trpo_pendulum] epoch #81 | Saving snapshot...\n",
      "2022-08-24 10:11:49 | [trpo_pendulum] epoch #81 | Saved\n",
      "2022-08-24 10:11:49 | [trpo_pendulum] epoch #81 | Time 45.16 s\n",
      "2022-08-24 10:11:49 | [trpo_pendulum] epoch #81 | EpochTime 0.54 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.87274\n",
      "Evaluation/AverageReturn                -95.2407\n",
      "Evaluation/Iteration                     81\n",
      "Evaluation/MaxReturn                    -90.1868\n",
      "Evaluation/MinReturn                   -100.295\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      5.05388\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37392\n",
      "GaussianMLPPolicy/KL                      1.11633e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -5.79886\n",
      "GaussianMLPPolicy/LossBefore             -5.79783\n",
      "GaussianMLPPolicy/dLoss                   0.00102377\n",
      "GaussianMLPValueFunction/LossAfter       10.4421\n",
      "GaussianMLPValueFunction/LossBefore      10.6977\n",
      "GaussianMLPValueFunction/dLoss            0.255547\n",
      "TotalEnvSteps                        163836\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:50 | [trpo_pendulum] epoch #82 | Saving snapshot...\n",
      "2022-08-24 10:11:50 | [trpo_pendulum] epoch #82 | Saved\n",
      "2022-08-24 10:11:50 | [trpo_pendulum] epoch #82 | Time 45.68 s\n",
      "2022-08-24 10:11:50 | [trpo_pendulum] epoch #82 | EpochTime 0.52 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -7.92026\n",
      "Evaluation/AverageReturn                -89.8764\n",
      "Evaluation/Iteration                     82\n",
      "Evaluation/MaxReturn                    -88.4053\n",
      "Evaluation/MinReturn                    -91.3476\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.47115\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37333\n",
      "GaussianMLPPolicy/KL                      6.11349e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.98604\n",
      "GaussianMLPPolicy/LossBefore             -4.986\n",
      "GaussianMLPPolicy/dLoss                   3.67165e-05\n",
      "GaussianMLPValueFunction/LossAfter        8.5736\n",
      "GaussianMLPValueFunction/LossBefore       8.79964\n",
      "GaussianMLPValueFunction/dLoss            0.226039\n",
      "TotalEnvSteps                        165834\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:50 | [trpo_pendulum] epoch #83 | Saving snapshot...\n",
      "2022-08-24 10:11:50 | [trpo_pendulum] epoch #83 | Saved\n",
      "2022-08-24 10:11:50 | [trpo_pendulum] epoch #83 | Time 46.23 s\n",
      "2022-08-24 10:11:50 | [trpo_pendulum] epoch #83 | EpochTime 0.55 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.16858\n",
      "Evaluation/AverageReturn                -91.9445\n",
      "Evaluation/Iteration                     83\n",
      "Evaluation/MaxReturn                    -91.3262\n",
      "Evaluation/MinReturn                    -92.5628\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.618314\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37276\n",
      "GaussianMLPPolicy/KL                      1.5955e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.97135\n",
      "GaussianMLPPolicy/LossBefore             -4.97132\n",
      "GaussianMLPPolicy/dLoss                   3.05176e-05\n",
      "GaussianMLPValueFunction/LossAfter        8.01139\n",
      "GaussianMLPValueFunction/LossBefore       8.23905\n",
      "GaussianMLPValueFunction/dLoss            0.227662\n",
      "TotalEnvSteps                        167832\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:51 | [trpo_pendulum] epoch #84 | Saving snapshot...\n",
      "2022-08-24 10:11:51 | [trpo_pendulum] epoch #84 | Saved\n",
      "2022-08-24 10:11:51 | [trpo_pendulum] epoch #84 | Time 46.78 s\n",
      "2022-08-24 10:11:51 | [trpo_pendulum] epoch #84 | EpochTime 0.54 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.3271\n",
      "Evaluation/AverageReturn                -90.0667\n",
      "Evaluation/Iteration                     84\n",
      "Evaluation/MaxReturn                    -89.3758\n",
      "Evaluation/MinReturn                    -90.7576\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.690868\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37219\n",
      "GaussianMLPPolicy/KL                      3.42101e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.63067\n",
      "GaussianMLPPolicy/LossBefore             -4.6306\n",
      "GaussianMLPPolicy/dLoss                   7.53403e-05\n",
      "GaussianMLPValueFunction/LossAfter        7.81614\n",
      "GaussianMLPValueFunction/LossBefore       8.02073\n",
      "GaussianMLPValueFunction/dLoss            0.204587\n",
      "TotalEnvSteps                        169830\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:52 | [trpo_pendulum] epoch #85 | Saving snapshot...\n",
      "2022-08-24 10:11:52 | [trpo_pendulum] epoch #85 | Saved\n",
      "2022-08-24 10:11:52 | [trpo_pendulum] epoch #85 | Time 47.33 s\n",
      "2022-08-24 10:11:52 | [trpo_pendulum] epoch #85 | EpochTime 0.55 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.22518\n",
      "Evaluation/AverageReturn                -91.4642\n",
      "Evaluation/Iteration                     85\n",
      "Evaluation/MaxReturn                    -89.1487\n",
      "Evaluation/MinReturn                    -93.7797\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.31552\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37162\n",
      "GaussianMLPPolicy/KL                      5.71097e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.81358\n",
      "GaussianMLPPolicy/LossBefore             -4.81345\n",
      "GaussianMLPPolicy/dLoss                   0.000133514\n",
      "GaussianMLPValueFunction/LossAfter        7.97198\n",
      "GaussianMLPValueFunction/LossBefore       8.18209\n",
      "GaussianMLPValueFunction/dLoss            0.210111\n",
      "TotalEnvSteps                        171828\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:52 | [trpo_pendulum] epoch #86 | Saving snapshot...\n",
      "2022-08-24 10:11:52 | [trpo_pendulum] epoch #86 | Saved\n",
      "2022-08-24 10:11:52 | [trpo_pendulum] epoch #86 | Time 47.88 s\n",
      "2022-08-24 10:11:52 | [trpo_pendulum] epoch #86 | EpochTime 0.54 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn      -10.9956\n",
      "Evaluation/AverageReturn                -91.4027\n",
      "Evaluation/Iteration                     86\n",
      "Evaluation/MaxReturn                    -87.7181\n",
      "Evaluation/MinReturn                    -95.0872\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.68454\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37104\n",
      "GaussianMLPPolicy/KL                      1.0384e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.44378\n",
      "GaussianMLPPolicy/LossBefore             -4.44356\n",
      "GaussianMLPPolicy/dLoss                   0.000213623\n",
      "GaussianMLPValueFunction/LossAfter        6.89367\n",
      "GaussianMLPValueFunction/LossBefore       7.08799\n",
      "GaussianMLPValueFunction/dLoss            0.194313\n",
      "TotalEnvSteps                        173826\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:53 | [trpo_pendulum] epoch #87 | Saving snapshot...\n",
      "2022-08-24 10:11:53 | [trpo_pendulum] epoch #87 | Saved\n",
      "2022-08-24 10:11:53 | [trpo_pendulum] epoch #87 | Time 48.42 s\n",
      "2022-08-24 10:11:53 | [trpo_pendulum] epoch #87 | EpochTime 0.54 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.93754\n",
      "Evaluation/AverageReturn                -89.4319\n",
      "Evaluation/Iteration                     87\n",
      "Evaluation/MaxReturn                    -85.832\n",
      "Evaluation/MinReturn                    -93.0319\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.59996\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.37049\n",
      "GaussianMLPPolicy/KL                      3.12991e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.23162\n",
      "GaussianMLPPolicy/LossBefore             -4.23143\n",
      "GaussianMLPPolicy/dLoss                   0.000182152\n",
      "GaussianMLPValueFunction/LossAfter        6.65125\n",
      "GaussianMLPValueFunction/LossBefore       6.83273\n",
      "GaussianMLPValueFunction/dLoss            0.181475\n",
      "TotalEnvSteps                        175824\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:53 | [trpo_pendulum] epoch #88 | Saving snapshot...\n",
      "2022-08-24 10:11:53 | [trpo_pendulum] epoch #88 | Saved\n",
      "2022-08-24 10:11:53 | [trpo_pendulum] epoch #88 | Time 48.98 s\n",
      "2022-08-24 10:11:53 | [trpo_pendulum] epoch #88 | EpochTime 0.55 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn      -10.3914\n",
      "Evaluation/AverageReturn                -94.975\n",
      "Evaluation/Iteration                     88\n",
      "Evaluation/MaxReturn                    -93.8192\n",
      "Evaluation/MinReturn                    -96.1309\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.15587\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.36989\n",
      "GaussianMLPPolicy/KL                      2.12368e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.91953\n",
      "GaussianMLPPolicy/LossBefore             -4.91921\n",
      "GaussianMLPPolicy/dLoss                   0.000315666\n",
      "GaussianMLPValueFunction/LossAfter        8.36827\n",
      "GaussianMLPValueFunction/LossBefore       8.5743\n",
      "GaussianMLPValueFunction/dLoss            0.20603\n",
      "TotalEnvSteps                        177822\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:54 | [trpo_pendulum] epoch #89 | Saving snapshot...\n",
      "2022-08-24 10:11:54 | [trpo_pendulum] epoch #89 | Saved\n",
      "2022-08-24 10:11:54 | [trpo_pendulum] epoch #89 | Time 49.53 s\n",
      "2022-08-24 10:11:54 | [trpo_pendulum] epoch #89 | EpochTime 0.53 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -8.47043\n",
      "Evaluation/AverageReturn                -88.0076\n",
      "Evaluation/Iteration                     89\n",
      "Evaluation/MaxReturn                    -85.1708\n",
      "Evaluation/MinReturn                    -90.8444\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.83682\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.36934\n",
      "GaussianMLPPolicy/KL                      6.0506e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.85871\n",
      "GaussianMLPPolicy/LossBefore             -3.8585\n",
      "GaussianMLPPolicy/dLoss                   0.000205517\n",
      "GaussianMLPValueFunction/LossAfter        5.83493\n",
      "GaussianMLPValueFunction/LossBefore       6.00424\n",
      "GaussianMLPValueFunction/dLoss            0.169311\n",
      "TotalEnvSteps                        179820\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:54 | [trpo_pendulum] epoch #90 | Saving snapshot...\n",
      "2022-08-24 10:11:54 | [trpo_pendulum] epoch #90 | Saved\n",
      "2022-08-24 10:11:54 | [trpo_pendulum] epoch #90 | Time 50.06 s\n",
      "2022-08-24 10:11:54 | [trpo_pendulum] epoch #90 | EpochTime 0.53 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -8.93612\n",
      "Evaluation/AverageReturn                -91.6633\n",
      "Evaluation/Iteration                     90\n",
      "Evaluation/MaxReturn                    -85.1593\n",
      "Evaluation/MinReturn                    -98.1673\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.50397\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.36877\n",
      "GaussianMLPPolicy/KL                      1.87171e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.33644\n",
      "GaussianMLPPolicy/LossBefore             -4.33562\n",
      "GaussianMLPPolicy/dLoss                   0.000822067\n",
      "GaussianMLPValueFunction/LossAfter        6.87299\n",
      "GaussianMLPValueFunction/LossBefore       7.05758\n",
      "GaussianMLPValueFunction/dLoss            0.184598\n",
      "TotalEnvSteps                        181818\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:55 | [trpo_pendulum] epoch #91 | Saving snapshot...\n",
      "2022-08-24 10:11:55 | [trpo_pendulum] epoch #91 | Saved\n",
      "2022-08-24 10:11:55 | [trpo_pendulum] epoch #91 | Time 50.60 s\n",
      "2022-08-24 10:11:55 | [trpo_pendulum] epoch #91 | EpochTime 0.53 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -8.09209\n",
      "Evaluation/AverageReturn                -85.1575\n",
      "Evaluation/Iteration                     91\n",
      "Evaluation/MaxReturn                    -83.1608\n",
      "Evaluation/MinReturn                    -87.1543\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      1.9968\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.36823\n",
      "GaussianMLPPolicy/KL                      2.7422e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.40868\n",
      "GaussianMLPPolicy/LossBefore             -3.40817\n",
      "GaussianMLPPolicy/dLoss                   0.000519037\n",
      "GaussianMLPValueFunction/LossAfter        5.46422\n",
      "GaussianMLPValueFunction/LossBefore       5.60639\n",
      "GaussianMLPValueFunction/dLoss            0.14216\n",
      "TotalEnvSteps                        183816\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:55 | [trpo_pendulum] epoch #92 | Saving snapshot...\n",
      "2022-08-24 10:11:55 | [trpo_pendulum] epoch #92 | Saved\n",
      "2022-08-24 10:11:55 | [trpo_pendulum] epoch #92 | Time 51.13 s\n",
      "2022-08-24 10:11:55 | [trpo_pendulum] epoch #92 | EpochTime 0.53 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn      -10.2315\n",
      "Evaluation/AverageReturn                -92.5023\n",
      "Evaluation/Iteration                     92\n",
      "Evaluation/MaxReturn                    -89.2592\n",
      "Evaluation/MinReturn                    -95.7453\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      3.24305\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.36768\n",
      "GaussianMLPPolicy/KL                      4.03996e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.04809\n",
      "GaussianMLPPolicy/LossBefore             -4.0483\n",
      "GaussianMLPPolicy/dLoss                  -0.000208378\n",
      "GaussianMLPValueFunction/LossAfter        6.35292\n",
      "GaussianMLPValueFunction/LossBefore       6.51804\n",
      "GaussianMLPValueFunction/dLoss            0.165117\n",
      "TotalEnvSteps                        185814\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:56 | [trpo_pendulum] epoch #93 | Saving snapshot...\n",
      "2022-08-24 10:11:56 | [trpo_pendulum] epoch #93 | Saved\n",
      "2022-08-24 10:11:56 | [trpo_pendulum] epoch #93 | Time 51.69 s\n",
      "2022-08-24 10:11:56 | [trpo_pendulum] epoch #93 | EpochTime 0.56 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -8.5534\n",
      "Evaluation/AverageReturn                -90.8004\n",
      "Evaluation/Iteration                     93\n",
      "Evaluation/MaxReturn                    -83.6257\n",
      "Evaluation/MinReturn                    -97.9752\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      7.17479\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.36712\n",
      "GaussianMLPPolicy/KL                      3.88368e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.01633\n",
      "GaussianMLPPolicy/LossBefore             -4.01624\n",
      "GaussianMLPPolicy/dLoss                   9.58443e-05\n",
      "GaussianMLPValueFunction/LossAfter        6.37768\n",
      "GaussianMLPValueFunction/LossBefore       6.54116\n",
      "GaussianMLPValueFunction/dLoss            0.163481\n",
      "TotalEnvSteps                        187812\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:56 | [trpo_pendulum] epoch #94 | Saving snapshot...\n",
      "2022-08-24 10:11:56 | [trpo_pendulum] epoch #94 | Saved\n",
      "2022-08-24 10:11:56 | [trpo_pendulum] epoch #94 | Time 52.24 s\n",
      "2022-08-24 10:11:56 | [trpo_pendulum] epoch #94 | EpochTime 0.54 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -8.96721\n",
      "Evaluation/AverageReturn                -93.9106\n",
      "Evaluation/Iteration                     94\n",
      "Evaluation/MaxReturn                    -91.1666\n",
      "Evaluation/MinReturn                    -96.6545\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      2.74398\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.36652\n",
      "GaussianMLPPolicy/KL                      1.58884e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.46227\n",
      "GaussianMLPPolicy/LossBefore             -4.46113\n",
      "GaussianMLPPolicy/dLoss                   0.00113249\n",
      "GaussianMLPValueFunction/LossAfter        7.47106\n",
      "GaussianMLPValueFunction/LossBefore       7.64361\n",
      "GaussianMLPValueFunction/dLoss            0.172549\n",
      "TotalEnvSteps                        189810\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:57 | [trpo_pendulum] epoch #95 | Saving snapshot...\n",
      "2022-08-24 10:11:57 | [trpo_pendulum] epoch #95 | Saved\n",
      "2022-08-24 10:11:57 | [trpo_pendulum] epoch #95 | Time 52.79 s\n",
      "2022-08-24 10:11:57 | [trpo_pendulum] epoch #95 | EpochTime 0.55 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.19942\n",
      "Evaluation/AverageReturn                -88.8322\n",
      "Evaluation/Iteration                     95\n",
      "Evaluation/MaxReturn                    -88.5682\n",
      "Evaluation/MinReturn                    -89.0962\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.263977\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.36595\n",
      "GaussianMLPPolicy/KL                      1.51249e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.51587\n",
      "GaussianMLPPolicy/LossBefore             -3.51573\n",
      "GaussianMLPPolicy/dLoss                   0.000136852\n",
      "GaussianMLPValueFunction/LossAfter        5.39023\n",
      "GaussianMLPValueFunction/LossBefore       5.5277\n",
      "GaussianMLPValueFunction/dLoss            0.13747\n",
      "TotalEnvSteps                        191808\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:58 | [trpo_pendulum] epoch #96 | Saving snapshot...\n",
      "2022-08-24 10:11:58 | [trpo_pendulum] epoch #96 | Saved\n",
      "2022-08-24 10:11:58 | [trpo_pendulum] epoch #96 | Time 53.33 s\n",
      "2022-08-24 10:11:58 | [trpo_pendulum] epoch #96 | EpochTime 0.54 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.3983\n",
      "Evaluation/AverageReturn                -95.0771\n",
      "Evaluation/Iteration                     96\n",
      "Evaluation/MaxReturn                    -88.3055\n",
      "Evaluation/MinReturn                   -101.849\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      6.77163\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.36535\n",
      "GaussianMLPPolicy/KL                      3.92652e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -4.32786\n",
      "GaussianMLPPolicy/LossBefore             -4.32784\n",
      "GaussianMLPPolicy/dLoss                   2.57492e-05\n",
      "GaussianMLPValueFunction/LossAfter        6.96648\n",
      "GaussianMLPValueFunction/LossBefore       7.13299\n",
      "GaussianMLPValueFunction/dLoss            0.166506\n",
      "TotalEnvSteps                        193806\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:58 | [trpo_pendulum] epoch #97 | Saving snapshot...\n",
      "2022-08-24 10:11:58 | [trpo_pendulum] epoch #97 | Saved\n",
      "2022-08-24 10:11:58 | [trpo_pendulum] epoch #97 | Time 53.88 s\n",
      "2022-08-24 10:11:58 | [trpo_pendulum] epoch #97 | EpochTime 0.55 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.20991\n",
      "Evaluation/AverageReturn                -88.2665\n",
      "Evaluation/Iteration                     97\n",
      "Evaluation/MaxReturn                    -88.2608\n",
      "Evaluation/MinReturn                    -88.2723\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0057589\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.36473\n",
      "GaussianMLPPolicy/KL                      3.98643e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.27793\n",
      "GaussianMLPPolicy/LossBefore             -3.27776\n",
      "GaussianMLPPolicy/dLoss                   0.000172377\n",
      "GaussianMLPValueFunction/LossAfter        5.44413\n",
      "GaussianMLPValueFunction/LossBefore       5.56863\n",
      "GaussianMLPValueFunction/dLoss            0.124508\n",
      "TotalEnvSteps                        195804\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:59 | [trpo_pendulum] epoch #98 | Saving snapshot...\n",
      "2022-08-24 10:11:59 | [trpo_pendulum] epoch #98 | Saved\n",
      "2022-08-24 10:11:59 | [trpo_pendulum] epoch #98 | Time 54.43 s\n",
      "2022-08-24 10:11:59 | [trpo_pendulum] epoch #98 | EpochTime 0.54 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -7.86985\n",
      "Evaluation/AverageReturn                -91.7511\n",
      "Evaluation/Iteration                     98\n",
      "Evaluation/MaxReturn                    -91.1144\n",
      "Evaluation/MinReturn                    -92.3877\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.63664\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.36411\n",
      "GaussianMLPPolicy/KL                      1.89308e-06\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.70632\n",
      "GaussianMLPPolicy/LossBefore             -3.70611\n",
      "GaussianMLPPolicy/dLoss                   0.000214815\n",
      "GaussianMLPValueFunction/LossAfter        5.90301\n",
      "GaussianMLPValueFunction/LossBefore       6.04721\n",
      "GaussianMLPValueFunction/dLoss            0.144201\n",
      "TotalEnvSteps                        197802\n",
      "-----------------------------------  ----------------\n",
      "2022-08-24 10:11:59 | [trpo_pendulum] epoch #99 | Saving snapshot...\n",
      "2022-08-24 10:11:59 | [trpo_pendulum] epoch #99 | Saved\n",
      "2022-08-24 10:11:59 | [trpo_pendulum] epoch #99 | Time 55.06 s\n",
      "2022-08-24 10:11:59 | [trpo_pendulum] epoch #99 | EpochTime 0.62 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -9.02019\n",
      "Evaluation/AverageReturn                -90.4562\n",
      "Evaluation/Iteration                     99\n",
      "Evaluation/MaxReturn                    -90.2055\n",
      "Evaluation/MinReturn                    -90.7068\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.250653\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                 1.3635\n",
      "GaussianMLPPolicy/KL                      8.67079e-07\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -3.30601\n",
      "GaussianMLPPolicy/LossBefore             -3.30592\n",
      "GaussianMLPPolicy/dLoss                   8.36849e-05\n",
      "GaussianMLPValueFunction/LossAfter        5.09577\n",
      "GaussianMLPValueFunction/LossBefore       5.22193\n",
      "GaussianMLPValueFunction/dLoss            0.126166\n",
      "TotalEnvSteps                        199800\n",
      "-----------------------------------  ----------------\n"
     ]
    }
   ],
   "source": [
    "trpo_pendulum(seed=1234)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
