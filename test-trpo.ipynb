{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from garage import wrap_experiment\n",
    "from garage.envs import GymEnv\n",
    "from garage.experiment.deterministic import set_seed\n",
    "from garage.sampler import LocalSampler\n",
    "from garage.torch.algos import TRPO\n",
    "from garage.torch.algos import VPG\n",
    "from garage.torch.policies import GaussianMLPPolicy\n",
    "from garage.torch.value_functions import GaussianMLPValueFunction\n",
    "from garage.trainer import Trainer\n",
    "\n",
    "@wrap_experiment\n",
    "def trpo_pendulum(ctxt=None, seed=1):\n",
    "    \"\"\"Train TRPO with InvertedDoublePendulum-v2 environment.\n",
    "    Args:\n",
    "        ctxt (garage.experiment.ExperimentContext): The experiment\n",
    "            configuration used by Trainer to create the snapshotter.\n",
    "        seed (int): Used to seed the random number generator to produce\n",
    "            determinism.\n",
    "    \"\"\"\n",
    "    set_seed(seed)\n",
    "    env = GymEnv('MountainCarContinuous-v0')\n",
    "\n",
    "    trainer = Trainer(ctxt)\n",
    "\n",
    "    policy = GaussianMLPPolicy(env.spec,\n",
    "                               hidden_sizes=[32, 32],\n",
    "                               hidden_nonlinearity=torch.tanh,\n",
    "                               output_nonlinearity=None)\n",
    "\n",
    "    value_function = GaussianMLPValueFunction(env_spec=env.spec,\n",
    "                                              hidden_sizes=(32, 32),\n",
    "                                              hidden_nonlinearity=torch.tanh,\n",
    "                                              output_nonlinearity=None)\n",
    "\n",
    "    sampler = LocalSampler(agents=policy,\n",
    "                           envs=env,\n",
    "                           max_episode_length=env.spec.max_episode_length)\n",
    "\n",
    "    algo = TRPO(env_spec=env.spec,\n",
    "                policy=policy,\n",
    "                value_function=value_function,\n",
    "                sampler=sampler,\n",
    "                discount=0.99,\n",
    "                center_adv=False)\n",
    "\n",
    "    trainer.setup(algo, env)\n",
    "    trainer.train(n_epochs=100, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-24 15:55:32 | [trpo_pendulum] Logging to D:\\Github\\DRSOM-for-RL\\data/local/experiment/trpo_pendulum_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\garage\\experiment\\deterministic.py:36: UserWarning: Enabeling deterministic mode in PyTorch can have a performance impact when using GPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-24 15:55:32 | [trpo_pendulum] Obtaining samples...\n",
      "tensor([ 7.5510e-02,  1.9935e-02, -1.6855e-07,  ..., -8.5516e-02,\n",
      "        -4.1725e-02,  7.6796e-01])\n",
      "2022-08-24 15:55:33 | [trpo_pendulum] epoch #0 | Saving snapshot...\n",
      "2022-08-24 15:55:33 | [trpo_pendulum] epoch #0 | Saved\n",
      "2022-08-24 15:55:33 | [trpo_pendulum] epoch #0 | Time 0.91 s\n",
      "2022-08-24 15:55:33 | [trpo_pendulum] epoch #0 | EpochTime 0.91 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn    -10.35\n",
      "Evaluation/AverageReturn              -96.0916\n",
      "Evaluation/Iteration                    0\n",
      "Evaluation/MaxReturn                  -92.4869\n",
      "Evaluation/MinReturn                  -99.6962\n",
      "Evaluation/NumEpisodes                  2\n",
      "Evaluation/StdReturn                    3.60468\n",
      "Evaluation/TerminationRate              0\n",
      "GaussianMLPPolicy/Entropy               1.40969\n",
      "GaussianMLPPolicy/KL                    0.000224939\n",
      "GaussianMLPPolicy/KLBefore              0\n",
      "GaussianMLPPolicy/LossAfter             3.13369\n",
      "GaussianMLPPolicy/LossBefore            3.13476\n",
      "GaussianMLPPolicy/dLoss                 0.00107312\n",
      "GaussianMLPValueFunction/LossAfter      9.59472\n",
      "GaussianMLPValueFunction/LossBefore    41.0752\n",
      "GaussianMLPValueFunction/dLoss         31.4805\n",
      "TotalEnvSteps                        1998\n",
      "-----------------------------------  --------------\n",
      "tensor([ 3.6931e-01,  6.8045e-03,  5.0950e-06,  ...,  9.7703e-03,\n",
      "        -6.4474e-03,  1.0153e-01])\n",
      "2022-08-24 15:55:34 | [trpo_pendulum] epoch #1 | Saving snapshot...\n",
      "2022-08-24 15:55:34 | [trpo_pendulum] epoch #1 | Saved\n",
      "2022-08-24 15:55:34 | [trpo_pendulum] epoch #1 | Time 1.85 s\n",
      "2022-08-24 15:55:34 | [trpo_pendulum] epoch #1 | EpochTime 0.93 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn     -9.47042\n",
      "Evaluation/AverageReturn              -97.4188\n",
      "Evaluation/Iteration                    1\n",
      "Evaluation/MaxReturn                  -90.9383\n",
      "Evaluation/MinReturn                 -103.899\n",
      "Evaluation/NumEpisodes                  2\n",
      "Evaluation/StdReturn                    6.4805\n",
      "Evaluation/TerminationRate              0\n",
      "GaussianMLPPolicy/Entropy               1.39483\n",
      "GaussianMLPPolicy/KL                    0.00716363\n",
      "GaussianMLPPolicy/KLBefore              0\n",
      "GaussianMLPPolicy/LossAfter             1.39712\n",
      "GaussianMLPPolicy/LossBefore            1.40108\n",
      "GaussianMLPPolicy/dLoss                 0.00396049\n",
      "GaussianMLPValueFunction/LossAfter      3.53205\n",
      "GaussianMLPValueFunction/LossBefore    10.1215\n",
      "GaussianMLPValueFunction/dLoss          6.58948\n",
      "TotalEnvSteps                        3996\n",
      "-----------------------------------  -------------\n",
      "tensor([ 3.3512e-01, -3.1778e-02, -3.1487e-06,  ..., -1.8945e-02,\n",
      "         3.1079e-02, -4.7790e-01])\n",
      "2022-08-24 15:55:35 | [trpo_pendulum] epoch #2 | Saving snapshot...\n",
      "2022-08-24 15:55:35 | [trpo_pendulum] epoch #2 | Saved\n",
      "2022-08-24 15:55:35 | [trpo_pendulum] epoch #2 | Time 2.83 s\n",
      "2022-08-24 15:55:35 | [trpo_pendulum] epoch #2 | EpochTime 0.98 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn     -9.27148\n",
      "Evaluation/AverageReturn              -95.236\n",
      "Evaluation/Iteration                    2\n",
      "Evaluation/MaxReturn                  -92.8261\n",
      "Evaluation/MinReturn                  -97.6458\n",
      "Evaluation/NumEpisodes                  2\n",
      "Evaluation/StdReturn                    2.40986\n",
      "Evaluation/TerminationRate              0\n",
      "GaussianMLPPolicy/Entropy               1.36174\n",
      "GaussianMLPPolicy/KL                    0.00706961\n",
      "GaussianMLPPolicy/KLBefore              0\n",
      "GaussianMLPPolicy/LossAfter             0.0728142\n",
      "GaussianMLPPolicy/LossBefore            0.0852376\n",
      "GaussianMLPPolicy/dLoss                 0.0124235\n",
      "GaussianMLPValueFunction/LossAfter      2.80939\n",
      "GaussianMLPValueFunction/LossBefore     2.85207\n",
      "GaussianMLPValueFunction/dLoss          0.0426843\n",
      "TotalEnvSteps                        5994\n",
      "-----------------------------------  -------------\n",
      "tensor([ 2.5217e-01, -1.8902e-02, -1.1048e-07,  ...,  6.3616e-03,\n",
      "         1.5444e-02, -3.2441e-01])\n",
      "2022-08-24 15:55:36 | [trpo_pendulum] epoch #3 | Saving snapshot...\n",
      "2022-08-24 15:55:36 | [trpo_pendulum] epoch #3 | Saved\n",
      "2022-08-24 15:55:36 | [trpo_pendulum] epoch #3 | Time 3.73 s\n",
      "2022-08-24 15:55:36 | [trpo_pendulum] epoch #3 | EpochTime 0.89 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn     -8.25433\n",
      "Evaluation/AverageReturn              -90.3817\n",
      "Evaluation/Iteration                    3\n",
      "Evaluation/MaxReturn                  -90.0547\n",
      "Evaluation/MinReturn                  -90.7086\n",
      "Evaluation/NumEpisodes                  2\n",
      "Evaluation/StdReturn                    0.326929\n",
      "Evaluation/TerminationRate              0\n",
      "GaussianMLPPolicy/Entropy               1.30041\n",
      "GaussianMLPPolicy/KL                    0.00837573\n",
      "GaussianMLPPolicy/KLBefore              0\n",
      "GaussianMLPPolicy/LossAfter            -0.161298\n",
      "GaussianMLPPolicy/LossBefore           -0.15479\n",
      "GaussianMLPPolicy/dLoss                 0.00650828\n",
      "GaussianMLPValueFunction/LossAfter      2.6018\n",
      "GaussianMLPValueFunction/LossBefore     2.71036\n",
      "GaussianMLPValueFunction/dLoss          0.108557\n",
      "TotalEnvSteps                        7992\n",
      "-----------------------------------  -------------\n",
      "tensor([ 3.3143e-01, -1.7443e-02,  3.4778e-06,  ..., -3.6885e-02,\n",
      "         8.2535e-02, -5.4794e-01])\n",
      "2022-08-24 15:55:37 | [trpo_pendulum] epoch #4 | Saving snapshot...\n",
      "2022-08-24 15:55:37 | [trpo_pendulum] epoch #4 | Saved\n",
      "2022-08-24 15:55:37 | [trpo_pendulum] epoch #4 | Time 4.62 s\n",
      "2022-08-24 15:55:37 | [trpo_pendulum] epoch #4 | EpochTime 0.88 s\n",
      "-----------------------------------  -------------\n",
      "Evaluation/AverageDiscountedReturn     -8.21463\n",
      "Evaluation/AverageReturn              -81.9913\n",
      "Evaluation/Iteration                    4\n",
      "Evaluation/MaxReturn                  -76.4601\n",
      "Evaluation/MinReturn                  -87.5226\n",
      "Evaluation/NumEpisodes                  2\n",
      "Evaluation/StdReturn                    5.5313\n",
      "Evaluation/TerminationRate              0\n",
      "GaussianMLPPolicy/Entropy               1.2622\n",
      "GaussianMLPPolicy/KL                    0.00538484\n",
      "GaussianMLPPolicy/KLBefore              0\n",
      "GaussianMLPPolicy/LossAfter            -0.284845\n",
      "GaussianMLPPolicy/LossBefore           -0.280914\n",
      "GaussianMLPPolicy/dLoss                 0.00393099\n",
      "GaussianMLPValueFunction/LossAfter      2.54055\n",
      "GaussianMLPValueFunction/LossBefore     2.85717\n",
      "GaussianMLPValueFunction/dLoss          0.316617\n",
      "TotalEnvSteps                        9990\n",
      "-----------------------------------  -------------\n",
      "tensor([ 4.0297e-01,  1.2887e-02,  6.0934e-06,  ..., -9.8474e-02,\n",
      "         1.8034e-02, -3.7985e-01])\n",
      "2022-08-24 15:55:38 | [trpo_pendulum] epoch #5 | Saving snapshot...\n",
      "2022-08-24 15:55:38 | [trpo_pendulum] epoch #5 | Saved\n",
      "2022-08-24 15:55:38 | [trpo_pendulum] epoch #5 | Time 5.53 s\n",
      "2022-08-24 15:55:38 | [trpo_pendulum] epoch #5 | EpochTime 0.91 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -7.86046\n",
      "Evaluation/AverageReturn               -78.2989\n",
      "Evaluation/Iteration                     5\n",
      "Evaluation/MaxReturn                   -75.2227\n",
      "Evaluation/MinReturn                   -81.375\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     3.07616\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.23942\n",
      "GaussianMLPPolicy/KL                     0.00580147\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.121238\n",
      "GaussianMLPPolicy/LossBefore            -0.120014\n",
      "GaussianMLPPolicy/dLoss                  0.00122407\n",
      "GaussianMLPValueFunction/LossAfter       2.39152\n",
      "GaussianMLPValueFunction/LossBefore      2.49743\n",
      "GaussianMLPValueFunction/dLoss           0.10591\n",
      "TotalEnvSteps                        11988\n",
      "-----------------------------------  --------------\n",
      "tensor([ 2.6890e-01,  6.4148e-03,  3.3185e-06,  ..., -3.6301e-02,\n",
      "        -5.0843e-03, -1.2712e-01])\n",
      "2022-08-24 15:55:39 | [trpo_pendulum] epoch #6 | Saving snapshot...\n",
      "2022-08-24 15:55:39 | [trpo_pendulum] epoch #6 | Saved\n",
      "2022-08-24 15:55:39 | [trpo_pendulum] epoch #6 | Time 6.42 s\n",
      "2022-08-24 15:55:39 | [trpo_pendulum] epoch #6 | EpochTime 0.89 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -8.44673\n",
      "Evaluation/AverageReturn               -74.626\n",
      "Evaluation/Iteration                     6\n",
      "Evaluation/MaxReturn                   -71.2339\n",
      "Evaluation/MinReturn                   -78.0181\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     3.39211\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.20232\n",
      "GaussianMLPPolicy/KL                     0.00933985\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0988326\n",
      "GaussianMLPPolicy/LossBefore            -0.0848011\n",
      "GaussianMLPPolicy/dLoss                  0.0140315\n",
      "GaussianMLPValueFunction/LossAfter       2.30219\n",
      "GaussianMLPValueFunction/LossBefore      2.40698\n",
      "GaussianMLPValueFunction/dLoss           0.104794\n",
      "TotalEnvSteps                        13986\n",
      "-----------------------------------  --------------\n",
      "tensor([ 3.1075e-01,  9.0554e-03, -1.0851e-07,  ..., -7.9125e-02,\n",
      "        -2.8766e-02, -3.0949e-01])\n",
      "2022-08-24 15:55:40 | [trpo_pendulum] epoch #7 | Saving snapshot...\n",
      "2022-08-24 15:55:40 | [trpo_pendulum] epoch #7 | Saved\n",
      "2022-08-24 15:55:40 | [trpo_pendulum] epoch #7 | Time 7.31 s\n",
      "2022-08-24 15:55:40 | [trpo_pendulum] epoch #7 | EpochTime 0.88 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -7.36136\n",
      "Evaluation/AverageReturn               -70.3939\n",
      "Evaluation/Iteration                     7\n",
      "Evaluation/MaxReturn                   -68.4431\n",
      "Evaluation/MinReturn                   -72.3447\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     1.9508\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.14129\n",
      "GaussianMLPPolicy/KL                     0.00575403\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0972723\n",
      "GaussianMLPPolicy/LossBefore            -0.0869761\n",
      "GaussianMLPPolicy/dLoss                  0.0102962\n",
      "GaussianMLPValueFunction/LossAfter       2.0596\n",
      "GaussianMLPValueFunction/LossBefore      2.11987\n",
      "GaussianMLPValueFunction/dLoss           0.0602694\n",
      "TotalEnvSteps                        15984\n",
      "-----------------------------------  --------------\n",
      "tensor([ 2.6779e-01, -6.9402e-03,  1.4579e-09,  ...,  1.1531e-01,\n",
      "         1.5449e-02,  2.8821e-01])\n",
      "2022-08-24 15:55:40 | [trpo_pendulum] epoch #8 | Saving snapshot...\n",
      "2022-08-24 15:55:40 | [trpo_pendulum] epoch #8 | Saved\n",
      "2022-08-24 15:55:40 | [trpo_pendulum] epoch #8 | Time 8.20 s\n",
      "2022-08-24 15:55:40 | [trpo_pendulum] epoch #8 | EpochTime 0.89 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -5.84666\n",
      "Evaluation/AverageReturn               -58.9688\n",
      "Evaluation/Iteration                     8\n",
      "Evaluation/MaxReturn                   -57\n",
      "Evaluation/MinReturn                   -60.9376\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     1.96878\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.06473\n",
      "GaussianMLPPolicy/KL                     0.00627082\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.335523\n",
      "GaussianMLPPolicy/LossBefore            -0.325811\n",
      "GaussianMLPPolicy/dLoss                  0.00971103\n",
      "GaussianMLPValueFunction/LossAfter       1.70567\n",
      "GaussianMLPValueFunction/LossBefore      2.06669\n",
      "GaussianMLPValueFunction/dLoss           0.36102\n",
      "TotalEnvSteps                        17982\n",
      "-----------------------------------  --------------\n",
      "tensor([ 1.8451e-01,  4.9440e-03,  9.9492e-07,  ..., -6.2808e-02,\n",
      "        -4.0395e-03, -2.4555e-01])\n",
      "2022-08-24 15:55:41 | [trpo_pendulum] epoch #9 | Saving snapshot...\n",
      "2022-08-24 15:55:41 | [trpo_pendulum] epoch #9 | Saved\n",
      "2022-08-24 15:55:41 | [trpo_pendulum] epoch #9 | Time 9.18 s\n",
      "2022-08-24 15:55:41 | [trpo_pendulum] epoch #9 | EpochTime 0.97 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -4.76132\n",
      "Evaluation/AverageReturn               -49.3531\n",
      "Evaluation/Iteration                     9\n",
      "Evaluation/MaxReturn                   -47.4783\n",
      "Evaluation/MinReturn                   -51.2279\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     1.87482\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.03363\n",
      "GaussianMLPPolicy/KL                     0.00789086\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.301886\n",
      "GaussianMLPPolicy/LossBefore            -0.297658\n",
      "GaussianMLPPolicy/dLoss                  0.00422844\n",
      "GaussianMLPValueFunction/LossAfter       1.51009\n",
      "GaussianMLPValueFunction/LossBefore      1.80514\n",
      "GaussianMLPValueFunction/dLoss           0.295055\n",
      "TotalEnvSteps                        19980\n",
      "-----------------------------------  --------------\n",
      "tensor([ 8.6586e-02, -1.8048e-02, -1.4507e-05,  ...,  3.2116e-01,\n",
      "        -1.7869e-02,  7.5508e-01])\n",
      "2022-08-24 15:55:42 | [trpo_pendulum] epoch #10 | Saving snapshot...\n",
      "2022-08-24 15:55:42 | [trpo_pendulum] epoch #10 | Saved\n",
      "2022-08-24 15:55:42 | [trpo_pendulum] epoch #10 | Time 10.08 s\n",
      "2022-08-24 15:55:42 | [trpo_pendulum] epoch #10 | EpochTime 0.90 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -4.63502\n",
      "Evaluation/AverageReturn               -47.3002\n",
      "Evaluation/Iteration                    10\n",
      "Evaluation/MaxReturn                   -45.8234\n",
      "Evaluation/MinReturn                   -48.777\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     1.47676\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.02495\n",
      "GaussianMLPPolicy/KL                     0.00200869\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0376748\n",
      "GaussianMLPPolicy/LossBefore            -0.0376498\n",
      "GaussianMLPPolicy/dLoss                  2.49967e-05\n",
      "GaussianMLPValueFunction/LossAfter       1.34071\n",
      "GaussianMLPValueFunction/LossBefore      1.35402\n",
      "GaussianMLPValueFunction/dLoss           0.0133016\n",
      "TotalEnvSteps                        21978\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 1.7336e-01, -3.5087e-02,  3.7848e-06,  ...,  3.1153e-01,\n",
      "        -6.5752e-02,  9.1558e-01])\n",
      "2022-08-24 15:55:43 | [trpo_pendulum] epoch #11 | Saving snapshot...\n",
      "2022-08-24 15:55:43 | [trpo_pendulum] epoch #11 | Saved\n",
      "2022-08-24 15:55:43 | [trpo_pendulum] epoch #11 | Time 10.99 s\n",
      "2022-08-24 15:55:43 | [trpo_pendulum] epoch #11 | EpochTime 0.90 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -4.7879\n",
      "Evaluation/AverageReturn               -50.6764\n",
      "Evaluation/Iteration                    11\n",
      "Evaluation/MaxReturn                   -50.0663\n",
      "Evaluation/MinReturn                   -51.2865\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.610097\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.01974\n",
      "GaussianMLPPolicy/KL                     0.000782451\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.131678\n",
      "GaussianMLPPolicy/LossBefore             0.131767\n",
      "GaussianMLPPolicy/dLoss                  8.87513e-05\n",
      "GaussianMLPValueFunction/LossAfter       1.52196\n",
      "GaussianMLPValueFunction/LossBefore      1.57035\n",
      "GaussianMLPValueFunction/dLoss           0.0483874\n",
      "TotalEnvSteps                        23976\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 1.8988e-01, -1.2656e-02, -3.2488e-05,  ...,  3.0406e-01,\n",
      "        -8.2296e-02,  6.7927e-01])\n",
      "2022-08-24 15:55:44 | [trpo_pendulum] epoch #12 | Saving snapshot...\n",
      "2022-08-24 15:55:44 | [trpo_pendulum] epoch #12 | Saved\n",
      "2022-08-24 15:55:44 | [trpo_pendulum] epoch #12 | Time 11.92 s\n",
      "2022-08-24 15:55:44 | [trpo_pendulum] epoch #12 | EpochTime 0.93 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -5.29738\n",
      "Evaluation/AverageReturn               -51.9296\n",
      "Evaluation/Iteration                    12\n",
      "Evaluation/MaxReturn                   -50.82\n",
      "Evaluation/MinReturn                   -53.0391\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     1.10953\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                1.00656\n",
      "GaussianMLPPolicy/KL                     0.00608387\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.0434023\n",
      "GaussianMLPPolicy/LossBefore             0.0446302\n",
      "GaussianMLPPolicy/dLoss                  0.00122795\n",
      "GaussianMLPValueFunction/LossAfter       1.52319\n",
      "GaussianMLPValueFunction/LossBefore      1.54337\n",
      "GaussianMLPValueFunction/dLoss           0.020187\n",
      "TotalEnvSteps                        25974\n",
      "-----------------------------------  --------------\n",
      "tensor([ 1.9066e-01, -1.5109e-03, -1.1008e-06,  ...,  1.7427e-01,\n",
      "        -1.6245e-03,  6.7155e-01])\n",
      "2022-08-24 15:55:45 | [trpo_pendulum] epoch #13 | Saving snapshot...\n",
      "2022-08-24 15:55:45 | [trpo_pendulum] epoch #13 | Saved\n",
      "2022-08-24 15:55:45 | [trpo_pendulum] epoch #13 | Time 12.85 s\n",
      "2022-08-24 15:55:45 | [trpo_pendulum] epoch #13 | EpochTime 0.93 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -4.48598\n",
      "Evaluation/AverageReturn               -46.4716\n",
      "Evaluation/Iteration                    13\n",
      "Evaluation/MaxReturn                   -45.8785\n",
      "Evaluation/MinReturn                   -47.0646\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.593023\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.979368\n",
      "GaussianMLPPolicy/KL                     0.00847964\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.147976\n",
      "GaussianMLPPolicy/LossBefore            -0.144133\n",
      "GaussianMLPPolicy/dLoss                  0.00384313\n",
      "GaussianMLPValueFunction/LossAfter       1.42583\n",
      "GaussianMLPValueFunction/LossBefore      1.5006\n",
      "GaussianMLPValueFunction/dLoss           0.0747709\n",
      "TotalEnvSteps                        27972\n",
      "-----------------------------------  --------------\n",
      "tensor([ 1.6910e-01,  3.3612e-03, -4.3686e-06,  ..., -2.8015e-02,\n",
      "        -2.3281e-02, -2.6740e-01])\n",
      "2022-08-24 15:55:46 | [trpo_pendulum] epoch #14 | Saving snapshot...\n",
      "2022-08-24 15:55:46 | [trpo_pendulum] epoch #14 | Saved\n",
      "2022-08-24 15:55:46 | [trpo_pendulum] epoch #14 | Time 13.74 s\n",
      "2022-08-24 15:55:46 | [trpo_pendulum] epoch #14 | EpochTime 0.88 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -4.08862\n",
      "Evaluation/AverageReturn               -40.9559\n",
      "Evaluation/Iteration                    14\n",
      "Evaluation/MaxReturn                   -40.0553\n",
      "Evaluation/MinReturn                   -41.8566\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.900652\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.908717\n",
      "GaussianMLPPolicy/KL                     0.00829826\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.179733\n",
      "GaussianMLPPolicy/LossBefore            -0.172843\n",
      "GaussianMLPPolicy/dLoss                  0.00689091\n",
      "GaussianMLPValueFunction/LossAfter       1.37604\n",
      "GaussianMLPValueFunction/LossBefore      1.49688\n",
      "GaussianMLPValueFunction/dLoss           0.120845\n",
      "TotalEnvSteps                        29970\n",
      "-----------------------------------  --------------\n",
      "tensor([1.8028e-01, 7.1663e-02, 3.0335e-06,  ..., 1.0360e-01, 1.7000e-01,\n",
      "        1.0248e+00])\n",
      "2022-08-24 15:55:47 | [trpo_pendulum] epoch #15 | Saving snapshot...\n",
      "2022-08-24 15:55:47 | [trpo_pendulum] epoch #15 | Saved\n",
      "2022-08-24 15:55:47 | [trpo_pendulum] epoch #15 | Time 14.65 s\n",
      "2022-08-24 15:55:47 | [trpo_pendulum] epoch #15 | EpochTime 0.91 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -3.64431\n",
      "Evaluation/AverageReturn               -40.7699\n",
      "Evaluation/Iteration                    15\n",
      "Evaluation/MaxReturn                   -40.2786\n",
      "Evaluation/MinReturn                   -41.2611\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.491263\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.859911\n",
      "GaussianMLPPolicy/KL                     0.00621564\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.00246953\n",
      "GaussianMLPPolicy/LossBefore             0.0109076\n",
      "GaussianMLPPolicy/dLoss                  0.00843807\n",
      "GaussianMLPValueFunction/LossAfter       1.37214\n",
      "GaussianMLPValueFunction/LossBefore      1.37561\n",
      "GaussianMLPValueFunction/dLoss           0.0034672\n",
      "TotalEnvSteps                        31968\n",
      "-----------------------------------  --------------\n",
      "tensor([ 1.2425e-01,  9.9967e-03, -7.8906e-07,  ...,  5.0795e-03,\n",
      "         2.9661e-02,  1.5641e-01])\n",
      "2022-08-24 15:55:48 | [trpo_pendulum] epoch #16 | Saving snapshot...\n",
      "2022-08-24 15:55:48 | [trpo_pendulum] epoch #16 | Saved\n",
      "2022-08-24 15:55:48 | [trpo_pendulum] epoch #16 | Time 15.58 s\n",
      "2022-08-24 15:55:48 | [trpo_pendulum] epoch #16 | EpochTime 0.93 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -3.64187\n",
      "Evaluation/AverageReturn               -36.4035\n",
      "Evaluation/Iteration                    16\n",
      "Evaluation/MaxReturn                   -35.1614\n",
      "Evaluation/MinReturn                   -37.6457\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     1.24213\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.843505\n",
      "GaussianMLPPolicy/KL                     0.00512788\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.14957\n",
      "GaussianMLPPolicy/LossBefore            -0.148609\n",
      "GaussianMLPPolicy/dLoss                  0.000961319\n",
      "GaussianMLPValueFunction/LossAfter       1.26947\n",
      "GaussianMLPValueFunction/LossBefore      1.35631\n",
      "GaussianMLPValueFunction/dLoss           0.0868468\n",
      "TotalEnvSteps                        33966\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 1.1356e-01,  2.8128e-02,  4.4721e-06,  ..., -8.7884e-02,\n",
      "         1.2730e-01,  7.1555e-01])\n",
      "2022-08-24 15:55:49 | [trpo_pendulum] epoch #17 | Saving snapshot...\n",
      "2022-08-24 15:55:49 | [trpo_pendulum] epoch #17 | Saved\n",
      "2022-08-24 15:55:49 | [trpo_pendulum] epoch #17 | Time 16.48 s\n",
      "2022-08-24 15:55:49 | [trpo_pendulum] epoch #17 | EpochTime 0.90 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -2.92497\n",
      "Evaluation/AverageReturn               -30.5798\n",
      "Evaluation/Iteration                    17\n",
      "Evaluation/MaxReturn                   -29.9065\n",
      "Evaluation/MinReturn                   -31.253\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.673205\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.822349\n",
      "GaussianMLPPolicy/KL                     0.00863996\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.182906\n",
      "GaussianMLPPolicy/LossBefore            -0.179857\n",
      "GaussianMLPPolicy/dLoss                  0.00304919\n",
      "GaussianMLPValueFunction/LossAfter       1.17642\n",
      "GaussianMLPValueFunction/LossBefore      1.30187\n",
      "GaussianMLPValueFunction/dLoss           0.125453\n",
      "TotalEnvSteps                        35964\n",
      "-----------------------------------  --------------\n",
      "tensor([ 1.1891e-01, -8.5470e-03,  2.3173e-06,  ..., -2.1956e-01,\n",
      "         1.1714e-01,  5.4088e-01])\n",
      "2022-08-24 15:55:50 | [trpo_pendulum] epoch #18 | Saving snapshot...\n",
      "2022-08-24 15:55:50 | [trpo_pendulum] epoch #18 | Saved\n",
      "2022-08-24 15:55:50 | [trpo_pendulum] epoch #18 | Time 17.40 s\n",
      "2022-08-24 15:55:50 | [trpo_pendulum] epoch #18 | EpochTime 0.91 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -3.27204\n",
      "Evaluation/AverageReturn               -31.9843\n",
      "Evaluation/Iteration                    18\n",
      "Evaluation/MaxReturn                   -30.475\n",
      "Evaluation/MinReturn                   -33.4936\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     1.50929\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.744723\n",
      "GaussianMLPPolicy/KL                     0.00738023\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.044249\n",
      "GaussianMLPPolicy/LossBefore             0.0481561\n",
      "GaussianMLPPolicy/dLoss                  0.00390708\n",
      "GaussianMLPValueFunction/LossAfter       1.18511\n",
      "GaussianMLPValueFunction/LossBefore      1.20653\n",
      "GaussianMLPValueFunction/dLoss           0.0214188\n",
      "TotalEnvSteps                        37962\n",
      "-----------------------------------  --------------\n",
      "tensor([ 1.0417e-01, -3.3514e-03, -1.1680e-06,  ..., -3.9159e-02,\n",
      "         4.0555e-02,  2.3832e-01])\n",
      "2022-08-24 15:55:51 | [trpo_pendulum] epoch #19 | Saving snapshot...\n",
      "2022-08-24 15:55:51 | [trpo_pendulum] epoch #19 | Saved\n",
      "2022-08-24 15:55:51 | [trpo_pendulum] epoch #19 | Time 18.34 s\n",
      "2022-08-24 15:55:51 | [trpo_pendulum] epoch #19 | EpochTime 0.93 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -2.76385\n",
      "Evaluation/AverageReturn               -26.4481\n",
      "Evaluation/Iteration                    19\n",
      "Evaluation/MaxReturn                   -25.8549\n",
      "Evaluation/MinReturn                   -27.0413\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.593194\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.739182\n",
      "GaussianMLPPolicy/KL                     0.00185429\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.172027\n",
      "GaussianMLPPolicy/LossBefore            -0.172007\n",
      "GaussianMLPPolicy/dLoss                  2.01017e-05\n",
      "GaussianMLPValueFunction/LossAfter       1.10579\n",
      "GaussianMLPValueFunction/LossBefore      1.24655\n",
      "GaussianMLPValueFunction/dLoss           0.14076\n",
      "TotalEnvSteps                        39960\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 1.2173e-01, -4.0690e-05,  9.5990e-09,  ...,  5.0590e-03,\n",
      "        -3.4694e-03, -2.2391e-02])\n",
      "2022-08-24 15:55:52 | [trpo_pendulum] epoch #20 | Saving snapshot...\n",
      "2022-08-24 15:55:52 | [trpo_pendulum] epoch #20 | Saved\n",
      "2022-08-24 15:55:52 | [trpo_pendulum] epoch #20 | Time 19.29 s\n",
      "2022-08-24 15:55:52 | [trpo_pendulum] epoch #20 | EpochTime 0.94 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -2.60176\n",
      "Evaluation/AverageReturn               -25.7703\n",
      "Evaluation/Iteration                    20\n",
      "Evaluation/MaxReturn                   -25.7468\n",
      "Evaluation/MinReturn                   -25.7938\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.023485\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.713663\n",
      "GaussianMLPPolicy/KL                     0.00424916\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0212729\n",
      "GaussianMLPPolicy/LossBefore            -0.019805\n",
      "GaussianMLPPolicy/dLoss                  0.00146792\n",
      "GaussianMLPValueFunction/LossAfter       1.0726\n",
      "GaussianMLPValueFunction/LossBefore      1.10102\n",
      "GaussianMLPValueFunction/dLoss           0.0284197\n",
      "TotalEnvSteps                        41958\n",
      "-----------------------------------  --------------\n",
      "tensor([ 9.5001e-02, -3.6946e-04,  8.4046e-08,  ..., -1.7583e-02,\n",
      "         2.0920e-02,  1.3526e-01])\n",
      "2022-08-24 15:55:52 | [trpo_pendulum] epoch #21 | Saving snapshot...\n",
      "2022-08-24 15:55:52 | [trpo_pendulum] epoch #21 | Saved\n",
      "2022-08-24 15:55:52 | [trpo_pendulum] epoch #21 | Time 20.21 s\n",
      "2022-08-24 15:55:52 | [trpo_pendulum] epoch #21 | EpochTime 0.91 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -2.95554\n",
      "Evaluation/AverageReturn               -27.7174\n",
      "Evaluation/Iteration                    21\n",
      "Evaluation/MaxReturn                   -26.7628\n",
      "Evaluation/MinReturn                   -28.6721\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.954682\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.684746\n",
      "GaussianMLPPolicy/KL                     0.00978631\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.064377\n",
      "GaussianMLPPolicy/LossBefore             0.065741\n",
      "GaussianMLPPolicy/dLoss                  0.00136397\n",
      "GaussianMLPValueFunction/LossAfter       1.0141\n",
      "GaussianMLPValueFunction/LossBefore      1.05944\n",
      "GaussianMLPValueFunction/dLoss           0.0453339\n",
      "TotalEnvSteps                        43956\n",
      "-----------------------------------  --------------\n",
      "tensor([ 8.1596e-02, -2.2858e-02, -3.8981e-07,  ..., -3.0670e-01,\n",
      "         1.2928e-01,  1.4735e+00])\n",
      "2022-08-24 15:55:53 | [trpo_pendulum] epoch #22 | Saving snapshot...\n",
      "2022-08-24 15:55:53 | [trpo_pendulum] epoch #22 | Saved\n",
      "2022-08-24 15:55:53 | [trpo_pendulum] epoch #22 | Time 21.19 s\n",
      "2022-08-24 15:55:53 | [trpo_pendulum] epoch #22 | EpochTime 0.97 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -2.67099\n",
      "Evaluation/AverageReturn               -26.4796\n",
      "Evaluation/Iteration                    22\n",
      "Evaluation/MaxReturn                   -25.7122\n",
      "Evaluation/MinReturn                   -27.2471\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.767445\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.640697\n",
      "GaussianMLPPolicy/KL                     0.00970293\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0324682\n",
      "GaussianMLPPolicy/LossBefore            -0.0293682\n",
      "GaussianMLPPolicy/dLoss                  0.00310006\n",
      "GaussianMLPValueFunction/LossAfter       0.988068\n",
      "GaussianMLPValueFunction/LossBefore      1.0234\n",
      "GaussianMLPValueFunction/dLoss           0.035329\n",
      "TotalEnvSteps                        45954\n",
      "-----------------------------------  --------------\n",
      "tensor([ 1.0101e-01, -1.3136e-01,  1.9358e-05,  ..., -3.3788e-01,\n",
      "        -3.5182e-01,  2.4661e+00])\n",
      "2022-08-24 15:55:54 | [trpo_pendulum] epoch #23 | Saving snapshot...\n",
      "2022-08-24 15:55:54 | [trpo_pendulum] epoch #23 | Saved\n",
      "2022-08-24 15:55:54 | [trpo_pendulum] epoch #23 | Time 22.10 s\n",
      "2022-08-24 15:55:54 | [trpo_pendulum] epoch #23 | EpochTime 0.91 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -2.46552\n",
      "Evaluation/AverageReturn               -24.7437\n",
      "Evaluation/Iteration                    23\n",
      "Evaluation/MaxReturn                   -24.2459\n",
      "Evaluation/MinReturn                   -25.2415\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.497768\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.566549\n",
      "GaussianMLPPolicy/KL                     0.00889963\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0486764\n",
      "GaussianMLPPolicy/LossBefore            -0.0461342\n",
      "GaussianMLPPolicy/dLoss                  0.0025422\n",
      "GaussianMLPValueFunction/LossAfter       0.934834\n",
      "GaussianMLPValueFunction/LossBefore      0.980783\n",
      "GaussianMLPValueFunction/dLoss           0.0459488\n",
      "TotalEnvSteps                        47952\n",
      "-----------------------------------  --------------\n",
      "tensor([ 3.9824e-02, -2.8792e-01,  1.0778e-04,  ..., -6.8493e-01,\n",
      "        -8.8542e-01,  4.5436e+00])\n",
      "2022-08-24 15:55:55 | [trpo_pendulum] epoch #24 | Saving snapshot...\n",
      "2022-08-24 15:55:55 | [trpo_pendulum] epoch #24 | Saved\n",
      "2022-08-24 15:55:55 | [trpo_pendulum] epoch #24 | Time 23.01 s\n",
      "2022-08-24 15:55:55 | [trpo_pendulum] epoch #24 | EpochTime 0.90 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -2.27466\n",
      "Evaluation/AverageReturn               -22.2058\n",
      "Evaluation/Iteration                    24\n",
      "Evaluation/MaxReturn                   -21.5596\n",
      "Evaluation/MinReturn                   -22.852\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.646186\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.534686\n",
      "GaussianMLPPolicy/KL                     0.00688018\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0636855\n",
      "GaussianMLPPolicy/LossBefore            -0.0630596\n",
      "GaussianMLPPolicy/dLoss                  0.000625916\n",
      "GaussianMLPValueFunction/LossAfter       0.84243\n",
      "GaussianMLPValueFunction/LossBefore      0.91048\n",
      "GaussianMLPValueFunction/dLoss           0.06805\n",
      "TotalEnvSteps                        49950\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 9.1556e-02, -3.2873e-01,  4.1073e-05,  ..., -1.2402e+00,\n",
      "        -1.7579e+00,  4.9608e+00])\n",
      "2022-08-24 15:55:56 | [trpo_pendulum] epoch #25 | Saving snapshot...\n",
      "2022-08-24 15:55:56 | [trpo_pendulum] epoch #25 | Saved\n",
      "2022-08-24 15:55:56 | [trpo_pendulum] epoch #25 | Time 23.95 s\n",
      "2022-08-24 15:55:56 | [trpo_pendulum] epoch #25 | EpochTime 0.94 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -2.07305\n",
      "Evaluation/AverageReturn               -21.8948\n",
      "Evaluation/Iteration                    25\n",
      "Evaluation/MaxReturn                   -20.1918\n",
      "Evaluation/MinReturn                   -23.5977\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     1.70297\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.525694\n",
      "GaussianMLPPolicy/KL                     0.00145737\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.000249431\n",
      "GaussianMLPPolicy/LossBefore             0.000526089\n",
      "GaussianMLPPolicy/dLoss                  0.000276657\n",
      "GaussianMLPValueFunction/LossAfter       0.899142\n",
      "GaussianMLPValueFunction/LossBefore      0.921765\n",
      "GaussianMLPValueFunction/dLoss           0.0226229\n",
      "TotalEnvSteps                        51948\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 6.2013e-02, -9.1607e-02,  5.3714e-06,  ..., -3.9143e-01,\n",
      "        -5.2539e-01,  1.4964e+00])\n",
      "2022-08-24 15:55:57 | [trpo_pendulum] epoch #26 | Saving snapshot...\n",
      "2022-08-24 15:55:57 | [trpo_pendulum] epoch #26 | Saved\n",
      "2022-08-24 15:55:57 | [trpo_pendulum] epoch #26 | Time 24.88 s\n",
      "2022-08-24 15:55:57 | [trpo_pendulum] epoch #26 | EpochTime 0.93 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -2.09953\n",
      "Evaluation/AverageReturn               -21.7262\n",
      "Evaluation/Iteration                    26\n",
      "Evaluation/MaxReturn                   -21.4521\n",
      "Evaluation/MinReturn                   -22.0003\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.274088\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.492368\n",
      "GaussianMLPPolicy/KL                     0.00444625\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0126248\n",
      "GaussianMLPPolicy/LossBefore            -0.0111882\n",
      "GaussianMLPPolicy/dLoss                  0.00143662\n",
      "GaussianMLPValueFunction/LossAfter       0.776975\n",
      "GaussianMLPValueFunction/LossBefore      0.816316\n",
      "GaussianMLPValueFunction/dLoss           0.0393405\n",
      "TotalEnvSteps                        53946\n",
      "-----------------------------------  --------------\n",
      "tensor([ 4.5435e-02, -1.0770e+00,  1.3506e-04,  ..., -2.3388e+00,\n",
      "        -6.2969e+00,  1.0747e+01])\n",
      "2022-08-24 15:55:58 | [trpo_pendulum] epoch #27 | Saving snapshot...\n",
      "2022-08-24 15:55:58 | [trpo_pendulum] epoch #27 | Saved\n",
      "2022-08-24 15:55:58 | [trpo_pendulum] epoch #27 | Time 25.79 s\n",
      "2022-08-24 15:55:58 | [trpo_pendulum] epoch #27 | EpochTime 0.90 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -2.09063\n",
      "Evaluation/AverageReturn               -21.7714\n",
      "Evaluation/Iteration                    27\n",
      "Evaluation/MaxReturn                   -21.7203\n",
      "Evaluation/MinReturn                   -21.8224\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.0510408\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.458717\n",
      "GaussianMLPPolicy/KL                     0.00388565\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.0124168\n",
      "GaussianMLPPolicy/LossBefore             0.0126594\n",
      "GaussianMLPPolicy/dLoss                  0.000242569\n",
      "GaussianMLPValueFunction/LossAfter       0.864077\n",
      "GaussianMLPValueFunction/LossBefore      0.877914\n",
      "GaussianMLPValueFunction/dLoss           0.0138365\n",
      "TotalEnvSteps                        55944\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 7.6232e-02, -7.4730e-01,  4.7407e-05,  ..., -1.8246e+00,\n",
      "        -5.1534e+00,  8.1761e+00])\n",
      "2022-08-24 15:55:59 | [trpo_pendulum] epoch #28 | Saving snapshot...\n",
      "2022-08-24 15:55:59 | [trpo_pendulum] epoch #28 | Saved\n",
      "2022-08-24 15:55:59 | [trpo_pendulum] epoch #28 | Time 26.69 s\n",
      "2022-08-24 15:55:59 | [trpo_pendulum] epoch #28 | EpochTime 0.90 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -1.77964\n",
      "Evaluation/AverageReturn               -20.101\n",
      "Evaluation/Iteration                    28\n",
      "Evaluation/MaxReturn                   -19.8788\n",
      "Evaluation/MinReturn                   -20.3232\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.222193\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.386242\n",
      "GaussianMLPPolicy/KL                     0.00862227\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0646979\n",
      "GaussianMLPPolicy/LossBefore            -0.0606431\n",
      "GaussianMLPPolicy/dLoss                  0.00405472\n",
      "GaussianMLPValueFunction/LossAfter       0.754263\n",
      "GaussianMLPValueFunction/LossBefore      0.80887\n",
      "GaussianMLPValueFunction/dLoss           0.054607\n",
      "TotalEnvSteps                        57942\n",
      "-----------------------------------  --------------\n",
      "tensor([ 7.4390e-02, -5.3760e-01,  2.3802e-05,  ..., -1.0177e+00,\n",
      "        -4.1405e+00,  5.4021e+00])\n",
      "2022-08-24 15:56:00 | [trpo_pendulum] epoch #29 | Saving snapshot...\n",
      "2022-08-24 15:56:00 | [trpo_pendulum] epoch #29 | Saved\n",
      "2022-08-24 15:56:00 | [trpo_pendulum] epoch #29 | Time 27.58 s\n",
      "2022-08-24 15:56:00 | [trpo_pendulum] epoch #29 | EpochTime 0.88 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -1.78725\n",
      "Evaluation/AverageReturn               -17.2409\n",
      "Evaluation/Iteration                    29\n",
      "Evaluation/MaxReturn                   -16.4625\n",
      "Evaluation/MinReturn                   -18.0193\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.778379\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.322439\n",
      "GaussianMLPPolicy/KL                     0.00627808\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0832907\n",
      "GaussianMLPPolicy/LossBefore            -0.0802481\n",
      "GaussianMLPPolicy/dLoss                  0.00304262\n",
      "GaussianMLPValueFunction/LossAfter       0.620049\n",
      "GaussianMLPValueFunction/LossBefore      0.731297\n",
      "GaussianMLPValueFunction/dLoss           0.111248\n",
      "TotalEnvSteps                        59940\n",
      "-----------------------------------  --------------\n",
      "tensor([ 4.5652e-02, -1.5418e+00, -1.3512e-04,  ..., -1.8901e+00,\n",
      "        -8.6116e+00,  1.1256e+01])\n",
      "2022-08-24 15:56:01 | [trpo_pendulum] epoch #30 | Saving snapshot...\n",
      "2022-08-24 15:56:01 | [trpo_pendulum] epoch #30 | Saved\n",
      "2022-08-24 15:56:01 | [trpo_pendulum] epoch #30 | Time 28.50 s\n",
      "2022-08-24 15:56:01 | [trpo_pendulum] epoch #30 | EpochTime 0.92 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -1.70636\n",
      "Evaluation/AverageReturn               -16.5061\n",
      "Evaluation/Iteration                    30\n",
      "Evaluation/MaxReturn                   -16.3312\n",
      "Evaluation/MinReturn                   -16.6811\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.174937\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.320093\n",
      "GaussianMLPPolicy/KL                     1.51589e-05\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0279442\n",
      "GaussianMLPPolicy/LossBefore            -0.0279265\n",
      "GaussianMLPPolicy/dLoss                  1.76057e-05\n",
      "GaussianMLPValueFunction/LossAfter       0.543767\n",
      "GaussianMLPValueFunction/LossBefore      0.600927\n",
      "GaussianMLPValueFunction/dLoss           0.0571596\n",
      "TotalEnvSteps                        61938\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 6.2858e-02, -1.1502e+00,  3.0522e-04,  ..., -1.3634e+00,\n",
      "        -6.5947e+00,  8.5412e+00])\n",
      "2022-08-24 15:56:02 | [trpo_pendulum] epoch #31 | Saving snapshot...\n",
      "2022-08-24 15:56:02 | [trpo_pendulum] epoch #31 | Saved\n",
      "2022-08-24 15:56:02 | [trpo_pendulum] epoch #31 | Time 29.41 s\n",
      "2022-08-24 15:56:02 | [trpo_pendulum] epoch #31 | EpochTime 0.91 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -1.5897\n",
      "Evaluation/AverageReturn               -16.3709\n",
      "Evaluation/Iteration                    31\n",
      "Evaluation/MaxReturn                   -15.9734\n",
      "Evaluation/MinReturn                   -16.7683\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.397492\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.281533\n",
      "GaussianMLPPolicy/KL                     0.00614528\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.00158915\n",
      "GaussianMLPPolicy/LossBefore             0.00161942\n",
      "GaussianMLPPolicy/dLoss                  3.02651e-05\n",
      "GaussianMLPValueFunction/LossAfter       0.515973\n",
      "GaussianMLPValueFunction/LossBefore      0.549535\n",
      "GaussianMLPValueFunction/dLoss           0.0335618\n",
      "TotalEnvSteps                        63936\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 2.7689e-02, -1.7899e+00,  5.7861e-04,  ..., -3.1731e+00,\n",
      "        -1.0677e+01,  1.4711e+01])\n",
      "2022-08-24 15:56:03 | [trpo_pendulum] epoch #32 | Saving snapshot...\n",
      "2022-08-24 15:56:03 | [trpo_pendulum] epoch #32 | Saved\n",
      "2022-08-24 15:56:03 | [trpo_pendulum] epoch #32 | Time 30.32 s\n",
      "2022-08-24 15:56:03 | [trpo_pendulum] epoch #32 | EpochTime 0.90 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -1.75449\n",
      "Evaluation/AverageReturn               -17.1678\n",
      "Evaluation/Iteration                    32\n",
      "Evaluation/MaxReturn                   -16.8024\n",
      "Evaluation/MinReturn                   -17.5333\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.365418\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.265958\n",
      "GaussianMLPPolicy/KL                     0.00779394\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.0253374\n",
      "GaussianMLPPolicy/LossBefore             0.0283171\n",
      "GaussianMLPPolicy/dLoss                  0.00297965\n",
      "GaussianMLPValueFunction/LossAfter       0.492232\n",
      "GaussianMLPValueFunction/LossBefore      0.526239\n",
      "GaussianMLPValueFunction/dLoss           0.0340073\n",
      "TotalEnvSteps                        65934\n",
      "-----------------------------------  --------------\n",
      "tensor([ 3.1255e-02, -1.0635e+00, -1.9881e-04,  ..., -1.7129e+00,\n",
      "        -5.5602e+00,  7.7911e+00])\n",
      "2022-08-24 15:56:03 | [trpo_pendulum] epoch #33 | Saving snapshot...\n",
      "2022-08-24 15:56:03 | [trpo_pendulum] epoch #33 | Saved\n",
      "2022-08-24 15:56:03 | [trpo_pendulum] epoch #33 | Time 31.23 s\n",
      "2022-08-24 15:56:03 | [trpo_pendulum] epoch #33 | EpochTime 0.91 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -1.36247\n",
      "Evaluation/AverageReturn               -14.5719\n",
      "Evaluation/Iteration                    33\n",
      "Evaluation/MaxReturn                   -14.146\n",
      "Evaluation/MinReturn                   -14.9978\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.425888\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.245105\n",
      "GaussianMLPPolicy/KL                     0.00584641\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0719841\n",
      "GaussianMLPPolicy/LossBefore            -0.070727\n",
      "GaussianMLPPolicy/dLoss                  0.00125703\n",
      "GaussianMLPValueFunction/LossAfter       0.366054\n",
      "GaussianMLPValueFunction/LossBefore      0.494388\n",
      "GaussianMLPValueFunction/dLoss           0.128335\n",
      "TotalEnvSteps                        67932\n",
      "-----------------------------------  --------------\n",
      "tensor([ 4.3071e-02, -2.4587e+00, -3.2134e-04,  ..., -4.0256e+00,\n",
      "        -1.3201e+01,  1.8512e+01])\n",
      "2022-08-24 15:56:04 | [trpo_pendulum] epoch #34 | Saving snapshot...\n",
      "2022-08-24 15:56:04 | [trpo_pendulum] epoch #34 | Saved\n",
      "2022-08-24 15:56:04 | [trpo_pendulum] epoch #34 | Time 32.13 s\n",
      "2022-08-24 15:56:04 | [trpo_pendulum] epoch #34 | EpochTime 0.89 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -1.19602\n",
      "Evaluation/AverageReturn               -12.4139\n",
      "Evaluation/Iteration                    34\n",
      "Evaluation/MaxReturn                   -11.5572\n",
      "Evaluation/MinReturn                   -13.2705\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.856603\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.215788\n",
      "GaussianMLPPolicy/KL                     0.00687265\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0717383\n",
      "GaussianMLPPolicy/LossBefore            -0.0689958\n",
      "GaussianMLPPolicy/dLoss                  0.00274254\n",
      "GaussianMLPValueFunction/LossAfter       0.319491\n",
      "GaussianMLPValueFunction/LossBefore      0.455933\n",
      "GaussianMLPValueFunction/dLoss           0.136442\n",
      "TotalEnvSteps                        69930\n",
      "-----------------------------------  --------------\n",
      "tensor([ 2.9654e-02, -1.6244e+00,  2.0990e-04,  ..., -2.8039e+00,\n",
      "        -9.6391e+00,  1.3027e+01])\n",
      "2022-08-24 15:56:05 | [trpo_pendulum] epoch #35 | Saving snapshot...\n",
      "2022-08-24 15:56:05 | [trpo_pendulum] epoch #35 | Saved\n",
      "2022-08-24 15:56:05 | [trpo_pendulum] epoch #35 | Time 33.05 s\n",
      "2022-08-24 15:56:05 | [trpo_pendulum] epoch #35 | EpochTime 0.91 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -1.16708\n",
      "Evaluation/AverageReturn               -10.6674\n",
      "Evaluation/Iteration                    35\n",
      "Evaluation/MaxReturn                   -10.5723\n",
      "Evaluation/MinReturn                   -10.7625\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.0950865\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.180702\n",
      "GaussianMLPPolicy/KL                     0.00914304\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0602979\n",
      "GaussianMLPPolicy/LossBefore            -0.0579957\n",
      "GaussianMLPPolicy/dLoss                  0.00230213\n",
      "GaussianMLPValueFunction/LossAfter       0.166903\n",
      "GaussianMLPValueFunction/LossBefore      0.30925\n",
      "GaussianMLPValueFunction/dLoss           0.142346\n",
      "TotalEnvSteps                        71928\n",
      "-----------------------------------  --------------\n",
      "tensor([ 4.3242e-02, -8.2360e-01,  2.2104e-04,  ..., -1.3218e+00,\n",
      "        -4.3990e+00,  5.9958e+00])\n",
      "2022-08-24 15:56:06 | [trpo_pendulum] epoch #36 | Saving snapshot...\n",
      "2022-08-24 15:56:06 | [trpo_pendulum] epoch #36 | Saved\n",
      "2022-08-24 15:56:06 | [trpo_pendulum] epoch #36 | Time 33.93 s\n",
      "2022-08-24 15:56:06 | [trpo_pendulum] epoch #36 | EpochTime 0.88 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -0.887537\n",
      "Evaluation/AverageReturn                -9.59777\n",
      "Evaluation/Iteration                    36\n",
      "Evaluation/MaxReturn                    -9.16762\n",
      "Evaluation/MinReturn                   -10.0279\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.430154\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.145578\n",
      "GaussianMLPPolicy/KL                     0.00427246\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0334188\n",
      "GaussianMLPPolicy/LossBefore            -0.0330761\n",
      "GaussianMLPPolicy/dLoss                  0.000342675\n",
      "GaussianMLPValueFunction/LossAfter       0.055553\n",
      "GaussianMLPValueFunction/LossBefore      0.146129\n",
      "GaussianMLPValueFunction/dLoss           0.090576\n",
      "TotalEnvSteps                        73926\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 3.8446e-02, -6.9735e-01, -2.0187e-04,  ..., -1.3863e+00,\n",
      "        -5.0143e+00,  6.4930e+00])\n",
      "2022-08-24 15:56:07 | [trpo_pendulum] epoch #37 | Saving snapshot...\n",
      "2022-08-24 15:56:07 | [trpo_pendulum] epoch #37 | Saved\n",
      "2022-08-24 15:56:07 | [trpo_pendulum] epoch #37 | Time 34.84 s\n",
      "2022-08-24 15:56:07 | [trpo_pendulum] epoch #37 | EpochTime 0.91 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -0.805021\n",
      "Evaluation/AverageReturn                -8.82595\n",
      "Evaluation/Iteration                    37\n",
      "Evaluation/MaxReturn                    -8.09658\n",
      "Evaluation/MinReturn                    -9.55532\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.729372\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.122784\n",
      "GaussianMLPPolicy/KL                     0.00183716\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0199571\n",
      "GaussianMLPPolicy/LossBefore            -0.0194396\n",
      "GaussianMLPPolicy/dLoss                  0.000517417\n",
      "GaussianMLPValueFunction/LossAfter       0.0118234\n",
      "GaussianMLPValueFunction/LossBefore      0.067567\n",
      "GaussianMLPValueFunction/dLoss           0.0557436\n",
      "TotalEnvSteps                        75924\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 2.4905e-02, -2.8696e-01, -4.9874e-06,  ..., -9.1570e-01,\n",
      "        -3.9268e+00,  4.5828e+00])\n",
      "2022-08-24 15:56:08 | [trpo_pendulum] epoch #38 | Saving snapshot...\n",
      "2022-08-24 15:56:08 | [trpo_pendulum] epoch #38 | Saved\n",
      "2022-08-24 15:56:08 | [trpo_pendulum] epoch #38 | Time 35.76 s\n",
      "2022-08-24 15:56:08 | [trpo_pendulum] epoch #38 | EpochTime 0.91 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -0.837922\n",
      "Evaluation/AverageReturn                -8.76466\n",
      "Evaluation/Iteration                    38\n",
      "Evaluation/MaxReturn                    -8.59482\n",
      "Evaluation/MinReturn                    -8.93449\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.169833\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.0869958\n",
      "GaussianMLPPolicy/KL                     0.00249981\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0130246\n",
      "GaussianMLPPolicy/LossBefore            -0.0129065\n",
      "GaussianMLPPolicy/dLoss                  0.000118083\n",
      "GaussianMLPValueFunction/LossAfter      -0.108016\n",
      "GaussianMLPValueFunction/LossBefore     -0.046963\n",
      "GaussianMLPValueFunction/dLoss           0.0610531\n",
      "TotalEnvSteps                        77922\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 3.1485e-02, -1.0172e+00,  1.6355e-05,  ..., -2.9329e+00,\n",
      "        -9.7349e+00,  1.2446e+01])\n",
      "2022-08-24 15:56:09 | [trpo_pendulum] epoch #39 | Saving snapshot...\n",
      "2022-08-24 15:56:09 | [trpo_pendulum] epoch #39 | Saved\n",
      "2022-08-24 15:56:09 | [trpo_pendulum] epoch #39 | Time 36.68 s\n",
      "2022-08-24 15:56:09 | [trpo_pendulum] epoch #39 | EpochTime 0.91 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -0.755925\n",
      "Evaluation/AverageReturn                -8.73482\n",
      "Evaluation/Iteration                    39\n",
      "Evaluation/MaxReturn                    -7.95338\n",
      "Evaluation/MinReturn                    -9.51627\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.781448\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy                0.0544087\n",
      "GaussianMLPPolicy/KL                     0.00575796\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.00478894\n",
      "GaussianMLPPolicy/LossBefore             0.00639196\n",
      "GaussianMLPPolicy/dLoss                  0.00160302\n",
      "GaussianMLPValueFunction/LossAfter      -0.0913715\n",
      "GaussianMLPValueFunction/LossBefore     -0.0575126\n",
      "GaussianMLPValueFunction/dLoss           0.033859\n",
      "TotalEnvSteps                        79920\n",
      "-----------------------------------  --------------\n",
      "tensor([ 3.5537e-02, -2.6069e-01, -4.3913e-05,  ..., -1.1455e+00,\n",
      "        -3.3388e+00,  4.2330e+00])\n",
      "2022-08-24 15:56:10 | [trpo_pendulum] epoch #40 | Saving snapshot...\n",
      "2022-08-24 15:56:10 | [trpo_pendulum] epoch #40 | Saved\n",
      "2022-08-24 15:56:10 | [trpo_pendulum] epoch #40 | Time 37.59 s\n",
      "2022-08-24 15:56:10 | [trpo_pendulum] epoch #40 | EpochTime 0.91 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -0.785539\n",
      "Evaluation/AverageReturn                -7.83703\n",
      "Evaluation/Iteration                    40\n",
      "Evaluation/MaxReturn                    -7.15981\n",
      "Evaluation/MinReturn                    -8.51426\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.677225\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy               -0.0156043\n",
      "GaussianMLPPolicy/KL                     0.00663609\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0278494\n",
      "GaussianMLPPolicy/LossBefore            -0.0267733\n",
      "GaussianMLPPolicy/dLoss                  0.00107605\n",
      "GaussianMLPValueFunction/LossAfter      -0.135482\n",
      "GaussianMLPValueFunction/LossBefore     -0.0669378\n",
      "GaussianMLPValueFunction/dLoss           0.0685441\n",
      "TotalEnvSteps                        81918\n",
      "-----------------------------------  --------------\n",
      "tensor([ 2.9232e-02, -2.5469e-01, -5.6174e-05,  ..., -1.9074e+00,\n",
      "        -5.9055e+00,  7.2395e+00])\n",
      "2022-08-24 15:56:11 | [trpo_pendulum] epoch #41 | Saving snapshot...\n",
      "2022-08-24 15:56:11 | [trpo_pendulum] epoch #41 | Saved\n",
      "2022-08-24 15:56:11 | [trpo_pendulum] epoch #41 | Time 38.50 s\n",
      "2022-08-24 15:56:11 | [trpo_pendulum] epoch #41 | EpochTime 0.90 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -0.742306\n",
      "Evaluation/AverageReturn                -7.28643\n",
      "Evaluation/Iteration                    41\n",
      "Evaluation/MaxReturn                    -7.25085\n",
      "Evaluation/MinReturn                    -7.32201\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.0355787\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy               -0.032532\n",
      "GaussianMLPPolicy/KL                     0.00134377\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0217335\n",
      "GaussianMLPPolicy/LossBefore            -0.0216699\n",
      "GaussianMLPPolicy/dLoss                  6.36e-05\n",
      "GaussianMLPValueFunction/LossAfter      -0.307264\n",
      "GaussianMLPValueFunction/LossBefore     -0.220709\n",
      "GaussianMLPValueFunction/dLoss           0.0865548\n",
      "TotalEnvSteps                        83916\n",
      "-----------------------------------  --------------\n",
      "tensor([ 2.8856e-02, -6.3497e-01, -2.9456e-05,  ..., -3.9211e+00,\n",
      "        -1.1372e+01,  1.4296e+01])\n",
      "2022-08-24 15:56:12 | [trpo_pendulum] epoch #42 | Saving snapshot...\n",
      "2022-08-24 15:56:12 | [trpo_pendulum] epoch #42 | Saved\n",
      "2022-08-24 15:56:12 | [trpo_pendulum] epoch #42 | Time 39.53 s\n",
      "2022-08-24 15:56:12 | [trpo_pendulum] epoch #42 | EpochTime 1.02 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -0.785308\n",
      "Evaluation/AverageReturn                -7.46758\n",
      "Evaluation/Iteration                    42\n",
      "Evaluation/MaxReturn                    -7.01006\n",
      "Evaluation/MinReturn                    -7.9251\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.457522\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy               -0.0355644\n",
      "GaussianMLPPolicy/KL                     0.000237819\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.00920135\n",
      "GaussianMLPPolicy/LossBefore             0.00929931\n",
      "GaussianMLPPolicy/dLoss                  9.7964e-05\n",
      "GaussianMLPValueFunction/LossAfter      -0.281295\n",
      "GaussianMLPValueFunction/LossBefore     -0.249612\n",
      "GaussianMLPValueFunction/dLoss           0.0316825\n",
      "TotalEnvSteps                        85914\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 2.1050e-02, -8.1601e-02, -3.8432e-07,  ..., -5.0075e-01,\n",
      "        -1.4556e+00,  1.7561e+00])\n",
      "2022-08-24 15:56:13 | [trpo_pendulum] epoch #43 | Saving snapshot...\n",
      "2022-08-24 15:56:13 | [trpo_pendulum] epoch #43 | Saved\n",
      "2022-08-24 15:56:13 | [trpo_pendulum] epoch #43 | Time 40.42 s\n",
      "2022-08-24 15:56:13 | [trpo_pendulum] epoch #43 | EpochTime 0.89 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -0.590448\n",
      "Evaluation/AverageReturn                -6.57215\n",
      "Evaluation/Iteration                    43\n",
      "Evaluation/MaxReturn                    -6.50025\n",
      "Evaluation/MinReturn                    -6.64404\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.0718958\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy               -0.0428181\n",
      "GaussianMLPPolicy/KL                     0.00455718\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0201903\n",
      "GaussianMLPPolicy/LossBefore            -0.0201862\n",
      "GaussianMLPPolicy/dLoss                  4.07547e-06\n",
      "GaussianMLPValueFunction/LossAfter      -0.467182\n",
      "GaussianMLPValueFunction/LossBefore     -0.378577\n",
      "GaussianMLPValueFunction/dLoss           0.088605\n",
      "TotalEnvSteps                        87912\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 2.4428e-02, -6.0219e-01, -3.0612e-05,  ..., -4.1721e+00,\n",
      "        -1.0405e+01,  1.3541e+01])\n",
      "2022-08-24 15:56:14 | [trpo_pendulum] epoch #44 | Saving snapshot...\n",
      "2022-08-24 15:56:14 | [trpo_pendulum] epoch #44 | Saved\n",
      "2022-08-24 15:56:14 | [trpo_pendulum] epoch #44 | Time 41.36 s\n",
      "2022-08-24 15:56:14 | [trpo_pendulum] epoch #44 | EpochTime 0.93 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn      -0.76508\n",
      "Evaluation/AverageReturn                -7.82981\n",
      "Evaluation/Iteration                    44\n",
      "Evaluation/MaxReturn                    -7.62198\n",
      "Evaluation/MinReturn                    -8.03765\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.207836\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy               -0.0620941\n",
      "GaussianMLPPolicy/KL                     0.0097182\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.0358848\n",
      "GaussianMLPPolicy/LossBefore             0.0372525\n",
      "GaussianMLPPolicy/dLoss                  0.00136777\n",
      "GaussianMLPValueFunction/LossAfter      -0.392236\n",
      "GaussianMLPValueFunction/LossBefore     -0.242311\n",
      "GaussianMLPValueFunction/dLoss           0.149925\n",
      "TotalEnvSteps                        89910\n",
      "-----------------------------------  --------------\n",
      "tensor([ 1.8789e-02, -4.7781e-01, -3.1064e-05,  ..., -3.0558e+00,\n",
      "        -7.7718e+00,  1.0486e+01])\n",
      "2022-08-24 15:56:15 | [trpo_pendulum] epoch #45 | Saving snapshot...\n",
      "2022-08-24 15:56:15 | [trpo_pendulum] epoch #45 | Saved\n",
      "2022-08-24 15:56:15 | [trpo_pendulum] epoch #45 | Time 42.32 s\n",
      "2022-08-24 15:56:15 | [trpo_pendulum] epoch #45 | EpochTime 0.96 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -0.624573\n",
      "Evaluation/AverageReturn                -6.65471\n",
      "Evaluation/Iteration                    45\n",
      "Evaluation/MaxReturn                    -6.50256\n",
      "Evaluation/MinReturn                    -6.80687\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.152152\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy               -0.097824\n",
      "GaussianMLPPolicy/KL                     0.0058829\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.0329685\n",
      "GaussianMLPPolicy/LossBefore            -0.0321092\n",
      "GaussianMLPPolicy/dLoss                  0.000859275\n",
      "GaussianMLPValueFunction/LossAfter      -0.438279\n",
      "GaussianMLPValueFunction/LossBefore     -0.320713\n",
      "GaussianMLPValueFunction/dLoss           0.117566\n",
      "TotalEnvSteps                        91908\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 2.1525e-02, -3.5953e-01,  1.1146e-06,  ..., -1.9834e+00,\n",
      "        -5.6417e+00,  7.4773e+00])\n",
      "2022-08-24 15:56:15 | [trpo_pendulum] epoch #46 | Saving snapshot...\n",
      "2022-08-24 15:56:15 | [trpo_pendulum] epoch #46 | Saved\n",
      "2022-08-24 15:56:15 | [trpo_pendulum] epoch #46 | Time 43.26 s\n",
      "2022-08-24 15:56:15 | [trpo_pendulum] epoch #46 | EpochTime 0.93 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -0.60448\n",
      "Evaluation/AverageReturn                -6.01873\n",
      "Evaluation/Iteration                    46\n",
      "Evaluation/MaxReturn                    -5.72156\n",
      "Evaluation/MinReturn                    -6.31591\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.297173\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy               -0.14179\n",
      "GaussianMLPPolicy/KL                     0.00766011\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.00883002\n",
      "GaussianMLPPolicy/LossBefore            -0.00876943\n",
      "GaussianMLPPolicy/dLoss                  6.05844e-05\n",
      "GaussianMLPValueFunction/LossAfter      -0.551229\n",
      "GaussianMLPValueFunction/LossBefore     -0.50951\n",
      "GaussianMLPValueFunction/dLoss           0.0417189\n",
      "TotalEnvSteps                        93906\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 1.7555e-02, -7.1678e-01, -2.2948e-04,  ..., -4.2092e+00,\n",
      "        -1.3207e+01,  1.6392e+01])\n",
      "2022-08-24 15:56:16 | [trpo_pendulum] epoch #47 | Saving snapshot...\n",
      "2022-08-24 15:56:16 | [trpo_pendulum] epoch #47 | Saved\n",
      "2022-08-24 15:56:16 | [trpo_pendulum] epoch #47 | Time 44.22 s\n",
      "2022-08-24 15:56:16 | [trpo_pendulum] epoch #47 | EpochTime 0.96 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -0.645231\n",
      "Evaluation/AverageReturn                -6.09065\n",
      "Evaluation/Iteration                    47\n",
      "Evaluation/MaxReturn                    -6.08856\n",
      "Evaluation/MinReturn                    -6.09275\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.00209458\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy               -0.149208\n",
      "GaussianMLPPolicy/KL                     0.000148527\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter              0.000186078\n",
      "GaussianMLPPolicy/LossBefore             0.000219629\n",
      "GaussianMLPPolicy/dLoss                  3.3551e-05\n",
      "GaussianMLPValueFunction/LossAfter      -0.471603\n",
      "GaussianMLPValueFunction/LossBefore     -0.478948\n",
      "GaussianMLPValueFunction/dLoss          -0.00734591\n",
      "TotalEnvSteps                        95904\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 2.8057e-02, -9.5001e-01, -1.3698e-04,  ..., -4.9991e+00,\n",
      "        -1.6368e+01,  1.9767e+01])\n",
      "2022-08-24 15:56:17 | [trpo_pendulum] epoch #48 | Saving snapshot...\n",
      "2022-08-24 15:56:17 | [trpo_pendulum] epoch #48 | Saved\n",
      "2022-08-24 15:56:17 | [trpo_pendulum] epoch #48 | Time 45.18 s\n",
      "2022-08-24 15:56:17 | [trpo_pendulum] epoch #48 | EpochTime 0.95 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -0.64847\n",
      "Evaluation/AverageReturn                -6.31439\n",
      "Evaluation/Iteration                    48\n",
      "Evaluation/MaxReturn                    -5.79755\n",
      "Evaluation/MinReturn                    -6.83123\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.516842\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy               -0.158198\n",
      "GaussianMLPPolicy/KL                     0.000219095\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.00227778\n",
      "GaussianMLPPolicy/LossBefore            -0.00223888\n",
      "GaussianMLPPolicy/dLoss                  3.89032e-05\n",
      "GaussianMLPValueFunction/LossAfter      -0.339379\n",
      "GaussianMLPValueFunction/LossBefore     -0.336144\n",
      "GaussianMLPValueFunction/dLoss           0.00323561\n",
      "TotalEnvSteps                        97902\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 1.5981e-02, -5.5348e-01,  6.9835e-05,  ..., -3.0958e+00,\n",
      "        -9.3014e+00,  1.1893e+01])\n",
      "2022-08-24 15:56:18 | [trpo_pendulum] epoch #49 | Saving snapshot...\n",
      "2022-08-24 15:56:18 | [trpo_pendulum] epoch #49 | Saved\n",
      "2022-08-24 15:56:18 | [trpo_pendulum] epoch #49 | Time 46.12 s\n",
      "2022-08-24 15:56:18 | [trpo_pendulum] epoch #49 | EpochTime 0.94 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn      -0.544998\n",
      "Evaluation/AverageReturn                -5.92949\n",
      "Evaluation/Iteration                    49\n",
      "Evaluation/MaxReturn                    -5.68943\n",
      "Evaluation/MinReturn                    -6.16956\n",
      "Evaluation/NumEpisodes                   2\n",
      "Evaluation/StdReturn                     0.240063\n",
      "Evaluation/TerminationRate               0\n",
      "GaussianMLPPolicy/Entropy               -0.163776\n",
      "GaussianMLPPolicy/KL                     0.00011594\n",
      "GaussianMLPPolicy/KLBefore               0\n",
      "GaussianMLPPolicy/LossAfter             -0.00829477\n",
      "GaussianMLPPolicy/LossBefore            -0.00828902\n",
      "GaussianMLPPolicy/dLoss                  5.74253e-06\n",
      "GaussianMLPValueFunction/LossAfter      -0.688003\n",
      "GaussianMLPValueFunction/LossBefore     -0.632928\n",
      "GaussianMLPValueFunction/dLoss           0.0550756\n",
      "TotalEnvSteps                        99900\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 2.1400e-02, -8.5677e-01, -1.1066e-04,  ..., -4.7815e+00,\n",
      "        -1.3568e+01,  1.7831e+01])\n",
      "2022-08-24 15:56:19 | [trpo_pendulum] epoch #50 | Saving snapshot...\n",
      "2022-08-24 15:56:19 | [trpo_pendulum] epoch #50 | Saved\n",
      "2022-08-24 15:56:19 | [trpo_pendulum] epoch #50 | Time 47.01 s\n",
      "2022-08-24 15:56:19 | [trpo_pendulum] epoch #50 | EpochTime 0.88 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.497545\n",
      "Evaluation/AverageReturn                 -5.78892\n",
      "Evaluation/Iteration                     50\n",
      "Evaluation/MaxReturn                     -5.59325\n",
      "Evaluation/MinReturn                     -5.9846\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.195677\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.237309\n",
      "GaussianMLPPolicy/KL                      0.00626512\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00133737\n",
      "GaussianMLPPolicy/LossBefore             -0.000765087\n",
      "GaussianMLPPolicy/dLoss                   0.000572285\n",
      "GaussianMLPValueFunction/LossAfter       -0.525442\n",
      "GaussianMLPValueFunction/LossBefore      -0.526802\n",
      "GaussianMLPValueFunction/dLoss           -0.00136042\n",
      "TotalEnvSteps                        101898\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 2.4240e-02, -5.2038e-01,  2.1187e-05,  ..., -4.2417e+00,\n",
      "        -1.1721e+01,  1.5507e+01])\n",
      "2022-08-24 15:56:20 | [trpo_pendulum] epoch #51 | Saving snapshot...\n",
      "2022-08-24 15:56:20 | [trpo_pendulum] epoch #51 | Saved\n",
      "2022-08-24 15:56:20 | [trpo_pendulum] epoch #51 | Time 47.94 s\n",
      "2022-08-24 15:56:20 | [trpo_pendulum] epoch #51 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.552371\n",
      "Evaluation/AverageReturn                 -5.62534\n",
      "Evaluation/Iteration                     51\n",
      "Evaluation/MaxReturn                     -5.35199\n",
      "Evaluation/MinReturn                     -5.8987\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.27336\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.319451\n",
      "GaussianMLPPolicy/KL                      0.0083277\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0127444\n",
      "GaussianMLPPolicy/LossBefore             -0.0119103\n",
      "GaussianMLPPolicy/dLoss                   0.000834092\n",
      "GaussianMLPValueFunction/LossAfter       -0.543955\n",
      "GaussianMLPValueFunction/LossBefore      -0.517116\n",
      "GaussianMLPValueFunction/dLoss            0.0268386\n",
      "TotalEnvSteps                        103896\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 9.1618e-03, -1.4814e+00, -9.9907e-05,  ..., -8.4505e+00,\n",
      "        -2.4143e+01,  3.0837e+01])\n",
      "2022-08-24 15:56:21 | [trpo_pendulum] epoch #52 | Line search condition violated. Rejecting the step!\n",
      "2022-08-24 15:56:21 | [trpo_pendulum] epoch #52 | Violated because loss not improving\n",
      "2022-08-24 15:56:21 | [trpo_pendulum] epoch #52 | Saving snapshot...\n",
      "2022-08-24 15:56:21 | [trpo_pendulum] epoch #52 | Saved\n",
      "2022-08-24 15:56:21 | [trpo_pendulum] epoch #52 | Time 48.87 s\n",
      "2022-08-24 15:56:21 | [trpo_pendulum] epoch #52 | EpochTime 0.93 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn       -0.434087\n",
      "Evaluation/AverageReturn                 -4.82782\n",
      "Evaluation/Iteration                     52\n",
      "Evaluation/MaxReturn                     -4.61448\n",
      "Evaluation/MinReturn                     -5.04116\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.213339\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.319451\n",
      "GaussianMLPPolicy/KL                      0\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0294871\n",
      "GaussianMLPPolicy/LossBefore             -0.0294871\n",
      "GaussianMLPPolicy/dLoss                   0\n",
      "GaussianMLPValueFunction/LossAfter       -0.723492\n",
      "GaussianMLPValueFunction/LossBefore      -0.541731\n",
      "GaussianMLPValueFunction/dLoss            0.181761\n",
      "TotalEnvSteps                        105894\n",
      "-----------------------------------  --------------\n",
      "tensor([ 9.9960e-03, -9.8596e-01,  1.1083e-04,  ..., -5.6218e+00,\n",
      "        -1.6068e+01,  2.0518e+01])\n",
      "2022-08-24 15:56:22 | [trpo_pendulum] epoch #53 | Saving snapshot...\n",
      "2022-08-24 15:56:22 | [trpo_pendulum] epoch #53 | Saved\n",
      "2022-08-24 15:56:22 | [trpo_pendulum] epoch #53 | Time 49.79 s\n",
      "2022-08-24 15:56:22 | [trpo_pendulum] epoch #53 | EpochTime 0.91 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.501725\n",
      "Evaluation/AverageReturn                 -4.86088\n",
      "Evaluation/Iteration                     53\n",
      "Evaluation/MaxReturn                     -4.8601\n",
      "Evaluation/MinReturn                     -4.86166\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000776021\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.337238\n",
      "GaussianMLPPolicy/KL                      0.000627384\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00223649\n",
      "GaussianMLPPolicy/LossBefore              0.00223731\n",
      "GaussianMLPPolicy/dLoss                   8.23056e-07\n",
      "GaussianMLPValueFunction/LossAfter       -0.712348\n",
      "GaussianMLPValueFunction/LossBefore      -0.70645\n",
      "GaussianMLPValueFunction/dLoss            0.00589764\n",
      "TotalEnvSteps                        107892\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 1.7119e-02, -1.3399e+00, -4.6513e-06,  ..., -9.6925e+00,\n",
      "        -2.7283e+01,  3.4854e+01])\n",
      "2022-08-24 15:56:23 | [trpo_pendulum] epoch #54 | Saving snapshot...\n",
      "2022-08-24 15:56:23 | [trpo_pendulum] epoch #54 | Saved\n",
      "2022-08-24 15:56:23 | [trpo_pendulum] epoch #54 | Time 50.70 s\n",
      "2022-08-24 15:56:23 | [trpo_pendulum] epoch #54 | EpochTime 0.90 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.516612\n",
      "Evaluation/AverageReturn                 -5.26415\n",
      "Evaluation/Iteration                     54\n",
      "Evaluation/MaxReturn                     -5.03296\n",
      "Evaluation/MinReturn                     -5.49533\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.231186\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.351286\n",
      "GaussianMLPPolicy/KL                      0.00023227\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.0106957\n",
      "GaussianMLPPolicy/LossBefore              0.0107714\n",
      "GaussianMLPPolicy/dLoss                   7.57687e-05\n",
      "GaussianMLPValueFunction/LossAfter       -0.627288\n",
      "GaussianMLPValueFunction/LossBefore      -0.619677\n",
      "GaussianMLPValueFunction/dLoss            0.00761139\n",
      "TotalEnvSteps                        109890\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 1.5932e-02, -1.2511e+00, -2.0004e-04,  ..., -9.2800e+00,\n",
      "        -2.4262e+01,  3.2001e+01])\n",
      "2022-08-24 15:56:24 | [trpo_pendulum] epoch #55 | Line search condition violated. Rejecting the step!\n",
      "2022-08-24 15:56:24 | [trpo_pendulum] epoch #55 | Violated because loss not improving\n",
      "2022-08-24 15:56:24 | [trpo_pendulum] epoch #55 | Saving snapshot...\n",
      "2022-08-24 15:56:24 | [trpo_pendulum] epoch #55 | Saved\n",
      "2022-08-24 15:56:24 | [trpo_pendulum] epoch #55 | Time 51.63 s\n",
      "2022-08-24 15:56:24 | [trpo_pendulum] epoch #55 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.477748\n",
      "Evaluation/AverageReturn                 -4.97705\n",
      "Evaluation/Iteration                     55\n",
      "Evaluation/MaxReturn                     -4.52252\n",
      "Evaluation/MinReturn                     -5.43157\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.454525\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.351286\n",
      "GaussianMLPPolicy/KL                      0\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000935549\n",
      "GaussianMLPPolicy/LossBefore             -0.000935549\n",
      "GaussianMLPPolicy/dLoss                   0\n",
      "GaussianMLPValueFunction/LossAfter       -0.672883\n",
      "GaussianMLPValueFunction/LossBefore      -0.680722\n",
      "GaussianMLPValueFunction/dLoss           -0.00783908\n",
      "TotalEnvSteps                        111888\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 4.3982e-03, -9.9303e-01, -5.3367e-05,  ..., -7.3974e+00,\n",
      "        -1.9331e+01,  2.5503e+01])\n",
      "2022-08-24 15:56:24 | [trpo_pendulum] epoch #56 | Line search condition violated. Rejecting the step!\n",
      "2022-08-24 15:56:24 | [trpo_pendulum] epoch #56 | Violated because loss not improving\n",
      "2022-08-24 15:56:25 | [trpo_pendulum] epoch #56 | Saving snapshot...\n",
      "2022-08-24 15:56:25 | [trpo_pendulum] epoch #56 | Saved\n",
      "2022-08-24 15:56:25 | [trpo_pendulum] epoch #56 | Time 52.56 s\n",
      "2022-08-24 15:56:25 | [trpo_pendulum] epoch #56 | EpochTime 0.93 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn       -0.518368\n",
      "Evaluation/AverageReturn                 -5.0058\n",
      "Evaluation/Iteration                     56\n",
      "Evaluation/MaxReturn                     -4.82452\n",
      "Evaluation/MinReturn                     -5.18708\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.181281\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.351286\n",
      "GaussianMLPPolicy/KL                      0\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00785748\n",
      "GaussianMLPPolicy/LossBefore              0.00785748\n",
      "GaussianMLPPolicy/dLoss                   0\n",
      "GaussianMLPValueFunction/LossAfter       -0.774927\n",
      "GaussianMLPValueFunction/LossBefore      -0.757756\n",
      "GaussianMLPValueFunction/dLoss            0.0171713\n",
      "TotalEnvSteps                        113886\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 2.3324e-02, -8.8092e-01, -6.7766e-05,  ..., -6.5338e+00,\n",
      "        -1.7078e+01,  2.2532e+01])\n",
      "2022-08-24 15:56:26 | [trpo_pendulum] epoch #57 | Saving snapshot...\n",
      "2022-08-24 15:56:26 | [trpo_pendulum] epoch #57 | Saved\n",
      "2022-08-24 15:56:26 | [trpo_pendulum] epoch #57 | Time 53.45 s\n",
      "2022-08-24 15:56:26 | [trpo_pendulum] epoch #57 | EpochTime 0.89 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.466663\n",
      "Evaluation/AverageReturn                 -4.89253\n",
      "Evaluation/Iteration                     57\n",
      "Evaluation/MaxReturn                     -4.89014\n",
      "Evaluation/MinReturn                     -4.89493\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00239491\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.382134\n",
      "GaussianMLPPolicy/KL                      0.00295807\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00410331\n",
      "GaussianMLPPolicy/LossBefore             -0.00398288\n",
      "GaussianMLPPolicy/dLoss                   0.000120434\n",
      "GaussianMLPValueFunction/LossAfter       -0.735097\n",
      "GaussianMLPValueFunction/LossBefore      -0.727364\n",
      "GaussianMLPValueFunction/dLoss            0.00773323\n",
      "TotalEnvSteps                        115884\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 4.4104e-03, -7.6352e-01, -7.6765e-05,  ..., -7.9647e+00,\n",
      "        -2.0706e+01,  2.7104e+01])\n",
      "2022-08-24 15:56:26 | [trpo_pendulum] epoch #58 | Line search condition violated. Rejecting the step!\n",
      "2022-08-24 15:56:26 | [trpo_pendulum] epoch #58 | Violated because loss not improving\n",
      "2022-08-24 15:56:27 | [trpo_pendulum] epoch #58 | Saving snapshot...\n",
      "2022-08-24 15:56:27 | [trpo_pendulum] epoch #58 | Saved\n",
      "2022-08-24 15:56:27 | [trpo_pendulum] epoch #58 | Time 54.39 s\n",
      "2022-08-24 15:56:27 | [trpo_pendulum] epoch #58 | EpochTime 0.94 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn       -0.474524\n",
      "Evaluation/AverageReturn                 -4.78248\n",
      "Evaluation/Iteration                     58\n",
      "Evaluation/MaxReturn                     -4.73976\n",
      "Evaluation/MinReturn                     -4.82521\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0427266\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.382134\n",
      "GaussianMLPPolicy/KL                      0\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00559425\n",
      "GaussianMLPPolicy/LossBefore             -0.00559425\n",
      "GaussianMLPPolicy/dLoss                   0\n",
      "GaussianMLPValueFunction/LossAfter       -0.848138\n",
      "GaussianMLPValueFunction/LossBefore      -0.821451\n",
      "GaussianMLPValueFunction/dLoss            0.0266867\n",
      "TotalEnvSteps                        117882\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 9.4950e-03, -5.6215e-01,  3.6972e-05,  ..., -5.8908e+00,\n",
      "        -1.5308e+01,  2.0043e+01])\n",
      "2022-08-24 15:56:27 | [trpo_pendulum] epoch #59 | Line search condition violated. Rejecting the step!\n",
      "2022-08-24 15:56:27 | [trpo_pendulum] epoch #59 | Violated because loss not improving\n",
      "2022-08-24 15:56:28 | [trpo_pendulum] epoch #59 | Saving snapshot...\n",
      "2022-08-24 15:56:28 | [trpo_pendulum] epoch #59 | Saved\n",
      "2022-08-24 15:56:28 | [trpo_pendulum] epoch #59 | Time 55.31 s\n",
      "2022-08-24 15:56:28 | [trpo_pendulum] epoch #59 | EpochTime 0.92 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn       -0.509409\n",
      "Evaluation/AverageReturn                 -5.16956\n",
      "Evaluation/Iteration                     59\n",
      "Evaluation/MaxReturn                     -5.12716\n",
      "Evaluation/MinReturn                     -5.21195\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0423974\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.382134\n",
      "GaussianMLPPolicy/KL                      0\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.0144404\n",
      "GaussianMLPPolicy/LossBefore              0.0144404\n",
      "GaussianMLPPolicy/dLoss                   0\n",
      "GaussianMLPValueFunction/LossAfter       -0.816318\n",
      "GaussianMLPValueFunction/LossBefore      -0.761866\n",
      "GaussianMLPValueFunction/dLoss            0.0544515\n",
      "TotalEnvSteps                        119880\n",
      "-----------------------------------  --------------\n",
      "tensor([ 5.9009e-03, -6.1355e-01,  8.1732e-05,  ..., -6.4299e+00,\n",
      "        -1.6701e+01,  2.1877e+01])\n",
      "2022-08-24 15:56:28 | [trpo_pendulum] epoch #60 | Saving snapshot...\n",
      "2022-08-24 15:56:28 | [trpo_pendulum] epoch #60 | Saved\n",
      "2022-08-24 15:56:28 | [trpo_pendulum] epoch #60 | Time 56.22 s\n",
      "2022-08-24 15:56:28 | [trpo_pendulum] epoch #60 | EpochTime 0.90 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.53256\n",
      "Evaluation/AverageReturn                 -5.12132\n",
      "Evaluation/Iteration                     60\n",
      "Evaluation/MaxReturn                     -5.00612\n",
      "Evaluation/MinReturn                     -5.23652\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.115202\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.385163\n",
      "GaussianMLPPolicy/KL                      1.21174e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0026481\n",
      "GaussianMLPPolicy/LossBefore             -0.00263674\n",
      "GaussianMLPPolicy/dLoss                   1.13556e-05\n",
      "GaussianMLPValueFunction/LossAfter       -0.782609\n",
      "GaussianMLPValueFunction/LossBefore      -0.777684\n",
      "GaussianMLPValueFunction/dLoss            0.00492412\n",
      "TotalEnvSteps                        121878\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 1.1336e-02, -6.6076e-01,  2.9239e-05,  ..., -7.2816e+00,\n",
      "        -1.8299e+01,  2.4183e+01])\n",
      "2022-08-24 15:56:29 | [trpo_pendulum] epoch #61 | Saving snapshot...\n",
      "2022-08-24 15:56:29 | [trpo_pendulum] epoch #61 | Saved\n",
      "2022-08-24 15:56:29 | [trpo_pendulum] epoch #61 | Time 57.14 s\n",
      "2022-08-24 15:56:29 | [trpo_pendulum] epoch #61 | EpochTime 0.91 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.511686\n",
      "Evaluation/AverageReturn                 -5.20708\n",
      "Evaluation/Iteration                     61\n",
      "Evaluation/MaxReturn                     -5.19222\n",
      "Evaluation/MinReturn                     -5.22194\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0148568\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.392186\n",
      "GaussianMLPPolicy/KL                      7.92458e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00447241\n",
      "GaussianMLPPolicy/LossBefore              0.00449631\n",
      "GaussianMLPPolicy/dLoss                   2.39001e-05\n",
      "GaussianMLPValueFunction/LossAfter       -0.712192\n",
      "GaussianMLPValueFunction/LossBefore      -0.705067\n",
      "GaussianMLPValueFunction/dLoss            0.00712532\n",
      "TotalEnvSteps                        123876\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 1.1261e-02, -7.5948e-01,  6.3889e-05,  ..., -7.2177e+00,\n",
      "        -1.8631e+01,  2.4445e+01])\n",
      "2022-08-24 15:56:30 | [trpo_pendulum] epoch #62 | Saving snapshot...\n",
      "2022-08-24 15:56:30 | [trpo_pendulum] epoch #62 | Saved\n",
      "2022-08-24 15:56:30 | [trpo_pendulum] epoch #62 | Time 58.03 s\n",
      "2022-08-24 15:56:30 | [trpo_pendulum] epoch #62 | EpochTime 0.89 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.533564\n",
      "Evaluation/AverageReturn                 -5.25373\n",
      "Evaluation/Iteration                     62\n",
      "Evaluation/MaxReturn                     -5.1869\n",
      "Evaluation/MinReturn                     -5.32057\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0668373\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.447472\n",
      "GaussianMLPPolicy/KL                      0.00434872\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.000647186\n",
      "GaussianMLPPolicy/LossBefore              0.0011527\n",
      "GaussianMLPPolicy/dLoss                   0.000505515\n",
      "GaussianMLPValueFunction/LossAfter       -0.764691\n",
      "GaussianMLPValueFunction/LossBefore      -0.764937\n",
      "GaussianMLPValueFunction/dLoss           -0.000245869\n",
      "TotalEnvSteps                        125874\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 2.2686e-03, -1.6218e+00,  7.5415e-05,  ..., -1.0379e+01,\n",
      "        -2.7718e+01,  3.5223e+01])\n",
      "2022-08-24 15:56:31 | [trpo_pendulum] epoch #63 | Line search condition violated. Rejecting the step!\n",
      "2022-08-24 15:56:31 | [trpo_pendulum] epoch #63 | Violated because loss not improving\n",
      "2022-08-24 15:56:31 | [trpo_pendulum] epoch #63 | Saving snapshot...\n",
      "2022-08-24 15:56:31 | [trpo_pendulum] epoch #63 | Saved\n",
      "2022-08-24 15:56:31 | [trpo_pendulum] epoch #63 | Time 59.03 s\n",
      "2022-08-24 15:56:31 | [trpo_pendulum] epoch #63 | EpochTime 0.99 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn       -0.421276\n",
      "Evaluation/AverageReturn                 -4.63848\n",
      "Evaluation/Iteration                     63\n",
      "Evaluation/MaxReturn                     -4.52837\n",
      "Evaluation/MinReturn                     -4.7486\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.110117\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.447472\n",
      "GaussianMLPPolicy/KL                      0\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0194599\n",
      "GaussianMLPPolicy/LossBefore             -0.0194599\n",
      "GaussianMLPPolicy/dLoss                   0\n",
      "GaussianMLPValueFunction/LossAfter       -0.85966\n",
      "GaussianMLPValueFunction/LossBefore      -0.738001\n",
      "GaussianMLPValueFunction/dLoss            0.121659\n",
      "TotalEnvSteps                        127872\n",
      "-----------------------------------  --------------\n",
      "tensor([ 1.0190e-02, -1.3244e+00, -6.0350e-05,  ..., -8.5030e+00,\n",
      "        -2.2691e+01,  2.8849e+01])\n",
      "2022-08-24 15:56:32 | [trpo_pendulum] epoch #64 | Saving snapshot...\n",
      "2022-08-24 15:56:32 | [trpo_pendulum] epoch #64 | Saved\n",
      "2022-08-24 15:56:32 | [trpo_pendulum] epoch #64 | Time 59.95 s\n",
      "2022-08-24 15:56:32 | [trpo_pendulum] epoch #64 | EpochTime 0.91 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.498883\n",
      "Evaluation/AverageReturn                 -4.82224\n",
      "Evaluation/Iteration                     64\n",
      "Evaluation/MaxReturn                     -4.75487\n",
      "Evaluation/MinReturn                     -4.88961\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0673735\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.453356\n",
      "GaussianMLPPolicy/KL                      5.69901e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00210096\n",
      "GaussianMLPPolicy/LossBefore              0.00210709\n",
      "GaussianMLPPolicy/dLoss                   6.12671e-06\n",
      "GaussianMLPValueFunction/LossAfter       -0.846857\n",
      "GaussianMLPValueFunction/LossBefore      -0.845302\n",
      "GaussianMLPValueFunction/dLoss            0.00155461\n",
      "TotalEnvSteps                        129870\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 1.8158e-02, -1.7616e+00,  2.0024e-04,  ..., -1.0078e+01,\n",
      "        -2.7043e+01,  3.4338e+01])\n",
      "2022-08-24 15:56:33 | [trpo_pendulum] epoch #65 | Line search condition violated. Rejecting the step!\n",
      "2022-08-24 15:56:33 | [trpo_pendulum] epoch #65 | Violated because loss not improving\n",
      "2022-08-24 15:56:33 | [trpo_pendulum] epoch #65 | Saving snapshot...\n",
      "2022-08-24 15:56:33 | [trpo_pendulum] epoch #65 | Saved\n",
      "2022-08-24 15:56:33 | [trpo_pendulum] epoch #65 | Time 60.88 s\n",
      "2022-08-24 15:56:33 | [trpo_pendulum] epoch #65 | EpochTime 0.93 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn       -0.485941\n",
      "Evaluation/AverageReturn                 -4.85047\n",
      "Evaluation/Iteration                     65\n",
      "Evaluation/MaxReturn                     -4.8288\n",
      "Evaluation/MinReturn                     -4.87214\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.021666\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.453356\n",
      "GaussianMLPPolicy/KL                      0\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00450676\n",
      "GaussianMLPPolicy/LossBefore              0.00450676\n",
      "GaussianMLPPolicy/dLoss                   0\n",
      "GaussianMLPValueFunction/LossAfter       -0.820756\n",
      "GaussianMLPValueFunction/LossBefore      -0.816307\n",
      "GaussianMLPValueFunction/dLoss            0.00444955\n",
      "TotalEnvSteps                        131868\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 7.1694e-03, -1.4178e+00,  2.8734e-04,  ..., -8.1117e+00,\n",
      "        -2.1759e+01,  2.7639e+01])\n",
      "2022-08-24 15:56:34 | [trpo_pendulum] epoch #66 | Saving snapshot...\n",
      "2022-08-24 15:56:34 | [trpo_pendulum] epoch #66 | Saved\n",
      "2022-08-24 15:56:34 | [trpo_pendulum] epoch #66 | Time 61.80 s\n",
      "2022-08-24 15:56:34 | [trpo_pendulum] epoch #66 | EpochTime 0.92 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.453341\n",
      "Evaluation/AverageReturn                 -4.8743\n",
      "Evaluation/Iteration                     66\n",
      "Evaluation/MaxReturn                     -4.86577\n",
      "Evaluation/MinReturn                     -4.88284\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00853276\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.45582\n",
      "GaussianMLPPolicy/KL                      1.03685e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00117915\n",
      "GaussianMLPPolicy/LossBefore              0.00118154\n",
      "GaussianMLPPolicy/dLoss                   2.39734e-06\n",
      "GaussianMLPValueFunction/LossAfter       -0.798947\n",
      "GaussianMLPValueFunction/LossBefore      -0.800706\n",
      "GaussianMLPValueFunction/dLoss           -0.00175828\n",
      "TotalEnvSteps                        133866\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 1.1695e-02, -1.3756e+00, -1.9844e-04,  ..., -7.5340e+00,\n",
      "        -2.0653e+01,  2.5987e+01])\n",
      "2022-08-24 15:56:35 | [trpo_pendulum] epoch #67 | Line search condition violated. Rejecting the step!\n",
      "2022-08-24 15:56:35 | [trpo_pendulum] epoch #67 | Violated because loss not improving\n",
      "2022-08-24 15:56:35 | [trpo_pendulum] epoch #67 | Saving snapshot...\n",
      "2022-08-24 15:56:35 | [trpo_pendulum] epoch #67 | Saved\n",
      "2022-08-24 15:56:35 | [trpo_pendulum] epoch #67 | Time 62.73 s\n",
      "2022-08-24 15:56:35 | [trpo_pendulum] epoch #67 | EpochTime 0.92 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn       -0.534981\n",
      "Evaluation/AverageReturn                 -4.62306\n",
      "Evaluation/Iteration                     67\n",
      "Evaluation/MaxReturn                     -4.49611\n",
      "Evaluation/MinReturn                     -4.75002\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.126953\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.45582\n",
      "GaussianMLPPolicy/KL                      0\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00631642\n",
      "GaussianMLPPolicy/LossBefore             -0.00631642\n",
      "GaussianMLPPolicy/dLoss                   0\n",
      "GaussianMLPValueFunction/LossAfter       -0.864189\n",
      "GaussianMLPValueFunction/LossBefore      -0.838679\n",
      "GaussianMLPValueFunction/dLoss            0.0255101\n",
      "TotalEnvSteps                        135864\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 1.4242e-02, -1.8101e+00,  2.9448e-04,  ..., -9.9820e+00,\n",
      "        -2.7336e+01,  3.4420e+01])\n",
      "2022-08-24 15:56:36 | [trpo_pendulum] epoch #68 | Saving snapshot...\n",
      "2022-08-24 15:56:36 | [trpo_pendulum] epoch #68 | Saved\n",
      "2022-08-24 15:56:36 | [trpo_pendulum] epoch #68 | Time 63.63 s\n",
      "2022-08-24 15:56:36 | [trpo_pendulum] epoch #68 | EpochTime 0.89 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.483292\n",
      "Evaluation/AverageReturn                 -4.72485\n",
      "Evaluation/Iteration                     68\n",
      "Evaluation/MaxReturn                     -4.54426\n",
      "Evaluation/MinReturn                     -4.90544\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.180589\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.462601\n",
      "GaussianMLPPolicy/KL                      8.32889e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00976484\n",
      "GaussianMLPPolicy/LossBefore              0.0097751\n",
      "GaussianMLPPolicy/dLoss                   1.02669e-05\n",
      "GaussianMLPValueFunction/LossAfter       -0.825264\n",
      "GaussianMLPValueFunction/LossBefore      -0.800022\n",
      "GaussianMLPValueFunction/dLoss            0.0252418\n",
      "TotalEnvSteps                        137862\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 1.7222e-02, -1.9190e+00, -2.6061e-04,  ..., -1.1888e+01,\n",
      "        -3.2260e+01,  4.0788e+01])\n",
      "2022-08-24 15:56:37 | [trpo_pendulum] epoch #69 | Saving snapshot...\n",
      "2022-08-24 15:56:37 | [trpo_pendulum] epoch #69 | Saved\n",
      "2022-08-24 15:56:37 | [trpo_pendulum] epoch #69 | Time 64.56 s\n",
      "2022-08-24 15:56:37 | [trpo_pendulum] epoch #69 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.561779\n",
      "Evaluation/AverageReturn                 -5.03762\n",
      "Evaluation/Iteration                     69\n",
      "Evaluation/MaxReturn                     -5.02344\n",
      "Evaluation/MinReturn                     -5.05181\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0141847\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.46608\n",
      "GaussianMLPPolicy/KL                      2.0833e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.0125309\n",
      "GaussianMLPPolicy/LossBefore              0.0125412\n",
      "GaussianMLPPolicy/dLoss                   1.03144e-05\n",
      "GaussianMLPValueFunction/LossAfter       -0.72778\n",
      "GaussianMLPValueFunction/LossBefore      -0.680369\n",
      "GaussianMLPValueFunction/dLoss            0.0474103\n",
      "TotalEnvSteps                        139860\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 5.9922e-03, -1.2449e+00,  1.9534e-04,  ..., -7.9864e+00,\n",
      "        -2.2334e+01,  2.7849e+01])\n",
      "2022-08-24 15:56:38 | [trpo_pendulum] epoch #70 | Saving snapshot...\n",
      "2022-08-24 15:56:38 | [trpo_pendulum] epoch #70 | Saved\n",
      "2022-08-24 15:56:38 | [trpo_pendulum] epoch #70 | Time 65.48 s\n",
      "2022-08-24 15:56:38 | [trpo_pendulum] epoch #70 | EpochTime 0.91 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.470525\n",
      "Evaluation/AverageReturn                 -4.8174\n",
      "Evaluation/Iteration                     70\n",
      "Evaluation/MaxReturn                     -4.62582\n",
      "Evaluation/MinReturn                     -5.00897\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.191575\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.472743\n",
      "GaussianMLPPolicy/KL                      5.27705e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00586394\n",
      "GaussianMLPPolicy/LossBefore             -0.00583834\n",
      "GaussianMLPPolicy/dLoss                   2.56007e-05\n",
      "GaussianMLPValueFunction/LossAfter       -0.838939\n",
      "GaussianMLPValueFunction/LossBefore      -0.838618\n",
      "GaussianMLPValueFunction/dLoss            0.000320733\n",
      "TotalEnvSteps                        141858\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 7.4360e-03, -1.2137e+00, -1.3736e-05,  ..., -7.6590e+00,\n",
      "        -2.0480e+01,  2.6162e+01])\n",
      "2022-08-24 15:56:39 | [trpo_pendulum] epoch #71 | Saving snapshot...\n",
      "2022-08-24 15:56:39 | [trpo_pendulum] epoch #71 | Saved\n",
      "2022-08-24 15:56:39 | [trpo_pendulum] epoch #71 | Time 66.38 s\n",
      "2022-08-24 15:56:39 | [trpo_pendulum] epoch #71 | EpochTime 0.89 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.500877\n",
      "Evaluation/AverageReturn                 -4.60367\n",
      "Evaluation/Iteration                     71\n",
      "Evaluation/MaxReturn                     -4.49674\n",
      "Evaluation/MinReturn                     -4.71059\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.106922\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.519596\n",
      "GaussianMLPPolicy/KL                      0.00439346\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -8.38104e-05\n",
      "GaussianMLPPolicy/LossBefore              0.000344358\n",
      "GaussianMLPPolicy/dLoss                   0.000428168\n",
      "GaussianMLPValueFunction/LossAfter       -0.950268\n",
      "GaussianMLPValueFunction/LossBefore      -0.939702\n",
      "GaussianMLPValueFunction/dLoss            0.0105662\n",
      "TotalEnvSteps                        143856\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 5.9506e-03, -1.3603e+00, -1.1453e-04,  ..., -1.0054e+01,\n",
      "        -2.7241e+01,  3.3396e+01])\n",
      "2022-08-24 15:56:40 | [trpo_pendulum] epoch #72 | Saving snapshot...\n",
      "2022-08-24 15:56:40 | [trpo_pendulum] epoch #72 | Saved\n",
      "2022-08-24 15:56:40 | [trpo_pendulum] epoch #72 | Time 67.29 s\n",
      "2022-08-24 15:56:40 | [trpo_pendulum] epoch #72 | EpochTime 0.91 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.425325\n",
      "Evaluation/AverageReturn                 -4.14468\n",
      "Evaluation/Iteration                     72\n",
      "Evaluation/MaxReturn                     -4.05158\n",
      "Evaluation/MinReturn                     -4.23777\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0930938\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.524224\n",
      "GaussianMLPPolicy/KL                      4.92096e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0136878\n",
      "GaussianMLPPolicy/LossBefore             -0.0136829\n",
      "GaussianMLPPolicy/dLoss                   4.8792e-06\n",
      "GaussianMLPValueFunction/LossAfter       -1.00275\n",
      "GaussianMLPValueFunction/LossBefore      -0.908575\n",
      "GaussianMLPValueFunction/dLoss            0.0941776\n",
      "TotalEnvSteps                        145854\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 1.6388e-03, -1.7343e+00, -2.2617e-04,  ..., -1.1017e+01,\n",
      "        -2.9867e+01,  3.6777e+01])\n",
      "2022-08-24 15:56:40 | [trpo_pendulum] epoch #73 | Saving snapshot...\n",
      "2022-08-24 15:56:40 | [trpo_pendulum] epoch #73 | Saved\n",
      "2022-08-24 15:56:40 | [trpo_pendulum] epoch #73 | Time 68.21 s\n",
      "2022-08-24 15:56:40 | [trpo_pendulum] epoch #73 | EpochTime 0.91 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.434631\n",
      "Evaluation/AverageReturn                 -4.20606\n",
      "Evaluation/Iteration                     73\n",
      "Evaluation/MaxReturn                     -4.09154\n",
      "Evaluation/MinReturn                     -4.32057\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.114511\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.526367\n",
      "GaussianMLPPolicy/KL                      2.58469e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00679643\n",
      "GaussianMLPPolicy/LossBefore              0.00682155\n",
      "GaussianMLPPolicy/dLoss                   2.51224e-05\n",
      "GaussianMLPValueFunction/LossAfter       -1.03433\n",
      "GaussianMLPValueFunction/LossBefore      -1.01351\n",
      "GaussianMLPValueFunction/dLoss            0.0208198\n",
      "TotalEnvSteps                        147852\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 3.3804e-03, -1.9053e+00, -7.9990e-05,  ..., -1.0476e+01,\n",
      "        -2.8557e+01,  3.5132e+01])\n",
      "2022-08-24 15:56:41 | [trpo_pendulum] epoch #74 | Saving snapshot...\n",
      "2022-08-24 15:56:41 | [trpo_pendulum] epoch #74 | Saved\n",
      "2022-08-24 15:56:41 | [trpo_pendulum] epoch #74 | Time 69.14 s\n",
      "2022-08-24 15:56:41 | [trpo_pendulum] epoch #74 | EpochTime 0.92 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.431787\n",
      "Evaluation/AverageReturn                 -4.04293\n",
      "Evaluation/Iteration                     74\n",
      "Evaluation/MaxReturn                     -3.96556\n",
      "Evaluation/MinReturn                     -4.12031\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0773758\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.5494\n",
      "GaussianMLPPolicy/KL                      0.000739822\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00231402\n",
      "GaussianMLPPolicy/LossBefore             -0.00228558\n",
      "GaussianMLPPolicy/dLoss                   2.84461e-05\n",
      "GaussianMLPValueFunction/LossAfter       -1.03726\n",
      "GaussianMLPValueFunction/LossBefore      -1.02535\n",
      "GaussianMLPValueFunction/dLoss            0.0119166\n",
      "TotalEnvSteps                        149850\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 7.9049e-03, -3.8279e+00,  3.4846e-04,  ..., -1.6295e+01,\n",
      "        -4.5300e+01,  5.5997e+01])\n",
      "2022-08-24 15:56:42 | [trpo_pendulum] epoch #75 | Saving snapshot...\n",
      "2022-08-24 15:56:42 | [trpo_pendulum] epoch #75 | Saved\n",
      "2022-08-24 15:56:42 | [trpo_pendulum] epoch #75 | Time 70.04 s\n",
      "2022-08-24 15:56:42 | [trpo_pendulum] epoch #75 | EpochTime 0.90 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.3929\n",
      "Evaluation/AverageReturn                 -4.0783\n",
      "Evaluation/Iteration                     75\n",
      "Evaluation/MaxReturn                     -3.95708\n",
      "Evaluation/MinReturn                     -4.19952\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.121222\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.588497\n",
      "GaussianMLPPolicy/KL                      0.00266861\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00297671\n",
      "GaussianMLPPolicy/LossBefore              0.00341711\n",
      "GaussianMLPPolicy/dLoss                   0.000440397\n",
      "GaussianMLPValueFunction/LossAfter       -0.931085\n",
      "GaussianMLPValueFunction/LossBefore      -0.924624\n",
      "GaussianMLPValueFunction/dLoss            0.00646085\n",
      "TotalEnvSteps                        151848\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 2.4719e-03, -2.5835e+00, -2.0019e-04,  ..., -9.1869e+00,\n",
      "        -2.5886e+01,  3.2432e+01])\n",
      "2022-08-24 15:56:43 | [trpo_pendulum] epoch #76 | Saving snapshot...\n",
      "2022-08-24 15:56:43 | [trpo_pendulum] epoch #76 | Saved\n",
      "2022-08-24 15:56:43 | [trpo_pendulum] epoch #76 | Time 70.95 s\n",
      "2022-08-24 15:56:43 | [trpo_pendulum] epoch #76 | EpochTime 0.91 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.376163\n",
      "Evaluation/AverageReturn                 -3.71905\n",
      "Evaluation/Iteration                     76\n",
      "Evaluation/MaxReturn                     -3.65586\n",
      "Evaluation/MinReturn                     -3.78224\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0631909\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.590254\n",
      "GaussianMLPPolicy/KL                      1.56399e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0114536\n",
      "GaussianMLPPolicy/LossBefore             -0.0114514\n",
      "GaussianMLPPolicy/dLoss                   2.16905e-06\n",
      "GaussianMLPValueFunction/LossAfter       -1.12615\n",
      "GaussianMLPValueFunction/LossBefore      -1.04874\n",
      "GaussianMLPValueFunction/dLoss            0.0774153\n",
      "TotalEnvSteps                        153846\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 4.3442e-03, -3.2747e+00,  4.5130e-04,  ..., -1.2458e+01,\n",
      "        -3.4805e+01,  4.3707e+01])\n",
      "2022-08-24 15:56:44 | [trpo_pendulum] epoch #77 | Saving snapshot...\n",
      "2022-08-24 15:56:44 | [trpo_pendulum] epoch #77 | Saved\n",
      "2022-08-24 15:56:44 | [trpo_pendulum] epoch #77 | Time 71.84 s\n",
      "2022-08-24 15:56:44 | [trpo_pendulum] epoch #77 | EpochTime 0.88 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.363176\n",
      "Evaluation/AverageReturn                 -3.62085\n",
      "Evaluation/Iteration                     77\n",
      "Evaluation/MaxReturn                     -3.56692\n",
      "Evaluation/MinReturn                     -3.67478\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0539319\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.608053\n",
      "GaussianMLPPolicy/KL                      0.000404515\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00397841\n",
      "GaussianMLPPolicy/LossBefore             -0.00392557\n",
      "GaussianMLPPolicy/dLoss                   5.28358e-05\n",
      "GaussianMLPValueFunction/LossAfter       -1.10744\n",
      "GaussianMLPValueFunction/LossBefore      -1.09119\n",
      "GaussianMLPValueFunction/dLoss            0.0162499\n",
      "TotalEnvSteps                        155844\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 9.0805e-03, -4.1771e+00,  5.3886e-04,  ..., -1.3602e+01,\n",
      "        -3.8701e+01,  4.8575e+01])\n",
      "2022-08-24 15:56:45 | [trpo_pendulum] epoch #78 | Saving snapshot...\n",
      "2022-08-24 15:56:45 | [trpo_pendulum] epoch #78 | Saved\n",
      "2022-08-24 15:56:45 | [trpo_pendulum] epoch #78 | Time 72.76 s\n",
      "2022-08-24 15:56:45 | [trpo_pendulum] epoch #78 | EpochTime 0.92 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.410528\n",
      "Evaluation/AverageReturn                 -3.79902\n",
      "Evaluation/Iteration                     78\n",
      "Evaluation/MaxReturn                     -3.6478\n",
      "Evaluation/MinReturn                     -3.95024\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.151217\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.611453\n",
      "GaussianMLPPolicy/KL                      1.74196e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00412791\n",
      "GaussianMLPPolicy/LossBefore              0.00413387\n",
      "GaussianMLPPolicy/dLoss                   5.96326e-06\n",
      "GaussianMLPValueFunction/LossAfter       -1.04746\n",
      "GaussianMLPValueFunction/LossBefore      -1.0433\n",
      "GaussianMLPValueFunction/dLoss            0.0041573\n",
      "TotalEnvSteps                        157842\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 7.0983e-03, -4.5936e+00, -3.0600e-04,  ..., -1.4868e+01,\n",
      "        -4.1396e+01,  5.2756e+01])\n",
      "2022-08-24 15:56:46 | [trpo_pendulum] epoch #79 | Saving snapshot...\n",
      "2022-08-24 15:56:46 | [trpo_pendulum] epoch #79 | Saved\n",
      "2022-08-24 15:56:46 | [trpo_pendulum] epoch #79 | Time 73.65 s\n",
      "2022-08-24 15:56:46 | [trpo_pendulum] epoch #79 | EpochTime 0.88 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.416813\n",
      "Evaluation/AverageReturn                 -3.85057\n",
      "Evaluation/Iteration                     79\n",
      "Evaluation/MaxReturn                     -3.79867\n",
      "Evaluation/MinReturn                     -3.90248\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0519064\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.656465\n",
      "GaussianMLPPolicy/KL                      0.00890813\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00222846\n",
      "GaussianMLPPolicy/LossBefore              0.0028944\n",
      "GaussianMLPPolicy/dLoss                   0.000665937\n",
      "GaussianMLPValueFunction/LossAfter       -1.05667\n",
      "GaussianMLPValueFunction/LossBefore      -1.05539\n",
      "GaussianMLPValueFunction/dLoss            0.00127947\n",
      "TotalEnvSteps                        159840\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 4.0907e-03, -3.0116e+00, -2.7242e-04,  ..., -9.6475e+00,\n",
      "        -2.7697e+01,  3.4015e+01])\n",
      "2022-08-24 15:56:47 | [trpo_pendulum] epoch #80 | Saving snapshot...\n",
      "2022-08-24 15:56:47 | [trpo_pendulum] epoch #80 | Saved\n",
      "2022-08-24 15:56:47 | [trpo_pendulum] epoch #80 | Time 74.56 s\n",
      "2022-08-24 15:56:47 | [trpo_pendulum] epoch #80 | EpochTime 0.91 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.385612\n",
      "Evaluation/AverageReturn                 -3.38367\n",
      "Evaluation/Iteration                     80\n",
      "Evaluation/MaxReturn                     -3.32979\n",
      "Evaluation/MinReturn                     -3.43755\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0538771\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.696915\n",
      "GaussianMLPPolicy/KL                      0.00719281\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0151536\n",
      "GaussianMLPPolicy/LossBefore             -0.0148342\n",
      "GaussianMLPPolicy/dLoss                   0.000319418\n",
      "GaussianMLPValueFunction/LossAfter       -1.26438\n",
      "GaussianMLPValueFunction/LossBefore      -1.09085\n",
      "GaussianMLPValueFunction/dLoss            0.173531\n",
      "TotalEnvSteps                        161838\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 9.4306e-03, -4.6328e+00,  9.5658e-04,  ..., -1.4142e+01,\n",
      "        -4.0867e+01,  5.0384e+01])\n",
      "2022-08-24 15:56:48 | [trpo_pendulum] epoch #81 | Saving snapshot...\n",
      "2022-08-24 15:56:48 | [trpo_pendulum] epoch #81 | Saved\n",
      "2022-08-24 15:56:48 | [trpo_pendulum] epoch #81 | Time 75.47 s\n",
      "2022-08-24 15:56:48 | [trpo_pendulum] epoch #81 | EpochTime 0.91 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn       -0.29973\n",
      "Evaluation/AverageReturn                 -2.94656\n",
      "Evaluation/Iteration                     81\n",
      "Evaluation/MaxReturn                     -2.89291\n",
      "Evaluation/MinReturn                     -3.0002\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0536453\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.770229\n",
      "GaussianMLPPolicy/KL                      0.00981999\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0122038\n",
      "GaussianMLPPolicy/LossBefore             -0.0116572\n",
      "GaussianMLPPolicy/dLoss                   0.00054657\n",
      "GaussianMLPValueFunction/LossAfter       -1.23735\n",
      "GaussianMLPValueFunction/LossBefore      -1.14542\n",
      "GaussianMLPValueFunction/dLoss            0.0919209\n",
      "TotalEnvSteps                        163836\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 5.5052e-03, -6.2938e+00,  4.5674e-04,  ..., -2.0560e+01,\n",
      "        -5.9236e+01,  7.2632e+01])\n",
      "2022-08-24 15:56:49 | [trpo_pendulum] epoch #82 | Saving snapshot...\n",
      "2022-08-24 15:56:49 | [trpo_pendulum] epoch #82 | Saved\n",
      "2022-08-24 15:56:49 | [trpo_pendulum] epoch #82 | Time 76.38 s\n",
      "2022-08-24 15:56:49 | [trpo_pendulum] epoch #82 | EpochTime 0.90 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.193732\n",
      "Evaluation/AverageReturn                 -2.27785\n",
      "Evaluation/Iteration                     82\n",
      "Evaluation/MaxReturn                     -2.19573\n",
      "Evaluation/MinReturn                     -2.35996\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0821121\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.777664\n",
      "GaussianMLPPolicy/KL                      0.000100076\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0147671\n",
      "GaussianMLPPolicy/LossBefore             -0.0147663\n",
      "GaussianMLPPolicy/dLoss                   7.55303e-07\n",
      "GaussianMLPValueFunction/LossAfter       -1.43525\n",
      "GaussianMLPValueFunction/LossBefore      -1.25114\n",
      "GaussianMLPValueFunction/dLoss            0.184108\n",
      "TotalEnvSteps                        165834\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 4.0545e-03, -6.4988e+00,  1.1554e-03,  ..., -1.9196e+01,\n",
      "        -5.5893e+01,  6.8697e+01])\n",
      "2022-08-24 15:56:49 | [trpo_pendulum] epoch #83 | Line search condition violated. Rejecting the step!\n",
      "2022-08-24 15:56:49 | [trpo_pendulum] epoch #83 | Violated because loss not improving\n",
      "2022-08-24 15:56:50 | [trpo_pendulum] epoch #83 | Saving snapshot...\n",
      "2022-08-24 15:56:50 | [trpo_pendulum] epoch #83 | Saved\n",
      "2022-08-24 15:56:50 | [trpo_pendulum] epoch #83 | Time 77.39 s\n",
      "2022-08-24 15:56:50 | [trpo_pendulum] epoch #83 | EpochTime 1.01 s\n",
      "-----------------------------------  --------------\n",
      "Evaluation/AverageDiscountedReturn       -0.219766\n",
      "Evaluation/AverageReturn                 -2.31932\n",
      "Evaluation/Iteration                     83\n",
      "Evaluation/MaxReturn                     -2.23632\n",
      "Evaluation/MinReturn                     -2.40231\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0829969\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.777664\n",
      "GaussianMLPPolicy/KL                      0\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.0014538\n",
      "GaussianMLPPolicy/LossBefore              0.0014538\n",
      "GaussianMLPPolicy/dLoss                   0\n",
      "GaussianMLPValueFunction/LossAfter       -1.50057\n",
      "GaussianMLPValueFunction/LossBefore      -1.47628\n",
      "GaussianMLPValueFunction/dLoss            0.0242858\n",
      "TotalEnvSteps                        167832\n",
      "-----------------------------------  --------------\n",
      "tensor([ 5.3106e-03, -3.4472e+00,  4.6372e-04,  ..., -1.0188e+01,\n",
      "        -2.9659e+01,  3.6458e+01])\n",
      "2022-08-24 15:56:51 | [trpo_pendulum] epoch #84 | Saving snapshot...\n",
      "2022-08-24 15:56:51 | [trpo_pendulum] epoch #84 | Saved\n",
      "2022-08-24 15:56:51 | [trpo_pendulum] epoch #84 | Time 78.31 s\n",
      "2022-08-24 15:56:51 | [trpo_pendulum] epoch #84 | EpochTime 0.91 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.247611\n",
      "Evaluation/AverageReturn                 -2.33227\n",
      "Evaluation/Iteration                     84\n",
      "Evaluation/MaxReturn                     -2.29585\n",
      "Evaluation/MinReturn                     -2.36869\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0364216\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.834549\n",
      "GaussianMLPPolicy/KL                      0.00727127\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00322279\n",
      "GaussianMLPPolicy/LossBefore              0.00351328\n",
      "GaussianMLPPolicy/dLoss                   0.000290484\n",
      "GaussianMLPValueFunction/LossAfter       -1.55974\n",
      "GaussianMLPValueFunction/LossBefore      -1.52898\n",
      "GaussianMLPValueFunction/dLoss            0.0307529\n",
      "TotalEnvSteps                        169830\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 4.7760e-03, -2.9071e+00,  1.2920e-05,  ..., -8.7826e+00,\n",
      "        -2.5588e+01,  3.1222e+01])\n",
      "2022-08-24 15:56:51 | [trpo_pendulum] epoch #85 | Saving snapshot...\n",
      "2022-08-24 15:56:51 | [trpo_pendulum] epoch #85 | Saved\n",
      "2022-08-24 15:56:51 | [trpo_pendulum] epoch #85 | Time 79.19 s\n",
      "2022-08-24 15:56:51 | [trpo_pendulum] epoch #85 | EpochTime 0.88 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.209992\n",
      "Evaluation/AverageReturn                 -2.04854\n",
      "Evaluation/Iteration                     85\n",
      "Evaluation/MaxReturn                     -2.04727\n",
      "Evaluation/MinReturn                     -2.04982\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00127197\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.895144\n",
      "GaussianMLPPolicy/KL                      0.00786295\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00884416\n",
      "GaussianMLPPolicy/LossBefore             -0.00859007\n",
      "GaussianMLPPolicy/dLoss                   0.000254092\n",
      "GaussianMLPValueFunction/LossAfter       -1.72076\n",
      "GaussianMLPValueFunction/LossBefore      -1.58517\n",
      "GaussianMLPValueFunction/dLoss            0.135592\n",
      "TotalEnvSteps                        171828\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 5.3383e-03, -1.0175e+01, -1.8404e-03,  ..., -2.7342e+01,\n",
      "        -7.9636e+01,  9.9467e+01])\n",
      "2022-08-24 15:56:52 | [trpo_pendulum] epoch #86 | Saving snapshot...\n",
      "2022-08-24 15:56:52 | [trpo_pendulum] epoch #86 | Saved\n",
      "2022-08-24 15:56:52 | [trpo_pendulum] epoch #86 | Time 80.12 s\n",
      "2022-08-24 15:56:52 | [trpo_pendulum] epoch #86 | EpochTime 0.92 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.221107\n",
      "Evaluation/AverageReturn                 -1.81392\n",
      "Evaluation/Iteration                     86\n",
      "Evaluation/MaxReturn                     -1.76828\n",
      "Evaluation/MinReturn                     -1.85957\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0456493\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.898756\n",
      "GaussianMLPPolicy/KL                      1.63498e-05\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00867958\n",
      "GaussianMLPPolicy/LossBefore             -0.00867424\n",
      "GaussianMLPPolicy/dLoss                   5.34672e-06\n",
      "GaussianMLPValueFunction/LossAfter       -1.72375\n",
      "GaussianMLPValueFunction/LossBefore      -1.58196\n",
      "GaussianMLPValueFunction/dLoss            0.141786\n",
      "TotalEnvSteps                        173826\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 3.8468e-03, -5.3371e+00, -8.5976e-04,  ..., -1.4348e+01,\n",
      "        -4.0976e+01,  5.1912e+01])\n",
      "2022-08-24 15:56:53 | [trpo_pendulum] epoch #87 | Line search condition violated. Rejecting the step!\n",
      "2022-08-24 15:56:53 | [trpo_pendulum] epoch #87 | Violated because loss not improving\n",
      "2022-08-24 15:56:53 | [trpo_pendulum] epoch #87 | Saving snapshot...\n",
      "2022-08-24 15:56:53 | [trpo_pendulum] epoch #87 | Saved\n",
      "2022-08-24 15:56:53 | [trpo_pendulum] epoch #87 | Time 81.06 s\n",
      "2022-08-24 15:56:53 | [trpo_pendulum] epoch #87 | EpochTime 0.93 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.211098\n",
      "Evaluation/AverageReturn                 -1.81768\n",
      "Evaluation/Iteration                     87\n",
      "Evaluation/MaxReturn                     -1.77537\n",
      "Evaluation/MinReturn                     -1.85999\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0423078\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.898756\n",
      "GaussianMLPPolicy/KL                      0\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000562397\n",
      "GaussianMLPPolicy/LossBefore             -0.000562397\n",
      "GaussianMLPPolicy/dLoss                   0\n",
      "GaussianMLPValueFunction/LossAfter       -1.85577\n",
      "GaussianMLPValueFunction/LossBefore      -1.8146\n",
      "GaussianMLPValueFunction/dLoss            0.0411695\n",
      "TotalEnvSteps                        175824\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 4.8361e-03, -5.6150e+00, -3.8902e-04,  ..., -1.5066e+01,\n",
      "        -4.3058e+01,  5.4523e+01])\n",
      "2022-08-24 15:56:54 | [trpo_pendulum] epoch #88 | Saving snapshot...\n",
      "2022-08-24 15:56:54 | [trpo_pendulum] epoch #88 | Saved\n",
      "2022-08-24 15:56:54 | [trpo_pendulum] epoch #88 | Time 81.95 s\n",
      "2022-08-24 15:56:54 | [trpo_pendulum] epoch #88 | EpochTime 0.89 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.199743\n",
      "Evaluation/AverageReturn                 -1.81533\n",
      "Evaluation/Iteration                     88\n",
      "Evaluation/MaxReturn                     -1.807\n",
      "Evaluation/MinReturn                     -1.82365\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00832461\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.970416\n",
      "GaussianMLPPolicy/KL                      0.00942342\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter               0.00115672\n",
      "GaussianMLPPolicy/LossBefore              0.00144898\n",
      "GaussianMLPPolicy/dLoss                   0.000292254\n",
      "GaussianMLPValueFunction/LossAfter       -1.84387\n",
      "GaussianMLPValueFunction/LossBefore      -1.82685\n",
      "GaussianMLPValueFunction/dLoss            0.0170188\n",
      "TotalEnvSteps                        177822\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 1.6713e-03, -1.0147e+01, -5.0306e-04,  ..., -2.2156e+01,\n",
      "        -6.5458e+01,  8.2081e+01])\n",
      "2022-08-24 15:56:55 | [trpo_pendulum] epoch #89 | Saving snapshot...\n",
      "2022-08-24 15:56:55 | [trpo_pendulum] epoch #89 | Saved\n",
      "2022-08-24 15:56:55 | [trpo_pendulum] epoch #89 | Time 82.84 s\n",
      "2022-08-24 15:56:55 | [trpo_pendulum] epoch #89 | EpochTime 0.89 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.152311\n",
      "Evaluation/AverageReturn                 -1.46848\n",
      "Evaluation/Iteration                     89\n",
      "Evaluation/MaxReturn                     -1.40569\n",
      "Evaluation/MinReturn                     -1.53127\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0627862\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -0.997085\n",
      "GaussianMLPPolicy/KL                      0.00641761\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.0094885\n",
      "GaussianMLPPolicy/LossBefore             -0.00929726\n",
      "GaussianMLPPolicy/dLoss                   0.000191241\n",
      "GaussianMLPValueFunction/LossAfter       -2.00656\n",
      "GaussianMLPValueFunction/LossBefore      -1.785\n",
      "GaussianMLPValueFunction/dLoss            0.22156\n",
      "TotalEnvSteps                        179820\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 3.9867e-03, -6.7300e+00,  1.0243e-03,  ..., -1.4861e+01,\n",
      "        -4.3738e+01,  5.5167e+01])\n",
      "2022-08-24 15:56:56 | [trpo_pendulum] epoch #90 | Saving snapshot...\n",
      "2022-08-24 15:56:56 | [trpo_pendulum] epoch #90 | Saved\n",
      "2022-08-24 15:56:56 | [trpo_pendulum] epoch #90 | Time 83.73 s\n",
      "2022-08-24 15:56:56 | [trpo_pendulum] epoch #90 | EpochTime 0.89 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.140698\n",
      "Evaluation/AverageReturn                 -1.34003\n",
      "Evaluation/Iteration                     90\n",
      "Evaluation/MaxReturn                     -1.26866\n",
      "Evaluation/MinReturn                     -1.41141\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0713756\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.06071\n",
      "GaussianMLPPolicy/KL                      0.0076515\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00505797\n",
      "GaussianMLPPolicy/LossBefore             -0.00485628\n",
      "GaussianMLPPolicy/dLoss                   0.000201687\n",
      "GaussianMLPValueFunction/LossAfter       -2.07228\n",
      "GaussianMLPValueFunction/LossBefore      -1.9693\n",
      "GaussianMLPValueFunction/dLoss            0.102989\n",
      "TotalEnvSteps                        181818\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 4.0882e-03, -7.3030e+00, -7.3820e-04,  ..., -1.7399e+01,\n",
      "        -5.1221e+01,  6.4599e+01])\n",
      "2022-08-24 15:56:57 | [trpo_pendulum] epoch #91 | Saving snapshot...\n",
      "2022-08-24 15:56:57 | [trpo_pendulum] epoch #91 | Saved\n",
      "2022-08-24 15:56:57 | [trpo_pendulum] epoch #91 | Time 84.62 s\n",
      "2022-08-24 15:56:57 | [trpo_pendulum] epoch #91 | EpochTime 0.89 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.116179\n",
      "Evaluation/AverageReturn                 -1.07389\n",
      "Evaluation/Iteration                     91\n",
      "Evaluation/MaxReturn                     -1.04722\n",
      "Evaluation/MinReturn                     -1.10057\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0266721\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.12488\n",
      "GaussianMLPPolicy/KL                      0.00685361\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00732263\n",
      "GaussianMLPPolicy/LossBefore             -0.00714172\n",
      "GaussianMLPPolicy/dLoss                   0.000180906\n",
      "GaussianMLPValueFunction/LossAfter       -2.21596\n",
      "GaussianMLPValueFunction/LossBefore      -2.01616\n",
      "GaussianMLPValueFunction/dLoss            0.199799\n",
      "TotalEnvSteps                        183816\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 5.5481e-04, -8.6770e+00, -6.4381e-04,  ..., -2.0647e+01,\n",
      "        -6.0791e+01,  7.6769e+01])\n",
      "2022-08-24 15:56:58 | [trpo_pendulum] epoch #92 | Saving snapshot...\n",
      "2022-08-24 15:56:58 | [trpo_pendulum] epoch #92 | Saved\n",
      "2022-08-24 15:56:58 | [trpo_pendulum] epoch #92 | Time 85.52 s\n",
      "2022-08-24 15:56:58 | [trpo_pendulum] epoch #92 | EpochTime 0.89 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.106524\n",
      "Evaluation/AverageReturn                 -0.923693\n",
      "Evaluation/Iteration                     92\n",
      "Evaluation/MaxReturn                     -0.910615\n",
      "Evaluation/MinReturn                     -0.936771\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0130783\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.13019\n",
      "GaussianMLPPolicy/KL                      0.00789788\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00404073\n",
      "GaussianMLPPolicy/LossBefore             -0.00389942\n",
      "GaussianMLPPolicy/dLoss                   0.000141314\n",
      "GaussianMLPValueFunction/LossAfter       -2.3832\n",
      "GaussianMLPValueFunction/LossBefore      -2.25481\n",
      "GaussianMLPValueFunction/dLoss            0.128389\n",
      "TotalEnvSteps                        185814\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 2.4556e-03, -3.2826e+00, -4.7488e-04,  ..., -8.7970e+00,\n",
      "        -2.5878e+01,  3.2487e+01])\n",
      "2022-08-24 15:56:59 | [trpo_pendulum] epoch #93 | Saving snapshot...\n",
      "2022-08-24 15:56:59 | [trpo_pendulum] epoch #93 | Saved\n",
      "2022-08-24 15:56:59 | [trpo_pendulum] epoch #93 | Time 86.40 s\n",
      "2022-08-24 15:56:59 | [trpo_pendulum] epoch #93 | EpochTime 0.88 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0879143\n",
      "Evaluation/AverageReturn                 -0.821059\n",
      "Evaluation/Iteration                     93\n",
      "Evaluation/MaxReturn                     -0.793226\n",
      "Evaluation/MinReturn                     -0.848891\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0278325\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.19921\n",
      "GaussianMLPPolicy/KL                      0.00675018\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00249857\n",
      "GaussianMLPPolicy/LossBefore             -0.00239506\n",
      "GaussianMLPPolicy/dLoss                   0.000103506\n",
      "GaussianMLPValueFunction/LossAfter       -2.46754\n",
      "GaussianMLPValueFunction/LossBefore      -2.38133\n",
      "GaussianMLPValueFunction/dLoss            0.0862093\n",
      "TotalEnvSteps                        187812\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 1.4187e-03, -8.9648e+00,  1.3012e-03,  ..., -2.3698e+01,\n",
      "        -7.0056e+01,  8.7607e+01])\n",
      "2022-08-24 15:57:00 | [trpo_pendulum] epoch #94 | Saving snapshot...\n",
      "2022-08-24 15:57:00 | [trpo_pendulum] epoch #94 | Saved\n",
      "2022-08-24 15:57:00 | [trpo_pendulum] epoch #94 | Time 87.30 s\n",
      "2022-08-24 15:57:00 | [trpo_pendulum] epoch #94 | EpochTime 0.89 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0766856\n",
      "Evaluation/AverageReturn                 -0.73278\n",
      "Evaluation/Iteration                     94\n",
      "Evaluation/MaxReturn                     -0.699398\n",
      "Evaluation/MinReturn                     -0.766162\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0333821\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.23255\n",
      "GaussianMLPPolicy/KL                      0.00905056\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00296254\n",
      "GaussianMLPPolicy/LossBefore             -0.00281313\n",
      "GaussianMLPPolicy/dLoss                   0.000149412\n",
      "GaussianMLPValueFunction/LossAfter       -2.47753\n",
      "GaussianMLPValueFunction/LossBefore      -2.39997\n",
      "GaussianMLPValueFunction/dLoss            0.0775607\n",
      "TotalEnvSteps                        189810\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 1.0438e-03, -2.9717e+00, -3.7888e-04,  ..., -8.2943e+00,\n",
      "        -2.4334e+01,  3.0484e+01])\n",
      "2022-08-24 15:57:00 | [trpo_pendulum] epoch #95 | Saving snapshot...\n",
      "2022-08-24 15:57:00 | [trpo_pendulum] epoch #95 | Saved\n",
      "2022-08-24 15:57:00 | [trpo_pendulum] epoch #95 | Time 88.18 s\n",
      "2022-08-24 15:57:00 | [trpo_pendulum] epoch #95 | EpochTime 0.88 s\n",
      "-----------------------------------  ---------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0684614\n",
      "Evaluation/AverageReturn                 -0.593664\n",
      "Evaluation/Iteration                     95\n",
      "Evaluation/MaxReturn                     -0.587013\n",
      "Evaluation/MinReturn                     -0.600314\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00665053\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.26517\n",
      "GaussianMLPPolicy/KL                      0.00725161\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00600077\n",
      "GaussianMLPPolicy/LossBefore             -0.00594397\n",
      "GaussianMLPPolicy/dLoss                   5.6807e-05\n",
      "GaussianMLPValueFunction/LossAfter       -2.70484\n",
      "GaussianMLPValueFunction/LossBefore      -2.41252\n",
      "GaussianMLPValueFunction/dLoss            0.292317\n",
      "TotalEnvSteps                        191808\n",
      "-----------------------------------  ---------------\n",
      "tensor([ 1.9557e-03, -2.9700e+00,  1.5042e-04,  ..., -9.1073e+00,\n",
      "        -2.6803e+01,  3.3253e+01])\n",
      "2022-08-24 15:57:01 | [trpo_pendulum] epoch #96 | Saving snapshot...\n",
      "2022-08-24 15:57:01 | [trpo_pendulum] epoch #96 | Saved\n",
      "2022-08-24 15:57:01 | [trpo_pendulum] epoch #96 | Time 89.08 s\n",
      "2022-08-24 15:57:01 | [trpo_pendulum] epoch #96 | EpochTime 0.89 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0541496\n",
      "Evaluation/AverageReturn                 -0.534514\n",
      "Evaluation/Iteration                     96\n",
      "Evaluation/MaxReturn                     -0.510443\n",
      "Evaluation/MinReturn                     -0.558586\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.0240714\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.33384\n",
      "GaussianMLPPolicy/KL                      0.00657189\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000532962\n",
      "GaussianMLPPolicy/LossBefore             -0.000451399\n",
      "GaussianMLPPolicy/dLoss                   8.15626e-05\n",
      "GaussianMLPValueFunction/LossAfter       -2.78287\n",
      "GaussianMLPValueFunction/LossBefore      -2.71695\n",
      "GaussianMLPValueFunction/dLoss            0.0659196\n",
      "TotalEnvSteps                        193806\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 2.3809e-03,  3.7132e-01,  4.0605e-05,  ...,  1.1164e+00,\n",
      "         3.3084e+00, -4.0745e+00])\n",
      "2022-08-24 15:57:02 | [trpo_pendulum] epoch #97 | Saving snapshot...\n",
      "2022-08-24 15:57:02 | [trpo_pendulum] epoch #97 | Saved\n",
      "2022-08-24 15:57:02 | [trpo_pendulum] epoch #97 | Time 89.96 s\n",
      "2022-08-24 15:57:02 | [trpo_pendulum] epoch #97 | EpochTime 0.88 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0499222\n",
      "Evaluation/AverageReturn                 -0.441505\n",
      "Evaluation/Iteration                     97\n",
      "Evaluation/MaxReturn                     -0.441297\n",
      "Evaluation/MinReturn                     -0.441714\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.000208334\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.4132\n",
      "GaussianMLPPolicy/KL                      0.00666025\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00397485\n",
      "GaussianMLPPolicy/LossBefore             -0.00388551\n",
      "GaussianMLPPolicy/dLoss                   8.93387e-05\n",
      "GaussianMLPValueFunction/LossAfter       -2.87201\n",
      "GaussianMLPValueFunction/LossBefore      -2.67096\n",
      "GaussianMLPValueFunction/dLoss            0.201052\n",
      "TotalEnvSteps                        195804\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 1.0291e-03, -4.6402e+00,  4.5803e-04,  ..., -1.3928e+01,\n",
      "        -4.1299e+01,  5.0842e+01])\n",
      "2022-08-24 15:57:03 | [trpo_pendulum] epoch #98 | Saving snapshot...\n",
      "2022-08-24 15:57:03 | [trpo_pendulum] epoch #98 | Saved\n",
      "2022-08-24 15:57:03 | [trpo_pendulum] epoch #98 | Time 90.88 s\n",
      "2022-08-24 15:57:03 | [trpo_pendulum] epoch #98 | EpochTime 0.91 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0340833\n",
      "Evaluation/AverageReturn                 -0.378024\n",
      "Evaluation/Iteration                     98\n",
      "Evaluation/MaxReturn                     -0.372805\n",
      "Evaluation/MinReturn                     -0.383243\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00521916\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.43816\n",
      "GaussianMLPPolicy/KL                      0.00653289\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.00250562\n",
      "GaussianMLPPolicy/LossBefore             -0.00245032\n",
      "GaussianMLPPolicy/dLoss                   5.52996e-05\n",
      "GaussianMLPValueFunction/LossAfter       -2.99073\n",
      "GaussianMLPValueFunction/LossBefore      -2.85953\n",
      "GaussianMLPValueFunction/dLoss            0.131205\n",
      "TotalEnvSteps                        197802\n",
      "-----------------------------------  ----------------\n",
      "tensor([ 1.2923e-03, -1.7377e+00,  2.0283e-04,  ..., -5.7357e+00,\n",
      "        -1.7000e+01,  2.0765e+01])\n",
      "2022-08-24 15:57:04 | [trpo_pendulum] epoch #99 | Saving snapshot...\n",
      "2022-08-24 15:57:04 | [trpo_pendulum] epoch #99 | Saved\n",
      "2022-08-24 15:57:04 | [trpo_pendulum] epoch #99 | Time 91.77 s\n",
      "2022-08-24 15:57:04 | [trpo_pendulum] epoch #99 | EpochTime 0.88 s\n",
      "-----------------------------------  ----------------\n",
      "Evaluation/AverageDiscountedReturn       -0.0351191\n",
      "Evaluation/AverageReturn                 -0.352999\n",
      "Evaluation/Iteration                     99\n",
      "Evaluation/MaxReturn                     -0.350827\n",
      "Evaluation/MinReturn                     -0.355171\n",
      "Evaluation/NumEpisodes                    2\n",
      "Evaluation/StdReturn                      0.00217201\n",
      "Evaluation/TerminationRate                0\n",
      "GaussianMLPPolicy/Entropy                -1.49588\n",
      "GaussianMLPPolicy/KL                      0.0098928\n",
      "GaussianMLPPolicy/KLBefore                0\n",
      "GaussianMLPPolicy/LossAfter              -0.000286981\n",
      "GaussianMLPPolicy/LossBefore             -0.000239505\n",
      "GaussianMLPPolicy/dLoss                   4.74759e-05\n",
      "GaussianMLPValueFunction/LossAfter       -3.07903\n",
      "GaussianMLPValueFunction/LossBefore      -3.00952\n",
      "GaussianMLPValueFunction/dLoss            0.0695038\n",
      "TotalEnvSteps                        199800\n",
      "-----------------------------------  ----------------\n"
     ]
    }
   ],
   "source": [
    "trpo_pendulum(seed=1234)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}