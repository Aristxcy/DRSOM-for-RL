2022-08-17 18:04:44 | [trpo_pendulum] Logging to d:\Github\DRSOM-for-RL\data/local/experiment/trpo_pendulum_2
2022-08-17 18:04:44 | [trpo_pendulum] Obtaining samples...
2022-08-17 18:04:44 | [trpo_pendulum] epoch #0 | Saving snapshot...
2022-08-17 18:04:44 | [trpo_pendulum] epoch #0 | Saved
2022-08-17 18:04:44 | [trpo_pendulum] epoch #0 | Time 0.66 s
2022-08-17 18:04:44 | [trpo_pendulum] epoch #0 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -781.443
Evaluation/AverageReturn              -1820.62
Evaluation/Iteration                      0
Evaluation/MaxReturn                  -1796.07
Evaluation/MinReturn                  -1831.93
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     11.4397
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41622
GaussianMLPPolicy/KL                      0.00508066
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             255.405
GaussianMLPPolicy/LossBefore            257.089
GaussianMLPPolicy/dLoss                   1.6841
GaussianMLPValueFunction/LossAfter   145473
GaussianMLPValueFunction/LossBefore  161289
GaussianMLPValueFunction/dLoss        15815.8
TotalEnvSteps                          1200
-----------------------------------  ---------------
2022-08-17 18:04:45 | [trpo_pendulum] epoch #1 | Saving snapshot...
2022-08-17 18:04:45 | [trpo_pendulum] epoch #1 | Saved
2022-08-17 18:04:45 | [trpo_pendulum] epoch #1 | Time 1.45 s
2022-08-17 18:04:45 | [trpo_pendulum] epoch #1 | EpochTime 0.78 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -532.452
Evaluation/AverageReturn             -1319.82
Evaluation/Iteration                     1
Evaluation/MaxReturn                 -1293.65
Evaluation/MinReturn                 -1333.23
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    14.7533
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41287
GaussianMLPPolicy/KL                     0.00916445
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            191.179
GaussianMLPPolicy/LossBefore           192.44
GaussianMLPPolicy/dLoss                  1.26132
GaussianMLPValueFunction/LossAfter   76739.8
GaussianMLPValueFunction/LossBefore  83157.6
GaussianMLPValueFunction/dLoss        6417.84
TotalEnvSteps                         2400
-----------------------------------  --------------
2022-08-17 18:04:46 | [trpo_pendulum] epoch #2 | Saving snapshot...
2022-08-17 18:04:46 | [trpo_pendulum] epoch #2 | Saved
2022-08-17 18:04:46 | [trpo_pendulum] epoch #2 | Time 2.16 s
2022-08-17 18:04:46 | [trpo_pendulum] epoch #2 | EpochTime 0.71 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -542.336
Evaluation/AverageReturn             -1224.1
Evaluation/Iteration                     2
Evaluation/MaxReturn                 -1095.93
Evaluation/MinReturn                 -1371.01
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    80.6247
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.40929
GaussianMLPPolicy/KL                     0.00725884
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            166.202
GaussianMLPPolicy/LossBefore           169.018
GaussianMLPPolicy/dLoss                  2.81534
GaussianMLPValueFunction/LossAfter   55877.4
GaussianMLPValueFunction/LossBefore  59541.9
GaussianMLPValueFunction/dLoss        3664.51
TotalEnvSteps                         3600
-----------------------------------  --------------
2022-08-17 18:04:47 | [trpo_pendulum] epoch #3 | Saving snapshot...
2022-08-17 18:04:47 | [trpo_pendulum] epoch #3 | Saved
2022-08-17 18:04:47 | [trpo_pendulum] epoch #3 | Time 2.83 s
2022-08-17 18:04:47 | [trpo_pendulum] epoch #3 | EpochTime 0.66 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn    -561.206
Evaluation/AverageReturn             -1249.46
Evaluation/Iteration                     3
Evaluation/MaxReturn                 -1162.38
Evaluation/MinReturn                 -1428.41
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    84.8067
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.43097
GaussianMLPPolicy/KL                     0.0093822
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            166.754
GaussianMLPPolicy/LossBefore           169.97
GaussianMLPPolicy/dLoss                  3.21602
GaussianMLPValueFunction/LossAfter   53345.4
GaussianMLPValueFunction/LossBefore  57452.1
GaussianMLPValueFunction/dLoss        4106.71
TotalEnvSteps                         4800
-----------------------------------  -------------
2022-08-17 18:04:47 | [trpo_pendulum] epoch #4 | Saving snapshot...
2022-08-17 18:04:47 | [trpo_pendulum] epoch #4 | Saved
2022-08-17 18:04:47 | [trpo_pendulum] epoch #4 | Time 3.48 s
2022-08-17 18:04:47 | [trpo_pendulum] epoch #4 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -526.13
Evaluation/AverageReturn             -1283.49
Evaluation/Iteration                     4
Evaluation/MaxReturn                 -1213.03
Evaluation/MinReturn                 -1328.04
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    42.7216
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.44805
GaussianMLPPolicy/KL                     0.00913798
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            179.277
GaussianMLPPolicy/LossBefore           181.986
GaussianMLPPolicy/dLoss                  2.70923
GaussianMLPValueFunction/LossAfter   58251.1
GaussianMLPValueFunction/LossBefore  63407.3
GaussianMLPValueFunction/dLoss        5156.2
TotalEnvSteps                         6000
-----------------------------------  --------------
2022-08-17 18:04:48 | [trpo_pendulum] epoch #5 | Saving snapshot...
2022-08-17 18:04:48 | [trpo_pendulum] epoch #5 | Saved
2022-08-17 18:04:48 | [trpo_pendulum] epoch #5 | Time 4.11 s
2022-08-17 18:04:48 | [trpo_pendulum] epoch #5 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -481.6
Evaluation/AverageReturn             -1180.66
Evaluation/Iteration                     5
Evaluation/MaxReturn                 -1052.62
Evaluation/MinReturn                 -1257.43
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    78.3684
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41102
GaussianMLPPolicy/KL                     0.00720053
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            166.498
GaussianMLPPolicy/LossBefore           168.005
GaussianMLPPolicy/dLoss                  1.50748
GaussianMLPValueFunction/LossAfter   46348.8
GaussianMLPValueFunction/LossBefore  50635.2
GaussianMLPValueFunction/dLoss        4286.43
TotalEnvSteps                         7200
-----------------------------------  --------------
2022-08-17 18:04:48 | [trpo_pendulum] epoch #6 | Saving snapshot...
2022-08-17 18:04:48 | [trpo_pendulum] epoch #6 | Saved
2022-08-17 18:04:48 | [trpo_pendulum] epoch #6 | Time 4.74 s
2022-08-17 18:04:48 | [trpo_pendulum] epoch #6 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -735.861
Evaluation/AverageReturn             -1713.64
Evaluation/Iteration                     6
Evaluation/MaxReturn                 -1391.33
Evaluation/MinReturn                 -1851.08
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   154.393
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42396
GaussianMLPPolicy/KL                     0.00702261
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            233.276
GaussianMLPPolicy/LossBefore           235.395
GaussianMLPPolicy/dLoss                  2.11879
GaussianMLPValueFunction/LossAfter   82565.3
GaussianMLPValueFunction/LossBefore  92798.3
GaussianMLPValueFunction/dLoss       10233
TotalEnvSteps                         8400
-----------------------------------  --------------
2022-08-17 18:04:49 | [trpo_pendulum] epoch #7 | Saving snapshot...
2022-08-17 18:04:49 | [trpo_pendulum] epoch #7 | Saved
2022-08-17 18:04:49 | [trpo_pendulum] epoch #7 | Time 5.37 s
2022-08-17 18:04:49 | [trpo_pendulum] epoch #7 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -448.465
Evaluation/AverageReturn             -1133.73
Evaluation/Iteration                     7
Evaluation/MaxReturn                 -1005.34
Evaluation/MinReturn                 -1204.99
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    67.4442
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.4064
GaussianMLPPolicy/KL                     0.00801691
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            157.089
GaussianMLPPolicy/LossBefore           159.188
GaussianMLPPolicy/dLoss                  2.09914
GaussianMLPValueFunction/LossAfter   36486.3
GaussianMLPValueFunction/LossBefore  38944.3
GaussianMLPValueFunction/dLoss        2458.08
TotalEnvSteps                         9600
-----------------------------------  --------------
2022-08-17 18:04:50 | [trpo_pendulum] epoch #8 | Saving snapshot...
2022-08-17 18:04:50 | [trpo_pendulum] epoch #8 | Saved
2022-08-17 18:04:50 | [trpo_pendulum] epoch #8 | Time 6.04 s
2022-08-17 18:04:50 | [trpo_pendulum] epoch #8 | EpochTime 0.67 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -677.424
Evaluation/AverageReturn             -1576.27
Evaluation/Iteration                     8
Evaluation/MaxReturn                 -1198.93
Evaluation/MinReturn                 -1722.37
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   181.82
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.38821
GaussianMLPPolicy/KL                     0.00671731
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            211.668
GaussianMLPPolicy/LossBefore           213.956
GaussianMLPPolicy/dLoss                  2.28836
GaussianMLPValueFunction/LossAfter   60507.7
GaussianMLPValueFunction/LossBefore  66303.6
GaussianMLPValueFunction/dLoss        5795.84
TotalEnvSteps                        10800
-----------------------------------  --------------
2022-08-17 18:04:50 | [trpo_pendulum] epoch #9 | Saving snapshot...
2022-08-17 18:04:50 | [trpo_pendulum] epoch #9 | Saved
2022-08-17 18:04:50 | [trpo_pendulum] epoch #9 | Time 6.67 s
2022-08-17 18:04:50 | [trpo_pendulum] epoch #9 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -457.391
Evaluation/AverageReturn             -1165.8
Evaluation/Iteration                     9
Evaluation/MaxReturn                 -1078.72
Evaluation/MinReturn                 -1210.65
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    49.8502
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.376
GaussianMLPPolicy/KL                     0.00431574
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            164.037
GaussianMLPPolicy/LossBefore           164.795
GaussianMLPPolicy/dLoss                  0.757385
GaussianMLPValueFunction/LossAfter   34002.8
GaussianMLPValueFunction/LossBefore  36162.9
GaussianMLPValueFunction/dLoss        2160.09
TotalEnvSteps                        12000
-----------------------------------  --------------
2022-08-17 18:04:51 | [trpo_pendulum] epoch #10 | Saving snapshot...
2022-08-17 18:04:51 | [trpo_pendulum] epoch #10 | Saved
2022-08-17 18:04:51 | [trpo_pendulum] epoch #10 | Time 7.33 s
2022-08-17 18:04:51 | [trpo_pendulum] epoch #10 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -548.641
Evaluation/AverageReturn             -1309.99
Evaluation/Iteration                    10
Evaluation/MaxReturn                 -1220.24
Evaluation/MinReturn                 -1342.36
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    41.0997
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.37665
GaussianMLPPolicy/KL                     0.00600999
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            177.319
GaussianMLPPolicy/LossBefore           178.022
GaussianMLPPolicy/dLoss                  0.702332
GaussianMLPValueFunction/LossAfter   36888.9
GaussianMLPValueFunction/LossBefore  39378.1
GaussianMLPValueFunction/dLoss        2489.21
TotalEnvSteps                        13200
-----------------------------------  --------------
2022-08-17 18:04:52 | [trpo_pendulum] epoch #11 | Saving snapshot...
2022-08-17 18:04:52 | [trpo_pendulum] epoch #11 | Saved
2022-08-17 18:04:52 | [trpo_pendulum] epoch #11 | Time 7.96 s
2022-08-17 18:04:52 | [trpo_pendulum] epoch #11 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -499.512
Evaluation/AverageReturn             -1226.08
Evaluation/Iteration                    11
Evaluation/MaxReturn                 -1146.31
Evaluation/MinReturn                 -1274.16
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    53.067
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.3788
GaussianMLPPolicy/KL                     0.00626133
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            165.204
GaussianMLPPolicy/LossBefore           167.575
GaussianMLPPolicy/dLoss                  2.37154
GaussianMLPValueFunction/LossAfter   30802.6
GaussianMLPValueFunction/LossBefore  33343.1
GaussianMLPValueFunction/dLoss        2540.43
TotalEnvSteps                        14400
-----------------------------------  --------------
2022-08-17 18:04:52 | [trpo_pendulum] epoch #12 | Saving snapshot...
2022-08-17 18:04:52 | [trpo_pendulum] epoch #12 | Saved
2022-08-17 18:04:52 | [trpo_pendulum] epoch #12 | Time 8.57 s
2022-08-17 18:04:52 | [trpo_pendulum] epoch #12 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -565.061
Evaluation/AverageReturn             -1244.87
Evaluation/Iteration                    12
Evaluation/MaxReturn                 -1125.81
Evaluation/MinReturn                 -1367.49
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    91.7845
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.4086
GaussianMLPPolicy/KL                     0.00976514
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            156.952
GaussianMLPPolicy/LossBefore           160.224
GaussianMLPPolicy/dLoss                  3.27231
GaussianMLPValueFunction/LossAfter   27195.8
GaussianMLPValueFunction/LossBefore  28768.6
GaussianMLPValueFunction/dLoss        1572.79
TotalEnvSteps                        15600
-----------------------------------  --------------
2022-08-17 18:04:53 | [trpo_pendulum] epoch #13 | Saving snapshot...
2022-08-17 18:04:53 | [trpo_pendulum] epoch #13 | Saved
2022-08-17 18:04:53 | [trpo_pendulum] epoch #13 | Time 9.20 s
2022-08-17 18:04:53 | [trpo_pendulum] epoch #13 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -721.17
Evaluation/AverageReturn             -1659.11
Evaluation/Iteration                    13
Evaluation/MaxReturn                 -1581.58
Evaluation/MinReturn                 -1704.02
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    47.7599
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42562
GaussianMLPPolicy/KL                     0.00757263
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            218.879
GaussianMLPPolicy/LossBefore           221.474
GaussianMLPPolicy/dLoss                  2.59563
GaussianMLPValueFunction/LossAfter   46967.9
GaussianMLPValueFunction/LossBefore  51679.5
GaussianMLPValueFunction/dLoss        4711.66
TotalEnvSteps                        16800
-----------------------------------  --------------
2022-08-17 18:04:54 | [trpo_pendulum] epoch #14 | Saving snapshot...
2022-08-17 18:04:54 | [trpo_pendulum] epoch #14 | Saved
2022-08-17 18:04:54 | [trpo_pendulum] epoch #14 | Time 9.82 s
2022-08-17 18:04:54 | [trpo_pendulum] epoch #14 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -671.706
Evaluation/AverageReturn             -1507.86
Evaluation/Iteration                    14
Evaluation/MaxReturn                 -1349.66
Evaluation/MinReturn                 -1709.33
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   144.27
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.38411
GaussianMLPPolicy/KL                     0.00686711
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            194.485
GaussianMLPPolicy/LossBefore           196.813
GaussianMLPPolicy/dLoss                  2.32852
GaussianMLPValueFunction/LossAfter   34982.4
GaussianMLPValueFunction/LossBefore  37737.1
GaussianMLPValueFunction/dLoss        2754.68
TotalEnvSteps                        18000
-----------------------------------  --------------
2022-08-17 18:04:54 | [trpo_pendulum] epoch #15 | Saving snapshot...
2022-08-17 18:04:54 | [trpo_pendulum] epoch #15 | Saved
2022-08-17 18:04:54 | [trpo_pendulum] epoch #15 | Time 10.44 s
2022-08-17 18:04:54 | [trpo_pendulum] epoch #15 | EpochTime 0.61 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn    -537.621
Evaluation/AverageReturn             -1287.03
Evaluation/Iteration                    15
Evaluation/MaxReturn                 -1265.39
Evaluation/MinReturn                 -1338.29
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    27.8083
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.35119
GaussianMLPPolicy/KL                     0.0077006
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            168.408
GaussianMLPPolicy/LossBefore           170.035
GaussianMLPPolicy/dLoss                  1.62628
GaussianMLPValueFunction/LossAfter   24902.9
GaussianMLPValueFunction/LossBefore  26417.8
GaussianMLPValueFunction/dLoss        1514.87
TotalEnvSteps                        19200
-----------------------------------  -------------
2022-08-17 18:04:55 | [trpo_pendulum] epoch #16 | Saving snapshot...
2022-08-17 18:04:55 | [trpo_pendulum] epoch #16 | Saved
2022-08-17 18:04:55 | [trpo_pendulum] epoch #16 | Time 11.08 s
2022-08-17 18:04:55 | [trpo_pendulum] epoch #16 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -639.499
Evaluation/AverageReturn             -1447.15
Evaluation/Iteration                    16
Evaluation/MaxReturn                 -1288.58
Evaluation/MinReturn                 -1613.4
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   117.946
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.35843
GaussianMLPPolicy/KL                     0.00755162
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            185.128
GaussianMLPPolicy/LossBefore           188.041
GaussianMLPPolicy/dLoss                  2.91229
GaussianMLPValueFunction/LossAfter   28379.6
GaussianMLPValueFunction/LossBefore  30383.3
GaussianMLPValueFunction/dLoss        2003.62
TotalEnvSteps                        20400
-----------------------------------  --------------
2022-08-17 18:04:55 | [trpo_pendulum] epoch #17 | Saving snapshot...
2022-08-17 18:04:55 | [trpo_pendulum] epoch #17 | Saved
2022-08-17 18:04:55 | [trpo_pendulum] epoch #17 | Time 11.71 s
2022-08-17 18:04:55 | [trpo_pendulum] epoch #17 | EpochTime 0.63 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn    -575.304
Evaluation/AverageReturn             -1342.98
Evaluation/Iteration                    17
Evaluation/MaxReturn                 -1310.57
Evaluation/MinReturn                 -1373.61
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    18.6035
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.33391
GaussianMLPPolicy/KL                     0.0068331
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            175.456
GaussianMLPPolicy/LossBefore           176.829
GaussianMLPPolicy/dLoss                  1.37369
GaussianMLPValueFunction/LossAfter   23713.2
GaussianMLPValueFunction/LossBefore  25229.2
GaussianMLPValueFunction/dLoss        1515.97
TotalEnvSteps                        21600
-----------------------------------  -------------
2022-08-17 18:04:56 | [trpo_pendulum] epoch #18 | Saving snapshot...
2022-08-17 18:04:56 | [trpo_pendulum] epoch #18 | Saved
2022-08-17 18:04:56 | [trpo_pendulum] epoch #18 | Time 12.34 s
2022-08-17 18:04:56 | [trpo_pendulum] epoch #18 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -722.552
Evaluation/AverageReturn             -1666.12
Evaluation/Iteration                    18
Evaluation/MaxReturn                 -1658.58
Evaluation/MinReturn                 -1671.89
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     4.25628
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.33189
GaussianMLPPolicy/KL                     0.00745881
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            217.767
GaussianMLPPolicy/LossBefore           219.541
GaussianMLPPolicy/dLoss                  1.77423
GaussianMLPValueFunction/LossAfter   33408.3
GaussianMLPValueFunction/LossBefore  36454.9
GaussianMLPValueFunction/dLoss        3046.6
TotalEnvSteps                        22800
-----------------------------------  --------------
2022-08-17 18:04:57 | [trpo_pendulum] epoch #19 | Saving snapshot...
2022-08-17 18:04:57 | [trpo_pendulum] epoch #19 | Saved
2022-08-17 18:04:57 | [trpo_pendulum] epoch #19 | Time 12.96 s
2022-08-17 18:04:57 | [trpo_pendulum] epoch #19 | EpochTime 0.62 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn    -614.065
Evaluation/AverageReturn             -1463.78
Evaluation/Iteration                    19
Evaluation/MaxReturn                 -1392.12
Evaluation/MinReturn                 -1484.26
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    32.3789
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.32768
GaussianMLPPolicy/KL                     0.0085652
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            193.13
GaussianMLPPolicy/LossBefore           195.022
GaussianMLPPolicy/dLoss                  1.89209
GaussianMLPValueFunction/LossAfter   24709
GaussianMLPValueFunction/LossBefore  26486.5
GaussianMLPValueFunction/dLoss        1777.53
TotalEnvSteps                        24000
-----------------------------------  -------------
2022-08-17 18:04:57 | [trpo_pendulum] epoch #20 | Saving snapshot...
2022-08-17 18:04:57 | [trpo_pendulum] epoch #20 | Saved
2022-08-17 18:04:57 | [trpo_pendulum] epoch #20 | Time 13.59 s
2022-08-17 18:04:57 | [trpo_pendulum] epoch #20 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -651.616
Evaluation/AverageReturn             -1533.8
Evaluation/Iteration                    20
Evaluation/MaxReturn                 -1303.57
Evaluation/MinReturn                 -1667.75
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   156.554
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.31191
GaussianMLPPolicy/KL                     0.00837117
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            197.874
GaussianMLPPolicy/LossBefore           201.74
GaussianMLPPolicy/dLoss                  3.86555
GaussianMLPValueFunction/LossAfter   25172.1
GaussianMLPValueFunction/LossBefore  27073.8
GaussianMLPValueFunction/dLoss        1901.75
TotalEnvSteps                        25200
-----------------------------------  --------------
2022-08-17 18:04:58 | [trpo_pendulum] epoch #21 | Saving snapshot...
2022-08-17 18:04:58 | [trpo_pendulum] epoch #21 | Saved
2022-08-17 18:04:58 | [trpo_pendulum] epoch #21 | Time 14.25 s
2022-08-17 18:04:58 | [trpo_pendulum] epoch #21 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -581.433
Evaluation/AverageReturn             -1405.34
Evaluation/Iteration                    21
Evaluation/MaxReturn                 -1354.73
Evaluation/MinReturn                 -1462.48
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    36.2653
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.30693
GaussianMLPPolicy/KL                     0.00986008
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            184.582
GaussianMLPPolicy/LossBefore           186.613
GaussianMLPPolicy/dLoss                  2.03114
GaussianMLPValueFunction/LossAfter   20245
GaussianMLPValueFunction/LossBefore  21558.7
GaussianMLPValueFunction/dLoss        1313.72
TotalEnvSteps                        26400
-----------------------------------  --------------
2022-08-17 18:04:59 | [trpo_pendulum] epoch #22 | Saving snapshot...
2022-08-17 18:04:59 | [trpo_pendulum] epoch #22 | Saved
2022-08-17 18:04:59 | [trpo_pendulum] epoch #22 | Time 14.88 s
2022-08-17 18:04:59 | [trpo_pendulum] epoch #22 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -565.326
Evaluation/AverageReturn             -1369.19
Evaluation/Iteration                    22
Evaluation/MaxReturn                 -1344.96
Evaluation/MinReturn                 -1436.66
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    33.2707
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.3025
GaussianMLPPolicy/KL                     0.00816652
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            181.434
GaussianMLPPolicy/LossBefore           182.618
GaussianMLPPolicy/dLoss                  1.18451
GaussianMLPValueFunction/LossAfter   18330
GaussianMLPValueFunction/LossBefore  19467.7
GaussianMLPValueFunction/dLoss        1137.69
TotalEnvSteps                        27600
-----------------------------------  --------------
2022-08-17 18:04:59 | [trpo_pendulum] epoch #23 | Saving snapshot...
2022-08-17 18:04:59 | [trpo_pendulum] epoch #23 | Saved
2022-08-17 18:04:59 | [trpo_pendulum] epoch #23 | Time 15.49 s
2022-08-17 18:04:59 | [trpo_pendulum] epoch #23 | EpochTime 0.61 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn    -559.053
Evaluation/AverageReturn             -1337.66
Evaluation/Iteration                    23
Evaluation/MaxReturn                 -1317.72
Evaluation/MinReturn                 -1356.9
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    14.0517
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.29153
GaussianMLPPolicy/KL                     0.0099557
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            174.712
GaussianMLPPolicy/LossBefore           175.564
GaussianMLPPolicy/dLoss                  0.852112
GaussianMLPValueFunction/LossAfter   16044.7
GaussianMLPValueFunction/LossBefore  16979.2
GaussianMLPValueFunction/dLoss         934.525
TotalEnvSteps                        28800
-----------------------------------  -------------
2022-08-17 18:05:00 | [trpo_pendulum] epoch #24 | Saving snapshot...
2022-08-17 18:05:00 | [trpo_pendulum] epoch #24 | Saved
2022-08-17 18:05:00 | [trpo_pendulum] epoch #24 | Time 16.12 s
2022-08-17 18:05:00 | [trpo_pendulum] epoch #24 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -554.398
Evaluation/AverageReturn             -1327.84
Evaluation/Iteration                    24
Evaluation/MaxReturn                 -1224.27
Evaluation/MinReturn                 -1364.11
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    47.6523
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.2994
GaussianMLPPolicy/KL                     0.00895109
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            169.434
GaussianMLPPolicy/LossBefore           171.395
GaussianMLPPolicy/dLoss                  1.96071
GaussianMLPValueFunction/LossAfter   14666.8
GaussianMLPValueFunction/LossBefore  15507
GaussianMLPValueFunction/dLoss         840.248
TotalEnvSteps                        30000
-----------------------------------  --------------
2022-08-17 18:05:00 | [trpo_pendulum] epoch #25 | Saving snapshot...
2022-08-17 18:05:00 | [trpo_pendulum] epoch #25 | Saved
2022-08-17 18:05:00 | [trpo_pendulum] epoch #25 | Time 16.74 s
2022-08-17 18:05:00 | [trpo_pendulum] epoch #25 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -533.196
Evaluation/AverageReturn             -1274.12
Evaluation/Iteration                    25
Evaluation/MaxReturn                 -1153.2
Evaluation/MinReturn                 -1311.08
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    56.323
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.27868
GaussianMLPPolicy/KL                     0.00935154
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            159.43
GaussianMLPPolicy/LossBefore           163.474
GaussianMLPPolicy/dLoss                  4.04419
GaussianMLPValueFunction/LossAfter   12738.9
GaussianMLPValueFunction/LossBefore  13419.6
GaussianMLPValueFunction/dLoss         680.653
TotalEnvSteps                        31200
-----------------------------------  --------------
2022-08-17 18:05:01 | [trpo_pendulum] epoch #26 | Saving snapshot...
2022-08-17 18:05:01 | [trpo_pendulum] epoch #26 | Saved
2022-08-17 18:05:01 | [trpo_pendulum] epoch #26 | Time 17.34 s
2022-08-17 18:05:01 | [trpo_pendulum] epoch #26 | EpochTime 0.60 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn    -658.8
Evaluation/AverageReturn             -1540.47
Evaluation/Iteration                    26
Evaluation/MaxReturn                 -1524.4
Evaluation/MinReturn                 -1559.18
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    10.6226
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.32464
GaussianMLPPolicy/KL                     0.0079823
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            196.372
GaussianMLPPolicy/LossBefore           200.018
GaussianMLPPolicy/dLoss                  3.64636
GaussianMLPValueFunction/LossAfter   17547.4
GaussianMLPValueFunction/LossBefore  18878.4
GaussianMLPValueFunction/dLoss        1331.04
TotalEnvSteps                        32400
-----------------------------------  -------------
2022-08-17 18:05:02 | [trpo_pendulum] epoch #27 | Saving snapshot...
2022-08-17 18:05:02 | [trpo_pendulum] epoch #27 | Saved
2022-08-17 18:05:02 | [trpo_pendulum] epoch #27 | Time 17.97 s
2022-08-17 18:05:02 | [trpo_pendulum] epoch #27 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -684.242
Evaluation/AverageReturn             -1572.28
Evaluation/Iteration                    27
Evaluation/MaxReturn                 -1558.26
Evaluation/MinReturn                 -1580.33
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     7.30813
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.33092
GaussianMLPPolicy/KL                     0.00879141
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            199.96
GaussianMLPPolicy/LossBefore           201.72
GaussianMLPPolicy/dLoss                  1.7608
GaussianMLPValueFunction/LossAfter   16592.2
GaussianMLPValueFunction/LossBefore  17856.7
GaussianMLPValueFunction/dLoss        1264.46
TotalEnvSteps                        33600
-----------------------------------  --------------
2022-08-17 18:05:02 | [trpo_pendulum] epoch #28 | Saving snapshot...
2022-08-17 18:05:02 | [trpo_pendulum] epoch #28 | Saved
2022-08-17 18:05:02 | [trpo_pendulum] epoch #28 | Time 18.61 s
2022-08-17 18:05:02 | [trpo_pendulum] epoch #28 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -675.904
Evaluation/AverageReturn             -1567.09
Evaluation/Iteration                    28
Evaluation/MaxReturn                 -1554.11
Evaluation/MinReturn                 -1578.89
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     7.80244
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.3571
GaussianMLPPolicy/KL                     0.00867829
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            198.851
GaussianMLPPolicy/LossBefore           201.471
GaussianMLPPolicy/dLoss                  2.6196
GaussianMLPValueFunction/LossAfter   15536.4
GaussianMLPValueFunction/LossBefore  16691.3
GaussianMLPValueFunction/dLoss        1154.95
TotalEnvSteps                        34800
-----------------------------------  --------------
2022-08-17 18:05:03 | [trpo_pendulum] epoch #29 | Saving snapshot...
2022-08-17 18:05:03 | [trpo_pendulum] epoch #29 | Saved
2022-08-17 18:05:03 | [trpo_pendulum] epoch #29 | Time 19.26 s
2022-08-17 18:05:03 | [trpo_pendulum] epoch #29 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -682.027
Evaluation/AverageReturn             -1563.9
Evaluation/Iteration                    29
Evaluation/MaxReturn                 -1557.54
Evaluation/MinReturn                 -1575.54
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     6.53228
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.37498
GaussianMLPPolicy/KL                     0.00797219
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            198.226
GaussianMLPPolicy/LossBefore           198.772
GaussianMLPPolicy/dLoss                  0.546051
GaussianMLPValueFunction/LossAfter   14149.5
GaussianMLPValueFunction/LossBefore  15159
GaussianMLPValueFunction/dLoss        1009.53
TotalEnvSteps                        36000
-----------------------------------  --------------
2022-08-17 18:05:04 | [trpo_pendulum] epoch #30 | Saving snapshot...
2022-08-17 18:05:04 | [trpo_pendulum] epoch #30 | Saved
2022-08-17 18:05:04 | [trpo_pendulum] epoch #30 | Time 19.89 s
2022-08-17 18:05:04 | [trpo_pendulum] epoch #30 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -678.814
Evaluation/AverageReturn             -1574.75
Evaluation/Iteration                    30
Evaluation/MaxReturn                 -1564.79
Evaluation/MinReturn                 -1585.21
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     7.34288
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.34524
GaussianMLPPolicy/KL                     0.00646464
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            199.492
GaussianMLPPolicy/LossBefore           201.838
GaussianMLPPolicy/dLoss                  2.34605
GaussianMLPValueFunction/LossAfter   13672.9
GaussianMLPValueFunction/LossBefore  14661.9
GaussianMLPValueFunction/dLoss         988.919
TotalEnvSteps                        37200
-----------------------------------  --------------
2022-08-17 18:05:04 | [trpo_pendulum] epoch #31 | Saving snapshot...
2022-08-17 18:05:04 | [trpo_pendulum] epoch #31 | Saved
2022-08-17 18:05:04 | [trpo_pendulum] epoch #31 | Time 20.51 s
2022-08-17 18:05:04 | [trpo_pendulum] epoch #31 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -645.295
Evaluation/AverageReturn             -1532.36
Evaluation/Iteration                    31
Evaluation/MaxReturn                 -1516.24
Evaluation/MinReturn                 -1542.85
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     8.69484
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.34177
GaussianMLPPolicy/KL                     0.00963607
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            194.883
GaussianMLPPolicy/LossBefore           198.069
GaussianMLPPolicy/dLoss                  3.1857
GaussianMLPValueFunction/LossAfter   12450.7
GaussianMLPValueFunction/LossBefore  13315.4
GaussianMLPValueFunction/dLoss         864.734
TotalEnvSteps                        38400
-----------------------------------  --------------
2022-08-17 18:05:05 | [trpo_pendulum] epoch #32 | Saving snapshot...
2022-08-17 18:05:05 | [trpo_pendulum] epoch #32 | Saved
2022-08-17 18:05:05 | [trpo_pendulum] epoch #32 | Time 21.14 s
2022-08-17 18:05:05 | [trpo_pendulum] epoch #32 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -497.587
Evaluation/AverageReturn             -1348.63
Evaluation/Iteration                    32
Evaluation/MaxReturn                 -1169.37
Evaluation/MinReturn                 -1390.81
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    80.3691
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.34874
GaussianMLPPolicy/KL                     0.00769049
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            180.714
GaussianMLPPolicy/LossBefore           183.749
GaussianMLPPolicy/dLoss                  3.03432
GaussianMLPValueFunction/LossAfter   10478.3
GaussianMLPValueFunction/LossBefore  11130.8
GaussianMLPValueFunction/dLoss         652.534
TotalEnvSteps                        39600
-----------------------------------  --------------
2022-08-17 18:05:05 | [trpo_pendulum] epoch #33 | Saving snapshot...
2022-08-17 18:05:05 | [trpo_pendulum] epoch #33 | Saved
2022-08-17 18:05:05 | [trpo_pendulum] epoch #33 | Time 21.75 s
2022-08-17 18:05:05 | [trpo_pendulum] epoch #33 | EpochTime 0.60 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -601.387
Evaluation/AverageReturn             -1478.35
Evaluation/Iteration                    33
Evaluation/MaxReturn                 -1471.64
Evaluation/MinReturn                 -1494.81
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     8.08195
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.37273
GaussianMLPPolicy/KL                     0.00975692
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            189.949
GaussianMLPPolicy/LossBefore           193.537
GaussianMLPPolicy/dLoss                  3.58847
GaussianMLPValueFunction/LossAfter   10665.2
GaussianMLPValueFunction/LossBefore  11374
GaussianMLPValueFunction/dLoss         708.809
TotalEnvSteps                        40800
-----------------------------------  --------------
2022-08-17 18:05:06 | [trpo_pendulum] epoch #34 | Saving snapshot...
2022-08-17 18:05:06 | [trpo_pendulum] epoch #34 | Saved
2022-08-17 18:05:06 | [trpo_pendulum] epoch #34 | Time 22.37 s
2022-08-17 18:05:06 | [trpo_pendulum] epoch #34 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -680.649
Evaluation/AverageReturn             -1576.66
Evaluation/Iteration                    34
Evaluation/MaxReturn                 -1570.14
Evaluation/MinReturn                 -1583.36
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     5.26941
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.35604
GaussianMLPPolicy/KL                     0.00773859
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            197.375
GaussianMLPPolicy/LossBefore           200.152
GaussianMLPPolicy/dLoss                  2.77657
GaussianMLPValueFunction/LossAfter   10574
GaussianMLPValueFunction/LossBefore  11310.7
GaussianMLPValueFunction/dLoss         736.71
TotalEnvSteps                        42000
-----------------------------------  --------------
2022-08-17 18:05:07 | [trpo_pendulum] epoch #35 | Saving snapshot...
2022-08-17 18:05:07 | [trpo_pendulum] epoch #35 | Saved
2022-08-17 18:05:07 | [trpo_pendulum] epoch #35 | Time 22.99 s
2022-08-17 18:05:07 | [trpo_pendulum] epoch #35 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -612.104
Evaluation/AverageReturn             -1484.75
Evaluation/Iteration                    35
Evaluation/MaxReturn                 -1454.98
Evaluation/MinReturn                 -1524.49
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    24.8385
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.35083
GaussianMLPPolicy/KL                     0.00729163
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            187.557
GaussianMLPPolicy/LossBefore           190.853
GaussianMLPPolicy/dLoss                  3.2959
GaussianMLPValueFunction/LossAfter    9205.62
GaussianMLPValueFunction/LossBefore   9801.07
GaussianMLPValueFunction/dLoss         595.45
TotalEnvSteps                        43200
-----------------------------------  --------------
2022-08-17 18:05:07 | [trpo_pendulum] epoch #36 | Saving snapshot...
2022-08-17 18:05:07 | [trpo_pendulum] epoch #36 | Saved
2022-08-17 18:05:07 | [trpo_pendulum] epoch #36 | Time 23.61 s
2022-08-17 18:05:07 | [trpo_pendulum] epoch #36 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -641.136
Evaluation/AverageReturn             -1530.61
Evaluation/Iteration                    36
Evaluation/MaxReturn                 -1496.72
Evaluation/MinReturn                 -1564.6
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    21.038
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.34025
GaussianMLPPolicy/KL                     0.00636631
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            193.185
GaussianMLPPolicy/LossBefore           195.803
GaussianMLPPolicy/dLoss                  2.61821
GaussianMLPValueFunction/LossAfter    9083.47
GaussianMLPValueFunction/LossBefore   9692.86
GaussianMLPValueFunction/dLoss         609.387
TotalEnvSteps                        44400
-----------------------------------  --------------
2022-08-17 18:05:08 | [trpo_pendulum] epoch #37 | Saving snapshot...
2022-08-17 18:05:08 | [trpo_pendulum] epoch #37 | Saved
2022-08-17 18:05:08 | [trpo_pendulum] epoch #37 | Time 24.22 s
2022-08-17 18:05:08 | [trpo_pendulum] epoch #37 | EpochTime 0.60 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -598.332
Evaluation/AverageReturn             -1470.71
Evaluation/Iteration                    37
Evaluation/MaxReturn                 -1450.5
Evaluation/MinReturn                 -1493.36
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    16.9856
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.33452
GaussianMLPPolicy/KL                     0.00739906
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            186.077
GaussianMLPPolicy/LossBefore           189.004
GaussianMLPPolicy/dLoss                  2.92757
GaussianMLPValueFunction/LossAfter    8075.44
GaussianMLPValueFunction/LossBefore   8588.84
GaussianMLPValueFunction/dLoss         513.4
TotalEnvSteps                        45600
-----------------------------------  --------------
2022-08-17 18:05:09 | [trpo_pendulum] epoch #38 | Saving snapshot...
2022-08-17 18:05:09 | [trpo_pendulum] epoch #38 | Saved
2022-08-17 18:05:09 | [trpo_pendulum] epoch #38 | Time 24.84 s
2022-08-17 18:05:09 | [trpo_pendulum] epoch #38 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -600.012
Evaluation/AverageReturn             -1479.95
Evaluation/Iteration                    38
Evaluation/MaxReturn                 -1466.16
Evaluation/MinReturn                 -1499.81
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    10.6239
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.3292
GaussianMLPPolicy/KL                     0.00879991
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            187.519
GaussianMLPPolicy/LossBefore           190.515
GaussianMLPPolicy/dLoss                  2.99557
GaussianMLPValueFunction/LossAfter    7739.6
GaussianMLPValueFunction/LossBefore   8238.61
GaussianMLPValueFunction/dLoss         499.01
TotalEnvSteps                        46800
-----------------------------------  --------------
2022-08-17 18:05:09 | [trpo_pendulum] epoch #39 | Saving snapshot...
2022-08-17 18:05:09 | [trpo_pendulum] epoch #39 | Saved
2022-08-17 18:05:09 | [trpo_pendulum] epoch #39 | Time 25.48 s
2022-08-17 18:05:09 | [trpo_pendulum] epoch #39 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -562.133
Evaluation/AverageReturn             -1441.11
Evaluation/Iteration                    39
Evaluation/MaxReturn                 -1419.94
Evaluation/MinReturn                 -1467.11
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    14.3128
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.32987
GaussianMLPPolicy/KL                     0.00663558
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            186.95
GaussianMLPPolicy/LossBefore           189.794
GaussianMLPPolicy/dLoss                  2.84383
GaussianMLPValueFunction/LossAfter    7257.11
GaussianMLPValueFunction/LossBefore   7722.98
GaussianMLPValueFunction/dLoss         465.871
TotalEnvSteps                        48000
-----------------------------------  --------------
2022-08-17 18:05:10 | [trpo_pendulum] epoch #40 | Saving snapshot...
2022-08-17 18:05:10 | [trpo_pendulum] epoch #40 | Saved
2022-08-17 18:05:10 | [trpo_pendulum] epoch #40 | Time 26.11 s
2022-08-17 18:05:10 | [trpo_pendulum] epoch #40 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -658.848
Evaluation/AverageReturn             -1552.31
Evaluation/Iteration                    40
Evaluation/MaxReturn                 -1540.96
Evaluation/MinReturn                 -1566.48
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     7.78932
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.35238
GaussianMLPPolicy/KL                     0.00707211
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            193.098
GaussianMLPPolicy/LossBefore           195.711
GaussianMLPPolicy/dLoss                  2.61293
GaussianMLPValueFunction/LossAfter    7169.34
GaussianMLPValueFunction/LossBefore   7648.85
GaussianMLPValueFunction/dLoss         479.519
TotalEnvSteps                        49200
-----------------------------------  --------------
2022-08-17 18:05:10 | [trpo_pendulum] epoch #41 | Saving snapshot...
2022-08-17 18:05:10 | [trpo_pendulum] epoch #41 | Saved
2022-08-17 18:05:10 | [trpo_pendulum] epoch #41 | Time 26.71 s
2022-08-17 18:05:10 | [trpo_pendulum] epoch #41 | EpochTime 0.60 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -684.044
Evaluation/AverageReturn             -1578.24
Evaluation/Iteration                    41
Evaluation/MaxReturn                 -1568.18
Evaluation/MinReturn                 -1587.83
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     6.58961
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.36168
GaussianMLPPolicy/KL                     0.00683646
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            196.19
GaussianMLPPolicy/LossBefore           196.229
GaussianMLPPolicy/dLoss                  0.0392151
GaussianMLPValueFunction/LossAfter    6750.4
GaussianMLPValueFunction/LossBefore   7201.04
GaussianMLPValueFunction/dLoss         450.648
TotalEnvSteps                        50400
-----------------------------------  --------------
2022-08-17 18:05:11 | [trpo_pendulum] epoch #42 | Saving snapshot...
2022-08-17 18:05:11 | [trpo_pendulum] epoch #42 | Saved
2022-08-17 18:05:11 | [trpo_pendulum] epoch #42 | Time 27.33 s
2022-08-17 18:05:11 | [trpo_pendulum] epoch #42 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -559.942
Evaluation/AverageReturn             -1325.81
Evaluation/Iteration                    42
Evaluation/MaxReturn                 -1281.81
Evaluation/MinReturn                 -1427.4
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    49.6777
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.3474
GaussianMLPPolicy/KL                     0.00796381
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            159.125
GaussianMLPPolicy/LossBefore           162.156
GaussianMLPPolicy/dLoss                  3.03134
GaussianMLPValueFunction/LossAfter    4458.15
GaussianMLPValueFunction/LossBefore   4674.59
GaussianMLPValueFunction/dLoss         216.435
TotalEnvSteps                        51600
-----------------------------------  --------------
2022-08-17 18:05:12 | [trpo_pendulum] epoch #43 | Saving snapshot...
2022-08-17 18:05:12 | [trpo_pendulum] epoch #43 | Saved
2022-08-17 18:05:12 | [trpo_pendulum] epoch #43 | Time 27.96 s
2022-08-17 18:05:12 | [trpo_pendulum] epoch #43 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -576.616
Evaluation/AverageReturn             -1409.99
Evaluation/Iteration                    43
Evaluation/MaxReturn                 -1330.03
Evaluation/MinReturn                 -1447.81
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    39.8634
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.33981
GaussianMLPPolicy/KL                     0.00690613
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            173.831
GaussianMLPPolicy/LossBefore           176.414
GaussianMLPPolicy/dLoss                  2.58284
GaussianMLPValueFunction/LossAfter    5030.44
GaussianMLPValueFunction/LossBefore   5317.37
GaussianMLPValueFunction/dLoss         286.938
TotalEnvSteps                        52800
-----------------------------------  --------------
2022-08-17 18:05:12 | [trpo_pendulum] epoch #44 | Saving snapshot...
2022-08-17 18:05:12 | [trpo_pendulum] epoch #44 | Saved
2022-08-17 18:05:12 | [trpo_pendulum] epoch #44 | Time 28.61 s
2022-08-17 18:05:12 | [trpo_pendulum] epoch #44 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -597.729
Evaluation/AverageReturn             -1434.48
Evaluation/Iteration                    44
Evaluation/MaxReturn                 -1384.68
Evaluation/MinReturn                 -1496.63
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    35.9515
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.35085
GaussianMLPPolicy/KL                     0.00635082
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            176.047
GaussianMLPPolicy/LossBefore           178.455
GaussianMLPPolicy/dLoss                  2.40742
GaussianMLPValueFunction/LossAfter    4861.95
GaussianMLPValueFunction/LossBefore   5149.44
GaussianMLPValueFunction/dLoss         287.487
TotalEnvSteps                        54000
-----------------------------------  --------------
2022-08-17 18:05:13 | [trpo_pendulum] epoch #45 | Saving snapshot...
2022-08-17 18:05:13 | [trpo_pendulum] epoch #45 | Saved
2022-08-17 18:05:13 | [trpo_pendulum] epoch #45 | Time 29.22 s
2022-08-17 18:05:13 | [trpo_pendulum] epoch #45 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -495.375
Evaluation/AverageReturn             -1272.83
Evaluation/Iteration                    45
Evaluation/MaxReturn                 -1141.92
Evaluation/MinReturn                 -1378.07
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    71.7617
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.32102
GaussianMLPPolicy/KL                     0.00871888
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            159.438
GaussianMLPPolicy/LossBefore           161.775
GaussianMLPPolicy/dLoss                  2.33662
GaussianMLPValueFunction/LossAfter    3860.06
GaussianMLPValueFunction/LossBefore   4057.94
GaussianMLPValueFunction/dLoss         197.878
TotalEnvSteps                        55200
-----------------------------------  --------------
2022-08-17 18:05:14 | [trpo_pendulum] epoch #46 | Saving snapshot...
2022-08-17 18:05:14 | [trpo_pendulum] epoch #46 | Saved
2022-08-17 18:05:14 | [trpo_pendulum] epoch #46 | Time 29.84 s
2022-08-17 18:05:14 | [trpo_pendulum] epoch #46 | EpochTime 0.61 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn    -601.828
Evaluation/AverageReturn             -1429.08
Evaluation/Iteration                    46
Evaluation/MaxReturn                 -1365.78
Evaluation/MinReturn                 -1494.64
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    40.209
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.31591
GaussianMLPPolicy/KL                     0.0072531
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            173.559
GaussianMLPPolicy/LossBefore           176.132
GaussianMLPPolicy/dLoss                  2.57263
GaussianMLPValueFunction/LossAfter    4304.25
GaussianMLPValueFunction/LossBefore   4561.76
GaussianMLPValueFunction/dLoss         257.515
TotalEnvSteps                        56400
-----------------------------------  -------------
2022-08-17 18:05:14 | [trpo_pendulum] epoch #47 | Saving snapshot...
2022-08-17 18:05:14 | [trpo_pendulum] epoch #47 | Saved
2022-08-17 18:05:14 | [trpo_pendulum] epoch #47 | Time 30.45 s
2022-08-17 18:05:14 | [trpo_pendulum] epoch #47 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -623.187
Evaluation/AverageReturn             -1474.85
Evaluation/Iteration                    47
Evaluation/MaxReturn                 -1397.14
Evaluation/MinReturn                 -1517.59
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    39.9239
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.3155
GaussianMLPPolicy/KL                     0.00733579
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            179.138
GaussianMLPPolicy/LossBefore           181.578
GaussianMLPPolicy/dLoss                  2.43982
GaussianMLPValueFunction/LossAfter    4284.08
GaussianMLPValueFunction/LossBefore   4556.79
GaussianMLPValueFunction/dLoss         272.708
TotalEnvSteps                        57600
-----------------------------------  --------------
2022-08-17 18:05:15 | [trpo_pendulum] epoch #48 | Saving snapshot...
2022-08-17 18:05:15 | [trpo_pendulum] epoch #48 | Saved
2022-08-17 18:05:15 | [trpo_pendulum] epoch #48 | Time 31.08 s
2022-08-17 18:05:15 | [trpo_pendulum] epoch #48 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -594.947
Evaluation/AverageReturn             -1437.05
Evaluation/Iteration                    48
Evaluation/MaxReturn                 -1403.34
Evaluation/MinReturn                 -1456.38
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    17.1079
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.31298
GaussianMLPPolicy/KL                     0.00675291
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            174.54
GaussianMLPPolicy/LossBefore           177.984
GaussianMLPPolicy/dLoss                  3.44327
GaussianMLPValueFunction/LossAfter    3934.85
GaussianMLPValueFunction/LossBefore   4180.38
GaussianMLPValueFunction/dLoss         245.53
TotalEnvSteps                        58800
-----------------------------------  --------------
2022-08-17 18:05:15 | [trpo_pendulum] epoch #49 | Saving snapshot...
2022-08-17 18:05:15 | [trpo_pendulum] epoch #49 | Saved
2022-08-17 18:05:15 | [trpo_pendulum] epoch #49 | Time 31.69 s
2022-08-17 18:05:15 | [trpo_pendulum] epoch #49 | EpochTime 0.61 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn    -659.762
Evaluation/AverageReturn             -1546.76
Evaluation/Iteration                    49
Evaluation/MaxReturn                 -1499.99
Evaluation/MinReturn                 -1576.26
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    27.3766
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.3207
GaussianMLPPolicy/KL                     0.0085073
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            187.854
GaussianMLPPolicy/LossBefore           190.13
GaussianMLPPolicy/dLoss                  2.27678
GaussianMLPValueFunction/LossAfter    4180.75
GaussianMLPValueFunction/LossBefore   4471.79
GaussianMLPValueFunction/dLoss         291.04
TotalEnvSteps                        60000
-----------------------------------  -------------
2022-08-17 18:05:16 | [trpo_pendulum] epoch #50 | Saving snapshot...
2022-08-17 18:05:16 | [trpo_pendulum] epoch #50 | Saved
2022-08-17 18:05:16 | [trpo_pendulum] epoch #50 | Time 32.30 s
2022-08-17 18:05:16 | [trpo_pendulum] epoch #50 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -444.565
Evaluation/AverageReturn             -1119.97
Evaluation/Iteration                    50
Evaluation/MaxReturn                  -998.356
Evaluation/MinReturn                 -1309.47
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   134.485
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.30878
GaussianMLPPolicy/KL                     0.00699904
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            131.233
GaussianMLPPolicy/LossBefore           133.656
GaussianMLPPolicy/dLoss                  2.42216
GaussianMLPValueFunction/LossAfter    2108.66
GaussianMLPValueFunction/LossBefore   2193.6
GaussianMLPValueFunction/dLoss          84.9414
TotalEnvSteps                        61200
-----------------------------------  --------------
2022-08-17 18:05:17 | [trpo_pendulum] epoch #51 | Saving snapshot...
2022-08-17 18:05:17 | [trpo_pendulum] epoch #51 | Saved
2022-08-17 18:05:17 | [trpo_pendulum] epoch #51 | Time 32.90 s
2022-08-17 18:05:17 | [trpo_pendulum] epoch #51 | EpochTime 0.60 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -659.82
Evaluation/AverageReturn             -1561.09
Evaluation/Iteration                    51
Evaluation/MaxReturn                 -1507.14
Evaluation/MinReturn                 -1585.03
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    26.5398
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.31803
GaussianMLPPolicy/KL                     0.00899894
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            189.64
GaussianMLPPolicy/LossBefore           192.258
GaussianMLPPolicy/dLoss                  2.61777
GaussianMLPValueFunction/LossAfter    3867.99
GaussianMLPValueFunction/LossBefore   4147.81
GaussianMLPValueFunction/dLoss         279.822
TotalEnvSteps                        62400
-----------------------------------  --------------
2022-08-17 18:05:17 | [trpo_pendulum] epoch #52 | Saving snapshot...
2022-08-17 18:05:17 | [trpo_pendulum] epoch #52 | Saved
2022-08-17 18:05:17 | [trpo_pendulum] epoch #52 | Time 33.52 s
2022-08-17 18:05:17 | [trpo_pendulum] epoch #52 | EpochTime 0.62 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn    -546.185
Evaluation/AverageReturn             -1388.53
Evaluation/Iteration                    52
Evaluation/MaxReturn                 -1335.02
Evaluation/MinReturn                 -1426.45
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    28.4244
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.31244
GaussianMLPPolicy/KL                     0.0090833
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            170.268
GaussianMLPPolicy/LossBefore           174.572
GaussianMLPPolicy/dLoss                  4.30362
GaussianMLPValueFunction/LossAfter    3038.2
GaussianMLPValueFunction/LossBefore   3227.45
GaussianMLPValueFunction/dLoss         189.244
TotalEnvSteps                        63600
-----------------------------------  -------------
2022-08-17 18:05:18 | [trpo_pendulum] epoch #53 | Saving snapshot...
2022-08-17 18:05:18 | [trpo_pendulum] epoch #53 | Saved
2022-08-17 18:05:18 | [trpo_pendulum] epoch #53 | Time 34.16 s
2022-08-17 18:05:18 | [trpo_pendulum] epoch #53 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -654.044
Evaluation/AverageReturn             -1551
Evaluation/Iteration                    53
Evaluation/MaxReturn                 -1538.94
Evaluation/MinReturn                 -1565.98
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    12.0087
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.33596
GaussianMLPPolicy/KL                     0.00561468
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            188.051
GaussianMLPPolicy/LossBefore           190.609
GaussianMLPPolicy/dLoss                  2.55797
GaussianMLPValueFunction/LossAfter    3378.65
GaussianMLPValueFunction/LossBefore   3620.99
GaussianMLPValueFunction/dLoss         242.339
TotalEnvSteps                        64800
-----------------------------------  --------------
2022-08-17 18:05:18 | [trpo_pendulum] epoch #54 | Saving snapshot...
2022-08-17 18:05:19 | [trpo_pendulum] epoch #54 | Saved
2022-08-17 18:05:19 | [trpo_pendulum] epoch #54 | Time 34.78 s
2022-08-17 18:05:19 | [trpo_pendulum] epoch #54 | EpochTime 0.61 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn    -651.724
Evaluation/AverageReturn             -1551.87
Evaluation/Iteration                    54
Evaluation/MaxReturn                 -1522.08
Evaluation/MinReturn                 -1569.74
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    17.401
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.32292
GaussianMLPPolicy/KL                     0.0076935
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            188.165
GaussianMLPPolicy/LossBefore           190.219
GaussianMLPPolicy/dLoss                  2.05397
GaussianMLPValueFunction/LossAfter    3154.71
GaussianMLPValueFunction/LossBefore   3378.65
GaussianMLPValueFunction/dLoss         223.944
TotalEnvSteps                        66000
-----------------------------------  -------------
2022-08-17 18:05:19 | [trpo_pendulum] epoch #55 | Saving snapshot...
2022-08-17 18:05:19 | [trpo_pendulum] epoch #55 | Saved
2022-08-17 18:05:19 | [trpo_pendulum] epoch #55 | Time 35.39 s
2022-08-17 18:05:19 | [trpo_pendulum] epoch #55 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -693.297
Evaluation/AverageReturn             -1597.69
Evaluation/Iteration                    55
Evaluation/MaxReturn                 -1585.15
Evaluation/MinReturn                 -1605.82
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     8.7879
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.31881
GaussianMLPPolicy/KL                     0.00727999
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            190.213
GaussianMLPPolicy/LossBefore           193.167
GaussianMLPPolicy/dLoss                  2.95439
GaussianMLPValueFunction/LossAfter    3028.72
GaussianMLPValueFunction/LossBefore   3245.23
GaussianMLPValueFunction/dLoss         216.511
TotalEnvSteps                        67200
-----------------------------------  --------------
2022-08-17 18:05:20 | [trpo_pendulum] epoch #56 | Saving snapshot...
2022-08-17 18:05:20 | [trpo_pendulum] epoch #56 | Saved
2022-08-17 18:05:20 | [trpo_pendulum] epoch #56 | Time 36.00 s
2022-08-17 18:05:20 | [trpo_pendulum] epoch #56 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -566.882
Evaluation/AverageReturn             -1358.14
Evaluation/Iteration                    56
Evaluation/MaxReturn                 -1300.94
Evaluation/MinReturn                 -1435.77
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    50.8135
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.30405
GaussianMLPPolicy/KL                     0.00772874
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            159.78
GaussianMLPPolicy/LossBefore           161.79
GaussianMLPPolicy/dLoss                  2.00969
GaussianMLPValueFunction/LossAfter    2059.69
GaussianMLPValueFunction/LossBefore   2168.99
GaussianMLPValueFunction/dLoss         109.299
TotalEnvSteps                        68400
-----------------------------------  --------------
2022-08-17 18:05:20 | [trpo_pendulum] epoch #57 | Saving snapshot...
2022-08-17 18:05:20 | [trpo_pendulum] epoch #57 | Saved
2022-08-17 18:05:20 | [trpo_pendulum] epoch #57 | Time 36.61 s
2022-08-17 18:05:20 | [trpo_pendulum] epoch #57 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -474.287
Evaluation/AverageReturn             -1102.83
Evaluation/Iteration                    57
Evaluation/MaxReturn                  -971.02
Evaluation/MinReturn                 -1181.68
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    70.2617
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.26117
GaussianMLPPolicy/KL                     0.00939128
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            120.912
GaussianMLPPolicy/LossBefore           123.28
GaussianMLPPolicy/dLoss                  2.36758
GaussianMLPValueFunction/LossAfter    1171.18
GaussianMLPValueFunction/LossBefore   1211.03
GaussianMLPValueFunction/dLoss          39.8506
TotalEnvSteps                        69600
-----------------------------------  --------------
2022-08-17 18:05:21 | [trpo_pendulum] epoch #58 | Saving snapshot...
2022-08-17 18:05:21 | [trpo_pendulum] epoch #58 | Saved
2022-08-17 18:05:21 | [trpo_pendulum] epoch #58 | Time 37.24 s
2022-08-17 18:05:21 | [trpo_pendulum] epoch #58 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -543.362
Evaluation/AverageReturn             -1280.42
Evaluation/Iteration                    58
Evaluation/MaxReturn                 -1245.95
Evaluation/MinReturn                 -1324.14
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    27.9651
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.2539
GaussianMLPPolicy/KL                     0.00682559
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            146.975
GaussianMLPPolicy/LossBefore           148.751
GaussianMLPPolicy/dLoss                  1.77672
GaussianMLPValueFunction/LossAfter    1619.06
GaussianMLPValueFunction/LossBefore   1696.36
GaussianMLPValueFunction/dLoss          77.2958
TotalEnvSteps                        70800
-----------------------------------  --------------
2022-08-17 18:05:22 | [trpo_pendulum] epoch #59 | Saving snapshot...
2022-08-17 18:05:22 | [trpo_pendulum] epoch #59 | Saved
2022-08-17 18:05:22 | [trpo_pendulum] epoch #59 | Time 37.86 s
2022-08-17 18:05:22 | [trpo_pendulum] epoch #59 | EpochTime 0.62 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn    -475.038
Evaluation/AverageReturn             -1100.35
Evaluation/Iteration                    59
Evaluation/MaxReturn                 -1028.62
Evaluation/MinReturn                 -1171.74
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    64.168
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.22481
GaussianMLPPolicy/KL                     0.0086607
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            121.857
GaussianMLPPolicy/LossBefore           122.373
GaussianMLPPolicy/dLoss                  0.51651
GaussianMLPValueFunction/LossAfter    1084.19
GaussianMLPValueFunction/LossBefore   1123.94
GaussianMLPValueFunction/dLoss          39.7484
TotalEnvSteps                        72000
-----------------------------------  -------------
2022-08-17 18:05:22 | [trpo_pendulum] epoch #60 | Saving snapshot...
2022-08-17 18:05:22 | [trpo_pendulum] epoch #60 | Saved
2022-08-17 18:05:22 | [trpo_pendulum] epoch #60 | Time 38.50 s
2022-08-17 18:05:22 | [trpo_pendulum] epoch #60 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -521.526
Evaluation/AverageReturn             -1231.25
Evaluation/Iteration                    60
Evaluation/MaxReturn                 -1074.18
Evaluation/MinReturn                 -1408.14
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   120.256
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.21852
GaussianMLPPolicy/KL                     0.00980041
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            138.459
GaussianMLPPolicy/LossBefore           141.251
GaussianMLPPolicy/dLoss                  2.79213
GaussianMLPValueFunction/LossAfter    1384.32
GaussianMLPValueFunction/LossBefore   1451.08
GaussianMLPValueFunction/dLoss          66.7585
TotalEnvSteps                        73200
-----------------------------------  --------------
2022-08-17 18:05:23 | [trpo_pendulum] epoch #61 | Saving snapshot...
2022-08-17 18:05:23 | [trpo_pendulum] epoch #61 | Saved
2022-08-17 18:05:23 | [trpo_pendulum] epoch #61 | Time 39.15 s
2022-08-17 18:05:23 | [trpo_pendulum] epoch #61 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -617.858
Evaluation/AverageReturn             -1468.45
Evaluation/Iteration                    61
Evaluation/MaxReturn                 -1330.63
Evaluation/MinReturn                 -1553.29
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    74.9415
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.24211
GaussianMLPPolicy/KL                     0.00989011
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            172.73
GaussianMLPPolicy/LossBefore           175.116
GaussianMLPPolicy/dLoss                  2.38609
GaussianMLPValueFunction/LossAfter    1946.31
GaussianMLPValueFunction/LossBefore   2085.12
GaussianMLPValueFunction/dLoss         138.817
TotalEnvSteps                        74400
-----------------------------------  --------------
2022-08-17 18:05:24 | [trpo_pendulum] epoch #62 | Saving snapshot...
2022-08-17 18:05:24 | [trpo_pendulum] epoch #62 | Saved
2022-08-17 18:05:24 | [trpo_pendulum] epoch #62 | Time 39.80 s
2022-08-17 18:05:24 | [trpo_pendulum] epoch #62 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -639.833
Evaluation/AverageReturn             -1503.08
Evaluation/Iteration                    62
Evaluation/MaxReturn                 -1436
Evaluation/MinReturn                 -1583.43
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    54.3134
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.23588
GaussianMLPPolicy/KL                     0.00871737
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            176.528
GaussianMLPPolicy/LossBefore           178.569
GaussianMLPPolicy/dLoss                  2.04132
GaussianMLPValueFunction/LossAfter    1898.15
GaussianMLPValueFunction/LossBefore   2038.71
GaussianMLPValueFunction/dLoss         140.555
TotalEnvSteps                        75600
-----------------------------------  --------------
2022-08-17 18:05:24 | [trpo_pendulum] epoch #63 | Saving snapshot...
2022-08-17 18:05:24 | [trpo_pendulum] epoch #63 | Saved
2022-08-17 18:05:24 | [trpo_pendulum] epoch #63 | Time 40.43 s
2022-08-17 18:05:24 | [trpo_pendulum] epoch #63 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -546.189
Evaluation/AverageReturn             -1319.5
Evaluation/Iteration                    63
Evaluation/MaxReturn                 -1198.5
Evaluation/MinReturn                 -1374.31
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    62.1978
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.22108
GaussianMLPPolicy/KL                     0.00760917
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            151.8
GaussianMLPPolicy/LossBefore           154.244
GaussianMLPPolicy/dLoss                  2.44456
GaussianMLPValueFunction/LossAfter    1359.14
GaussianMLPValueFunction/LossBefore   1437.05
GaussianMLPValueFunction/dLoss          77.9038
TotalEnvSteps                        76800
-----------------------------------  --------------
2022-08-17 18:05:25 | [trpo_pendulum] epoch #64 | Saving snapshot...
2022-08-17 18:05:25 | [trpo_pendulum] epoch #64 | Saved
2022-08-17 18:05:25 | [trpo_pendulum] epoch #64 | Time 41.06 s
2022-08-17 18:05:25 | [trpo_pendulum] epoch #64 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -695.622
Evaluation/AverageReturn             -1610.84
Evaluation/Iteration                    64
Evaluation/MaxReturn                 -1599.2
Evaluation/MinReturn                 -1624.12
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     8.82016
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.20913
GaussianMLPPolicy/KL                     0.00709967
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            188.896
GaussianMLPPolicy/LossBefore           191.627
GaussianMLPPolicy/dLoss                  2.73109
GaussianMLPValueFunction/LossAfter    1912.66
GaussianMLPValueFunction/LossBefore   2069.47
GaussianMLPValueFunction/dLoss         156.815
TotalEnvSteps                        78000
-----------------------------------  --------------
2022-08-17 18:05:25 | [trpo_pendulum] epoch #65 | Saving snapshot...
2022-08-17 18:05:25 | [trpo_pendulum] epoch #65 | Saved
2022-08-17 18:05:25 | [trpo_pendulum] epoch #65 | Time 41.68 s
2022-08-17 18:05:25 | [trpo_pendulum] epoch #65 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -533.864
Evaluation/AverageReturn             -1301.78
Evaluation/Iteration                    65
Evaluation/MaxReturn                 -1181.47
Evaluation/MinReturn                 -1362.99
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    57.5765
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.20549
GaussianMLPPolicy/KL                     0.00754131
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            150.153
GaussianMLPPolicy/LossBefore           151.795
GaussianMLPPolicy/dLoss                  1.6416
GaussianMLPValueFunction/LossAfter    1186.2
GaussianMLPValueFunction/LossBefore   1252.53
GaussianMLPValueFunction/dLoss          66.3236
TotalEnvSteps                        79200
-----------------------------------  --------------
2022-08-17 18:05:26 | [trpo_pendulum] epoch #66 | Saving snapshot...
2022-08-17 18:05:26 | [trpo_pendulum] epoch #66 | Saved
2022-08-17 18:05:26 | [trpo_pendulum] epoch #66 | Time 42.29 s
2022-08-17 18:05:26 | [trpo_pendulum] epoch #66 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -607.093
Evaluation/AverageReturn             -1339.99
Evaluation/Iteration                    66
Evaluation/MaxReturn                 -1273.1
Evaluation/MinReturn                 -1430.5
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    50.1948
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.21935
GaussianMLPPolicy/KL                     0.00857452
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            145.849
GaussianMLPPolicy/LossBefore           148.268
GaussianMLPPolicy/dLoss                  2.41891
GaussianMLPValueFunction/LossAfter    1048.85
GaussianMLPValueFunction/LossBefore   1103.34
GaussianMLPValueFunction/dLoss          54.4928
TotalEnvSteps                        80400
-----------------------------------  --------------
2022-08-17 18:05:27 | [trpo_pendulum] epoch #67 | Saving snapshot...
2022-08-17 18:05:27 | [trpo_pendulum] epoch #67 | Saved
2022-08-17 18:05:27 | [trpo_pendulum] epoch #67 | Time 42.93 s
2022-08-17 18:05:27 | [trpo_pendulum] epoch #67 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -535.666
Evaluation/AverageReturn             -1315.28
Evaluation/Iteration                    67
Evaluation/MaxReturn                 -1257.73
Evaluation/MinReturn                 -1361.03
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    34.1951
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.22002
GaussianMLPPolicy/KL                     0.00683381
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            150.961
GaussianMLPPolicy/LossBefore           153.041
GaussianMLPPolicy/dLoss                  2.07999
GaussianMLPValueFunction/LossAfter    1098.24
GaussianMLPValueFunction/LossBefore   1161.8
GaussianMLPValueFunction/dLoss          63.5593
TotalEnvSteps                        81600
-----------------------------------  --------------
2022-08-17 18:05:27 | [trpo_pendulum] epoch #68 | Saving snapshot...
2022-08-17 18:05:27 | [trpo_pendulum] epoch #68 | Saved
2022-08-17 18:05:27 | [trpo_pendulum] epoch #68 | Time 43.55 s
2022-08-17 18:05:27 | [trpo_pendulum] epoch #68 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -573.314
Evaluation/AverageReturn             -1413.72
Evaluation/Iteration                    68
Evaluation/MaxReturn                 -1359.34
Evaluation/MinReturn                 -1459.32
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    37.8351
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.25053
GaussianMLPPolicy/KL                     0.00588201
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            167.126
GaussianMLPPolicy/LossBefore           169.048
GaussianMLPPolicy/dLoss                  1.92192
GaussianMLPValueFunction/LossAfter    1231.81
GaussianMLPValueFunction/LossBefore   1316.37
GaussianMLPValueFunction/dLoss          84.5571
TotalEnvSteps                        82800
-----------------------------------  --------------
2022-08-17 18:05:28 | [trpo_pendulum] epoch #69 | Saving snapshot...
2022-08-17 18:05:28 | [trpo_pendulum] epoch #69 | Saved
2022-08-17 18:05:28 | [trpo_pendulum] epoch #69 | Time 44.17 s
2022-08-17 18:05:28 | [trpo_pendulum] epoch #69 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -661.47
Evaluation/AverageReturn             -1515.57
Evaluation/Iteration                    69
Evaluation/MaxReturn                 -1505.59
Evaluation/MinReturn                 -1527.35
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     8.75946
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.2342
GaussianMLPPolicy/KL                     0.00582888
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            174.115
GaussianMLPPolicy/LossBefore           174.727
GaussianMLPPolicy/dLoss                  0.612793
GaussianMLPValueFunction/LossAfter    1220
GaussianMLPValueFunction/LossBefore   1307.72
GaussianMLPValueFunction/dLoss          87.7236
TotalEnvSteps                        84000
-----------------------------------  --------------
2022-08-17 18:05:29 | [trpo_pendulum] epoch #70 | Saving snapshot...
2022-08-17 18:05:29 | [trpo_pendulum] epoch #70 | Saved
2022-08-17 18:05:29 | [trpo_pendulum] epoch #70 | Time 44.82 s
2022-08-17 18:05:29 | [trpo_pendulum] epoch #70 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -648.962
Evaluation/AverageReturn             -1505.01
Evaluation/Iteration                    70
Evaluation/MaxReturn                 -1501.77
Evaluation/MinReturn                 -1510.69
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     3.31313
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.23643
GaussianMLPPolicy/KL                     0.00546278
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            173.986
GaussianMLPPolicy/LossBefore           174.371
GaussianMLPPolicy/dLoss                  0.385101
GaussianMLPValueFunction/LossAfter    1136.46
GaussianMLPValueFunction/LossBefore   1216.65
GaussianMLPValueFunction/dLoss          80.197
TotalEnvSteps                        85200
-----------------------------------  --------------
2022-08-17 18:05:29 | [trpo_pendulum] epoch #71 | Saving snapshot...
2022-08-17 18:05:29 | [trpo_pendulum] epoch #71 | Saved
2022-08-17 18:05:29 | [trpo_pendulum] epoch #71 | Time 45.44 s
2022-08-17 18:05:29 | [trpo_pendulum] epoch #71 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -663.924
Evaluation/AverageReturn             -1524.47
Evaluation/Iteration                    71
Evaluation/MaxReturn                 -1517.7
Evaluation/MinReturn                 -1528.49
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     3.93185
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.22713
GaussianMLPPolicy/KL                     0.00784402
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            174.239
GaussianMLPPolicy/LossBefore           175.545
GaussianMLPPolicy/dLoss                  1.30643
GaussianMLPValueFunction/LossAfter    1081.55
GaussianMLPValueFunction/LossBefore   1157.78
GaussianMLPValueFunction/dLoss          76.2246
TotalEnvSteps                        86400
-----------------------------------  --------------
2022-08-17 18:05:30 | [trpo_pendulum] epoch #72 | Saving snapshot...
2022-08-17 18:05:30 | [trpo_pendulum] epoch #72 | Saved
2022-08-17 18:05:30 | [trpo_pendulum] epoch #72 | Time 46.08 s
2022-08-17 18:05:30 | [trpo_pendulum] epoch #72 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -650.908
Evaluation/AverageReturn             -1516.15
Evaluation/Iteration                    72
Evaluation/MaxReturn                 -1509.28
Evaluation/MinReturn                 -1524.68
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     5.38064
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.22187
GaussianMLPPolicy/KL                     0.00719913
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            173
GaussianMLPPolicy/LossBefore           175.993
GaussianMLPPolicy/dLoss                  2.99355
GaussianMLPValueFunction/LossAfter    1021.59
GaussianMLPValueFunction/LossBefore   1093.31
GaussianMLPValueFunction/dLoss          71.7168
TotalEnvSteps                        87600
-----------------------------------  --------------
2022-08-17 18:05:30 | [trpo_pendulum] epoch #73 | Saving snapshot...
2022-08-17 18:05:30 | [trpo_pendulum] epoch #73 | Saved
2022-08-17 18:05:30 | [trpo_pendulum] epoch #73 | Time 46.70 s
2022-08-17 18:05:30 | [trpo_pendulum] epoch #73 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -549.927
Evaluation/AverageReturn             -1311.95
Evaluation/Iteration                    73
Evaluation/MaxReturn                 -1214.99
Evaluation/MinReturn                 -1387.24
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    50.7077
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.20608
GaussianMLPPolicy/KL                     0.00791982
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            146.381
GaussianMLPPolicy/LossBefore           148.1
GaussianMLPPolicy/dLoss                  1.71947
GaussianMLPValueFunction/LossAfter     717.455
GaussianMLPValueFunction/LossBefore    755.964
GaussianMLPValueFunction/dLoss          38.5096
TotalEnvSteps                        88800
-----------------------------------  --------------
2022-08-17 18:05:31 | [trpo_pendulum] epoch #74 | Saving snapshot...
2022-08-17 18:05:31 | [trpo_pendulum] epoch #74 | Saved
2022-08-17 18:05:31 | [trpo_pendulum] epoch #74 | Time 47.33 s
2022-08-17 18:05:31 | [trpo_pendulum] epoch #74 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -652.684
Evaluation/AverageReturn             -1514.17
Evaluation/Iteration                    74
Evaluation/MaxReturn                 -1503.51
Evaluation/MinReturn                 -1533.72
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    11.2147
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.19749
GaussianMLPPolicy/KL                     0.00973236
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            173.582
GaussianMLPPolicy/LossBefore           174.113
GaussianMLPPolicy/dLoss                  0.531601
GaussianMLPValueFunction/LossAfter     897.656
GaussianMLPValueFunction/LossBefore    959.531
GaussianMLPValueFunction/dLoss          61.8752
TotalEnvSteps                        90000
-----------------------------------  --------------
2022-08-17 18:05:32 | [trpo_pendulum] epoch #75 | Saving snapshot...
2022-08-17 18:05:32 | [trpo_pendulum] epoch #75 | Saved
2022-08-17 18:05:32 | [trpo_pendulum] epoch #75 | Time 47.97 s
2022-08-17 18:05:32 | [trpo_pendulum] epoch #75 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -479.045
Evaluation/AverageReturn             -1152.19
Evaluation/Iteration                    75
Evaluation/MaxReturn                  -947.624
Evaluation/MinReturn                 -1310.31
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   132.593
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.20749
GaussianMLPPolicy/KL                     0.00879509
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            122.941
GaussianMLPPolicy/LossBefore           124.197
GaussianMLPPolicy/dLoss                  1.2559
GaussianMLPValueFunction/LossAfter     465.711
GaussianMLPValueFunction/LossBefore    484.76
GaussianMLPValueFunction/dLoss          19.0489
TotalEnvSteps                        91200
-----------------------------------  --------------
2022-08-17 18:05:32 | [trpo_pendulum] epoch #76 | Saving snapshot...
2022-08-17 18:05:32 | [trpo_pendulum] epoch #76 | Saved
2022-08-17 18:05:32 | [trpo_pendulum] epoch #76 | Time 48.60 s
2022-08-17 18:05:32 | [trpo_pendulum] epoch #76 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -494.041
Evaluation/AverageReturn             -1161.73
Evaluation/Iteration                    76
Evaluation/MaxReturn                 -1057.99
Evaluation/MinReturn                 -1279.6
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    82.4716
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.20769
GaussianMLPPolicy/KL                     0.00896536
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            121.062
GaussianMLPPolicy/LossBefore           123.05
GaussianMLPPolicy/dLoss                  1.98774
GaussianMLPValueFunction/LossAfter     432.325
GaussianMLPValueFunction/LossBefore    449.618
GaussianMLPValueFunction/dLoss          17.2931
TotalEnvSteps                        92400
-----------------------------------  --------------
2022-08-17 18:05:33 | [trpo_pendulum] epoch #77 | Saving snapshot...
2022-08-17 18:05:33 | [trpo_pendulum] epoch #77 | Saved
2022-08-17 18:05:33 | [trpo_pendulum] epoch #77 | Time 49.23 s
2022-08-17 18:05:33 | [trpo_pendulum] epoch #77 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -524.474
Evaluation/AverageReturn             -1243.97
Evaluation/Iteration                    77
Evaluation/MaxReturn                 -1169.1
Evaluation/MinReturn                 -1320.63
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    52.9219
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.19188
GaussianMLPPolicy/KL                     0.00955395
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            135.708
GaussianMLPPolicy/LossBefore           136.639
GaussianMLPPolicy/dLoss                  0.930038
GaussianMLPValueFunction/LossAfter     504.508
GaussianMLPValueFunction/LossBefore    529.461
GaussianMLPValueFunction/dLoss          24.9533
TotalEnvSteps                        93600
-----------------------------------  --------------
2022-08-17 18:05:34 | [trpo_pendulum] epoch #78 | Saving snapshot...
2022-08-17 18:05:34 | [trpo_pendulum] epoch #78 | Saved
2022-08-17 18:05:34 | [trpo_pendulum] epoch #78 | Time 49.85 s
2022-08-17 18:05:34 | [trpo_pendulum] epoch #78 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -490.081
Evaluation/AverageReturn             -1164.33
Evaluation/Iteration                    78
Evaluation/MaxReturn                 -1135.04
Evaluation/MinReturn                 -1221.23
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    27.0565
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.18692
GaussianMLPPolicy/KL                     0.00634159
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            122.241
GaussianMLPPolicy/LossBefore           124.088
GaussianMLPPolicy/dLoss                  1.84679
GaussianMLPValueFunction/LossAfter     406.5
GaussianMLPValueFunction/LossBefore    424.431
GaussianMLPValueFunction/dLoss          17.9307
TotalEnvSteps                        94800
-----------------------------------  --------------
2022-08-17 18:05:34 | [trpo_pendulum] epoch #79 | Saving snapshot...
2022-08-17 18:05:34 | [trpo_pendulum] epoch #79 | Saved
2022-08-17 18:05:34 | [trpo_pendulum] epoch #79 | Time 50.48 s
2022-08-17 18:05:34 | [trpo_pendulum] epoch #79 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -659.719
Evaluation/AverageReturn             -1507.22
Evaluation/Iteration                    79
Evaluation/MaxReturn                 -1504.68
Evaluation/MinReturn                 -1510.46
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     1.69571
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.19996
GaussianMLPPolicy/KL                     0.00756281
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            167.212
GaussianMLPPolicy/LossBefore           168.968
GaussianMLPPolicy/dLoss                  1.75682
GaussianMLPValueFunction/LossAfter     681.516
GaussianMLPValueFunction/LossBefore    732.825
GaussianMLPValueFunction/dLoss          51.3097
TotalEnvSteps                        96000
-----------------------------------  --------------
2022-08-17 18:05:35 | [trpo_pendulum] epoch #80 | Saving snapshot...
2022-08-17 18:05:35 | [trpo_pendulum] epoch #80 | Saved
2022-08-17 18:05:35 | [trpo_pendulum] epoch #80 | Time 51.11 s
2022-08-17 18:05:35 | [trpo_pendulum] epoch #80 | EpochTime 0.63 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn    -581.47
Evaluation/AverageReturn             -1435.87
Evaluation/Iteration                    80
Evaluation/MaxReturn                 -1357.39
Evaluation/MinReturn                 -1480.66
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    41.376
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.19631
GaussianMLPPolicy/KL                     0.0066716
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            168.169
GaussianMLPPolicy/LossBefore           168.279
GaussianMLPPolicy/dLoss                  0.10994
GaussianMLPValueFunction/LossAfter     635.955
GaussianMLPValueFunction/LossBefore    683.695
GaussianMLPValueFunction/dLoss          47.7404
TotalEnvSteps                        97200
-----------------------------------  -------------
2022-08-17 18:05:35 | [trpo_pendulum] epoch #81 | Saving snapshot...
2022-08-17 18:05:35 | [trpo_pendulum] epoch #81 | Saved
2022-08-17 18:05:35 | [trpo_pendulum] epoch #81 | Time 51.73 s
2022-08-17 18:05:35 | [trpo_pendulum] epoch #81 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -652.146
Evaluation/AverageReturn             -1507.75
Evaluation/Iteration                    81
Evaluation/MaxReturn                 -1505.55
Evaluation/MinReturn                 -1509.67
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     1.37749
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.18279
GaussianMLPPolicy/KL                     0.00786775
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            167.198
GaussianMLPPolicy/LossBefore           170.174
GaussianMLPPolicy/dLoss                  2.97668
GaussianMLPValueFunction/LossAfter     603.015
GaussianMLPValueFunction/LossBefore    647.813
GaussianMLPValueFunction/dLoss          44.7982
TotalEnvSteps                        98400
-----------------------------------  --------------
2022-08-17 18:05:36 | [trpo_pendulum] epoch #82 | Saving snapshot...
2022-08-17 18:05:36 | [trpo_pendulum] epoch #82 | Saved
2022-08-17 18:05:36 | [trpo_pendulum] epoch #82 | Time 52.34 s
2022-08-17 18:05:36 | [trpo_pendulum] epoch #82 | EpochTime 0.61 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn    -561.246
Evaluation/AverageReturn             -1359.45
Evaluation/Iteration                    82
Evaluation/MaxReturn                 -1336.96
Evaluation/MinReturn                 -1416.12
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    27.9306
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.1777
GaussianMLPPolicy/KL                     0.0081134
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            150.541
GaussianMLPPolicy/LossBefore           152.741
GaussianMLPPolicy/dLoss                  2.20023
GaussianMLPValueFunction/LossAfter     474.701
GaussianMLPValueFunction/LossBefore    504.263
GaussianMLPValueFunction/dLoss          29.5629
TotalEnvSteps                        99600
-----------------------------------  -------------
2022-08-17 18:05:37 | [trpo_pendulum] epoch #83 | Saving snapshot...
2022-08-17 18:05:37 | [trpo_pendulum] epoch #83 | Saved
2022-08-17 18:05:37 | [trpo_pendulum] epoch #83 | Time 52.96 s
2022-08-17 18:05:37 | [trpo_pendulum] epoch #83 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -650.095
Evaluation/AverageReturn              -1505.06
Evaluation/Iteration                     83
Evaluation/MaxReturn                  -1502.94
Evaluation/MinReturn                  -1508.53
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      1.80826
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.21231
GaussianMLPPolicy/KL                      0.00786599
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             166.715
GaussianMLPPolicy/LossBefore            169.096
GaussianMLPPolicy/dLoss                   2.38161
GaussianMLPValueFunction/LossAfter      528.578
GaussianMLPValueFunction/LossBefore     566.652
GaussianMLPValueFunction/dLoss           38.0738
TotalEnvSteps                        100800
-----------------------------------  ---------------
2022-08-17 18:05:37 | [trpo_pendulum] epoch #84 | Saving snapshot...
2022-08-17 18:05:37 | [trpo_pendulum] epoch #84 | Saved
2022-08-17 18:05:37 | [trpo_pendulum] epoch #84 | Time 53.60 s
2022-08-17 18:05:37 | [trpo_pendulum] epoch #84 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -533.476
Evaluation/AverageReturn              -1186.68
Evaluation/Iteration                     84
Evaluation/MaxReturn                   -966.396
Evaluation/MinReturn                  -1284.21
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    104.468
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.21184
GaussianMLPPolicy/KL                      0.00878988
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             117.914
GaussianMLPPolicy/LossBefore            120.541
GaussianMLPPolicy/dLoss                   2.62647
GaussianMLPValueFunction/LossAfter      277.361
GaussianMLPValueFunction/LossBefore     289.071
GaussianMLPValueFunction/dLoss           11.7094
TotalEnvSteps                        102000
-----------------------------------  ---------------
2022-08-17 18:05:38 | [trpo_pendulum] epoch #85 | Saving snapshot...
2022-08-17 18:05:38 | [trpo_pendulum] epoch #85 | Saved
2022-08-17 18:05:38 | [trpo_pendulum] epoch #85 | Time 54.23 s
2022-08-17 18:05:38 | [trpo_pendulum] epoch #85 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -658.54
Evaluation/AverageReturn              -1511.14
Evaluation/Iteration                     85
Evaluation/MaxReturn                  -1507.47
Evaluation/MinReturn                  -1516.6
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      3.09983
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.21484
GaussianMLPPolicy/KL                      0.00673354
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             165.546
GaussianMLPPolicy/LossBefore            167.609
GaussianMLPPolicy/dLoss                   2.06218
GaussianMLPValueFunction/LossAfter      471.381
GaussianMLPValueFunction/LossBefore     505.348
GaussianMLPValueFunction/dLoss           33.9672
TotalEnvSteps                        103200
-----------------------------------  ---------------
2022-08-17 18:05:39 | [trpo_pendulum] epoch #86 | Saving snapshot...
2022-08-17 18:05:39 | [trpo_pendulum] epoch #86 | Saved
2022-08-17 18:05:39 | [trpo_pendulum] epoch #86 | Time 54.85 s
2022-08-17 18:05:39 | [trpo_pendulum] epoch #86 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -443.521
Evaluation/AverageReturn               -962.925
Evaluation/Iteration                     86
Evaluation/MaxReturn                   -748.358
Evaluation/MinReturn                  -1084.19
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    102.926
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.21026
GaussianMLPPolicy/KL                      0.00935717
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              84.8415
GaussianMLPPolicy/LossBefore             85.8047
GaussianMLPPolicy/dLoss                   0.963219
GaussianMLPValueFunction/LossAfter      135.61
GaussianMLPValueFunction/LossBefore     139.125
GaussianMLPValueFunction/dLoss            3.51506
TotalEnvSteps                        104400
-----------------------------------  ---------------
2022-08-17 18:05:39 | [trpo_pendulum] epoch #87 | Saving snapshot...
2022-08-17 18:05:39 | [trpo_pendulum] epoch #87 | Saved
2022-08-17 18:05:39 | [trpo_pendulum] epoch #87 | Time 55.46 s
2022-08-17 18:05:39 | [trpo_pendulum] epoch #87 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -658.553
Evaluation/AverageReturn              -1512.79
Evaluation/Iteration                     87
Evaluation/MaxReturn                  -1509.79
Evaluation/MinReturn                  -1516.69
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      2.43669
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.2334
GaussianMLPPolicy/KL                      0.00844781
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             164.324
GaussianMLPPolicy/LossBefore            167.277
GaussianMLPPolicy/dLoss                   2.95375
GaussianMLPValueFunction/LossAfter      430.201
GaussianMLPValueFunction/LossBefore     462.277
GaussianMLPValueFunction/dLoss           32.0758
TotalEnvSteps                        105600
-----------------------------------  ---------------
2022-08-17 18:05:40 | [trpo_pendulum] epoch #88 | Saving snapshot...
2022-08-17 18:05:40 | [trpo_pendulum] epoch #88 | Saved
2022-08-17 18:05:40 | [trpo_pendulum] epoch #88 | Time 56.09 s
2022-08-17 18:05:40 | [trpo_pendulum] epoch #88 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -467.274
Evaluation/AverageReturn              -1106.68
Evaluation/Iteration                     88
Evaluation/MaxReturn                  -1018.99
Evaluation/MinReturn                  -1205.11
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     67.8079
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.246
GaussianMLPPolicy/KL                      0.0078909
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             110.635
GaussianMLPPolicy/LossBefore            112.017
GaussianMLPPolicy/dLoss                   1.3819
GaussianMLPValueFunction/LossAfter      197.144
GaussianMLPValueFunction/LossBefore     205.007
GaussianMLPValueFunction/dLoss            7.86378
TotalEnvSteps                        106800
-----------------------------------  --------------
2022-08-17 18:05:40 | [trpo_pendulum] epoch #89 | Saving snapshot...
2022-08-17 18:05:40 | [trpo_pendulum] epoch #89 | Saved
2022-08-17 18:05:40 | [trpo_pendulum] epoch #89 | Time 56.70 s
2022-08-17 18:05:40 | [trpo_pendulum] epoch #89 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -449.99
Evaluation/AverageReturn              -1033.67
Evaluation/Iteration                     89
Evaluation/MaxReturn                   -765.537
Evaluation/MinReturn                  -1165.23
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    133.145
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.24596
GaussianMLPPolicy/KL                      0.0095529
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              97.9965
GaussianMLPPolicy/LossBefore             99.4068
GaussianMLPPolicy/dLoss                   1.4103
GaussianMLPValueFunction/LossAfter      155.209
GaussianMLPValueFunction/LossBefore     160.343
GaussianMLPValueFunction/dLoss            5.13432
TotalEnvSteps                        108000
-----------------------------------  --------------
2022-08-17 18:05:41 | [trpo_pendulum] epoch #90 | Saving snapshot...
2022-08-17 18:05:41 | [trpo_pendulum] epoch #90 | Saved
2022-08-17 18:05:41 | [trpo_pendulum] epoch #90 | Time 57.32 s
2022-08-17 18:05:41 | [trpo_pendulum] epoch #90 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -662.345
Evaluation/AverageReturn              -1522.38
Evaluation/Iteration                     90
Evaluation/MaxReturn                  -1513.46
Evaluation/MinReturn                  -1533.71
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      6.60279
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.29421
GaussianMLPPolicy/KL                      0.00929743
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             164.688
GaussianMLPPolicy/LossBefore            167.595
GaussianMLPPolicy/dLoss                   2.90683
GaussianMLPValueFunction/LossAfter      378.784
GaussianMLPValueFunction/LossBefore     409.58
GaussianMLPValueFunction/dLoss           30.7961
TotalEnvSteps                        109200
-----------------------------------  ---------------
2022-08-17 18:05:42 | [trpo_pendulum] epoch #91 | Saving snapshot...
2022-08-17 18:05:42 | [trpo_pendulum] epoch #91 | Saved
2022-08-17 18:05:42 | [trpo_pendulum] epoch #91 | Time 57.94 s
2022-08-17 18:05:42 | [trpo_pendulum] epoch #91 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -661.209
Evaluation/AverageReturn              -1513.59
Evaluation/Iteration                     91
Evaluation/MaxReturn                  -1510.16
Evaluation/MinReturn                  -1520.58
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      3.61789
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.32793
GaussianMLPPolicy/KL                      0.00632201
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             163.322
GaussianMLPPolicy/LossBefore            165.149
GaussianMLPPolicy/dLoss                   1.82701
GaussianMLPValueFunction/LossAfter      342.246
GaussianMLPValueFunction/LossBefore     369.104
GaussianMLPValueFunction/dLoss           26.8577
TotalEnvSteps                        110400
-----------------------------------  ---------------
2022-08-17 18:05:42 | [trpo_pendulum] epoch #92 | Saving snapshot...
2022-08-17 18:05:42 | [trpo_pendulum] epoch #92 | Saved
2022-08-17 18:05:42 | [trpo_pendulum] epoch #92 | Time 58.57 s
2022-08-17 18:05:42 | [trpo_pendulum] epoch #92 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -497.558
Evaluation/AverageReturn              -1038.21
Evaluation/Iteration                     92
Evaluation/MaxReturn                   -939.039
Evaluation/MinReturn                  -1152.87
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     73.8904
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.32737
GaussianMLPPolicy/KL                      0.00784701
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              90.6295
GaussianMLPPolicy/LossBefore             92.6727
GaussianMLPPolicy/dLoss                   2.04321
GaussianMLPValueFunction/LossAfter      123
GaussianMLPValueFunction/LossBefore     126.893
GaussianMLPValueFunction/dLoss            3.89254
TotalEnvSteps                        111600
-----------------------------------  ---------------
2022-08-17 18:05:43 | [trpo_pendulum] epoch #93 | Saving snapshot...
2022-08-17 18:05:43 | [trpo_pendulum] epoch #93 | Saved
2022-08-17 18:05:43 | [trpo_pendulum] epoch #93 | Time 59.17 s
2022-08-17 18:05:43 | [trpo_pendulum] epoch #93 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -376.52
Evaluation/AverageReturn               -877.496
Evaluation/Iteration                     93
Evaluation/MaxReturn                   -633.522
Evaluation/MinReturn                   -985.958
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    118.568
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.32945
GaussianMLPPolicy/KL                      0.00638536
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              75.6927
GaussianMLPPolicy/LossBefore             76.5765
GaussianMLPPolicy/dLoss                   0.88385
GaussianMLPValueFunction/LossAfter       85.1563
GaussianMLPValueFunction/LossBefore      87.1539
GaussianMLPValueFunction/dLoss            1.99758
TotalEnvSteps                        112800
-----------------------------------  ---------------
2022-08-17 18:05:44 | [trpo_pendulum] epoch #94 | Saving snapshot...
2022-08-17 18:05:44 | [trpo_pendulum] epoch #94 | Saved
2022-08-17 18:05:44 | [trpo_pendulum] epoch #94 | Time 59.80 s
2022-08-17 18:05:44 | [trpo_pendulum] epoch #94 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -358.217
Evaluation/AverageReturn               -842.434
Evaluation/Iteration                     94
Evaluation/MaxReturn                   -757.402
Evaluation/MinReturn                   -967.7
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     69.0395
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.32155
GaussianMLPPolicy/KL                      0.00690715
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              72.7598
GaussianMLPPolicy/LossBefore             73.9479
GaussianMLPPolicy/dLoss                   1.18811
GaussianMLPValueFunction/LossAfter       76.2726
GaussianMLPValueFunction/LossBefore      78.0023
GaussianMLPValueFunction/dLoss            1.72971
TotalEnvSteps                        114000
-----------------------------------  ---------------
2022-08-17 18:05:44 | [trpo_pendulum] epoch #95 | Saving snapshot...
2022-08-17 18:05:44 | [trpo_pendulum] epoch #95 | Saved
2022-08-17 18:05:44 | [trpo_pendulum] epoch #95 | Time 60.43 s
2022-08-17 18:05:44 | [trpo_pendulum] epoch #95 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -390.012
Evaluation/AverageReturn               -888.507
Evaluation/Iteration                     95
Evaluation/MaxReturn                   -790.664
Evaluation/MinReturn                   -965.114
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     60.3403
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.32074
GaussianMLPPolicy/KL                      0.0083933
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              73.2889
GaussianMLPPolicy/LossBefore             75.0217
GaussianMLPPolicy/dLoss                   1.73285
GaussianMLPValueFunction/LossAfter       74.7843
GaussianMLPValueFunction/LossBefore      76.6295
GaussianMLPValueFunction/dLoss            1.8452
TotalEnvSteps                        115200
-----------------------------------  --------------
2022-08-17 18:05:45 | [trpo_pendulum] epoch #96 | Saving snapshot...
2022-08-17 18:05:45 | [trpo_pendulum] epoch #96 | Saved
2022-08-17 18:05:45 | [trpo_pendulum] epoch #96 | Time 61.07 s
2022-08-17 18:05:45 | [trpo_pendulum] epoch #96 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -336.625
Evaluation/AverageReturn               -832.341
Evaluation/Iteration                     96
Evaluation/MaxReturn                   -668.739
Evaluation/MinReturn                   -873.755
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     73.4874
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.30338
GaussianMLPPolicy/KL                      0.00931518
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              72.2784
GaussianMLPPolicy/LossBefore             73.5409
GaussianMLPPolicy/dLoss                   1.26246
GaussianMLPValueFunction/LossAfter       70.8513
GaussianMLPValueFunction/LossBefore      72.6734
GaussianMLPValueFunction/dLoss            1.8221
TotalEnvSteps                        116400
-----------------------------------  ---------------
2022-08-17 18:05:45 | [trpo_pendulum] epoch #97 | Saving snapshot...
2022-08-17 18:05:45 | [trpo_pendulum] epoch #97 | Saved
2022-08-17 18:05:45 | [trpo_pendulum] epoch #97 | Time 61.70 s
2022-08-17 18:05:45 | [trpo_pendulum] epoch #97 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -660.382
Evaluation/AverageReturn              -1514.98
Evaluation/Iteration                     97
Evaluation/MaxReturn                  -1507.01
Evaluation/MinReturn                  -1525.53
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      6.25886
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.30981
GaussianMLPPolicy/KL                      0.00977101
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             161.831
GaussianMLPPolicy/LossBefore            163.871
GaussianMLPPolicy/dLoss                   2.04057
GaussianMLPValueFunction/LossAfter      277.891
GaussianMLPValueFunction/LossBefore     305.58
GaussianMLPValueFunction/dLoss           27.6883
TotalEnvSteps                        117600
-----------------------------------  ---------------
2022-08-17 18:05:46 | [trpo_pendulum] epoch #98 | Saving snapshot...
2022-08-17 18:05:46 | [trpo_pendulum] epoch #98 | Saved
2022-08-17 18:05:46 | [trpo_pendulum] epoch #98 | Time 62.34 s
2022-08-17 18:05:46 | [trpo_pendulum] epoch #98 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -659.361
Evaluation/AverageReturn              -1512.62
Evaluation/Iteration                     98
Evaluation/MaxReturn                  -1506.9
Evaluation/MinReturn                  -1523.82
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      6.09634
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.30874
GaussianMLPPolicy/KL                      0.00779661
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             161.315
GaussianMLPPolicy/LossBefore            162.677
GaussianMLPPolicy/dLoss                   1.36244
GaussianMLPValueFunction/LossAfter      252.125
GaussianMLPValueFunction/LossBefore     275.869
GaussianMLPValueFunction/dLoss           23.7446
TotalEnvSteps                        118800
-----------------------------------  ---------------
2022-08-17 18:05:47 | [trpo_pendulum] epoch #99 | Saving snapshot...
2022-08-17 18:05:47 | [trpo_pendulum] epoch #99 | Saved
2022-08-17 18:05:47 | [trpo_pendulum] epoch #99 | Time 62.98 s
2022-08-17 18:05:47 | [trpo_pendulum] epoch #99 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -648.506
Evaluation/AverageReturn              -1505.33
Evaluation/Iteration                     99
Evaluation/MaxReturn                  -1500.08
Evaluation/MinReturn                  -1512.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      3.73053
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.31945
GaussianMLPPolicy/KL                      0.00680731
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             161.471
GaussianMLPPolicy/LossBefore            163.246
GaussianMLPPolicy/dLoss                   1.77446
GaussianMLPValueFunction/LossAfter      234.559
GaussianMLPValueFunction/LossBefore     255.44
GaussianMLPValueFunction/dLoss           20.8807
TotalEnvSteps                        120000
-----------------------------------  ---------------
2022-08-17 18:05:47 | [trpo_pendulum] epoch #100 | Saving snapshot...
2022-08-17 18:05:47 | [trpo_pendulum] epoch #100 | Saved
2022-08-17 18:05:47 | [trpo_pendulum] epoch #100 | Time 63.59 s
2022-08-17 18:05:47 | [trpo_pendulum] epoch #100 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -656.093
Evaluation/AverageReturn              -1510.96
Evaluation/Iteration                    100
Evaluation/MaxReturn                  -1504.17
Evaluation/MinReturn                  -1516.58
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      3.83684
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.32194
GaussianMLPPolicy/KL                      0.00764064
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             160.532
GaussianMLPPolicy/LossBefore            162.329
GaussianMLPPolicy/dLoss                   1.79738
GaussianMLPValueFunction/LossAfter      215.458
GaussianMLPValueFunction/LossBefore     233.463
GaussianMLPValueFunction/dLoss           18.0041
TotalEnvSteps                        121200
-----------------------------------  ---------------
2022-08-17 18:05:48 | [trpo_pendulum] epoch #101 | Saving snapshot...
2022-08-17 18:05:48 | [trpo_pendulum] epoch #101 | Saved
2022-08-17 18:05:48 | [trpo_pendulum] epoch #101 | Time 64.22 s
2022-08-17 18:05:48 | [trpo_pendulum] epoch #101 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -390.669
Evaluation/AverageReturn              -1144.38
Evaluation/Iteration                    101
Evaluation/MaxReturn                   -982.897
Evaluation/MinReturn                  -1221.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     85.6858
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.32738
GaussianMLPPolicy/KL                      0.00723165
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             124.297
GaussianMLPPolicy/LossBefore            126.805
GaussianMLPPolicy/dLoss                   2.50802
GaussianMLPValueFunction/LossAfter      137.717
GaussianMLPValueFunction/LossBefore     145.564
GaussianMLPValueFunction/dLoss            7.84688
TotalEnvSteps                        122400
-----------------------------------  ---------------
2022-08-17 18:05:49 | [trpo_pendulum] epoch #102 | Saving snapshot...
2022-08-17 18:05:49 | [trpo_pendulum] epoch #102 | Saved
2022-08-17 18:05:49 | [trpo_pendulum] epoch #102 | Time 64.84 s
2022-08-17 18:05:49 | [trpo_pendulum] epoch #102 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -570.37
Evaluation/AverageReturn              -1413.21
Evaluation/Iteration                    102
Evaluation/MaxReturn                  -1392.71
Evaluation/MinReturn                  -1440.9
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     18.3295
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.33268
GaussianMLPPolicy/KL                      0.00690781
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             153.484
GaussianMLPPolicy/LossBefore            155.554
GaussianMLPPolicy/dLoss                   2.07088
GaussianMLPValueFunction/LossAfter      179.949
GaussianMLPValueFunction/LossBefore     193.609
GaussianMLPValueFunction/dLoss           13.6606
TotalEnvSteps                        123600
-----------------------------------  ---------------
2022-08-17 18:05:49 | [trpo_pendulum] epoch #103 | Saving snapshot...
2022-08-17 18:05:49 | [trpo_pendulum] epoch #103 | Saved
2022-08-17 18:05:49 | [trpo_pendulum] epoch #103 | Time 65.47 s
2022-08-17 18:05:49 | [trpo_pendulum] epoch #103 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -582.678
Evaluation/AverageReturn              -1427.54
Evaluation/Iteration                    103
Evaluation/MaxReturn                  -1406.48
Evaluation/MinReturn                  -1455.26
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     15.5925
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.31698
GaussianMLPPolicy/KL                      0.00598143
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             153.413
GaussianMLPPolicy/LossBefore            155.713
GaussianMLPPolicy/dLoss                   2.30026
GaussianMLPValueFunction/LossAfter      168.579
GaussianMLPValueFunction/LossBefore     181.195
GaussianMLPValueFunction/dLoss           12.6168
TotalEnvSteps                        124800
-----------------------------------  ---------------
2022-08-17 18:05:50 | [trpo_pendulum] epoch #104 | Saving snapshot...
2022-08-17 18:05:50 | [trpo_pendulum] epoch #104 | Saved
2022-08-17 18:05:50 | [trpo_pendulum] epoch #104 | Time 66.11 s
2022-08-17 18:05:50 | [trpo_pendulum] epoch #104 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -571.907
Evaluation/AverageReturn              -1423.41
Evaluation/Iteration                    104
Evaluation/MaxReturn                  -1407.35
Evaluation/MinReturn                  -1437.63
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.5277
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.31016
GaussianMLPPolicy/KL                      0.00669109
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             153.886
GaussianMLPPolicy/LossBefore            156.872
GaussianMLPPolicy/dLoss                   2.98538
GaussianMLPValueFunction/LossAfter      160.457
GaussianMLPValueFunction/LossBefore     172.365
GaussianMLPValueFunction/dLoss           11.908
TotalEnvSteps                        126000
-----------------------------------  ---------------
2022-08-17 18:05:50 | [trpo_pendulum] epoch #105 | Saving snapshot...
2022-08-17 18:05:50 | [trpo_pendulum] epoch #105 | Saved
2022-08-17 18:05:50 | [trpo_pendulum] epoch #105 | Time 66.71 s
2022-08-17 18:05:50 | [trpo_pendulum] epoch #105 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -662.733
Evaluation/AverageReturn              -1518.48
Evaluation/Iteration                    105
Evaluation/MaxReturn                  -1513.93
Evaluation/MinReturn                  -1523.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      3.17643
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.33568
GaussianMLPPolicy/KL                      0.00866118
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             158.305
GaussianMLPPolicy/LossBefore            159.667
GaussianMLPPolicy/dLoss                   1.3616
GaussianMLPValueFunction/LossAfter      152.663
GaussianMLPValueFunction/LossBefore     163.885
GaussianMLPValueFunction/dLoss           11.2222
TotalEnvSteps                        127200
-----------------------------------  ---------------
2022-08-17 18:05:51 | [trpo_pendulum] epoch #106 | Saving snapshot...
2022-08-17 18:05:51 | [trpo_pendulum] epoch #106 | Saved
2022-08-17 18:05:51 | [trpo_pendulum] epoch #106 | Time 67.34 s
2022-08-17 18:05:51 | [trpo_pendulum] epoch #106 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -644.12
Evaluation/AverageReturn              -1502.37
Evaluation/Iteration                    106
Evaluation/MaxReturn                  -1490.8
Evaluation/MinReturn                  -1512.2
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      6.61324
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.38348
GaussianMLPPolicy/KL                      0.00902623
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             158.023
GaussianMLPPolicy/LossBefore            160.067
GaussianMLPPolicy/dLoss                   2.04321
GaussianMLPValueFunction/LossAfter      144.102
GaussianMLPValueFunction/LossBefore     154.531
GaussianMLPValueFunction/dLoss           10.4284
TotalEnvSteps                        128400
-----------------------------------  ---------------
2022-08-17 18:05:52 | [trpo_pendulum] epoch #107 | Saving snapshot...
2022-08-17 18:05:52 | [trpo_pendulum] epoch #107 | Saved
2022-08-17 18:05:52 | [trpo_pendulum] epoch #107 | Time 67.97 s
2022-08-17 18:05:52 | [trpo_pendulum] epoch #107 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -596.742
Evaluation/AverageReturn              -1454.25
Evaluation/Iteration                    107
Evaluation/MaxReturn                  -1443.53
Evaluation/MinReturn                  -1464.41
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      7.93536
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.411
GaussianMLPPolicy/KL                      0.00972998
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             154.85
GaussianMLPPolicy/LossBefore            157.86
GaussianMLPPolicy/dLoss                   3.01076
GaussianMLPValueFunction/LossAfter      133.214
GaussianMLPValueFunction/LossBefore     142.524
GaussianMLPValueFunction/dLoss            9.30951
TotalEnvSteps                        129600
-----------------------------------  ---------------
2022-08-17 18:05:52 | [trpo_pendulum] epoch #108 | Saving snapshot...
2022-08-17 18:05:52 | [trpo_pendulum] epoch #108 | Saved
2022-08-17 18:05:52 | [trpo_pendulum] epoch #108 | Time 68.58 s
2022-08-17 18:05:52 | [trpo_pendulum] epoch #108 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -533.88
Evaluation/AverageReturn              -1371.02
Evaluation/Iteration                    108
Evaluation/MaxReturn                  -1288.56
Evaluation/MinReturn                  -1410.44
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     41.1704
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.39987
GaussianMLPPolicy/KL                      0.00877982
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             146.353
GaussianMLPPolicy/LossBefore            149.245
GaussianMLPPolicy/dLoss                   2.8922
GaussianMLPValueFunction/LossAfter      115.876
GaussianMLPValueFunction/LossBefore     123.274
GaussianMLPValueFunction/dLoss            7.39783
TotalEnvSteps                        130800
-----------------------------------  ---------------
2022-08-17 18:05:53 | [trpo_pendulum] epoch #109 | Saving snapshot...
2022-08-17 18:05:53 | [trpo_pendulum] epoch #109 | Saved
2022-08-17 18:05:53 | [trpo_pendulum] epoch #109 | Time 69.20 s
2022-08-17 18:05:53 | [trpo_pendulum] epoch #109 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -602.457
Evaluation/AverageReturn              -1462.19
Evaluation/Iteration                    109
Evaluation/MaxReturn                  -1447.1
Evaluation/MinReturn                  -1470.56
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.49246
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40296
GaussianMLPPolicy/KL                      0.00978456
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             153.921
GaussianMLPPolicy/LossBefore            157.197
GaussianMLPPolicy/dLoss                   3.27522
GaussianMLPValueFunction/LossAfter      117.422
GaussianMLPValueFunction/LossBefore     125.377
GaussianMLPValueFunction/dLoss            7.95563
TotalEnvSteps                        132000
-----------------------------------  ---------------
2022-08-17 18:05:54 | [trpo_pendulum] epoch #110 | Saving snapshot...
2022-08-17 18:05:54 | [trpo_pendulum] epoch #110 | Saved
2022-08-17 18:05:54 | [trpo_pendulum] epoch #110 | Time 69.82 s
2022-08-17 18:05:54 | [trpo_pendulum] epoch #110 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -640.757
Evaluation/AverageReturn              -1507.26
Evaluation/Iteration                    110
Evaluation/MaxReturn                  -1492.74
Evaluation/MinReturn                  -1518.87
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.11295
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4143
GaussianMLPPolicy/KL                      0.00808053
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             157.229
GaussianMLPPolicy/LossBefore            159.766
GaussianMLPPolicy/dLoss                   2.53728
GaussianMLPValueFunction/LossAfter      113.345
GaussianMLPValueFunction/LossBefore     121.128
GaussianMLPValueFunction/dLoss            7.78316
TotalEnvSteps                        133200
-----------------------------------  ---------------
2022-08-17 18:05:54 | [trpo_pendulum] epoch #111 | Saving snapshot...
2022-08-17 18:05:54 | [trpo_pendulum] epoch #111 | Saved
2022-08-17 18:05:54 | [trpo_pendulum] epoch #111 | Time 70.45 s
2022-08-17 18:05:54 | [trpo_pendulum] epoch #111 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -664.193
Evaluation/AverageReturn              -1533.15
Evaluation/Iteration                    111
Evaluation/MaxReturn                  -1522.52
Evaluation/MinReturn                  -1544.54
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.61496
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.39751
GaussianMLPPolicy/KL                      0.0097255
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             158.053
GaussianMLPPolicy/LossBefore            160.558
GaussianMLPPolicy/dLoss                   2.50558
GaussianMLPValueFunction/LossAfter      107.154
GaussianMLPValueFunction/LossBefore     114.44
GaussianMLPValueFunction/dLoss            7.28661
TotalEnvSteps                        134400
-----------------------------------  --------------
2022-08-17 18:05:55 | [trpo_pendulum] epoch #112 | Saving snapshot...
2022-08-17 18:05:55 | [trpo_pendulum] epoch #112 | Saved
2022-08-17 18:05:55 | [trpo_pendulum] epoch #112 | Time 71.07 s
2022-08-17 18:05:55 | [trpo_pendulum] epoch #112 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -657.096
Evaluation/AverageReturn              -1521.8
Evaluation/Iteration                    112
Evaluation/MaxReturn                  -1516.16
Evaluation/MinReturn                  -1532.53
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.14899
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.3977
GaussianMLPPolicy/KL                      0.00719097
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             156.819
GaussianMLPPolicy/LossBefore            158.889
GaussianMLPPolicy/dLoss                   2.06982
GaussianMLPValueFunction/LossAfter       99.2397
GaussianMLPValueFunction/LossBefore     105.783
GaussianMLPValueFunction/dLoss            6.54289
TotalEnvSteps                        135600
-----------------------------------  ---------------
2022-08-17 18:05:55 | [trpo_pendulum] epoch #113 | Saving snapshot...
2022-08-17 18:05:55 | [trpo_pendulum] epoch #113 | Saved
2022-08-17 18:05:55 | [trpo_pendulum] epoch #113 | Time 71.69 s
2022-08-17 18:05:55 | [trpo_pendulum] epoch #113 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -643.27
Evaluation/AverageReturn              -1507.27
Evaluation/Iteration                    113
Evaluation/MaxReturn                  -1493.9
Evaluation/MinReturn                  -1517.43
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      6.9363
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.39553
GaussianMLPPolicy/KL                      0.00950533
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             155.308
GaussianMLPPolicy/LossBefore            157.892
GaussianMLPPolicy/dLoss                   2.58363
GaussianMLPValueFunction/LossAfter       92.6204
GaussianMLPValueFunction/LossBefore      98.594
GaussianMLPValueFunction/dLoss            5.97352
TotalEnvSteps                        136800
-----------------------------------  ---------------
2022-08-17 18:05:56 | [trpo_pendulum] epoch #114 | Saving snapshot...
2022-08-17 18:05:56 | [trpo_pendulum] epoch #114 | Saved
2022-08-17 18:05:56 | [trpo_pendulum] epoch #114 | Time 72.30 s
2022-08-17 18:05:56 | [trpo_pendulum] epoch #114 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -324.48
Evaluation/AverageReturn              -1070.13
Evaluation/Iteration                    114
Evaluation/MaxReturn                  -1010.3
Evaluation/MinReturn                  -1142.16
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.1829
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.37312
GaussianMLPPolicy/KL                      0.00686011
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             112.9
GaussianMLPPolicy/LossBefore            114.949
GaussianMLPPolicy/dLoss                   2.04916
GaussianMLPValueFunction/LossAfter       57.4515
GaussianMLPValueFunction/LossBefore      59.8623
GaussianMLPValueFunction/dLoss            2.41085
TotalEnvSteps                        138000
-----------------------------------  ---------------
2022-08-17 18:05:57 | [trpo_pendulum] epoch #115 | Saving snapshot...
2022-08-17 18:05:57 | [trpo_pendulum] epoch #115 | Saved
2022-08-17 18:05:57 | [trpo_pendulum] epoch #115 | Time 72.92 s
2022-08-17 18:05:57 | [trpo_pendulum] epoch #115 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -564.906
Evaluation/AverageReturn              -1415.93
Evaluation/Iteration                    115
Evaluation/MaxReturn                  -1404.99
Evaluation/MinReturn                  -1431.45
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.1948
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.35198
GaussianMLPPolicy/KL                      0.00681072
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             148.647
GaussianMLPPolicy/LossBefore            151.201
GaussianMLPPolicy/dLoss                   2.55392
GaussianMLPValueFunction/LossAfter       79.2384
GaussianMLPValueFunction/LossBefore      84.0962
GaussianMLPValueFunction/dLoss            4.85776
TotalEnvSteps                        139200
-----------------------------------  ---------------
2022-08-17 18:05:57 | [trpo_pendulum] epoch #116 | Saving snapshot...
2022-08-17 18:05:57 | [trpo_pendulum] epoch #116 | Saved
2022-08-17 18:05:57 | [trpo_pendulum] epoch #116 | Time 73.56 s
2022-08-17 18:05:57 | [trpo_pendulum] epoch #116 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -624.504
Evaluation/AverageReturn              -1490.32
Evaluation/Iteration                    116
Evaluation/MaxReturn                  -1477.32
Evaluation/MinReturn                  -1499.68
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      7.92015
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.38795
GaussianMLPPolicy/KL                      0.00978314
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             152.573
GaussianMLPPolicy/LossBefore            156.452
GaussianMLPPolicy/dLoss                   3.87904
GaussianMLPValueFunction/LossAfter       78.6904
GaussianMLPValueFunction/LossBefore      83.802
GaussianMLPValueFunction/dLoss            5.11156
TotalEnvSteps                        140400
-----------------------------------  ---------------
2022-08-17 18:05:58 | [trpo_pendulum] epoch #117 | Saving snapshot...
2022-08-17 18:05:58 | [trpo_pendulum] epoch #117 | Saved
2022-08-17 18:05:58 | [trpo_pendulum] epoch #117 | Time 74.20 s
2022-08-17 18:05:58 | [trpo_pendulum] epoch #117 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -645.374
Evaluation/AverageReturn              -1510.28
Evaluation/Iteration                    117
Evaluation/MaxReturn                  -1498.85
Evaluation/MinReturn                  -1529.9
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.4937
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40215
GaussianMLPPolicy/KL                      0.00893921
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             153.87
GaussianMLPPolicy/LossBefore            156.28
GaussianMLPPolicy/dLoss                   2.40958
GaussianMLPValueFunction/LossAfter       74.3586
GaussianMLPValueFunction/LossBefore      79.1433
GaussianMLPValueFunction/dLoss            4.7847
TotalEnvSteps                        141600
-----------------------------------  ---------------
2022-08-17 18:05:59 | [trpo_pendulum] epoch #118 | Saving snapshot...
2022-08-17 18:05:59 | [trpo_pendulum] epoch #118 | Saved
2022-08-17 18:05:59 | [trpo_pendulum] epoch #118 | Time 74.81 s
2022-08-17 18:05:59 | [trpo_pendulum] epoch #118 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -562.729
Evaluation/AverageReturn              -1408.29
Evaluation/Iteration                    118
Evaluation/MaxReturn                  -1359.52
Evaluation/MinReturn                  -1462.99
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     37.3531
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.36217
GaussianMLPPolicy/KL                      0.00720368
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             144.16
GaussianMLPPolicy/LossBefore            147.402
GaussianMLPPolicy/dLoss                   3.24147
GaussianMLPValueFunction/LossAfter       64.4019
GaussianMLPValueFunction/LossBefore      68.1533
GaussianMLPValueFunction/dLoss            3.7514
TotalEnvSteps                        142800
-----------------------------------  ---------------
2022-08-17 18:05:59 | [trpo_pendulum] epoch #119 | Saving snapshot...
2022-08-17 18:05:59 | [trpo_pendulum] epoch #119 | Saved
2022-08-17 18:05:59 | [trpo_pendulum] epoch #119 | Time 75.44 s
2022-08-17 18:05:59 | [trpo_pendulum] epoch #119 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -592.427
Evaluation/AverageReturn              -1450.78
Evaluation/Iteration                    119
Evaluation/MaxReturn                  -1398.88
Evaluation/MinReturn                  -1481.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     25.4431
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.38284
GaussianMLPPolicy/KL                      0.00691496
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             150.587
GaussianMLPPolicy/LossBefore            151.91
GaussianMLPPolicy/dLoss                   1.32324
GaussianMLPValueFunction/LossAfter       63.7946
GaussianMLPValueFunction/LossBefore      67.6662
GaussianMLPValueFunction/dLoss            3.8716
TotalEnvSteps                        144000
-----------------------------------  ---------------
2022-08-17 18:06:00 | [trpo_pendulum] epoch #120 | Saving snapshot...
2022-08-17 18:06:00 | [trpo_pendulum] epoch #120 | Saved
2022-08-17 18:06:00 | [trpo_pendulum] epoch #120 | Time 76.07 s
2022-08-17 18:06:00 | [trpo_pendulum] epoch #120 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -624.216
Evaluation/AverageReturn              -1491
Evaluation/Iteration                    120
Evaluation/MaxReturn                  -1479.22
Evaluation/MinReturn                  -1512.91
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     11.1496
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.37627
GaussianMLPPolicy/KL                      0.0070352
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             152.235
GaussianMLPPolicy/LossBefore            154.751
GaussianMLPPolicy/dLoss                   2.51614
GaussianMLPValueFunction/LossAfter       62.3415
GaussianMLPValueFunction/LossBefore      66.2232
GaussianMLPValueFunction/dLoss            3.88176
TotalEnvSteps                        145200
-----------------------------------  --------------
2022-08-17 18:06:00 | [trpo_pendulum] epoch #121 | Saving snapshot...
2022-08-17 18:06:00 | [trpo_pendulum] epoch #121 | Saved
2022-08-17 18:06:00 | [trpo_pendulum] epoch #121 | Time 76.70 s
2022-08-17 18:06:00 | [trpo_pendulum] epoch #121 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -626.442
Evaluation/AverageReturn              -1488.16
Evaluation/Iteration                    121
Evaluation/MaxReturn                  -1477.43
Evaluation/MinReturn                  -1496.72
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.7508
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.37735
GaussianMLPPolicy/KL                      0.00769456
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             151.085
GaussianMLPPolicy/LossBefore            153.197
GaussianMLPPolicy/dLoss                   2.11188
GaussianMLPValueFunction/LossAfter       58.0721
GaussianMLPValueFunction/LossBefore      61.6014
GaussianMLPValueFunction/dLoss            3.5293
TotalEnvSteps                        146400
-----------------------------------  ---------------
2022-08-17 18:06:01 | [trpo_pendulum] epoch #122 | Saving snapshot...
2022-08-17 18:06:01 | [trpo_pendulum] epoch #122 | Saved
2022-08-17 18:06:01 | [trpo_pendulum] epoch #122 | Time 77.34 s
2022-08-17 18:06:01 | [trpo_pendulum] epoch #122 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -666.355
Evaluation/AverageReturn              -1537.16
Evaluation/Iteration                    122
Evaluation/MaxReturn                  -1523.73
Evaluation/MinReturn                  -1552.52
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.699
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.35014
GaussianMLPPolicy/KL                      0.00752858
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             154.078
GaussianMLPPolicy/LossBefore            156.004
GaussianMLPPolicy/dLoss                   1.9263
GaussianMLPValueFunction/LossAfter       56.3443
GaussianMLPValueFunction/LossBefore      59.8293
GaussianMLPValueFunction/dLoss            3.485
TotalEnvSteps                        147600
-----------------------------------  ---------------
2022-08-17 18:06:02 | [trpo_pendulum] epoch #123 | Saving snapshot...
2022-08-17 18:06:02 | [trpo_pendulum] epoch #123 | Saved
2022-08-17 18:06:02 | [trpo_pendulum] epoch #123 | Time 77.96 s
2022-08-17 18:06:02 | [trpo_pendulum] epoch #123 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -671.045
Evaluation/AverageReturn              -1535.23
Evaluation/Iteration                    123
Evaluation/MaxReturn                  -1524.8
Evaluation/MinReturn                  -1546.53
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      7.94749
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.36077
GaussianMLPPolicy/KL                      0.00973557
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             152.627
GaussianMLPPolicy/LossBefore            153.8
GaussianMLPPolicy/dLoss                   1.17325
GaussianMLPValueFunction/LossAfter       52.0585
GaussianMLPValueFunction/LossBefore      55.1616
GaussianMLPValueFunction/dLoss            3.1031
TotalEnvSteps                        148800
-----------------------------------  ---------------
2022-08-17 18:06:02 | [trpo_pendulum] epoch #124 | Saving snapshot...
2022-08-17 18:06:02 | [trpo_pendulum] epoch #124 | Saved
2022-08-17 18:06:02 | [trpo_pendulum] epoch #124 | Time 78.59 s
2022-08-17 18:06:02 | [trpo_pendulum] epoch #124 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -555.339
Evaluation/AverageReturn              -1418.29
Evaluation/Iteration                    124
Evaluation/MaxReturn                  -1390.51
Evaluation/MinReturn                  -1439.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     15.7455
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.3673
GaussianMLPPolicy/KL                      0.00646781
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             147.184
GaussianMLPPolicy/LossBefore            149.594
GaussianMLPPolicy/dLoss                   2.41093
GaussianMLPValueFunction/LossAfter       47.9386
GaussianMLPValueFunction/LossBefore      50.6854
GaussianMLPValueFunction/dLoss            2.74677
TotalEnvSteps                        150000
-----------------------------------  ---------------
2022-08-17 18:06:03 | [trpo_pendulum] epoch #125 | Saving snapshot...
2022-08-17 18:06:03 | [trpo_pendulum] epoch #125 | Saved
2022-08-17 18:06:03 | [trpo_pendulum] epoch #125 | Time 79.19 s
2022-08-17 18:06:03 | [trpo_pendulum] epoch #125 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -667.791
Evaluation/AverageReturn              -1534.61
Evaluation/Iteration                    125
Evaluation/MaxReturn                  -1519.09
Evaluation/MinReturn                  -1550.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.0604
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.35246
GaussianMLPPolicy/KL                      0.00810059
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             153.003
GaussianMLPPolicy/LossBefore            153.444
GaussianMLPPolicy/dLoss                   0.440948
GaussianMLPValueFunction/LossAfter       46.8248
GaussianMLPValueFunction/LossBefore      49.5665
GaussianMLPValueFunction/dLoss            2.74161
TotalEnvSteps                        151200
-----------------------------------  ---------------
2022-08-17 18:06:04 | [trpo_pendulum] epoch #126 | Saving snapshot...
2022-08-17 18:06:04 | [trpo_pendulum] epoch #126 | Saved
2022-08-17 18:06:04 | [trpo_pendulum] epoch #126 | Time 79.81 s
2022-08-17 18:06:04 | [trpo_pendulum] epoch #126 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -475.24
Evaluation/AverageReturn              -1147.28
Evaluation/Iteration                    126
Evaluation/MaxReturn                  -1002.31
Evaluation/MinReturn                  -1238.94
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     72.1008
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.34269
GaussianMLPPolicy/KL                      0.00720555
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             100.48
GaussianMLPPolicy/LossBefore            101.735
GaussianMLPPolicy/dLoss                   1.25455
GaussianMLPValueFunction/LossAfter       23.7822
GaussianMLPValueFunction/LossBefore      24.4344
GaussianMLPValueFunction/dLoss            0.652203
TotalEnvSteps                        152400
-----------------------------------  ---------------
2022-08-17 18:06:04 | [trpo_pendulum] epoch #127 | Saving snapshot...
2022-08-17 18:06:04 | [trpo_pendulum] epoch #127 | Saved
2022-08-17 18:06:04 | [trpo_pendulum] epoch #127 | Time 80.45 s
2022-08-17 18:06:04 | [trpo_pendulum] epoch #127 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -664.095
Evaluation/AverageReturn              -1541.25
Evaluation/Iteration                    127
Evaluation/MaxReturn                  -1517.87
Evaluation/MinReturn                  -1564.37
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.3809
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.37969
GaussianMLPPolicy/KL                      0.00646532
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             153.576
GaussianMLPPolicy/LossBefore            155.076
GaussianMLPPolicy/dLoss                   1.49992
GaussianMLPValueFunction/LossAfter       43.8951
GaussianMLPValueFunction/LossBefore      46.566
GaussianMLPValueFunction/dLoss            2.67085
TotalEnvSteps                        153600
-----------------------------------  ---------------
2022-08-17 18:06:05 | [trpo_pendulum] epoch #128 | Saving snapshot...
2022-08-17 18:06:05 | [trpo_pendulum] epoch #128 | Saved
2022-08-17 18:06:05 | [trpo_pendulum] epoch #128 | Time 81.07 s
2022-08-17 18:06:05 | [trpo_pendulum] epoch #128 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -644.186
Evaluation/AverageReturn              -1518.76
Evaluation/Iteration                    128
Evaluation/MaxReturn                  -1502.79
Evaluation/MinReturn                  -1547.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     15.9568
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.35393
GaussianMLPPolicy/KL                      0.00987175
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             151.675
GaussianMLPPolicy/LossBefore            153.844
GaussianMLPPolicy/dLoss                   2.16951
GaussianMLPValueFunction/LossAfter       41.2704
GaussianMLPValueFunction/LossBefore      43.7802
GaussianMLPValueFunction/dLoss            2.50982
TotalEnvSteps                        154800
-----------------------------------  ---------------
2022-08-17 18:06:05 | [trpo_pendulum] epoch #129 | Saving snapshot...
2022-08-17 18:06:05 | [trpo_pendulum] epoch #129 | Saved
2022-08-17 18:06:05 | [trpo_pendulum] epoch #129 | Time 81.70 s
2022-08-17 18:06:05 | [trpo_pendulum] epoch #129 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -328.649
Evaluation/AverageReturn               -764.806
Evaluation/Iteration                    129
Evaluation/MaxReturn                   -504.184
Evaluation/MinReturn                   -899.404
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    148.881
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.33872
GaussianMLPPolicy/KL                      0.00814958
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              44.0688
GaussianMLPPolicy/LossBefore             45.5578
GaussianMLPPolicy/dLoss                   1.48904
GaussianMLPValueFunction/LossAfter       10.4301
GaussianMLPValueFunction/LossBefore      10.5086
GaussianMLPValueFunction/dLoss            0.0785275
TotalEnvSteps                        156000
-----------------------------------  ---------------
2022-08-17 18:06:06 | [trpo_pendulum] epoch #130 | Saving snapshot...
2022-08-17 18:06:06 | [trpo_pendulum] epoch #130 | Saved
2022-08-17 18:06:06 | [trpo_pendulum] epoch #130 | Time 82.31 s
2022-08-17 18:06:06 | [trpo_pendulum] epoch #130 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -546.644
Evaluation/AverageReturn              -1352.5
Evaluation/Iteration                    130
Evaluation/MaxReturn                  -1096.31
Evaluation/MinReturn                  -1457.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    119.104
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.31396
GaussianMLPPolicy/KL                      0.00709339
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             130.985
GaussianMLPPolicy/LossBefore            133.229
GaussianMLPPolicy/dLoss                   2.24364
GaussianMLPValueFunction/LossAfter       31.5407
GaussianMLPValueFunction/LossBefore      33.0567
GaussianMLPValueFunction/dLoss            1.51603
TotalEnvSteps                        157200
-----------------------------------  ---------------
2022-08-17 18:06:07 | [trpo_pendulum] epoch #131 | Saving snapshot...
2022-08-17 18:06:07 | [trpo_pendulum] epoch #131 | Saved
2022-08-17 18:06:07 | [trpo_pendulum] epoch #131 | Time 82.93 s
2022-08-17 18:06:07 | [trpo_pendulum] epoch #131 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -666.827
Evaluation/AverageReturn              -1536.54
Evaluation/Iteration                    131
Evaluation/MaxReturn                  -1511.26
Evaluation/MinReturn                  -1551.53
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.3894
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.30128
GaussianMLPPolicy/KL                      0.00927492
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             150.989
GaussianMLPPolicy/LossBefore            152.48
GaussianMLPPolicy/dLoss                   1.4911
GaussianMLPValueFunction/LossAfter       36.112
GaussianMLPValueFunction/LossBefore      38.3685
GaussianMLPValueFunction/dLoss            2.25651
TotalEnvSteps                        158400
-----------------------------------  ---------------
2022-08-17 18:06:07 | [trpo_pendulum] epoch #132 | Saving snapshot...
2022-08-17 18:06:07 | [trpo_pendulum] epoch #132 | Saved
2022-08-17 18:06:07 | [trpo_pendulum] epoch #132 | Time 83.54 s
2022-08-17 18:06:07 | [trpo_pendulum] epoch #132 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -595.595
Evaluation/AverageReturn              -1453.5
Evaluation/Iteration                    132
Evaluation/MaxReturn                  -1441.27
Evaluation/MinReturn                  -1463.51
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.73533
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.33304
GaussianMLPPolicy/KL                      0.00860206
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             145.257
GaussianMLPPolicy/LossBefore            146.914
GaussianMLPPolicy/dLoss                   1.65784
GaussianMLPValueFunction/LossAfter       32.5984
GaussianMLPValueFunction/LossBefore      34.49
GaussianMLPValueFunction/dLoss            1.89158
TotalEnvSteps                        159600
-----------------------------------  ---------------
2022-08-17 18:06:08 | [trpo_pendulum] epoch #133 | Saving snapshot...
2022-08-17 18:06:08 | [trpo_pendulum] epoch #133 | Saved
2022-08-17 18:06:08 | [trpo_pendulum] epoch #133 | Time 84.18 s
2022-08-17 18:06:08 | [trpo_pendulum] epoch #133 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -604.92
Evaluation/AverageReturn              -1468.04
Evaluation/Iteration                    133
Evaluation/MaxReturn                  -1456.49
Evaluation/MinReturn                  -1482.13
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.21514
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.32037
GaussianMLPPolicy/KL                      0.00820664
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             145.887
GaussianMLPPolicy/LossBefore            148.31
GaussianMLPPolicy/dLoss                   2.42316
GaussianMLPValueFunction/LossAfter       31.5289
GaussianMLPValueFunction/LossBefore      33.3589
GaussianMLPValueFunction/dLoss            1.82994
TotalEnvSteps                        160800
-----------------------------------  ---------------
2022-08-17 18:06:09 | [trpo_pendulum] epoch #134 | Saving snapshot...
2022-08-17 18:06:09 | [trpo_pendulum] epoch #134 | Saved
2022-08-17 18:06:09 | [trpo_pendulum] epoch #134 | Time 84.80 s
2022-08-17 18:06:09 | [trpo_pendulum] epoch #134 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -662.295
Evaluation/AverageReturn              -1528.67
Evaluation/Iteration                    134
Evaluation/MaxReturn                  -1514.23
Evaluation/MinReturn                  -1538.34
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      7.83323
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.32066
GaussianMLPPolicy/KL                      0.00991749
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             147.911
GaussianMLPPolicy/LossBefore            149.759
GaussianMLPPolicy/dLoss                   1.84773
GaussianMLPValueFunction/LossAfter       30.2057
GaussianMLPValueFunction/LossBefore      31.9428
GaussianMLPValueFunction/dLoss            1.73717
TotalEnvSteps                        162000
-----------------------------------  ---------------
2022-08-17 18:06:09 | [trpo_pendulum] epoch #135 | Saving snapshot...
2022-08-17 18:06:09 | [trpo_pendulum] epoch #135 | Saved
2022-08-17 18:06:09 | [trpo_pendulum] epoch #135 | Time 85.41 s
2022-08-17 18:06:09 | [trpo_pendulum] epoch #135 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -662.357
Evaluation/AverageReturn              -1524.18
Evaluation/Iteration                    135
Evaluation/MaxReturn                  -1516.28
Evaluation/MinReturn                  -1535.83
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      6.73844
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.29307
GaussianMLPPolicy/KL                      0.0068578
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             146.719
GaussianMLPPolicy/LossBefore            148.663
GaussianMLPPolicy/dLoss                   1.94411
GaussianMLPValueFunction/LossAfter       28.4239
GaussianMLPValueFunction/LossBefore      30.0009
GaussianMLPValueFunction/dLoss            1.577
TotalEnvSteps                        163200
-----------------------------------  --------------
2022-08-17 18:06:10 | [trpo_pendulum] epoch #136 | Saving snapshot...
2022-08-17 18:06:10 | [trpo_pendulum] epoch #136 | Saved
2022-08-17 18:06:10 | [trpo_pendulum] epoch #136 | Time 86.03 s
2022-08-17 18:06:10 | [trpo_pendulum] epoch #136 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -670.236
Evaluation/AverageReturn              -1529.51
Evaluation/Iteration                    136
Evaluation/MaxReturn                  -1521.32
Evaluation/MinReturn                  -1537.82
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.66504
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.30021
GaussianMLPPolicy/KL                      0.0066612
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             147.032
GaussianMLPPolicy/LossBefore            147.374
GaussianMLPPolicy/dLoss                   0.342789
GaussianMLPValueFunction/LossAfter       26.6652
GaussianMLPValueFunction/LossBefore      28.0888
GaussianMLPValueFunction/dLoss            1.4236
TotalEnvSteps                        164400
-----------------------------------  --------------
2022-08-17 18:06:10 | [trpo_pendulum] epoch #137 | Saving snapshot...
2022-08-17 18:06:10 | [trpo_pendulum] epoch #137 | Saved
2022-08-17 18:06:10 | [trpo_pendulum] epoch #137 | Time 86.65 s
2022-08-17 18:06:10 | [trpo_pendulum] epoch #137 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -680.438
Evaluation/AverageReturn              -1547.33
Evaluation/Iteration                    137
Evaluation/MaxReturn                  -1538.69
Evaluation/MinReturn                  -1565.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.38032
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.27444
GaussianMLPPolicy/KL                      0.0071064
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             147.621
GaussianMLPPolicy/LossBefore            149.181
GaussianMLPPolicy/dLoss                   1.56059
GaussianMLPValueFunction/LossAfter       25.8781
GaussianMLPValueFunction/LossBefore      27.2678
GaussianMLPValueFunction/dLoss            1.38973
TotalEnvSteps                        165600
-----------------------------------  --------------
2022-08-17 18:06:11 | [trpo_pendulum] epoch #138 | Saving snapshot...
2022-08-17 18:06:11 | [trpo_pendulum] epoch #138 | Saved
2022-08-17 18:06:11 | [trpo_pendulum] epoch #138 | Time 87.28 s
2022-08-17 18:06:11 | [trpo_pendulum] epoch #138 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -670.216
Evaluation/AverageReturn              -1527.16
Evaluation/Iteration                    138
Evaluation/MaxReturn                  -1522.48
Evaluation/MinReturn                  -1538.02
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.64176
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.29509
GaussianMLPPolicy/KL                      0.00875141
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             144.102
GaussianMLPPolicy/LossBefore            145.852
GaussianMLPPolicy/dLoss                   1.75055
GaussianMLPValueFunction/LossAfter       23.9999
GaussianMLPValueFunction/LossBefore      25.2149
GaussianMLPValueFunction/dLoss            1.21502
TotalEnvSteps                        166800
-----------------------------------  ---------------
2022-08-17 18:06:12 | [trpo_pendulum] epoch #139 | Saving snapshot...
2022-08-17 18:06:12 | [trpo_pendulum] epoch #139 | Saved
2022-08-17 18:06:12 | [trpo_pendulum] epoch #139 | Time 87.92 s
2022-08-17 18:06:12 | [trpo_pendulum] epoch #139 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -629.197
Evaluation/AverageReturn              -1489.44
Evaluation/Iteration                    139
Evaluation/MaxReturn                  -1478.46
Evaluation/MinReturn                  -1512.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     12.3162
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.28653
GaussianMLPPolicy/KL                      0.00697644
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             143.126
GaussianMLPPolicy/LossBefore            145.158
GaussianMLPPolicy/dLoss                   2.03262
GaussianMLPValueFunction/LossAfter       22.8698
GaussianMLPValueFunction/LossBefore      24.003
GaussianMLPValueFunction/dLoss            1.13317
TotalEnvSteps                        168000
-----------------------------------  ---------------
2022-08-17 18:06:12 | [trpo_pendulum] epoch #140 | Saving snapshot...
2022-08-17 18:06:12 | [trpo_pendulum] epoch #140 | Saved
2022-08-17 18:06:12 | [trpo_pendulum] epoch #140 | Time 88.53 s
2022-08-17 18:06:12 | [trpo_pendulum] epoch #140 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -653.272
Evaluation/AverageReturn              -1511.63
Evaluation/Iteration                    140
Evaluation/MaxReturn                  -1506.91
Evaluation/MinReturn                  -1518.46
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      4.78988
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.30998
GaussianMLPPolicy/KL                      0.00600333
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             143.373
GaussianMLPPolicy/LossBefore            144.882
GaussianMLPPolicy/dLoss                   1.50851
GaussianMLPValueFunction/LossAfter       21.7758
GaussianMLPValueFunction/LossBefore      22.8288
GaussianMLPValueFunction/dLoss            1.05301
TotalEnvSteps                        169200
-----------------------------------  ---------------
2022-08-17 18:06:13 | [trpo_pendulum] epoch #141 | Saving snapshot...
2022-08-17 18:06:13 | [trpo_pendulum] epoch #141 | Saved
2022-08-17 18:06:13 | [trpo_pendulum] epoch #141 | Time 89.14 s
2022-08-17 18:06:13 | [trpo_pendulum] epoch #141 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -665.865
Evaluation/AverageReturn              -1531.34
Evaluation/Iteration                    141
Evaluation/MaxReturn                  -1525.77
Evaluation/MinReturn                  -1539.02
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      4.93002
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.31211
GaussianMLPPolicy/KL                      0.00770574
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             145.43
GaussianMLPPolicy/LossBefore            147.009
GaussianMLPPolicy/dLoss                   1.57912
GaussianMLPValueFunction/LossAfter       21.2594
GaussianMLPValueFunction/LossBefore      22.3012
GaussianMLPValueFunction/dLoss            1.04181
TotalEnvSteps                        170400
-----------------------------------  ---------------
2022-08-17 18:06:13 | [trpo_pendulum] epoch #142 | Saving snapshot...
2022-08-17 18:06:14 | [trpo_pendulum] epoch #142 | Saved
2022-08-17 18:06:14 | [trpo_pendulum] epoch #142 | Time 89.78 s
2022-08-17 18:06:14 | [trpo_pendulum] epoch #142 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -546.892
Evaluation/AverageReturn              -1383.61
Evaluation/Iteration                    142
Evaluation/MaxReturn                  -1358.94
Evaluation/MinReturn                  -1422.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     24.7625
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.32577
GaussianMLPPolicy/KL                      0.00819975
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             136.416
GaussianMLPPolicy/LossBefore            137.192
GaussianMLPPolicy/dLoss                   0.775986
GaussianMLPValueFunction/LossAfter       18.9451
GaussianMLPValueFunction/LossBefore      19.7548
GaussianMLPValueFunction/dLoss            0.809687
TotalEnvSteps                        171600
-----------------------------------  ---------------
2022-08-17 18:06:14 | [trpo_pendulum] epoch #143 | Saving snapshot...
2022-08-17 18:06:14 | [trpo_pendulum] epoch #143 | Saved
2022-08-17 18:06:14 | [trpo_pendulum] epoch #143 | Time 90.42 s
2022-08-17 18:06:14 | [trpo_pendulum] epoch #143 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -483.805
Evaluation/AverageReturn              -1262.6
Evaluation/Iteration                    143
Evaluation/MaxReturn                  -1085.98
Evaluation/MinReturn                  -1411.93
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    107.588
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.34951
GaussianMLPPolicy/KL                      0.00962839
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             114.407
GaussianMLPPolicy/LossBefore            116.468
GaussianMLPPolicy/dLoss                   2.06033
GaussianMLPValueFunction/LossAfter       15.476
GaussianMLPValueFunction/LossBefore      15.9619
GaussianMLPValueFunction/dLoss            0.485996
TotalEnvSteps                        172800
-----------------------------------  ---------------
2022-08-17 18:06:15 | [trpo_pendulum] epoch #144 | Saving snapshot...
2022-08-17 18:06:15 | [trpo_pendulum] epoch #144 | Saved
2022-08-17 18:06:15 | [trpo_pendulum] epoch #144 | Time 91.03 s
2022-08-17 18:06:15 | [trpo_pendulum] epoch #144 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -584.85
Evaluation/AverageReturn              -1423.94
Evaluation/Iteration                    144
Evaluation/MaxReturn                  -1372.71
Evaluation/MinReturn                  -1477.35
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     36.6537
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.3778
GaussianMLPPolicy/KL                      0.00996302
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             135.279
GaussianMLPPolicy/LossBefore            137.781
GaussianMLPPolicy/dLoss                   2.5011
GaussianMLPValueFunction/LossAfter       17.6211
GaussianMLPValueFunction/LossBefore      18.3618
GaussianMLPValueFunction/dLoss            0.740612
TotalEnvSteps                        174000
-----------------------------------  ---------------
2022-08-17 18:06:15 | [trpo_pendulum] epoch #145 | Saving snapshot...
2022-08-17 18:06:15 | [trpo_pendulum] epoch #145 | Saved
2022-08-17 18:06:15 | [trpo_pendulum] epoch #145 | Time 91.66 s
2022-08-17 18:06:15 | [trpo_pendulum] epoch #145 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -474.04
Evaluation/AverageReturn              -1140.85
Evaluation/Iteration                    145
Evaluation/MaxReturn                  -1071.41
Evaluation/MinReturn                  -1200.28
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.832
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.38755
GaussianMLPPolicy/KL                      0.00571416
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              90.7446
GaussianMLPPolicy/LossBefore             92.3405
GaussianMLPPolicy/dLoss                   1.59591
GaussianMLPValueFunction/LossAfter       11.1888
GaussianMLPValueFunction/LossBefore      11.3811
GaussianMLPValueFunction/dLoss            0.192246
TotalEnvSteps                        175200
-----------------------------------  ---------------
2022-08-17 18:06:16 | [trpo_pendulum] epoch #146 | Saving snapshot...
2022-08-17 18:06:16 | [trpo_pendulum] epoch #146 | Saved
2022-08-17 18:06:16 | [trpo_pendulum] epoch #146 | Time 92.28 s
2022-08-17 18:06:16 | [trpo_pendulum] epoch #146 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -585.325
Evaluation/AverageReturn              -1419.19
Evaluation/Iteration                    146
Evaluation/MaxReturn                  -1359.1
Evaluation/MinReturn                  -1477.64
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     37.2394
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40128
GaussianMLPPolicy/KL                      0.00588239
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             134.373
GaussianMLPPolicy/LossBefore            135.976
GaussianMLPPolicy/dLoss                   1.60265
GaussianMLPValueFunction/LossAfter       16.3439
GaussianMLPValueFunction/LossBefore      17.019
GaussianMLPValueFunction/dLoss            0.675064
TotalEnvSteps                        176400
-----------------------------------  ---------------
2022-08-17 18:06:17 | [trpo_pendulum] epoch #147 | Saving snapshot...
2022-08-17 18:06:17 | [trpo_pendulum] epoch #147 | Saved
2022-08-17 18:06:17 | [trpo_pendulum] epoch #147 | Time 92.90 s
2022-08-17 18:06:17 | [trpo_pendulum] epoch #147 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -602.254
Evaluation/AverageReturn              -1449.26
Evaluation/Iteration                    147
Evaluation/MaxReturn                  -1401.58
Evaluation/MinReturn                  -1482.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     24.7867
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.38892
GaussianMLPPolicy/KL                      0.00797664
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             134.208
GaussianMLPPolicy/LossBefore            136.519
GaussianMLPPolicy/dLoss                   2.31097
GaussianMLPValueFunction/LossAfter       15.8144
GaussianMLPValueFunction/LossBefore      16.4771
GaussianMLPValueFunction/dLoss            0.66268
TotalEnvSteps                        177600
-----------------------------------  ---------------
2022-08-17 18:06:17 | [trpo_pendulum] epoch #148 | Saving snapshot...
2022-08-17 18:06:17 | [trpo_pendulum] epoch #148 | Saved
2022-08-17 18:06:17 | [trpo_pendulum] epoch #148 | Time 93.52 s
2022-08-17 18:06:17 | [trpo_pendulum] epoch #148 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -615.336
Evaluation/AverageReturn              -1454.01
Evaluation/Iteration                    148
Evaluation/MaxReturn                  -1426.61
Evaluation/MinReturn                  -1499.17
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     29.3892
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.38076
GaussianMLPPolicy/KL                      0.00562169
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             135.777
GaussianMLPPolicy/LossBefore            136.427
GaussianMLPPolicy/dLoss                   0.650345
GaussianMLPValueFunction/LossAfter       15.1773
GaussianMLPValueFunction/LossBefore      15.7909
GaussianMLPValueFunction/dLoss            0.613633
TotalEnvSteps                        178800
-----------------------------------  ---------------
2022-08-17 18:06:18 | [trpo_pendulum] epoch #149 | Saving snapshot...
2022-08-17 18:06:18 | [trpo_pendulum] epoch #149 | Saved
2022-08-17 18:06:18 | [trpo_pendulum] epoch #149 | Time 94.13 s
2022-08-17 18:06:18 | [trpo_pendulum] epoch #149 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -654.552
Evaluation/AverageReturn              -1521.52
Evaluation/Iteration                    149
Evaluation/MaxReturn                  -1513.73
Evaluation/MinReturn                  -1529.89
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.07156
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.37486
GaussianMLPPolicy/KL                      0.00714277
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             142.367
GaussianMLPPolicy/LossBefore            143.406
GaussianMLPPolicy/dLoss                   1.03931
GaussianMLPValueFunction/LossAfter       15.5893
GaussianMLPValueFunction/LossBefore      16.2871
GaussianMLPValueFunction/dLoss            0.697733
TotalEnvSteps                        180000
-----------------------------------  ---------------
2022-08-17 18:06:18 | [trpo_pendulum] epoch #150 | Saving snapshot...
2022-08-17 18:06:18 | [trpo_pendulum] epoch #150 | Saved
2022-08-17 18:06:18 | [trpo_pendulum] epoch #150 | Time 94.74 s
2022-08-17 18:06:18 | [trpo_pendulum] epoch #150 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -660.026
Evaluation/AverageReturn              -1517.66
Evaluation/Iteration                    150
Evaluation/MaxReturn                  -1510.9
Evaluation/MinReturn                  -1526.28
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.46468
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.39959
GaussianMLPPolicy/KL                      0.00697503
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             138.566
GaussianMLPPolicy/LossBefore            140.9
GaussianMLPPolicy/dLoss                   2.33383
GaussianMLPValueFunction/LossAfter       14.7304
GaussianMLPValueFunction/LossBefore      15.3436
GaussianMLPValueFunction/dLoss            0.613216
TotalEnvSteps                        181200
-----------------------------------  ---------------
2022-08-17 18:06:19 | [trpo_pendulum] epoch #151 | Saving snapshot...
2022-08-17 18:06:19 | [trpo_pendulum] epoch #151 | Saved
2022-08-17 18:06:19 | [trpo_pendulum] epoch #151 | Time 95.37 s
2022-08-17 18:06:19 | [trpo_pendulum] epoch #151 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -658.514
Evaluation/AverageReturn              -1513.9
Evaluation/Iteration                    151
Evaluation/MaxReturn                  -1509.22
Evaluation/MinReturn                  -1518.83
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      3.53387
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40071
GaussianMLPPolicy/KL                      0.00706691
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             138.365
GaussianMLPPolicy/LossBefore            139.604
GaussianMLPPolicy/dLoss                   1.23924
GaussianMLPValueFunction/LossAfter       14.0446
GaussianMLPValueFunction/LossBefore      14.5959
GaussianMLPValueFunction/dLoss            0.551348
TotalEnvSteps                        182400
-----------------------------------  ---------------
2022-08-17 18:06:20 | [trpo_pendulum] epoch #152 | Saving snapshot...
2022-08-17 18:06:20 | [trpo_pendulum] epoch #152 | Saved
2022-08-17 18:06:20 | [trpo_pendulum] epoch #152 | Time 96.00 s
2022-08-17 18:06:20 | [trpo_pendulum] epoch #152 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -558.962
Evaluation/AverageReturn              -1293.54
Evaluation/Iteration                    152
Evaluation/MaxReturn                  -1230.98
Evaluation/MinReturn                  -1369.25
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     40.7592
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.43538
GaussianMLPPolicy/KL                      0.00920586
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             107.568
GaussianMLPPolicy/LossBefore            109.826
GaussianMLPPolicy/dLoss                   2.25769
GaussianMLPValueFunction/LossAfter       10.8567
GaussianMLPValueFunction/LossBefore      11.087
GaussianMLPValueFunction/dLoss            0.2303
TotalEnvSteps                        183600
-----------------------------------  ---------------
2022-08-17 18:06:20 | [trpo_pendulum] epoch #153 | Saving snapshot...
2022-08-17 18:06:20 | [trpo_pendulum] epoch #153 | Saved
2022-08-17 18:06:20 | [trpo_pendulum] epoch #153 | Time 96.62 s
2022-08-17 18:06:20 | [trpo_pendulum] epoch #153 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -548.035
Evaluation/AverageReturn              -1424.49
Evaluation/Iteration                    153
Evaluation/MaxReturn                  -1381.34
Evaluation/MinReturn                  -1482.78
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     32.9898
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.43857
GaussianMLPPolicy/KL                      0.00899619
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             134.085
GaussianMLPPolicy/LossBefore            136.578
GaussianMLPPolicy/dLoss                   2.49356
GaussianMLPValueFunction/LossAfter       13.3018
GaussianMLPValueFunction/LossBefore      13.8132
GaussianMLPValueFunction/dLoss            0.511369
TotalEnvSteps                        184800
-----------------------------------  ---------------
2022-08-17 18:06:21 | [trpo_pendulum] epoch #154 | Saving snapshot...
2022-08-17 18:06:21 | [trpo_pendulum] epoch #154 | Saved
2022-08-17 18:06:21 | [trpo_pendulum] epoch #154 | Time 97.27 s
2022-08-17 18:06:21 | [trpo_pendulum] epoch #154 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -684.097
Evaluation/AverageReturn              -1621.96
Evaluation/Iteration                    154
Evaluation/MaxReturn                  -1607.67
Evaluation/MinReturn                  -1635.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.27668
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.44849
GaussianMLPPolicy/KL                      0.00779092
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             155.854
GaussianMLPPolicy/LossBefore            157.97
GaussianMLPPolicy/dLoss                   2.11594
GaussianMLPValueFunction/LossAfter       14.5699
GaussianMLPValueFunction/LossBefore      15.2981
GaussianMLPValueFunction/dLoss            0.72811
TotalEnvSteps                        186000
-----------------------------------  ---------------
2022-08-17 18:06:22 | [trpo_pendulum] epoch #155 | Saving snapshot...
2022-08-17 18:06:22 | [trpo_pendulum] epoch #155 | Saved
2022-08-17 18:06:22 | [trpo_pendulum] epoch #155 | Time 97.89 s
2022-08-17 18:06:22 | [trpo_pendulum] epoch #155 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -682.13
Evaluation/AverageReturn              -1618.72
Evaluation/Iteration                    155
Evaluation/MaxReturn                  -1599.98
Evaluation/MinReturn                  -1633.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     11.4829
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41918
GaussianMLPPolicy/KL                      0.00877756
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             155.557
GaussianMLPPolicy/LossBefore            157.242
GaussianMLPPolicy/dLoss                   1.6848
GaussianMLPValueFunction/LossAfter       13.921
GaussianMLPValueFunction/LossBefore      14.5671
GaussianMLPValueFunction/dLoss            0.64612
TotalEnvSteps                        187200
-----------------------------------  ---------------
2022-08-17 18:06:22 | [trpo_pendulum] epoch #156 | Saving snapshot...
2022-08-17 18:06:22 | [trpo_pendulum] epoch #156 | Saved
2022-08-17 18:06:22 | [trpo_pendulum] epoch #156 | Time 98.53 s
2022-08-17 18:06:22 | [trpo_pendulum] epoch #156 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -665.718
Evaluation/AverageReturn              -1596.53
Evaluation/Iteration                    156
Evaluation/MaxReturn                  -1572.93
Evaluation/MinReturn                  -1612.58
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     11.8964
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41109
GaussianMLPPolicy/KL                      0.00650137
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             152.794
GaussianMLPPolicy/LossBefore            154.36
GaussianMLPPolicy/dLoss                   1.56619
GaussianMLPValueFunction/LossAfter       13.1958
GaussianMLPValueFunction/LossBefore      13.7497
GaussianMLPValueFunction/dLoss            0.553841
TotalEnvSteps                        188400
-----------------------------------  ---------------
2022-08-17 18:06:23 | [trpo_pendulum] epoch #157 | Saving snapshot...
2022-08-17 18:06:23 | [trpo_pendulum] epoch #157 | Saved
2022-08-17 18:06:23 | [trpo_pendulum] epoch #157 | Time 99.15 s
2022-08-17 18:06:23 | [trpo_pendulum] epoch #157 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -504.025
Evaluation/AverageReturn              -1364.61
Evaluation/Iteration                    157
Evaluation/MaxReturn                  -1335.23
Evaluation/MinReturn                  -1467.11
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     46.5481
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.39838
GaussianMLPPolicy/KL                      0.00703374
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             129.157
GaussianMLPPolicy/LossBefore            131.244
GaussianMLPPolicy/dLoss                   2.0863
GaussianMLPValueFunction/LossAfter       11.1483
GaussianMLPValueFunction/LossBefore      11.4546
GaussianMLPValueFunction/dLoss            0.306281
TotalEnvSteps                        189600
-----------------------------------  ---------------
2022-08-17 18:06:23 | [trpo_pendulum] epoch #158 | Saving snapshot...
2022-08-17 18:06:23 | [trpo_pendulum] epoch #158 | Saved
2022-08-17 18:06:23 | [trpo_pendulum] epoch #158 | Time 99.77 s
2022-08-17 18:06:23 | [trpo_pendulum] epoch #158 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -535.662
Evaluation/AverageReturn              -1396.79
Evaluation/Iteration                    158
Evaluation/MaxReturn                  -1192.03
Evaluation/MinReturn                  -1504.31
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    102.725
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42476
GaussianMLPPolicy/KL                      0.0055714
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             129.109
GaussianMLPPolicy/LossBefore            130.336
GaussianMLPPolicy/dLoss                   1.22656
GaussianMLPValueFunction/LossAfter       10.9228
GaussianMLPValueFunction/LossBefore      11.215
GaussianMLPValueFunction/dLoss            0.292202
TotalEnvSteps                        190800
-----------------------------------  --------------
2022-08-17 18:06:24 | [trpo_pendulum] epoch #159 | Saving snapshot...
2022-08-17 18:06:24 | [trpo_pendulum] epoch #159 | Saved
2022-08-17 18:06:24 | [trpo_pendulum] epoch #159 | Time 100.40 s
2022-08-17 18:06:24 | [trpo_pendulum] epoch #159 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -505.033
Evaluation/AverageReturn              -1325.54
Evaluation/Iteration                    159
Evaluation/MaxReturn                  -1273.08
Evaluation/MinReturn                  -1400.73
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     41.0628
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42725
GaussianMLPPolicy/KL                      0.00734265
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             116.698
GaussianMLPPolicy/LossBefore            118.611
GaussianMLPPolicy/dLoss                   1.91318
GaussianMLPValueFunction/LossAfter        9.84658
GaussianMLPValueFunction/LossBefore      10.0422
GaussianMLPValueFunction/dLoss            0.195575
TotalEnvSteps                        192000
-----------------------------------  ---------------
2022-08-17 18:06:25 | [trpo_pendulum] epoch #160 | Saving snapshot...
2022-08-17 18:06:25 | [trpo_pendulum] epoch #160 | Saved
2022-08-17 18:06:25 | [trpo_pendulum] epoch #160 | Time 101.03 s
2022-08-17 18:06:25 | [trpo_pendulum] epoch #160 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -670.107
Evaluation/AverageReturn              -1593.97
Evaluation/Iteration                    160
Evaluation/MaxReturn                  -1578.07
Evaluation/MinReturn                  -1612.14
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.7148
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.43469
GaussianMLPPolicy/KL                      0.00671077
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             150.693
GaussianMLPPolicy/LossBefore            152.1
GaussianMLPPolicy/dLoss                   1.40686
GaussianMLPValueFunction/LossAfter       11.6339
GaussianMLPValueFunction/LossBefore      12.0524
GaussianMLPValueFunction/dLoss            0.418449
TotalEnvSteps                        193200
-----------------------------------  ---------------
2022-08-17 18:06:25 | [trpo_pendulum] epoch #161 | Saving snapshot...
2022-08-17 18:06:25 | [trpo_pendulum] epoch #161 | Saved
2022-08-17 18:06:25 | [trpo_pendulum] epoch #161 | Time 101.67 s
2022-08-17 18:06:25 | [trpo_pendulum] epoch #161 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -663.741
Evaluation/AverageReturn              -1571.94
Evaluation/Iteration                    161
Evaluation/MaxReturn                  -1557.15
Evaluation/MinReturn                  -1597.16
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.0421
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4314
GaussianMLPPolicy/KL                      0.00646256
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             147.669
GaussianMLPPolicy/LossBefore            148.105
GaussianMLPPolicy/dLoss                   0.436798
GaussianMLPValueFunction/LossAfter       11.0506
GaussianMLPValueFunction/LossBefore      11.406
GaussianMLPValueFunction/dLoss            0.355356
TotalEnvSteps                        194400
-----------------------------------  ---------------
2022-08-17 18:06:26 | [trpo_pendulum] epoch #162 | Saving snapshot...
2022-08-17 18:06:26 | [trpo_pendulum] epoch #162 | Saved
2022-08-17 18:06:26 | [trpo_pendulum] epoch #162 | Time 102.29 s
2022-08-17 18:06:26 | [trpo_pendulum] epoch #162 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -613.794
Evaluation/AverageReturn              -1438.6
Evaluation/Iteration                    162
Evaluation/MaxReturn                  -1369.6
Evaluation/MinReturn                  -1481.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     39.6081
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.44535
GaussianMLPPolicy/KL                      0.00690137
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             123.621
GaussianMLPPolicy/LossBefore            125.967
GaussianMLPPolicy/dLoss                   2.34544
GaussianMLPValueFunction/LossAfter        9.50999
GaussianMLPValueFunction/LossBefore       9.69314
GaussianMLPValueFunction/dLoss            0.183148
TotalEnvSteps                        195600
-----------------------------------  ---------------
2022-08-17 18:06:27 | [trpo_pendulum] epoch #163 | Saving snapshot...
2022-08-17 18:06:27 | [trpo_pendulum] epoch #163 | Saved
2022-08-17 18:06:27 | [trpo_pendulum] epoch #163 | Time 102.91 s
2022-08-17 18:06:27 | [trpo_pendulum] epoch #163 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -654.298
Evaluation/AverageReturn              -1549.98
Evaluation/Iteration                    163
Evaluation/MaxReturn                  -1536.44
Evaluation/MinReturn                  -1574.13
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     12.4338
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41049
GaussianMLPPolicy/KL                      0.00658483
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             142.962
GaussianMLPPolicy/LossBefore            144.327
GaussianMLPPolicy/dLoss                   1.36542
GaussianMLPValueFunction/LossAfter       10.3656
GaussianMLPValueFunction/LossBefore      10.6552
GaussianMLPValueFunction/dLoss            0.289518
TotalEnvSteps                        196800
-----------------------------------  ---------------
2022-08-17 18:06:27 | [trpo_pendulum] epoch #164 | Saving snapshot...
2022-08-17 18:06:27 | [trpo_pendulum] epoch #164 | Saved
2022-08-17 18:06:27 | [trpo_pendulum] epoch #164 | Time 103.53 s
2022-08-17 18:06:27 | [trpo_pendulum] epoch #164 | EpochTime 0.61 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn     -650.406
Evaluation/AverageReturn              -1503.44
Evaluation/Iteration                    164
Evaluation/MaxReturn                  -1501.91
Evaluation/MinReturn                  -1504.74
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      0.846991
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40646
GaussianMLPPolicy/KL                      0.00678
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             130.941
GaussianMLPPolicy/LossBefore            133.215
GaussianMLPPolicy/dLoss                   2.27411
GaussianMLPValueFunction/LossAfter        9.48036
GaussianMLPValueFunction/LossBefore       9.67647
GaussianMLPValueFunction/dLoss            0.196107
TotalEnvSteps                        198000
-----------------------------------  -------------
2022-08-17 18:06:28 | [trpo_pendulum] epoch #165 | Saving snapshot...
2022-08-17 18:06:28 | [trpo_pendulum] epoch #165 | Saved
2022-08-17 18:06:28 | [trpo_pendulum] epoch #165 | Time 104.15 s
2022-08-17 18:06:28 | [trpo_pendulum] epoch #165 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -527.391
Evaluation/AverageReturn              -1422.79
Evaluation/Iteration                    165
Evaluation/MaxReturn                  -1372.95
Evaluation/MinReturn                  -1456.74
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     28.0441
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40974
GaussianMLPPolicy/KL                      0.00638616
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             135.973
GaussianMLPPolicy/LossBefore            137.915
GaussianMLPPolicy/dLoss                   1.94127
GaussianMLPValueFunction/LossAfter        9.68331
GaussianMLPValueFunction/LossBefore       9.91103
GaussianMLPValueFunction/dLoss            0.227716
TotalEnvSteps                        199200
-----------------------------------  ---------------
2022-08-17 18:06:28 | [trpo_pendulum] epoch #166 | Saving snapshot...
2022-08-17 18:06:29 | [trpo_pendulum] epoch #166 | Saved
2022-08-17 18:06:29 | [trpo_pendulum] epoch #166 | Time 104.78 s
2022-08-17 18:06:29 | [trpo_pendulum] epoch #166 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -570.789
Evaluation/AverageReturn              -1462.48
Evaluation/Iteration                    166
Evaluation/MaxReturn                  -1388.77
Evaluation/MinReturn                  -1506.58
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     40.1482
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40864
GaussianMLPPolicy/KL                      0.00567165
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             134.913
GaussianMLPPolicy/LossBefore            136.006
GaussianMLPPolicy/dLoss                   1.09285
GaussianMLPValueFunction/LossAfter        9.42783
GaussianMLPValueFunction/LossBefore       9.63444
GaussianMLPValueFunction/dLoss            0.20661
TotalEnvSteps                        200400
-----------------------------------  ---------------
2022-08-17 18:06:29 | [trpo_pendulum] epoch #167 | Saving snapshot...
2022-08-17 18:06:29 | [trpo_pendulum] epoch #167 | Saved
2022-08-17 18:06:29 | [trpo_pendulum] epoch #167 | Time 105.40 s
2022-08-17 18:06:29 | [trpo_pendulum] epoch #167 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -632.559
Evaluation/AverageReturn              -1545.52
Evaluation/Iteration                    167
Evaluation/MaxReturn                  -1518.13
Evaluation/MinReturn                  -1575.35
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     19.9293
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.37647
GaussianMLPPolicy/KL                      0.00649952
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             143.222
GaussianMLPPolicy/LossBefore            144.699
GaussianMLPPolicy/dLoss                   1.47684
GaussianMLPValueFunction/LossAfter        9.55832
GaussianMLPValueFunction/LossBefore       9.78911
GaussianMLPValueFunction/dLoss            0.2308
TotalEnvSteps                        201600
-----------------------------------  ---------------
2022-08-17 18:06:30 | [trpo_pendulum] epoch #168 | Saving snapshot...
2022-08-17 18:06:30 | [trpo_pendulum] epoch #168 | Saved
2022-08-17 18:06:30 | [trpo_pendulum] epoch #168 | Time 106.02 s
2022-08-17 18:06:30 | [trpo_pendulum] epoch #168 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -631.323
Evaluation/AverageReturn              -1537.33
Evaluation/Iteration                    168
Evaluation/MaxReturn                  -1525.02
Evaluation/MinReturn                  -1545.28
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      7.65788
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42579
GaussianMLPPolicy/KL                      0.00817137
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             142.767
GaussianMLPPolicy/LossBefore            144.289
GaussianMLPPolicy/dLoss                   1.52228
GaussianMLPValueFunction/LossAfter        9.37486
GaussianMLPValueFunction/LossBefore       9.58862
GaussianMLPValueFunction/dLoss            0.213754
TotalEnvSteps                        202800
-----------------------------------  ---------------
2022-08-17 18:06:30 | [trpo_pendulum] epoch #169 | Saving snapshot...
2022-08-17 18:06:30 | [trpo_pendulum] epoch #169 | Saved
2022-08-17 18:06:30 | [trpo_pendulum] epoch #169 | Time 106.64 s
2022-08-17 18:06:30 | [trpo_pendulum] epoch #169 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -668.021
Evaluation/AverageReturn              -1598.72
Evaluation/Iteration                    169
Evaluation/MaxReturn                  -1575.44
Evaluation/MinReturn                  -1621.39
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     16.2376
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.43918
GaussianMLPPolicy/KL                      0.00812295
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             148.291
GaussianMLPPolicy/LossBefore            149.609
GaussianMLPPolicy/dLoss                   1.31798
GaussianMLPValueFunction/LossAfter        9.34045
GaussianMLPValueFunction/LossBefore       9.55746
GaussianMLPValueFunction/dLoss            0.21701
TotalEnvSteps                        204000
-----------------------------------  ---------------
2022-08-17 18:06:31 | [trpo_pendulum] epoch #170 | Saving snapshot...
2022-08-17 18:06:31 | [trpo_pendulum] epoch #170 | Saved
2022-08-17 18:06:31 | [trpo_pendulum] epoch #170 | Time 107.28 s
2022-08-17 18:06:31 | [trpo_pendulum] epoch #170 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -581.852
Evaluation/AverageReturn              -1451.8
Evaluation/Iteration                    170
Evaluation/MaxReturn                  -1323.16
Evaluation/MinReturn                  -1507.72
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     60.1063
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.43689
GaussianMLPPolicy/KL                      0.0099131
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             127.335
GaussianMLPPolicy/LossBefore            129.652
GaussianMLPPolicy/dLoss                   2.31744
GaussianMLPValueFunction/LossAfter        8.53064
GaussianMLPValueFunction/LossBefore       8.65608
GaussianMLPValueFunction/dLoss            0.125437
TotalEnvSteps                        205200
-----------------------------------  --------------
2022-08-17 18:06:32 | [trpo_pendulum] epoch #171 | Saving snapshot...
2022-08-17 18:06:32 | [trpo_pendulum] epoch #171 | Saved
2022-08-17 18:06:32 | [trpo_pendulum] epoch #171 | Time 107.91 s
2022-08-17 18:06:32 | [trpo_pendulum] epoch #171 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -574.481
Evaluation/AverageReturn              -1405.76
Evaluation/Iteration                    171
Evaluation/MaxReturn                  -1381.02
Evaluation/MinReturn                  -1430.74
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     16.5505
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4423
GaussianMLPPolicy/KL                      0.0067528
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             117.551
GaussianMLPPolicy/LossBefore            119.905
GaussianMLPPolicy/dLoss                   2.35389
GaussianMLPValueFunction/LossAfter        7.98959
GaussianMLPValueFunction/LossBefore       8.06758
GaussianMLPValueFunction/dLoss            0.0779948
TotalEnvSteps                        206400
-----------------------------------  --------------
2022-08-17 18:06:32 | [trpo_pendulum] epoch #172 | Saving snapshot...
2022-08-17 18:06:32 | [trpo_pendulum] epoch #172 | Saved
2022-08-17 18:06:32 | [trpo_pendulum] epoch #172 | Time 108.53 s
2022-08-17 18:06:32 | [trpo_pendulum] epoch #172 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -614.035
Evaluation/AverageReturn              -1403.54
Evaluation/Iteration                    172
Evaluation/MaxReturn                  -1355.61
Evaluation/MinReturn                  -1446.21
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     32.0192
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.45679
GaussianMLPPolicy/KL                      0.00647602
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             112.57
GaussianMLPPolicy/LossBefore            114.693
GaussianMLPPolicy/dLoss                   2.12305
GaussianMLPValueFunction/LossAfter        7.8508
GaussianMLPValueFunction/LossBefore       7.9185
GaussianMLPValueFunction/dLoss            0.0676961
TotalEnvSteps                        207600
-----------------------------------  ---------------
2022-08-17 18:06:33 | [trpo_pendulum] epoch #173 | Saving snapshot...
2022-08-17 18:06:33 | [trpo_pendulum] epoch #173 | Saved
2022-08-17 18:06:33 | [trpo_pendulum] epoch #173 | Time 109.18 s
2022-08-17 18:06:33 | [trpo_pendulum] epoch #173 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -508.712
Evaluation/AverageReturn              -1357.28
Evaluation/Iteration                    173
Evaluation/MaxReturn                  -1223.81
Evaluation/MinReturn                  -1452.72
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     76.5704
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.47809
GaussianMLPPolicy/KL                      0.00650216
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             117.327
GaussianMLPPolicy/LossBefore            119.065
GaussianMLPPolicy/dLoss                   1.73854
GaussianMLPValueFunction/LossAfter        8.00024
GaussianMLPValueFunction/LossBefore       8.08617
GaussianMLPValueFunction/dLoss            0.0859318
TotalEnvSteps                        208800
-----------------------------------  ---------------
2022-08-17 18:06:34 | [trpo_pendulum] epoch #174 | Saving snapshot...
2022-08-17 18:06:34 | [trpo_pendulum] epoch #174 | Saved
2022-08-17 18:06:34 | [trpo_pendulum] epoch #174 | Time 109.81 s
2022-08-17 18:06:34 | [trpo_pendulum] epoch #174 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -664.186
Evaluation/AverageReturn              -1572.72
Evaluation/Iteration                    174
Evaluation/MaxReturn                  -1562.08
Evaluation/MinReturn                  -1587.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.343
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.46097
GaussianMLPPolicy/KL                      0.0062855
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             141.882
GaussianMLPPolicy/LossBefore            142.456
GaussianMLPPolicy/dLoss                   0.573685
GaussianMLPValueFunction/LossAfter        8.50113
GaussianMLPValueFunction/LossBefore       8.64794
GaussianMLPValueFunction/dLoss            0.146814
TotalEnvSteps                        210000
-----------------------------------  --------------
2022-08-17 18:06:34 | [trpo_pendulum] epoch #175 | Saving snapshot...
2022-08-17 18:06:34 | [trpo_pendulum] epoch #175 | Saved
2022-08-17 18:06:34 | [trpo_pendulum] epoch #175 | Time 110.44 s
2022-08-17 18:06:34 | [trpo_pendulum] epoch #175 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -614.973
Evaluation/AverageReturn              -1494.98
Evaluation/Iteration                    175
Evaluation/MaxReturn                  -1391.73
Evaluation/MinReturn                  -1538.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.2817
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.45401
GaussianMLPPolicy/KL                      0.00802846
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             131.234
GaussianMLPPolicy/LossBefore            132.931
GaussianMLPPolicy/dLoss                   1.69652
GaussianMLPValueFunction/LossAfter        8.16348
GaussianMLPValueFunction/LossBefore       8.27294
GaussianMLPValueFunction/dLoss            0.10946
TotalEnvSteps                        211200
-----------------------------------  ---------------
2022-08-17 18:06:35 | [trpo_pendulum] epoch #176 | Saving snapshot...
2022-08-17 18:06:35 | [trpo_pendulum] epoch #176 | Saved
2022-08-17 18:06:35 | [trpo_pendulum] epoch #176 | Time 111.06 s
2022-08-17 18:06:35 | [trpo_pendulum] epoch #176 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -620.592
Evaluation/AverageReturn              -1490.22
Evaluation/Iteration                    176
Evaluation/MaxReturn                  -1473.06
Evaluation/MinReturn                  -1519.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.9971
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.48137
GaussianMLPPolicy/KL                      0.00729855
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             128.748
GaussianMLPPolicy/LossBefore            130.682
GaussianMLPPolicy/dLoss                   1.9341
GaussianMLPValueFunction/LossAfter        8.01279
GaussianMLPValueFunction/LossBefore       8.10708
GaussianMLPValueFunction/dLoss            0.0942936
TotalEnvSteps                        212400
-----------------------------------  ---------------
2022-08-17 18:06:35 | [trpo_pendulum] epoch #177 | Saving snapshot...
2022-08-17 18:06:35 | [trpo_pendulum] epoch #177 | Saved
2022-08-17 18:06:35 | [trpo_pendulum] epoch #177 | Time 111.69 s
2022-08-17 18:06:35 | [trpo_pendulum] epoch #177 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -486.835
Evaluation/AverageReturn              -1297.08
Evaluation/Iteration                    177
Evaluation/MaxReturn                  -1212.9
Evaluation/MinReturn                  -1423.6
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     83.4842
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.44568
GaussianMLPPolicy/KL                      0.00665414
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             106.028
GaussianMLPPolicy/LossBefore            108.349
GaussianMLPPolicy/dLoss                   2.32129
GaussianMLPValueFunction/LossAfter        7.48697
GaussianMLPValueFunction/LossBefore       7.53315
GaussianMLPValueFunction/dLoss            0.0461798
TotalEnvSteps                        213600
-----------------------------------  ---------------
2022-08-17 18:06:36 | [trpo_pendulum] epoch #178 | Saving snapshot...
2022-08-17 18:06:36 | [trpo_pendulum] epoch #178 | Saved
2022-08-17 18:06:36 | [trpo_pendulum] epoch #178 | Time 112.32 s
2022-08-17 18:06:36 | [trpo_pendulum] epoch #178 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -616.73
Evaluation/AverageReturn              -1493.94
Evaluation/Iteration                    178
Evaluation/MaxReturn                  -1482.65
Evaluation/MinReturn                  -1500.61
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.52351
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.44906
GaussianMLPPolicy/KL                      0.00694222
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             129.989
GaussianMLPPolicy/LossBefore            132.242
GaussianMLPPolicy/dLoss                   2.25333
GaussianMLPValueFunction/LossAfter        7.91355
GaussianMLPValueFunction/LossBefore       8.00228
GaussianMLPValueFunction/dLoss            0.0887256
TotalEnvSteps                        214800
-----------------------------------  ---------------
2022-08-17 18:06:37 | [trpo_pendulum] epoch #179 | Saving snapshot...
2022-08-17 18:06:37 | [trpo_pendulum] epoch #179 | Saved
2022-08-17 18:06:37 | [trpo_pendulum] epoch #179 | Time 112.94 s
2022-08-17 18:06:37 | [trpo_pendulum] epoch #179 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -582.216
Evaluation/AverageReturn              -1471.52
Evaluation/Iteration                    179
Evaluation/MaxReturn                  -1451.89
Evaluation/MinReturn                  -1492.62
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     15.4506
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.45669
GaussianMLPPolicy/KL                      0.0076229
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             130.628
GaussianMLPPolicy/LossBefore            132.711
GaussianMLPPolicy/dLoss                   2.08247
GaussianMLPValueFunction/LossAfter        7.83276
GaussianMLPValueFunction/LossBefore       7.91565
GaussianMLPValueFunction/dLoss            0.0828867
TotalEnvSteps                        216000
-----------------------------------  --------------
2022-08-17 18:06:37 | [trpo_pendulum] epoch #180 | Saving snapshot...
2022-08-17 18:06:37 | [trpo_pendulum] epoch #180 | Saved
2022-08-17 18:06:37 | [trpo_pendulum] epoch #180 | Time 113.59 s
2022-08-17 18:06:37 | [trpo_pendulum] epoch #180 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -647.836
Evaluation/AverageReturn              -1537.12
Evaluation/Iteration                    180
Evaluation/MaxReturn                  -1524.35
Evaluation/MinReturn                  -1554.34
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.6202
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.5045
GaussianMLPPolicy/KL                      0.0098813
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             133.22
GaussianMLPPolicy/LossBefore            135.574
GaussianMLPPolicy/dLoss                   2.35324
GaussianMLPValueFunction/LossAfter        7.84433
GaussianMLPValueFunction/LossBefore       7.92945
GaussianMLPValueFunction/dLoss            0.0851183
TotalEnvSteps                        217200
-----------------------------------  --------------
2022-08-17 18:06:38 | [trpo_pendulum] epoch #181 | Saving snapshot...
2022-08-17 18:06:38 | [trpo_pendulum] epoch #181 | Saved
2022-08-17 18:06:38 | [trpo_pendulum] epoch #181 | Time 114.21 s
2022-08-17 18:06:38 | [trpo_pendulum] epoch #181 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -644.784
Evaluation/AverageReturn              -1507.51
Evaluation/Iteration                    181
Evaluation/MaxReturn                  -1500.2
Evaluation/MinReturn                  -1514.03
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      4.33726
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.51734
GaussianMLPPolicy/KL                      0.00903883
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             124.892
GaussianMLPPolicy/LossBefore            127.822
GaussianMLPPolicy/dLoss                   2.92986
GaussianMLPValueFunction/LossAfter        7.57644
GaussianMLPValueFunction/LossBefore       7.63293
GaussianMLPValueFunction/dLoss            0.0564909
TotalEnvSteps                        218400
-----------------------------------  ---------------
2022-08-17 18:06:39 | [trpo_pendulum] epoch #182 | Saving snapshot...
2022-08-17 18:06:39 | [trpo_pendulum] epoch #182 | Saved
2022-08-17 18:06:39 | [trpo_pendulum] epoch #182 | Time 114.84 s
2022-08-17 18:06:39 | [trpo_pendulum] epoch #182 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -516.631
Evaluation/AverageReturn              -1317.72
Evaluation/Iteration                    182
Evaluation/MaxReturn                  -1054.46
Evaluation/MinReturn                  -1462.12
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    153.893
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.50133
GaussianMLPPolicy/KL                      0.00662648
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             103.102
GaussianMLPPolicy/LossBefore            105.052
GaussianMLPPolicy/dLoss                   1.94955
GaussianMLPValueFunction/LossAfter        7.19999
GaussianMLPValueFunction/LossBefore       7.22537
GaussianMLPValueFunction/dLoss            0.0253825
TotalEnvSteps                        219600
-----------------------------------  ---------------
2022-08-17 18:06:39 | [trpo_pendulum] epoch #183 | Saving snapshot...
2022-08-17 18:06:39 | [trpo_pendulum] epoch #183 | Saved
2022-08-17 18:06:39 | [trpo_pendulum] epoch #183 | Time 115.45 s
2022-08-17 18:06:39 | [trpo_pendulum] epoch #183 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -588.347
Evaluation/AverageReturn              -1471.55
Evaluation/Iteration                    183
Evaluation/MaxReturn                  -1397.04
Evaluation/MinReturn                  -1492.34
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     33.4804
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.49791
GaussianMLPPolicy/KL                      0.00928845
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             127.812
GaussianMLPPolicy/LossBefore            129.866
GaussianMLPPolicy/dLoss                   2.05418
GaussianMLPValueFunction/LossAfter        7.583
GaussianMLPValueFunction/LossBefore       7.64289
GaussianMLPValueFunction/dLoss            0.0598965
TotalEnvSteps                        220800
-----------------------------------  ---------------
2022-08-17 18:06:40 | [trpo_pendulum] epoch #184 | Saving snapshot...
2022-08-17 18:06:40 | [trpo_pendulum] epoch #184 | Saved
2022-08-17 18:06:40 | [trpo_pendulum] epoch #184 | Time 116.08 s
2022-08-17 18:06:40 | [trpo_pendulum] epoch #184 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -533.9
Evaluation/AverageReturn              -1379.65
Evaluation/Iteration                    184
Evaluation/MaxReturn                  -1207.64
Evaluation/MinReturn                  -1466.44
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     95.4425
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.52873
GaussianMLPPolicy/KL                      0.00958598
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             113.028
GaussianMLPPolicy/LossBefore            115.598
GaussianMLPPolicy/dLoss                   2.5705
GaussianMLPValueFunction/LossAfter        7.32714
GaussianMLPValueFunction/LossBefore       7.36282
GaussianMLPValueFunction/dLoss            0.0356784
TotalEnvSteps                        222000
-----------------------------------  ---------------
2022-08-17 18:06:40 | [trpo_pendulum] epoch #185 | Saving snapshot...
2022-08-17 18:06:40 | [trpo_pendulum] epoch #185 | Saved
2022-08-17 18:06:40 | [trpo_pendulum] epoch #185 | Time 116.70 s
2022-08-17 18:06:40 | [trpo_pendulum] epoch #185 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -509.785
Evaluation/AverageReturn              -1369.53
Evaluation/Iteration                    185
Evaluation/MaxReturn                  -1356.41
Evaluation/MinReturn                  -1381.17
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.4943
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.55408
GaussianMLPPolicy/KL                      0.00656777
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             119.142
GaussianMLPPolicy/LossBefore            121.141
GaussianMLPPolicy/dLoss                   1.99969
GaussianMLPValueFunction/LossAfter        7.38548
GaussianMLPValueFunction/LossBefore       7.42643
GaussianMLPValueFunction/dLoss            0.0409479
TotalEnvSteps                        223200
-----------------------------------  ---------------
2022-08-17 18:06:41 | [trpo_pendulum] epoch #186 | Saving snapshot...
2022-08-17 18:06:41 | [trpo_pendulum] epoch #186 | Saved
2022-08-17 18:06:41 | [trpo_pendulum] epoch #186 | Time 117.34 s
2022-08-17 18:06:41 | [trpo_pendulum] epoch #186 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -584.252
Evaluation/AverageReturn              -1459.93
Evaluation/Iteration                    186
Evaluation/MaxReturn                  -1456.7
Evaluation/MinReturn                  -1463.01
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      2.14586
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.57305
GaussianMLPPolicy/KL                      0.00845872
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             122.936
GaussianMLPPolicy/LossBefore            124.517
GaussianMLPPolicy/dLoss                   1.5817
GaussianMLPValueFunction/LossAfter        7.37904
GaussianMLPValueFunction/LossBefore       7.41993
GaussianMLPValueFunction/dLoss            0.0408878
TotalEnvSteps                        224400
-----------------------------------  ---------------
2022-08-17 18:06:42 | [trpo_pendulum] epoch #187 | Saving snapshot...
2022-08-17 18:06:42 | [trpo_pendulum] epoch #187 | Saved
2022-08-17 18:06:42 | [trpo_pendulum] epoch #187 | Time 117.96 s
2022-08-17 18:06:42 | [trpo_pendulum] epoch #187 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -643.387
Evaluation/AverageReturn              -1492.06
Evaluation/Iteration                    187
Evaluation/MaxReturn                  -1492.06
Evaluation/MinReturn                  -1492.06
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      0
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.57146
GaussianMLPPolicy/KL                      0.00558837
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             121.132
GaussianMLPPolicy/LossBefore            121.896
GaussianMLPPolicy/dLoss                   0.764015
GaussianMLPValueFunction/LossAfter        7.28175
GaussianMLPValueFunction/LossBefore       7.31298
GaussianMLPValueFunction/dLoss            0.0312257
TotalEnvSteps                        225600
-----------------------------------  ---------------
2022-08-17 18:06:42 | [trpo_pendulum] epoch #188 | Saving snapshot...
2022-08-17 18:06:42 | [trpo_pendulum] epoch #188 | Saved
2022-08-17 18:06:42 | [trpo_pendulum] epoch #188 | Time 118.58 s
2022-08-17 18:06:42 | [trpo_pendulum] epoch #188 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -656.036
Evaluation/AverageReturn              -1511.69
Evaluation/Iteration                    188
Evaluation/MaxReturn                  -1509.5
Evaluation/MinReturn                  -1513.43
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      1.30054
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.5828
GaussianMLPPolicy/KL                      0.00983819
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             121.352
GaussianMLPPolicy/LossBefore            123.51
GaussianMLPPolicy/dLoss                   2.15819
GaussianMLPValueFunction/LossAfter        7.28183
GaussianMLPValueFunction/LossBefore       7.31279
GaussianMLPValueFunction/dLoss            0.0309668
TotalEnvSteps                        226800
-----------------------------------  ---------------
2022-08-17 18:06:43 | [trpo_pendulum] epoch #189 | Saving snapshot...
2022-08-17 18:06:43 | [trpo_pendulum] epoch #189 | Saved
2022-08-17 18:06:43 | [trpo_pendulum] epoch #189 | Time 119.21 s
2022-08-17 18:06:43 | [trpo_pendulum] epoch #189 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -644.725
Evaluation/AverageReturn              -1492.56
Evaluation/Iteration                    189
Evaluation/MaxReturn                  -1492.45
Evaluation/MinReturn                  -1492.82
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      0.132303
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.58235
GaussianMLPPolicy/KL                      0.00778507
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             119.853
GaussianMLPPolicy/LossBefore            120.854
GaussianMLPPolicy/dLoss                   1.00138
GaussianMLPValueFunction/LossAfter        7.22707
GaussianMLPValueFunction/LossBefore       7.25296
GaussianMLPValueFunction/dLoss            0.0258894
TotalEnvSteps                        228000
-----------------------------------  ---------------
2022-08-17 18:06:44 | [trpo_pendulum] epoch #190 | Saving snapshot...
2022-08-17 18:06:44 | [trpo_pendulum] epoch #190 | Saved
2022-08-17 18:06:44 | [trpo_pendulum] epoch #190 | Time 119.81 s
2022-08-17 18:06:44 | [trpo_pendulum] epoch #190 | EpochTime 0.59 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -615.273
Evaluation/AverageReturn              -1472.92
Evaluation/Iteration                    190
Evaluation/MaxReturn                  -1467.14
Evaluation/MinReturn                  -1483.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.39767
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.56182
GaussianMLPPolicy/KL                      0.00769587
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             120.314
GaussianMLPPolicy/LossBefore            122.195
GaussianMLPPolicy/dLoss                   1.88125
GaussianMLPValueFunction/LossAfter        7.22699
GaussianMLPValueFunction/LossBefore       7.25246
GaussianMLPValueFunction/dLoss            0.0254712
TotalEnvSteps                        229200
-----------------------------------  ---------------
2022-08-17 18:06:44 | [trpo_pendulum] epoch #191 | Saving snapshot...
2022-08-17 18:06:44 | [trpo_pendulum] epoch #191 | Saved
2022-08-17 18:06:44 | [trpo_pendulum] epoch #191 | Time 120.44 s
2022-08-17 18:06:44 | [trpo_pendulum] epoch #191 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -655.381
Evaluation/AverageReturn              -1501.47
Evaluation/Iteration                    191
Evaluation/MaxReturn                  -1499.92
Evaluation/MinReturn                  -1503.95
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      1.52509
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.58387
GaussianMLPPolicy/KL                      0.00643464
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             118.166
GaussianMLPPolicy/LossBefore            119.956
GaussianMLPPolicy/dLoss                   1.78957
GaussianMLPValueFunction/LossAfter        7.18753
GaussianMLPValueFunction/LossBefore       7.20903
GaussianMLPValueFunction/dLoss            0.0215039
TotalEnvSteps                        230400
-----------------------------------  ---------------
2022-08-17 18:06:45 | [trpo_pendulum] epoch #192 | Saving snapshot...
2022-08-17 18:06:45 | [trpo_pendulum] epoch #192 | Saved
2022-08-17 18:06:45 | [trpo_pendulum] epoch #192 | Time 121.06 s
2022-08-17 18:06:45 | [trpo_pendulum] epoch #192 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -556.906
Evaluation/AverageReturn              -1400.21
Evaluation/Iteration                    192
Evaluation/MaxReturn                  -1392.57
Evaluation/MinReturn                  -1407.52
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.04506
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.56533
GaussianMLPPolicy/KL                      0.00964547
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             113.257
GaussianMLPPolicy/LossBefore            115.963
GaussianMLPPolicy/dLoss                   2.70643
GaussianMLPValueFunction/LossAfter        7.12885
GaussianMLPValueFunction/LossBefore       7.14538
GaussianMLPValueFunction/dLoss            0.0165339
TotalEnvSteps                        231600
-----------------------------------  ---------------
2022-08-17 18:06:45 | [trpo_pendulum] epoch #193 | Saving snapshot...
2022-08-17 18:06:45 | [trpo_pendulum] epoch #193 | Saved
2022-08-17 18:06:45 | [trpo_pendulum] epoch #193 | Time 121.67 s
2022-08-17 18:06:45 | [trpo_pendulum] epoch #193 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -193.624
Evaluation/AverageReturn               -790.223
Evaluation/Iteration                    193
Evaluation/MaxReturn                   -738.001
Evaluation/MinReturn                   -844.736
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     36.0431
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.56532
GaussianMLPPolicy/KL                      0.00699607
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              36.8265
GaussianMLPPolicy/LossBefore             38.8714
GaussianMLPPolicy/dLoss                   2.04488
GaussianMLPValueFunction/LossAfter        6.518
GaussianMLPValueFunction/LossBefore       6.527
GaussianMLPValueFunction/dLoss            0.0089941
TotalEnvSteps                        232800
-----------------------------------  ---------------
2022-08-17 18:06:46 | [trpo_pendulum] epoch #194 | Saving snapshot...
2022-08-17 18:06:46 | [trpo_pendulum] epoch #194 | Saved
2022-08-17 18:06:46 | [trpo_pendulum] epoch #194 | Time 122.31 s
2022-08-17 18:06:46 | [trpo_pendulum] epoch #194 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -636.594
Evaluation/AverageReturn              -1484.62
Evaluation/Iteration                    194
Evaluation/MaxReturn                  -1474.99
Evaluation/MinReturn                  -1491.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.5426
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.58306
GaussianMLPPolicy/KL                      0.00647514
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             117.001
GaussianMLPPolicy/LossBefore            118.844
GaussianMLPPolicy/dLoss                   1.84242
GaussianMLPValueFunction/LossAfter        7.16156
GaussianMLPValueFunction/LossBefore       7.18181
GaussianMLPValueFunction/dLoss            0.0202546
TotalEnvSteps                        234000
-----------------------------------  ---------------
2022-08-17 18:06:47 | [trpo_pendulum] epoch #195 | Saving snapshot...
2022-08-17 18:06:47 | [trpo_pendulum] epoch #195 | Saved
2022-08-17 18:06:47 | [trpo_pendulum] epoch #195 | Time 122.93 s
2022-08-17 18:06:47 | [trpo_pendulum] epoch #195 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -643.095
Evaluation/AverageReturn              -1491.87
Evaluation/Iteration                    195
Evaluation/MaxReturn                  -1488.2
Evaluation/MinReturn                  -1493.56
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      1.97957
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.59596
GaussianMLPPolicy/KL                      0.00662677
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             116.793
GaussianMLPPolicy/LossBefore            118.716
GaussianMLPPolicy/dLoss                   1.92269
GaussianMLPValueFunction/LossAfter        7.14522
GaussianMLPValueFunction/LossBefore       7.16447
GaussianMLPValueFunction/dLoss            0.0192432
TotalEnvSteps                        235200
-----------------------------------  ---------------
2022-08-17 18:06:47 | [trpo_pendulum] epoch #196 | Saving snapshot...
2022-08-17 18:06:47 | [trpo_pendulum] epoch #196 | Saved
2022-08-17 18:06:47 | [trpo_pendulum] epoch #196 | Time 123.55 s
2022-08-17 18:06:47 | [trpo_pendulum] epoch #196 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -646.844
Evaluation/AverageReturn              -1497.25
Evaluation/Iteration                    196
Evaluation/MaxReturn                  -1497.24
Evaluation/MinReturn                  -1497.26
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      0.00737273
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.59774
GaussianMLPPolicy/KL                      0.00724977
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             117.851
GaussianMLPPolicy/LossBefore            118.375
GaussianMLPPolicy/dLoss                   0.524025
GaussianMLPValueFunction/LossAfter        7.12158
GaussianMLPValueFunction/LossBefore       7.13771
GaussianMLPValueFunction/dLoss            0.0161271
TotalEnvSteps                        236400
-----------------------------------  ---------------
2022-08-17 18:06:48 | [trpo_pendulum] epoch #197 | Saving snapshot...
2022-08-17 18:06:48 | [trpo_pendulum] epoch #197 | Saved
2022-08-17 18:06:48 | [trpo_pendulum] epoch #197 | Time 124.16 s
2022-08-17 18:06:48 | [trpo_pendulum] epoch #197 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -68.4623
Evaluation/AverageReturn               -269.902
Evaluation/Iteration                    197
Evaluation/MaxReturn                    -11.6494
Evaluation/MinReturn                   -939.49
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    372.947
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.58267
GaussianMLPPolicy/KL                      0.00659879
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -50.3794
GaussianMLPPolicy/LossBefore            -48.718
GaussianMLPPolicy/dLoss                   1.6614
GaussianMLPValueFunction/LossAfter        6.68587
GaussianMLPValueFunction/LossBefore       6.69055
GaussianMLPValueFunction/dLoss            0.00468636
TotalEnvSteps                        237600
-----------------------------------  ---------------
2022-08-17 18:06:48 | [trpo_pendulum] epoch #198 | Saving snapshot...
2022-08-17 18:06:48 | [trpo_pendulum] epoch #198 | Saved
2022-08-17 18:06:48 | [trpo_pendulum] epoch #198 | Time 124.77 s
2022-08-17 18:06:48 | [trpo_pendulum] epoch #198 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -635.786
Evaluation/AverageReturn              -1483.06
Evaluation/Iteration                    198
Evaluation/MaxReturn                  -1476.45
Evaluation/MinReturn                  -1490
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      4.78803
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.55927
GaussianMLPPolicy/KL                      0.00695748
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             115.371
GaussianMLPPolicy/LossBefore            117.753
GaussianMLPPolicy/dLoss                   2.38171
GaussianMLPValueFunction/LossAfter        7.11884
GaussianMLPValueFunction/LossBefore       7.13495
GaussianMLPValueFunction/dLoss            0.0161123
TotalEnvSteps                        238800
-----------------------------------  ---------------
2022-08-17 18:06:49 | [trpo_pendulum] epoch #199 | Saving snapshot...
2022-08-17 18:06:49 | [trpo_pendulum] epoch #199 | Saved
2022-08-17 18:06:49 | [trpo_pendulum] epoch #199 | Time 125.39 s
2022-08-17 18:06:49 | [trpo_pendulum] epoch #199 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -630.793
Evaluation/AverageReturn              -1485.52
Evaluation/Iteration                    199
Evaluation/MaxReturn                  -1484.06
Evaluation/MinReturn                  -1486.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      0.850492
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.54173
GaussianMLPPolicy/KL                      0.0065919
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             116.416
GaussianMLPPolicy/LossBefore            118.58
GaussianMLPPolicy/dLoss                   2.16376
GaussianMLPValueFunction/LossAfter        7.10824
GaussianMLPValueFunction/LossBefore       7.12343
GaussianMLPValueFunction/dLoss            0.0151892
TotalEnvSteps                        240000
-----------------------------------  --------------
2022-08-17 18:06:50 | [trpo_pendulum] epoch #200 | Saving snapshot...
2022-08-17 18:06:50 | [trpo_pendulum] epoch #200 | Saved
2022-08-17 18:06:50 | [trpo_pendulum] epoch #200 | Time 126.00 s
2022-08-17 18:06:50 | [trpo_pendulum] epoch #200 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -649.729
Evaluation/AverageReturn              -1495.73
Evaluation/Iteration                    200
Evaluation/MaxReturn                  -1493.55
Evaluation/MinReturn                  -1497.82
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      1.40739
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.57187
GaussianMLPPolicy/KL                      0.00918416
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             114.08
GaussianMLPPolicy/LossBefore            116.252
GaussianMLPPolicy/dLoss                   2.17113
GaussianMLPValueFunction/LossAfter        7.08592
GaussianMLPValueFunction/LossBefore       7.09788
GaussianMLPValueFunction/dLoss            0.0119538
TotalEnvSteps                        241200
-----------------------------------  ---------------
2022-08-17 18:06:50 | [trpo_pendulum] epoch #201 | Saving snapshot...
2022-08-17 18:06:50 | [trpo_pendulum] epoch #201 | Saved
2022-08-17 18:06:50 | [trpo_pendulum] epoch #201 | Time 126.60 s
2022-08-17 18:06:50 | [trpo_pendulum] epoch #201 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -587.517
Evaluation/AverageReturn              -1439.2
Evaluation/Iteration                    201
Evaluation/MaxReturn                  -1436.95
Evaluation/MinReturn                  -1440.62
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      1.25617
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.55613
GaussianMLPPolicy/KL                      0.00796817
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             112.929
GaussianMLPPolicy/LossBefore            115.775
GaussianMLPPolicy/dLoss                   2.84544
GaussianMLPValueFunction/LossAfter        7.07633
GaussianMLPValueFunction/LossBefore       7.0865
GaussianMLPValueFunction/dLoss            0.0101638
TotalEnvSteps                        242400
-----------------------------------  ---------------
2022-08-17 18:06:51 | [trpo_pendulum] epoch #202 | Saving snapshot...
2022-08-17 18:06:51 | [trpo_pendulum] epoch #202 | Saved
2022-08-17 18:06:51 | [trpo_pendulum] epoch #202 | Time 127.24 s
2022-08-17 18:06:51 | [trpo_pendulum] epoch #202 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -635.485
Evaluation/AverageReturn              -1483
Evaluation/Iteration                    202
Evaluation/MaxReturn                  -1478.42
Evaluation/MinReturn                  -1487.87
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      3.64055
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.57965
GaussianMLPPolicy/KL                      0.00808035
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             113.483
GaussianMLPPolicy/LossBefore            115.66
GaussianMLPPolicy/dLoss                   2.17727
GaussianMLPValueFunction/LossAfter        7.0736
GaussianMLPValueFunction/LossBefore       7.08266
GaussianMLPValueFunction/dLoss            0.00905895
TotalEnvSteps                        243600
-----------------------------------  ---------------
2022-08-17 18:06:52 | [trpo_pendulum] epoch #203 | Saving snapshot...
2022-08-17 18:06:52 | [trpo_pendulum] epoch #203 | Saved
2022-08-17 18:06:52 | [trpo_pendulum] epoch #203 | Time 127.97 s
2022-08-17 18:06:52 | [trpo_pendulum] epoch #203 | EpochTime 0.73 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -643.652
Evaluation/AverageReturn              -1498.97
Evaluation/Iteration                    203
Evaluation/MaxReturn                  -1498.56
Evaluation/MinReturn                  -1499.28
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      0.290074
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.55514
GaussianMLPPolicy/KL                      0.00942788
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             114.99
GaussianMLPPolicy/LossBefore            116.841
GaussianMLPPolicy/dLoss                   1.85138
GaussianMLPValueFunction/LossAfter        7.07196
GaussianMLPValueFunction/LossBefore       7.08014
GaussianMLPValueFunction/dLoss            0.00818682
TotalEnvSteps                        244800
-----------------------------------  ---------------
2022-08-17 18:06:52 | [trpo_pendulum] epoch #204 | Saving snapshot...
2022-08-17 18:06:52 | [trpo_pendulum] epoch #204 | Saved
2022-08-17 18:06:52 | [trpo_pendulum] epoch #204 | Time 128.59 s
2022-08-17 18:06:52 | [trpo_pendulum] epoch #204 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -632.664
Evaluation/AverageReturn              -1478.33
Evaluation/Iteration                    204
Evaluation/MaxReturn                  -1465.95
Evaluation/MinReturn                  -1482.74
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.67706
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.5987
GaussianMLPPolicy/KL                      0.00967894
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             111.25
GaussianMLPPolicy/LossBefore            113.767
GaussianMLPPolicy/dLoss                   2.51711
GaussianMLPValueFunction/LossAfter        7.05292
GaussianMLPValueFunction/LossBefore       7.05918
GaussianMLPValueFunction/dLoss            0.00625324
TotalEnvSteps                        246000
-----------------------------------  ---------------
2022-08-17 18:06:53 | [trpo_pendulum] epoch #205 | Saving snapshot...
2022-08-17 18:06:53 | [trpo_pendulum] epoch #205 | Saved
2022-08-17 18:06:53 | [trpo_pendulum] epoch #205 | Time 129.22 s
2022-08-17 18:06:53 | [trpo_pendulum] epoch #205 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -627.495
Evaluation/AverageReturn              -1473.88
Evaluation/Iteration                    205
Evaluation/MaxReturn                  -1470.17
Evaluation/MinReturn                  -1479.42
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      3.31253
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.60088
GaussianMLPPolicy/KL                      0.00860836
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             111.606
GaussianMLPPolicy/LossBefore            113.427
GaussianMLPPolicy/dLoss                   1.82138
GaussianMLPValueFunction/LossAfter        7.04958
GaussianMLPValueFunction/LossBefore       7.05519
GaussianMLPValueFunction/dLoss            0.00560856
TotalEnvSteps                        247200
-----------------------------------  ---------------
2022-08-17 18:06:54 | [trpo_pendulum] epoch #206 | Saving snapshot...
2022-08-17 18:06:54 | [trpo_pendulum] epoch #206 | Saved
2022-08-17 18:06:54 | [trpo_pendulum] epoch #206 | Time 129.85 s
2022-08-17 18:06:54 | [trpo_pendulum] epoch #206 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -656.444
Evaluation/AverageReturn              -1501.9
Evaluation/Iteration                    206
Evaluation/MaxReturn                  -1501.41
Evaluation/MinReturn                  -1503.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      0.721251
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.59751
GaussianMLPPolicy/KL                      0.00702447
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             111.081
GaussianMLPPolicy/LossBefore            112.821
GaussianMLPPolicy/dLoss                   1.73941
GaussianMLPValueFunction/LossAfter        7.04152
GaussianMLPValueFunction/LossBefore       7.04638
GaussianMLPValueFunction/dLoss            0.00486422
TotalEnvSteps                        248400
-----------------------------------  ---------------
2022-08-17 18:06:54 | [trpo_pendulum] epoch #207 | Saving snapshot...
2022-08-17 18:06:54 | [trpo_pendulum] epoch #207 | Saved
2022-08-17 18:06:54 | [trpo_pendulum] epoch #207 | Time 130.46 s
2022-08-17 18:06:54 | [trpo_pendulum] epoch #207 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -650.439
Evaluation/AverageReturn              -1505.75
Evaluation/Iteration                    207
Evaluation/MaxReturn                  -1504.47
Evaluation/MinReturn                  -1507.79
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      1.01179
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.58549
GaussianMLPPolicy/KL                      0.00706593
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             112.578
GaussianMLPPolicy/LossBefore            114.753
GaussianMLPPolicy/dLoss                   2.17466
GaussianMLPValueFunction/LossAfter        7.05088
GaussianMLPValueFunction/LossBefore       7.05594
GaussianMLPValueFunction/dLoss            0.00506067
TotalEnvSteps                        249600
-----------------------------------  ---------------
2022-08-17 18:06:55 | [trpo_pendulum] epoch #208 | Saving snapshot...
2022-08-17 18:06:55 | [trpo_pendulum] epoch #208 | Saved
2022-08-17 18:06:55 | [trpo_pendulum] epoch #208 | Time 131.07 s
2022-08-17 18:06:55 | [trpo_pendulum] epoch #208 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -279.95
Evaluation/AverageReturn               -983.476
Evaluation/Iteration                    208
Evaluation/MaxReturn                   -911.79
Evaluation/MinReturn                  -1020.7
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     35.8338
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.58043
GaussianMLPPolicy/KL                      0.00751233
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              58.5532
GaussianMLPPolicy/LossBefore             61.1965
GaussianMLPPolicy/dLoss                   2.64327
GaussianMLPValueFunction/LossAfter        6.73371
GaussianMLPValueFunction/LossBefore       6.75463
GaussianMLPValueFunction/dLoss            0.0209203
TotalEnvSteps                        250800
-----------------------------------  ---------------
2022-08-17 18:06:55 | [trpo_pendulum] epoch #209 | Saving snapshot...
2022-08-17 18:06:55 | [trpo_pendulum] epoch #209 | Saved
2022-08-17 18:06:55 | [trpo_pendulum] epoch #209 | Time 131.68 s
2022-08-17 18:06:55 | [trpo_pendulum] epoch #209 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -655.559
Evaluation/AverageReturn              -1501.05
Evaluation/Iteration                    209
Evaluation/MaxReturn                  -1499.65
Evaluation/MinReturn                  -1505.29
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      1.937
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.59788
GaussianMLPPolicy/KL                      0.00942043
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             109.302
GaussianMLPPolicy/LossBefore            111.218
GaussianMLPPolicy/dLoss                   1.91575
GaussianMLPValueFunction/LossAfter        7.03116
GaussianMLPValueFunction/LossBefore       7.03705
GaussianMLPValueFunction/dLoss            0.0058918
TotalEnvSteps                        252000
-----------------------------------  ---------------
2022-08-17 18:06:56 | [trpo_pendulum] epoch #210 | Saving snapshot...
2022-08-17 18:06:56 | [trpo_pendulum] epoch #210 | Saved
2022-08-17 18:06:56 | [trpo_pendulum] epoch #210 | Time 132.31 s
2022-08-17 18:06:56 | [trpo_pendulum] epoch #210 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -509.285
Evaluation/AverageReturn              -1341.2
Evaluation/Iteration                    210
Evaluation/MaxReturn                  -1320.62
Evaluation/MinReturn                  -1364.95
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     19.7858
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.60421
GaussianMLPPolicy/KL                      0.00672566
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             100.078
GaussianMLPPolicy/LossBefore            102.611
GaussianMLPPolicy/dLoss                   2.53297
GaussianMLPValueFunction/LossAfter        6.97174
GaussianMLPValueFunction/LossBefore       6.97582
GaussianMLPValueFunction/dLoss            0.0040822
TotalEnvSteps                        253200
-----------------------------------  ---------------
2022-08-17 18:06:57 | [trpo_pendulum] epoch #211 | Saving snapshot...
2022-08-17 18:06:57 | [trpo_pendulum] epoch #211 | Saved
2022-08-17 18:06:57 | [trpo_pendulum] epoch #211 | Time 132.92 s
2022-08-17 18:06:57 | [trpo_pendulum] epoch #211 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -647.287
Evaluation/AverageReturn              -1501.51
Evaluation/Iteration                    211
Evaluation/MaxReturn                  -1499.87
Evaluation/MinReturn                  -1502.95
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      1.23752
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.57304
GaussianMLPPolicy/KL                      0.00806381
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             110.822
GaussianMLPPolicy/LossBefore            112.239
GaussianMLPPolicy/dLoss                   1.41725
GaussianMLPValueFunction/LossAfter        7.03486
GaussianMLPValueFunction/LossBefore       7.04085
GaussianMLPValueFunction/dLoss            0.0059948
TotalEnvSteps                        254400
-----------------------------------  ---------------
2022-08-17 18:06:57 | [trpo_pendulum] epoch #212 | Saving snapshot...
2022-08-17 18:06:57 | [trpo_pendulum] epoch #212 | Saved
2022-08-17 18:06:57 | [trpo_pendulum] epoch #212 | Time 133.55 s
2022-08-17 18:06:57 | [trpo_pendulum] epoch #212 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -644.68
Evaluation/AverageReturn              -1492.65
Evaluation/Iteration                    212
Evaluation/MaxReturn                  -1492.14
Evaluation/MinReturn                  -1493.79
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      0.538444
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.56974
GaussianMLPPolicy/KL                      0.00767799
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             108.396
GaussianMLPPolicy/LossBefore            109.625
GaussianMLPPolicy/dLoss                   1.22893
GaussianMLPValueFunction/LossAfter        7.016
GaussianMLPValueFunction/LossBefore       7.0206
GaussianMLPValueFunction/dLoss            0.00460768
TotalEnvSteps                        255600
-----------------------------------  ---------------
2022-08-17 18:06:58 | [trpo_pendulum] epoch #213 | Saving snapshot...
2022-08-17 18:06:58 | [trpo_pendulum] epoch #213 | Saved
2022-08-17 18:06:58 | [trpo_pendulum] epoch #213 | Time 134.19 s
2022-08-17 18:06:58 | [trpo_pendulum] epoch #213 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -658.924
Evaluation/AverageReturn              -1506.09
Evaluation/Iteration                    213
Evaluation/MaxReturn                  -1502.43
Evaluation/MinReturn                  -1510.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      2.54287
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.56626
GaussianMLPPolicy/KL                      0.00692595
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             106.67
GaussianMLPPolicy/LossBefore            109.433
GaussianMLPPolicy/dLoss                   2.76302
GaussianMLPValueFunction/LossAfter        7.01921
GaussianMLPValueFunction/LossBefore       7.02359
GaussianMLPValueFunction/dLoss            0.00438499
TotalEnvSteps                        256800
-----------------------------------  ---------------
2022-08-17 18:06:58 | [trpo_pendulum] epoch #214 | Saving snapshot...
2022-08-17 18:06:59 | [trpo_pendulum] epoch #214 | Saved
2022-08-17 18:06:59 | [trpo_pendulum] epoch #214 | Time 134.79 s
2022-08-17 18:06:59 | [trpo_pendulum] epoch #214 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -615.665
Evaluation/AverageReturn              -1458.13
Evaluation/Iteration                    214
Evaluation/MaxReturn                  -1440.09
Evaluation/MinReturn                  -1472.61
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.5381
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.55477
GaussianMLPPolicy/KL                      0.00970836
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             103.562
GaussianMLPPolicy/LossBefore            106.098
GaussianMLPPolicy/dLoss                   2.53693
GaussianMLPValueFunction/LossAfter        6.99853
GaussianMLPValueFunction/LossBefore       7.00242
GaussianMLPValueFunction/dLoss            0.00388622
TotalEnvSteps                        258000
-----------------------------------  ---------------
2022-08-17 18:06:59 | [trpo_pendulum] epoch #215 | Saving snapshot...
2022-08-17 18:06:59 | [trpo_pendulum] epoch #215 | Saved
2022-08-17 18:06:59 | [trpo_pendulum] epoch #215 | Time 135.43 s
2022-08-17 18:06:59 | [trpo_pendulum] epoch #215 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -660.386
Evaluation/AverageReturn              -1514.99
Evaluation/Iteration                    215
Evaluation/MaxReturn                  -1511.78
Evaluation/MinReturn                  -1517.96
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      2.00902
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.50782
GaussianMLPPolicy/KL                      0.00647575
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             108.464
GaussianMLPPolicy/LossBefore            109.981
GaussianMLPPolicy/dLoss                   1.51627
GaussianMLPValueFunction/LossAfter        7.01799
GaussianMLPValueFunction/LossBefore       7.02228
GaussianMLPValueFunction/dLoss            0.00428486
TotalEnvSteps                        259200
-----------------------------------  ---------------
2022-08-17 18:07:00 | [trpo_pendulum] epoch #216 | Saving snapshot...
2022-08-17 18:07:00 | [trpo_pendulum] epoch #216 | Saved
2022-08-17 18:07:00 | [trpo_pendulum] epoch #216 | Time 136.06 s
2022-08-17 18:07:00 | [trpo_pendulum] epoch #216 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -610.494
Evaluation/AverageReturn              -1477.49
Evaluation/Iteration                    216
Evaluation/MaxReturn                  -1399.46
Evaluation/MinReturn                  -1506.38
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     35.9066
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.49155
GaussianMLPPolicy/KL                      0.00576824
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             108.406
GaussianMLPPolicy/LossBefore            110.063
GaussianMLPPolicy/dLoss                   1.6574
GaussianMLPValueFunction/LossAfter        7.03219
GaussianMLPValueFunction/LossBefore       7.03684
GaussianMLPValueFunction/dLoss            0.0046525
TotalEnvSteps                        260400
-----------------------------------  ---------------
2022-08-17 18:07:00 | [trpo_pendulum] epoch #217 | Saving snapshot...
2022-08-17 18:07:00 | [trpo_pendulum] epoch #217 | Saved
2022-08-17 18:07:00 | [trpo_pendulum] epoch #217 | Time 136.66 s
2022-08-17 18:07:00 | [trpo_pendulum] epoch #217 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -363.033
Evaluation/AverageReturn              -1024.15
Evaluation/Iteration                    217
Evaluation/MaxReturn                   -805.43
Evaluation/MinReturn                  -1349.96
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    175.175
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.49234
GaussianMLPPolicy/KL                      0.00832353
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              46.275
GaussianMLPPolicy/LossBefore             47.6884
GaussianMLPPolicy/dLoss                   1.41338
GaussianMLPValueFunction/LossAfter        6.65999
GaussianMLPValueFunction/LossBefore       6.70989
GaussianMLPValueFunction/dLoss            0.0498948
TotalEnvSteps                        261600
-----------------------------------  ---------------
2022-08-17 18:07:01 | [trpo_pendulum] epoch #218 | Saving snapshot...
2022-08-17 18:07:01 | [trpo_pendulum] epoch #218 | Saved
2022-08-17 18:07:01 | [trpo_pendulum] epoch #218 | Time 137.29 s
2022-08-17 18:07:01 | [trpo_pendulum] epoch #218 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -644.969
Evaluation/AverageReturn              -1492.33
Evaluation/Iteration                    218
Evaluation/MaxReturn                  -1491.85
Evaluation/MinReturn                  -1493.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      0.660119
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.48033
GaussianMLPPolicy/KL                      0.00940307
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             104.585
GaussianMLPPolicy/LossBefore            105.968
GaussianMLPPolicy/dLoss                   1.38287
GaussianMLPValueFunction/LossAfter        6.9955
GaussianMLPValueFunction/LossBefore       7.00255
GaussianMLPValueFunction/dLoss            0.00704813
TotalEnvSteps                        262800
-----------------------------------  ---------------
2022-08-17 18:07:02 | [trpo_pendulum] epoch #219 | Saving snapshot...
2022-08-17 18:07:02 | [trpo_pendulum] epoch #219 | Saved
2022-08-17 18:07:02 | [trpo_pendulum] epoch #219 | Time 137.90 s
2022-08-17 18:07:02 | [trpo_pendulum] epoch #219 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -583.423
Evaluation/AverageReturn              -1425.04
Evaluation/Iteration                    219
Evaluation/MaxReturn                  -1421.07
Evaluation/MinReturn                  -1429.76
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      2.71807
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.47716
GaussianMLPPolicy/KL                      0.00802847
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             100.368
GaussianMLPPolicy/LossBefore            102.426
GaussianMLPPolicy/dLoss                   2.05882
GaussianMLPValueFunction/LossAfter        6.97371
GaussianMLPValueFunction/LossBefore       6.979
GaussianMLPValueFunction/dLoss            0.00529528
TotalEnvSteps                        264000
-----------------------------------  ---------------
2022-08-17 18:07:02 | [trpo_pendulum] epoch #220 | Saving snapshot...
2022-08-17 18:07:02 | [trpo_pendulum] epoch #220 | Saved
2022-08-17 18:07:02 | [trpo_pendulum] epoch #220 | Time 138.54 s
2022-08-17 18:07:02 | [trpo_pendulum] epoch #220 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -650.725
Evaluation/AverageReturn              -1499.64
Evaluation/Iteration                    220
Evaluation/MaxReturn                  -1489.17
Evaluation/MinReturn                  -1506.06
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.4732
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.48587
GaussianMLPPolicy/KL                      0.00845824
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             103.15
GaussianMLPPolicy/LossBefore            105.327
GaussianMLPPolicy/dLoss                   2.17654
GaussianMLPValueFunction/LossAfter        6.9956
GaussianMLPValueFunction/LossBefore       7.00128
GaussianMLPValueFunction/dLoss            0.00567102
TotalEnvSteps                        265200
-----------------------------------  ---------------
2022-08-17 18:07:03 | [trpo_pendulum] epoch #221 | Saving snapshot...
2022-08-17 18:07:03 | [trpo_pendulum] epoch #221 | Saved
2022-08-17 18:07:03 | [trpo_pendulum] epoch #221 | Time 139.16 s
2022-08-17 18:07:03 | [trpo_pendulum] epoch #221 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -657.934
Evaluation/AverageReturn              -1511.28
Evaluation/Iteration                    221
Evaluation/MaxReturn                  -1509.43
Evaluation/MinReturn                  -1512.85
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      1.26712
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.48549
GaussianMLPPolicy/KL                      0.00939251
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             103.463
GaussianMLPPolicy/LossBefore            105.715
GaussianMLPPolicy/dLoss                   2.25146
GaussianMLPValueFunction/LossAfter        6.99254
GaussianMLPValueFunction/LossBefore       6.99748
GaussianMLPValueFunction/dLoss            0.0049448
TotalEnvSteps                        266400
-----------------------------------  ---------------
2022-08-17 18:07:03 | [trpo_pendulum] epoch #222 | Saving snapshot...
2022-08-17 18:07:04 | [trpo_pendulum] epoch #222 | Saved
2022-08-17 18:07:04 | [trpo_pendulum] epoch #222 | Time 139.79 s
2022-08-17 18:07:04 | [trpo_pendulum] epoch #222 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -273.21
Evaluation/AverageReturn               -920.603
Evaluation/Iteration                    222
Evaluation/MaxReturn                   -778.06
Evaluation/MinReturn                  -1055.42
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     80.4152
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.47309
GaussianMLPPolicy/KL                      0.00803264
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              40.7965
GaussianMLPPolicy/LossBefore             41.444
GaussianMLPPolicy/dLoss                   0.647507
GaussianMLPValueFunction/LossAfter        6.58503
GaussianMLPValueFunction/LossBefore       6.64457
GaussianMLPValueFunction/dLoss            0.0595369
TotalEnvSteps                        267600
-----------------------------------  ---------------
2022-08-17 18:07:04 | [trpo_pendulum] epoch #223 | Saving snapshot...
2022-08-17 18:07:04 | [trpo_pendulum] epoch #223 | Saved
2022-08-17 18:07:04 | [trpo_pendulum] epoch #223 | Time 140.40 s
2022-08-17 18:07:04 | [trpo_pendulum] epoch #223 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -620.232
Evaluation/AverageReturn              -1473.14
Evaluation/Iteration                    223
Evaluation/MaxReturn                  -1468.09
Evaluation/MinReturn                  -1481.94
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      4.4362
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.45451
GaussianMLPPolicy/KL                      0.00667791
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             101.002
GaussianMLPPolicy/LossBefore            103.567
GaussianMLPPolicy/dLoss                   2.56479
GaussianMLPValueFunction/LossAfter        6.98546
GaussianMLPValueFunction/LossBefore       6.99597
GaussianMLPValueFunction/dLoss            0.0105085
TotalEnvSteps                        268800
-----------------------------------  ---------------
2022-08-17 18:07:05 | [trpo_pendulum] epoch #224 | Saving snapshot...
2022-08-17 18:07:05 | [trpo_pendulum] epoch #224 | Saved
2022-08-17 18:07:05 | [trpo_pendulum] epoch #224 | Time 141.01 s
2022-08-17 18:07:05 | [trpo_pendulum] epoch #224 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -653.684
Evaluation/AverageReturn              -1508.38
Evaluation/Iteration                    224
Evaluation/MaxReturn                  -1507.25
Evaluation/MinReturn                  -1509.2
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      0.670921
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.44444
GaussianMLPPolicy/KL                      0.00647916
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             102.471
GaussianMLPPolicy/LossBefore            104.001
GaussianMLPPolicy/dLoss                   1.52999
GaussianMLPValueFunction/LossAfter        6.98296
GaussianMLPValueFunction/LossBefore       6.99148
GaussianMLPValueFunction/dLoss            0.00851822
TotalEnvSteps                        270000
-----------------------------------  ---------------
2022-08-17 18:07:05 | [trpo_pendulum] epoch #225 | Saving snapshot...
2022-08-17 18:07:05 | [trpo_pendulum] epoch #225 | Saved
2022-08-17 18:07:05 | [trpo_pendulum] epoch #225 | Time 141.63 s
2022-08-17 18:07:05 | [trpo_pendulum] epoch #225 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -578.54
Evaluation/AverageReturn              -1412.53
Evaluation/Iteration                    225
Evaluation/MaxReturn                  -1396.14
Evaluation/MinReturn                  -1427.53
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.43029
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.43428
GaussianMLPPolicy/KL                      0.00658687
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              93.0878
GaussianMLPPolicy/LossBefore             95.8296
GaussianMLPPolicy/dLoss                   2.74182
GaussianMLPValueFunction/LossAfter        6.92443
GaussianMLPValueFunction/LossBefore       6.92896
GaussianMLPValueFunction/dLoss            0.00453043
TotalEnvSteps                        271200
-----------------------------------  ---------------
2022-08-17 18:07:06 | [trpo_pendulum] epoch #226 | Saving snapshot...
2022-08-17 18:07:06 | [trpo_pendulum] epoch #226 | Saved
2022-08-17 18:07:06 | [trpo_pendulum] epoch #226 | Time 142.26 s
2022-08-17 18:07:06 | [trpo_pendulum] epoch #226 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -658.727
Evaluation/AverageReturn              -1503.92
Evaluation/Iteration                    226
Evaluation/MaxReturn                  -1502.32
Evaluation/MinReturn                  -1506.23
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      1.27033
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.49143
GaussianMLPPolicy/KL                      0.00961215
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              98.2608
GaussianMLPPolicy/LossBefore            100.291
GaussianMLPPolicy/dLoss                   2.03006
GaussianMLPValueFunction/LossAfter        6.96135
GaussianMLPValueFunction/LossBefore       6.96665
GaussianMLPValueFunction/dLoss            0.00530052
TotalEnvSteps                        272400
-----------------------------------  ---------------
2022-08-17 18:07:07 | [trpo_pendulum] epoch #227 | Saving snapshot...
2022-08-17 18:07:07 | [trpo_pendulum] epoch #227 | Saved
2022-08-17 18:07:07 | [trpo_pendulum] epoch #227 | Time 142.88 s
2022-08-17 18:07:07 | [trpo_pendulum] epoch #227 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -474.999
Evaluation/AverageReturn              -1257.28
Evaluation/Iteration                    227
Evaluation/MaxReturn                  -1115.79
Evaluation/MinReturn                  -1431.7
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    120.932
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.466
GaussianMLPPolicy/KL                      0.00978542
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              73.9267
GaussianMLPPolicy/LossBefore             75.3442
GaussianMLPPolicy/dLoss                   1.41745
GaussianMLPValueFunction/LossAfter        6.78455
GaussianMLPValueFunction/LossBefore       6.7985
GaussianMLPValueFunction/dLoss            0.0139489
TotalEnvSteps                        273600
-----------------------------------  ---------------
2022-08-17 18:07:07 | [trpo_pendulum] epoch #228 | Saving snapshot...
2022-08-17 18:07:07 | [trpo_pendulum] epoch #228 | Saved
2022-08-17 18:07:07 | [trpo_pendulum] epoch #228 | Time 143.52 s
2022-08-17 18:07:07 | [trpo_pendulum] epoch #228 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -650.423
Evaluation/AverageReturn              -1503.23
Evaluation/Iteration                    228
Evaluation/MaxReturn                  -1501.85
Evaluation/MinReturn                  -1504.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      0.781434
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.46102
GaussianMLPPolicy/KL                      0.00647833
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              99.298
GaussianMLPPolicy/LossBefore            100.667
GaussianMLPPolicy/dLoss                   1.36914
GaussianMLPValueFunction/LossAfter        6.96176
GaussianMLPValueFunction/LossBefore       6.96944
GaussianMLPValueFunction/dLoss            0.00768232
TotalEnvSteps                        274800
-----------------------------------  ---------------
2022-08-17 18:07:08 | [trpo_pendulum] epoch #229 | Saving snapshot...
2022-08-17 18:07:08 | [trpo_pendulum] epoch #229 | Saved
2022-08-17 18:07:08 | [trpo_pendulum] epoch #229 | Time 144.13 s
2022-08-17 18:07:08 | [trpo_pendulum] epoch #229 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -628.777
Evaluation/AverageReturn              -1475.44
Evaluation/Iteration                    229
Evaluation/MaxReturn                  -1466.94
Evaluation/MinReturn                  -1483.82
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      7.51287
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.43778
GaussianMLPPolicy/KL                      0.00686814
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              95.0997
GaussianMLPPolicy/LossBefore             97.7524
GaussianMLPPolicy/dLoss                   2.65269
GaussianMLPValueFunction/LossAfter        6.94943
GaussianMLPValueFunction/LossBefore       6.95484
GaussianMLPValueFunction/dLoss            0.00541162
TotalEnvSteps                        276000
-----------------------------------  ---------------
2022-08-17 18:07:08 | [trpo_pendulum] epoch #230 | Saving snapshot...
2022-08-17 18:07:08 | [trpo_pendulum] epoch #230 | Saved
2022-08-17 18:07:08 | [trpo_pendulum] epoch #230 | Time 144.75 s
2022-08-17 18:07:08 | [trpo_pendulum] epoch #230 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -524.196
Evaluation/AverageReturn              -1368.28
Evaluation/Iteration                    230
Evaluation/MaxReturn                  -1354.31
Evaluation/MinReturn                  -1405.46
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     16.9785
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41779
GaussianMLPPolicy/KL                      0.00780491
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              93.1881
GaussianMLPPolicy/LossBefore             94.0438
GaussianMLPPolicy/dLoss                   0.855721
GaussianMLPValueFunction/LossAfter        6.92926
GaussianMLPValueFunction/LossBefore       6.93361
GaussianMLPValueFunction/dLoss            0.00434923
TotalEnvSteps                        277200
-----------------------------------  ---------------
2022-08-17 18:07:09 | [trpo_pendulum] epoch #231 | Saving snapshot...
2022-08-17 18:07:09 | [trpo_pendulum] epoch #231 | Saved
2022-08-17 18:07:09 | [trpo_pendulum] epoch #231 | Time 145.36 s
2022-08-17 18:07:09 | [trpo_pendulum] epoch #231 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -617.373
Evaluation/AverageReturn              -1477.99
Evaluation/Iteration                    231
Evaluation/MaxReturn                  -1431.42
Evaluation/MinReturn                  -1496.2
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     21.8412
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.43955
GaussianMLPPolicy/KL                      0.00912804
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              98.4228
GaussianMLPPolicy/LossBefore             99.6586
GaussianMLPPolicy/dLoss                   1.2358
GaussianMLPValueFunction/LossAfter        6.95431
GaussianMLPValueFunction/LossBefore       6.95935
GaussianMLPValueFunction/dLoss            0.00504255
TotalEnvSteps                        278400
-----------------------------------  ---------------
2022-08-17 18:07:10 | [trpo_pendulum] epoch #232 | Saving snapshot...
2022-08-17 18:07:10 | [trpo_pendulum] epoch #232 | Saved
2022-08-17 18:07:10 | [trpo_pendulum] epoch #232 | Time 145.96 s
2022-08-17 18:07:10 | [trpo_pendulum] epoch #232 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -547.203
Evaluation/AverageReturn              -1361.82
Evaluation/Iteration                    232
Evaluation/MaxReturn                  -1302.71
Evaluation/MinReturn                  -1409.81
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     36.8221
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40228
GaussianMLPPolicy/KL                      0.00886965
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              82.8792
GaussianMLPPolicy/LossBefore             85.0233
GaussianMLPPolicy/dLoss                   2.14405
GaussianMLPValueFunction/LossAfter        6.84504
GaussianMLPValueFunction/LossBefore       6.85358
GaussianMLPValueFunction/dLoss            0.00853586
TotalEnvSteps                        279600
-----------------------------------  ---------------
2022-08-17 18:07:10 | [trpo_pendulum] epoch #233 | Saving snapshot...
2022-08-17 18:07:10 | [trpo_pendulum] epoch #233 | Saved
2022-08-17 18:07:10 | [trpo_pendulum] epoch #233 | Time 146.58 s
2022-08-17 18:07:10 | [trpo_pendulum] epoch #233 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -483.997
Evaluation/AverageReturn              -1221.54
Evaluation/Iteration                    233
Evaluation/MaxReturn                   -922.228
Evaluation/MinReturn                  -1393
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    165.393
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42969
GaussianMLPPolicy/KL                      0.00887035
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              61.0907
GaussianMLPPolicy/LossBefore             63.8394
GaussianMLPPolicy/dLoss                   2.74877
GaussianMLPValueFunction/LossAfter        6.69289
GaussianMLPValueFunction/LossBefore       6.71894
GaussianMLPValueFunction/dLoss            0.0260501
TotalEnvSteps                        280800
-----------------------------------  ---------------
2022-08-17 18:07:11 | [trpo_pendulum] epoch #234 | Saving snapshot...
2022-08-17 18:07:11 | [trpo_pendulum] epoch #234 | Saved
2022-08-17 18:07:11 | [trpo_pendulum] epoch #234 | Time 147.18 s
2022-08-17 18:07:11 | [trpo_pendulum] epoch #234 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -656.684
Evaluation/AverageReturn              -1500.88
Evaluation/Iteration                    234
Evaluation/MaxReturn                  -1500.07
Evaluation/MinReturn                  -1502.18
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      0.655889
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40173
GaussianMLPPolicy/KL                      0.00860134
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              92.7547
GaussianMLPPolicy/LossBefore             94.6361
GaussianMLPPolicy/dLoss                   1.88135
GaussianMLPValueFunction/LossAfter        6.92843
GaussianMLPValueFunction/LossBefore       6.93948
GaussianMLPValueFunction/dLoss            0.0110517
TotalEnvSteps                        282000
-----------------------------------  ---------------
2022-08-17 18:07:12 | [trpo_pendulum] epoch #235 | Saving snapshot...
2022-08-17 18:07:12 | [trpo_pendulum] epoch #235 | Saved
2022-08-17 18:07:12 | [trpo_pendulum] epoch #235 | Time 147.80 s
2022-08-17 18:07:12 | [trpo_pendulum] epoch #235 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -638.214
Evaluation/AverageReturn              -1560.11
Evaluation/Iteration                    235
Evaluation/MaxReturn                  -1547.85
Evaluation/MinReturn                  -1575.5
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.64917
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41046
GaussianMLPPolicy/KL                      0.00547622
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             111.469
GaussianMLPPolicy/LossBefore            112.256
GaussianMLPPolicy/dLoss                   0.787132
GaussianMLPValueFunction/LossAfter        7.08827
GaussianMLPValueFunction/LossBefore       7.12473
GaussianMLPValueFunction/dLoss            0.0364609
TotalEnvSteps                        283200
-----------------------------------  ---------------
2022-08-17 18:07:12 | [trpo_pendulum] epoch #236 | Saving snapshot...
2022-08-17 18:07:12 | [trpo_pendulum] epoch #236 | Saved
2022-08-17 18:07:12 | [trpo_pendulum] epoch #236 | Time 148.41 s
2022-08-17 18:07:12 | [trpo_pendulum] epoch #236 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -557.457
Evaluation/AverageReturn              -1331.3
Evaluation/Iteration                    236
Evaluation/MaxReturn                  -1137.79
Evaluation/MinReturn                  -1456.64
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    121.64
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4124
GaussianMLPPolicy/KL                      0.0071981
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              70.7335
GaussianMLPPolicy/LossBefore             72.9898
GaussianMLPPolicy/dLoss                   2.25624
GaussianMLPValueFunction/LossAfter        6.75629
GaussianMLPValueFunction/LossBefore       6.7734
GaussianMLPValueFunction/dLoss            0.0171089
TotalEnvSteps                        284400
-----------------------------------  --------------
2022-08-17 18:07:13 | [trpo_pendulum] epoch #237 | Saving snapshot...
2022-08-17 18:07:13 | [trpo_pendulum] epoch #237 | Saved
2022-08-17 18:07:13 | [trpo_pendulum] epoch #237 | Time 149.04 s
2022-08-17 18:07:13 | [trpo_pendulum] epoch #237 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -644.556
Evaluation/AverageReturn              -1565.69
Evaluation/Iteration                    237
Evaluation/MaxReturn                  -1557.59
Evaluation/MinReturn                  -1575.65
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      7.55727
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.43559
GaussianMLPPolicy/KL                      0.00569856
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             108.906
GaussianMLPPolicy/LossBefore            110.902
GaussianMLPPolicy/dLoss                   1.99683
GaussianMLPValueFunction/LossAfter        7.07711
GaussianMLPValueFunction/LossBefore       7.10088
GaussianMLPValueFunction/dLoss            0.0237651
TotalEnvSteps                        285600
-----------------------------------  ---------------
2022-08-17 18:07:13 | [trpo_pendulum] epoch #238 | Saving snapshot...
2022-08-17 18:07:13 | [trpo_pendulum] epoch #238 | Saved
2022-08-17 18:07:13 | [trpo_pendulum] epoch #238 | Time 149.65 s
2022-08-17 18:07:13 | [trpo_pendulum] epoch #238 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -589.44
Evaluation/AverageReturn              -1515.27
Evaluation/Iteration                    238
Evaluation/MaxReturn                  -1503.49
Evaluation/MinReturn                  -1526.35
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      7.27931
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.44383
GaussianMLPPolicy/KL                      0.00980682
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             108.188
GaussianMLPPolicy/LossBefore            108.899
GaussianMLPPolicy/dLoss                   0.710945
GaussianMLPValueFunction/LossAfter        7.05078
GaussianMLPValueFunction/LossBefore       7.06212
GaussianMLPValueFunction/dLoss            0.0113478
TotalEnvSteps                        286800
-----------------------------------  ---------------
2022-08-17 18:07:14 | [trpo_pendulum] epoch #239 | Saving snapshot...
2022-08-17 18:07:14 | [trpo_pendulum] epoch #239 | Saved
2022-08-17 18:07:14 | [trpo_pendulum] epoch #239 | Time 150.27 s
2022-08-17 18:07:14 | [trpo_pendulum] epoch #239 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -507.036
Evaluation/AverageReturn              -1300.39
Evaluation/Iteration                    239
Evaluation/MaxReturn                  -1180.61
Evaluation/MinReturn                  -1459.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     97.6081
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.44573
GaussianMLPPolicy/KL                      0.00689944
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              68.7221
GaussianMLPPolicy/LossBefore             70.7187
GaussianMLPPolicy/dLoss                   1.9966
GaussianMLPValueFunction/LossAfter        6.76911
GaussianMLPValueFunction/LossBefore       6.78927
GaussianMLPValueFunction/dLoss            0.0201612
TotalEnvSteps                        288000
-----------------------------------  ---------------
2022-08-17 18:07:15 | [trpo_pendulum] epoch #240 | Saving snapshot...
2022-08-17 18:07:15 | [trpo_pendulum] epoch #240 | Saved
2022-08-17 18:07:15 | [trpo_pendulum] epoch #240 | Time 150.88 s
2022-08-17 18:07:15 | [trpo_pendulum] epoch #240 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -574.301
Evaluation/AverageReturn              -1328.03
Evaluation/Iteration                    240
Evaluation/MaxReturn                  -1120.5
Evaluation/MinReturn                  -1477.85
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    121.373
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.44337
GaussianMLPPolicy/KL                      0.00649025
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              65.571
GaussianMLPPolicy/LossBefore             67.8013
GaussianMLPPolicy/dLoss                   2.23026
GaussianMLPValueFunction/LossAfter        6.75852
GaussianMLPValueFunction/LossBefore       6.77269
GaussianMLPValueFunction/dLoss            0.0141726
TotalEnvSteps                        289200
-----------------------------------  ---------------
2022-08-17 18:07:15 | [trpo_pendulum] epoch #241 | Saving snapshot...
2022-08-17 18:07:15 | [trpo_pendulum] epoch #241 | Saved
2022-08-17 18:07:15 | [trpo_pendulum] epoch #241 | Time 151.50 s
2022-08-17 18:07:15 | [trpo_pendulum] epoch #241 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -648.81
Evaluation/AverageReturn              -1504.96
Evaluation/Iteration                    241
Evaluation/MaxReturn                  -1502.83
Evaluation/MinReturn                  -1506.18
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      1.4099
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.45177
GaussianMLPPolicy/KL                      0.00743112
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              91.5079
GaussianMLPPolicy/LossBefore             92.9277
GaussianMLPPolicy/dLoss                   1.41982
GaussianMLPValueFunction/LossAfter        6.91368
GaussianMLPValueFunction/LossBefore       6.91907
GaussianMLPValueFunction/dLoss            0.00538778
TotalEnvSteps                        290400
-----------------------------------  ---------------
2022-08-17 18:07:16 | [trpo_pendulum] epoch #242 | Saving snapshot...
2022-08-17 18:07:16 | [trpo_pendulum] epoch #242 | Saved
2022-08-17 18:07:16 | [trpo_pendulum] epoch #242 | Time 152.13 s
2022-08-17 18:07:16 | [trpo_pendulum] epoch #242 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -665.933
Evaluation/AverageReturn              -1603.48
Evaluation/Iteration                    242
Evaluation/MaxReturn                  -1592.74
Evaluation/MinReturn                  -1617.96
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.5495
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.43844
GaussianMLPPolicy/KL                      0.00795256
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             109.115
GaussianMLPPolicy/LossBefore            110.443
GaussianMLPPolicy/dLoss                   1.32859
GaussianMLPValueFunction/LossAfter        7.06108
GaussianMLPValueFunction/LossBefore       7.08372
GaussianMLPValueFunction/dLoss            0.0226421
TotalEnvSteps                        291600
-----------------------------------  ---------------
2022-08-17 18:07:16 | [trpo_pendulum] epoch #243 | Saving snapshot...
2022-08-17 18:07:16 | [trpo_pendulum] epoch #243 | Saved
2022-08-17 18:07:16 | [trpo_pendulum] epoch #243 | Time 152.74 s
2022-08-17 18:07:16 | [trpo_pendulum] epoch #243 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -649.228
Evaluation/AverageReturn              -1504.61
Evaluation/Iteration                    243
Evaluation/MaxReturn                  -1503.25
Evaluation/MinReturn                  -1507.13
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      1.29885
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.45675
GaussianMLPPolicy/KL                      0.00984598
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              88.9806
GaussianMLPPolicy/LossBefore             91.2502
GaussianMLPPolicy/dLoss                   2.26963
GaussianMLPValueFunction/LossAfter        6.90423
GaussianMLPValueFunction/LossBefore       6.90837
GaussianMLPValueFunction/dLoss            0.00414276
TotalEnvSteps                        292800
-----------------------------------  ---------------
2022-08-17 18:07:17 | [trpo_pendulum] epoch #244 | Saving snapshot...
2022-08-17 18:07:17 | [trpo_pendulum] epoch #244 | Saved
2022-08-17 18:07:17 | [trpo_pendulum] epoch #244 | Time 153.38 s
2022-08-17 18:07:17 | [trpo_pendulum] epoch #244 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -597.475
Evaluation/AverageReturn              -1420.01
Evaluation/Iteration                    244
Evaluation/MaxReturn                  -1360.84
Evaluation/MinReturn                  -1467.24
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     39.7804
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.46415
GaussianMLPPolicy/KL                      0.00623678
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              81.1554
GaussianMLPPolicy/LossBefore             81.9623
GaussianMLPPolicy/dLoss                   0.806938
GaussianMLPValueFunction/LossAfter        6.83725
GaussianMLPValueFunction/LossBefore       6.84462
GaussianMLPValueFunction/dLoss            0.00737143
TotalEnvSteps                        294000
-----------------------------------  ---------------
2022-08-17 18:07:18 | [trpo_pendulum] epoch #245 | Saving snapshot...
2022-08-17 18:07:18 | [trpo_pendulum] epoch #245 | Saved
2022-08-17 18:07:18 | [trpo_pendulum] epoch #245 | Time 153.99 s
2022-08-17 18:07:18 | [trpo_pendulum] epoch #245 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -541.088
Evaluation/AverageReturn              -1313.27
Evaluation/Iteration                    245
Evaluation/MaxReturn                   -962.492
Evaluation/MinReturn                  -1438.94
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    164.284
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4689
GaussianMLPPolicy/KL                      0.00920232
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              61.6278
GaussianMLPPolicy/LossBefore             63.5099
GaussianMLPPolicy/dLoss                   1.88211
GaussianMLPValueFunction/LossAfter        6.69017
GaussianMLPValueFunction/LossBefore       6.71365
GaussianMLPValueFunction/dLoss            0.0234799
TotalEnvSteps                        295200
-----------------------------------  ---------------
2022-08-17 18:07:18 | [trpo_pendulum] epoch #246 | Saving snapshot...
2022-08-17 18:07:18 | [trpo_pendulum] epoch #246 | Saved
2022-08-17 18:07:18 | [trpo_pendulum] epoch #246 | Time 154.60 s
2022-08-17 18:07:18 | [trpo_pendulum] epoch #246 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -574.687
Evaluation/AverageReturn              -1431.3
Evaluation/Iteration                    246
Evaluation/MaxReturn                  -1332.47
Evaluation/MinReturn                  -1483.88
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     55.8266
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.46217
GaussianMLPPolicy/KL                      0.00806716
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              82.9399
GaussianMLPPolicy/LossBefore             84.5495
GaussianMLPPolicy/dLoss                   1.60954
GaussianMLPValueFunction/LossAfter        6.8659
GaussianMLPValueFunction/LossBefore       6.87135
GaussianMLPValueFunction/dLoss            0.00545549
TotalEnvSteps                        296400
-----------------------------------  ---------------
2022-08-17 18:07:19 | [trpo_pendulum] epoch #247 | Saving snapshot...
2022-08-17 18:07:19 | [trpo_pendulum] epoch #247 | Saved
2022-08-17 18:07:19 | [trpo_pendulum] epoch #247 | Time 155.22 s
2022-08-17 18:07:19 | [trpo_pendulum] epoch #247 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -658.45
Evaluation/AverageReturn              -1591.77
Evaluation/Iteration                    247
Evaluation/MaxReturn                  -1564.16
Evaluation/MinReturn                  -1606.95
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.9982
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.47309
GaussianMLPPolicy/KL                      0.00564115
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             105.501
GaussianMLPPolicy/LossBefore            106.87
GaussianMLPPolicy/dLoss                   1.36891
GaussianMLPValueFunction/LossAfter        7.04781
GaussianMLPValueFunction/LossBefore       7.0769
GaussianMLPValueFunction/dLoss            0.0290818
TotalEnvSteps                        297600
-----------------------------------  ---------------
2022-08-17 18:07:20 | [trpo_pendulum] epoch #248 | Saving snapshot...
2022-08-17 18:07:20 | [trpo_pendulum] epoch #248 | Saved
2022-08-17 18:07:20 | [trpo_pendulum] epoch #248 | Time 155.84 s
2022-08-17 18:07:20 | [trpo_pendulum] epoch #248 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -673.566
Evaluation/AverageReturn              -1614.78
Evaluation/Iteration                    248
Evaluation/MaxReturn                  -1586.45
Evaluation/MinReturn                  -1629.62
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.0545
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.50328
GaussianMLPPolicy/KL                      0.00987866
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             106.825
GaussianMLPPolicy/LossBefore            107.405
GaussianMLPPolicy/dLoss                   0.580872
GaussianMLPValueFunction/LossAfter        7.03881
GaussianMLPValueFunction/LossBefore       7.05339
GaussianMLPValueFunction/dLoss            0.0145779
TotalEnvSteps                        298800
-----------------------------------  ---------------
2022-08-17 18:07:20 | [trpo_pendulum] epoch #249 | Saving snapshot...
2022-08-17 18:07:20 | [trpo_pendulum] epoch #249 | Saved
2022-08-17 18:07:20 | [trpo_pendulum] epoch #249 | Time 156.45 s
2022-08-17 18:07:20 | [trpo_pendulum] epoch #249 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -579.684
Evaluation/AverageReturn              -1407.06
Evaluation/Iteration                    249
Evaluation/MaxReturn                  -1186.85
Evaluation/MinReturn                  -1465.62
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     99.3086
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.49316
GaussianMLPPolicy/KL                      0.00667186
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              73.6615
GaussianMLPPolicy/LossBefore             75.8469
GaussianMLPPolicy/dLoss                   2.18538
GaussianMLPValueFunction/LossAfter        6.81045
GaussianMLPValueFunction/LossBefore       6.82182
GaussianMLPValueFunction/dLoss            0.0113649
TotalEnvSteps                        300000
-----------------------------------  ---------------
2022-08-17 18:07:21 | [trpo_pendulum] epoch #250 | Saving snapshot...
2022-08-17 18:07:21 | [trpo_pendulum] epoch #250 | Saved
2022-08-17 18:07:21 | [trpo_pendulum] epoch #250 | Time 157.06 s
2022-08-17 18:07:21 | [trpo_pendulum] epoch #250 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -690.116
Evaluation/AverageReturn              -1635.27
Evaluation/Iteration                    250
Evaluation/MaxReturn                  -1627.39
Evaluation/MinReturn                  -1638.98
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      4.05815
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.54756
GaussianMLPPolicy/KL                      0.00831224
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             105.864
GaussianMLPPolicy/LossBefore            107.557
GaussianMLPPolicy/dLoss                   1.69262
GaussianMLPValueFunction/LossAfter        7.03967
GaussianMLPValueFunction/LossBefore       7.05367
GaussianMLPValueFunction/dLoss            0.0139999
TotalEnvSteps                        301200
-----------------------------------  ---------------
2022-08-17 18:07:21 | [trpo_pendulum] epoch #251 | Saving snapshot...
2022-08-17 18:07:21 | [trpo_pendulum] epoch #251 | Saved
2022-08-17 18:07:21 | [trpo_pendulum] epoch #251 | Time 157.68 s
2022-08-17 18:07:21 | [trpo_pendulum] epoch #251 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -606.765
Evaluation/AverageReturn              -1471.95
Evaluation/Iteration                    251
Evaluation/MaxReturn                  -1411.66
Evaluation/MinReturn                  -1496.89
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     27.9043
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.56131
GaussianMLPPolicy/KL                      0.00747854
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              85.8429
GaussianMLPPolicy/LossBefore             86.5746
GaussianMLPPolicy/dLoss                   0.731667
GaussianMLPValueFunction/LossAfter        6.87686
GaussianMLPValueFunction/LossBefore       6.88258
GaussianMLPValueFunction/dLoss            0.00571871
TotalEnvSteps                        302400
-----------------------------------  ---------------
2022-08-17 18:07:22 | [trpo_pendulum] epoch #252 | Saving snapshot...
2022-08-17 18:07:22 | [trpo_pendulum] epoch #252 | Saved
2022-08-17 18:07:22 | [trpo_pendulum] epoch #252 | Time 158.29 s
2022-08-17 18:07:22 | [trpo_pendulum] epoch #252 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -687.812
Evaluation/AverageReturn              -1638.76
Evaluation/Iteration                    252
Evaluation/MaxReturn                  -1632.23
Evaluation/MinReturn                  -1642.6
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      3.45688
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.56935
GaussianMLPPolicy/KL                      0.00713519
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             106.077
GaussianMLPPolicy/LossBefore            107.558
GaussianMLPPolicy/dLoss                   1.48087
GaussianMLPValueFunction/LossAfter        7.04079
GaussianMLPValueFunction/LossBefore       7.05281
GaussianMLPValueFunction/dLoss            0.0120249
TotalEnvSteps                        303600
-----------------------------------  ---------------
2022-08-17 18:07:23 | [trpo_pendulum] epoch #253 | Saving snapshot...
2022-08-17 18:07:23 | [trpo_pendulum] epoch #253 | Saved
2022-08-17 18:07:23 | [trpo_pendulum] epoch #253 | Time 158.93 s
2022-08-17 18:07:23 | [trpo_pendulum] epoch #253 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -676.091
Evaluation/AverageReturn              -1616.35
Evaluation/Iteration                    253
Evaluation/MaxReturn                  -1599.85
Evaluation/MinReturn                  -1630.8
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     11.3498
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.5874
GaussianMLPPolicy/KL                      0.00713081
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             102.287
GaussianMLPPolicy/LossBefore            103.952
GaussianMLPPolicy/dLoss                   1.66413
GaussianMLPValueFunction/LossAfter        7.0126
GaussianMLPValueFunction/LossBefore       7.01826
GaussianMLPValueFunction/dLoss            0.00566244
TotalEnvSteps                        304800
-----------------------------------  ---------------
2022-08-17 18:07:23 | [trpo_pendulum] epoch #254 | Saving snapshot...
2022-08-17 18:07:23 | [trpo_pendulum] epoch #254 | Saved
2022-08-17 18:07:23 | [trpo_pendulum] epoch #254 | Time 159.56 s
2022-08-17 18:07:23 | [trpo_pendulum] epoch #254 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -685.422
Evaluation/AverageReturn              -1629.66
Evaluation/Iteration                    254
Evaluation/MaxReturn                  -1614.41
Evaluation/MinReturn                  -1642.05
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.36514
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.58752
GaussianMLPPolicy/KL                      0.00685111
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             103.411
GaussianMLPPolicy/LossBefore            104.206
GaussianMLPPolicy/dLoss                   0.794937
GaussianMLPValueFunction/LossAfter        7.01384
GaussianMLPValueFunction/LossBefore       7.0186
GaussianMLPValueFunction/dLoss            0.00475502
TotalEnvSteps                        306000
-----------------------------------  ---------------
2022-08-17 18:07:24 | [trpo_pendulum] epoch #255 | Saving snapshot...
2022-08-17 18:07:24 | [trpo_pendulum] epoch #255 | Saved
2022-08-17 18:07:24 | [trpo_pendulum] epoch #255 | Time 160.19 s
2022-08-17 18:07:24 | [trpo_pendulum] epoch #255 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -571.312
Evaluation/AverageReturn              -1496.82
Evaluation/Iteration                    255
Evaluation/MaxReturn                  -1472.75
Evaluation/MinReturn                  -1508.79
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     12.6127
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.58104
GaussianMLPPolicy/KL                      0.00920095
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              94.7937
GaussianMLPPolicy/LossBefore             96.4264
GaussianMLPPolicy/dLoss                   1.63271
GaussianMLPValueFunction/LossAfter        6.96697
GaussianMLPValueFunction/LossBefore       6.97096
GaussianMLPValueFunction/dLoss            0.00399113
TotalEnvSteps                        307200
-----------------------------------  ---------------
2022-08-17 18:07:25 | [trpo_pendulum] epoch #256 | Saving snapshot...
2022-08-17 18:07:25 | [trpo_pendulum] epoch #256 | Saved
2022-08-17 18:07:25 | [trpo_pendulum] epoch #256 | Time 160.81 s
2022-08-17 18:07:25 | [trpo_pendulum] epoch #256 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -563.935
Evaluation/AverageReturn              -1379.38
Evaluation/Iteration                    256
Evaluation/MaxReturn                  -1309.28
Evaluation/MinReturn                  -1472.12
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     65.8405
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.56835
GaussianMLPPolicy/KL                      0.00691559
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              67.5114
GaussianMLPPolicy/LossBefore             69.0549
GaussianMLPPolicy/dLoss                   1.54356
GaussianMLPValueFunction/LossAfter        6.78504
GaussianMLPValueFunction/LossBefore       6.80776
GaussianMLPValueFunction/dLoss            0.0227242
TotalEnvSteps                        308400
-----------------------------------  ---------------
2022-08-17 18:07:25 | [trpo_pendulum] epoch #257 | Saving snapshot...
2022-08-17 18:07:25 | [trpo_pendulum] epoch #257 | Saved
2022-08-17 18:07:25 | [trpo_pendulum] epoch #257 | Time 161.43 s
2022-08-17 18:07:25 | [trpo_pendulum] epoch #257 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -651.301
Evaluation/AverageReturn              -1501.57
Evaluation/Iteration                    257
Evaluation/MaxReturn                  -1499.78
Evaluation/MinReturn                  -1504.62
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      1.69842
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.56706
GaussianMLPPolicy/KL                      0.00938841
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              79.1733
GaussianMLPPolicy/LossBefore             80.4464
GaussianMLPPolicy/dLoss                   1.27308
GaussianMLPValueFunction/LossAfter        6.83943
GaussianMLPValueFunction/LossBefore       6.84615
GaussianMLPValueFunction/dLoss            0.00672102
TotalEnvSteps                        309600
-----------------------------------  ---------------
2022-08-17 18:07:26 | [trpo_pendulum] epoch #258 | Saving snapshot...
2022-08-17 18:07:26 | [trpo_pendulum] epoch #258 | Saved
2022-08-17 18:07:26 | [trpo_pendulum] epoch #258 | Time 162.09 s
2022-08-17 18:07:26 | [trpo_pendulum] epoch #258 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -585.003
Evaluation/AverageReturn              -1451.96
Evaluation/Iteration                    258
Evaluation/MaxReturn                  -1427.73
Evaluation/MinReturn                  -1466.31
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.299
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.54152
GaussianMLPPolicy/KL                      0.00673583
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              77.5891
GaussianMLPPolicy/LossBefore             79.5059
GaussianMLPPolicy/dLoss                   1.91679
GaussianMLPValueFunction/LossAfter        6.82916
GaussianMLPValueFunction/LossBefore       6.83522
GaussianMLPValueFunction/dLoss            0.00606251
TotalEnvSteps                        310800
-----------------------------------  ---------------
2022-08-17 18:07:26 | [trpo_pendulum] epoch #259 | Saving snapshot...
2022-08-17 18:07:26 | [trpo_pendulum] epoch #259 | Saved
2022-08-17 18:07:26 | [trpo_pendulum] epoch #259 | Time 162.71 s
2022-08-17 18:07:26 | [trpo_pendulum] epoch #259 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -661.742
Evaluation/AverageReturn              -1508.12
Evaluation/Iteration                    259
Evaluation/MaxReturn                  -1502.98
Evaluation/MinReturn                  -1512.98
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      3.20123
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.57218
GaussianMLPPolicy/KL                      0.00865874
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              76.7167
GaussianMLPPolicy/LossBefore             78.4571
GaussianMLPPolicy/dLoss                   1.74037
GaussianMLPValueFunction/LossAfter        6.83056
GaussianMLPValueFunction/LossBefore       6.83503
GaussianMLPValueFunction/dLoss            0.00447321
TotalEnvSteps                        312000
-----------------------------------  ---------------
2022-08-17 18:07:27 | [trpo_pendulum] epoch #260 | Saving snapshot...
2022-08-17 18:07:27 | [trpo_pendulum] epoch #260 | Saved
2022-08-17 18:07:27 | [trpo_pendulum] epoch #260 | Time 163.33 s
2022-08-17 18:07:27 | [trpo_pendulum] epoch #260 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -607.779
Evaluation/AverageReturn              -1498.47
Evaluation/Iteration                    260
Evaluation/MaxReturn                  -1347.01
Evaluation/MinReturn                  -1569.79
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     74.3721
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.59082
GaussianMLPPolicy/KL                      0.00634767
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              81.2745
GaussianMLPPolicy/LossBefore             83.1572
GaussianMLPPolicy/dLoss                   1.88268
GaussianMLPValueFunction/LossAfter        6.86873
GaussianMLPValueFunction/LossBefore       6.87374
GaussianMLPValueFunction/dLoss            0.00500727
TotalEnvSteps                        313200
-----------------------------------  ---------------
2022-08-17 18:07:28 | [trpo_pendulum] epoch #261 | Saving snapshot...
2022-08-17 18:07:28 | [trpo_pendulum] epoch #261 | Saved
2022-08-17 18:07:28 | [trpo_pendulum] epoch #261 | Time 163.95 s
2022-08-17 18:07:28 | [trpo_pendulum] epoch #261 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -651.28
Evaluation/AverageReturn              -1500.21
Evaluation/Iteration                    261
Evaluation/MaxReturn                  -1499.4
Evaluation/MinReturn                  -1500.95
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      0.47936
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.61338
GaussianMLPPolicy/KL                      0.00972306
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              76.2955
GaussianMLPPolicy/LossBefore             77.3546
GaussianMLPPolicy/dLoss                   1.05913
GaussianMLPValueFunction/LossAfter        6.81991
GaussianMLPValueFunction/LossBefore       6.82452
GaussianMLPValueFunction/dLoss            0.00461149
TotalEnvSteps                        314400
-----------------------------------  ---------------
2022-08-17 18:07:28 | [trpo_pendulum] epoch #262 | Saving snapshot...
2022-08-17 18:07:28 | [trpo_pendulum] epoch #262 | Saved
2022-08-17 18:07:28 | [trpo_pendulum] epoch #262 | Time 164.58 s
2022-08-17 18:07:28 | [trpo_pendulum] epoch #262 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -702.302
Evaluation/AverageReturn              -1649.44
Evaluation/Iteration                    262
Evaluation/MaxReturn                  -1644.38
Evaluation/MinReturn                  -1653.92
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      3.05599
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.61167
GaussianMLPPolicy/KL                      0.00676168
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              98.9402
GaussianMLPPolicy/LossBefore            100.495
GaussianMLPPolicy/dLoss                   1.55475
GaussianMLPValueFunction/LossAfter        7.00787
GaussianMLPValueFunction/LossBefore       7.0327
GaussianMLPValueFunction/dLoss            0.0248308
TotalEnvSteps                        315600
-----------------------------------  ---------------
2022-08-17 18:07:29 | [trpo_pendulum] epoch #263 | Saving snapshot...
2022-08-17 18:07:29 | [trpo_pendulum] epoch #263 | Saved
2022-08-17 18:07:29 | [trpo_pendulum] epoch #263 | Time 165.21 s
2022-08-17 18:07:29 | [trpo_pendulum] epoch #263 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -619.264
Evaluation/AverageReturn              -1541.09
Evaluation/Iteration                    263
Evaluation/MaxReturn                  -1499.61
Evaluation/MinReturn                  -1564.58
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     21.2846
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62635
GaussianMLPPolicy/KL                      0.00818332
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              89.2539
GaussianMLPPolicy/LossBefore             91.1763
GaussianMLPPolicy/dLoss                   1.92236
GaussianMLPValueFunction/LossAfter        6.94617
GaussianMLPValueFunction/LossBefore       6.95129
GaussianMLPValueFunction/dLoss            0.00512218
TotalEnvSteps                        316800
-----------------------------------  ---------------
2022-08-17 18:07:30 | [trpo_pendulum] epoch #264 | Saving snapshot...
2022-08-17 18:07:30 | [trpo_pendulum] epoch #264 | Saved
2022-08-17 18:07:30 | [trpo_pendulum] epoch #264 | Time 165.85 s
2022-08-17 18:07:30 | [trpo_pendulum] epoch #264 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -663.316
Evaluation/AverageReturn              -1509.26
Evaluation/Iteration                    264
Evaluation/MaxReturn                  -1505.58
Evaluation/MinReturn                  -1513.47
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      3.27086
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.61547
GaussianMLPPolicy/KL                      0.00891687
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              72.9548
GaussianMLPPolicy/LossBefore             74.6626
GaussianMLPPolicy/dLoss                   1.70787
GaussianMLPValueFunction/LossAfter        6.81307
GaussianMLPValueFunction/LossBefore       6.82318
GaussianMLPValueFunction/dLoss            0.0101118
TotalEnvSteps                        318000
-----------------------------------  ---------------
2022-08-17 18:07:30 | [trpo_pendulum] epoch #265 | Saving snapshot...
2022-08-17 18:07:30 | [trpo_pendulum] epoch #265 | Saved
2022-08-17 18:07:30 | [trpo_pendulum] epoch #265 | Time 166.48 s
2022-08-17 18:07:30 | [trpo_pendulum] epoch #265 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -617.729
Evaluation/AverageReturn              -1523.18
Evaluation/Iteration                    265
Evaluation/MaxReturn                  -1508.76
Evaluation/MinReturn                  -1535.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.2063
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62985
GaussianMLPPolicy/KL                      0.00677926
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              86.0594
GaussianMLPPolicy/LossBefore             87.414
GaussianMLPPolicy/dLoss                   1.35463
GaussianMLPValueFunction/LossAfter        6.92166
GaussianMLPValueFunction/LossBefore       6.92677
GaussianMLPValueFunction/dLoss            0.00510836
TotalEnvSteps                        319200
-----------------------------------  ---------------
2022-08-17 18:07:31 | [trpo_pendulum] epoch #266 | Saving snapshot...
2022-08-17 18:07:31 | [trpo_pendulum] epoch #266 | Saved
2022-08-17 18:07:31 | [trpo_pendulum] epoch #266 | Time 167.12 s
2022-08-17 18:07:31 | [trpo_pendulum] epoch #266 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -609.263
Evaluation/AverageReturn              -1523.52
Evaluation/Iteration                    266
Evaluation/MaxReturn                  -1513.43
Evaluation/MinReturn                  -1536.45
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.70471
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62609
GaussianMLPPolicy/KL                      0.00851123
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              84.2746
GaussianMLPPolicy/LossBefore             85.944
GaussianMLPPolicy/dLoss                   1.66936
GaussianMLPValueFunction/LossAfter        6.91986
GaussianMLPValueFunction/LossBefore       6.92429
GaussianMLPValueFunction/dLoss            0.00443935
TotalEnvSteps                        320400
-----------------------------------  ---------------
2022-08-17 18:07:31 | [trpo_pendulum] epoch #267 | Saving snapshot...
2022-08-17 18:07:31 | [trpo_pendulum] epoch #267 | Saved
2022-08-17 18:07:31 | [trpo_pendulum] epoch #267 | Time 167.74 s
2022-08-17 18:07:31 | [trpo_pendulum] epoch #267 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -622.106
Evaluation/AverageReturn              -1534.39
Evaluation/Iteration                    267
Evaluation/MaxReturn                  -1463.72
Evaluation/MinReturn                  -1607.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     45.0591
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.63877
GaussianMLPPolicy/KL                      0.00598386
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              82.6909
GaussianMLPPolicy/LossBefore             84.2133
GaussianMLPPolicy/dLoss                   1.52239
GaussianMLPValueFunction/LossAfter        6.88851
GaussianMLPValueFunction/LossBefore       6.89274
GaussianMLPValueFunction/dLoss            0.00422621
TotalEnvSteps                        321600
-----------------------------------  ---------------
2022-08-17 18:07:32 | [trpo_pendulum] epoch #268 | Saving snapshot...
2022-08-17 18:07:32 | [trpo_pendulum] epoch #268 | Saved
2022-08-17 18:07:32 | [trpo_pendulum] epoch #268 | Time 168.35 s
2022-08-17 18:07:32 | [trpo_pendulum] epoch #268 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -538.918
Evaluation/AverageReturn              -1323.27
Evaluation/Iteration                    268
Evaluation/MaxReturn                  -1263.65
Evaluation/MinReturn                  -1350.39
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     28.1616
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.64976
GaussianMLPPolicy/KL                      0.00825767
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              50.8054
GaussianMLPPolicy/LossBefore             52.6334
GaussianMLPPolicy/dLoss                   1.82791
GaussianMLPValueFunction/LossAfter        6.64082
GaussianMLPValueFunction/LossBefore       6.67883
GaussianMLPValueFunction/dLoss            0.038003
TotalEnvSteps                        322800
-----------------------------------  ---------------
2022-08-17 18:07:33 | [trpo_pendulum] epoch #269 | Saving snapshot...
2022-08-17 18:07:33 | [trpo_pendulum] epoch #269 | Saved
2022-08-17 18:07:33 | [trpo_pendulum] epoch #269 | Time 168.97 s
2022-08-17 18:07:33 | [trpo_pendulum] epoch #269 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -663.039
Evaluation/AverageReturn              -1612.22
Evaluation/Iteration                    269
Evaluation/MaxReturn                  -1593.15
Evaluation/MinReturn                  -1619.5
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.28443
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.65026
GaussianMLPPolicy/KL                      0.00961168
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              92.6595
GaussianMLPPolicy/LossBefore             94.2251
GaussianMLPPolicy/dLoss                   1.56565
GaussianMLPValueFunction/LossAfter        6.96717
GaussianMLPValueFunction/LossBefore       6.9889
GaussianMLPValueFunction/dLoss            0.0217247
TotalEnvSteps                        324000
-----------------------------------  ---------------
2022-08-17 18:07:33 | [trpo_pendulum] epoch #270 | Saving snapshot...
2022-08-17 18:07:33 | [trpo_pendulum] epoch #270 | Saved
2022-08-17 18:07:33 | [trpo_pendulum] epoch #270 | Time 169.59 s
2022-08-17 18:07:33 | [trpo_pendulum] epoch #270 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -642.058
Evaluation/AverageReturn              -1574.3
Evaluation/Iteration                    270
Evaluation/MaxReturn                  -1564.07
Evaluation/MinReturn                  -1591
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.73121
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.67643
GaussianMLPPolicy/KL                      0.00598076
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              87.6653
GaussianMLPPolicy/LossBefore             88.8417
GaussianMLPPolicy/dLoss                   1.17646
GaussianMLPValueFunction/LossAfter        6.93603
GaussianMLPValueFunction/LossBefore       6.94432
GaussianMLPValueFunction/dLoss            0.00829172
TotalEnvSteps                        325200
-----------------------------------  ---------------
2022-08-17 18:07:34 | [trpo_pendulum] epoch #271 | Saving snapshot...
2022-08-17 18:07:34 | [trpo_pendulum] epoch #271 | Saved
2022-08-17 18:07:34 | [trpo_pendulum] epoch #271 | Time 170.21 s
2022-08-17 18:07:34 | [trpo_pendulum] epoch #271 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -644.396
Evaluation/AverageReturn              -1585.91
Evaluation/Iteration                    271
Evaluation/MaxReturn                  -1564.23
Evaluation/MinReturn                  -1604.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     12.4372
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.67739
GaussianMLPPolicy/KL                      0.00859645
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              88.741
GaussianMLPPolicy/LossBefore             90.5654
GaussianMLPPolicy/dLoss                   1.82443
GaussianMLPValueFunction/LossAfter        6.94109
GaussianMLPValueFunction/LossBefore       6.9473
GaussianMLPValueFunction/dLoss            0.00621414
TotalEnvSteps                        326400
-----------------------------------  ---------------
2022-08-17 18:07:35 | [trpo_pendulum] epoch #272 | Saving snapshot...
2022-08-17 18:07:35 | [trpo_pendulum] epoch #272 | Saved
2022-08-17 18:07:35 | [trpo_pendulum] epoch #272 | Time 170.83 s
2022-08-17 18:07:35 | [trpo_pendulum] epoch #272 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -650.459
Evaluation/AverageReturn              -1498.4
Evaluation/Iteration                    272
Evaluation/MaxReturn                  -1494.96
Evaluation/MinReturn                  -1503.02
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      2.43257
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.64726
GaussianMLPPolicy/KL                      0.00937135
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              68.8952
GaussianMLPPolicy/LossBefore             69.463
GaussianMLPPolicy/dLoss                   0.567787
GaussianMLPValueFunction/LossAfter        6.78324
GaussianMLPValueFunction/LossBefore       6.79389
GaussianMLPValueFunction/dLoss            0.0106411
TotalEnvSteps                        327600
-----------------------------------  ---------------
2022-08-17 18:07:35 | [trpo_pendulum] epoch #273 | Saving snapshot...
2022-08-17 18:07:35 | [trpo_pendulum] epoch #273 | Saved
2022-08-17 18:07:35 | [trpo_pendulum] epoch #273 | Time 171.45 s
2022-08-17 18:07:35 | [trpo_pendulum] epoch #273 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -564.793
Evaluation/AverageReturn              -1386.09
Evaluation/Iteration                    273
Evaluation/MaxReturn                  -1259.53
Evaluation/MinReturn                  -1431.29
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     60.5511
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.66363
GaussianMLPPolicy/KL                      0.00861044
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              54.1397
GaussianMLPPolicy/LossBefore             56.6508
GaussianMLPPolicy/dLoss                   2.51105
GaussianMLPValueFunction/LossAfter        6.64844
GaussianMLPValueFunction/LossBefore       6.6744
GaussianMLPValueFunction/dLoss            0.0259523
TotalEnvSteps                        328800
-----------------------------------  ---------------
2022-08-17 18:07:36 | [trpo_pendulum] epoch #274 | Saving snapshot...
2022-08-17 18:07:36 | [trpo_pendulum] epoch #274 | Saved
2022-08-17 18:07:36 | [trpo_pendulum] epoch #274 | Time 172.07 s
2022-08-17 18:07:36 | [trpo_pendulum] epoch #274 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -471.899
Evaluation/AverageReturn              -1356.12
Evaluation/Iteration                    274
Evaluation/MaxReturn                  -1244.97
Evaluation/MinReturn                  -1393.36
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     51.0133
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.63735
GaussianMLPPolicy/KL                      0.00593905
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              67.8559
GaussianMLPPolicy/LossBefore             69.5145
GaussianMLPPolicy/dLoss                   1.65858
GaussianMLPValueFunction/LossAfter        6.80687
GaussianMLPValueFunction/LossBefore       6.81131
GaussianMLPValueFunction/dLoss            0.00443792
TotalEnvSteps                        330000
-----------------------------------  ---------------
2022-08-17 18:07:36 | [trpo_pendulum] epoch #275 | Saving snapshot...
2022-08-17 18:07:36 | [trpo_pendulum] epoch #275 | Saved
2022-08-17 18:07:36 | [trpo_pendulum] epoch #275 | Time 172.70 s
2022-08-17 18:07:36 | [trpo_pendulum] epoch #275 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -629.099
Evaluation/AverageReturn              -1487.63
Evaluation/Iteration                    275
Evaluation/MaxReturn                  -1480.1
Evaluation/MinReturn                  -1494.5
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.38562
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.63649
GaussianMLPPolicy/KL                      0.0078858
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              67.3731
GaussianMLPPolicy/LossBefore             69.4979
GaussianMLPPolicy/dLoss                   2.1248
GaussianMLPValueFunction/LossAfter        6.77614
GaussianMLPValueFunction/LossBefore       6.77997
GaussianMLPValueFunction/dLoss            0.00382996
TotalEnvSteps                        331200
-----------------------------------  ---------------
2022-08-17 18:07:37 | [trpo_pendulum] epoch #276 | Saving snapshot...
2022-08-17 18:07:37 | [trpo_pendulum] epoch #276 | Saved
2022-08-17 18:07:37 | [trpo_pendulum] epoch #276 | Time 173.34 s
2022-08-17 18:07:37 | [trpo_pendulum] epoch #276 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -597.81
Evaluation/AverageReturn              -1530.54
Evaluation/Iteration                    276
Evaluation/MaxReturn                  -1514.6
Evaluation/MinReturn                  -1547.95
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     12.4435
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62498
GaussianMLPPolicy/KL                      0.00733943
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              84.6523
GaussianMLPPolicy/LossBefore             85.5614
GaussianMLPPolicy/dLoss                   0.909088
GaussianMLPValueFunction/LossAfter        6.93029
GaussianMLPValueFunction/LossBefore       6.94816
GaussianMLPValueFunction/dLoss            0.017869
TotalEnvSteps                        332400
-----------------------------------  ---------------
2022-08-17 18:07:38 | [trpo_pendulum] epoch #277 | Saving snapshot...
2022-08-17 18:07:38 | [trpo_pendulum] epoch #277 | Saved
2022-08-17 18:07:38 | [trpo_pendulum] epoch #277 | Time 173.96 s
2022-08-17 18:07:38 | [trpo_pendulum] epoch #277 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -681.245
Evaluation/AverageReturn              -1638.53
Evaluation/Iteration                    277
Evaluation/MaxReturn                  -1631.82
Evaluation/MinReturn                  -1645.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.54743
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62844
GaussianMLPPolicy/KL                      0.00769079
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              90.7595
GaussianMLPPolicy/LossBefore             92.1437
GaussianMLPPolicy/dLoss                   1.38422
GaussianMLPValueFunction/LossAfter        6.95545
GaussianMLPValueFunction/LossBefore       6.9687
GaussianMLPValueFunction/dLoss            0.013257
TotalEnvSteps                        333600
-----------------------------------  ---------------
2022-08-17 18:07:38 | [trpo_pendulum] epoch #278 | Saving snapshot...
2022-08-17 18:07:38 | [trpo_pendulum] epoch #278 | Saved
2022-08-17 18:07:38 | [trpo_pendulum] epoch #278 | Time 174.60 s
2022-08-17 18:07:38 | [trpo_pendulum] epoch #278 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -660.879
Evaluation/AverageReturn              -1506.89
Evaluation/Iteration                    278
Evaluation/MaxReturn                  -1505.75
Evaluation/MinReturn                  -1507.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      0.699981
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62343
GaussianMLPPolicy/KL                      0.00731491
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              64.1755
GaussianMLPPolicy/LossBefore             65.2829
GaussianMLPPolicy/dLoss                   1.1074
GaussianMLPValueFunction/LossAfter        6.76498
GaussianMLPValueFunction/LossBefore       6.77449
GaussianMLPValueFunction/dLoss            0.00950909
TotalEnvSteps                        334800
-----------------------------------  ---------------
2022-08-17 18:07:39 | [trpo_pendulum] epoch #279 | Saving snapshot...
2022-08-17 18:07:39 | [trpo_pendulum] epoch #279 | Saved
2022-08-17 18:07:39 | [trpo_pendulum] epoch #279 | Time 175.24 s
2022-08-17 18:07:39 | [trpo_pendulum] epoch #279 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -535.504
Evaluation/AverageReturn              -1298.57
Evaluation/Iteration                    279
Evaluation/MaxReturn                   -778.5
Evaluation/MinReturn                  -1545.3
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    280.805
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.63014
GaussianMLPPolicy/KL                      0.00863427
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              37.2613
GaussianMLPPolicy/LossBefore             38.6441
GaussianMLPPolicy/dLoss                   1.38283
GaussianMLPValueFunction/LossAfter        6.6619
GaussianMLPValueFunction/LossBefore       6.68026
GaussianMLPValueFunction/dLoss            0.0183568
TotalEnvSteps                        336000
-----------------------------------  ---------------
2022-08-17 18:07:40 | [trpo_pendulum] epoch #280 | Saving snapshot...
2022-08-17 18:07:40 | [trpo_pendulum] epoch #280 | Saved
2022-08-17 18:07:40 | [trpo_pendulum] epoch #280 | Time 175.88 s
2022-08-17 18:07:40 | [trpo_pendulum] epoch #280 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -691.337
Evaluation/AverageReturn              -1646.88
Evaluation/Iteration                    280
Evaluation/MaxReturn                  -1640.99
Evaluation/MinReturn                  -1651.38
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      3.47809
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.6168
GaussianMLPPolicy/KL                      0.00884585
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              90.0598
GaussianMLPPolicy/LossBefore             90.3362
GaussianMLPPolicy/dLoss                   0.276436
GaussianMLPValueFunction/LossAfter        6.95422
GaussianMLPValueFunction/LossBefore       6.97668
GaussianMLPValueFunction/dLoss            0.02246
TotalEnvSteps                        337200
-----------------------------------  ---------------
2022-08-17 18:07:40 | [trpo_pendulum] epoch #281 | Saving snapshot...
2022-08-17 18:07:40 | [trpo_pendulum] epoch #281 | Saved
2022-08-17 18:07:40 | [trpo_pendulum] epoch #281 | Time 176.54 s
2022-08-17 18:07:40 | [trpo_pendulum] epoch #281 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -591.32
Evaluation/AverageReturn              -1455.82
Evaluation/Iteration                    281
Evaluation/MaxReturn                  -1324.37
Evaluation/MinReturn                  -1508.45
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     64.7342
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62089
GaussianMLPPolicy/KL                      0.00886214
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              60.9468
GaussianMLPPolicy/LossBefore             62.6228
GaussianMLPPolicy/dLoss                   1.67598
GaussianMLPValueFunction/LossAfter        6.73083
GaussianMLPValueFunction/LossBefore       6.73928
GaussianMLPValueFunction/dLoss            0.00844908
TotalEnvSteps                        338400
-----------------------------------  ---------------
2022-08-17 18:07:41 | [trpo_pendulum] epoch #282 | Saving snapshot...
2022-08-17 18:07:41 | [trpo_pendulum] epoch #282 | Saved
2022-08-17 18:07:41 | [trpo_pendulum] epoch #282 | Time 177.18 s
2022-08-17 18:07:41 | [trpo_pendulum] epoch #282 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -646.577
Evaluation/AverageReturn              -1492.7
Evaluation/Iteration                    282
Evaluation/MaxReturn                  -1491.67
Evaluation/MinReturn                  -1494.14
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      0.87334
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62922
GaussianMLPPolicy/KL                      0.00852226
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              61.9475
GaussianMLPPolicy/LossBefore             62.5974
GaussianMLPPolicy/dLoss                   0.649879
GaussianMLPValueFunction/LossAfter        6.74025
GaussianMLPValueFunction/LossBefore       6.74538
GaussianMLPValueFunction/dLoss            0.00513506
TotalEnvSteps                        339600
-----------------------------------  ---------------
2022-08-17 18:07:42 | [trpo_pendulum] epoch #283 | Saving snapshot...
2022-08-17 18:07:42 | [trpo_pendulum] epoch #283 | Saved
2022-08-17 18:07:42 | [trpo_pendulum] epoch #283 | Time 177.83 s
2022-08-17 18:07:42 | [trpo_pendulum] epoch #283 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -674.897
Evaluation/AverageReturn              -1632.33
Evaluation/Iteration                    283
Evaluation/MaxReturn                  -1628.35
Evaluation/MinReturn                  -1636.99
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      2.85674
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.64099
GaussianMLPPolicy/KL                      0.00550773
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              87.9299
GaussianMLPPolicy/LossBefore             88.3532
GaussianMLPPolicy/dLoss                   0.423271
GaussianMLPValueFunction/LossAfter        6.93847
GaussianMLPValueFunction/LossBefore       6.95825
GaussianMLPValueFunction/dLoss            0.0197878
TotalEnvSteps                        340800
-----------------------------------  ---------------
2022-08-17 18:07:42 | [trpo_pendulum] epoch #284 | Saving snapshot...
2022-08-17 18:07:42 | [trpo_pendulum] epoch #284 | Saved
2022-08-17 18:07:42 | [trpo_pendulum] epoch #284 | Time 178.48 s
2022-08-17 18:07:42 | [trpo_pendulum] epoch #284 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -601.249
Evaluation/AverageReturn              -1448.37
Evaluation/Iteration                    284
Evaluation/MaxReturn                  -1380.27
Evaluation/MinReturn                  -1510.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     45.3449
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.6295
GaussianMLPPolicy/KL                      0.00913113
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              58.7229
GaussianMLPPolicy/LossBefore             59.8541
GaussianMLPPolicy/dLoss                   1.13118
GaussianMLPValueFunction/LossAfter        6.725
GaussianMLPValueFunction/LossBefore       6.73338
GaussianMLPValueFunction/dLoss            0.00837612
TotalEnvSteps                        342000
-----------------------------------  ---------------
2022-08-17 18:07:43 | [trpo_pendulum] epoch #285 | Saving snapshot...
2022-08-17 18:07:43 | [trpo_pendulum] epoch #285 | Saved
2022-08-17 18:07:43 | [trpo_pendulum] epoch #285 | Time 179.09 s
2022-08-17 18:07:43 | [trpo_pendulum] epoch #285 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -546.845
Evaluation/AverageReturn              -1366.15
Evaluation/Iteration                    285
Evaluation/MaxReturn                  -1320.08
Evaluation/MinReturn                  -1399.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     27.7867
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62431
GaussianMLPPolicy/KL                      0.0059322
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              48.3109
GaussianMLPPolicy/LossBefore             49.8513
GaussianMLPPolicy/dLoss                   1.54044
GaussianMLPValueFunction/LossAfter        6.66679
GaussianMLPValueFunction/LossBefore       6.67831
GaussianMLPValueFunction/dLoss            0.0115223
TotalEnvSteps                        343200
-----------------------------------  --------------
2022-08-17 18:07:43 | [trpo_pendulum] epoch #286 | Saving snapshot...
2022-08-17 18:07:43 | [trpo_pendulum] epoch #286 | Saved
2022-08-17 18:07:43 | [trpo_pendulum] epoch #286 | Time 179.70 s
2022-08-17 18:07:43 | [trpo_pendulum] epoch #286 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -574.962
Evaluation/AverageReturn              -1394.88
Evaluation/Iteration                    286
Evaluation/MaxReturn                  -1291.02
Evaluation/MinReturn                  -1508.05
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     71.7793
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62192
GaussianMLPPolicy/KL                      0.00642585
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              48.2987
GaussianMLPPolicy/LossBefore             49.8134
GaussianMLPPolicy/dLoss                   1.51471
GaussianMLPValueFunction/LossAfter        6.63175
GaussianMLPValueFunction/LossBefore       6.64257
GaussianMLPValueFunction/dLoss            0.0108256
TotalEnvSteps                        344400
-----------------------------------  ---------------
2022-08-17 18:07:44 | [trpo_pendulum] epoch #287 | Saving snapshot...
2022-08-17 18:07:44 | [trpo_pendulum] epoch #287 | Saved
2022-08-17 18:07:44 | [trpo_pendulum] epoch #287 | Time 180.33 s
2022-08-17 18:07:44 | [trpo_pendulum] epoch #287 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -695.285
Evaluation/AverageReturn              -1643.41
Evaluation/Iteration                    287
Evaluation/MaxReturn                  -1640.51
Evaluation/MinReturn                  -1645.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      1.717
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.61687
GaussianMLPPolicy/KL                      0.00986264
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              82.9813
GaussianMLPPolicy/LossBefore             83.8654
GaussianMLPPolicy/dLoss                   0.884163
GaussianMLPValueFunction/LossAfter        6.92385
GaussianMLPValueFunction/LossBefore       6.95507
GaussianMLPValueFunction/dLoss            0.0312223
TotalEnvSteps                        345600
-----------------------------------  ---------------
2022-08-17 18:07:45 | [trpo_pendulum] epoch #288 | Saving snapshot...
2022-08-17 18:07:45 | [trpo_pendulum] epoch #288 | Saved
2022-08-17 18:07:45 | [trpo_pendulum] epoch #288 | Time 180.96 s
2022-08-17 18:07:45 | [trpo_pendulum] epoch #288 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -693.788
Evaluation/AverageReturn              -1644.76
Evaluation/Iteration                    288
Evaluation/MaxReturn                  -1641.27
Evaluation/MinReturn                  -1648.24
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      2.8426
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.60706
GaussianMLPPolicy/KL                      0.00475806
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              83.2742
GaussianMLPPolicy/LossBefore             83.5849
GaussianMLPPolicy/dLoss                   0.310631
GaussianMLPValueFunction/LossAfter        6.91149
GaussianMLPValueFunction/LossBefore       6.92618
GaussianMLPValueFunction/dLoss            0.0146837
TotalEnvSteps                        346800
-----------------------------------  ---------------
2022-08-17 18:07:45 | [trpo_pendulum] epoch #289 | Saving snapshot...
2022-08-17 18:07:45 | [trpo_pendulum] epoch #289 | Saved
2022-08-17 18:07:45 | [trpo_pendulum] epoch #289 | Time 181.57 s
2022-08-17 18:07:45 | [trpo_pendulum] epoch #289 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -572.967
Evaluation/AverageReturn              -1420.82
Evaluation/Iteration                    289
Evaluation/MaxReturn                  -1145.37
Evaluation/MinReturn                  -1600.27
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    179.523
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.61132
GaussianMLPPolicy/KL                      0.00751795
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              52.7701
GaussianMLPPolicy/LossBefore             54.3828
GaussianMLPPolicy/dLoss                   1.61269
GaussianMLPValueFunction/LossAfter        6.72609
GaussianMLPValueFunction/LossBefore       6.73263
GaussianMLPValueFunction/dLoss            0.00653982
TotalEnvSteps                        348000
-----------------------------------  ---------------
2022-08-17 18:07:46 | [trpo_pendulum] epoch #290 | Saving snapshot...
2022-08-17 18:07:46 | [trpo_pendulum] epoch #290 | Saved
2022-08-17 18:07:46 | [trpo_pendulum] epoch #290 | Time 182.22 s
2022-08-17 18:07:46 | [trpo_pendulum] epoch #290 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -453.247
Evaluation/AverageReturn              -1277.58
Evaluation/Iteration                    290
Evaluation/MaxReturn                  -1152.11
Evaluation/MinReturn                  -1409.38
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     82.7738
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.61197
GaussianMLPPolicy/KL                      0.00729874
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              37.8432
GaussianMLPPolicy/LossBefore             39.1672
GaussianMLPPolicy/dLoss                   1.32399
GaussianMLPValueFunction/LossAfter        6.60691
GaussianMLPValueFunction/LossBefore       6.62557
GaussianMLPValueFunction/dLoss            0.018661
TotalEnvSteps                        349200
-----------------------------------  ---------------
2022-08-17 18:07:47 | [trpo_pendulum] epoch #291 | Saving snapshot...
2022-08-17 18:07:47 | [trpo_pendulum] epoch #291 | Saved
2022-08-17 18:07:47 | [trpo_pendulum] epoch #291 | Time 182.86 s
2022-08-17 18:07:47 | [trpo_pendulum] epoch #291 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -527.979
Evaluation/AverageReturn              -1396.72
Evaluation/Iteration                    291
Evaluation/MaxReturn                  -1181.21
Evaluation/MinReturn                  -1529.47
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    106.675
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.63528
GaussianMLPPolicy/KL                      0.00741728
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              52.4194
GaussianMLPPolicy/LossBefore             53.8842
GaussianMLPPolicy/dLoss                   1.46481
GaussianMLPValueFunction/LossAfter        6.70789
GaussianMLPValueFunction/LossBefore       6.71188
GaussianMLPValueFunction/dLoss            0.00399542
TotalEnvSteps                        350400
-----------------------------------  ---------------
2022-08-17 18:07:47 | [trpo_pendulum] epoch #292 | Saving snapshot...
2022-08-17 18:07:47 | [trpo_pendulum] epoch #292 | Saved
2022-08-17 18:07:47 | [trpo_pendulum] epoch #292 | Time 183.48 s
2022-08-17 18:07:47 | [trpo_pendulum] epoch #292 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -588.677
Evaluation/AverageReturn              -1480.55
Evaluation/Iteration                    292
Evaluation/MaxReturn                  -1268.63
Evaluation/MinReturn                  -1609.25
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    124.318
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62533
GaussianMLPPolicy/KL                      0.00613563
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              60.8963
GaussianMLPPolicy/LossBefore             62.265
GaussianMLPPolicy/dLoss                   1.36872
GaussianMLPValueFunction/LossAfter        6.77524
GaussianMLPValueFunction/LossBefore       6.78053
GaussianMLPValueFunction/dLoss            0.00529003
TotalEnvSteps                        351600
-----------------------------------  ---------------
2022-08-17 18:07:48 | [trpo_pendulum] epoch #293 | Saving snapshot...
2022-08-17 18:07:48 | [trpo_pendulum] epoch #293 | Saved
2022-08-17 18:07:48 | [trpo_pendulum] epoch #293 | Time 184.09 s
2022-08-17 18:07:48 | [trpo_pendulum] epoch #293 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -544.207
Evaluation/AverageReturn              -1276.13
Evaluation/Iteration                    293
Evaluation/MaxReturn                  -1176.64
Evaluation/MinReturn                  -1343.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     66.1224
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.63529
GaussianMLPPolicy/KL                      0.00583808
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              26.4378
GaussianMLPPolicy/LossBefore             27.4221
GaussianMLPPolicy/dLoss                   0.984352
GaussianMLPValueFunction/LossAfter        6.50329
GaussianMLPValueFunction/LossBefore       6.53074
GaussianMLPValueFunction/dLoss            0.0274529
TotalEnvSteps                        352800
-----------------------------------  ---------------
2022-08-17 18:07:48 | [trpo_pendulum] epoch #294 | Saving snapshot...
2022-08-17 18:07:48 | [trpo_pendulum] epoch #294 | Saved
2022-08-17 18:07:48 | [trpo_pendulum] epoch #294 | Time 184.70 s
2022-08-17 18:07:48 | [trpo_pendulum] epoch #294 | EpochTime 0.60 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -677.403
Evaluation/AverageReturn              -1619.13
Evaluation/Iteration                    294
Evaluation/MaxReturn                  -1610.88
Evaluation/MinReturn                  -1628.79
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      6.20502
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.67349
GaussianMLPPolicy/KL                      0.0074126
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              76.5982
GaussianMLPPolicy/LossBefore             78.0541
GaussianMLPPolicy/dLoss                   1.45591
GaussianMLPValueFunction/LossAfter        6.88516
GaussianMLPValueFunction/LossBefore       6.91489
GaussianMLPValueFunction/dLoss            0.0297284
TotalEnvSteps                        354000
-----------------------------------  --------------
2022-08-17 18:07:49 | [trpo_pendulum] epoch #295 | Saving snapshot...
2022-08-17 18:07:49 | [trpo_pendulum] epoch #295 | Saved
2022-08-17 18:07:49 | [trpo_pendulum] epoch #295 | Time 185.32 s
2022-08-17 18:07:49 | [trpo_pendulum] epoch #295 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -647.281
Evaluation/AverageReturn              -1504.73
Evaluation/Iteration                    295
Evaluation/MaxReturn                  -1455.91
Evaluation/MinReturn                  -1517.56
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     22.1081
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.66256
GaussianMLPPolicy/KL                      0.00648832
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              55.5017
GaussianMLPPolicy/LossBefore             57.0393
GaussianMLPPolicy/dLoss                   1.53757
GaussianMLPValueFunction/LossAfter        6.71338
GaussianMLPValueFunction/LossBefore       6.71625
GaussianMLPValueFunction/dLoss            0.00286579
TotalEnvSteps                        355200
-----------------------------------  ---------------
2022-08-17 18:07:50 | [trpo_pendulum] epoch #296 | Saving snapshot...
2022-08-17 18:07:50 | [trpo_pendulum] epoch #296 | Saved
2022-08-17 18:07:50 | [trpo_pendulum] epoch #296 | Time 185.94 s
2022-08-17 18:07:50 | [trpo_pendulum] epoch #296 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -657.509
Evaluation/AverageReturn              -1509.33
Evaluation/Iteration                    296
Evaluation/MaxReturn                  -1505.19
Evaluation/MinReturn                  -1511.09
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      2.10536
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.66044
GaussianMLPPolicy/KL                      0.00804067
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              53.789
GaussianMLPPolicy/LossBefore             55.483
GaussianMLPPolicy/dLoss                   1.69405
GaussianMLPValueFunction/LossAfter        6.71786
GaussianMLPValueFunction/LossBefore       6.72044
GaussianMLPValueFunction/dLoss            0.0025816
TotalEnvSteps                        356400
-----------------------------------  ---------------
2022-08-17 18:07:50 | [trpo_pendulum] epoch #297 | Saving snapshot...
2022-08-17 18:07:50 | [trpo_pendulum] epoch #297 | Saved
2022-08-17 18:07:50 | [trpo_pendulum] epoch #297 | Time 186.54 s
2022-08-17 18:07:50 | [trpo_pendulum] epoch #297 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -547.705
Evaluation/AverageReturn              -1384.46
Evaluation/Iteration                    297
Evaluation/MaxReturn                  -1201.71
Evaluation/MinReturn                  -1459.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     97.538
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.6379
GaussianMLPPolicy/KL                      0.0072114
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              42.9241
GaussianMLPPolicy/LossBefore             44.3628
GaussianMLPPolicy/dLoss                   1.43868
GaussianMLPValueFunction/LossAfter        6.60581
GaussianMLPValueFunction/LossBefore       6.61518
GaussianMLPValueFunction/dLoss            0.00936508
TotalEnvSteps                        357600
-----------------------------------  ---------------
2022-08-17 18:07:51 | [trpo_pendulum] epoch #298 | Saving snapshot...
2022-08-17 18:07:51 | [trpo_pendulum] epoch #298 | Saved
2022-08-17 18:07:51 | [trpo_pendulum] epoch #298 | Time 187.16 s
2022-08-17 18:07:51 | [trpo_pendulum] epoch #298 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -538.577
Evaluation/AverageReturn              -1436.47
Evaluation/Iteration                    298
Evaluation/MaxReturn                  -1356.12
Evaluation/MinReturn                  -1496.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     55.523
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.6708
GaussianMLPPolicy/KL                      0.00808504
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              59.0615
GaussianMLPPolicy/LossBefore             60.9933
GaussianMLPPolicy/dLoss                   1.9318
GaussianMLPValueFunction/LossAfter        6.75634
GaussianMLPValueFunction/LossBefore       6.76322
GaussianMLPValueFunction/dLoss            0.00688314
TotalEnvSteps                        358800
-----------------------------------  ---------------
2022-08-17 18:07:51 | [trpo_pendulum] epoch #299 | Saving snapshot...
2022-08-17 18:07:52 | [trpo_pendulum] epoch #299 | Saved
2022-08-17 18:07:52 | [trpo_pendulum] epoch #299 | Time 187.79 s
2022-08-17 18:07:52 | [trpo_pendulum] epoch #299 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -665.656
Evaluation/AverageReturn              -1519.17
Evaluation/Iteration                    299
Evaluation/MaxReturn                  -1513.9
Evaluation/MinReturn                  -1526.01
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      4.72708
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.71461
GaussianMLPPolicy/KL                      0.00645711
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              52.645
GaussianMLPPolicy/LossBefore             53.9506
GaussianMLPPolicy/dLoss                   1.30564
GaussianMLPValueFunction/LossAfter        6.70939
GaussianMLPValueFunction/LossBefore       6.71194
GaussianMLPValueFunction/dLoss            0.00255156
TotalEnvSteps                        360000
-----------------------------------  ---------------
2022-08-17 18:07:52 | [trpo_pendulum] epoch #300 | Saving snapshot...
2022-08-17 18:07:52 | [trpo_pendulum] epoch #300 | Saved
2022-08-17 18:07:52 | [trpo_pendulum] epoch #300 | Time 188.41 s
2022-08-17 18:07:52 | [trpo_pendulum] epoch #300 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -607.211
Evaluation/AverageReturn              -1435.5
Evaluation/Iteration                    300
Evaluation/MaxReturn                  -1385.33
Evaluation/MinReturn                  -1465.46
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     30.5031
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.74288
GaussianMLPPolicy/KL                      0.008145
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              44.9397
GaussianMLPPolicy/LossBefore             46.122
GaussianMLPPolicy/dLoss                   1.18231
GaussianMLPValueFunction/LossAfter        6.63763
GaussianMLPValueFunction/LossBefore       6.64253
GaussianMLPValueFunction/dLoss            0.00490618
TotalEnvSteps                        361200
-----------------------------------  ---------------
2022-08-17 18:07:53 | [trpo_pendulum] epoch #301 | Saving snapshot...
2022-08-17 18:07:53 | [trpo_pendulum] epoch #301 | Saved
2022-08-17 18:07:53 | [trpo_pendulum] epoch #301 | Time 189.02 s
2022-08-17 18:07:53 | [trpo_pendulum] epoch #301 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -609.257
Evaluation/AverageReturn              -1421.13
Evaluation/Iteration                    301
Evaluation/MaxReturn                  -1333.87
Evaluation/MinReturn                  -1470.25
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.6115
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.75344
GaussianMLPPolicy/KL                      0.00609408
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              41.5898
GaussianMLPPolicy/LossBefore             42.6638
GaussianMLPPolicy/dLoss                   1.07399
GaussianMLPValueFunction/LossAfter        6.63713
GaussianMLPValueFunction/LossBefore       6.64005
GaussianMLPValueFunction/dLoss            0.0029254
TotalEnvSteps                        362400
-----------------------------------  ---------------
2022-08-17 18:07:53 | [trpo_pendulum] epoch #302 | Saving snapshot...
2022-08-17 18:07:53 | [trpo_pendulum] epoch #302 | Saved
2022-08-17 18:07:53 | [trpo_pendulum] epoch #302 | Time 189.64 s
2022-08-17 18:07:53 | [trpo_pendulum] epoch #302 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -506.797
Evaluation/AverageReturn              -1266.55
Evaluation/Iteration                    302
Evaluation/MaxReturn                  -1157.42
Evaluation/MinReturn                  -1330.83
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     74.1688
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.76705
GaussianMLPPolicy/KL                      0.0064451
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              24.1898
GaussianMLPPolicy/LossBefore             25.2208
GaussianMLPPolicy/dLoss                   1.03095
GaussianMLPValueFunction/LossAfter        6.47423
GaussianMLPValueFunction/LossBefore       6.49463
GaussianMLPValueFunction/dLoss            0.0204043
TotalEnvSteps                        363600
-----------------------------------  --------------
2022-08-17 18:07:54 | [trpo_pendulum] epoch #303 | Saving snapshot...
2022-08-17 18:07:54 | [trpo_pendulum] epoch #303 | Saved
2022-08-17 18:07:54 | [trpo_pendulum] epoch #303 | Time 190.26 s
2022-08-17 18:07:54 | [trpo_pendulum] epoch #303 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -657.697
Evaluation/AverageReturn              -1522.14
Evaluation/Iteration                    303
Evaluation/MaxReturn                  -1507.73
Evaluation/MinReturn                  -1538.13
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.40712
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.7748
GaussianMLPPolicy/KL                      0.0073064
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              52.3194
GaussianMLPPolicy/LossBefore             54.5729
GaussianMLPPolicy/dLoss                   2.25358
GaussianMLPValueFunction/LossAfter        6.73145
GaussianMLPValueFunction/LossBefore       6.74581
GaussianMLPValueFunction/dLoss            0.0143538
TotalEnvSteps                        364800
-----------------------------------  --------------
2022-08-17 18:07:55 | [trpo_pendulum] epoch #304 | Saving snapshot...
2022-08-17 18:07:55 | [trpo_pendulum] epoch #304 | Saved
2022-08-17 18:07:55 | [trpo_pendulum] epoch #304 | Time 190.87 s
2022-08-17 18:07:55 | [trpo_pendulum] epoch #304 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -439.183
Evaluation/AverageReturn              -1106.06
Evaluation/Iteration                    304
Evaluation/MaxReturn                   -641.128
Evaluation/MinReturn                  -1291.24
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    212.484
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.77783
GaussianMLPPolicy/KL                      0.00771194
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               1.55698
GaussianMLPPolicy/LossBefore              3.44286
GaussianMLPPolicy/dLoss                   1.88588
GaussianMLPValueFunction/LossAfter        6.55416
GaussianMLPValueFunction/LossBefore       6.55878
GaussianMLPValueFunction/dLoss            0.00461626
TotalEnvSteps                        366000
-----------------------------------  ---------------
2022-08-17 18:07:55 | [trpo_pendulum] epoch #305 | Saving snapshot...
2022-08-17 18:07:55 | [trpo_pendulum] epoch #305 | Saved
2022-08-17 18:07:55 | [trpo_pendulum] epoch #305 | Time 191.49 s
2022-08-17 18:07:55 | [trpo_pendulum] epoch #305 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -387.48
Evaluation/AverageReturn               -996.078
Evaluation/Iteration                    305
Evaluation/MaxReturn                   -768.332
Evaluation/MinReturn                  -1232.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    163.594
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.78079
GaussianMLPPolicy/KL                      0.00611513
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -14.6382
GaussianMLPPolicy/LossBefore            -13.8413
GaussianMLPPolicy/dLoss                   0.796866
GaussianMLPValueFunction/LossAfter        6.39929
GaussianMLPValueFunction/LossBefore       6.42461
GaussianMLPValueFunction/dLoss            0.0253263
TotalEnvSteps                        367200
-----------------------------------  ---------------
2022-08-17 18:07:56 | [trpo_pendulum] epoch #306 | Saving snapshot...
2022-08-17 18:07:56 | [trpo_pendulum] epoch #306 | Saved
2022-08-17 18:07:56 | [trpo_pendulum] epoch #306 | Time 192.11 s
2022-08-17 18:07:56 | [trpo_pendulum] epoch #306 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -669.31
Evaluation/AverageReturn              -1530.96
Evaluation/Iteration                    306
Evaluation/MaxReturn                  -1523.24
Evaluation/MinReturn                  -1537.41
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.04616
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.76593
GaussianMLPPolicy/KL                      0.0078293
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              52.0818
GaussianMLPPolicy/LossBefore             54.1797
GaussianMLPPolicy/dLoss                   2.09797
GaussianMLPValueFunction/LossAfter        6.73415
GaussianMLPValueFunction/LossBefore       6.75724
GaussianMLPValueFunction/dLoss            0.0230885
TotalEnvSteps                        368400
-----------------------------------  --------------
2022-08-17 18:07:56 | [trpo_pendulum] epoch #307 | Saving snapshot...
2022-08-17 18:07:56 | [trpo_pendulum] epoch #307 | Saved
2022-08-17 18:07:56 | [trpo_pendulum] epoch #307 | Time 192.73 s
2022-08-17 18:07:56 | [trpo_pendulum] epoch #307 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -490.56
Evaluation/AverageReturn              -1058.07
Evaluation/Iteration                    307
Evaluation/MaxReturn                   -624.297
Evaluation/MinReturn                  -1195.17
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    200.318
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.77305
GaussianMLPPolicy/KL                      0.00867417
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -17.3921
GaussianMLPPolicy/LossBefore            -15.3627
GaussianMLPPolicy/dLoss                   2.02946
GaussianMLPValueFunction/LossAfter        6.64063
GaussianMLPValueFunction/LossBefore       6.6449
GaussianMLPValueFunction/dLoss            0.00426912
TotalEnvSteps                        369600
-----------------------------------  ---------------
2022-08-17 18:07:57 | [trpo_pendulum] epoch #308 | Saving snapshot...
2022-08-17 18:07:57 | [trpo_pendulum] epoch #308 | Saved
2022-08-17 18:07:57 | [trpo_pendulum] epoch #308 | Time 193.34 s
2022-08-17 18:07:57 | [trpo_pendulum] epoch #308 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -656.758
Evaluation/AverageReturn              -1522.69
Evaluation/Iteration                    308
Evaluation/MaxReturn                  -1425.28
Evaluation/MinReturn                  -1554.81
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     44.1941
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.79718
GaussianMLPPolicy/KL                      0.00958171
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              52.202
GaussianMLPPolicy/LossBefore             54.3869
GaussianMLPPolicy/dLoss                   2.18491
GaussianMLPValueFunction/LossAfter        6.72795
GaussianMLPValueFunction/LossBefore       6.73834
GaussianMLPValueFunction/dLoss            0.0103869
TotalEnvSteps                        370800
-----------------------------------  ---------------
2022-08-17 18:07:58 | [trpo_pendulum] epoch #309 | Saving snapshot...
2022-08-17 18:07:58 | [trpo_pendulum] epoch #309 | Saved
2022-08-17 18:07:58 | [trpo_pendulum] epoch #309 | Time 193.96 s
2022-08-17 18:07:58 | [trpo_pendulum] epoch #309 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -328.512
Evaluation/AverageReturn               -777.8
Evaluation/Iteration                    309
Evaluation/MaxReturn                   -617.6
Evaluation/MinReturn                   -900.756
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    121.368
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.7826
GaussianMLPPolicy/KL                      0.00988823
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -55.2505
GaussianMLPPolicy/LossBefore            -51.2557
GaussianMLPPolicy/dLoss                   3.99476
GaussianMLPValueFunction/LossAfter        6.56383
GaussianMLPValueFunction/LossBefore       6.57649
GaussianMLPValueFunction/dLoss            0.0126591
TotalEnvSteps                        372000
-----------------------------------  ---------------
2022-08-17 18:07:58 | [trpo_pendulum] epoch #310 | Saving snapshot...
2022-08-17 18:07:58 | [trpo_pendulum] epoch #310 | Saved
2022-08-17 18:07:58 | [trpo_pendulum] epoch #310 | Time 194.59 s
2022-08-17 18:07:58 | [trpo_pendulum] epoch #310 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -684.868
Evaluation/AverageReturn              -1573.03
Evaluation/Iteration                    310
Evaluation/MaxReturn                  -1543.15
Evaluation/MinReturn                  -1589.27
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     15.1745
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.7768
GaussianMLPPolicy/KL                      0.00609124
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              58.8149
GaussianMLPPolicy/LossBefore             60.5115
GaussianMLPPolicy/dLoss                   1.69656
GaussianMLPValueFunction/LossAfter        6.76141
GaussianMLPValueFunction/LossBefore       6.77515
GaussianMLPValueFunction/dLoss            0.013742
TotalEnvSteps                        373200
-----------------------------------  ---------------
2022-08-17 18:07:59 | [trpo_pendulum] epoch #311 | Saving snapshot...
2022-08-17 18:07:59 | [trpo_pendulum] epoch #311 | Saved
2022-08-17 18:07:59 | [trpo_pendulum] epoch #311 | Time 195.22 s
2022-08-17 18:07:59 | [trpo_pendulum] epoch #311 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -371.053
Evaluation/AverageReturn               -705.668
Evaluation/Iteration                    311
Evaluation/MaxReturn                   -478.575
Evaluation/MinReturn                  -1121.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    205.554
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.72422
GaussianMLPPolicy/KL                      0.00942134
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -74.1709
GaussianMLPPolicy/LossBefore            -72.0702
GaussianMLPPolicy/dLoss                   2.10072
GaussianMLPValueFunction/LossAfter        6.84852
GaussianMLPValueFunction/LossBefore       6.87972
GaussianMLPValueFunction/dLoss            0.0311995
TotalEnvSteps                        374400
-----------------------------------  ---------------
2022-08-17 18:08:00 | [trpo_pendulum] epoch #312 | Saving snapshot...
2022-08-17 18:08:00 | [trpo_pendulum] epoch #312 | Saved
2022-08-17 18:08:00 | [trpo_pendulum] epoch #312 | Time 195.85 s
2022-08-17 18:08:00 | [trpo_pendulum] epoch #312 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -657.09
Evaluation/AverageReturn              -1498.76
Evaluation/Iteration                    312
Evaluation/MaxReturn                  -1350.13
Evaluation/MinReturn                  -1569.25
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     74.6174
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.72964
GaussianMLPPolicy/KL                      0.00671618
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              48.5075
GaussianMLPPolicy/LossBefore             50.9503
GaussianMLPPolicy/dLoss                   2.44279
GaussianMLPValueFunction/LossAfter        6.73426
GaussianMLPValueFunction/LossBefore       6.73547
GaussianMLPValueFunction/dLoss            0.00120878
TotalEnvSteps                        375600
-----------------------------------  ---------------
2022-08-17 18:08:00 | [trpo_pendulum] epoch #313 | Saving snapshot...
2022-08-17 18:08:00 | [trpo_pendulum] epoch #313 | Saved
2022-08-17 18:08:00 | [trpo_pendulum] epoch #313 | Time 196.48 s
2022-08-17 18:08:00 | [trpo_pendulum] epoch #313 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -444.711
Evaluation/AverageReturn              -1019.4
Evaluation/Iteration                    313
Evaluation/MaxReturn                   -745.79
Evaluation/MinReturn                  -1147.63
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    155.542
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.74627
GaussianMLPPolicy/KL                      0.00771846
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -19.0882
GaussianMLPPolicy/LossBefore            -17.6243
GaussianMLPPolicy/dLoss                   1.46393
GaussianMLPValueFunction/LossAfter        6.48896
GaussianMLPValueFunction/LossBefore       6.51678
GaussianMLPValueFunction/dLoss            0.0278139
TotalEnvSteps                        376800
-----------------------------------  ---------------
2022-08-17 18:08:01 | [trpo_pendulum] epoch #314 | Saving snapshot...
2022-08-17 18:08:01 | [trpo_pendulum] epoch #314 | Saved
2022-08-17 18:08:01 | [trpo_pendulum] epoch #314 | Time 197.10 s
2022-08-17 18:08:01 | [trpo_pendulum] epoch #314 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -522.675
Evaluation/AverageReturn              -1198.68
Evaluation/Iteration                    314
Evaluation/MaxReturn                  -1090.29
Evaluation/MinReturn                  -1254.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     60.7035
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.77909
GaussianMLPPolicy/KL                      0.00717956
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               6.31381
GaussianMLPPolicy/LossBefore              8.61893
GaussianMLPPolicy/dLoss                   2.30512
GaussianMLPValueFunction/LossAfter        6.44147
GaussianMLPValueFunction/LossBefore       6.46341
GaussianMLPValueFunction/dLoss            0.0219364
TotalEnvSteps                        378000
-----------------------------------  ---------------
2022-08-17 18:08:01 | [trpo_pendulum] epoch #315 | Saving snapshot...
2022-08-17 18:08:01 | [trpo_pendulum] epoch #315 | Saved
2022-08-17 18:08:01 | [trpo_pendulum] epoch #315 | Time 197.70 s
2022-08-17 18:08:01 | [trpo_pendulum] epoch #315 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -457.529
Evaluation/AverageReturn              -1055.33
Evaluation/Iteration                    315
Evaluation/MaxReturn                   -892.803
Evaluation/MinReturn                  -1156.35
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     82.5908
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.78766
GaussianMLPPolicy/KL                      0.00643884
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -10.8693
GaussianMLPPolicy/LossBefore             -9.08231
GaussianMLPPolicy/dLoss                   1.78695
GaussianMLPValueFunction/LossAfter        6.48356
GaussianMLPValueFunction/LossBefore       6.49222
GaussianMLPValueFunction/dLoss            0.00866175
TotalEnvSteps                        379200
-----------------------------------  ---------------
2022-08-17 18:08:02 | [trpo_pendulum] epoch #316 | Saving snapshot...
2022-08-17 18:08:02 | [trpo_pendulum] epoch #316 | Saved
2022-08-17 18:08:02 | [trpo_pendulum] epoch #316 | Time 198.30 s
2022-08-17 18:08:02 | [trpo_pendulum] epoch #316 | EpochTime 0.59 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -455.727
Evaluation/AverageReturn              -1014.55
Evaluation/Iteration                    316
Evaluation/MaxReturn                   -477.73
Evaluation/MinReturn                  -1140.51
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    241.012
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.75012
GaussianMLPPolicy/KL                      0.0065464
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -20.2577
GaussianMLPPolicy/LossBefore            -18.3467
GaussianMLPPolicy/dLoss                   1.91099
GaussianMLPValueFunction/LossAfter        6.5942
GaussianMLPValueFunction/LossBefore       6.59813
GaussianMLPValueFunction/dLoss            0.0039258
TotalEnvSteps                        380400
-----------------------------------  --------------
2022-08-17 18:08:03 | [trpo_pendulum] epoch #317 | Saving snapshot...
2022-08-17 18:08:03 | [trpo_pendulum] epoch #317 | Saved
2022-08-17 18:08:03 | [trpo_pendulum] epoch #317 | Time 198.91 s
2022-08-17 18:08:03 | [trpo_pendulum] epoch #317 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -660.569
Evaluation/AverageReturn              -1488.11
Evaluation/Iteration                    317
Evaluation/MaxReturn                  -1438.35
Evaluation/MinReturn                  -1536.25
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     39.7437
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.73698
GaussianMLPPolicy/KL                      0.0093326
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              46.039
GaussianMLPPolicy/LossBefore             49.563
GaussianMLPPolicy/dLoss                   3.52407
GaussianMLPValueFunction/LossAfter        6.74184
GaussianMLPValueFunction/LossBefore       6.75857
GaussianMLPValueFunction/dLoss            0.0167327
TotalEnvSteps                        381600
-----------------------------------  --------------
2022-08-17 18:08:03 | [trpo_pendulum] epoch #318 | Saving snapshot...
2022-08-17 18:08:03 | [trpo_pendulum] epoch #318 | Saved
2022-08-17 18:08:03 | [trpo_pendulum] epoch #318 | Time 199.53 s
2022-08-17 18:08:03 | [trpo_pendulum] epoch #318 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -298.218
Evaluation/AverageReturn               -609.152
Evaluation/Iteration                    318
Evaluation/MaxReturn                   -375.384
Evaluation/MinReturn                   -893.669
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    172.387
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.72944
GaussianMLPPolicy/KL                      0.00641086
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -78.3813
GaussianMLPPolicy/LossBefore            -76.1785
GaussianMLPPolicy/dLoss                   2.20277
GaussianMLPValueFunction/LossAfter        6.85407
GaussianMLPValueFunction/LossBefore       6.89815
GaussianMLPValueFunction/dLoss            0.0440798
TotalEnvSteps                        382800
-----------------------------------  ---------------
2022-08-17 18:08:04 | [trpo_pendulum] epoch #319 | Saving snapshot...
2022-08-17 18:08:04 | [trpo_pendulum] epoch #319 | Saved
2022-08-17 18:08:04 | [trpo_pendulum] epoch #319 | Time 200.14 s
2022-08-17 18:08:04 | [trpo_pendulum] epoch #319 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -271.424
Evaluation/AverageReturn               -694.469
Evaluation/Iteration                    319
Evaluation/MaxReturn                   -522.072
Evaluation/MinReturn                   -873.086
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    139.836
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.68396
GaussianMLPPolicy/KL                      0.00948571
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -54.8448
GaussianMLPPolicy/LossBefore            -53.0265
GaussianMLPPolicy/dLoss                   1.81832
GaussianMLPValueFunction/LossAfter        6.6029
GaussianMLPValueFunction/LossBefore       6.61263
GaussianMLPValueFunction/dLoss            0.00972891
TotalEnvSteps                        384000
-----------------------------------  ---------------
2022-08-17 18:08:04 | [trpo_pendulum] epoch #320 | Saving snapshot...
2022-08-17 18:08:04 | [trpo_pendulum] epoch #320 | Saved
2022-08-17 18:08:04 | [trpo_pendulum] epoch #320 | Time 200.75 s
2022-08-17 18:08:04 | [trpo_pendulum] epoch #320 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -312.356
Evaluation/AverageReturn               -644.101
Evaluation/Iteration                    320
Evaluation/MaxReturn                   -379.843
Evaluation/MinReturn                   -906.391
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    170.353
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.70811
GaussianMLPPolicy/KL                      0.00675838
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -73.2972
GaussianMLPPolicy/LossBefore            -71.6166
GaussianMLPPolicy/dLoss                   1.6806
GaussianMLPValueFunction/LossAfter        6.76554
GaussianMLPValueFunction/LossBefore       6.78075
GaussianMLPValueFunction/dLoss            0.0152068
TotalEnvSteps                        385200
-----------------------------------  ---------------
2022-08-17 18:08:05 | [trpo_pendulum] epoch #321 | Saving snapshot...
2022-08-17 18:08:05 | [trpo_pendulum] epoch #321 | Saved
2022-08-17 18:08:05 | [trpo_pendulum] epoch #321 | Time 201.37 s
2022-08-17 18:08:05 | [trpo_pendulum] epoch #321 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -285.083
Evaluation/AverageReturn               -682.339
Evaluation/Iteration                    321
Evaluation/MaxReturn                   -505.012
Evaluation/MinReturn                   -878.419
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    157.729
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.70712
GaussianMLPPolicy/KL                      0.00717175
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -58.1231
GaussianMLPPolicy/LossBefore            -55.9703
GaussianMLPPolicy/dLoss                   2.15283
GaussianMLPValueFunction/LossAfter        6.61926
GaussianMLPValueFunction/LossBefore       6.62846
GaussianMLPValueFunction/dLoss            0.00919914
TotalEnvSteps                        386400
-----------------------------------  ---------------
2022-08-17 18:08:06 | [trpo_pendulum] epoch #322 | Saving snapshot...
2022-08-17 18:08:06 | [trpo_pendulum] epoch #322 | Saved
2022-08-17 18:08:06 | [trpo_pendulum] epoch #322 | Time 201.99 s
2022-08-17 18:08:06 | [trpo_pendulum] epoch #322 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -420.457
Evaluation/AverageReturn               -831.44
Evaluation/Iteration                    322
Evaluation/MaxReturn                   -591.583
Evaluation/MinReturn                  -1122.16
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    176.112
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.71337
GaussianMLPPolicy/KL                      0.00970543
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -47.6996
GaussianMLPPolicy/LossBefore            -45.8007
GaussianMLPPolicy/dLoss                   1.89891
GaussianMLPValueFunction/LossAfter        6.70328
GaussianMLPValueFunction/LossBefore       6.70952
GaussianMLPValueFunction/dLoss            0.00623989
TotalEnvSteps                        387600
-----------------------------------  ---------------
2022-08-17 18:08:06 | [trpo_pendulum] epoch #323 | Saving snapshot...
2022-08-17 18:08:06 | [trpo_pendulum] epoch #323 | Saved
2022-08-17 18:08:06 | [trpo_pendulum] epoch #323 | Time 202.61 s
2022-08-17 18:08:06 | [trpo_pendulum] epoch #323 | EpochTime 0.61 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -625.211
Evaluation/AverageReturn              -1320.32
Evaluation/Iteration                    323
Evaluation/MaxReturn                  -1115.87
Evaluation/MinReturn                  -1544.65
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    163.808
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.74064
GaussianMLPPolicy/KL                      0.00915751
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              21.5533
GaussianMLPPolicy/LossBefore             25.5691
GaussianMLPPolicy/dLoss                   4.01581
GaussianMLPValueFunction/LossAfter        6.71992
GaussianMLPValueFunction/LossBefore       6.72055
GaussianMLPValueFunction/dLoss            0.000634193
TotalEnvSteps                        388800
-----------------------------------  ----------------
2022-08-17 18:08:07 | [trpo_pendulum] epoch #324 | Saving snapshot...
2022-08-17 18:08:07 | [trpo_pendulum] epoch #324 | Saved
2022-08-17 18:08:07 | [trpo_pendulum] epoch #324 | Time 203.22 s
2022-08-17 18:08:07 | [trpo_pendulum] epoch #324 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -331.241
Evaluation/AverageReturn               -680.314
Evaluation/Iteration                    324
Evaluation/MaxReturn                   -371.208
Evaluation/MinReturn                  -1124.47
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    299.146
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.7473
GaussianMLPPolicy/KL                      0.00688114
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -65.6068
GaussianMLPPolicy/LossBefore            -64.5578
GaussianMLPPolicy/dLoss                   1.04907
GaussianMLPValueFunction/LossAfter        6.80939
GaussianMLPValueFunction/LossBefore       6.82483
GaussianMLPValueFunction/dLoss            0.0154424
TotalEnvSteps                        390000
-----------------------------------  ---------------
2022-08-17 18:08:08 | [trpo_pendulum] epoch #325 | Saving snapshot...
2022-08-17 18:08:08 | [trpo_pendulum] epoch #325 | Saved
2022-08-17 18:08:08 | [trpo_pendulum] epoch #325 | Time 203.84 s
2022-08-17 18:08:08 | [trpo_pendulum] epoch #325 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -401.409
Evaluation/AverageReturn               -800.396
Evaluation/Iteration                    325
Evaluation/MaxReturn                   -343.657
Evaluation/MinReturn                  -1172.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    280.331
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.75088
GaussianMLPPolicy/KL                      0.00731452
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -51.5274
GaussianMLPPolicy/LossBefore            -49.5698
GaussianMLPPolicy/dLoss                   1.95761
GaussianMLPValueFunction/LossAfter        6.74181
GaussianMLPValueFunction/LossBefore       6.74698
GaussianMLPValueFunction/dLoss            0.00517035
TotalEnvSteps                        391200
-----------------------------------  ---------------
2022-08-17 18:08:08 | [trpo_pendulum] epoch #326 | Saving snapshot...
2022-08-17 18:08:08 | [trpo_pendulum] epoch #326 | Saved
2022-08-17 18:08:08 | [trpo_pendulum] epoch #326 | Time 204.47 s
2022-08-17 18:08:08 | [trpo_pendulum] epoch #326 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -312.851
Evaluation/AverageReturn               -633.048
Evaluation/Iteration                    326
Evaluation/MaxReturn                   -247.729
Evaluation/MinReturn                  -1149.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    330.944
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.72632
GaussianMLPPolicy/KL                      0.0085091
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -73.1369
GaussianMLPPolicy/LossBefore            -70.7429
GaussianMLPPolicy/dLoss                   2.39397
GaussianMLPValueFunction/LossAfter        6.87078
GaussianMLPValueFunction/LossBefore       6.88889
GaussianMLPValueFunction/dLoss            0.0181041
TotalEnvSteps                        392400
-----------------------------------  --------------
2022-08-17 18:08:09 | [trpo_pendulum] epoch #327 | Saving snapshot...
2022-08-17 18:08:09 | [trpo_pendulum] epoch #327 | Saved
2022-08-17 18:08:09 | [trpo_pendulum] epoch #327 | Time 205.11 s
2022-08-17 18:08:09 | [trpo_pendulum] epoch #327 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -396.733
Evaluation/AverageReturn               -791.122
Evaluation/Iteration                    327
Evaluation/MaxReturn                   -491.533
Evaluation/MinReturn                   -992.389
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    185.197
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.70134
GaussianMLPPolicy/KL                      0.00924146
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -49.1252
GaussianMLPPolicy/LossBefore            -47.8746
GaussianMLPPolicy/dLoss                   1.25063
GaussianMLPValueFunction/LossAfter        6.70317
GaussianMLPValueFunction/LossBefore       6.71091
GaussianMLPValueFunction/dLoss            0.0077405
TotalEnvSteps                        393600
-----------------------------------  ---------------
2022-08-17 18:08:09 | [trpo_pendulum] epoch #328 | Saving snapshot...
2022-08-17 18:08:09 | [trpo_pendulum] epoch #328 | Saved
2022-08-17 18:08:09 | [trpo_pendulum] epoch #328 | Time 205.73 s
2022-08-17 18:08:09 | [trpo_pendulum] epoch #328 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -591.133
Evaluation/AverageReturn              -1208.26
Evaluation/Iteration                    328
Evaluation/MaxReturn                   -945.401
Evaluation/MinReturn                  -1338.35
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    124.794
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.7102
GaussianMLPPolicy/KL                      0.00647286
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               7.8214
GaussianMLPPolicy/LossBefore             10.0552
GaussianMLPPolicy/dLoss                   2.23379
GaussianMLPValueFunction/LossAfter        6.63015
GaussianMLPValueFunction/LossBefore       6.63947
GaussianMLPValueFunction/dLoss            0.00931978
TotalEnvSteps                        394800
-----------------------------------  ---------------
2022-08-17 18:08:10 | [trpo_pendulum] epoch #329 | Saving snapshot...
2022-08-17 18:08:10 | [trpo_pendulum] epoch #329 | Saved
2022-08-17 18:08:10 | [trpo_pendulum] epoch #329 | Time 206.34 s
2022-08-17 18:08:10 | [trpo_pendulum] epoch #329 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -429.155
Evaluation/AverageReturn               -840.157
Evaluation/Iteration                    329
Evaluation/MaxReturn                   -617.189
Evaluation/MinReturn                  -1127.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    201.729
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.70227
GaussianMLPPolicy/KL                      0.00667463
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -45.2899
GaussianMLPPolicy/LossBefore            -42.9505
GaussianMLPPolicy/dLoss                   2.33941
GaussianMLPValueFunction/LossAfter        6.68292
GaussianMLPValueFunction/LossBefore       6.68851
GaussianMLPValueFunction/dLoss            0.00558519
TotalEnvSteps                        396000
-----------------------------------  ---------------
2022-08-17 18:08:11 | [trpo_pendulum] epoch #330 | Saving snapshot...
2022-08-17 18:08:11 | [trpo_pendulum] epoch #330 | Saved
2022-08-17 18:08:11 | [trpo_pendulum] epoch #330 | Time 206.98 s
2022-08-17 18:08:11 | [trpo_pendulum] epoch #330 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -364.185
Evaluation/AverageReturn               -794.839
Evaluation/Iteration                    330
Evaluation/MaxReturn                   -606.933
Evaluation/MinReturn                  -1113.99
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    173.458
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.6997
GaussianMLPPolicy/KL                      0.00655046
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -43.9859
GaussianMLPPolicy/LossBefore            -41.9739
GaussianMLPPolicy/dLoss                   2.01195
GaussianMLPValueFunction/LossAfter        6.55858
GaussianMLPValueFunction/LossBefore       6.57466
GaussianMLPValueFunction/dLoss            0.0160823
TotalEnvSteps                        397200
-----------------------------------  ---------------
2022-08-17 18:08:11 | [trpo_pendulum] epoch #331 | Saving snapshot...
2022-08-17 18:08:11 | [trpo_pendulum] epoch #331 | Saved
2022-08-17 18:08:11 | [trpo_pendulum] epoch #331 | Time 207.61 s
2022-08-17 18:08:11 | [trpo_pendulum] epoch #331 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -109.026
Evaluation/AverageReturn               -381.323
Evaluation/Iteration                    331
Evaluation/MaxReturn                   -145.542
Evaluation/MinReturn                   -762.675
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    193.703
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.66612
GaussianMLPPolicy/KL                      0.00756935
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -88.9607
GaussianMLPPolicy/LossBefore            -87.4751
GaussianMLPPolicy/dLoss                   1.48569
GaussianMLPValueFunction/LossAfter        6.81446
GaussianMLPValueFunction/LossBefore       6.84275
GaussianMLPValueFunction/dLoss            0.0282946
TotalEnvSteps                        398400
-----------------------------------  ---------------
2022-08-17 18:08:12 | [trpo_pendulum] epoch #332 | Saving snapshot...
2022-08-17 18:08:12 | [trpo_pendulum] epoch #332 | Saved
2022-08-17 18:08:12 | [trpo_pendulum] epoch #332 | Time 208.24 s
2022-08-17 18:08:12 | [trpo_pendulum] epoch #332 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -589.376
Evaluation/AverageReturn              -1159.95
Evaluation/Iteration                    332
Evaluation/MaxReturn                   -879.609
Evaluation/MinReturn                  -1460.68
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    215.461
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.64236
GaussianMLPPolicy/KL                      0.00678281
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               2.24384
GaussianMLPPolicy/LossBefore              4.835
GaussianMLPPolicy/dLoss                   2.59117
GaussianMLPValueFunction/LossAfter        6.78717
GaussianMLPValueFunction/LossBefore       6.79125
GaussianMLPValueFunction/dLoss            0.00407839
TotalEnvSteps                        399600
-----------------------------------  ---------------
2022-08-17 18:08:13 | [trpo_pendulum] epoch #333 | Saving snapshot...
2022-08-17 18:08:13 | [trpo_pendulum] epoch #333 | Saved
2022-08-17 18:08:13 | [trpo_pendulum] epoch #333 | Time 208.86 s
2022-08-17 18:08:13 | [trpo_pendulum] epoch #333 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -458.718
Evaluation/AverageReturn               -923.822
Evaluation/Iteration                    333
Evaluation/MaxReturn                   -717.722
Evaluation/MinReturn                  -1119.46
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    170.58
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.64947
GaussianMLPPolicy/KL                      0.00948938
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -29.7028
GaussianMLPPolicy/LossBefore            -27.8229
GaussianMLPPolicy/dLoss                   1.87989
GaussianMLPValueFunction/LossAfter        6.5465
GaussianMLPValueFunction/LossBefore       6.5669
GaussianMLPValueFunction/dLoss            0.0203924
TotalEnvSteps                        400800
-----------------------------------  ---------------
2022-08-17 18:08:13 | [trpo_pendulum] epoch #334 | Saving snapshot...
2022-08-17 18:08:13 | [trpo_pendulum] epoch #334 | Saved
2022-08-17 18:08:13 | [trpo_pendulum] epoch #334 | Time 209.48 s
2022-08-17 18:08:13 | [trpo_pendulum] epoch #334 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -386.512
Evaluation/AverageReturn               -791.617
Evaluation/Iteration                    334
Evaluation/MaxReturn                   -628.745
Evaluation/MinReturn                  -1014.74
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    125.317
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.66689
GaussianMLPPolicy/KL                      0.00832425
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -44.2075
GaussianMLPPolicy/LossBefore            -42.2295
GaussianMLPPolicy/dLoss                   1.97803
GaussianMLPValueFunction/LossAfter        6.59061
GaussianMLPValueFunction/LossBefore       6.60036
GaussianMLPValueFunction/dLoss            0.00975704
TotalEnvSteps                        402000
-----------------------------------  ---------------
2022-08-17 18:08:14 | [trpo_pendulum] epoch #335 | Saving snapshot...
2022-08-17 18:08:14 | [trpo_pendulum] epoch #335 | Saved
2022-08-17 18:08:14 | [trpo_pendulum] epoch #335 | Time 210.11 s
2022-08-17 18:08:14 | [trpo_pendulum] epoch #335 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -392.216
Evaluation/AverageReturn               -730.199
Evaluation/Iteration                    335
Evaluation/MaxReturn                   -601.72
Evaluation/MinReturn                   -980.752
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    144.87
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.64889
GaussianMLPPolicy/KL                      0.00835723
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -56.9689
GaussianMLPPolicy/LossBefore            -54.971
GaussianMLPPolicy/dLoss                   1.99788
GaussianMLPValueFunction/LossAfter        6.73358
GaussianMLPValueFunction/LossBefore       6.74637
GaussianMLPValueFunction/dLoss            0.0127835
TotalEnvSteps                        403200
-----------------------------------  ---------------
2022-08-17 18:08:14 | [trpo_pendulum] epoch #336 | Saving snapshot...
2022-08-17 18:08:14 | [trpo_pendulum] epoch #336 | Saved
2022-08-17 18:08:14 | [trpo_pendulum] epoch #336 | Time 210.74 s
2022-08-17 18:08:14 | [trpo_pendulum] epoch #336 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -647.744
Evaluation/AverageReturn              -1397.88
Evaluation/Iteration                    336
Evaluation/MaxReturn                  -1268.14
Evaluation/MinReturn                  -1553.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    103.315
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.64316
GaussianMLPPolicy/KL                      0.00737656
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              43.5603
GaussianMLPPolicy/LossBefore             45.5401
GaussianMLPPolicy/dLoss                   1.97981
GaussianMLPValueFunction/LossAfter        6.71881
GaussianMLPValueFunction/LossBefore       6.72051
GaussianMLPValueFunction/dLoss            0.00169992
TotalEnvSteps                        404400
-----------------------------------  ---------------
2022-08-17 18:08:15 | [trpo_pendulum] epoch #337 | Saving snapshot...
2022-08-17 18:08:15 | [trpo_pendulum] epoch #337 | Saved
2022-08-17 18:08:15 | [trpo_pendulum] epoch #337 | Time 211.36 s
2022-08-17 18:08:15 | [trpo_pendulum] epoch #337 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -476.166
Evaluation/AverageReturn               -951.158
Evaluation/Iteration                    337
Evaluation/MaxReturn                   -758.278
Evaluation/MinReturn                  -1165.41
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    141.677
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62195
GaussianMLPPolicy/KL                      0.00994962
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -24.8313
GaussianMLPPolicy/LossBefore            -22.2243
GaussianMLPPolicy/dLoss                   2.60702
GaussianMLPValueFunction/LossAfter        6.54803
GaussianMLPValueFunction/LossBefore       6.56162
GaussianMLPValueFunction/dLoss            0.0135889
TotalEnvSteps                        405600
-----------------------------------  ---------------
2022-08-17 18:08:16 | [trpo_pendulum] epoch #338 | Saving snapshot...
2022-08-17 18:08:16 | [trpo_pendulum] epoch #338 | Saved
2022-08-17 18:08:16 | [trpo_pendulum] epoch #338 | Time 211.98 s
2022-08-17 18:08:16 | [trpo_pendulum] epoch #338 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -365.844
Evaluation/AverageReturn               -710.556
Evaluation/Iteration                    338
Evaluation/MaxReturn                   -482.971
Evaluation/MinReturn                  -1048.26
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    188.414
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.60136
GaussianMLPPolicy/KL                      0.00723536
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -56.5444
GaussianMLPPolicy/LossBefore            -54.9951
GaussianMLPPolicy/dLoss                   1.54939
GaussianMLPValueFunction/LossAfter        6.72071
GaussianMLPValueFunction/LossBefore       6.73269
GaussianMLPValueFunction/dLoss            0.0119848
TotalEnvSteps                        406800
-----------------------------------  ---------------
2022-08-17 18:08:16 | [trpo_pendulum] epoch #339 | Saving snapshot...
2022-08-17 18:08:16 | [trpo_pendulum] epoch #339 | Saved
2022-08-17 18:08:16 | [trpo_pendulum] epoch #339 | Time 212.60 s
2022-08-17 18:08:16 | [trpo_pendulum] epoch #339 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -330.127
Evaluation/AverageReturn               -738.474
Evaluation/Iteration                    339
Evaluation/MaxReturn                   -504.692
Evaluation/MinReturn                  -1012.64
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    200.459
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.60244
GaussianMLPPolicy/KL                      0.00900725
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -41.9486
GaussianMLPPolicy/LossBefore            -39.6971
GaussianMLPPolicy/dLoss                   2.25152
GaussianMLPValueFunction/LossAfter        6.5905
GaussianMLPValueFunction/LossBefore       6.59906
GaussianMLPValueFunction/dLoss            0.00855827
TotalEnvSteps                        408000
-----------------------------------  ---------------
2022-08-17 18:08:17 | [trpo_pendulum] epoch #340 | Saving snapshot...
2022-08-17 18:08:17 | [trpo_pendulum] epoch #340 | Saved
2022-08-17 18:08:17 | [trpo_pendulum] epoch #340 | Time 213.23 s
2022-08-17 18:08:17 | [trpo_pendulum] epoch #340 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -667.409
Evaluation/AverageReturn              -1529.84
Evaluation/Iteration                    340
Evaluation/MaxReturn                  -1505.58
Evaluation/MinReturn                  -1569.14
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     19.5846
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.57378
GaussianMLPPolicy/KL                      0.00721352
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              68.3308
GaussianMLPPolicy/LossBefore             69.9165
GaussianMLPPolicy/dLoss                   1.58571
GaussianMLPValueFunction/LossAfter        6.79562
GaussianMLPValueFunction/LossBefore       6.81359
GaussianMLPValueFunction/dLoss            0.0179725
TotalEnvSteps                        409200
-----------------------------------  ---------------
2022-08-17 18:08:18 | [trpo_pendulum] epoch #341 | Saving snapshot...
2022-08-17 18:08:18 | [trpo_pendulum] epoch #341 | Saved
2022-08-17 18:08:18 | [trpo_pendulum] epoch #341 | Time 213.87 s
2022-08-17 18:08:18 | [trpo_pendulum] epoch #341 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -412.071
Evaluation/AverageReturn               -834.291
Evaluation/Iteration                    341
Evaluation/MaxReturn                   -611.645
Evaluation/MinReturn                  -1073.71
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    187.202
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.56005
GaussianMLPPolicy/KL                      0.00727619
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -36.6767
GaussianMLPPolicy/LossBefore            -34.8449
GaussianMLPPolicy/dLoss                   1.83172
GaussianMLPValueFunction/LossAfter        6.5703
GaussianMLPValueFunction/LossBefore       6.5823
GaussianMLPValueFunction/dLoss            0.0120001
TotalEnvSteps                        410400
-----------------------------------  ---------------
2022-08-17 18:08:18 | [trpo_pendulum] epoch #342 | Saving snapshot...
2022-08-17 18:08:18 | [trpo_pendulum] epoch #342 | Saved
2022-08-17 18:08:18 | [trpo_pendulum] epoch #342 | Time 214.51 s
2022-08-17 18:08:18 | [trpo_pendulum] epoch #342 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -214.389
Evaluation/AverageReturn               -472.926
Evaluation/Iteration                    342
Evaluation/MaxReturn                   -272.524
Evaluation/MinReturn                   -686.112
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    153.597
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.57946
GaussianMLPPolicy/KL                      0.00832142
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -83.5404
GaussianMLPPolicy/LossBefore            -81.9925
GaussianMLPPolicy/dLoss                   1.54794
GaussianMLPValueFunction/LossAfter        6.75631
GaussianMLPValueFunction/LossBefore       6.77422
GaussianMLPValueFunction/dLoss            0.017909
TotalEnvSteps                        411600
-----------------------------------  ---------------
2022-08-17 18:08:19 | [trpo_pendulum] epoch #343 | Saving snapshot...
2022-08-17 18:08:19 | [trpo_pendulum] epoch #343 | Saved
2022-08-17 18:08:19 | [trpo_pendulum] epoch #343 | Time 215.12 s
2022-08-17 18:08:19 | [trpo_pendulum] epoch #343 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -467.28
Evaluation/AverageReturn               -872.506
Evaluation/Iteration                    343
Evaluation/MaxReturn                   -717.729
Evaluation/MinReturn                  -1066.96
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    127.992
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.57482
GaussianMLPPolicy/KL                      0.00698557
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -34.5566
GaussianMLPPolicy/LossBefore            -32.0602
GaussianMLPPolicy/dLoss                   2.49646
GaussianMLPValueFunction/LossAfter        6.65911
GaussianMLPValueFunction/LossBefore       6.66375
GaussianMLPValueFunction/dLoss            0.00463724
TotalEnvSteps                        412800
-----------------------------------  ---------------
2022-08-17 18:08:19 | [trpo_pendulum] epoch #344 | Saving snapshot...
2022-08-17 18:08:19 | [trpo_pendulum] epoch #344 | Saved
2022-08-17 18:08:19 | [trpo_pendulum] epoch #344 | Time 215.75 s
2022-08-17 18:08:19 | [trpo_pendulum] epoch #344 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -467.213
Evaluation/AverageReturn               -841.068
Evaluation/Iteration                    344
Evaluation/MaxReturn                   -725.024
Evaluation/MinReturn                   -948.903
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     64.8599
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.58144
GaussianMLPPolicy/KL                      0.00681701
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -39.4421
GaussianMLPPolicy/LossBefore            -36.6742
GaussianMLPPolicy/dLoss                   2.76792
GaussianMLPValueFunction/LossAfter        6.72544
GaussianMLPValueFunction/LossBefore       6.73166
GaussianMLPValueFunction/dLoss            0.00621462
TotalEnvSteps                        414000
-----------------------------------  ---------------
2022-08-17 18:08:20 | [trpo_pendulum] epoch #345 | Saving snapshot...
2022-08-17 18:08:20 | [trpo_pendulum] epoch #345 | Saved
2022-08-17 18:08:20 | [trpo_pendulum] epoch #345 | Time 216.36 s
2022-08-17 18:08:20 | [trpo_pendulum] epoch #345 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -543.761
Evaluation/AverageReturn              -1099.66
Evaluation/Iteration                    345
Evaluation/MaxReturn                   -833.985
Evaluation/MinReturn                  -1333.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    164.798
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.57057
GaussianMLPPolicy/KL                      0.00671992
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               1.63646
GaussianMLPPolicy/LossBefore              4.1865
GaussianMLPPolicy/dLoss                   2.55004
GaussianMLPValueFunction/LossAfter        6.60525
GaussianMLPValueFunction/LossBefore       6.61074
GaussianMLPValueFunction/dLoss            0.00548792
TotalEnvSteps                        415200
-----------------------------------  ---------------
2022-08-17 18:08:21 | [trpo_pendulum] epoch #346 | Saving snapshot...
2022-08-17 18:08:21 | [trpo_pendulum] epoch #346 | Saved
2022-08-17 18:08:21 | [trpo_pendulum] epoch #346 | Time 216.98 s
2022-08-17 18:08:21 | [trpo_pendulum] epoch #346 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -579.504
Evaluation/AverageReturn              -1213.65
Evaluation/Iteration                    346
Evaluation/MaxReturn                   -758.3
Evaluation/MinReturn                  -1551.99
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    278.066
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.5678
GaussianMLPPolicy/KL                      0.00977375
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              19.8164
GaussianMLPPolicy/LossBefore             22.8398
GaussianMLPPolicy/dLoss                   3.02337
GaussianMLPValueFunction/LossAfter        6.73345
GaussianMLPValueFunction/LossBefore       6.73633
GaussianMLPValueFunction/dLoss            0.00287771
TotalEnvSteps                        416400
-----------------------------------  ---------------
2022-08-17 18:08:21 | [trpo_pendulum] epoch #347 | Saving snapshot...
2022-08-17 18:08:21 | [trpo_pendulum] epoch #347 | Saved
2022-08-17 18:08:21 | [trpo_pendulum] epoch #347 | Time 217.61 s
2022-08-17 18:08:21 | [trpo_pendulum] epoch #347 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -334.604
Evaluation/AverageReturn               -625.181
Evaluation/Iteration                    347
Evaluation/MaxReturn                   -490.487
Evaluation/MinReturn                   -966.265
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    161.644
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.54672
GaussianMLPPolicy/KL                      0.00911814
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -64.961
GaussianMLPPolicy/LossBefore            -63.2238
GaussianMLPPolicy/dLoss                   1.73721
GaussianMLPValueFunction/LossAfter        6.73542
GaussianMLPValueFunction/LossBefore       6.74605
GaussianMLPValueFunction/dLoss            0.0106201
TotalEnvSteps                        417600
-----------------------------------  ---------------
2022-08-17 18:08:22 | [trpo_pendulum] epoch #348 | Saving snapshot...
2022-08-17 18:08:22 | [trpo_pendulum] epoch #348 | Saved
2022-08-17 18:08:22 | [trpo_pendulum] epoch #348 | Time 218.24 s
2022-08-17 18:08:22 | [trpo_pendulum] epoch #348 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -660.421
Evaluation/AverageReturn              -1475.75
Evaluation/Iteration                    348
Evaluation/MaxReturn                  -1305.56
Evaluation/MinReturn                  -1536.92
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     83.7464
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.54703
GaussianMLPPolicy/KL                      0.00780015
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              59.8548
GaussianMLPPolicy/LossBefore             64.1008
GaussianMLPPolicy/dLoss                   4.24601
GaussianMLPValueFunction/LossAfter        6.79423
GaussianMLPValueFunction/LossBefore       6.80145
GaussianMLPValueFunction/dLoss            0.00721645
TotalEnvSteps                        418800
-----------------------------------  ---------------
2022-08-17 18:08:23 | [trpo_pendulum] epoch #349 | Saving snapshot...
2022-08-17 18:08:23 | [trpo_pendulum] epoch #349 | Saved
2022-08-17 18:08:23 | [trpo_pendulum] epoch #349 | Time 218.86 s
2022-08-17 18:08:23 | [trpo_pendulum] epoch #349 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -482.056
Evaluation/AverageReturn               -939.94
Evaluation/Iteration                    349
Evaluation/MaxReturn                   -594.467
Evaluation/MinReturn                  -1096.11
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    200.661
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.54947
GaussianMLPPolicy/KL                      0.00650053
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -20.5842
GaussianMLPPolicy/LossBefore            -18.5175
GaussianMLPPolicy/dLoss                   2.06675
GaussianMLPValueFunction/LossAfter        6.63358
GaussianMLPValueFunction/LossBefore       6.64274
GaussianMLPValueFunction/dLoss            0.009161
TotalEnvSteps                        420000
-----------------------------------  ---------------
2022-08-17 18:08:23 | [trpo_pendulum] epoch #350 | Saving snapshot...
2022-08-17 18:08:23 | [trpo_pendulum] epoch #350 | Saved
2022-08-17 18:08:23 | [trpo_pendulum] epoch #350 | Time 219.49 s
2022-08-17 18:08:23 | [trpo_pendulum] epoch #350 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -412.067
Evaluation/AverageReturn               -790.859
Evaluation/Iteration                    350
Evaluation/MaxReturn                   -476.413
Evaluation/MinReturn                   -992.336
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    175.71
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.54954
GaussianMLPPolicy/KL                      0.0065507
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -41.4422
GaussianMLPPolicy/LossBefore            -39.2679
GaussianMLPPolicy/dLoss                   2.1743
GaussianMLPValueFunction/LossAfter        6.64142
GaussianMLPValueFunction/LossBefore       6.64902
GaussianMLPValueFunction/dLoss            0.00759649
TotalEnvSteps                        421200
-----------------------------------  ---------------
2022-08-17 18:08:24 | [trpo_pendulum] epoch #351 | Saving snapshot...
2022-08-17 18:08:24 | [trpo_pendulum] epoch #351 | Saved
2022-08-17 18:08:24 | [trpo_pendulum] epoch #351 | Time 220.12 s
2022-08-17 18:08:24 | [trpo_pendulum] epoch #351 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -322.726
Evaluation/AverageReturn               -543.583
Evaluation/Iteration                    351
Evaluation/MaxReturn                   -239.055
Evaluation/MinReturn                   -943.14
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    222.863
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.58813
GaussianMLPPolicy/KL                      0.00793293
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -77.3824
GaussianMLPPolicy/LossBefore            -75.4956
GaussianMLPPolicy/dLoss                   1.88678
GaussianMLPValueFunction/LossAfter        6.91159
GaussianMLPValueFunction/LossBefore       6.95889
GaussianMLPValueFunction/dLoss            0.0473032
TotalEnvSteps                        422400
-----------------------------------  ---------------
2022-08-17 18:08:24 | [trpo_pendulum] epoch #352 | Saving snapshot...
2022-08-17 18:08:24 | [trpo_pendulum] epoch #352 | Saved
2022-08-17 18:08:24 | [trpo_pendulum] epoch #352 | Time 220.75 s
2022-08-17 18:08:24 | [trpo_pendulum] epoch #352 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -252.559
Evaluation/AverageReturn               -386.006
Evaluation/Iteration                    352
Evaluation/MaxReturn                   -237.935
Evaluation/MinReturn                   -865.181
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    221.558
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.57026
GaussianMLPPolicy/KL                      0.00943466
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -100.096
GaussianMLPPolicy/LossBefore            -98.257
GaussianMLPPolicy/dLoss                   1.83916
GaussianMLPValueFunction/LossAfter        7.01686
GaussianMLPValueFunction/LossBefore       7.06514
GaussianMLPValueFunction/dLoss            0.0482793
TotalEnvSteps                        423600
-----------------------------------  ---------------
2022-08-17 18:08:25 | [trpo_pendulum] epoch #353 | Saving snapshot...
2022-08-17 18:08:25 | [trpo_pendulum] epoch #353 | Saved
2022-08-17 18:08:25 | [trpo_pendulum] epoch #353 | Time 221.40 s
2022-08-17 18:08:25 | [trpo_pendulum] epoch #353 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -250.373
Evaluation/AverageReturn               -463.315
Evaluation/Iteration                    353
Evaluation/MaxReturn                   -126.612
Evaluation/MinReturn                   -886.272
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    269.688
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.56323
GaussianMLPPolicy/KL                      0.00798521
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -80.1595
GaussianMLPPolicy/LossBefore            -78.3112
GaussianMLPPolicy/dLoss                   1.84825
GaussianMLPValueFunction/LossAfter        6.89042
GaussianMLPValueFunction/LossBefore       6.89796
GaussianMLPValueFunction/dLoss            0.00753736
TotalEnvSteps                        424800
-----------------------------------  ---------------
2022-08-17 18:08:26 | [trpo_pendulum] epoch #354 | Saving snapshot...
2022-08-17 18:08:26 | [trpo_pendulum] epoch #354 | Saved
2022-08-17 18:08:26 | [trpo_pendulum] epoch #354 | Time 222.02 s
2022-08-17 18:08:26 | [trpo_pendulum] epoch #354 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -423.369
Evaluation/AverageReturn               -843.419
Evaluation/Iteration                    354
Evaluation/MaxReturn                   -514.669
Evaluation/MinReturn                  -1169.98
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    255.074
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.57178
GaussianMLPPolicy/KL                      0.00759244
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -27.6436
GaussianMLPPolicy/LossBefore            -24.7698
GaussianMLPPolicy/dLoss                   2.87379
GaussianMLPValueFunction/LossAfter        6.70764
GaussianMLPValueFunction/LossBefore       6.71934
GaussianMLPValueFunction/dLoss            0.011704
TotalEnvSteps                        426000
-----------------------------------  ---------------
2022-08-17 18:08:26 | [trpo_pendulum] epoch #355 | Saving snapshot...
2022-08-17 18:08:26 | [trpo_pendulum] epoch #355 | Saved
2022-08-17 18:08:26 | [trpo_pendulum] epoch #355 | Time 222.63 s
2022-08-17 18:08:26 | [trpo_pendulum] epoch #355 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -306.348
Evaluation/AverageReturn               -554.593
Evaluation/Iteration                    355
Evaluation/MaxReturn                   -121.068
Evaluation/MinReturn                   -860.123
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    257.566
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.56892
GaussianMLPPolicy/KL                      0.0096219
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -70.3244
GaussianMLPPolicy/LossBefore            -68.1252
GaussianMLPPolicy/dLoss                   2.19924
GaussianMLPValueFunction/LossAfter        6.83128
GaussianMLPValueFunction/LossBefore       6.83719
GaussianMLPValueFunction/dLoss            0.00591183
TotalEnvSteps                        427200
-----------------------------------  ---------------
2022-08-17 18:08:27 | [trpo_pendulum] epoch #356 | Saving snapshot...
2022-08-17 18:08:27 | [trpo_pendulum] epoch #356 | Saved
2022-08-17 18:08:27 | [trpo_pendulum] epoch #356 | Time 223.25 s
2022-08-17 18:08:27 | [trpo_pendulum] epoch #356 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -286.344
Evaluation/AverageReturn               -504.364
Evaluation/Iteration                    356
Evaluation/MaxReturn                   -244.876
Evaluation/MinReturn                  -1021.91
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    268.168
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.55141
GaussianMLPPolicy/KL                      0.00904125
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -76.6874
GaussianMLPPolicy/LossBefore            -74.8296
GaussianMLPPolicy/dLoss                   1.8578
GaussianMLPValueFunction/LossAfter        6.86684
GaussianMLPValueFunction/LossBefore       6.87464
GaussianMLPValueFunction/dLoss            0.00779533
TotalEnvSteps                        428400
-----------------------------------  ---------------
2022-08-17 18:08:28 | [trpo_pendulum] epoch #357 | Saving snapshot...
2022-08-17 18:08:28 | [trpo_pendulum] epoch #357 | Saved
2022-08-17 18:08:28 | [trpo_pendulum] epoch #357 | Time 223.86 s
2022-08-17 18:08:28 | [trpo_pendulum] epoch #357 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -318.092
Evaluation/AverageReturn               -559.461
Evaluation/Iteration                    357
Evaluation/MaxReturn                   -364.068
Evaluation/MinReturn                   -871.54
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    192.764
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.54126
GaussianMLPPolicy/KL                      0.0064671
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -69.0339
GaussianMLPPolicy/LossBefore            -67.2425
GaussianMLPPolicy/dLoss                   1.79142
GaussianMLPValueFunction/LossAfter        6.7991
GaussianMLPValueFunction/LossBefore       6.80533
GaussianMLPValueFunction/dLoss            0.00622559
TotalEnvSteps                        429600
-----------------------------------  ---------------
2022-08-17 18:08:28 | [trpo_pendulum] epoch #358 | Saving snapshot...
2022-08-17 18:08:28 | [trpo_pendulum] epoch #358 | Saved
2022-08-17 18:08:28 | [trpo_pendulum] epoch #358 | Time 224.47 s
2022-08-17 18:08:28 | [trpo_pendulum] epoch #358 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -291.006
Evaluation/AverageReturn               -539.863
Evaluation/Iteration                    358
Evaluation/MaxReturn                   -249.984
Evaluation/MinReturn                   -977.157
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    248.889
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.54077
GaussianMLPPolicy/KL                      0.00650241
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -65.9414
GaussianMLPPolicy/LossBefore            -64.7227
GaussianMLPPolicy/dLoss                   1.21865
GaussianMLPValueFunction/LossAfter        6.81217
GaussianMLPValueFunction/LossBefore       6.81767
GaussianMLPValueFunction/dLoss            0.00549555
TotalEnvSteps                        430800
-----------------------------------  ---------------
2022-08-17 18:08:29 | [trpo_pendulum] epoch #359 | Saving snapshot...
2022-08-17 18:08:29 | [trpo_pendulum] epoch #359 | Saved
2022-08-17 18:08:29 | [trpo_pendulum] epoch #359 | Time 225.10 s
2022-08-17 18:08:29 | [trpo_pendulum] epoch #359 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -339.612
Evaluation/AverageReturn               -588.613
Evaluation/Iteration                    359
Evaluation/MaxReturn                   -233.502
Evaluation/MinReturn                   -999.388
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    237.45
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.54246
GaussianMLPPolicy/KL                      0.00981871
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -65.0064
GaussianMLPPolicy/LossBefore            -63.2221
GaussianMLPPolicy/dLoss                   1.78436
GaussianMLPValueFunction/LossAfter        6.81265
GaussianMLPValueFunction/LossBefore       6.81807
GaussianMLPValueFunction/dLoss            0.00541639
TotalEnvSteps                        432000
-----------------------------------  ---------------
2022-08-17 18:08:29 | [trpo_pendulum] epoch #360 | Saving snapshot...
2022-08-17 18:08:29 | [trpo_pendulum] epoch #360 | Saved
2022-08-17 18:08:29 | [trpo_pendulum] epoch #360 | Time 225.72 s
2022-08-17 18:08:29 | [trpo_pendulum] epoch #360 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -278.255
Evaluation/AverageReturn               -460.273
Evaluation/Iteration                    360
Evaluation/MaxReturn                   -122.986
Evaluation/MinReturn                  -1027.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    276.917
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.55755
GaussianMLPPolicy/KL                      0.00866318
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -81.6984
GaussianMLPPolicy/LossBefore            -80.2428
GaussianMLPPolicy/dLoss                   1.45562
GaussianMLPValueFunction/LossAfter        6.90907
GaussianMLPValueFunction/LossBefore       6.92175
GaussianMLPValueFunction/dLoss            0.0126848
TotalEnvSteps                        433200
-----------------------------------  ---------------
2022-08-17 18:08:30 | [trpo_pendulum] epoch #361 | Saving snapshot...
2022-08-17 18:08:30 | [trpo_pendulum] epoch #361 | Saved
2022-08-17 18:08:30 | [trpo_pendulum] epoch #361 | Time 226.35 s
2022-08-17 18:08:30 | [trpo_pendulum] epoch #361 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -442.466
Evaluation/AverageReturn               -863.899
Evaluation/Iteration                    361
Evaluation/MaxReturn                   -727.194
Evaluation/MinReturn                   -968.666
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     80.0527
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.53878
GaussianMLPPolicy/KL                      0.00657455
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -22.0955
GaussianMLPPolicy/LossBefore            -20.4998
GaussianMLPPolicy/dLoss                   1.59571
GaussianMLPValueFunction/LossAfter        6.55079
GaussianMLPValueFunction/LossBefore       6.59609
GaussianMLPValueFunction/dLoss            0.0452995
TotalEnvSteps                        434400
-----------------------------------  ---------------
2022-08-17 18:08:31 | [trpo_pendulum] epoch #362 | Saving snapshot...
2022-08-17 18:08:31 | [trpo_pendulum] epoch #362 | Saved
2022-08-17 18:08:31 | [trpo_pendulum] epoch #362 | Time 226.96 s
2022-08-17 18:08:31 | [trpo_pendulum] epoch #362 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -246.635
Evaluation/AverageReturn               -391.005
Evaluation/Iteration                    362
Evaluation/MaxReturn                   -244.887
Evaluation/MinReturn                   -623.993
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    135.317
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.49635
GaussianMLPPolicy/KL                      0.00671263
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -89.5132
GaussianMLPPolicy/LossBefore            -87.9138
GaussianMLPPolicy/dLoss                   1.5994
GaussianMLPValueFunction/LossAfter        6.90688
GaussianMLPValueFunction/LossBefore       6.92804
GaussianMLPValueFunction/dLoss            0.0211573
TotalEnvSteps                        435600
-----------------------------------  ---------------
2022-08-17 18:08:31 | [trpo_pendulum] epoch #363 | Saving snapshot...
2022-08-17 18:08:31 | [trpo_pendulum] epoch #363 | Saved
2022-08-17 18:08:31 | [trpo_pendulum] epoch #363 | Time 227.59 s
2022-08-17 18:08:31 | [trpo_pendulum] epoch #363 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -654.025
Evaluation/AverageReturn              -1505.45
Evaluation/Iteration                    363
Evaluation/MaxReturn                  -1497.95
Evaluation/MinReturn                  -1511.19
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.17555
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.48336
GaussianMLPPolicy/KL                      0.00754466
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              79.3386
GaussianMLPPolicy/LossBefore             80.064
GaussianMLPPolicy/dLoss                   0.725357
GaussianMLPValueFunction/LossAfter        6.83709
GaussianMLPValueFunction/LossBefore       6.84067
GaussianMLPValueFunction/dLoss            0.003582
TotalEnvSteps                        436800
-----------------------------------  ---------------
2022-08-17 18:08:32 | [trpo_pendulum] epoch #364 | Saving snapshot...
2022-08-17 18:08:32 | [trpo_pendulum] epoch #364 | Saved
2022-08-17 18:08:32 | [trpo_pendulum] epoch #364 | Time 228.21 s
2022-08-17 18:08:32 | [trpo_pendulum] epoch #364 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -634.612
Evaluation/AverageReturn              -1426.16
Evaluation/Iteration                    364
Evaluation/MaxReturn                  -1198.85
Evaluation/MinReturn                  -1559.5
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    160.423
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.462
GaussianMLPPolicy/KL                      0.00936989
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              63.7066
GaussianMLPPolicy/LossBefore             66.6968
GaussianMLPPolicy/dLoss                   2.99025
GaussianMLPValueFunction/LossAfter        6.78174
GaussianMLPValueFunction/LossBefore       6.78448
GaussianMLPValueFunction/dLoss            0.00274229
TotalEnvSteps                        438000
-----------------------------------  ---------------
2022-08-17 18:08:33 | [trpo_pendulum] epoch #365 | Saving snapshot...
2022-08-17 18:08:33 | [trpo_pendulum] epoch #365 | Saved
2022-08-17 18:08:33 | [trpo_pendulum] epoch #365 | Time 228.82 s
2022-08-17 18:08:33 | [trpo_pendulum] epoch #365 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -406.652
Evaluation/AverageReturn               -875.073
Evaluation/Iteration                    365
Evaluation/MaxReturn                   -501.752
Evaluation/MinReturn                  -1057.13
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    222.255
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.47813
GaussianMLPPolicy/KL                      0.0069629
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -14.1789
GaussianMLPPolicy/LossBefore            -12.786
GaussianMLPPolicy/dLoss                   1.39285
GaussianMLPValueFunction/LossAfter        6.5318
GaussianMLPValueFunction/LossBefore       6.56648
GaussianMLPValueFunction/dLoss            0.0346785
TotalEnvSteps                        439200
-----------------------------------  --------------
2022-08-17 18:08:33 | [trpo_pendulum] epoch #366 | Saving snapshot...
2022-08-17 18:08:33 | [trpo_pendulum] epoch #366 | Saved
2022-08-17 18:08:33 | [trpo_pendulum] epoch #366 | Time 229.44 s
2022-08-17 18:08:33 | [trpo_pendulum] epoch #366 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -386.896
Evaluation/AverageReturn               -898.636
Evaluation/Iteration                    366
Evaluation/MaxReturn                   -489.315
Evaluation/MinReturn                  -1185.24
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    250.581
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.47735
GaussianMLPPolicy/KL                      0.00789022
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -7.81888
GaussianMLPPolicy/LossBefore             -6.85787
GaussianMLPPolicy/dLoss                   0.961009
GaussianMLPValueFunction/LossAfter        6.45084
GaussianMLPValueFunction/LossBefore       6.4837
GaussianMLPValueFunction/dLoss            0.0328541
TotalEnvSteps                        440400
-----------------------------------  ---------------
2022-08-17 18:08:34 | [trpo_pendulum] epoch #367 | Saving snapshot...
2022-08-17 18:08:34 | [trpo_pendulum] epoch #367 | Saved
2022-08-17 18:08:34 | [trpo_pendulum] epoch #367 | Time 230.05 s
2022-08-17 18:08:34 | [trpo_pendulum] epoch #367 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -464.112
Evaluation/AverageReturn              -1061.27
Evaluation/Iteration                    367
Evaluation/MaxReturn                   -752.408
Evaluation/MinReturn                  -1253.09
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    218.681
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.48065
GaussianMLPPolicy/KL                      0.00836544
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              14.3997
GaussianMLPPolicy/LossBefore             16.955
GaussianMLPPolicy/dLoss                   2.55525
GaussianMLPValueFunction/LossAfter        6.48679
GaussianMLPValueFunction/LossBefore       6.49933
GaussianMLPValueFunction/dLoss            0.0125318
TotalEnvSteps                        441600
-----------------------------------  ---------------
2022-08-17 18:08:34 | [trpo_pendulum] epoch #368 | Saving snapshot...
2022-08-17 18:08:34 | [trpo_pendulum] epoch #368 | Saved
2022-08-17 18:08:34 | [trpo_pendulum] epoch #368 | Time 230.67 s
2022-08-17 18:08:34 | [trpo_pendulum] epoch #368 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -410.775
Evaluation/AverageReturn               -959.185
Evaluation/Iteration                    368
Evaluation/MaxReturn                   -640.733
Evaluation/MinReturn                  -1091.62
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    145.975
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.48673
GaussianMLPPolicy/KL                      0.00639746
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               1.80911
GaussianMLPPolicy/LossBefore              2.58686
GaussianMLPPolicy/dLoss                   0.777749
GaussianMLPValueFunction/LossAfter        6.31302
GaussianMLPValueFunction/LossBefore       6.34762
GaussianMLPValueFunction/dLoss            0.0346069
TotalEnvSteps                        442800
-----------------------------------  ---------------
2022-08-17 18:08:35 | [trpo_pendulum] epoch #369 | Saving snapshot...
2022-08-17 18:08:35 | [trpo_pendulum] epoch #369 | Saved
2022-08-17 18:08:35 | [trpo_pendulum] epoch #369 | Time 231.31 s
2022-08-17 18:08:35 | [trpo_pendulum] epoch #369 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -381.842
Evaluation/AverageReturn               -777.134
Evaluation/Iteration                    369
Evaluation/MaxReturn                   -358.547
Evaluation/MinReturn                  -1004.37
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    292.097
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.47037
GaussianMLPPolicy/KL                      0.00955586
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -31.8941
GaussianMLPPolicy/LossBefore            -30.3885
GaussianMLPPolicy/dLoss                   1.50562
GaussianMLPValueFunction/LossAfter        6.5862
GaussianMLPValueFunction/LossBefore       6.59338
GaussianMLPValueFunction/dLoss            0.00717783
TotalEnvSteps                        444000
-----------------------------------  ---------------
2022-08-17 18:08:36 | [trpo_pendulum] epoch #370 | Saving snapshot...
2022-08-17 18:08:36 | [trpo_pendulum] epoch #370 | Saved
2022-08-17 18:08:36 | [trpo_pendulum] epoch #370 | Time 231.92 s
2022-08-17 18:08:36 | [trpo_pendulum] epoch #370 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -405.292
Evaluation/AverageReturn               -911.133
Evaluation/Iteration                    370
Evaluation/MaxReturn                   -507.129
Evaluation/MinReturn                  -1150.45
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    221.95
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.48674
GaussianMLPPolicy/KL                      0.00642554
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.86403
GaussianMLPPolicy/LossBefore             -2.15846
GaussianMLPPolicy/dLoss                   1.70557
GaussianMLPValueFunction/LossAfter        6.46318
GaussianMLPValueFunction/LossBefore       6.46762
GaussianMLPValueFunction/dLoss            0.00444698
TotalEnvSteps                        445200
-----------------------------------  ---------------
2022-08-17 18:08:36 | [trpo_pendulum] epoch #371 | Saving snapshot...
2022-08-17 18:08:36 | [trpo_pendulum] epoch #371 | Saved
2022-08-17 18:08:36 | [trpo_pendulum] epoch #371 | Time 232.57 s
2022-08-17 18:08:36 | [trpo_pendulum] epoch #371 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -651.067
Evaluation/AverageReturn              -1500.73
Evaluation/Iteration                    371
Evaluation/MaxReturn                  -1494.22
Evaluation/MinReturn                  -1508.37
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.13812
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.46856
GaussianMLPPolicy/KL                      0.00506543
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              80.3982
GaussianMLPPolicy/LossBefore             80.7477
GaussianMLPPolicy/dLoss                   0.349518
GaussianMLPValueFunction/LossAfter        6.90148
GaussianMLPValueFunction/LossBefore       6.97468
GaussianMLPValueFunction/dLoss            0.0732017
TotalEnvSteps                        446400
-----------------------------------  ---------------
2022-08-17 18:08:37 | [trpo_pendulum] epoch #372 | Saving snapshot...
2022-08-17 18:08:37 | [trpo_pendulum] epoch #372 | Saved
2022-08-17 18:08:37 | [trpo_pendulum] epoch #372 | Time 233.19 s
2022-08-17 18:08:37 | [trpo_pendulum] epoch #372 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -652.179
Evaluation/AverageReturn              -1511.73
Evaluation/Iteration                    372
Evaluation/MaxReturn                  -1497.78
Evaluation/MinReturn                  -1532.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.5175
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42799
GaussianMLPPolicy/KL                      0.00934908
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              81.1588
GaussianMLPPolicy/LossBefore             82.1526
GaussianMLPPolicy/dLoss                   0.993759
GaussianMLPValueFunction/LossAfter        6.89741
GaussianMLPValueFunction/LossBefore       6.93736
GaussianMLPValueFunction/dLoss            0.0399494
TotalEnvSteps                        447600
-----------------------------------  ---------------
2022-08-17 18:08:38 | [trpo_pendulum] epoch #373 | Saving snapshot...
2022-08-17 18:08:38 | [trpo_pendulum] epoch #373 | Saved
2022-08-17 18:08:38 | [trpo_pendulum] epoch #373 | Time 233.81 s
2022-08-17 18:08:38 | [trpo_pendulum] epoch #373 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -531.24
Evaluation/AverageReturn              -1267.24
Evaluation/Iteration                    373
Evaluation/MaxReturn                  -1198.82
Evaluation/MinReturn                  -1323.12
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     42.2234
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42245
GaussianMLPPolicy/KL                      0.00730137
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              49.0585
GaussianMLPPolicy/LossBefore             50.4666
GaussianMLPPolicy/dLoss                   1.40809
GaussianMLPValueFunction/LossAfter        6.58888
GaussianMLPValueFunction/LossBefore       6.59336
GaussianMLPValueFunction/dLoss            0.00447989
TotalEnvSteps                        448800
-----------------------------------  ---------------
2022-08-17 18:08:38 | [trpo_pendulum] epoch #374 | Saving snapshot...
2022-08-17 18:08:38 | [trpo_pendulum] epoch #374 | Saved
2022-08-17 18:08:38 | [trpo_pendulum] epoch #374 | Time 234.47 s
2022-08-17 18:08:38 | [trpo_pendulum] epoch #374 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -529.893
Evaluation/AverageReturn              -1300.68
Evaluation/Iteration                    374
Evaluation/MaxReturn                  -1273.15
Evaluation/MinReturn                  -1317.19
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     17.1654
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.43839
GaussianMLPPolicy/KL                      0.006105
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              54.2519
GaussianMLPPolicy/LossBefore             55.1166
GaussianMLPPolicy/dLoss                   0.864708
GaussianMLPValueFunction/LossAfter        6.61866
GaussianMLPValueFunction/LossBefore       6.62278
GaussianMLPValueFunction/dLoss            0.00411844
TotalEnvSteps                        450000
-----------------------------------  ---------------
2022-08-17 18:08:39 | [trpo_pendulum] epoch #375 | Saving snapshot...
2022-08-17 18:08:39 | [trpo_pendulum] epoch #375 | Saved
2022-08-17 18:08:39 | [trpo_pendulum] epoch #375 | Time 235.10 s
2022-08-17 18:08:39 | [trpo_pendulum] epoch #375 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -647.282
Evaluation/AverageReturn              -1499.2
Evaluation/Iteration                    375
Evaluation/MaxReturn                  -1495.25
Evaluation/MinReturn                  -1504.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      3.0141
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.48396
GaussianMLPPolicy/KL                      0.00884056
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              75.8249
GaussianMLPPolicy/LossBefore             78.1905
GaussianMLPPolicy/dLoss                   2.36562
GaussianMLPValueFunction/LossAfter        6.84692
GaussianMLPValueFunction/LossBefore       6.86935
GaussianMLPValueFunction/dLoss            0.0224247
TotalEnvSteps                        451200
-----------------------------------  ---------------
2022-08-17 18:08:39 | [trpo_pendulum] epoch #376 | Saving snapshot...
2022-08-17 18:08:39 | [trpo_pendulum] epoch #376 | Saved
2022-08-17 18:08:39 | [trpo_pendulum] epoch #376 | Time 235.72 s
2022-08-17 18:08:39 | [trpo_pendulum] epoch #376 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -290.972
Evaluation/AverageReturn               -807.221
Evaluation/Iteration                    376
Evaluation/MaxReturn                   -386.615
Evaluation/MinReturn                  -1178.85
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    310.112
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.47702
GaussianMLPPolicy/KL                      0.00650574
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -11.0635
GaussianMLPPolicy/LossBefore             -9.58611
GaussianMLPPolicy/dLoss                   1.47742
GaussianMLPValueFunction/LossAfter        6.5416
GaussianMLPValueFunction/LossBefore       6.55046
GaussianMLPValueFunction/dLoss            0.00886154
TotalEnvSteps                        452400
-----------------------------------  ---------------
2022-08-17 18:08:40 | [trpo_pendulum] epoch #377 | Saving snapshot...
2022-08-17 18:08:40 | [trpo_pendulum] epoch #377 | Saved
2022-08-17 18:08:40 | [trpo_pendulum] epoch #377 | Time 236.35 s
2022-08-17 18:08:40 | [trpo_pendulum] epoch #377 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -494.018
Evaluation/AverageReturn              -1151.33
Evaluation/Iteration                    377
Evaluation/MaxReturn                  -1131.54
Evaluation/MinReturn                  -1163.82
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.087
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.46354
GaussianMLPPolicy/KL                      0.00881613
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              27.6505
GaussianMLPPolicy/LossBefore             28.5716
GaussianMLPPolicy/dLoss                   0.921078
GaussianMLPValueFunction/LossAfter        6.41027
GaussianMLPValueFunction/LossBefore       6.43405
GaussianMLPValueFunction/dLoss            0.0237713
TotalEnvSteps                        453600
-----------------------------------  ---------------
2022-08-17 18:08:41 | [trpo_pendulum] epoch #378 | Saving snapshot...
2022-08-17 18:08:41 | [trpo_pendulum] epoch #378 | Saved
2022-08-17 18:08:41 | [trpo_pendulum] epoch #378 | Time 237.00 s
2022-08-17 18:08:41 | [trpo_pendulum] epoch #378 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -464.361
Evaluation/AverageReturn              -1098.6
Evaluation/Iteration                    378
Evaluation/MaxReturn                   -651.253
Evaluation/MinReturn                  -1240.92
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    201.769
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.47596
GaussianMLPPolicy/KL                      0.0087661
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              22.417
GaussianMLPPolicy/LossBefore             24.8257
GaussianMLPPolicy/dLoss                   2.4087
GaussianMLPValueFunction/LossAfter        6.55127
GaussianMLPValueFunction/LossBefore       6.55303
GaussianMLPValueFunction/dLoss            0.00176287
TotalEnvSteps                        454800
-----------------------------------  ---------------
2022-08-17 18:08:41 | [trpo_pendulum] epoch #379 | Saving snapshot...
2022-08-17 18:08:41 | [trpo_pendulum] epoch #379 | Saved
2022-08-17 18:08:41 | [trpo_pendulum] epoch #379 | Time 237.66 s
2022-08-17 18:08:41 | [trpo_pendulum] epoch #379 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -548.321
Evaluation/AverageReturn              -1307.04
Evaluation/Iteration                    379
Evaluation/MaxReturn                  -1164.28
Evaluation/MinReturn                  -1364.76
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     67.0298
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.48686
GaussianMLPPolicy/KL                      0.00858087
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              50.5773
GaussianMLPPolicy/LossBefore             52.1196
GaussianMLPPolicy/dLoss                   1.54225
GaussianMLPValueFunction/LossAfter        6.62736
GaussianMLPValueFunction/LossBefore       6.63194
GaussianMLPValueFunction/dLoss            0.00457621
TotalEnvSteps                        456000
-----------------------------------  ---------------
2022-08-17 18:08:42 | [trpo_pendulum] epoch #380 | Saving snapshot...
2022-08-17 18:08:42 | [trpo_pendulum] epoch #380 | Saved
2022-08-17 18:08:42 | [trpo_pendulum] epoch #380 | Time 238.30 s
2022-08-17 18:08:42 | [trpo_pendulum] epoch #380 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -655.962
Evaluation/AverageReturn              -1502.97
Evaluation/Iteration                    380
Evaluation/MaxReturn                  -1500.57
Evaluation/MinReturn                  -1507.17
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      2.33533
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.47779
GaussianMLPPolicy/KL                      0.00581812
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              74.3781
GaussianMLPPolicy/LossBefore             75.2197
GaussianMLPPolicy/dLoss                   0.84156
GaussianMLPValueFunction/LossAfter        6.83164
GaussianMLPValueFunction/LossBefore       6.86453
GaussianMLPValueFunction/dLoss            0.0328951
TotalEnvSteps                        457200
-----------------------------------  ---------------
2022-08-17 18:08:43 | [trpo_pendulum] epoch #381 | Saving snapshot...
2022-08-17 18:08:43 | [trpo_pendulum] epoch #381 | Saved
2022-08-17 18:08:43 | [trpo_pendulum] epoch #381 | Time 238.93 s
2022-08-17 18:08:43 | [trpo_pendulum] epoch #381 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -512.748
Evaluation/AverageReturn              -1176.56
Evaluation/Iteration                    381
Evaluation/MaxReturn                  -1007.77
Evaluation/MinReturn                  -1278.71
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     93.9323
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.47632
GaussianMLPPolicy/KL                      0.00998127
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              24.492
GaussianMLPPolicy/LossBefore             28.4625
GaussianMLPPolicy/dLoss                   3.97047
GaussianMLPValueFunction/LossAfter        6.46887
GaussianMLPValueFunction/LossBefore       6.48296
GaussianMLPValueFunction/dLoss            0.0140929
TotalEnvSteps                        458400
-----------------------------------  ---------------
2022-08-17 18:08:43 | [trpo_pendulum] epoch #382 | Saving snapshot...
2022-08-17 18:08:43 | [trpo_pendulum] epoch #382 | Saved
2022-08-17 18:08:43 | [trpo_pendulum] epoch #382 | Time 239.56 s
2022-08-17 18:08:43 | [trpo_pendulum] epoch #382 | EpochTime 0.62 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -473.683
Evaluation/AverageReturn              -1076.95
Evaluation/Iteration                    382
Evaluation/MaxReturn                   -245.906
Evaluation/MinReturn                  -1428.21
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    384.632
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.46453
GaussianMLPPolicy/KL                      0.00965521
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              10.3452
GaussianMLPPolicy/LossBefore             12.9236
GaussianMLPPolicy/dLoss                   2.57842
GaussianMLPValueFunction/LossAfter        6.64939
GaussianMLPValueFunction/LossBefore       6.64968
GaussianMLPValueFunction/dLoss            0.000285625
TotalEnvSteps                        459600
-----------------------------------  ----------------
2022-08-17 18:08:44 | [trpo_pendulum] epoch #383 | Saving snapshot...
2022-08-17 18:08:44 | [trpo_pendulum] epoch #383 | Saved
2022-08-17 18:08:44 | [trpo_pendulum] epoch #383 | Time 240.20 s
2022-08-17 18:08:44 | [trpo_pendulum] epoch #383 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -427.54
Evaluation/AverageReturn               -902.777
Evaluation/Iteration                    383
Evaluation/MaxReturn                   -246.214
Evaluation/MinReturn                  -1183.29
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    330.366
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.46485
GaussianMLPPolicy/KL                      0.00645402
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -15.5122
GaussianMLPPolicy/LossBefore            -13.6552
GaussianMLPPolicy/dLoss                   1.85703
GaussianMLPValueFunction/LossAfter        6.68279
GaussianMLPValueFunction/LossBefore       6.68677
GaussianMLPValueFunction/dLoss            0.00397873
TotalEnvSteps                        460800
-----------------------------------  ---------------
2022-08-17 18:08:45 | [trpo_pendulum] epoch #384 | Saving snapshot...
2022-08-17 18:08:45 | [trpo_pendulum] epoch #384 | Saved
2022-08-17 18:08:45 | [trpo_pendulum] epoch #384 | Time 240.85 s
2022-08-17 18:08:45 | [trpo_pendulum] epoch #384 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -660.071
Evaluation/AverageReturn              -1508.97
Evaluation/Iteration                    384
Evaluation/MaxReturn                  -1506.59
Evaluation/MinReturn                  -1513.88
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      2.5649
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.47304
GaussianMLPPolicy/KL                      0.00634072
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              73.5805
GaussianMLPPolicy/LossBefore             74.9321
GaussianMLPPolicy/dLoss                   1.3516
GaussianMLPValueFunction/LossAfter        6.81741
GaussianMLPValueFunction/LossBefore       6.84048
GaussianMLPValueFunction/dLoss            0.0230746
TotalEnvSteps                        462000
-----------------------------------  ---------------
2022-08-17 18:08:45 | [trpo_pendulum] epoch #385 | Saving snapshot...
2022-08-17 18:08:45 | [trpo_pendulum] epoch #385 | Saved
2022-08-17 18:08:45 | [trpo_pendulum] epoch #385 | Time 241.47 s
2022-08-17 18:08:45 | [trpo_pendulum] epoch #385 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -528.534
Evaluation/AverageReturn              -1278.94
Evaluation/Iteration                    385
Evaluation/MaxReturn                  -1065.7
Evaluation/MinReturn                  -1434.37
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    110.267
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.48905
GaussianMLPPolicy/KL                      0.00894895
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              43.0206
GaussianMLPPolicy/LossBefore             45.0741
GaussianMLPPolicy/dLoss                   2.05355
GaussianMLPValueFunction/LossAfter        6.55586
GaussianMLPValueFunction/LossBefore       6.56578
GaussianMLPValueFunction/dLoss            0.00991201
TotalEnvSteps                        463200
-----------------------------------  ---------------
2022-08-17 18:08:46 | [trpo_pendulum] epoch #386 | Saving snapshot...
2022-08-17 18:08:46 | [trpo_pendulum] epoch #386 | Saved
2022-08-17 18:08:46 | [trpo_pendulum] epoch #386 | Time 242.11 s
2022-08-17 18:08:46 | [trpo_pendulum] epoch #386 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -543.324
Evaluation/AverageReturn              -1375.28
Evaluation/Iteration                    386
Evaluation/MaxReturn                  -1045.25
Evaluation/MinReturn                  -1501.14
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    168.09
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.51544
GaussianMLPPolicy/KL                      0.00853948
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              61.8462
GaussianMLPPolicy/LossBefore             63.4806
GaussianMLPPolicy/dLoss                   1.6344
GaussianMLPValueFunction/LossAfter        6.73432
GaussianMLPValueFunction/LossBefore       6.74301
GaussianMLPValueFunction/dLoss            0.00869703
TotalEnvSteps                        464400
-----------------------------------  ---------------
2022-08-17 18:08:46 | [trpo_pendulum] epoch #387 | Saving snapshot...
2022-08-17 18:08:46 | [trpo_pendulum] epoch #387 | Saved
2022-08-17 18:08:46 | [trpo_pendulum] epoch #387 | Time 242.74 s
2022-08-17 18:08:46 | [trpo_pendulum] epoch #387 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -498.359
Evaluation/AverageReturn              -1146
Evaluation/Iteration                    387
Evaluation/MaxReturn                   -121.764
Evaluation/MinReturn                  -1391.9
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    459.248
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.5207
GaussianMLPPolicy/KL                      0.00653151
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              21.2214
GaussianMLPPolicy/LossBefore             22.79
GaussianMLPPolicy/dLoss                   1.5686
GaussianMLPValueFunction/LossAfter        6.77618
GaussianMLPValueFunction/LossBefore       6.78131
GaussianMLPValueFunction/dLoss            0.00513268
TotalEnvSteps                        465600
-----------------------------------  ---------------
2022-08-17 18:08:47 | [trpo_pendulum] epoch #388 | Saving snapshot...
2022-08-17 18:08:47 | [trpo_pendulum] epoch #388 | Saved
2022-08-17 18:08:47 | [trpo_pendulum] epoch #388 | Time 243.37 s
2022-08-17 18:08:47 | [trpo_pendulum] epoch #388 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -574.478
Evaluation/AverageReturn              -1344.83
Evaluation/Iteration                    388
Evaluation/MaxReturn                  -1322.41
Evaluation/MinReturn                  -1381.05
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     20.6991
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.55528
GaussianMLPPolicy/KL                      0.0084868
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              51.2758
GaussianMLPPolicy/LossBefore             52.674
GaussianMLPPolicy/dLoss                   1.39825
GaussianMLPValueFunction/LossAfter        6.64545
GaussianMLPValueFunction/LossBefore       6.64989
GaussianMLPValueFunction/dLoss            0.00443172
TotalEnvSteps                        466800
-----------------------------------  ---------------
2022-08-17 18:08:48 | [trpo_pendulum] epoch #389 | Saving snapshot...
2022-08-17 18:08:48 | [trpo_pendulum] epoch #389 | Saved
2022-08-17 18:08:48 | [trpo_pendulum] epoch #389 | Time 244.00 s
2022-08-17 18:08:48 | [trpo_pendulum] epoch #389 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -642.693
Evaluation/AverageReturn              -1548.29
Evaluation/Iteration                    389
Evaluation/MaxReturn                  -1531.7
Evaluation/MinReturn                  -1592.16
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     21.2398
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.55888
GaussianMLPPolicy/KL                      0.00754547
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              84.0909
GaussianMLPPolicy/LossBefore             85.6544
GaussianMLPPolicy/dLoss                   1.5635
GaussianMLPValueFunction/LossAfter        6.94374
GaussianMLPValueFunction/LossBefore       6.98656
GaussianMLPValueFunction/dLoss            0.0428257
TotalEnvSteps                        468000
-----------------------------------  ---------------
2022-08-17 18:08:48 | [trpo_pendulum] epoch #390 | Saving snapshot...
2022-08-17 18:08:48 | [trpo_pendulum] epoch #390 | Saved
2022-08-17 18:08:48 | [trpo_pendulum] epoch #390 | Time 244.64 s
2022-08-17 18:08:48 | [trpo_pendulum] epoch #390 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -535.714
Evaluation/AverageReturn              -1220.97
Evaluation/Iteration                    390
Evaluation/MaxReturn                   -392.084
Evaluation/MinReturn                  -1488.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    377.955
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.57573
GaussianMLPPolicy/KL                      0.00978412
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              25.209
GaussianMLPPolicy/LossBefore             28.6609
GaussianMLPPolicy/dLoss                   3.45197
GaussianMLPValueFunction/LossAfter        6.72943
GaussianMLPValueFunction/LossBefore       6.73028
GaussianMLPValueFunction/dLoss            0.00085783
TotalEnvSteps                        469200
-----------------------------------  ---------------
2022-08-17 18:08:49 | [trpo_pendulum] epoch #391 | Saving snapshot...
2022-08-17 18:08:49 | [trpo_pendulum] epoch #391 | Saved
2022-08-17 18:08:49 | [trpo_pendulum] epoch #391 | Time 245.27 s
2022-08-17 18:08:49 | [trpo_pendulum] epoch #391 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -685.727
Evaluation/AverageReturn              -1549.14
Evaluation/Iteration                    391
Evaluation/MaxReturn                  -1502.07
Evaluation/MinReturn                  -1588.37
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     30.7945
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.57673
GaussianMLPPolicy/KL                      0.00663599
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              72.4653
GaussianMLPPolicy/LossBefore             74.6348
GaussianMLPPolicy/dLoss                   2.16944
GaussianMLPValueFunction/LossAfter        6.8148
GaussianMLPValueFunction/LossBefore       6.82132
GaussianMLPValueFunction/dLoss            0.00652122
TotalEnvSteps                        470400
-----------------------------------  ---------------
2022-08-17 18:08:50 | [trpo_pendulum] epoch #392 | Saving snapshot...
2022-08-17 18:08:50 | [trpo_pendulum] epoch #392 | Saved
2022-08-17 18:08:50 | [trpo_pendulum] epoch #392 | Time 245.90 s
2022-08-17 18:08:50 | [trpo_pendulum] epoch #392 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -609.59
Evaluation/AverageReturn              -1492.92
Evaluation/Iteration                    392
Evaluation/MaxReturn                  -1482.92
Evaluation/MinReturn                  -1505.27
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      7.58263
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.60034
GaussianMLPPolicy/KL                      0.00619666
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              73.5795
GaussianMLPPolicy/LossBefore             75.5499
GaussianMLPPolicy/dLoss                   1.97038
GaussianMLPValueFunction/LossAfter        6.84001
GaussianMLPValueFunction/LossBefore       6.84751
GaussianMLPValueFunction/dLoss            0.00749826
TotalEnvSteps                        471600
-----------------------------------  ---------------
2022-08-17 18:08:50 | [trpo_pendulum] epoch #393 | Saving snapshot...
2022-08-17 18:08:50 | [trpo_pendulum] epoch #393 | Saved
2022-08-17 18:08:50 | [trpo_pendulum] epoch #393 | Time 246.53 s
2022-08-17 18:08:50 | [trpo_pendulum] epoch #393 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -553.659
Evaluation/AverageReturn              -1291.84
Evaluation/Iteration                    393
Evaluation/MaxReturn                  -1215.44
Evaluation/MinReturn                  -1351.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     39.7439
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.59724
GaussianMLPPolicy/KL                      0.00868728
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              40.0993
GaussianMLPPolicy/LossBefore             40.7753
GaussianMLPPolicy/dLoss                   0.676025
GaussianMLPValueFunction/LossAfter        6.55434
GaussianMLPValueFunction/LossBefore       6.58122
GaussianMLPValueFunction/dLoss            0.0268874
TotalEnvSteps                        472800
-----------------------------------  ---------------
2022-08-17 18:08:51 | [trpo_pendulum] epoch #394 | Saving snapshot...
2022-08-17 18:08:51 | [trpo_pendulum] epoch #394 | Saved
2022-08-17 18:08:51 | [trpo_pendulum] epoch #394 | Time 247.19 s
2022-08-17 18:08:51 | [trpo_pendulum] epoch #394 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -3.5977
Evaluation/AverageReturn                 -6.57439
Evaluation/Iteration                    394
Evaluation/MaxReturn                     -5.79532
Evaluation/MinReturn                     -7.45557
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      0.608445
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62219
GaussianMLPPolicy/KL                      0.00645888
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -143.274
GaussianMLPPolicy/LossBefore           -141.166
GaussianMLPPolicy/dLoss                   2.10825
GaussianMLPValueFunction/LossAfter        7.29179
GaussianMLPValueFunction/LossBefore       7.44763
GaussianMLPValueFunction/dLoss            0.155841
TotalEnvSteps                        474000
-----------------------------------  ---------------
2022-08-17 18:08:52 | [trpo_pendulum] epoch #395 | Saving snapshot...
2022-08-17 18:08:52 | [trpo_pendulum] epoch #395 | Saved
2022-08-17 18:08:52 | [trpo_pendulum] epoch #395 | Time 247.81 s
2022-08-17 18:08:52 | [trpo_pendulum] epoch #395 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -414.922
Evaluation/AverageReturn               -981.177
Evaluation/Iteration                    395
Evaluation/MaxReturn                   -132.88
Evaluation/MinReturn                  -1437.25
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    600.016
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.63294
GaussianMLPPolicy/KL                      0.00692541
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.35927
GaussianMLPPolicy/LossBefore             -1.43207
GaussianMLPPolicy/dLoss                   1.9272
GaussianMLPValueFunction/LossAfter        6.91734
GaussianMLPValueFunction/LossBefore       6.91953
GaussianMLPValueFunction/dLoss            0.00219011
TotalEnvSteps                        475200
-----------------------------------  ---------------
2022-08-17 18:08:52 | [trpo_pendulum] epoch #396 | Saving snapshot...
2022-08-17 18:08:52 | [trpo_pendulum] epoch #396 | Saved
2022-08-17 18:08:52 | [trpo_pendulum] epoch #396 | Time 248.46 s
2022-08-17 18:08:52 | [trpo_pendulum] epoch #396 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -430.25
Evaluation/AverageReturn               -982.697
Evaluation/Iteration                    396
Evaluation/MaxReturn                   -257.381
Evaluation/MinReturn                  -1184.67
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    328.504
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.61772
GaussianMLPPolicy/KL                      0.0064091
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -4.59801
GaussianMLPPolicy/LossBefore             -2.75315
GaussianMLPPolicy/dLoss                   1.84486
GaussianMLPValueFunction/LossAfter        6.64665
GaussianMLPValueFunction/LossBefore       6.66027
GaussianMLPValueFunction/dLoss            0.0136247
TotalEnvSteps                        476400
-----------------------------------  --------------
2022-08-17 18:08:53 | [trpo_pendulum] epoch #397 | Saving snapshot...
2022-08-17 18:08:53 | [trpo_pendulum] epoch #397 | Saved
2022-08-17 18:08:53 | [trpo_pendulum] epoch #397 | Time 249.09 s
2022-08-17 18:08:53 | [trpo_pendulum] epoch #397 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -532.46
Evaluation/AverageReturn              -1273.31
Evaluation/Iteration                    397
Evaluation/MaxReturn                  -1077.2
Evaluation/MinReturn                  -1461.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    142.176
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.60711
GaussianMLPPolicy/KL                      0.00779411
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              40.1903
GaussianMLPPolicy/LossBefore             42.1551
GaussianMLPPolicy/dLoss                   1.96481
GaussianMLPValueFunction/LossAfter        6.62508
GaussianMLPValueFunction/LossBefore       6.63842
GaussianMLPValueFunction/dLoss            0.0133467
TotalEnvSteps                        477600
-----------------------------------  ---------------
2022-08-17 18:08:53 | [trpo_pendulum] epoch #398 | Saving snapshot...
2022-08-17 18:08:53 | [trpo_pendulum] epoch #398 | Saved
2022-08-17 18:08:53 | [trpo_pendulum] epoch #398 | Time 249.73 s
2022-08-17 18:08:53 | [trpo_pendulum] epoch #398 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -487.769
Evaluation/AverageReturn              -1085.05
Evaluation/Iteration                    398
Evaluation/MaxReturn                   -375.602
Evaluation/MinReturn                  -1324.37
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    324.902
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.60562
GaussianMLPPolicy/KL                      0.00747698
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               5.04066
GaussianMLPPolicy/LossBefore              8.18213
GaussianMLPPolicy/dLoss                   3.14148
GaussianMLPValueFunction/LossAfter        6.64921
GaussianMLPValueFunction/LossBefore       6.65592
GaussianMLPValueFunction/dLoss            0.00671196
TotalEnvSteps                        478800
-----------------------------------  ---------------
2022-08-17 18:08:54 | [trpo_pendulum] epoch #399 | Saving snapshot...
2022-08-17 18:08:54 | [trpo_pendulum] epoch #399 | Saved
2022-08-17 18:08:54 | [trpo_pendulum] epoch #399 | Time 250.34 s
2022-08-17 18:08:54 | [trpo_pendulum] epoch #399 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -605.276
Evaluation/AverageReturn              -1464.89
Evaluation/Iteration                    399
Evaluation/MaxReturn                  -1419.91
Evaluation/MinReturn                  -1479.26
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     21.132
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.57576
GaussianMLPPolicy/KL                      0.00689302
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              70.8053
GaussianMLPPolicy/LossBefore             71.3679
GaussianMLPPolicy/dLoss                   0.562569
GaussianMLPValueFunction/LossAfter        6.77448
GaussianMLPValueFunction/LossBefore       6.77877
GaussianMLPValueFunction/dLoss            0.00428677
TotalEnvSteps                        480000
-----------------------------------  ---------------
2022-08-17 18:08:55 | [trpo_pendulum] epoch #400 | Saving snapshot...
2022-08-17 18:08:55 | [trpo_pendulum] epoch #400 | Saved
2022-08-17 18:08:55 | [trpo_pendulum] epoch #400 | Time 250.96 s
2022-08-17 18:08:55 | [trpo_pendulum] epoch #400 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -666.307
Evaluation/AverageReturn              -1516.15
Evaluation/Iteration                    400
Evaluation/MaxReturn                  -1508.53
Evaluation/MinReturn                  -1537.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.6958
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.58937
GaussianMLPPolicy/KL                      0.00692352
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              68.9053
GaussianMLPPolicy/LossBefore             70.2241
GaussianMLPPolicy/dLoss                   1.31872
GaussianMLPValueFunction/LossAfter        6.78379
GaussianMLPValueFunction/LossBefore       6.78793
GaussianMLPValueFunction/dLoss            0.00414133
TotalEnvSteps                        481200
-----------------------------------  ---------------
2022-08-17 18:08:55 | [trpo_pendulum] epoch #401 | Saving snapshot...
2022-08-17 18:08:55 | [trpo_pendulum] epoch #401 | Saved
2022-08-17 18:08:55 | [trpo_pendulum] epoch #401 | Time 251.58 s
2022-08-17 18:08:55 | [trpo_pendulum] epoch #401 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -668.375
Evaluation/AverageReturn              -1517.69
Evaluation/Iteration                    401
Evaluation/MaxReturn                  -1507.31
Evaluation/MinReturn                  -1524.16
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.92516
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.60135
GaussianMLPPolicy/KL                      0.00921809
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              67.7892
GaussianMLPPolicy/LossBefore             69.207
GaussianMLPPolicy/dLoss                   1.41779
GaussianMLPValueFunction/LossAfter        6.77231
GaussianMLPValueFunction/LossBefore       6.77608
GaussianMLPValueFunction/dLoss            0.00377035
TotalEnvSteps                        482400
-----------------------------------  ---------------
2022-08-17 18:08:56 | [trpo_pendulum] epoch #402 | Saving snapshot...
2022-08-17 18:08:56 | [trpo_pendulum] epoch #402 | Saved
2022-08-17 18:08:56 | [trpo_pendulum] epoch #402 | Time 252.22 s
2022-08-17 18:08:56 | [trpo_pendulum] epoch #402 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -543.923
Evaluation/AverageReturn              -1319.57
Evaluation/Iteration                    402
Evaluation/MaxReturn                  -1208.35
Evaluation/MinReturn                  -1379.81
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     54.0817
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.59377
GaussianMLPPolicy/KL                      0.00625282
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              46.1654
GaussianMLPPolicy/LossBefore             47.5956
GaussianMLPPolicy/dLoss                   1.4302
GaussianMLPValueFunction/LossAfter        6.62301
GaussianMLPValueFunction/LossBefore       6.63351
GaussianMLPValueFunction/dLoss            0.010498
TotalEnvSteps                        483600
-----------------------------------  ---------------
2022-08-17 18:08:57 | [trpo_pendulum] epoch #403 | Saving snapshot...
2022-08-17 18:08:57 | [trpo_pendulum] epoch #403 | Saved
2022-08-17 18:08:57 | [trpo_pendulum] epoch #403 | Time 252.86 s
2022-08-17 18:08:57 | [trpo_pendulum] epoch #403 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -551.012
Evaluation/AverageReturn              -1315.38
Evaluation/Iteration                    403
Evaluation/MaxReturn                  -1304.16
Evaluation/MinReturn                  -1339.18
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     11.7766
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.596
GaussianMLPPolicy/KL                      0.00824501
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              43.7716
GaussianMLPPolicy/LossBefore             45.1007
GaussianMLPPolicy/dLoss                   1.32907
GaussianMLPValueFunction/LossAfter        6.5886
GaussianMLPValueFunction/LossBefore       6.59949
GaussianMLPValueFunction/dLoss            0.0108857
TotalEnvSteps                        484800
-----------------------------------  ---------------
2022-08-17 18:08:57 | [trpo_pendulum] epoch #404 | Saving snapshot...
2022-08-17 18:08:57 | [trpo_pendulum] epoch #404 | Saved
2022-08-17 18:08:57 | [trpo_pendulum] epoch #404 | Time 253.50 s
2022-08-17 18:08:57 | [trpo_pendulum] epoch #404 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -105.836
Evaluation/AverageReturn               -220.906
Evaluation/Iteration                    404
Evaluation/MaxReturn                    -12.1777
Evaluation/MinReturn                   -653.614
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    229.398
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.59892
GaussianMLPPolicy/KL                      0.00713409
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -115.018
GaussianMLPPolicy/LossBefore           -113.515
GaussianMLPPolicy/dLoss                   1.50299
GaussianMLPValueFunction/LossAfter        7.118
GaussianMLPValueFunction/LossBefore       7.2165
GaussianMLPValueFunction/dLoss            0.0985041
TotalEnvSteps                        486000
-----------------------------------  ---------------
2022-08-17 18:08:58 | [trpo_pendulum] epoch #405 | Saving snapshot...
2022-08-17 18:08:58 | [trpo_pendulum] epoch #405 | Saved
2022-08-17 18:08:58 | [trpo_pendulum] epoch #405 | Time 254.12 s
2022-08-17 18:08:58 | [trpo_pendulum] epoch #405 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -445.316
Evaluation/AverageReturn               -997.23
Evaluation/Iteration                    405
Evaluation/MaxReturn                   -246.726
Evaluation/MinReturn                  -1303.23
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    383.808
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.60504
GaussianMLPPolicy/KL                      0.00910687
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -5.71256
GaussianMLPPolicy/LossBefore             -3.91738
GaussianMLPPolicy/dLoss                   1.79517
GaussianMLPValueFunction/LossAfter        6.70219
GaussianMLPValueFunction/LossBefore       6.70499
GaussianMLPValueFunction/dLoss            0.00280809
TotalEnvSteps                        487200
-----------------------------------  ---------------
2022-08-17 18:08:58 | [trpo_pendulum] epoch #406 | Saving snapshot...
2022-08-17 18:08:58 | [trpo_pendulum] epoch #406 | Saved
2022-08-17 18:08:58 | [trpo_pendulum] epoch #406 | Time 254.75 s
2022-08-17 18:08:58 | [trpo_pendulum] epoch #406 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -644.91
Evaluation/AverageReturn              -1492.79
Evaluation/Iteration                    406
Evaluation/MaxReturn                  -1492.49
Evaluation/MinReturn                  -1493.3
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      0.254276
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62284
GaussianMLPPolicy/KL                      0.00685256
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              67.9912
GaussianMLPPolicy/LossBefore             68.4061
GaussianMLPPolicy/dLoss                   0.414841
GaussianMLPValueFunction/LossAfter        6.76596
GaussianMLPValueFunction/LossBefore       6.76891
GaussianMLPValueFunction/dLoss            0.00294352
TotalEnvSteps                        488400
-----------------------------------  ---------------
2022-08-17 18:08:59 | [trpo_pendulum] epoch #407 | Saving snapshot...
2022-08-17 18:08:59 | [trpo_pendulum] epoch #407 | Saved
2022-08-17 18:08:59 | [trpo_pendulum] epoch #407 | Time 255.38 s
2022-08-17 18:08:59 | [trpo_pendulum] epoch #407 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -437.993
Evaluation/AverageReturn              -1041.54
Evaluation/Iteration                    407
Evaluation/MaxReturn                   -388.285
Evaluation/MinReturn                  -1208.01
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    293.663
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.6169
GaussianMLPPolicy/KL                      0.00713102
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               5.61081
GaussianMLPPolicy/LossBefore              6.74866
GaussianMLPPolicy/dLoss                   1.13785
GaussianMLPValueFunction/LossAfter        6.61167
GaussianMLPValueFunction/LossBefore       6.62159
GaussianMLPValueFunction/dLoss            0.00991964
TotalEnvSteps                        489600
-----------------------------------  ---------------
2022-08-17 18:09:00 | [trpo_pendulum] epoch #408 | Saving snapshot...
2022-08-17 18:09:00 | [trpo_pendulum] epoch #408 | Saved
2022-08-17 18:09:00 | [trpo_pendulum] epoch #408 | Time 256.02 s
2022-08-17 18:09:00 | [trpo_pendulum] epoch #408 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -497.485
Evaluation/AverageReturn              -1122.18
Evaluation/Iteration                    408
Evaluation/MaxReturn                   -735.05
Evaluation/MinReturn                  -1226.31
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    174.386
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.63713
GaussianMLPPolicy/KL                      0.00977274
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              10.9702
GaussianMLPPolicy/LossBefore             14.9724
GaussianMLPPolicy/dLoss                   4.00215
GaussianMLPValueFunction/LossAfter        6.53262
GaussianMLPValueFunction/LossBefore       6.54882
GaussianMLPValueFunction/dLoss            0.0161963
TotalEnvSteps                        490800
-----------------------------------  ---------------
2022-08-17 18:09:00 | [trpo_pendulum] epoch #409 | Saving snapshot...
2022-08-17 18:09:00 | [trpo_pendulum] epoch #409 | Saved
2022-08-17 18:09:00 | [trpo_pendulum] epoch #409 | Time 256.66 s
2022-08-17 18:09:00 | [trpo_pendulum] epoch #409 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -635.735
Evaluation/AverageReturn              -1490.1
Evaluation/Iteration                    409
Evaluation/MaxReturn                  -1477.35
Evaluation/MinReturn                  -1511.66
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.6465
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62932
GaussianMLPPolicy/KL                      0.00858756
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              66.5018
GaussianMLPPolicy/LossBefore             69.272
GaussianMLPPolicy/dLoss                   2.7702
GaussianMLPValueFunction/LossAfter        6.78701
GaussianMLPValueFunction/LossBefore       6.79533
GaussianMLPValueFunction/dLoss            0.00832558
TotalEnvSteps                        492000
-----------------------------------  ---------------
2022-08-17 18:09:01 | [trpo_pendulum] epoch #410 | Saving snapshot...
2022-08-17 18:09:01 | [trpo_pendulum] epoch #410 | Saved
2022-08-17 18:09:01 | [trpo_pendulum] epoch #410 | Time 257.29 s
2022-08-17 18:09:01 | [trpo_pendulum] epoch #410 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -725.65
Evaluation/AverageReturn              -1598.61
Evaluation/Iteration                    410
Evaluation/MaxReturn                  -1572.21
Evaluation/MinReturn                  -1634.6
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     21.8391
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.6361
GaussianMLPPolicy/KL                      0.00641225
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              73.8283
GaussianMLPPolicy/LossBefore             76.2218
GaussianMLPPolicy/dLoss                   2.39349
GaussianMLPValueFunction/LossAfter        6.85596
GaussianMLPValueFunction/LossBefore       6.87025
GaussianMLPValueFunction/dLoss            0.0142956
TotalEnvSteps                        493200
-----------------------------------  ---------------
2022-08-17 18:09:02 | [trpo_pendulum] epoch #411 | Saving snapshot...
2022-08-17 18:09:02 | [trpo_pendulum] epoch #411 | Saved
2022-08-17 18:09:02 | [trpo_pendulum] epoch #411 | Time 257.92 s
2022-08-17 18:09:02 | [trpo_pendulum] epoch #411 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -671.441
Evaluation/AverageReturn              -1525.82
Evaluation/Iteration                    411
Evaluation/MaxReturn                  -1506.92
Evaluation/MinReturn                  -1583.5
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     26.9622
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.64328
GaussianMLPPolicy/KL                      0.00960098
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              67.0858
GaussianMLPPolicy/LossBefore             69.0704
GaussianMLPPolicy/dLoss                   1.98454
GaussianMLPValueFunction/LossAfter        6.78331
GaussianMLPValueFunction/LossBefore       6.78764
GaussianMLPValueFunction/dLoss            0.00433588
TotalEnvSteps                        494400
-----------------------------------  ---------------
2022-08-17 18:09:02 | [trpo_pendulum] epoch #412 | Saving snapshot...
2022-08-17 18:09:02 | [trpo_pendulum] epoch #412 | Saved
2022-08-17 18:09:02 | [trpo_pendulum] epoch #412 | Time 258.56 s
2022-08-17 18:09:02 | [trpo_pendulum] epoch #412 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -4.25761
Evaluation/AverageReturn                -10.7578
Evaluation/Iteration                    412
Evaluation/MaxReturn                     -9.85373
Evaluation/MinReturn                    -11.6919
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      0.723986
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.6434
GaussianMLPPolicy/KL                      0.00544515
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -143.549
GaussianMLPPolicy/LossBefore           -142.817
GaussianMLPPolicy/dLoss                   0.732269
GaussianMLPValueFunction/LossAfter        7.29394
GaussianMLPValueFunction/LossBefore       7.43351
GaussianMLPValueFunction/dLoss            0.13957
TotalEnvSteps                        495600
-----------------------------------  ---------------
2022-08-17 18:09:03 | [trpo_pendulum] epoch #413 | Saving snapshot...
2022-08-17 18:09:03 | [trpo_pendulum] epoch #413 | Saved
2022-08-17 18:09:03 | [trpo_pendulum] epoch #413 | Time 259.19 s
2022-08-17 18:09:03 | [trpo_pendulum] epoch #413 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -644.296
Evaluation/AverageReturn              -1493.41
Evaluation/Iteration                    413
Evaluation/MaxReturn                  -1489.8
Evaluation/MinReturn                  -1502.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      4.59435
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.66397
GaussianMLPPolicy/KL                      0.00638805
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              65.5341
GaussianMLPPolicy/LossBefore             67.6126
GaussianMLPPolicy/dLoss                   2.07844
GaussianMLPValueFunction/LossAfter        6.77417
GaussianMLPValueFunction/LossBefore       6.77787
GaussianMLPValueFunction/dLoss            0.00369596
TotalEnvSteps                        496800
-----------------------------------  ---------------
2022-08-17 18:09:04 | [trpo_pendulum] epoch #414 | Saving snapshot...
2022-08-17 18:09:04 | [trpo_pendulum] epoch #414 | Saved
2022-08-17 18:09:04 | [trpo_pendulum] epoch #414 | Time 259.81 s
2022-08-17 18:09:04 | [trpo_pendulum] epoch #414 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -700.874
Evaluation/AverageReturn              -1596.26
Evaluation/Iteration                    414
Evaluation/MaxReturn                  -1544.91
Evaluation/MinReturn                  -1678.39
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     46.7144
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.6755
GaussianMLPPolicy/KL                      0.007564
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              77.9611
GaussianMLPPolicy/LossBefore             80.0964
GaussianMLPPolicy/dLoss                   2.13535
GaussianMLPValueFunction/LossAfter        6.88725
GaussianMLPValueFunction/LossBefore       6.89029
GaussianMLPValueFunction/dLoss            0.00304508
TotalEnvSteps                        498000
-----------------------------------  ---------------
2022-08-17 18:09:04 | [trpo_pendulum] epoch #415 | Saving snapshot...
2022-08-17 18:09:04 | [trpo_pendulum] epoch #415 | Saved
2022-08-17 18:09:04 | [trpo_pendulum] epoch #415 | Time 260.44 s
2022-08-17 18:09:04 | [trpo_pendulum] epoch #415 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -685.665
Evaluation/AverageReturn              -1582.45
Evaluation/Iteration                    415
Evaluation/MaxReturn                  -1492.07
Evaluation/MinReturn                  -1656.67
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     57.3948
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.65034
GaussianMLPPolicy/KL                      0.00966956
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              77.5674
GaussianMLPPolicy/LossBefore             79.5629
GaussianMLPPolicy/dLoss                   1.99556
GaussianMLPValueFunction/LossAfter        6.88896
GaussianMLPValueFunction/LossBefore       6.89208
GaussianMLPValueFunction/dLoss            0.00311804
TotalEnvSteps                        499200
-----------------------------------  ---------------
2022-08-17 18:09:05 | [trpo_pendulum] epoch #416 | Saving snapshot...
2022-08-17 18:09:05 | [trpo_pendulum] epoch #416 | Saved
2022-08-17 18:09:05 | [trpo_pendulum] epoch #416 | Time 261.17 s
2022-08-17 18:09:05 | [trpo_pendulum] epoch #416 | EpochTime 0.73 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -579.076
Evaluation/AverageReturn              -1386.29
Evaluation/Iteration                    416
Evaluation/MaxReturn                  -1137.16
Evaluation/MinReturn                  -1484.74
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    123.034
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.6611
GaussianMLPPolicy/KL                      0.00960964
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              50.1584
GaussianMLPPolicy/LossBefore             53.7194
GaussianMLPPolicy/dLoss                   3.56102
GaussianMLPValueFunction/LossAfter        6.69887
GaussianMLPValueFunction/LossBefore       6.7101
GaussianMLPValueFunction/dLoss            0.0112371
TotalEnvSteps                        500400
-----------------------------------  ---------------
2022-08-17 18:09:06 | [trpo_pendulum] epoch #417 | Saving snapshot...
2022-08-17 18:09:06 | [trpo_pendulum] epoch #417 | Saved
2022-08-17 18:09:06 | [trpo_pendulum] epoch #417 | Time 261.81 s
2022-08-17 18:09:06 | [trpo_pendulum] epoch #417 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -465.133
Evaluation/AverageReturn              -1158.87
Evaluation/Iteration                    417
Evaluation/MaxReturn                   -977.224
Evaluation/MinReturn                  -1357.25
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    146.534
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.67274
GaussianMLPPolicy/KL                      0.00885976
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              20.4768
GaussianMLPPolicy/LossBefore             23.2927
GaussianMLPPolicy/dLoss                   2.81591
GaussianMLPValueFunction/LossAfter        6.51134
GaussianMLPValueFunction/LossBefore       6.54609
GaussianMLPValueFunction/dLoss            0.0347505
TotalEnvSteps                        501600
-----------------------------------  ---------------
2022-08-17 18:09:06 | [trpo_pendulum] epoch #418 | Saving snapshot...
2022-08-17 18:09:06 | [trpo_pendulum] epoch #418 | Saved
2022-08-17 18:09:06 | [trpo_pendulum] epoch #418 | Time 262.44 s
2022-08-17 18:09:06 | [trpo_pendulum] epoch #418 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -615.618
Evaluation/AverageReturn              -1499.66
Evaluation/Iteration                    418
Evaluation/MaxReturn                  -1336.49
Evaluation/MinReturn                  -1636.66
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     93.1602
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.68838
GaussianMLPPolicy/KL                      0.00999695
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              67.9069
GaussianMLPPolicy/LossBefore             70.2311
GaussianMLPPolicy/dLoss                   2.32426
GaussianMLPValueFunction/LossAfter        6.77966
GaussianMLPValueFunction/LossBefore       6.78374
GaussianMLPValueFunction/dLoss            0.00407505
TotalEnvSteps                        502800
-----------------------------------  ---------------
2022-08-17 18:09:07 | [trpo_pendulum] epoch #419 | Saving snapshot...
2022-08-17 18:09:07 | [trpo_pendulum] epoch #419 | Saved
2022-08-17 18:09:07 | [trpo_pendulum] epoch #419 | Time 263.09 s
2022-08-17 18:09:07 | [trpo_pendulum] epoch #419 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -394.878
Evaluation/AverageReturn               -899.376
Evaluation/Iteration                    419
Evaluation/MaxReturn                   -130.082
Evaluation/MinReturn                  -1370.71
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    377.991
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.68892
GaussianMLPPolicy/KL                      0.00962906
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -23.0052
GaussianMLPPolicy/LossBefore            -20.2891
GaussianMLPPolicy/dLoss                   2.71603
GaussianMLPValueFunction/LossAfter        6.65323
GaussianMLPValueFunction/LossBefore       6.65979
GaussianMLPValueFunction/dLoss            0.00655365
TotalEnvSteps                        504000
-----------------------------------  ---------------
2022-08-17 18:09:07 | [trpo_pendulum] epoch #420 | Saving snapshot...
2022-08-17 18:09:07 | [trpo_pendulum] epoch #420 | Saved
2022-08-17 18:09:07 | [trpo_pendulum] epoch #420 | Time 263.71 s
2022-08-17 18:09:07 | [trpo_pendulum] epoch #420 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -320.083
Evaluation/AverageReturn               -710.288
Evaluation/Iteration                    420
Evaluation/MaxReturn                   -133.064
Evaluation/MinReturn                  -1012.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    330.402
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.71507
GaussianMLPPolicy/KL                      0.00737137
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -48.6419
GaussianMLPPolicy/LossBefore            -46.0799
GaussianMLPPolicy/dLoss                   2.562
GaussianMLPValueFunction/LossAfter        6.71153
GaussianMLPValueFunction/LossBefore       6.71746
GaussianMLPValueFunction/dLoss            0.00593328
TotalEnvSteps                        505200
-----------------------------------  ---------------
2022-08-17 18:09:08 | [trpo_pendulum] epoch #421 | Saving snapshot...
2022-08-17 18:09:08 | [trpo_pendulum] epoch #421 | Saved
2022-08-17 18:09:08 | [trpo_pendulum] epoch #421 | Time 264.35 s
2022-08-17 18:09:08 | [trpo_pendulum] epoch #421 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -716.83
Evaluation/AverageReturn              -1604.35
Evaluation/Iteration                    421
Evaluation/MaxReturn                  -1560.76
Evaluation/MinReturn                  -1716.98
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     55.2161
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.68592
GaussianMLPPolicy/KL                      0.00905096
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              75.2113
GaussianMLPPolicy/LossBefore             76.8545
GaussianMLPPolicy/dLoss                   1.64323
GaussianMLPValueFunction/LossAfter        6.86047
GaussianMLPValueFunction/LossBefore       6.87169
GaussianMLPValueFunction/dLoss            0.0112157
TotalEnvSteps                        506400
-----------------------------------  ---------------
2022-08-17 18:09:09 | [trpo_pendulum] epoch #422 | Saving snapshot...
2022-08-17 18:09:09 | [trpo_pendulum] epoch #422 | Saved
2022-08-17 18:09:09 | [trpo_pendulum] epoch #422 | Time 264.97 s
2022-08-17 18:09:09 | [trpo_pendulum] epoch #422 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -507.47
Evaluation/AverageReturn              -1175.38
Evaluation/Iteration                    422
Evaluation/MaxReturn                   -875.778
Evaluation/MinReturn                  -1520.95
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    223.742
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.70049
GaussianMLPPolicy/KL                      0.00976559
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              17.3074
GaussianMLPPolicy/LossBefore             19.9601
GaussianMLPPolicy/dLoss                   2.65273
GaussianMLPValueFunction/LossAfter        6.55143
GaussianMLPValueFunction/LossBefore       6.56971
GaussianMLPValueFunction/dLoss            0.0182805
TotalEnvSteps                        507600
-----------------------------------  ---------------
2022-08-17 18:09:09 | [trpo_pendulum] epoch #423 | Saving snapshot...
2022-08-17 18:09:09 | [trpo_pendulum] epoch #423 | Saved
2022-08-17 18:09:09 | [trpo_pendulum] epoch #423 | Time 265.59 s
2022-08-17 18:09:09 | [trpo_pendulum] epoch #423 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -530.145
Evaluation/AverageReturn              -1252.55
Evaluation/Iteration                    423
Evaluation/MaxReturn                  -1105.6
Evaluation/MinReturn                  -1498.79
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    128.27
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.70025
GaussianMLPPolicy/KL                      0.00704563
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              29.2159
GaussianMLPPolicy/LossBefore             32.8671
GaussianMLPPolicy/dLoss                   3.65122
GaussianMLPValueFunction/LossAfter        6.53838
GaussianMLPValueFunction/LossBefore       6.55243
GaussianMLPValueFunction/dLoss            0.0140567
TotalEnvSteps                        508800
-----------------------------------  ---------------
2022-08-17 18:09:10 | [trpo_pendulum] epoch #424 | Saving snapshot...
2022-08-17 18:09:10 | [trpo_pendulum] epoch #424 | Saved
2022-08-17 18:09:10 | [trpo_pendulum] epoch #424 | Time 266.22 s
2022-08-17 18:09:10 | [trpo_pendulum] epoch #424 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -656.399
Evaluation/AverageReturn              -1505.28
Evaluation/Iteration                    424
Evaluation/MaxReturn                  -1501.54
Evaluation/MinReturn                  -1512.04
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      3.26458
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.72461
GaussianMLPPolicy/KL                      0.00695479
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              63.5593
GaussianMLPPolicy/LossBefore             65.0263
GaussianMLPPolicy/dLoss                   1.46695
GaussianMLPValueFunction/LossAfter        6.75326
GaussianMLPValueFunction/LossBefore       6.76073
GaussianMLPValueFunction/dLoss            0.00746536
TotalEnvSteps                        510000
-----------------------------------  ---------------
2022-08-17 18:09:11 | [trpo_pendulum] epoch #425 | Saving snapshot...
2022-08-17 18:09:11 | [trpo_pendulum] epoch #425 | Saved
2022-08-17 18:09:11 | [trpo_pendulum] epoch #425 | Time 266.85 s
2022-08-17 18:09:11 | [trpo_pendulum] epoch #425 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -375.259
Evaluation/AverageReturn               -833.725
Evaluation/Iteration                    425
Evaluation/MaxReturn                   -312.902
Evaluation/MinReturn                  -1050.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    270.155
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.71576
GaussianMLPPolicy/KL                      0.00992224
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -31.2759
GaussianMLPPolicy/LossBefore            -28.5623
GaussianMLPPolicy/dLoss                   2.71359
GaussianMLPValueFunction/LossAfter        6.67068
GaussianMLPValueFunction/LossBefore       6.67462
GaussianMLPValueFunction/dLoss            0.00394249
TotalEnvSteps                        511200
-----------------------------------  ---------------
2022-08-17 18:09:11 | [trpo_pendulum] epoch #426 | Saving snapshot...
2022-08-17 18:09:11 | [trpo_pendulum] epoch #426 | Saved
2022-08-17 18:09:11 | [trpo_pendulum] epoch #426 | Time 267.49 s
2022-08-17 18:09:11 | [trpo_pendulum] epoch #426 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -415.431
Evaluation/AverageReturn               -837.213
Evaluation/Iteration                    426
Evaluation/MaxReturn                   -491.494
Evaluation/MinReturn                  -1194.34
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    342.864
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.72304
GaussianMLPPolicy/KL                      0.00851749
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -37.5628
GaussianMLPPolicy/LossBefore            -35.7812
GaussianMLPPolicy/dLoss                   1.78167
GaussianMLPValueFunction/LossAfter        6.78181
GaussianMLPValueFunction/LossBefore       6.79168
GaussianMLPValueFunction/dLoss            0.00986767
TotalEnvSteps                        512400
-----------------------------------  ---------------
2022-08-17 18:09:12 | [trpo_pendulum] epoch #427 | Saving snapshot...
2022-08-17 18:09:12 | [trpo_pendulum] epoch #427 | Saved
2022-08-17 18:09:12 | [trpo_pendulum] epoch #427 | Time 268.12 s
2022-08-17 18:09:12 | [trpo_pendulum] epoch #427 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -45.4561
Evaluation/AverageReturn               -199.178
Evaluation/Iteration                    427
Evaluation/MaxReturn                    -16.8905
Evaluation/MinReturn                   -391.568
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    142.787
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.71383
GaussianMLPPolicy/KL                      0.00844305
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -114.365
GaussianMLPPolicy/LossBefore           -112.097
GaussianMLPPolicy/dLoss                   2.26816
GaussianMLPValueFunction/LossAfter        6.98936
GaussianMLPValueFunction/LossBefore       7.04607
GaussianMLPValueFunction/dLoss            0.0567131
TotalEnvSteps                        513600
-----------------------------------  ---------------
2022-08-17 18:09:12 | [trpo_pendulum] epoch #428 | Saving snapshot...
2022-08-17 18:09:12 | [trpo_pendulum] epoch #428 | Saved
2022-08-17 18:09:12 | [trpo_pendulum] epoch #428 | Time 268.73 s
2022-08-17 18:09:12 | [trpo_pendulum] epoch #428 | EpochTime 0.60 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -417.51
Evaluation/AverageReturn               -952.468
Evaluation/Iteration                    428
Evaluation/MaxReturn                   -255.301
Evaluation/MinReturn                  -1308.71
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    490.859
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.73462
GaussianMLPPolicy/KL                      0.0071311
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -13.4718
GaussianMLPPolicy/LossBefore            -11.869
GaussianMLPPolicy/dLoss                   1.6028
GaussianMLPValueFunction/LossAfter        6.80122
GaussianMLPValueFunction/LossBefore       6.80198
GaussianMLPValueFunction/dLoss            0.000762463
TotalEnvSteps                        514800
-----------------------------------  ----------------
2022-08-17 18:09:13 | [trpo_pendulum] epoch #429 | Saving snapshot...
2022-08-17 18:09:13 | [trpo_pendulum] epoch #429 | Saved
2022-08-17 18:09:13 | [trpo_pendulum] epoch #429 | Time 269.36 s
2022-08-17 18:09:13 | [trpo_pendulum] epoch #429 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -470.949
Evaluation/AverageReturn              -1118.66
Evaluation/Iteration                    429
Evaluation/MaxReturn                   -252.749
Evaluation/MinReturn                  -1320.74
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    389.656
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.76066
GaussianMLPPolicy/KL                      0.00809935
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              12.9345
GaussianMLPPolicy/LossBefore             15.6163
GaussianMLPPolicy/dLoss                   2.68181
GaussianMLPValueFunction/LossAfter        6.69931
GaussianMLPValueFunction/LossBefore       6.70359
GaussianMLPValueFunction/dLoss            0.00427818
TotalEnvSteps                        516000
-----------------------------------  ---------------
2022-08-17 18:09:14 | [trpo_pendulum] epoch #430 | Saving snapshot...
2022-08-17 18:09:14 | [trpo_pendulum] epoch #430 | Saved
2022-08-17 18:09:14 | [trpo_pendulum] epoch #430 | Time 270.01 s
2022-08-17 18:09:14 | [trpo_pendulum] epoch #430 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -548.257
Evaluation/AverageReturn              -1337.18
Evaluation/Iteration                    430
Evaluation/MaxReturn                  -1285.42
Evaluation/MinReturn                  -1358.47
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     23.9937
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.7489
GaussianMLPPolicy/KL                      0.00500796
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              50.6845
GaussianMLPPolicy/LossBefore             51.2461
GaussianMLPPolicy/dLoss                   0.561562
GaussianMLPValueFunction/LossAfter        6.63691
GaussianMLPValueFunction/LossBefore       6.64684
GaussianMLPValueFunction/dLoss            0.0099287
TotalEnvSteps                        517200
-----------------------------------  ---------------
2022-08-17 18:09:14 | [trpo_pendulum] epoch #431 | Saving snapshot...
2022-08-17 18:09:14 | [trpo_pendulum] epoch #431 | Saved
2022-08-17 18:09:14 | [trpo_pendulum] epoch #431 | Time 270.63 s
2022-08-17 18:09:14 | [trpo_pendulum] epoch #431 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -374.363
Evaluation/AverageReturn               -830.841
Evaluation/Iteration                    431
Evaluation/MaxReturn                   -257.072
Evaluation/MinReturn                  -1328.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    421.161
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.72908
GaussianMLPPolicy/KL                      0.00928839
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -31.5864
GaussianMLPPolicy/LossBefore            -30.0479
GaussianMLPPolicy/dLoss                   1.53849
GaussianMLPValueFunction/LossAfter        6.7351
GaussianMLPValueFunction/LossBefore       6.73776
GaussianMLPValueFunction/dLoss            0.00266123
TotalEnvSteps                        518400
-----------------------------------  ---------------
2022-08-17 18:09:15 | [trpo_pendulum] epoch #432 | Saving snapshot...
2022-08-17 18:09:15 | [trpo_pendulum] epoch #432 | Saved
2022-08-17 18:09:15 | [trpo_pendulum] epoch #432 | Time 271.27 s
2022-08-17 18:09:15 | [trpo_pendulum] epoch #432 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -296.873
Evaluation/AverageReturn               -674.768
Evaluation/Iteration                    432
Evaluation/MaxReturn                   -168.43
Evaluation/MinReturn                  -1187.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    446.123
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.73718
GaussianMLPPolicy/KL                      0.00963448
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -53.3027
GaussianMLPPolicy/LossBefore            -50.3802
GaussianMLPPolicy/dLoss                   2.92247
GaussianMLPValueFunction/LossAfter        6.78498
GaussianMLPValueFunction/LossBefore       6.79207
GaussianMLPValueFunction/dLoss            0.00709438
TotalEnvSteps                        519600
-----------------------------------  ---------------
2022-08-17 18:09:16 | [trpo_pendulum] epoch #433 | Saving snapshot...
2022-08-17 18:09:16 | [trpo_pendulum] epoch #433 | Saved
2022-08-17 18:09:16 | [trpo_pendulum] epoch #433 | Time 271.90 s
2022-08-17 18:09:16 | [trpo_pendulum] epoch #433 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -77.5441
Evaluation/AverageReturn               -308.122
Evaluation/Iteration                    433
Evaluation/MaxReturn                   -123.147
Evaluation/MinReturn                   -805.139
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    240.046
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.73172
GaussianMLPPolicy/KL                      0.00816645
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -95.607
GaussianMLPPolicy/LossBefore            -92.0752
GaussianMLPPolicy/dLoss                   3.53182
GaussianMLPValueFunction/LossAfter        6.83937
GaussianMLPValueFunction/LossBefore       6.85555
GaussianMLPValueFunction/dLoss            0.0161824
TotalEnvSteps                        520800
-----------------------------------  ---------------
2022-08-17 18:09:16 | [trpo_pendulum] epoch #434 | Saving snapshot...
2022-08-17 18:09:16 | [trpo_pendulum] epoch #434 | Saved
2022-08-17 18:09:16 | [trpo_pendulum] epoch #434 | Time 272.54 s
2022-08-17 18:09:16 | [trpo_pendulum] epoch #434 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -343.754
Evaluation/AverageReturn               -749.498
Evaluation/Iteration                    434
Evaluation/MaxReturn                   -257.449
Evaluation/MinReturn                  -1169.56
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    322.923
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.74007
GaussianMLPPolicy/KL                      0.00674474
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -40.508
GaussianMLPPolicy/LossBefore            -37.9392
GaussianMLPPolicy/dLoss                   2.56878
GaussianMLPValueFunction/LossAfter        6.6882
GaussianMLPValueFunction/LossBefore       6.69596
GaussianMLPValueFunction/dLoss            0.0077548
TotalEnvSteps                        522000
-----------------------------------  ---------------
2022-08-17 18:09:17 | [trpo_pendulum] epoch #435 | Saving snapshot...
2022-08-17 18:09:17 | [trpo_pendulum] epoch #435 | Saved
2022-08-17 18:09:17 | [trpo_pendulum] epoch #435 | Time 273.16 s
2022-08-17 18:09:17 | [trpo_pendulum] epoch #435 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -368.618
Evaluation/AverageReturn               -760.517
Evaluation/Iteration                    435
Evaluation/MaxReturn                   -489.07
Evaluation/MinReturn                  -1160.13
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    280.996
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.74306
GaussianMLPPolicy/KL                      0.00933226
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -42.68
GaussianMLPPolicy/LossBefore            -40.402
GaussianMLPPolicy/dLoss                   2.27801
GaussianMLPValueFunction/LossAfter        6.65381
GaussianMLPValueFunction/LossBefore       6.66309
GaussianMLPValueFunction/dLoss            0.00927925
TotalEnvSteps                        523200
-----------------------------------  ---------------
2022-08-17 18:09:17 | [trpo_pendulum] epoch #436 | Saving snapshot...
2022-08-17 18:09:18 | [trpo_pendulum] epoch #436 | Saved
2022-08-17 18:09:18 | [trpo_pendulum] epoch #436 | Time 273.79 s
2022-08-17 18:09:18 | [trpo_pendulum] epoch #436 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -374.516
Evaluation/AverageReturn               -724.716
Evaluation/Iteration                    436
Evaluation/MaxReturn                   -493.57
Evaluation/MinReturn                  -1009.5
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    194.345
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.75269
GaussianMLPPolicy/KL                      0.00655764
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -48.2521
GaussianMLPPolicy/LossBefore            -45.964
GaussianMLPPolicy/dLoss                   2.28807
GaussianMLPValueFunction/LossAfter        6.68226
GaussianMLPValueFunction/LossBefore       6.689
GaussianMLPValueFunction/dLoss            0.00673819
TotalEnvSteps                        524400
-----------------------------------  ---------------
2022-08-17 18:09:18 | [trpo_pendulum] epoch #437 | Saving snapshot...
2022-08-17 18:09:18 | [trpo_pendulum] epoch #437 | Saved
2022-08-17 18:09:18 | [trpo_pendulum] epoch #437 | Time 274.41 s
2022-08-17 18:09:18 | [trpo_pendulum] epoch #437 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -365.388
Evaluation/AverageReturn               -648.155
Evaluation/Iteration                    437
Evaluation/MaxReturn                   -486.174
Evaluation/MinReturn                   -963.638
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    163.991
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.73343
GaussianMLPPolicy/KL                      0.00680668
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -61.4595
GaussianMLPPolicy/LossBefore            -59.6688
GaussianMLPPolicy/dLoss                   1.7907
GaussianMLPValueFunction/LossAfter        6.77105
GaussianMLPValueFunction/LossBefore       6.78248
GaussianMLPValueFunction/dLoss            0.0114293
TotalEnvSteps                        525600
-----------------------------------  ---------------
2022-08-17 18:09:19 | [trpo_pendulum] epoch #438 | Saving snapshot...
2022-08-17 18:09:19 | [trpo_pendulum] epoch #438 | Saved
2022-08-17 18:09:19 | [trpo_pendulum] epoch #438 | Time 275.04 s
2022-08-17 18:09:19 | [trpo_pendulum] epoch #438 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -233.241
Evaluation/AverageReturn               -523.059
Evaluation/Iteration                    438
Evaluation/MaxReturn                   -190.553
Evaluation/MinReturn                  -1044.09
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    270.946
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.73906
GaussianMLPPolicy/KL                      0.00955501
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -69.6703
GaussianMLPPolicy/LossBefore            -67.5907
GaussianMLPPolicy/dLoss                   2.07957
GaussianMLPValueFunction/LossAfter        6.73457
GaussianMLPValueFunction/LossBefore       6.74186
GaussianMLPValueFunction/dLoss            0.00728655
TotalEnvSteps                        526800
-----------------------------------  ---------------
2022-08-17 18:09:19 | [trpo_pendulum] epoch #439 | Saving snapshot...
2022-08-17 18:09:19 | [trpo_pendulum] epoch #439 | Saved
2022-08-17 18:09:19 | [trpo_pendulum] epoch #439 | Time 275.66 s
2022-08-17 18:09:19 | [trpo_pendulum] epoch #439 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -713.636
Evaluation/AverageReturn              -1599.99
Evaluation/Iteration                    439
Evaluation/MaxReturn                  -1573.13
Evaluation/MinReturn                  -1630.97
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     18.3655
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.71819
GaussianMLPPolicy/KL                      0.00977652
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              81.7386
GaussianMLPPolicy/LossBefore             85.3312
GaussianMLPPolicy/dLoss                   3.59254
GaussianMLPValueFunction/LossAfter        6.9193
GaussianMLPValueFunction/LossBefore       6.94587
GaussianMLPValueFunction/dLoss            0.0265698
TotalEnvSteps                        528000
-----------------------------------  ---------------
2022-08-17 18:09:20 | [trpo_pendulum] epoch #440 | Saving snapshot...
2022-08-17 18:09:20 | [trpo_pendulum] epoch #440 | Saved
2022-08-17 18:09:20 | [trpo_pendulum] epoch #440 | Time 276.28 s
2022-08-17 18:09:20 | [trpo_pendulum] epoch #440 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -403.855
Evaluation/AverageReturn               -909.453
Evaluation/Iteration                    440
Evaluation/MaxReturn                   -628.568
Evaluation/MinReturn                  -1168.46
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    221.353
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.72179
GaussianMLPPolicy/KL                      0.00759877
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -15.168
GaussianMLPPolicy/LossBefore            -12.7688
GaussianMLPPolicy/dLoss                   2.39928
GaussianMLPValueFunction/LossAfter        6.50852
GaussianMLPValueFunction/LossBefore       6.54785
GaussianMLPValueFunction/dLoss            0.0393295
TotalEnvSteps                        529200
-----------------------------------  ---------------
2022-08-17 18:09:21 | [trpo_pendulum] epoch #441 | Saving snapshot...
2022-08-17 18:09:21 | [trpo_pendulum] epoch #441 | Saved
2022-08-17 18:09:21 | [trpo_pendulum] epoch #441 | Time 276.91 s
2022-08-17 18:09:21 | [trpo_pendulum] epoch #441 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -464.098
Evaluation/AverageReturn               -912.073
Evaluation/Iteration                    441
Evaluation/MaxReturn                   -769.09
Evaluation/MinReturn                  -1181.58
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    184.417
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.72079
GaussianMLPPolicy/KL                      0.00751759
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -21.1759
GaussianMLPPolicy/LossBefore            -18.7722
GaussianMLPPolicy/dLoss                   2.40364
GaussianMLPValueFunction/LossAfter        6.6104
GaussianMLPValueFunction/LossBefore       6.61878
GaussianMLPValueFunction/dLoss            0.00837612
TotalEnvSteps                        530400
-----------------------------------  ---------------
2022-08-17 18:09:21 | [trpo_pendulum] epoch #442 | Saving snapshot...
2022-08-17 18:09:21 | [trpo_pendulum] epoch #442 | Saved
2022-08-17 18:09:21 | [trpo_pendulum] epoch #442 | Time 277.52 s
2022-08-17 18:09:21 | [trpo_pendulum] epoch #442 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -409.961
Evaluation/AverageReturn               -791.74
Evaluation/Iteration                    442
Evaluation/MaxReturn                   -494.85
Evaluation/MinReturn                  -1186.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    277.052
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.69956
GaussianMLPPolicy/KL                      0.00646008
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -37.8259
GaussianMLPPolicy/LossBefore            -36.1708
GaussianMLPPolicy/dLoss                   1.65513
GaussianMLPValueFunction/LossAfter        6.67381
GaussianMLPValueFunction/LossBefore       6.67866
GaussianMLPValueFunction/dLoss            0.00484705
TotalEnvSteps                        531600
-----------------------------------  ---------------
2022-08-17 18:09:22 | [trpo_pendulum] epoch #443 | Saving snapshot...
2022-08-17 18:09:22 | [trpo_pendulum] epoch #443 | Saved
2022-08-17 18:09:22 | [trpo_pendulum] epoch #443 | Time 278.16 s
2022-08-17 18:09:22 | [trpo_pendulum] epoch #443 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -406.81
Evaluation/AverageReturn               -813.41
Evaluation/Iteration                    443
Evaluation/MaxReturn                   -501.193
Evaluation/MinReturn                  -1178.45
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    239.763
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.70585
GaussianMLPPolicy/KL                      0.00642346
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -31.4164
GaussianMLPPolicy/LossBefore            -29.5614
GaussianMLPPolicy/dLoss                   1.85494
GaussianMLPValueFunction/LossAfter        6.64144
GaussianMLPValueFunction/LossBefore       6.64623
GaussianMLPValueFunction/dLoss            0.00478315
TotalEnvSteps                        532800
-----------------------------------  ---------------
2022-08-17 18:09:22 | [trpo_pendulum] epoch #444 | Saving snapshot...
2022-08-17 18:09:23 | [trpo_pendulum] epoch #444 | Saved
2022-08-17 18:09:23 | [trpo_pendulum] epoch #444 | Time 278.79 s
2022-08-17 18:09:23 | [trpo_pendulum] epoch #444 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -350.984
Evaluation/AverageReturn               -655.208
Evaluation/Iteration                    444
Evaluation/MaxReturn                   -369.87
Evaluation/MinReturn                  -1085.66
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    246.051
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.6816
GaussianMLPPolicy/KL                      0.00659733
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -56.1279
GaussianMLPPolicy/LossBefore            -54.1026
GaussianMLPPolicy/dLoss                   2.02531
GaussianMLPValueFunction/LossAfter        6.72977
GaussianMLPValueFunction/LossBefore       6.74001
GaussianMLPValueFunction/dLoss            0.0102396
TotalEnvSteps                        534000
-----------------------------------  ---------------
2022-08-17 18:09:23 | [trpo_pendulum] epoch #445 | Saving snapshot...
2022-08-17 18:09:23 | [trpo_pendulum] epoch #445 | Saved
2022-08-17 18:09:23 | [trpo_pendulum] epoch #445 | Time 279.42 s
2022-08-17 18:09:23 | [trpo_pendulum] epoch #445 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -311.196
Evaluation/AverageReturn               -664.522
Evaluation/Iteration                    445
Evaluation/MaxReturn                   -256.235
Evaluation/MinReturn                  -1059.52
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    296.812
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.6993
GaussianMLPPolicy/KL                      0.00903746
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -48.9798
GaussianMLPPolicy/LossBefore            -46.4213
GaussianMLPPolicy/dLoss                   2.55848
GaussianMLPValueFunction/LossAfter        6.60617
GaussianMLPValueFunction/LossBefore       6.61542
GaussianMLPValueFunction/dLoss            0.00924587
TotalEnvSteps                        535200
-----------------------------------  ---------------
2022-08-17 18:09:24 | [trpo_pendulum] epoch #446 | Saving snapshot...
2022-08-17 18:09:24 | [trpo_pendulum] epoch #446 | Saved
2022-08-17 18:09:24 | [trpo_pendulum] epoch #446 | Time 280.07 s
2022-08-17 18:09:24 | [trpo_pendulum] epoch #446 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -323.233
Evaluation/AverageReturn               -649.427
Evaluation/Iteration                    446
Evaluation/MaxReturn                   -498.095
Evaluation/MinReturn                  -1030.26
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    179.183
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.70073
GaussianMLPPolicy/KL                      0.00682161
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -51.9647
GaussianMLPPolicy/LossBefore            -50.2919
GaussianMLPPolicy/dLoss                   1.67279
GaussianMLPValueFunction/LossAfter        6.5847
GaussianMLPValueFunction/LossBefore       6.59516
GaussianMLPValueFunction/dLoss            0.0104651
TotalEnvSteps                        536400
-----------------------------------  ---------------
2022-08-17 18:09:24 | [trpo_pendulum] epoch #447 | Saving snapshot...
2022-08-17 18:09:24 | [trpo_pendulum] epoch #447 | Saved
2022-08-17 18:09:24 | [trpo_pendulum] epoch #447 | Time 280.71 s
2022-08-17 18:09:24 | [trpo_pendulum] epoch #447 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -435.08
Evaluation/AverageReturn               -834.719
Evaluation/Iteration                    447
Evaluation/MaxReturn                   -632.167
Evaluation/MinReturn                  -1128.81
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    183.179
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.72979
GaussianMLPPolicy/KL                      0.00966962
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -29.7144
GaussianMLPPolicy/LossBefore            -27.293
GaussianMLPPolicy/dLoss                   2.42142
GaussianMLPValueFunction/LossAfter        6.53709
GaussianMLPValueFunction/LossBefore       6.54671
GaussianMLPValueFunction/dLoss            0.0096159
TotalEnvSteps                        537600
-----------------------------------  ---------------
2022-08-17 18:09:25 | [trpo_pendulum] epoch #448 | Saving snapshot...
2022-08-17 18:09:25 | [trpo_pendulum] epoch #448 | Saved
2022-08-17 18:09:25 | [trpo_pendulum] epoch #448 | Time 281.34 s
2022-08-17 18:09:25 | [trpo_pendulum] epoch #448 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -89.761
Evaluation/AverageReturn               -310.214
Evaluation/Iteration                    448
Evaluation/MaxReturn                   -240.869
Evaluation/MinReturn                   -464.452
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     83.6616
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.73454
GaussianMLPPolicy/KL                      0.00759967
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -84.8462
GaussianMLPPolicy/LossBefore            -82.7783
GaussianMLPPolicy/dLoss                   2.06796
GaussianMLPValueFunction/LossAfter        6.69012
GaussianMLPValueFunction/LossBefore       6.70943
GaussianMLPValueFunction/dLoss            0.0193148
TotalEnvSteps                        538800
-----------------------------------  ---------------
2022-08-17 18:09:26 | [trpo_pendulum] epoch #449 | Saving snapshot...
2022-08-17 18:09:26 | [trpo_pendulum] epoch #449 | Saved
2022-08-17 18:09:26 | [trpo_pendulum] epoch #449 | Time 281.99 s
2022-08-17 18:09:26 | [trpo_pendulum] epoch #449 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -233.947
Evaluation/AverageReturn               -554.003
Evaluation/Iteration                    449
Evaluation/MaxReturn                   -257.467
Evaluation/MinReturn                   -781.595
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    192.016
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.74597
GaussianMLPPolicy/KL                      0.00889044
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -56.1931
GaussianMLPPolicy/LossBefore            -54.254
GaussianMLPPolicy/dLoss                   1.93912
GaussianMLPValueFunction/LossAfter        6.53751
GaussianMLPValueFunction/LossBefore       6.54947
GaussianMLPValueFunction/dLoss            0.0119615
TotalEnvSteps                        540000
-----------------------------------  ---------------
2022-08-17 18:09:26 | [trpo_pendulum] epoch #450 | Saving snapshot...
2022-08-17 18:09:26 | [trpo_pendulum] epoch #450 | Saved
2022-08-17 18:09:26 | [trpo_pendulum] epoch #450 | Time 282.61 s
2022-08-17 18:09:26 | [trpo_pendulum] epoch #450 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -110.133
Evaluation/AverageReturn               -295.729
Evaluation/Iteration                    450
Evaluation/MaxReturn                   -138.284
Evaluation/MinReturn                   -610.255
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    147.359
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.75449
GaussianMLPPolicy/KL                      0.00707331
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -87.9055
GaussianMLPPolicy/LossBefore            -86.1108
GaussianMLPPolicy/dLoss                   1.79475
GaussianMLPValueFunction/LossAfter        6.78281
GaussianMLPValueFunction/LossBefore       6.81748
GaussianMLPValueFunction/dLoss            0.0346732
TotalEnvSteps                        541200
-----------------------------------  ---------------
2022-08-17 18:09:27 | [trpo_pendulum] epoch #451 | Saving snapshot...
2022-08-17 18:09:27 | [trpo_pendulum] epoch #451 | Saved
2022-08-17 18:09:27 | [trpo_pendulum] epoch #451 | Time 283.25 s
2022-08-17 18:09:27 | [trpo_pendulum] epoch #451 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -540.375
Evaluation/AverageReturn              -1151.82
Evaluation/Iteration                    451
Evaluation/MaxReturn                  -1002.24
Evaluation/MinReturn                  -1308.65
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     89.9767
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.77207
GaussianMLPPolicy/KL                      0.00652619
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              23.1478
GaussianMLPPolicy/LossBefore             26.8016
GaussianMLPPolicy/dLoss                   3.65382
GaussianMLPValueFunction/LossAfter        6.54142
GaussianMLPValueFunction/LossBefore       6.54962
GaussianMLPValueFunction/dLoss            0.00819254
TotalEnvSteps                        542400
-----------------------------------  ---------------
2022-08-17 18:09:28 | [trpo_pendulum] epoch #452 | Saving snapshot...
2022-08-17 18:09:28 | [trpo_pendulum] epoch #452 | Saved
2022-08-17 18:09:28 | [trpo_pendulum] epoch #452 | Time 283.91 s
2022-08-17 18:09:28 | [trpo_pendulum] epoch #452 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -201.665
Evaluation/AverageReturn               -368.64
Evaluation/Iteration                    452
Evaluation/MaxReturn                   -257.733
Evaluation/MinReturn                   -618.669
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    122.519
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.75914
GaussianMLPPolicy/KL                      0.00657107
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -86.673
GaussianMLPPolicy/LossBefore            -85.3407
GaussianMLPPolicy/dLoss                   1.33228
GaussianMLPValueFunction/LossAfter        6.82036
GaussianMLPValueFunction/LossBefore       6.85442
GaussianMLPValueFunction/dLoss            0.0340652
TotalEnvSteps                        543600
-----------------------------------  ---------------
2022-08-17 18:09:28 | [trpo_pendulum] epoch #453 | Saving snapshot...
2022-08-17 18:09:28 | [trpo_pendulum] epoch #453 | Saved
2022-08-17 18:09:28 | [trpo_pendulum] epoch #453 | Time 284.57 s
2022-08-17 18:09:28 | [trpo_pendulum] epoch #453 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -347.396
Evaluation/AverageReturn               -632.884
Evaluation/Iteration                    453
Evaluation/MaxReturn                   -378.104
Evaluation/MinReturn                   -857.268
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    187.066
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.73463
GaussianMLPPolicy/KL                      0.00694446
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -52.7893
GaussianMLPPolicy/LossBefore            -51.0619
GaussianMLPPolicy/dLoss                   1.72739
GaussianMLPValueFunction/LossAfter        6.65384
GaussianMLPValueFunction/LossBefore       6.65992
GaussianMLPValueFunction/dLoss            0.00607872
TotalEnvSteps                        544800
-----------------------------------  ---------------
2022-08-17 18:09:29 | [trpo_pendulum] epoch #454 | Saving snapshot...
2022-08-17 18:09:29 | [trpo_pendulum] epoch #454 | Saved
2022-08-17 18:09:29 | [trpo_pendulum] epoch #454 | Time 285.20 s
2022-08-17 18:09:29 | [trpo_pendulum] epoch #454 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -79.7937
Evaluation/AverageReturn               -301.352
Evaluation/Iteration                    454
Evaluation/MaxReturn                   -133.994
Evaluation/MinReturn                   -503.724
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    116.134
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.75051
GaussianMLPPolicy/KL                      0.00645083
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -81.3539
GaussianMLPPolicy/LossBefore            -79.1821
GaussianMLPPolicy/dLoss                   2.17174
GaussianMLPValueFunction/LossAfter        6.67046
GaussianMLPValueFunction/LossBefore       6.67866
GaussianMLPValueFunction/dLoss            0.00819921
TotalEnvSteps                        546000
-----------------------------------  ---------------
2022-08-17 18:09:30 | [trpo_pendulum] epoch #455 | Saving snapshot...
2022-08-17 18:09:30 | [trpo_pendulum] epoch #455 | Saved
2022-08-17 18:09:30 | [trpo_pendulum] epoch #455 | Time 285.85 s
2022-08-17 18:09:30 | [trpo_pendulum] epoch #455 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -648.217
Evaluation/AverageReturn              -1496.98
Evaluation/Iteration                    455
Evaluation/MaxReturn                  -1494.78
Evaluation/MinReturn                  -1498.65
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      1.33563
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.73858
GaussianMLPPolicy/KL                      0.00638971
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              82.5172
GaussianMLPPolicy/LossBefore             82.5884
GaussianMLPPolicy/dLoss                   0.0712357
GaussianMLPValueFunction/LossAfter        6.86254
GaussianMLPValueFunction/LossBefore       6.88696
GaussianMLPValueFunction/dLoss            0.0244198
TotalEnvSteps                        547200
-----------------------------------  ---------------
2022-08-17 18:09:30 | [trpo_pendulum] epoch #456 | Saving snapshot...
2022-08-17 18:09:30 | [trpo_pendulum] epoch #456 | Saved
2022-08-17 18:09:30 | [trpo_pendulum] epoch #456 | Time 286.46 s
2022-08-17 18:09:30 | [trpo_pendulum] epoch #456 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -187.049
Evaluation/AverageReturn               -701.815
Evaluation/Iteration                    456
Evaluation/MaxReturn                   -503.929
Evaluation/MinReturn                  -1097.54
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    198.132
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.72818
GaussianMLPPolicy/KL                      0.00645872
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -16.1741
GaussianMLPPolicy/LossBefore            -14.1362
GaussianMLPPolicy/dLoss                   2.03794
GaussianMLPValueFunction/LossAfter        6.35151
GaussianMLPValueFunction/LossBefore       6.4099
GaussianMLPValueFunction/dLoss            0.0583916
TotalEnvSteps                        548400
-----------------------------------  ---------------
2022-08-17 18:09:31 | [trpo_pendulum] epoch #457 | Saving snapshot...
2022-08-17 18:09:31 | [trpo_pendulum] epoch #457 | Saved
2022-08-17 18:09:31 | [trpo_pendulum] epoch #457 | Time 287.11 s
2022-08-17 18:09:31 | [trpo_pendulum] epoch #457 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -658.501
Evaluation/AverageReturn              -1506.25
Evaluation/Iteration                    457
Evaluation/MaxReturn                  -1500.9
Evaluation/MinReturn                  -1509.71
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      2.99363
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.71115
GaussianMLPPolicy/KL                      0.0077042
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              80.142
GaussianMLPPolicy/LossBefore             82.3214
GaussianMLPPolicy/dLoss                   2.17942
GaussianMLPValueFunction/LossAfter        6.87972
GaussianMLPValueFunction/LossBefore       6.90792
GaussianMLPValueFunction/dLoss            0.028203
TotalEnvSteps                        549600
-----------------------------------  --------------
2022-08-17 18:09:31 | [trpo_pendulum] epoch #458 | Saving snapshot...
2022-08-17 18:09:31 | [trpo_pendulum] epoch #458 | Saved
2022-08-17 18:09:31 | [trpo_pendulum] epoch #458 | Time 287.77 s
2022-08-17 18:09:31 | [trpo_pendulum] epoch #458 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -298.265
Evaluation/AverageReturn               -602.179
Evaluation/Iteration                    458
Evaluation/MaxReturn                   -280.831
Evaluation/MinReturn                   -888.476
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    225.546
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.713
GaussianMLPPolicy/KL                      0.00935194
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -52.7973
GaussianMLPPolicy/LossBefore            -50.3199
GaussianMLPPolicy/dLoss                   2.47743
GaussianMLPValueFunction/LossAfter        6.61401
GaussianMLPValueFunction/LossBefore       6.62123
GaussianMLPValueFunction/dLoss            0.00722075
TotalEnvSteps                        550800
-----------------------------------  ---------------
2022-08-17 18:09:32 | [trpo_pendulum] epoch #459 | Saving snapshot...
2022-08-17 18:09:32 | [trpo_pendulum] epoch #459 | Saved
2022-08-17 18:09:32 | [trpo_pendulum] epoch #459 | Time 288.39 s
2022-08-17 18:09:32 | [trpo_pendulum] epoch #459 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -591.261
Evaluation/AverageReturn              -1281.38
Evaluation/Iteration                    459
Evaluation/MaxReturn                   -899.936
Evaluation/MinReturn                  -1514.95
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    190.746
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.71703
GaussianMLPPolicy/KL                      0.00992172
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              44.2025
GaussianMLPPolicy/LossBefore             47.6281
GaussianMLPPolicy/dLoss                   3.4256
GaussianMLPValueFunction/LossAfter        6.69263
GaussianMLPValueFunction/LossBefore       6.69363
GaussianMLPValueFunction/dLoss            0.00100136
TotalEnvSteps                        552000
-----------------------------------  ---------------
2022-08-17 18:09:33 | [trpo_pendulum] epoch #460 | Saving snapshot...
2022-08-17 18:09:33 | [trpo_pendulum] epoch #460 | Saved
2022-08-17 18:09:33 | [trpo_pendulum] epoch #460 | Time 289.03 s
2022-08-17 18:09:33 | [trpo_pendulum] epoch #460 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -490.754
Evaluation/AverageReturn              -1015.16
Evaluation/Iteration                    460
Evaluation/MaxReturn                   -747.561
Evaluation/MinReturn                  -1223.53
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    145.989
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.7152
GaussianMLPPolicy/KL                      0.00658165
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               5.89055
GaussianMLPPolicy/LossBefore              8.63009
GaussianMLPPolicy/dLoss                   2.73954
GaussianMLPValueFunction/LossAfter        6.5476
GaussianMLPValueFunction/LossBefore       6.55579
GaussianMLPValueFunction/dLoss            0.0081811
TotalEnvSteps                        553200
-----------------------------------  ---------------
2022-08-17 18:09:33 | [trpo_pendulum] epoch #461 | Saving snapshot...
2022-08-17 18:09:33 | [trpo_pendulum] epoch #461 | Saved
2022-08-17 18:09:33 | [trpo_pendulum] epoch #461 | Time 289.66 s
2022-08-17 18:09:33 | [trpo_pendulum] epoch #461 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -450.878
Evaluation/AverageReturn               -854.082
Evaluation/Iteration                    461
Evaluation/MaxReturn                   -637.289
Evaluation/MinReturn                  -1016.78
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    147.27
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.72476
GaussianMLPPolicy/KL                      0.00987694
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -21.3765
GaussianMLPPolicy/LossBefore            -18.8601
GaussianMLPPolicy/dLoss                   2.51643
GaussianMLPValueFunction/LossAfter        6.56349
GaussianMLPValueFunction/LossBefore       6.56979
GaussianMLPValueFunction/dLoss            0.00630236
TotalEnvSteps                        554400
-----------------------------------  ---------------
2022-08-17 18:09:34 | [trpo_pendulum] epoch #462 | Saving snapshot...
2022-08-17 18:09:34 | [trpo_pendulum] epoch #462 | Saved
2022-08-17 18:09:34 | [trpo_pendulum] epoch #462 | Time 290.28 s
2022-08-17 18:09:34 | [trpo_pendulum] epoch #462 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -373.941
Evaluation/AverageReturn               -720.36
Evaluation/Iteration                    462
Evaluation/MaxReturn                   -609.588
Evaluation/MinReturn                   -871.674
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    114.12
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.73916
GaussianMLPPolicy/KL                      0.00962298
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -38.0065
GaussianMLPPolicy/LossBefore            -35.7805
GaussianMLPPolicy/dLoss                   2.22602
GaussianMLPValueFunction/LossAfter        6.51604
GaussianMLPValueFunction/LossBefore       6.52722
GaussianMLPValueFunction/dLoss            0.0111742
TotalEnvSteps                        555600
-----------------------------------  ---------------
2022-08-17 18:09:35 | [trpo_pendulum] epoch #463 | Saving snapshot...
2022-08-17 18:09:35 | [trpo_pendulum] epoch #463 | Saved
2022-08-17 18:09:35 | [trpo_pendulum] epoch #463 | Time 290.91 s
2022-08-17 18:09:35 | [trpo_pendulum] epoch #463 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -356.927
Evaluation/AverageReturn               -685.161
Evaluation/Iteration                    463
Evaluation/MaxReturn                   -372.048
Evaluation/MinReturn                  -1100.86
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    246.575
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.74777
GaussianMLPPolicy/KL                      0.00940958
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -43.2236
GaussianMLPPolicy/LossBefore            -40.4977
GaussianMLPPolicy/dLoss                   2.72593
GaussianMLPValueFunction/LossAfter        6.58667
GaussianMLPValueFunction/LossBefore       6.59353
GaussianMLPValueFunction/dLoss            0.00686264
TotalEnvSteps                        556800
-----------------------------------  ---------------
2022-08-17 18:09:35 | [trpo_pendulum] epoch #464 | Saving snapshot...
2022-08-17 18:09:35 | [trpo_pendulum] epoch #464 | Saved
2022-08-17 18:09:35 | [trpo_pendulum] epoch #464 | Time 291.52 s
2022-08-17 18:09:35 | [trpo_pendulum] epoch #464 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -495.949
Evaluation/AverageReturn              -1008.05
Evaluation/Iteration                    464
Evaluation/MaxReturn                   -642.095
Evaluation/MinReturn                  -1303.2
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    227.808
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.75414
GaussianMLPPolicy/KL                      0.00669909
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               5.31913
GaussianMLPPolicy/LossBefore              7.78237
GaussianMLPPolicy/dLoss                   2.46324
GaussianMLPValueFunction/LossAfter        6.55223
GaussianMLPValueFunction/LossBefore       6.55349
GaussianMLPValueFunction/dLoss            0.00125885
TotalEnvSteps                        558000
-----------------------------------  ---------------
2022-08-17 18:09:36 | [trpo_pendulum] epoch #465 | Saving snapshot...
2022-08-17 18:09:36 | [trpo_pendulum] epoch #465 | Saved
2022-08-17 18:09:36 | [trpo_pendulum] epoch #465 | Time 292.16 s
2022-08-17 18:09:36 | [trpo_pendulum] epoch #465 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -318.574
Evaluation/AverageReturn               -691.34
Evaluation/Iteration                    465
Evaluation/MaxReturn                   -258.629
Evaluation/MinReturn                  -1049.43
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    257.086
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.74318
GaussianMLPPolicy/KL                      0.00727348
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -32.4077
GaussianMLPPolicy/LossBefore            -30.7128
GaussianMLPPolicy/dLoss                   1.69495
GaussianMLPValueFunction/LossAfter        6.51183
GaussianMLPValueFunction/LossBefore       6.51915
GaussianMLPValueFunction/dLoss            0.00731993
TotalEnvSteps                        559200
-----------------------------------  ---------------
2022-08-17 18:09:36 | [trpo_pendulum] epoch #466 | Saving snapshot...
2022-08-17 18:09:37 | [trpo_pendulum] epoch #466 | Saved
2022-08-17 18:09:37 | [trpo_pendulum] epoch #466 | Time 292.78 s
2022-08-17 18:09:37 | [trpo_pendulum] epoch #466 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -333.319
Evaluation/AverageReturn               -724.134
Evaluation/Iteration                    466
Evaluation/MaxReturn                   -383.686
Evaluation/MinReturn                  -1098.61
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    261.498
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.72389
GaussianMLPPolicy/KL                      0.00678894
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -29.6012
GaussianMLPPolicy/LossBefore            -27.8368
GaussianMLPPolicy/dLoss                   1.76436
GaussianMLPValueFunction/LossAfter        6.45702
GaussianMLPValueFunction/LossBefore       6.4669
GaussianMLPValueFunction/dLoss            0.00987101
TotalEnvSteps                        560400
-----------------------------------  ---------------
2022-08-17 18:09:37 | [trpo_pendulum] epoch #467 | Saving snapshot...
2022-08-17 18:09:37 | [trpo_pendulum] epoch #467 | Saved
2022-08-17 18:09:37 | [trpo_pendulum] epoch #467 | Time 293.41 s
2022-08-17 18:09:37 | [trpo_pendulum] epoch #467 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -320.148
Evaluation/AverageReturn               -676.676
Evaluation/Iteration                    467
Evaluation/MaxReturn                   -258.931
Evaluation/MinReturn                  -1062.52
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    311.178
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.71762
GaussianMLPPolicy/KL                      0.00684214
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -36.4561
GaussianMLPPolicy/LossBefore            -34.8215
GaussianMLPPolicy/dLoss                   1.63459
GaussianMLPValueFunction/LossAfter        6.56446
GaussianMLPValueFunction/LossBefore       6.57183
GaussianMLPValueFunction/dLoss            0.00736809
TotalEnvSteps                        561600
-----------------------------------  ---------------
2022-08-17 18:09:38 | [trpo_pendulum] epoch #468 | Saving snapshot...
2022-08-17 18:09:38 | [trpo_pendulum] epoch #468 | Saved
2022-08-17 18:09:38 | [trpo_pendulum] epoch #468 | Time 294.03 s
2022-08-17 18:09:38 | [trpo_pendulum] epoch #468 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -396.143
Evaluation/AverageReturn               -726.39
Evaluation/Iteration                    468
Evaluation/MaxReturn                   -498.572
Evaluation/MinReturn                   -878.544
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    151.324
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.72231
GaussianMLPPolicy/KL                      0.00642281
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -34.9346
GaussianMLPPolicy/LossBefore            -32.4196
GaussianMLPPolicy/dLoss                   2.51495
GaussianMLPValueFunction/LossAfter        6.5853
GaussianMLPValueFunction/LossBefore       6.59395
GaussianMLPValueFunction/dLoss            0.0086565
TotalEnvSteps                        562800
-----------------------------------  ---------------
2022-08-17 18:09:38 | [trpo_pendulum] epoch #469 | Saving snapshot...
2022-08-17 18:09:38 | [trpo_pendulum] epoch #469 | Saved
2022-08-17 18:09:38 | [trpo_pendulum] epoch #469 | Time 294.67 s
2022-08-17 18:09:38 | [trpo_pendulum] epoch #469 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -276.704
Evaluation/AverageReturn               -670.836
Evaluation/Iteration                    469
Evaluation/MaxReturn                   -264.458
Evaluation/MinReturn                   -935.225
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    231.424
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.72226
GaussianMLPPolicy/KL                      0.00576352
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -26.1023
GaussianMLPPolicy/LossBefore            -24.7761
GaussianMLPPolicy/dLoss                   1.32623
GaussianMLPValueFunction/LossAfter        6.46105
GaussianMLPValueFunction/LossBefore       6.46989
GaussianMLPValueFunction/dLoss            0.00883865
TotalEnvSteps                        564000
-----------------------------------  ---------------
2022-08-17 18:09:39 | [trpo_pendulum] epoch #470 | Saving snapshot...
2022-08-17 18:09:39 | [trpo_pendulum] epoch #470 | Saved
2022-08-17 18:09:39 | [trpo_pendulum] epoch #470 | Time 295.29 s
2022-08-17 18:09:39 | [trpo_pendulum] epoch #470 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -71.9723
Evaluation/AverageReturn               -284.927
Evaluation/Iteration                    470
Evaluation/MaxReturn                   -135.001
Evaluation/MinReturn                   -390.808
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     80.7015
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.72452
GaussianMLPPolicy/KL                      0.00777772
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -77.9251
GaussianMLPPolicy/LossBefore            -75.7537
GaussianMLPPolicy/dLoss                   2.17139
GaussianMLPValueFunction/LossAfter        6.60231
GaussianMLPValueFunction/LossBefore       6.62213
GaussianMLPValueFunction/dLoss            0.019824
TotalEnvSteps                        565200
-----------------------------------  ---------------
2022-08-17 18:09:40 | [trpo_pendulum] epoch #471 | Saving snapshot...
2022-08-17 18:09:40 | [trpo_pendulum] epoch #471 | Saved
2022-08-17 18:09:40 | [trpo_pendulum] epoch #471 | Time 295.93 s
2022-08-17 18:09:40 | [trpo_pendulum] epoch #471 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -308.937
Evaluation/AverageReturn               -680.515
Evaluation/Iteration                    471
Evaluation/MaxReturn                   -510.417
Evaluation/MinReturn                   -878.361
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    136.977
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.70249
GaussianMLPPolicy/KL                      0.00723277
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -27.356
GaussianMLPPolicy/LossBefore            -25.9084
GaussianMLPPolicy/dLoss                   1.4476
GaussianMLPValueFunction/LossAfter        6.39007
GaussianMLPValueFunction/LossBefore       6.40859
GaussianMLPValueFunction/dLoss            0.0185246
TotalEnvSteps                        566400
-----------------------------------  ---------------
2022-08-17 18:09:40 | [trpo_pendulum] epoch #472 | Saving snapshot...
2022-08-17 18:09:40 | [trpo_pendulum] epoch #472 | Saved
2022-08-17 18:09:40 | [trpo_pendulum] epoch #472 | Time 296.55 s
2022-08-17 18:09:40 | [trpo_pendulum] epoch #472 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -409.251
Evaluation/AverageReturn               -840.858
Evaluation/Iteration                    472
Evaluation/MaxReturn                   -497.332
Evaluation/MinReturn                  -1103.25
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    193.454
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.70326
GaussianMLPPolicy/KL                      0.00995777
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -11.8443
GaussianMLPPolicy/LossBefore             -8.8101
GaussianMLPPolicy/dLoss                   3.03421
GaussianMLPValueFunction/LossAfter        6.43255
GaussianMLPValueFunction/LossBefore       6.43709
GaussianMLPValueFunction/dLoss            0.00453615
TotalEnvSteps                        567600
-----------------------------------  ---------------
2022-08-17 18:09:41 | [trpo_pendulum] epoch #473 | Saving snapshot...
2022-08-17 18:09:41 | [trpo_pendulum] epoch #473 | Saved
2022-08-17 18:09:41 | [trpo_pendulum] epoch #473 | Time 297.19 s
2022-08-17 18:09:41 | [trpo_pendulum] epoch #473 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -381.524
Evaluation/AverageReturn               -763.935
Evaluation/Iteration                    473
Evaluation/MaxReturn                   -498.352
Evaluation/MinReturn                  -1013.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    172.292
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.69628
GaussianMLPPolicy/KL                      0.00650762
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -21.392
GaussianMLPPolicy/LossBefore            -19.5728
GaussianMLPPolicy/dLoss                   1.81918
GaussianMLPValueFunction/LossAfter        6.44737
GaussianMLPValueFunction/LossBefore       6.45205
GaussianMLPValueFunction/dLoss            0.00467968
TotalEnvSteps                        568800
-----------------------------------  ---------------
2022-08-17 18:09:42 | [trpo_pendulum] epoch #474 | Saving snapshot...
2022-08-17 18:09:42 | [trpo_pendulum] epoch #474 | Saved
2022-08-17 18:09:42 | [trpo_pendulum] epoch #474 | Time 297.81 s
2022-08-17 18:09:42 | [trpo_pendulum] epoch #474 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -274.526
Evaluation/AverageReturn               -549.165
Evaluation/Iteration                    474
Evaluation/MaxReturn                   -377.578
Evaluation/MinReturn                   -887.007
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    188.095
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.69561
GaussianMLPPolicy/KL                      0.0064772
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -48.7347
GaussianMLPPolicy/LossBefore            -46.8462
GaussianMLPPolicy/dLoss                   1.88858
GaussianMLPValueFunction/LossAfter        6.5836
GaussianMLPValueFunction/LossBefore       6.60453
GaussianMLPValueFunction/dLoss            0.0209308
TotalEnvSteps                        570000
-----------------------------------  --------------
2022-08-17 18:09:42 | [trpo_pendulum] epoch #475 | Saving snapshot...
2022-08-17 18:09:42 | [trpo_pendulum] epoch #475 | Saved
2022-08-17 18:09:42 | [trpo_pendulum] epoch #475 | Time 298.45 s
2022-08-17 18:09:42 | [trpo_pendulum] epoch #475 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -669.057
Evaluation/AverageReturn              -1536.35
Evaluation/Iteration                    475
Evaluation/MaxReturn                  -1522.37
Evaluation/MinReturn                  -1545.76
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.61413
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.69452
GaussianMLPPolicy/KL                      0.00820062
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              94.7612
GaussianMLPPolicy/LossBefore             96.2434
GaussianMLPPolicy/dLoss                   1.4822
GaussianMLPValueFunction/LossAfter        7.04885
GaussianMLPValueFunction/LossBefore       7.19956
GaussianMLPValueFunction/dLoss            0.150705
TotalEnvSteps                        571200
-----------------------------------  ---------------
2022-08-17 18:09:43 | [trpo_pendulum] epoch #476 | Saving snapshot...
2022-08-17 18:09:43 | [trpo_pendulum] epoch #476 | Saved
2022-08-17 18:09:43 | [trpo_pendulum] epoch #476 | Time 299.10 s
2022-08-17 18:09:43 | [trpo_pendulum] epoch #476 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -602.094
Evaluation/AverageReturn              -1432.76
Evaluation/Iteration                    476
Evaluation/MaxReturn                  -1307.12
Evaluation/MinReturn                  -1497.3
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     64.72
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.65653
GaussianMLPPolicy/KL                      0.00668324
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              82.668
GaussianMLPPolicy/LossBefore             84.7763
GaussianMLPPolicy/dLoss                   2.10828
GaussianMLPValueFunction/LossAfter        6.87968
GaussianMLPValueFunction/LossBefore       6.90769
GaussianMLPValueFunction/dLoss            0.0280108
TotalEnvSteps                        572400
-----------------------------------  ---------------
2022-08-17 18:09:43 | [trpo_pendulum] epoch #477 | Saving snapshot...
2022-08-17 18:09:43 | [trpo_pendulum] epoch #477 | Saved
2022-08-17 18:09:43 | [trpo_pendulum] epoch #477 | Time 299.72 s
2022-08-17 18:09:43 | [trpo_pendulum] epoch #477 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -132.959
Evaluation/AverageReturn               -526.361
Evaluation/Iteration                    477
Evaluation/MaxReturn                   -248.923
Evaluation/MinReturn                   -645.657
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    133.591
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.66131
GaussianMLPPolicy/KL                      0.00661678
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -36.1425
GaussianMLPPolicy/LossBefore            -34.1597
GaussianMLPPolicy/dLoss                   1.98276
GaussianMLPValueFunction/LossAfter        6.32958
GaussianMLPValueFunction/LossBefore       6.36558
GaussianMLPValueFunction/dLoss            0.0360026
TotalEnvSteps                        573600
-----------------------------------  ---------------
2022-08-17 18:09:44 | [trpo_pendulum] epoch #478 | Saving snapshot...
2022-08-17 18:09:44 | [trpo_pendulum] epoch #478 | Saved
2022-08-17 18:09:44 | [trpo_pendulum] epoch #478 | Time 300.35 s
2022-08-17 18:09:44 | [trpo_pendulum] epoch #478 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -573.643
Evaluation/AverageReturn              -1395.24
Evaluation/Iteration                    478
Evaluation/MaxReturn                  -1328.3
Evaluation/MinReturn                  -1490.97
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.738
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.66646
GaussianMLPPolicy/KL                      0.00975669
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              76.8754
GaussianMLPPolicy/LossBefore             80.1614
GaussianMLPPolicy/dLoss                   3.28595
GaussianMLPValueFunction/LossAfter        6.81758
GaussianMLPValueFunction/LossBefore       6.83489
GaussianMLPValueFunction/dLoss            0.0173125
TotalEnvSteps                        574800
-----------------------------------  ---------------
2022-08-17 18:09:45 | [trpo_pendulum] epoch #479 | Saving snapshot...
2022-08-17 18:09:45 | [trpo_pendulum] epoch #479 | Saved
2022-08-17 18:09:45 | [trpo_pendulum] epoch #479 | Time 300.98 s
2022-08-17 18:09:45 | [trpo_pendulum] epoch #479 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -515.282
Evaluation/AverageReturn              -1256.23
Evaluation/Iteration                    479
Evaluation/MaxReturn                  -1093.18
Evaluation/MinReturn                  -1396.67
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     97.7991
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.65598
GaussianMLPPolicy/KL                      0.0099839
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              57.3148
GaussianMLPPolicy/LossBefore             60.1637
GaussianMLPPolicy/dLoss                   2.84894
GaussianMLPValueFunction/LossAfter        6.61918
GaussianMLPValueFunction/LossBefore       6.62306
GaussianMLPValueFunction/dLoss            0.00388479
TotalEnvSteps                        576000
-----------------------------------  ---------------
2022-08-17 18:09:45 | [trpo_pendulum] epoch #480 | Saving snapshot...
2022-08-17 18:09:45 | [trpo_pendulum] epoch #480 | Saved
2022-08-17 18:09:45 | [trpo_pendulum] epoch #480 | Time 301.59 s
2022-08-17 18:09:45 | [trpo_pendulum] epoch #480 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -656.227
Evaluation/AverageReturn              -1506.18
Evaluation/Iteration                    480
Evaluation/MaxReturn                  -1497.24
Evaluation/MinReturn                  -1520.65
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      7.30133
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.69493
GaussianMLPPolicy/KL                      0.00728634
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              87.4193
GaussianMLPPolicy/LossBefore             89.5421
GaussianMLPPolicy/dLoss                   2.12273
GaussianMLPValueFunction/LossAfter        6.9363
GaussianMLPValueFunction/LossBefore       6.97205
GaussianMLPValueFunction/dLoss            0.0357561
TotalEnvSteps                        577200
-----------------------------------  ---------------
2022-08-17 18:09:46 | [trpo_pendulum] epoch #481 | Saving snapshot...
2022-08-17 18:09:46 | [trpo_pendulum] epoch #481 | Saved
2022-08-17 18:09:46 | [trpo_pendulum] epoch #481 | Time 302.22 s
2022-08-17 18:09:46 | [trpo_pendulum] epoch #481 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -523.873
Evaluation/AverageReturn              -1348.41
Evaluation/Iteration                    481
Evaluation/MaxReturn                  -1297.82
Evaluation/MinReturn                  -1400.98
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     35.6943
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.68032
GaussianMLPPolicy/KL                      0.00945328
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              74.7355
GaussianMLPPolicy/LossBefore             78.0933
GaussianMLPPolicy/dLoss                   3.35779
GaussianMLPValueFunction/LossAfter        6.8104
GaussianMLPValueFunction/LossBefore       6.81948
GaussianMLPValueFunction/dLoss            0.00907898
TotalEnvSteps                        578400
-----------------------------------  ---------------
2022-08-17 18:09:47 | [trpo_pendulum] epoch #482 | Saving snapshot...
2022-08-17 18:09:47 | [trpo_pendulum] epoch #482 | Saved
2022-08-17 18:09:47 | [trpo_pendulum] epoch #482 | Time 302.87 s
2022-08-17 18:09:47 | [trpo_pendulum] epoch #482 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -586.845
Evaluation/AverageReturn              -1434.29
Evaluation/Iteration                    482
Evaluation/MaxReturn                  -1383.81
Evaluation/MinReturn                  -1464.28
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     32.0596
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.66778
GaussianMLPPolicy/KL                      0.00683172
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              82.0578
GaussianMLPPolicy/LossBefore             84.9588
GaussianMLPPolicy/dLoss                   2.90104
GaussianMLPValueFunction/LossAfter        6.87422
GaussianMLPValueFunction/LossBefore       6.88756
GaussianMLPValueFunction/dLoss            0.0133438
TotalEnvSteps                        579600
-----------------------------------  ---------------
2022-08-17 18:09:47 | [trpo_pendulum] epoch #483 | Saving snapshot...
2022-08-17 18:09:47 | [trpo_pendulum] epoch #483 | Saved
2022-08-17 18:09:47 | [trpo_pendulum] epoch #483 | Time 303.51 s
2022-08-17 18:09:47 | [trpo_pendulum] epoch #483 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -662.112
Evaluation/AverageReturn              -1533.53
Evaluation/Iteration                    483
Evaluation/MaxReturn                  -1492.97
Evaluation/MinReturn                  -1573.18
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     23.6699
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.68479
GaussianMLPPolicy/KL                      0.00979233
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              91.0482
GaussianMLPPolicy/LossBefore             93.8443
GaussianMLPPolicy/dLoss                   2.79611
GaussianMLPValueFunction/LossAfter        6.961
GaussianMLPValueFunction/LossBefore       6.98251
GaussianMLPValueFunction/dLoss            0.0215054
TotalEnvSteps                        580800
-----------------------------------  ---------------
2022-08-17 18:09:48 | [trpo_pendulum] epoch #484 | Saving snapshot...
2022-08-17 18:09:48 | [trpo_pendulum] epoch #484 | Saved
2022-08-17 18:09:48 | [trpo_pendulum] epoch #484 | Time 304.17 s
2022-08-17 18:09:48 | [trpo_pendulum] epoch #484 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -351.214
Evaluation/AverageReturn              -1080.18
Evaluation/Iteration                    484
Evaluation/MaxReturn                   -811.335
Evaluation/MinReturn                  -1340.96
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    195.351
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.66132
GaussianMLPPolicy/KL                      0.00970756
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              42.6942
GaussianMLPPolicy/LossBefore             45.28
GaussianMLPPolicy/dLoss                   2.58579
GaussianMLPValueFunction/LossAfter        6.59539
GaussianMLPValueFunction/LossBefore       6.61102
GaussianMLPValueFunction/dLoss            0.0156336
TotalEnvSteps                        582000
-----------------------------------  ---------------
2022-08-17 18:09:49 | [trpo_pendulum] epoch #485 | Saving snapshot...
2022-08-17 18:09:49 | [trpo_pendulum] epoch #485 | Saved
2022-08-17 18:09:49 | [trpo_pendulum] epoch #485 | Time 304.82 s
2022-08-17 18:09:49 | [trpo_pendulum] epoch #485 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -395.891
Evaluation/AverageReturn              -1183.56
Evaluation/Iteration                    485
Evaluation/MaxReturn                  -1055.45
Evaluation/MinReturn                  -1308.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     88.0132
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.65454
GaussianMLPPolicy/KL                      0.00938559
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              58.0033
GaussianMLPPolicy/LossBefore             60.9356
GaussianMLPPolicy/dLoss                   2.93227
GaussianMLPValueFunction/LossAfter        6.67887
GaussianMLPValueFunction/LossBefore       6.68492
GaussianMLPValueFunction/dLoss            0.00604582
TotalEnvSteps                        583200
-----------------------------------  ---------------
2022-08-17 18:09:49 | [trpo_pendulum] epoch #486 | Saving snapshot...
2022-08-17 18:09:49 | [trpo_pendulum] epoch #486 | Saved
2022-08-17 18:09:49 | [trpo_pendulum] epoch #486 | Time 305.48 s
2022-08-17 18:09:49 | [trpo_pendulum] epoch #486 | EpochTime 0.66 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -644.053
Evaluation/AverageReturn              -1499.46
Evaluation/Iteration                    486
Evaluation/MaxReturn                  -1494.99
Evaluation/MinReturn                  -1505.92
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      3.43639
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.70364
GaussianMLPPolicy/KL                      0.0093816
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              84.0556
GaussianMLPPolicy/LossBefore             87.2967
GaussianMLPPolicy/dLoss                   3.24107
GaussianMLPValueFunction/LossAfter        6.89765
GaussianMLPValueFunction/LossBefore       6.91285
GaussianMLPValueFunction/dLoss            0.0151963
TotalEnvSteps                        584400
-----------------------------------  --------------
2022-08-17 18:09:50 | [trpo_pendulum] epoch #487 | Saving snapshot...
2022-08-17 18:09:50 | [trpo_pendulum] epoch #487 | Saved
2022-08-17 18:09:50 | [trpo_pendulum] epoch #487 | Time 306.16 s
2022-08-17 18:09:50 | [trpo_pendulum] epoch #487 | EpochTime 0.67 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -625.593
Evaluation/AverageReturn              -1527.06
Evaluation/Iteration                    487
Evaluation/MaxReturn                  -1404.95
Evaluation/MinReturn                  -1686.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     99.0075
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.69145
GaussianMLPPolicy/KL                      0.00970546
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              92.8153
GaussianMLPPolicy/LossBefore             96.1242
GaussianMLPPolicy/dLoss                   3.30894
GaussianMLPValueFunction/LossAfter        7.00807
GaussianMLPValueFunction/LossBefore       7.037
GaussianMLPValueFunction/dLoss            0.0289254
TotalEnvSteps                        585600
-----------------------------------  ---------------
2022-08-17 18:09:51 | [trpo_pendulum] epoch #488 | Saving snapshot...
2022-08-17 18:09:51 | [trpo_pendulum] epoch #488 | Saved
2022-08-17 18:09:51 | [trpo_pendulum] epoch #488 | Time 306.87 s
2022-08-17 18:09:51 | [trpo_pendulum] epoch #488 | EpochTime 0.70 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -664.743
Evaluation/AverageReturn              -1525.92
Evaluation/Iteration                    488
Evaluation/MaxReturn                  -1513.23
Evaluation/MinReturn                  -1540.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.51092
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.67337
GaussianMLPPolicy/KL                      0.00781602
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              85.2827
GaussianMLPPolicy/LossBefore             87.478
GaussianMLPPolicy/dLoss                   2.19527
GaussianMLPValueFunction/LossAfter        6.88972
GaussianMLPValueFunction/LossBefore       6.89528
GaussianMLPValueFunction/dLoss            0.00555182
TotalEnvSteps                        586800
-----------------------------------  ---------------
2022-08-17 18:09:51 | [trpo_pendulum] epoch #489 | Saving snapshot...
2022-08-17 18:09:51 | [trpo_pendulum] epoch #489 | Saved
2022-08-17 18:09:51 | [trpo_pendulum] epoch #489 | Time 307.51 s
2022-08-17 18:09:51 | [trpo_pendulum] epoch #489 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -655.476
Evaluation/AverageReturn              -1512.01
Evaluation/Iteration                    489
Evaluation/MaxReturn                  -1506.69
Evaluation/MinReturn                  -1524.73
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      6.07103
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.63713
GaussianMLPPolicy/KL                      0.00740152
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              83.6549
GaussianMLPPolicy/LossBefore             86.0803
GaussianMLPPolicy/dLoss                   2.42542
GaussianMLPValueFunction/LossAfter        6.88216
GaussianMLPValueFunction/LossBefore       6.88646
GaussianMLPValueFunction/dLoss            0.00429487
TotalEnvSteps                        588000
-----------------------------------  ---------------
2022-08-17 18:09:52 | [trpo_pendulum] epoch #490 | Saving snapshot...
2022-08-17 18:09:52 | [trpo_pendulum] epoch #490 | Saved
2022-08-17 18:09:52 | [trpo_pendulum] epoch #490 | Time 308.15 s
2022-08-17 18:09:52 | [trpo_pendulum] epoch #490 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -443.021
Evaluation/AverageReturn              -1251.55
Evaluation/Iteration                    490
Evaluation/MaxReturn                  -1064.26
Evaluation/MinReturn                  -1367.71
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    108.554
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.64083
GaussianMLPPolicy/KL                      0.00919843
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              63.0118
GaussianMLPPolicy/LossBefore             65.7662
GaussianMLPPolicy/dLoss                   2.75436
GaussianMLPValueFunction/LossAfter        6.74558
GaussianMLPValueFunction/LossBefore       6.75337
GaussianMLPValueFunction/dLoss            0.00779057
TotalEnvSteps                        589200
-----------------------------------  ---------------
2022-08-17 18:09:53 | [trpo_pendulum] epoch #491 | Saving snapshot...
2022-08-17 18:09:53 | [trpo_pendulum] epoch #491 | Saved
2022-08-17 18:09:53 | [trpo_pendulum] epoch #491 | Time 308.81 s
2022-08-17 18:09:53 | [trpo_pendulum] epoch #491 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -620.396
Evaluation/AverageReturn              -1471.92
Evaluation/Iteration                    491
Evaluation/MaxReturn                  -1461.71
Evaluation/MinReturn                  -1478.96
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.94282
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.66396
GaussianMLPPolicy/KL                      0.00888818
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              79.7434
GaussianMLPPolicy/LossBefore             82.6529
GaussianMLPPolicy/dLoss                   2.90955
GaussianMLPValueFunction/LossAfter        6.85932
GaussianMLPValueFunction/LossBefore       6.86368
GaussianMLPValueFunction/dLoss            0.00435686
TotalEnvSteps                        590400
-----------------------------------  ---------------
2022-08-17 18:09:53 | [trpo_pendulum] epoch #492 | Saving snapshot...
2022-08-17 18:09:53 | [trpo_pendulum] epoch #492 | Saved
2022-08-17 18:09:53 | [trpo_pendulum] epoch #492 | Time 309.45 s
2022-08-17 18:09:53 | [trpo_pendulum] epoch #492 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -669.136
Evaluation/AverageReturn              -1532.99
Evaluation/Iteration                    492
Evaluation/MaxReturn                  -1510.64
Evaluation/MinReturn                  -1621.12
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     39.5412
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.65334
GaussianMLPPolicy/KL                      0.00873062
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              84.4724
GaussianMLPPolicy/LossBefore             86.6703
GaussianMLPPolicy/dLoss                   2.19791
GaussianMLPValueFunction/LossAfter        6.89374
GaussianMLPValueFunction/LossBefore       6.89954
GaussianMLPValueFunction/dLoss            0.00579739
TotalEnvSteps                        591600
-----------------------------------  ---------------
2022-08-17 18:09:54 | [trpo_pendulum] epoch #493 | Saving snapshot...
2022-08-17 18:09:54 | [trpo_pendulum] epoch #493 | Saved
2022-08-17 18:09:54 | [trpo_pendulum] epoch #493 | Time 310.08 s
2022-08-17 18:09:54 | [trpo_pendulum] epoch #493 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -562.078
Evaluation/AverageReturn              -1408.25
Evaluation/Iteration                    493
Evaluation/MaxReturn                  -1389.65
Evaluation/MinReturn                  -1423.56
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.6881
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.65056
GaussianMLPPolicy/KL                      0.0064727
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              74.7852
GaussianMLPPolicy/LossBefore             77.3868
GaussianMLPPolicy/dLoss                   2.60158
GaussianMLPValueFunction/LossAfter        6.80755
GaussianMLPValueFunction/LossBefore       6.81212
GaussianMLPValueFunction/dLoss            0.00456905
TotalEnvSteps                        592800
-----------------------------------  ---------------
2022-08-17 18:09:54 | [trpo_pendulum] epoch #494 | Saving snapshot...
2022-08-17 18:09:54 | [trpo_pendulum] epoch #494 | Saved
2022-08-17 18:09:54 | [trpo_pendulum] epoch #494 | Time 310.71 s
2022-08-17 18:09:54 | [trpo_pendulum] epoch #494 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -599.043
Evaluation/AverageReturn              -1420.1
Evaluation/Iteration                    494
Evaluation/MaxReturn                  -1371.52
Evaluation/MinReturn                  -1453.78
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     28.3168
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.65688
GaussianMLPPolicy/KL                      0.00644904
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              69.4505
GaussianMLPPolicy/LossBefore             72.1803
GaussianMLPPolicy/dLoss                   2.7298
GaussianMLPValueFunction/LossAfter        6.76598
GaussianMLPValueFunction/LossBefore       6.77203
GaussianMLPValueFunction/dLoss            0.00605345
TotalEnvSteps                        594000
-----------------------------------  ---------------
2022-08-17 18:09:55 | [trpo_pendulum] epoch #495 | Saving snapshot...
2022-08-17 18:09:55 | [trpo_pendulum] epoch #495 | Saved
2022-08-17 18:09:55 | [trpo_pendulum] epoch #495 | Time 311.35 s
2022-08-17 18:09:55 | [trpo_pendulum] epoch #495 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -656.085
Evaluation/AverageReturn              -1505.92
Evaluation/Iteration                    495
Evaluation/MaxReturn                  -1500.18
Evaluation/MinReturn                  -1513.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      4.57813
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.6484
GaussianMLPPolicy/KL                      0.0081626
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              78.5398
GaussianMLPPolicy/LossBefore             80.2821
GaussianMLPPolicy/dLoss                   1.74232
GaussianMLPValueFunction/LossAfter        6.84254
GaussianMLPValueFunction/LossBefore       6.84701
GaussianMLPValueFunction/dLoss            0.00447178
TotalEnvSteps                        595200
-----------------------------------  ---------------
2022-08-17 18:09:56 | [trpo_pendulum] epoch #496 | Saving snapshot...
2022-08-17 18:09:56 | [trpo_pendulum] epoch #496 | Saved
2022-08-17 18:09:56 | [trpo_pendulum] epoch #496 | Time 311.98 s
2022-08-17 18:09:56 | [trpo_pendulum] epoch #496 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -660.663
Evaluation/AverageReturn              -1532.79
Evaluation/Iteration                    496
Evaluation/MaxReturn                  -1520.46
Evaluation/MinReturn                  -1544.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.80172
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.64898
GaussianMLPPolicy/KL                      0.00662806
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              82.9457
GaussianMLPPolicy/LossBefore             85.3621
GaussianMLPPolicy/dLoss                   2.41635
GaussianMLPValueFunction/LossAfter        6.88922
GaussianMLPValueFunction/LossBefore       6.89616
GaussianMLPValueFunction/dLoss            0.00693417
TotalEnvSteps                        596400
-----------------------------------  ---------------
2022-08-17 18:09:56 | [trpo_pendulum] epoch #497 | Saving snapshot...
2022-08-17 18:09:56 | [trpo_pendulum] epoch #497 | Saved
2022-08-17 18:09:56 | [trpo_pendulum] epoch #497 | Time 312.60 s
2022-08-17 18:09:56 | [trpo_pendulum] epoch #497 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -649.502
Evaluation/AverageReturn              -1548.52
Evaluation/Iteration                    497
Evaluation/MaxReturn                  -1491.89
Evaluation/MinReturn                  -1598.25
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     43.4555
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.64654
GaussianMLPPolicy/KL                      0.00661607
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              87.8367
GaussianMLPPolicy/LossBefore             89.888
GaussianMLPPolicy/dLoss                   2.05135
GaussianMLPValueFunction/LossAfter        6.93327
GaussianMLPValueFunction/LossBefore       6.9425
GaussianMLPValueFunction/dLoss            0.0092268
TotalEnvSteps                        597600
-----------------------------------  ---------------
2022-08-17 18:09:57 | [trpo_pendulum] epoch #498 | Saving snapshot...
2022-08-17 18:09:57 | [trpo_pendulum] epoch #498 | Saved
2022-08-17 18:09:57 | [trpo_pendulum] epoch #498 | Time 313.25 s
2022-08-17 18:09:57 | [trpo_pendulum] epoch #498 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -598.914
Evaluation/AverageReturn              -1468.59
Evaluation/Iteration                    498
Evaluation/MaxReturn                  -1432
Evaluation/MinReturn                  -1492.49
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     19.4753
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.65195
GaussianMLPPolicy/KL                      0.00959372
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              78.4272
GaussianMLPPolicy/LossBefore             80.8481
GaussianMLPPolicy/dLoss                   2.42093
GaussianMLPValueFunction/LossAfter        6.84302
GaussianMLPValueFunction/LossBefore       6.84743
GaussianMLPValueFunction/dLoss            0.00441122
TotalEnvSteps                        598800
-----------------------------------  ---------------
2022-08-17 18:09:58 | [trpo_pendulum] epoch #499 | Saving snapshot...
2022-08-17 18:09:58 | [trpo_pendulum] epoch #499 | Saved
2022-08-17 18:09:58 | [trpo_pendulum] epoch #499 | Time 313.87 s
2022-08-17 18:09:58 | [trpo_pendulum] epoch #499 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -599.613
Evaluation/AverageReturn              -1477.75
Evaluation/Iteration                    499
Evaluation/MaxReturn                  -1450.99
Evaluation/MinReturn                  -1531.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     27.5339
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.65101
GaussianMLPPolicy/KL                      0.0094219
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              79.0504
GaussianMLPPolicy/LossBefore             82.0459
GaussianMLPPolicy/dLoss                   2.99548
GaussianMLPValueFunction/LossAfter        6.8688
GaussianMLPValueFunction/LossBefore       6.87266
GaussianMLPValueFunction/dLoss            0.00386667
TotalEnvSteps                        600000
-----------------------------------  ---------------
2022-08-17 18:09:58 | [trpo_pendulum] epoch #500 | Saving snapshot...
2022-08-17 18:09:58 | [trpo_pendulum] epoch #500 | Saved
2022-08-17 18:09:58 | [trpo_pendulum] epoch #500 | Time 314.51 s
2022-08-17 18:09:58 | [trpo_pendulum] epoch #500 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -623.203
Evaluation/AverageReturn              -1502.61
Evaluation/Iteration                    500
Evaluation/MaxReturn                  -1476.63
Evaluation/MinReturn                  -1537.7
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     19.2765
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.65844
GaussianMLPPolicy/KL                      0.0069598
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              79.6289
GaussianMLPPolicy/LossBefore             81.967
GaussianMLPPolicy/dLoss                   2.33812
GaussianMLPValueFunction/LossAfter        6.86481
GaussianMLPValueFunction/LossBefore       6.86869
GaussianMLPValueFunction/dLoss            0.00388241
TotalEnvSteps                        601200
-----------------------------------  ---------------
2022-08-17 18:09:59 | [trpo_pendulum] epoch #501 | Saving snapshot...
2022-08-17 18:09:59 | [trpo_pendulum] epoch #501 | Saved
2022-08-17 18:09:59 | [trpo_pendulum] epoch #501 | Time 315.15 s
2022-08-17 18:09:59 | [trpo_pendulum] epoch #501 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -587.704
Evaluation/AverageReturn              -1441.94
Evaluation/Iteration                    501
Evaluation/MaxReturn                  -1432.55
Evaluation/MinReturn                  -1468.18
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     12.0164
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.63207
GaussianMLPPolicy/KL                      0.00689503
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              72.7385
GaussianMLPPolicy/LossBefore             75.0319
GaussianMLPPolicy/dLoss                   2.29331
GaussianMLPValueFunction/LossAfter        6.80558
GaussianMLPValueFunction/LossBefore       6.81138
GaussianMLPValueFunction/dLoss            0.00580359
TotalEnvSteps                        602400
-----------------------------------  ---------------
2022-08-17 18:09:59 | [trpo_pendulum] epoch #502 | Saving snapshot...
2022-08-17 18:10:00 | [trpo_pendulum] epoch #502 | Saved
2022-08-17 18:10:00 | [trpo_pendulum] epoch #502 | Time 315.78 s
2022-08-17 18:10:00 | [trpo_pendulum] epoch #502 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -644.906
Evaluation/AverageReturn              -1515.09
Evaluation/Iteration                    502
Evaluation/MaxReturn                  -1489.13
Evaluation/MinReturn                  -1544.11
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     17.4085
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.64143
GaussianMLPPolicy/KL                      0.00665744
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              77.8335
GaussianMLPPolicy/LossBefore             79.9672
GaussianMLPPolicy/dLoss                   2.13367
GaussianMLPValueFunction/LossAfter        6.84905
GaussianMLPValueFunction/LossBefore       6.85304
GaussianMLPValueFunction/dLoss            0.00398827
TotalEnvSteps                        603600
-----------------------------------  ---------------
2022-08-17 18:10:00 | [trpo_pendulum] epoch #503 | Saving snapshot...
2022-08-17 18:10:00 | [trpo_pendulum] epoch #503 | Saved
2022-08-17 18:10:00 | [trpo_pendulum] epoch #503 | Time 316.42 s
2022-08-17 18:10:00 | [trpo_pendulum] epoch #503 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -660.585
Evaluation/AverageReturn              -1532.96
Evaluation/Iteration                    503
Evaluation/MaxReturn                  -1516.24
Evaluation/MinReturn                  -1557.64
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.9437
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.63649
GaussianMLPPolicy/KL                      0.00761058
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              78.5056
GaussianMLPPolicy/LossBefore             80.4648
GaussianMLPPolicy/dLoss                   1.95923
GaussianMLPValueFunction/LossAfter        6.85855
GaussianMLPValueFunction/LossBefore       6.86258
GaussianMLPValueFunction/dLoss            0.00402737
TotalEnvSteps                        604800
-----------------------------------  ---------------
2022-08-17 18:10:01 | [trpo_pendulum] epoch #504 | Saving snapshot...
2022-08-17 18:10:01 | [trpo_pendulum] epoch #504 | Saved
2022-08-17 18:10:01 | [trpo_pendulum] epoch #504 | Time 317.05 s
2022-08-17 18:10:01 | [trpo_pendulum] epoch #504 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -589.555
Evaluation/AverageReturn              -1446.93
Evaluation/Iteration                    504
Evaluation/MaxReturn                  -1415.9
Evaluation/MinReturn                  -1472.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     22.4302
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62365
GaussianMLPPolicy/KL                      0.00815169
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              70.6421
GaussianMLPPolicy/LossBefore             73.0113
GaussianMLPPolicy/dLoss                   2.36919
GaussianMLPValueFunction/LossAfter        6.79649
GaussianMLPValueFunction/LossBefore       6.80209
GaussianMLPValueFunction/dLoss            0.00560331
TotalEnvSteps                        606000
-----------------------------------  ---------------
2022-08-17 18:10:01 | [trpo_pendulum] epoch #505 | Saving snapshot...
2022-08-17 18:10:01 | [trpo_pendulum] epoch #505 | Saved
2022-08-17 18:10:01 | [trpo_pendulum] epoch #505 | Time 317.68 s
2022-08-17 18:10:01 | [trpo_pendulum] epoch #505 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -393.29
Evaluation/AverageReturn              -1051.99
Evaluation/Iteration                    505
Evaluation/MaxReturn                   -618.234
Evaluation/MinReturn                  -1314.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    245.299
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62997
GaussianMLPPolicy/KL                      0.00696373
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              18.4484
GaussianMLPPolicy/LossBefore             20.3583
GaussianMLPPolicy/dLoss                   1.9099
GaussianMLPValueFunction/LossAfter        6.49694
GaussianMLPValueFunction/LossBefore       6.55317
GaussianMLPValueFunction/dLoss            0.056231
TotalEnvSteps                        607200
-----------------------------------  ---------------
2022-08-17 18:10:02 | [trpo_pendulum] epoch #506 | Saving snapshot...
2022-08-17 18:10:02 | [trpo_pendulum] epoch #506 | Saved
2022-08-17 18:10:02 | [trpo_pendulum] epoch #506 | Time 318.31 s
2022-08-17 18:10:02 | [trpo_pendulum] epoch #506 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -661.811
Evaluation/AverageReturn              -1527.54
Evaluation/Iteration                    506
Evaluation/MaxReturn                  -1512.33
Evaluation/MinReturn                  -1543.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     12.319
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.63839
GaussianMLPPolicy/KL                      0.00936059
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              74.6473
GaussianMLPPolicy/LossBefore             77.3397
GaussianMLPPolicy/dLoss                   2.69234
GaussianMLPValueFunction/LossAfter        6.83578
GaussianMLPValueFunction/LossBefore       6.85011
GaussianMLPValueFunction/dLoss            0.0143294
TotalEnvSteps                        608400
-----------------------------------  ---------------
2022-08-17 18:10:03 | [trpo_pendulum] epoch #507 | Saving snapshot...
2022-08-17 18:10:03 | [trpo_pendulum] epoch #507 | Saved
2022-08-17 18:10:03 | [trpo_pendulum] epoch #507 | Time 318.96 s
2022-08-17 18:10:03 | [trpo_pendulum] epoch #507 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -406.717
Evaluation/AverageReturn              -1025.21
Evaluation/Iteration                    507
Evaluation/MaxReturn                   -871.51
Evaluation/MinReturn                  -1124.94
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    105.463
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.65827
GaussianMLPPolicy/KL                      0.00758949
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              10.3273
GaussianMLPPolicy/LossBefore             12.2593
GaussianMLPPolicy/dLoss                   1.93202
GaussianMLPValueFunction/LossAfter        6.38524
GaussianMLPValueFunction/LossBefore       6.43829
GaussianMLPValueFunction/dLoss            0.0530581
TotalEnvSteps                        609600
-----------------------------------  ---------------
2022-08-17 18:10:03 | [trpo_pendulum] epoch #508 | Saving snapshot...
2022-08-17 18:10:03 | [trpo_pendulum] epoch #508 | Saved
2022-08-17 18:10:03 | [trpo_pendulum] epoch #508 | Time 319.60 s
2022-08-17 18:10:03 | [trpo_pendulum] epoch #508 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -654.911
Evaluation/AverageReturn              -1529.45
Evaluation/Iteration                    508
Evaluation/MaxReturn                  -1517.31
Evaluation/MinReturn                  -1551.69
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     12.3122
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.67247
GaussianMLPPolicy/KL                      0.00977626
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              75.8776
GaussianMLPPolicy/LossBefore             78.6261
GaussianMLPPolicy/dLoss                   2.74853
GaussianMLPValueFunction/LossAfter        6.85785
GaussianMLPValueFunction/LossBefore       6.88251
GaussianMLPValueFunction/dLoss            0.0246654
TotalEnvSteps                        610800
-----------------------------------  ---------------
2022-08-17 18:10:04 | [trpo_pendulum] epoch #509 | Saving snapshot...
2022-08-17 18:10:04 | [trpo_pendulum] epoch #509 | Saved
2022-08-17 18:10:04 | [trpo_pendulum] epoch #509 | Time 320.25 s
2022-08-17 18:10:04 | [trpo_pendulum] epoch #509 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -404.567
Evaluation/AverageReturn               -939.768
Evaluation/Iteration                    509
Evaluation/MaxReturn                   -752.523
Evaluation/MinReturn                  -1105.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    109.408
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.66957
GaussianMLPPolicy/KL                      0.00990712
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -9.65238
GaussianMLPPolicy/LossBefore             -6.67637
GaussianMLPPolicy/dLoss                   2.97601
GaussianMLPValueFunction/LossAfter        6.37301
GaussianMLPValueFunction/LossBefore       6.41167
GaussianMLPValueFunction/dLoss            0.03866
TotalEnvSteps                        612000
-----------------------------------  ---------------
2022-08-17 18:10:05 | [trpo_pendulum] epoch #510 | Saving snapshot...
2022-08-17 18:10:05 | [trpo_pendulum] epoch #510 | Saved
2022-08-17 18:10:05 | [trpo_pendulum] epoch #510 | Time 320.90 s
2022-08-17 18:10:05 | [trpo_pendulum] epoch #510 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -402.534
Evaluation/AverageReturn               -938.732
Evaluation/Iteration                    510
Evaluation/MaxReturn                   -783.67
Evaluation/MinReturn                  -1004.88
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     78.5217
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.67802
GaussianMLPPolicy/KL                      0.00661549
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -8.67525
GaussianMLPPolicy/LossBefore             -6.44516
GaussianMLPPolicy/dLoss                   2.23009
GaussianMLPValueFunction/LossAfter        6.34229
GaussianMLPValueFunction/LossBefore       6.37352
GaussianMLPValueFunction/dLoss            0.0312266
TotalEnvSteps                        613200
-----------------------------------  ---------------
2022-08-17 18:10:05 | [trpo_pendulum] epoch #511 | Saving snapshot...
2022-08-17 18:10:05 | [trpo_pendulum] epoch #511 | Saved
2022-08-17 18:10:05 | [trpo_pendulum] epoch #511 | Time 321.55 s
2022-08-17 18:10:05 | [trpo_pendulum] epoch #511 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -418.805
Evaluation/AverageReturn               -954.615
Evaluation/Iteration                    511
Evaluation/MaxReturn                   -875.623
Evaluation/MinReturn                  -1114.71
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     87.2831
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.65187
GaussianMLPPolicy/KL                      0.00768592
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -6.52549
GaussianMLPPolicy/LossBefore             -4.84565
GaussianMLPPolicy/dLoss                   1.67984
GaussianMLPValueFunction/LossAfter        6.3394
GaussianMLPValueFunction/LossBefore       6.3604
GaussianMLPValueFunction/dLoss            0.0210009
TotalEnvSteps                        614400
-----------------------------------  ---------------
2022-08-17 18:10:06 | [trpo_pendulum] epoch #512 | Saving snapshot...
2022-08-17 18:10:06 | [trpo_pendulum] epoch #512 | Saved
2022-08-17 18:10:06 | [trpo_pendulum] epoch #512 | Time 322.22 s
2022-08-17 18:10:06 | [trpo_pendulum] epoch #512 | EpochTime 0.67 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -580.577
Evaluation/AverageReturn              -1266.45
Evaluation/Iteration                    512
Evaluation/MaxReturn                  -1209.16
Evaluation/MinReturn                  -1340.28
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     52.1653
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.65742
GaussianMLPPolicy/KL                      0.00691532
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              32.347
GaussianMLPPolicy/LossBefore             35.2296
GaussianMLPPolicy/dLoss                   2.88253
GaussianMLPValueFunction/LossAfter        6.52373
GaussianMLPValueFunction/LossBefore       6.52496
GaussianMLPValueFunction/dLoss            0.00123549
TotalEnvSteps                        615600
-----------------------------------  ---------------
2022-08-17 18:10:07 | [trpo_pendulum] epoch #513 | Saving snapshot...
2022-08-17 18:10:07 | [trpo_pendulum] epoch #513 | Saved
2022-08-17 18:10:07 | [trpo_pendulum] epoch #513 | Time 322.88 s
2022-08-17 18:10:07 | [trpo_pendulum] epoch #513 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -403.178
Evaluation/AverageReturn               -951.987
Evaluation/Iteration                    513
Evaluation/MaxReturn                   -790.92
Evaluation/MinReturn                  -1066.39
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     92.0352
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.6381
GaussianMLPPolicy/KL                      0.00882097
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -5.67808
GaussianMLPPolicy/LossBefore             -4.24129
GaussianMLPPolicy/dLoss                   1.43679
GaussianMLPValueFunction/LossAfter        6.2641
GaussianMLPValueFunction/LossBefore       6.28912
GaussianMLPValueFunction/dLoss            0.0250168
TotalEnvSteps                        616800
-----------------------------------  ---------------
2022-08-17 18:10:07 | [trpo_pendulum] epoch #514 | Saving snapshot...
2022-08-17 18:10:07 | [trpo_pendulum] epoch #514 | Saved
2022-08-17 18:10:07 | [trpo_pendulum] epoch #514 | Time 323.53 s
2022-08-17 18:10:07 | [trpo_pendulum] epoch #514 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -438.57
Evaluation/AverageReturn              -1001.07
Evaluation/Iteration                    514
Evaluation/MaxReturn                   -904.698
Evaluation/MinReturn                  -1071.91
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     54.8363
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.63477
GaussianMLPPolicy/KL                      0.00670278
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.363815
GaussianMLPPolicy/LossBefore              1.50867
GaussianMLPPolicy/dLoss                   1.14485
GaussianMLPValueFunction/LossAfter        6.26718
GaussianMLPValueFunction/LossBefore       6.28377
GaussianMLPValueFunction/dLoss            0.0165901
TotalEnvSteps                        618000
-----------------------------------  ---------------
2022-08-17 18:10:08 | [trpo_pendulum] epoch #515 | Saving snapshot...
2022-08-17 18:10:08 | [trpo_pendulum] epoch #515 | Saved
2022-08-17 18:10:08 | [trpo_pendulum] epoch #515 | Time 324.19 s
2022-08-17 18:10:08 | [trpo_pendulum] epoch #515 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -413.451
Evaluation/AverageReturn               -959.476
Evaluation/Iteration                    515
Evaluation/MaxReturn                   -805.705
Evaluation/MinReturn                  -1031.35
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     85.6065
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.61369
GaussianMLPPolicy/KL                      0.00759252
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.9503
GaussianMLPPolicy/LossBefore             -3.01461
GaussianMLPPolicy/dLoss                   0.935695
GaussianMLPValueFunction/LossAfter        6.24181
GaussianMLPValueFunction/LossBefore       6.25679
GaussianMLPValueFunction/dLoss            0.0149803
TotalEnvSteps                        619200
-----------------------------------  ---------------
2022-08-17 18:10:09 | [trpo_pendulum] epoch #516 | Saving snapshot...
2022-08-17 18:10:09 | [trpo_pendulum] epoch #516 | Saved
2022-08-17 18:10:09 | [trpo_pendulum] epoch #516 | Time 324.84 s
2022-08-17 18:10:09 | [trpo_pendulum] epoch #516 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -599.474
Evaluation/AverageReturn              -1258.43
Evaluation/Iteration                    516
Evaluation/MaxReturn                  -1156.3
Evaluation/MinReturn                  -1349.41
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     65.8291
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.63712
GaussianMLPPolicy/KL                      0.00830771
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              28.7973
GaussianMLPPolicy/LossBefore             32.1171
GaussianMLPPolicy/dLoss                   3.31984
GaussianMLPValueFunction/LossAfter        6.59054
GaussianMLPValueFunction/LossBefore       6.607
GaussianMLPValueFunction/dLoss            0.016458
TotalEnvSteps                        620400
-----------------------------------  ---------------
2022-08-17 18:10:09 | [trpo_pendulum] epoch #517 | Saving snapshot...
2022-08-17 18:10:09 | [trpo_pendulum] epoch #517 | Saved
2022-08-17 18:10:09 | [trpo_pendulum] epoch #517 | Time 325.58 s
2022-08-17 18:10:09 | [trpo_pendulum] epoch #517 | EpochTime 0.74 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -510.537
Evaluation/AverageReturn              -1094.6
Evaluation/Iteration                    517
Evaluation/MaxReturn                  -1037.33
Evaluation/MinReturn                  -1164.9
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.8355
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.63161
GaussianMLPPolicy/KL                      0.0077011
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               8.87002
GaussianMLPPolicy/LossBefore             10.485
GaussianMLPPolicy/dLoss                   1.615
GaussianMLPValueFunction/LossAfter        6.34211
GaussianMLPValueFunction/LossBefore       6.34532
GaussianMLPValueFunction/dLoss            0.00320864
TotalEnvSteps                        621600
-----------------------------------  ---------------
2022-08-17 18:10:10 | [trpo_pendulum] epoch #518 | Saving snapshot...
2022-08-17 18:10:10 | [trpo_pendulum] epoch #518 | Saved
2022-08-17 18:10:10 | [trpo_pendulum] epoch #518 | Time 326.26 s
2022-08-17 18:10:10 | [trpo_pendulum] epoch #518 | EpochTime 0.67 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -512.773
Evaluation/AverageReturn              -1090.72
Evaluation/Iteration                    518
Evaluation/MaxReturn                  -1015.4
Evaluation/MinReturn                  -1193.31
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     63.2913
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62473
GaussianMLPPolicy/KL                      0.00689252
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               7.7091
GaussianMLPPolicy/LossBefore             10.1333
GaussianMLPPolicy/dLoss                   2.42422
GaussianMLPValueFunction/LossAfter        6.39909
GaussianMLPValueFunction/LossBefore       6.39971
GaussianMLPValueFunction/dLoss            0.000617981
TotalEnvSteps                        622800
-----------------------------------  ----------------
2022-08-17 18:10:11 | [trpo_pendulum] epoch #519 | Saving snapshot...
2022-08-17 18:10:11 | [trpo_pendulum] epoch #519 | Saved
2022-08-17 18:10:11 | [trpo_pendulum] epoch #519 | Time 326.95 s
2022-08-17 18:10:11 | [trpo_pendulum] epoch #519 | EpochTime 0.69 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -438.041
Evaluation/AverageReturn              -1033.64
Evaluation/Iteration                    519
Evaluation/MaxReturn                   -949.278
Evaluation/MinReturn                  -1113.23
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     53.7326
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62268
GaussianMLPPolicy/KL                      0.00990924
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              10.5418
GaussianMLPPolicy/LossBefore             11.6002
GaussianMLPPolicy/dLoss                   1.05839
GaussianMLPValueFunction/LossAfter        6.32977
GaussianMLPValueFunction/LossBefore       6.33266
GaussianMLPValueFunction/dLoss            0.00289488
TotalEnvSteps                        624000
-----------------------------------  ---------------
2022-08-17 18:10:11 | [trpo_pendulum] epoch #520 | Saving snapshot...
2022-08-17 18:10:11 | [trpo_pendulum] epoch #520 | Saved
2022-08-17 18:10:11 | [trpo_pendulum] epoch #520 | Time 327.61 s
2022-08-17 18:10:11 | [trpo_pendulum] epoch #520 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -419.588
Evaluation/AverageReturn               -978.172
Evaluation/Iteration                    520
Evaluation/MaxReturn                   -789.414
Evaluation/MinReturn                  -1056.89
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    106.419
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62318
GaussianMLPPolicy/KL                      0.00747094
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.866506
GaussianMLPPolicy/LossBefore              2.38748
GaussianMLPPolicy/dLoss                   1.52097
GaussianMLPValueFunction/LossAfter        6.32658
GaussianMLPValueFunction/LossBefore       6.32992
GaussianMLPValueFunction/dLoss            0.00333643
TotalEnvSteps                        625200
-----------------------------------  ---------------
2022-08-17 18:10:12 | [trpo_pendulum] epoch #521 | Saving snapshot...
2022-08-17 18:10:12 | [trpo_pendulum] epoch #521 | Saved
2022-08-17 18:10:12 | [trpo_pendulum] epoch #521 | Time 328.31 s
2022-08-17 18:10:12 | [trpo_pendulum] epoch #521 | EpochTime 0.70 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -466.807
Evaluation/AverageReturn              -1009.09
Evaluation/Iteration                    521
Evaluation/MaxReturn                   -870.479
Evaluation/MinReturn                  -1114.91
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     81.34
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.63356
GaussianMLPPolicy/KL                      0.00689001
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -1.367
GaussianMLPPolicy/LossBefore              1.0038
GaussianMLPPolicy/dLoss                   2.3708
GaussianMLPValueFunction/LossAfter        6.32634
GaussianMLPValueFunction/LossBefore       6.3299
GaussianMLPValueFunction/dLoss            0.00356197
TotalEnvSteps                        626400
-----------------------------------  ---------------
2022-08-17 18:10:13 | [trpo_pendulum] epoch #522 | Saving snapshot...
2022-08-17 18:10:13 | [trpo_pendulum] epoch #522 | Saved
2022-08-17 18:10:13 | [trpo_pendulum] epoch #522 | Time 329.01 s
2022-08-17 18:10:13 | [trpo_pendulum] epoch #522 | EpochTime 0.70 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -411.22
Evaluation/AverageReturn               -960.573
Evaluation/Iteration                    522
Evaluation/MaxReturn                   -754.283
Evaluation/MinReturn                  -1071.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    111.113
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.63339
GaussianMLPPolicy/KL                      0.00644613
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -2.94945
GaussianMLPPolicy/LossBefore             -1.40204
GaussianMLPPolicy/dLoss                   1.54741
GaussianMLPValueFunction/LossAfter        6.23914
GaussianMLPValueFunction/LossBefore       6.24786
GaussianMLPValueFunction/dLoss            0.00872898
TotalEnvSteps                        627600
-----------------------------------  ---------------
2022-08-17 18:10:13 | [trpo_pendulum] epoch #523 | Saving snapshot...
2022-08-17 18:10:13 | [trpo_pendulum] epoch #523 | Saved
2022-08-17 18:10:13 | [trpo_pendulum] epoch #523 | Time 329.67 s
2022-08-17 18:10:13 | [trpo_pendulum] epoch #523 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -459.085
Evaluation/AverageReturn              -1009.03
Evaluation/Iteration                    523
Evaluation/MaxReturn                   -926.609
Evaluation/MinReturn                  -1038.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     38.5351
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.63596
GaussianMLPPolicy/KL                      0.00915042
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               1.88801
GaussianMLPPolicy/LossBefore              3.14263
GaussianMLPPolicy/dLoss                   1.25462
GaussianMLPValueFunction/LossAfter        6.26014
GaussianMLPValueFunction/LossBefore       6.26423
GaussianMLPValueFunction/dLoss            0.00408697
TotalEnvSteps                        628800
-----------------------------------  ---------------
2022-08-17 18:10:14 | [trpo_pendulum] epoch #524 | Saving snapshot...
2022-08-17 18:10:14 | [trpo_pendulum] epoch #524 | Saved
2022-08-17 18:10:14 | [trpo_pendulum] epoch #524 | Time 330.31 s
2022-08-17 18:10:14 | [trpo_pendulum] epoch #524 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -397.437
Evaluation/AverageReturn               -911.88
Evaluation/Iteration                    524
Evaluation/MaxReturn                   -773.344
Evaluation/MinReturn                  -1075.17
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     89.8165
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.61075
GaussianMLPPolicy/KL                      0.00710651
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -8.81849
GaussianMLPPolicy/LossBefore             -7.15232
GaussianMLPPolicy/dLoss                   1.66618
GaussianMLPValueFunction/LossAfter        6.26142
GaussianMLPValueFunction/LossBefore       6.26744
GaussianMLPValueFunction/dLoss            0.00602102
TotalEnvSteps                        630000
-----------------------------------  ---------------
2022-08-17 18:10:15 | [trpo_pendulum] epoch #525 | Saving snapshot...
2022-08-17 18:10:15 | [trpo_pendulum] epoch #525 | Saved
2022-08-17 18:10:15 | [trpo_pendulum] epoch #525 | Time 330.95 s
2022-08-17 18:10:15 | [trpo_pendulum] epoch #525 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -660.57
Evaluation/AverageReturn              -1513.03
Evaluation/Iteration                    525
Evaluation/MaxReturn                  -1502.88
Evaluation/MinReturn                  -1529.5
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.57383
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.63614
GaussianMLPPolicy/KL                      0.00812061
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              76.8887
GaussianMLPPolicy/LossBefore             78.0398
GaussianMLPPolicy/dLoss                   1.1511
GaussianMLPValueFunction/LossAfter        7.0243
GaussianMLPValueFunction/LossBefore       7.2537
GaussianMLPValueFunction/dLoss            0.229399
TotalEnvSteps                        631200
-----------------------------------  ---------------
2022-08-17 18:10:15 | [trpo_pendulum] epoch #526 | Saving snapshot...
2022-08-17 18:10:15 | [trpo_pendulum] epoch #526 | Saved
2022-08-17 18:10:15 | [trpo_pendulum] epoch #526 | Time 331.60 s
2022-08-17 18:10:15 | [trpo_pendulum] epoch #526 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -676.907
Evaluation/AverageReturn              -1563.91
Evaluation/Iteration                    526
Evaluation/MaxReturn                  -1503
Evaluation/MinReturn                  -1644.9
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.2276
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.62674
GaussianMLPPolicy/KL                      0.00975253
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              83.4988
GaussianMLPPolicy/LossBefore             86.3733
GaussianMLPPolicy/dLoss                   2.87453
GaussianMLPValueFunction/LossAfter        7.13491
GaussianMLPValueFunction/LossBefore       7.27931
GaussianMLPValueFunction/dLoss            0.144403
TotalEnvSteps                        632400
-----------------------------------  ---------------
2022-08-17 18:10:16 | [trpo_pendulum] epoch #527 | Saving snapshot...
2022-08-17 18:10:16 | [trpo_pendulum] epoch #527 | Saved
2022-08-17 18:10:16 | [trpo_pendulum] epoch #527 | Time 332.24 s
2022-08-17 18:10:16 | [trpo_pendulum] epoch #527 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -212.391
Evaluation/AverageReturn               -665.554
Evaluation/Iteration                    527
Evaluation/MaxReturn                   -396.099
Evaluation/MinReturn                   -863.096
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    160.118
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.61144
GaussianMLPPolicy/KL                      0.00718585
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -32.6574
GaussianMLPPolicy/LossBefore            -30.7523
GaussianMLPPolicy/dLoss                   1.90515
GaussianMLPValueFunction/LossAfter        6.35453
GaussianMLPValueFunction/LossBefore       6.36162
GaussianMLPValueFunction/dLoss            0.00709295
TotalEnvSteps                        633600
-----------------------------------  ---------------
2022-08-17 18:10:17 | [trpo_pendulum] epoch #528 | Saving snapshot...
2022-08-17 18:10:17 | [trpo_pendulum] epoch #528 | Saved
2022-08-17 18:10:17 | [trpo_pendulum] epoch #528 | Time 332.92 s
2022-08-17 18:10:17 | [trpo_pendulum] epoch #528 | EpochTime 0.68 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -468.13
Evaluation/AverageReturn              -1108.14
Evaluation/Iteration                    528
Evaluation/MaxReturn                  -1061.82
Evaluation/MinReturn                  -1133.01
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     23.4968
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.59699
GaussianMLPPolicy/KL                      0.00708366
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              19.5717
GaussianMLPPolicy/LossBefore             21.683
GaussianMLPPolicy/dLoss                   2.11125
GaussianMLPValueFunction/LossAfter        6.33481
GaussianMLPValueFunction/LossBefore       6.34094
GaussianMLPValueFunction/dLoss            0.00612688
TotalEnvSteps                        634800
-----------------------------------  ---------------
2022-08-17 18:10:17 | [trpo_pendulum] epoch #529 | Saving snapshot...
2022-08-17 18:10:17 | [trpo_pendulum] epoch #529 | Saved
2022-08-17 18:10:17 | [trpo_pendulum] epoch #529 | Time 333.54 s
2022-08-17 18:10:17 | [trpo_pendulum] epoch #529 | EpochTime 0.62 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -457.512
Evaluation/AverageReturn              -1078.48
Evaluation/Iteration                    529
Evaluation/MaxReturn                   -744.555
Evaluation/MinReturn                  -1408.09
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    207.725
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.58
GaussianMLPPolicy/KL                      0.00867666
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              15.1297
GaussianMLPPolicy/LossBefore             17.6621
GaussianMLPPolicy/dLoss                   2.53241
GaussianMLPValueFunction/LossAfter        6.46151
GaussianMLPValueFunction/LossBefore       6.4617
GaussianMLPValueFunction/dLoss            0.000189781
TotalEnvSteps                        636000
-----------------------------------  ----------------
2022-08-17 18:10:18 | [trpo_pendulum] epoch #530 | Saving snapshot...
2022-08-17 18:10:18 | [trpo_pendulum] epoch #530 | Saved
2022-08-17 18:10:18 | [trpo_pendulum] epoch #530 | Time 334.17 s
2022-08-17 18:10:18 | [trpo_pendulum] epoch #530 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -665.191
Evaluation/AverageReturn              -1524.63
Evaluation/Iteration                    530
Evaluation/MaxReturn                  -1517.62
Evaluation/MinReturn                  -1530.82
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      4.54515
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.63685
GaussianMLPPolicy/KL                      0.0093164
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              75.1382
GaussianMLPPolicy/LossBefore             77.1379
GaussianMLPPolicy/dLoss                   1.99966
GaussianMLPValueFunction/LossAfter        6.91672
GaussianMLPValueFunction/LossBefore       6.97753
GaussianMLPValueFunction/dLoss            0.0608044
TotalEnvSteps                        637200
-----------------------------------  --------------
2022-08-17 18:10:19 | [trpo_pendulum] epoch #531 | Saving snapshot...
2022-08-17 18:10:19 | [trpo_pendulum] epoch #531 | Saved
2022-08-17 18:10:19 | [trpo_pendulum] epoch #531 | Time 334.80 s
2022-08-17 18:10:19 | [trpo_pendulum] epoch #531 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -527.438
Evaluation/AverageReturn              -1314.15
Evaluation/Iteration                    531
Evaluation/MaxReturn                  -1125.36
Evaluation/MinReturn                  -1443.3
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    102.35
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.65264
GaussianMLPPolicy/KL                      0.00634875
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              51.6072
GaussianMLPPolicy/LossBefore             54.1655
GaussianMLPPolicy/dLoss                   2.55827
GaussianMLPValueFunction/LossAfter        6.63202
GaussianMLPValueFunction/LossBefore       6.63932
GaussianMLPValueFunction/dLoss            0.00729656
TotalEnvSteps                        638400
-----------------------------------  ---------------
2022-08-17 18:10:19 | [trpo_pendulum] epoch #532 | Saving snapshot...
2022-08-17 18:10:19 | [trpo_pendulum] epoch #532 | Saved
2022-08-17 18:10:19 | [trpo_pendulum] epoch #532 | Time 335.45 s
2022-08-17 18:10:19 | [trpo_pendulum] epoch #532 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -561.802
Evaluation/AverageReturn              -1385.55
Evaluation/Iteration                    532
Evaluation/MaxReturn                  -1131.58
Evaluation/MinReturn                  -1508.98
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    126.715
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.64819
GaussianMLPPolicy/KL                      0.00670951
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              59.7752
GaussianMLPPolicy/LossBefore             62.3206
GaussianMLPPolicy/dLoss                   2.54541
GaussianMLPValueFunction/LossAfter        6.71826
GaussianMLPValueFunction/LossBefore       6.73187
GaussianMLPValueFunction/dLoss            0.0136161
TotalEnvSteps                        639600
-----------------------------------  ---------------
2022-08-17 18:10:20 | [trpo_pendulum] epoch #533 | Saving snapshot...
2022-08-17 18:10:20 | [trpo_pendulum] epoch #533 | Saved
2022-08-17 18:10:20 | [trpo_pendulum] epoch #533 | Time 336.10 s
2022-08-17 18:10:20 | [trpo_pendulum] epoch #533 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -550.184
Evaluation/AverageReturn              -1355.33
Evaluation/Iteration                    533
Evaluation/MaxReturn                  -1303.81
Evaluation/MinReturn                  -1460.47
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     51.8559
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.65974
GaussianMLPPolicy/KL                      0.00665832
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              55.0844
GaussianMLPPolicy/LossBefore             57.3806
GaussianMLPPolicy/dLoss                   2.29628
GaussianMLPValueFunction/LossAfter        6.63657
GaussianMLPValueFunction/LossBefore       6.64229
GaussianMLPValueFunction/dLoss            0.00571823
TotalEnvSteps                        640800
-----------------------------------  ---------------
2022-08-17 18:10:20 | [trpo_pendulum] epoch #534 | Saving snapshot...
2022-08-17 18:10:21 | [trpo_pendulum] epoch #534 | Saved
2022-08-17 18:10:21 | [trpo_pendulum] epoch #534 | Time 336.79 s
2022-08-17 18:10:21 | [trpo_pendulum] epoch #534 | EpochTime 0.69 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -656.04
Evaluation/AverageReturn              -1517.82
Evaluation/Iteration                    534
Evaluation/MaxReturn                  -1508.67
Evaluation/MinReturn                  -1528.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      6.76817
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.67701
GaussianMLPPolicy/KL                      0.00943428
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              73.7847
GaussianMLPPolicy/LossBefore             74.7607
GaussianMLPPolicy/dLoss                   0.975967
GaussianMLPValueFunction/LossAfter        6.85332
GaussianMLPValueFunction/LossBefore       6.88222
GaussianMLPValueFunction/dLoss            0.0288997
TotalEnvSteps                        642000
-----------------------------------  ---------------
2022-08-17 18:10:21 | [trpo_pendulum] epoch #535 | Saving snapshot...
2022-08-17 18:10:21 | [trpo_pendulum] epoch #535 | Saved
2022-08-17 18:10:21 | [trpo_pendulum] epoch #535 | Time 337.42 s
2022-08-17 18:10:21 | [trpo_pendulum] epoch #535 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -356.071
Evaluation/AverageReturn               -936.372
Evaluation/Iteration                    535
Evaluation/MaxReturn                   -714.993
Evaluation/MinReturn                  -1132.86
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    165.493
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.68397
GaussianMLPPolicy/KL                      0.00911271
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.87283
GaussianMLPPolicy/LossBefore              0.523197
GaussianMLPPolicy/dLoss                   1.39603
GaussianMLPValueFunction/LossAfter        6.34554
GaussianMLPValueFunction/LossBefore       6.36564
GaussianMLPValueFunction/dLoss            0.020102
TotalEnvSteps                        643200
-----------------------------------  ---------------
2022-08-17 18:10:22 | [trpo_pendulum] epoch #536 | Saving snapshot...
2022-08-17 18:10:22 | [trpo_pendulum] epoch #536 | Saved
2022-08-17 18:10:22 | [trpo_pendulum] epoch #536 | Time 338.06 s
2022-08-17 18:10:22 | [trpo_pendulum] epoch #536 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -456.682
Evaluation/AverageReturn              -1079.07
Evaluation/Iteration                    536
Evaluation/MaxReturn                  -1000.28
Evaluation/MinReturn                  -1156.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     53.9993
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.71705
GaussianMLPPolicy/KL                      0.00711102
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              11.7564
GaussianMLPPolicy/LossBefore             13.2546
GaussianMLPPolicy/dLoss                   1.49812
GaussianMLPValueFunction/LossAfter        6.34116
GaussianMLPValueFunction/LossBefore       6.35807
GaussianMLPValueFunction/dLoss            0.0169096
TotalEnvSteps                        644400
-----------------------------------  ---------------
2022-08-17 18:10:22 | [trpo_pendulum] epoch #537 | Saving snapshot...
2022-08-17 18:10:22 | [trpo_pendulum] epoch #537 | Saved
2022-08-17 18:10:22 | [trpo_pendulum] epoch #537 | Time 338.72 s
2022-08-17 18:10:22 | [trpo_pendulum] epoch #537 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -474.579
Evaluation/AverageReturn              -1074.45
Evaluation/Iteration                    537
Evaluation/MaxReturn                   -905.195
Evaluation/MinReturn                  -1165.82
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     88.1813
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.73108
GaussianMLPPolicy/KL                      0.00682137
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               6.64967
GaussianMLPPolicy/LossBefore              8.61953
GaussianMLPPolicy/dLoss                   1.96986
GaussianMLPValueFunction/LossAfter        6.29371
GaussianMLPValueFunction/LossBefore       6.31215
GaussianMLPValueFunction/dLoss            0.0184402
TotalEnvSteps                        645600
-----------------------------------  ---------------
2022-08-17 18:10:23 | [trpo_pendulum] epoch #538 | Saving snapshot...
2022-08-17 18:10:23 | [trpo_pendulum] epoch #538 | Saved
2022-08-17 18:10:23 | [trpo_pendulum] epoch #538 | Time 339.40 s
2022-08-17 18:10:23 | [trpo_pendulum] epoch #538 | EpochTime 0.67 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -462.182
Evaluation/AverageReturn              -1133.44
Evaluation/Iteration                    538
Evaluation/MaxReturn                  -1055.36
Evaluation/MinReturn                  -1188.97
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     51.0838
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.73825
GaussianMLPPolicy/KL                      0.00839463
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              22.6551
GaussianMLPPolicy/LossBefore             24.2425
GaussianMLPPolicy/dLoss                   1.58739
GaussianMLPValueFunction/LossAfter        6.38381
GaussianMLPValueFunction/LossBefore       6.38922
GaussianMLPValueFunction/dLoss            0.00541544
TotalEnvSteps                        646800
-----------------------------------  ---------------
2022-08-17 18:10:24 | [trpo_pendulum] epoch #539 | Saving snapshot...
2022-08-17 18:10:24 | [trpo_pendulum] epoch #539 | Saved
2022-08-17 18:10:24 | [trpo_pendulum] epoch #539 | Time 340.08 s
2022-08-17 18:10:24 | [trpo_pendulum] epoch #539 | EpochTime 0.68 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -658.111
Evaluation/AverageReturn              -1518.77
Evaluation/Iteration                    539
Evaluation/MaxReturn                  -1512.05
Evaluation/MinReturn                  -1526.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.25739
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.77862
GaussianMLPPolicy/KL                      0.00742717
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              72.4116
GaussianMLPPolicy/LossBefore             73.4589
GaussianMLPPolicy/dLoss                   1.04729
GaussianMLPValueFunction/LossAfter        6.87355
GaussianMLPValueFunction/LossBefore       6.93467
GaussianMLPValueFunction/dLoss            0.0611157
TotalEnvSteps                        648000
-----------------------------------  ---------------
2022-08-17 18:10:24 | [trpo_pendulum] epoch #540 | Saving snapshot...
2022-08-17 18:10:24 | [trpo_pendulum] epoch #540 | Saved
2022-08-17 18:10:24 | [trpo_pendulum] epoch #540 | Time 340.72 s
2022-08-17 18:10:24 | [trpo_pendulum] epoch #540 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -544.734
Evaluation/AverageReturn              -1291.37
Evaluation/Iteration                    540
Evaluation/MaxReturn                  -1216.08
Evaluation/MinReturn                  -1339.53
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     38.0642
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.79023
GaussianMLPPolicy/KL                      0.00661507
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              41.1296
GaussianMLPPolicy/LossBefore             42.7008
GaussianMLPPolicy/dLoss                   1.57114
GaussianMLPValueFunction/LossAfter        6.50794
GaussianMLPValueFunction/LossBefore       6.51084
GaussianMLPValueFunction/dLoss            0.0028944
TotalEnvSteps                        649200
-----------------------------------  ---------------
2022-08-17 18:10:25 | [trpo_pendulum] epoch #541 | Saving snapshot...
2022-08-17 18:10:25 | [trpo_pendulum] epoch #541 | Saved
2022-08-17 18:10:25 | [trpo_pendulum] epoch #541 | Time 341.35 s
2022-08-17 18:10:25 | [trpo_pendulum] epoch #541 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -547.689
Evaluation/AverageReturn              -1325.64
Evaluation/Iteration                    541
Evaluation/MaxReturn                  -1296.09
Evaluation/MinReturn                  -1342.68
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.2183
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.78654
GaussianMLPPolicy/KL                      0.00931673
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              49.5389
GaussianMLPPolicy/LossBefore             50.2953
GaussianMLPPolicy/dLoss                   0.756393
GaussianMLPValueFunction/LossAfter        6.59271
GaussianMLPValueFunction/LossBefore       6.59712
GaussianMLPValueFunction/dLoss            0.00441217
TotalEnvSteps                        650400
-----------------------------------  ---------------
2022-08-17 18:10:26 | [trpo_pendulum] epoch #542 | Saving snapshot...
2022-08-17 18:10:26 | [trpo_pendulum] epoch #542 | Saved
2022-08-17 18:10:26 | [trpo_pendulum] epoch #542 | Time 341.98 s
2022-08-17 18:10:26 | [trpo_pendulum] epoch #542 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -431.644
Evaluation/AverageReturn              -1078.57
Evaluation/Iteration                    542
Evaluation/MaxReturn                  -1017.38
Evaluation/MinReturn                  -1214.58
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     65.3793
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.82454
GaussianMLPPolicy/KL                      0.00816794
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              13.878
GaussianMLPPolicy/LossBefore             16.1627
GaussianMLPPolicy/dLoss                   2.28466
GaussianMLPValueFunction/LossAfter        6.37739
GaussianMLPValueFunction/LossBefore       6.3874
GaussianMLPValueFunction/dLoss            0.0100169
TotalEnvSteps                        651600
-----------------------------------  ---------------
2022-08-17 18:10:26 | [trpo_pendulum] epoch #543 | Saving snapshot...
2022-08-17 18:10:26 | [trpo_pendulum] epoch #543 | Saved
2022-08-17 18:10:26 | [trpo_pendulum] epoch #543 | Time 342.61 s
2022-08-17 18:10:26 | [trpo_pendulum] epoch #543 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -448.298
Evaluation/AverageReturn              -1064.06
Evaluation/Iteration                    543
Evaluation/MaxReturn                   -913.995
Evaluation/MinReturn                  -1303.61
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    117.121
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.82727
GaussianMLPPolicy/KL                      0.00846377
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               8.09107
GaussianMLPPolicy/LossBefore              9.56413
GaussianMLPPolicy/dLoss                   1.47307
GaussianMLPValueFunction/LossAfter        6.36812
GaussianMLPValueFunction/LossBefore       6.37649
GaussianMLPValueFunction/dLoss            0.0083704
TotalEnvSteps                        652800
-----------------------------------  ---------------
2022-08-17 18:10:27 | [trpo_pendulum] epoch #544 | Saving snapshot...
2022-08-17 18:10:27 | [trpo_pendulum] epoch #544 | Saved
2022-08-17 18:10:27 | [trpo_pendulum] epoch #544 | Time 343.25 s
2022-08-17 18:10:27 | [trpo_pendulum] epoch #544 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -544.382
Evaluation/AverageReturn              -1342.12
Evaluation/Iteration                    544
Evaluation/MaxReturn                  -1317.61
Evaluation/MinReturn                  -1367.52
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     15.3619
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.80931
GaussianMLPPolicy/KL                      0.00536022
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              52.2737
GaussianMLPPolicy/LossBefore             53.4787
GaussianMLPPolicy/dLoss                   1.20497
GaussianMLPValueFunction/LossAfter        6.65234
GaussianMLPValueFunction/LossBefore       6.66795
GaussianMLPValueFunction/dLoss            0.0156069
TotalEnvSteps                        654000
-----------------------------------  ---------------
2022-08-17 18:10:28 | [trpo_pendulum] epoch #545 | Saving snapshot...
2022-08-17 18:10:28 | [trpo_pendulum] epoch #545 | Saved
2022-08-17 18:10:28 | [trpo_pendulum] epoch #545 | Time 343.90 s
2022-08-17 18:10:28 | [trpo_pendulum] epoch #545 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -513.663
Evaluation/AverageReturn              -1285.93
Evaluation/Iteration                    545
Evaluation/MaxReturn                  -1175.09
Evaluation/MinReturn                  -1345.68
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     53.5083
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.78931
GaussianMLPPolicy/KL                      0.00603104
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              44.9995
GaussianMLPPolicy/LossBefore             46.4633
GaussianMLPPolicy/dLoss                   1.46385
GaussianMLPValueFunction/LossAfter        6.55957
GaussianMLPValueFunction/LossBefore       6.56396
GaussianMLPValueFunction/dLoss            0.00439119
TotalEnvSteps                        655200
-----------------------------------  ---------------
2022-08-17 18:10:28 | [trpo_pendulum] epoch #546 | Saving snapshot...
2022-08-17 18:10:28 | [trpo_pendulum] epoch #546 | Saved
2022-08-17 18:10:28 | [trpo_pendulum] epoch #546 | Time 344.55 s
2022-08-17 18:10:28 | [trpo_pendulum] epoch #546 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -679.829
Evaluation/AverageReturn              -1565.4
Evaluation/Iteration                    546
Evaluation/MaxReturn                  -1535.48
Evaluation/MinReturn                  -1592.46
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     18.9111
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.79176
GaussianMLPPolicy/KL                      0.00762296
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              75.0665
GaussianMLPPolicy/LossBefore             76.0229
GaussianMLPPolicy/dLoss                   0.956375
GaussianMLPValueFunction/LossAfter        6.89384
GaussianMLPValueFunction/LossBefore       6.95693
GaussianMLPValueFunction/dLoss            0.0630946
TotalEnvSteps                        656400
-----------------------------------  ---------------
2022-08-17 18:10:29 | [trpo_pendulum] epoch #547 | Saving snapshot...
2022-08-17 18:10:29 | [trpo_pendulum] epoch #547 | Saved
2022-08-17 18:10:29 | [trpo_pendulum] epoch #547 | Time 345.21 s
2022-08-17 18:10:29 | [trpo_pendulum] epoch #547 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -675.875
Evaluation/AverageReturn              -1556.88
Evaluation/Iteration                    547
Evaluation/MaxReturn                  -1545.43
Evaluation/MinReturn                  -1569.03
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      7.90699
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.78628
GaussianMLPPolicy/KL                      0.00806998
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              72.3527
GaussianMLPPolicy/LossBefore             73.8484
GaussianMLPPolicy/dLoss                   1.49566
GaussianMLPValueFunction/LossAfter        6.84819
GaussianMLPValueFunction/LossBefore       6.87659
GaussianMLPValueFunction/dLoss            0.0283942
TotalEnvSteps                        657600
-----------------------------------  ---------------
2022-08-17 18:10:30 | [trpo_pendulum] epoch #548 | Saving snapshot...
2022-08-17 18:10:30 | [trpo_pendulum] epoch #548 | Saved
2022-08-17 18:10:30 | [trpo_pendulum] epoch #548 | Time 345.88 s
2022-08-17 18:10:30 | [trpo_pendulum] epoch #548 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -628.801
Evaluation/AverageReturn              -1501.07
Evaluation/Iteration                    548
Evaluation/MaxReturn                  -1464.24
Evaluation/MinReturn                  -1535.18
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     20.782
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.7947
GaussianMLPPolicy/KL                      0.00928394
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              68.947
GaussianMLPPolicy/LossBefore             70.3685
GaussianMLPPolicy/dLoss                   1.42151
GaussianMLPValueFunction/LossAfter        6.81098
GaussianMLPValueFunction/LossBefore       6.82488
GaussianMLPValueFunction/dLoss            0.0139012
TotalEnvSteps                        658800
-----------------------------------  ---------------
2022-08-17 18:10:30 | [trpo_pendulum] epoch #549 | Saving snapshot...
2022-08-17 18:10:30 | [trpo_pendulum] epoch #549 | Saved
2022-08-17 18:10:30 | [trpo_pendulum] epoch #549 | Time 346.52 s
2022-08-17 18:10:30 | [trpo_pendulum] epoch #549 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -617.794
Evaluation/AverageReturn              -1457.86
Evaluation/Iteration                    549
Evaluation/MaxReturn                  -1408.08
Evaluation/MinReturn                  -1498.06
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     37.5593
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.78792
GaussianMLPPolicy/KL                      0.00594617
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              62.2966
GaussianMLPPolicy/LossBefore             62.3302
GaussianMLPPolicy/dLoss                   0.0335922
GaussianMLPValueFunction/LossAfter        6.73482
GaussianMLPValueFunction/LossBefore       6.73895
GaussianMLPValueFunction/dLoss            0.00413036
TotalEnvSteps                        660000
-----------------------------------  ---------------
2022-08-17 18:10:31 | [trpo_pendulum] epoch #550 | Saving snapshot...
2022-08-17 18:10:31 | [trpo_pendulum] epoch #550 | Saved
2022-08-17 18:10:31 | [trpo_pendulum] epoch #550 | Time 347.18 s
2022-08-17 18:10:31 | [trpo_pendulum] epoch #550 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -639.92
Evaluation/AverageReturn              -1467.91
Evaluation/Iteration                    550
Evaluation/MaxReturn                  -1355.86
Evaluation/MinReturn                  -1573.18
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     88.0579
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.80281
GaussianMLPPolicy/KL                      0.00690158
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              55.5329
GaussianMLPPolicy/LossBefore             57.9836
GaussianMLPPolicy/dLoss                   2.45073
GaussianMLPValueFunction/LossAfter        6.69442
GaussianMLPValueFunction/LossBefore       6.69724
GaussianMLPValueFunction/dLoss            0.00281477
TotalEnvSteps                        661200
-----------------------------------  ---------------
2022-08-17 18:10:32 | [trpo_pendulum] epoch #551 | Saving snapshot...
2022-08-17 18:10:32 | [trpo_pendulum] epoch #551 | Saved
2022-08-17 18:10:32 | [trpo_pendulum] epoch #551 | Time 347.82 s
2022-08-17 18:10:32 | [trpo_pendulum] epoch #551 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -670.504
Evaluation/AverageReturn              -1515.94
Evaluation/Iteration                    551
Evaluation/MaxReturn                  -1420.27
Evaluation/MinReturn                  -1562.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     47.7002
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.79472
GaussianMLPPolicy/KL                      0.0090231
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              59.704
GaussianMLPPolicy/LossBefore             63.2772
GaussianMLPPolicy/dLoss                   3.57315
GaussianMLPValueFunction/LossAfter        6.75113
GaussianMLPValueFunction/LossBefore       6.75563
GaussianMLPValueFunction/dLoss            0.00449657
TotalEnvSteps                        662400
-----------------------------------  ---------------
2022-08-17 18:10:32 | [trpo_pendulum] epoch #552 | Saving snapshot...
2022-08-17 18:10:32 | [trpo_pendulum] epoch #552 | Saved
2022-08-17 18:10:32 | [trpo_pendulum] epoch #552 | Time 348.47 s
2022-08-17 18:10:32 | [trpo_pendulum] epoch #552 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -673.601
Evaluation/AverageReturn              -1517.58
Evaluation/Iteration                    552
Evaluation/MaxReturn                  -1361.99
Evaluation/MinReturn                  -1609.71
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     84.2309
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.8059
GaussianMLPPolicy/KL                      0.00674311
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              61.1408
GaussianMLPPolicy/LossBefore             63.1795
GaussianMLPPolicy/dLoss                   2.03863
GaussianMLPValueFunction/LossAfter        6.76435
GaussianMLPValueFunction/LossBefore       6.76874
GaussianMLPValueFunction/dLoss            0.00438976
TotalEnvSteps                        663600
-----------------------------------  ---------------
2022-08-17 18:10:33 | [trpo_pendulum] epoch #553 | Saving snapshot...
2022-08-17 18:10:33 | [trpo_pendulum] epoch #553 | Saved
2022-08-17 18:10:33 | [trpo_pendulum] epoch #553 | Time 349.14 s
2022-08-17 18:10:33 | [trpo_pendulum] epoch #553 | EpochTime 0.67 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -555.248
Evaluation/AverageReturn              -1354.07
Evaluation/Iteration                    553
Evaluation/MaxReturn                  -1309.58
Evaluation/MinReturn                  -1402.46
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     33.3141
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.80494
GaussianMLPPolicy/KL                      0.00578046
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              43.2371
GaussianMLPPolicy/LossBefore             45.0164
GaussianMLPPolicy/dLoss                   1.77929
GaussianMLPValueFunction/LossAfter        6.57126
GaussianMLPValueFunction/LossBefore       6.58294
GaussianMLPValueFunction/dLoss            0.011683
TotalEnvSteps                        664800
-----------------------------------  ---------------
2022-08-17 18:10:33 | [trpo_pendulum] epoch #554 | Saving snapshot...
2022-08-17 18:10:34 | [trpo_pendulum] epoch #554 | Saved
2022-08-17 18:10:34 | [trpo_pendulum] epoch #554 | Time 349.79 s
2022-08-17 18:10:34 | [trpo_pendulum] epoch #554 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -557.803
Evaluation/AverageReturn              -1380.07
Evaluation/Iteration                    554
Evaluation/MaxReturn                  -1358.38
Evaluation/MinReturn                  -1409.23
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     22.0116
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.81999
GaussianMLPPolicy/KL                      0.00748273
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              53.3932
GaussianMLPPolicy/LossBefore             53.9277
GaussianMLPPolicy/dLoss                   0.534489
GaussianMLPValueFunction/LossAfter        6.687
GaussianMLPValueFunction/LossBefore       6.68972
GaussianMLPValueFunction/dLoss            0.00272512
TotalEnvSteps                        666000
-----------------------------------  ---------------
2022-08-17 18:10:34 | [trpo_pendulum] epoch #555 | Saving snapshot...
2022-08-17 18:10:34 | [trpo_pendulum] epoch #555 | Saved
2022-08-17 18:10:34 | [trpo_pendulum] epoch #555 | Time 350.41 s
2022-08-17 18:10:34 | [trpo_pendulum] epoch #555 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -584.96
Evaluation/AverageReturn              -1437.87
Evaluation/Iteration                    555
Evaluation/MaxReturn                  -1367.69
Evaluation/MinReturn                  -1495.64
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     40.4582
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.82881
GaussianMLPPolicy/KL                      0.00587917
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              58.64
GaussianMLPPolicy/LossBefore             59.3267
GaussianMLPPolicy/dLoss                   0.68668
GaussianMLPValueFunction/LossAfter        6.71119
GaussianMLPValueFunction/LossBefore       6.7153
GaussianMLPValueFunction/dLoss            0.004107
TotalEnvSteps                        667200
-----------------------------------  ---------------
2022-08-17 18:10:35 | [trpo_pendulum] epoch #556 | Saving snapshot...
2022-08-17 18:10:35 | [trpo_pendulum] epoch #556 | Saved
2022-08-17 18:10:35 | [trpo_pendulum] epoch #556 | Time 351.06 s
2022-08-17 18:10:35 | [trpo_pendulum] epoch #556 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -657.465
Evaluation/AverageReturn              -1494.85
Evaluation/Iteration                    556
Evaluation/MaxReturn                  -1385.4
Evaluation/MinReturn                  -1606.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     77.7054
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.84159
GaussianMLPPolicy/KL                      0.00744466
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              55.5013
GaussianMLPPolicy/LossBefore             58.8304
GaussianMLPPolicy/dLoss                   3.32911
GaussianMLPValueFunction/LossAfter        6.73202
GaussianMLPValueFunction/LossBefore       6.73585
GaussianMLPValueFunction/dLoss            0.00383091
TotalEnvSteps                        668400
-----------------------------------  ---------------
2022-08-17 18:10:35 | [trpo_pendulum] epoch #557 | Saving snapshot...
2022-08-17 18:10:35 | [trpo_pendulum] epoch #557 | Saved
2022-08-17 18:10:35 | [trpo_pendulum] epoch #557 | Time 351.68 s
2022-08-17 18:10:35 | [trpo_pendulum] epoch #557 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -533.778
Evaluation/AverageReturn              -1299.05
Evaluation/Iteration                    557
Evaluation/MaxReturn                  -1217.46
Evaluation/MinReturn                  -1343.51
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     47.2733
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.84291
GaussianMLPPolicy/KL                      0.00906056
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              36.1144
GaussianMLPPolicy/LossBefore             36.2636
GaussianMLPPolicy/dLoss                   0.149235
GaussianMLPValueFunction/LossAfter        6.54082
GaussianMLPValueFunction/LossBefore       6.5551
GaussianMLPValueFunction/dLoss            0.0142856
TotalEnvSteps                        669600
-----------------------------------  ---------------
2022-08-17 18:10:36 | [trpo_pendulum] epoch #558 | Saving snapshot...
2022-08-17 18:10:36 | [trpo_pendulum] epoch #558 | Saved
2022-08-17 18:10:36 | [trpo_pendulum] epoch #558 | Time 352.33 s
2022-08-17 18:10:36 | [trpo_pendulum] epoch #558 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -515.26
Evaluation/AverageReturn              -1253.66
Evaluation/Iteration                    558
Evaluation/MaxReturn                  -1187.31
Evaluation/MinReturn                  -1351.6
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     55.3155
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.82952
GaussianMLPPolicy/KL                      0.00725528
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              30.2316
GaussianMLPPolicy/LossBefore             31.3554
GaussianMLPPolicy/dLoss                   1.12382
GaussianMLPValueFunction/LossAfter        6.52533
GaussianMLPValueFunction/LossBefore       6.53483
GaussianMLPValueFunction/dLoss            0.00950575
TotalEnvSteps                        670800
-----------------------------------  ---------------
2022-08-17 18:10:37 | [trpo_pendulum] epoch #559 | Saving snapshot...
2022-08-17 18:10:37 | [trpo_pendulum] epoch #559 | Saved
2022-08-17 18:10:37 | [trpo_pendulum] epoch #559 | Time 352.95 s
2022-08-17 18:10:37 | [trpo_pendulum] epoch #559 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -497.629
Evaluation/AverageReturn              -1204.25
Evaluation/Iteration                    559
Evaluation/MaxReturn                  -1122.31
Evaluation/MinReturn                  -1316.45
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     60.1969
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.82389
GaussianMLPPolicy/KL                      0.00841726
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              19.1428
GaussianMLPPolicy/LossBefore             20.616
GaussianMLPPolicy/dLoss                   1.47314
GaussianMLPValueFunction/LossAfter        6.44827
GaussianMLPValueFunction/LossBefore       6.4623
GaussianMLPValueFunction/dLoss            0.01403
TotalEnvSteps                        672000
-----------------------------------  ---------------
2022-08-17 18:10:37 | [trpo_pendulum] epoch #560 | Saving snapshot...
2022-08-17 18:10:37 | [trpo_pendulum] epoch #560 | Saved
2022-08-17 18:10:37 | [trpo_pendulum] epoch #560 | Time 353.59 s
2022-08-17 18:10:37 | [trpo_pendulum] epoch #560 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -488.226
Evaluation/AverageReturn              -1176.93
Evaluation/Iteration                    560
Evaluation/MaxReturn                  -1060.48
Evaluation/MinReturn                  -1241.28
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     55.8851
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.82063
GaussianMLPPolicy/KL                      0.00541177
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              17.3748
GaussianMLPPolicy/LossBefore             18.2106
GaussianMLPPolicy/dLoss                   0.835716
GaussianMLPValueFunction/LossAfter        6.43189
GaussianMLPValueFunction/LossBefore       6.44082
GaussianMLPValueFunction/dLoss            0.00893307
TotalEnvSteps                        673200
-----------------------------------  ---------------
2022-08-17 18:10:38 | [trpo_pendulum] epoch #561 | Saving snapshot...
2022-08-17 18:10:38 | [trpo_pendulum] epoch #561 | Saved
2022-08-17 18:10:38 | [trpo_pendulum] epoch #561 | Time 354.21 s
2022-08-17 18:10:38 | [trpo_pendulum] epoch #561 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -497.596
Evaluation/AverageReturn              -1223.24
Evaluation/Iteration                    561
Evaluation/MaxReturn                  -1030.11
Evaluation/MinReturn                  -1346.18
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    125.736
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.8349
GaussianMLPPolicy/KL                      0.00837202
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              23.938
GaussianMLPPolicy/LossBefore             25.261
GaussianMLPPolicy/dLoss                   1.32301
GaussianMLPValueFunction/LossAfter        6.4978
GaussianMLPValueFunction/LossBefore       6.49892
GaussianMLPValueFunction/dLoss            0.00111151
TotalEnvSteps                        674400
-----------------------------------  ---------------
2022-08-17 18:10:39 | [trpo_pendulum] epoch #562 | Saving snapshot...
2022-08-17 18:10:39 | [trpo_pendulum] epoch #562 | Saved
2022-08-17 18:10:39 | [trpo_pendulum] epoch #562 | Time 354.84 s
2022-08-17 18:10:39 | [trpo_pendulum] epoch #562 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -411.015
Evaluation/AverageReturn              -1009.94
Evaluation/Iteration                    562
Evaluation/MaxReturn                   -941.542
Evaluation/MinReturn                  -1050.42
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     41.921
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.81194
GaussianMLPPolicy/KL                      0.00565266
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -5.06836
GaussianMLPPolicy/LossBefore             -4.1962
GaussianMLPPolicy/dLoss                   0.872159
GaussianMLPValueFunction/LossAfter        6.34558
GaussianMLPValueFunction/LossBefore       6.3615
GaussianMLPValueFunction/dLoss            0.0159202
TotalEnvSteps                        675600
-----------------------------------  ---------------
2022-08-17 18:10:39 | [trpo_pendulum] epoch #563 | Saving snapshot...
2022-08-17 18:10:39 | [trpo_pendulum] epoch #563 | Saved
2022-08-17 18:10:39 | [trpo_pendulum] epoch #563 | Time 355.46 s
2022-08-17 18:10:39 | [trpo_pendulum] epoch #563 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -510.351
Evaluation/AverageReturn              -1240.04
Evaluation/Iteration                    563
Evaluation/MaxReturn                  -1194.6
Evaluation/MinReturn                  -1302.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     41.5745
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.8186
GaussianMLPPolicy/KL                      0.00917504
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              23.795
GaussianMLPPolicy/LossBefore             25.4659
GaussianMLPPolicy/dLoss                   1.67087
GaussianMLPValueFunction/LossAfter        6.38485
GaussianMLPValueFunction/LossBefore       6.38929
GaussianMLPValueFunction/dLoss            0.00443411
TotalEnvSteps                        676800
-----------------------------------  ---------------
2022-08-17 18:10:40 | [trpo_pendulum] epoch #564 | Saving snapshot...
2022-08-17 18:10:40 | [trpo_pendulum] epoch #564 | Saved
2022-08-17 18:10:40 | [trpo_pendulum] epoch #564 | Time 356.10 s
2022-08-17 18:10:40 | [trpo_pendulum] epoch #564 | EpochTime 0.63 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -490.681
Evaluation/AverageReturn              -1190.23
Evaluation/Iteration                    564
Evaluation/MaxReturn                  -1031.45
Evaluation/MinReturn                  -1384.26
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    158.496
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.8319
GaussianMLPPolicy/KL                      0.00771533
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              17.7584
GaussianMLPPolicy/LossBefore             19.065
GaussianMLPPolicy/dLoss                   1.3066
GaussianMLPValueFunction/LossAfter        6.46419
GaussianMLPValueFunction/LossBefore       6.46485
GaussianMLPValueFunction/dLoss            0.000659943
TotalEnvSteps                        678000
-----------------------------------  ----------------
2022-08-17 18:10:40 | [trpo_pendulum] epoch #565 | Saving snapshot...
2022-08-17 18:10:40 | [trpo_pendulum] epoch #565 | Saved
2022-08-17 18:10:40 | [trpo_pendulum] epoch #565 | Time 356.73 s
2022-08-17 18:10:40 | [trpo_pendulum] epoch #565 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -670.056
Evaluation/AverageReturn              -1460.37
Evaluation/Iteration                    565
Evaluation/MaxReturn                  -1203.99
Evaluation/MinReturn                  -1628.54
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    147.927
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.83659
GaussianMLPPolicy/KL                      0.00649843
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              44.8334
GaussianMLPPolicy/LossBefore             47.2834
GaussianMLPPolicy/dLoss                   2.44999
GaussianMLPValueFunction/LossAfter        6.74523
GaussianMLPValueFunction/LossBefore       6.79994
GaussianMLPValueFunction/dLoss            0.0547166
TotalEnvSteps                        679200
-----------------------------------  ---------------
2022-08-17 18:10:41 | [trpo_pendulum] epoch #566 | Saving snapshot...
2022-08-17 18:10:41 | [trpo_pendulum] epoch #566 | Saved
2022-08-17 18:10:41 | [trpo_pendulum] epoch #566 | Time 357.37 s
2022-08-17 18:10:41 | [trpo_pendulum] epoch #566 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -485.814
Evaluation/AverageReturn              -1195.74
Evaluation/Iteration                    566
Evaluation/MaxReturn                  -1008.19
Evaluation/MinReturn                  -1358.51
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    153.163
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.82749
GaussianMLPPolicy/KL                      0.00953678
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              18.4791
GaussianMLPPolicy/LossBefore             20.1296
GaussianMLPPolicy/dLoss                   1.65047
GaussianMLPValueFunction/LossAfter        6.49128
GaussianMLPValueFunction/LossBefore       6.49229
GaussianMLPValueFunction/dLoss            0.00101185
TotalEnvSteps                        680400
-----------------------------------  ---------------
2022-08-17 18:10:42 | [trpo_pendulum] epoch #567 | Saving snapshot...
2022-08-17 18:10:42 | [trpo_pendulum] epoch #567 | Saved
2022-08-17 18:10:42 | [trpo_pendulum] epoch #567 | Time 358.00 s
2022-08-17 18:10:42 | [trpo_pendulum] epoch #567 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -472.915
Evaluation/AverageReturn              -1122.08
Evaluation/Iteration                    567
Evaluation/MaxReturn                  -1033.7
Evaluation/MinReturn                  -1314.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     96.3375
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.85108
GaussianMLPPolicy/KL                      0.00963718
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               5.25153
GaussianMLPPolicy/LossBefore              6.69288
GaussianMLPPolicy/dLoss                   1.44134
GaussianMLPValueFunction/LossAfter        6.38327
GaussianMLPValueFunction/LossBefore       6.39276
GaussianMLPValueFunction/dLoss            0.00949383
TotalEnvSteps                        681600
-----------------------------------  ---------------
2022-08-17 18:10:42 | [trpo_pendulum] epoch #568 | Saving snapshot...
2022-08-17 18:10:42 | [trpo_pendulum] epoch #568 | Saved
2022-08-17 18:10:42 | [trpo_pendulum] epoch #568 | Time 358.63 s
2022-08-17 18:10:42 | [trpo_pendulum] epoch #568 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -468.26
Evaluation/AverageReturn              -1118.74
Evaluation/Iteration                    568
Evaluation/MaxReturn                  -1031.3
Evaluation/MinReturn                  -1328.34
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    113.157
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.85361
GaussianMLPPolicy/KL                      0.00736476
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               5.20522
GaussianMLPPolicy/LossBefore              6.79396
GaussianMLPPolicy/dLoss                   1.58874
GaussianMLPValueFunction/LossAfter        6.4024
GaussianMLPValueFunction/LossBefore       6.40639
GaussianMLPValueFunction/dLoss            0.00398827
TotalEnvSteps                        682800
-----------------------------------  ---------------
2022-08-17 18:10:43 | [trpo_pendulum] epoch #569 | Saving snapshot...
2022-08-17 18:10:43 | [trpo_pendulum] epoch #569 | Saved
2022-08-17 18:10:43 | [trpo_pendulum] epoch #569 | Time 359.27 s
2022-08-17 18:10:43 | [trpo_pendulum] epoch #569 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -497.86
Evaluation/AverageReturn              -1239.9
Evaluation/Iteration                    569
Evaluation/MaxReturn                  -1055.03
Evaluation/MinReturn                  -1355.89
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    105.551
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.84926
GaussianMLPPolicy/KL                      0.00722843
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              29.2568
GaussianMLPPolicy/LossBefore             30.2036
GaussianMLPPolicy/dLoss                   0.946827
GaussianMLPValueFunction/LossAfter        6.53447
GaussianMLPValueFunction/LossBefore       6.53865
GaussianMLPValueFunction/dLoss            0.00418043
TotalEnvSteps                        684000
-----------------------------------  ---------------
2022-08-17 18:10:44 | [trpo_pendulum] epoch #570 | Saving snapshot...
2022-08-17 18:10:44 | [trpo_pendulum] epoch #570 | Saved
2022-08-17 18:10:44 | [trpo_pendulum] epoch #570 | Time 359.92 s
2022-08-17 18:10:44 | [trpo_pendulum] epoch #570 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -402.804
Evaluation/AverageReturn               -997.205
Evaluation/Iteration                    570
Evaluation/MaxReturn                   -797.998
Evaluation/MinReturn                  -1082.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     91.8962
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.82242
GaussianMLPPolicy/KL                      0.00879902
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -9.47858
GaussianMLPPolicy/LossBefore             -8.71902
GaussianMLPPolicy/dLoss                   0.759564
GaussianMLPValueFunction/LossAfter        6.28502
GaussianMLPValueFunction/LossBefore       6.30576
GaussianMLPValueFunction/dLoss            0.0207386
TotalEnvSteps                        685200
-----------------------------------  ---------------
2022-08-17 18:10:44 | [trpo_pendulum] epoch #571 | Saving snapshot...
2022-08-17 18:10:44 | [trpo_pendulum] epoch #571 | Saved
2022-08-17 18:10:44 | [trpo_pendulum] epoch #571 | Time 360.54 s
2022-08-17 18:10:44 | [trpo_pendulum] epoch #571 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -416.995
Evaluation/AverageReturn               -992.411
Evaluation/Iteration                    571
Evaluation/MaxReturn                   -895.871
Evaluation/MinReturn                  -1045.8
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     51.8972
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.86914
GaussianMLPPolicy/KL                      0.00675017
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -12.8169
GaussianMLPPolicy/LossBefore            -11.4837
GaussianMLPPolicy/dLoss                   1.33318
GaussianMLPValueFunction/LossAfter        6.32092
GaussianMLPValueFunction/LossBefore       6.33161
GaussianMLPValueFunction/dLoss            0.010695
TotalEnvSteps                        686400
-----------------------------------  ---------------
2022-08-17 18:10:45 | [trpo_pendulum] epoch #572 | Saving snapshot...
2022-08-17 18:10:45 | [trpo_pendulum] epoch #572 | Saved
2022-08-17 18:10:45 | [trpo_pendulum] epoch #572 | Time 361.25 s
2022-08-17 18:10:45 | [trpo_pendulum] epoch #572 | EpochTime 0.70 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -553.812
Evaluation/AverageReturn              -1256.15
Evaluation/Iteration                    572
Evaluation/MaxReturn                   -882.394
Evaluation/MinReturn                  -1484.28
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    208.146
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.85427
GaussianMLPPolicy/KL                      0.00887082
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              20.5721
GaussianMLPPolicy/LossBefore             23.1843
GaussianMLPPolicy/dLoss                   2.61218
GaussianMLPValueFunction/LossAfter        6.57565
GaussianMLPValueFunction/LossBefore       6.59187
GaussianMLPValueFunction/dLoss            0.0162191
TotalEnvSteps                        687600
-----------------------------------  ---------------
2022-08-17 18:10:46 | [trpo_pendulum] epoch #573 | Saving snapshot...
2022-08-17 18:10:46 | [trpo_pendulum] epoch #573 | Saved
2022-08-17 18:10:46 | [trpo_pendulum] epoch #573 | Time 361.92 s
2022-08-17 18:10:46 | [trpo_pendulum] epoch #573 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -631.835
Evaluation/AverageReturn              -1471.99
Evaluation/Iteration                    573
Evaluation/MaxReturn                  -1454.89
Evaluation/MinReturn                  -1488.85
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     12.0192
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.83323
GaussianMLPPolicy/KL                      0.00737744
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              54.6218
GaussianMLPPolicy/LossBefore             56.529
GaussianMLPPolicy/dLoss                   1.90717
GaussianMLPValueFunction/LossAfter        6.73816
GaussianMLPValueFunction/LossBefore       6.78898
GaussianMLPValueFunction/dLoss            0.0508151
TotalEnvSteps                        688800
-----------------------------------  ---------------
2022-08-17 18:10:46 | [trpo_pendulum] epoch #574 | Saving snapshot...
2022-08-17 18:10:46 | [trpo_pendulum] epoch #574 | Saved
2022-08-17 18:10:46 | [trpo_pendulum] epoch #574 | Time 362.55 s
2022-08-17 18:10:46 | [trpo_pendulum] epoch #574 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -470.094
Evaluation/AverageReturn              -1108.5
Evaluation/Iteration                    574
Evaluation/MaxReturn                   -841.763
Evaluation/MinReturn                  -1353.81
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    200.859
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.84165
GaussianMLPPolicy/KL                      0.00619185
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               2.08339
GaussianMLPPolicy/LossBefore              3.4298
GaussianMLPPolicy/dLoss                   1.34642
GaussianMLPValueFunction/LossAfter        6.44931
GaussianMLPValueFunction/LossBefore       6.45181
GaussianMLPValueFunction/dLoss            0.00249815
TotalEnvSteps                        690000
-----------------------------------  ---------------
2022-08-17 18:10:47 | [trpo_pendulum] epoch #575 | Saving snapshot...
2022-08-17 18:10:47 | [trpo_pendulum] epoch #575 | Saved
2022-08-17 18:10:47 | [trpo_pendulum] epoch #575 | Time 363.19 s
2022-08-17 18:10:47 | [trpo_pendulum] epoch #575 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -527.365
Evaluation/AverageReturn              -1203.01
Evaluation/Iteration                    575
Evaluation/MaxReturn                  -1017.04
Evaluation/MinReturn                  -1422.71
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    128.606
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.86689
GaussianMLPPolicy/KL                      0.00843855
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              11.4703
GaussianMLPPolicy/LossBefore             14.5023
GaussianMLPPolicy/dLoss                   3.03198
GaussianMLPValueFunction/LossAfter        6.41934
GaussianMLPValueFunction/LossBefore       6.42295
GaussianMLPValueFunction/dLoss            0.00360441
TotalEnvSteps                        691200
-----------------------------------  ---------------
2022-08-17 18:10:48 | [trpo_pendulum] epoch #576 | Saving snapshot...
2022-08-17 18:10:48 | [trpo_pendulum] epoch #576 | Saved
2022-08-17 18:10:48 | [trpo_pendulum] epoch #576 | Time 363.85 s
2022-08-17 18:10:48 | [trpo_pendulum] epoch #576 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -430.295
Evaluation/AverageReturn              -1025.45
Evaluation/Iteration                    576
Evaluation/MaxReturn                   -833.277
Evaluation/MinReturn                  -1320.24
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    207.134
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.87812
GaussianMLPPolicy/KL                      0.00598118
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -11.4142
GaussianMLPPolicy/LossBefore             -7.10268
GaussianMLPPolicy/dLoss                   4.31153
GaussianMLPValueFunction/LossAfter        6.43101
GaussianMLPValueFunction/LossBefore       6.43479
GaussianMLPValueFunction/dLoss            0.00378084
TotalEnvSteps                        692400
-----------------------------------  ---------------
2022-08-17 18:10:48 | [trpo_pendulum] epoch #577 | Saving snapshot...
2022-08-17 18:10:48 | [trpo_pendulum] epoch #577 | Saved
2022-08-17 18:10:48 | [trpo_pendulum] epoch #577 | Time 364.48 s
2022-08-17 18:10:48 | [trpo_pendulum] epoch #577 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -411.132
Evaluation/AverageReturn               -976.492
Evaluation/Iteration                    577
Evaluation/MaxReturn                   -850.183
Evaluation/MinReturn                  -1274.43
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    145.6
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.87746
GaussianMLPPolicy/KL                      0.00911425
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -13.4823
GaussianMLPPolicy/LossBefore            -12.6747
GaussianMLPPolicy/dLoss                   0.80758
GaussianMLPValueFunction/LossAfter        6.37741
GaussianMLPValueFunction/LossBefore       6.38583
GaussianMLPValueFunction/dLoss            0.00842142
TotalEnvSteps                        693600
-----------------------------------  ---------------
2022-08-17 18:10:49 | [trpo_pendulum] epoch #578 | Saving snapshot...
2022-08-17 18:10:49 | [trpo_pendulum] epoch #578 | Saved
2022-08-17 18:10:49 | [trpo_pendulum] epoch #578 | Time 365.14 s
2022-08-17 18:10:49 | [trpo_pendulum] epoch #578 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -505.544
Evaluation/AverageReturn              -1102.32
Evaluation/Iteration                    578
Evaluation/MaxReturn                  -1006.03
Evaluation/MinReturn                  -1314.2
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    111.822
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.87229
GaussianMLPPolicy/KL                      0.00771652
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -1.94639
GaussianMLPPolicy/LossBefore             -0.702586
GaussianMLPPolicy/dLoss                   1.24381
GaussianMLPValueFunction/LossAfter        6.41218
GaussianMLPValueFunction/LossBefore       6.41498
GaussianMLPValueFunction/dLoss            0.00279284
TotalEnvSteps                        694800
-----------------------------------  ---------------
2022-08-17 18:10:49 | [trpo_pendulum] epoch #579 | Saving snapshot...
2022-08-17 18:10:49 | [trpo_pendulum] epoch #579 | Saved
2022-08-17 18:10:49 | [trpo_pendulum] epoch #579 | Time 365.77 s
2022-08-17 18:10:49 | [trpo_pendulum] epoch #579 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -616.239
Evaluation/AverageReturn              -1340.28
Evaluation/Iteration                    579
Evaluation/MaxReturn                  -1236.06
Evaluation/MinReturn                  -1435.37
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     70.7348
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.87757
GaussianMLPPolicy/KL                      0.00996439
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              27.4818
GaussianMLPPolicy/LossBefore             32.3402
GaussianMLPPolicy/dLoss                   4.85832
GaussianMLPValueFunction/LossAfter        6.58232
GaussianMLPValueFunction/LossBefore       6.59468
GaussianMLPValueFunction/dLoss            0.0123606
TotalEnvSteps                        696000
-----------------------------------  ---------------
2022-08-17 18:10:50 | [trpo_pendulum] epoch #580 | Saving snapshot...
2022-08-17 18:10:50 | [trpo_pendulum] epoch #580 | Saved
2022-08-17 18:10:50 | [trpo_pendulum] epoch #580 | Time 366.43 s
2022-08-17 18:10:50 | [trpo_pendulum] epoch #580 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -559.111
Evaluation/AverageReturn              -1335.68
Evaluation/Iteration                    580
Evaluation/MaxReturn                  -1279.17
Evaluation/MinReturn                  -1380.83
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     31.943
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.85346
GaussianMLPPolicy/KL                      0.0059228
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              40.2272
GaussianMLPPolicy/LossBefore             40.6258
GaussianMLPPolicy/dLoss                   0.398582
GaussianMLPValueFunction/LossAfter        6.56542
GaussianMLPValueFunction/LossBefore       6.57299
GaussianMLPValueFunction/dLoss            0.00756454
TotalEnvSteps                        697200
-----------------------------------  ---------------
2022-08-17 18:10:51 | [trpo_pendulum] epoch #581 | Saving snapshot...
2022-08-17 18:10:51 | [trpo_pendulum] epoch #581 | Saved
2022-08-17 18:10:51 | [trpo_pendulum] epoch #581 | Time 367.08 s
2022-08-17 18:10:51 | [trpo_pendulum] epoch #581 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -424.886
Evaluation/AverageReturn               -994.731
Evaluation/Iteration                    581
Evaluation/MaxReturn                   -887.391
Evaluation/MinReturn                  -1170.39
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     97.7881
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.85534
GaussianMLPPolicy/KL                      0.00889604
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -12.9963
GaussianMLPPolicy/LossBefore            -11.9432
GaussianMLPPolicy/dLoss                   1.05313
GaussianMLPValueFunction/LossAfter        6.33715
GaussianMLPValueFunction/LossBefore       6.35356
GaussianMLPValueFunction/dLoss            0.0164089
TotalEnvSteps                        698400
-----------------------------------  ---------------
2022-08-17 18:10:51 | [trpo_pendulum] epoch #582 | Saving snapshot...
2022-08-17 18:10:51 | [trpo_pendulum] epoch #582 | Saved
2022-08-17 18:10:51 | [trpo_pendulum] epoch #582 | Time 367.70 s
2022-08-17 18:10:51 | [trpo_pendulum] epoch #582 | EpochTime 0.62 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -464.357
Evaluation/AverageReturn              -1176.69
Evaluation/Iteration                    582
Evaluation/MaxReturn                   -895.768
Evaluation/MinReturn                  -1336.47
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    161.076
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.83832
GaussianMLPPolicy/KL                      0.00689076
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              20.9221
GaussianMLPPolicy/LossBefore             21.9527
GaussianMLPPolicy/dLoss                   1.03068
GaussianMLPValueFunction/LossAfter        6.45956
GaussianMLPValueFunction/LossBefore       6.46005
GaussianMLPValueFunction/dLoss            0.000488281
TotalEnvSteps                        699600
-----------------------------------  ----------------
2022-08-17 18:10:52 | [trpo_pendulum] epoch #583 | Saving snapshot...
2022-08-17 18:10:52 | [trpo_pendulum] epoch #583 | Saved
2022-08-17 18:10:52 | [trpo_pendulum] epoch #583 | Time 368.36 s
2022-08-17 18:10:52 | [trpo_pendulum] epoch #583 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -426.999
Evaluation/AverageReturn              -1043.94
Evaluation/Iteration                    583
Evaluation/MaxReturn                  -1020.42
Evaluation/MinReturn                  -1077.9
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     17.7194
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.83932
GaussianMLPPolicy/KL                      0.00415264
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.146742
GaussianMLPPolicy/LossBefore              0.317312
GaussianMLPPolicy/dLoss                   0.464054
GaussianMLPValueFunction/LossAfter        6.29484
GaussianMLPValueFunction/LossBefore       6.30884
GaussianMLPValueFunction/dLoss            0.0139952
TotalEnvSteps                        700800
-----------------------------------  ---------------
2022-08-17 18:10:53 | [trpo_pendulum] epoch #584 | Saving snapshot...
2022-08-17 18:10:53 | [trpo_pendulum] epoch #584 | Saved
2022-08-17 18:10:53 | [trpo_pendulum] epoch #584 | Time 368.99 s
2022-08-17 18:10:53 | [trpo_pendulum] epoch #584 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -534.357
Evaluation/AverageReturn              -1305.59
Evaluation/Iteration                    584
Evaluation/MaxReturn                  -1227.54
Evaluation/MinReturn                  -1340.05
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     41.1933
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.87337
GaussianMLPPolicy/KL                      0.0096465
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              38.5656
GaussianMLPPolicy/LossBefore             38.7032
GaussianMLPPolicy/dLoss                   0.137592
GaussianMLPValueFunction/LossAfter        6.53278
GaussianMLPValueFunction/LossBefore       6.54476
GaussianMLPValueFunction/dLoss            0.0119786
TotalEnvSteps                        702000
-----------------------------------  --------------
2022-08-17 18:10:53 | [trpo_pendulum] epoch #585 | Saving snapshot...
2022-08-17 18:10:53 | [trpo_pendulum] epoch #585 | Saved
2022-08-17 18:10:53 | [trpo_pendulum] epoch #585 | Time 369.63 s
2022-08-17 18:10:53 | [trpo_pendulum] epoch #585 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -633.713
Evaluation/AverageReturn              -1395.74
Evaluation/Iteration                    585
Evaluation/MaxReturn                  -1143.85
Evaluation/MinReturn                  -1472.3
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    116.825
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.87505
GaussianMLPPolicy/KL                      0.00662258
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              37.8488
GaussianMLPPolicy/LossBefore             40.3271
GaussianMLPPolicy/dLoss                   2.47826
GaussianMLPValueFunction/LossAfter        6.66927
GaussianMLPValueFunction/LossBefore       6.6988
GaussianMLPValueFunction/dLoss            0.0295272
TotalEnvSteps                        703200
-----------------------------------  ---------------
2022-08-17 18:10:54 | [trpo_pendulum] epoch #586 | Saving snapshot...
2022-08-17 18:10:54 | [trpo_pendulum] epoch #586 | Saved
2022-08-17 18:10:54 | [trpo_pendulum] epoch #586 | Time 370.29 s
2022-08-17 18:10:54 | [trpo_pendulum] epoch #586 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -586.649
Evaluation/AverageReturn              -1285.94
Evaluation/Iteration                    586
Evaluation/MaxReturn                  -1224.53
Evaluation/MinReturn                  -1398.44
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     57.7237
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.86212
GaussianMLPPolicy/KL                      0.00699348
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              21.5567
GaussianMLPPolicy/LossBefore             23.8162
GaussianMLPPolicy/dLoss                   2.25949
GaussianMLPValueFunction/LossAfter        6.46515
GaussianMLPValueFunction/LossBefore       6.46632
GaussianMLPValueFunction/dLoss            0.00117159
TotalEnvSteps                        704400
-----------------------------------  ---------------
2022-08-17 18:10:55 | [trpo_pendulum] epoch #587 | Saving snapshot...
2022-08-17 18:10:55 | [trpo_pendulum] epoch #587 | Saved
2022-08-17 18:10:55 | [trpo_pendulum] epoch #587 | Time 370.92 s
2022-08-17 18:10:55 | [trpo_pendulum] epoch #587 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -618.937
Evaluation/AverageReturn              -1355.83
Evaluation/Iteration                    587
Evaluation/MaxReturn                  -1229.89
Evaluation/MinReturn                  -1480.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     83.2477
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.843
GaussianMLPPolicy/KL                      0.00668604
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              30.568
GaussianMLPPolicy/LossBefore             32.9718
GaussianMLPPolicy/dLoss                   2.40381
GaussianMLPValueFunction/LossAfter        6.59221
GaussianMLPValueFunction/LossBefore       6.59745
GaussianMLPValueFunction/dLoss            0.00524044
TotalEnvSteps                        705600
-----------------------------------  ---------------
2022-08-17 18:10:55 | [trpo_pendulum] epoch #588 | Saving snapshot...
2022-08-17 18:10:55 | [trpo_pendulum] epoch #588 | Saved
2022-08-17 18:10:55 | [trpo_pendulum] epoch #588 | Time 371.55 s
2022-08-17 18:10:55 | [trpo_pendulum] epoch #588 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -498.931
Evaluation/AverageReturn              -1209.16
Evaluation/Iteration                    588
Evaluation/MaxReturn                  -1135.96
Evaluation/MinReturn                  -1323.91
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     57.8161
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.83229
GaussianMLPPolicy/KL                      0.00636587
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              17.5374
GaussianMLPPolicy/LossBefore             18.8853
GaussianMLPPolicy/dLoss                   1.34787
GaussianMLPValueFunction/LossAfter        6.36362
GaussianMLPValueFunction/LossBefore       6.37639
GaussianMLPValueFunction/dLoss            0.0127697
TotalEnvSteps                        706800
-----------------------------------  ---------------
2022-08-17 18:10:56 | [trpo_pendulum] epoch #589 | Saving snapshot...
2022-08-17 18:10:56 | [trpo_pendulum] epoch #589 | Saved
2022-08-17 18:10:56 | [trpo_pendulum] epoch #589 | Time 372.20 s
2022-08-17 18:10:56 | [trpo_pendulum] epoch #589 | EpochTime 0.65 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -572.608
Evaluation/AverageReturn              -1285.92
Evaluation/Iteration                    589
Evaluation/MaxReturn                  -1153.8
Evaluation/MinReturn                  -1393.54
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     81.2
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.82809
GaussianMLPPolicy/KL                      0.00715901
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              22.2483
GaussianMLPPolicy/LossBefore             23.8792
GaussianMLPPolicy/dLoss                   1.63093
GaussianMLPValueFunction/LossAfter        6.45473
GaussianMLPValueFunction/LossBefore       6.45564
GaussianMLPValueFunction/dLoss            0.000903606
TotalEnvSteps                        708000
-----------------------------------  ----------------
2022-08-17 18:10:57 | [trpo_pendulum] epoch #590 | Saving snapshot...
2022-08-17 18:10:57 | [trpo_pendulum] epoch #590 | Saved
2022-08-17 18:10:57 | [trpo_pendulum] epoch #590 | Time 372.90 s
2022-08-17 18:10:57 | [trpo_pendulum] epoch #590 | EpochTime 0.69 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -517.867
Evaluation/AverageReturn              -1281.45
Evaluation/Iteration                    590
Evaluation/MaxReturn                  -1224.05
Evaluation/MinReturn                  -1346.14
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     54.042
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.84417
GaussianMLPPolicy/KL                      0.00980568
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              30.1139
GaussianMLPPolicy/LossBefore             31.701
GaussianMLPPolicy/dLoss                   1.5871
GaussianMLPValueFunction/LossAfter        6.49286
GaussianMLPValueFunction/LossBefore       6.49569
GaussianMLPValueFunction/dLoss            0.00282431
TotalEnvSteps                        709200
-----------------------------------  ---------------
2022-08-17 18:10:57 | [trpo_pendulum] epoch #591 | Saving snapshot...
2022-08-17 18:10:57 | [trpo_pendulum] epoch #591 | Saved
2022-08-17 18:10:57 | [trpo_pendulum] epoch #591 | Time 373.56 s
2022-08-17 18:10:57 | [trpo_pendulum] epoch #591 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -514.98
Evaluation/AverageReturn              -1274.37
Evaluation/Iteration                    591
Evaluation/MaxReturn                  -1187.54
Evaluation/MinReturn                  -1326
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     44.3866
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.85856
GaussianMLPPolicy/KL                      0.00759339
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              30.9678
GaussianMLPPolicy/LossBefore             31.4718
GaussianMLPPolicy/dLoss                   0.504063
GaussianMLPValueFunction/LossAfter        6.46375
GaussianMLPValueFunction/LossBefore       6.46604
GaussianMLPValueFunction/dLoss            0.00229836
TotalEnvSteps                        710400
-----------------------------------  ---------------
2022-08-17 18:10:58 | [trpo_pendulum] epoch #592 | Saving snapshot...
2022-08-17 18:10:58 | [trpo_pendulum] epoch #592 | Saved
2022-08-17 18:10:58 | [trpo_pendulum] epoch #592 | Time 374.25 s
2022-08-17 18:10:58 | [trpo_pendulum] epoch #592 | EpochTime 0.69 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -537.605
Evaluation/AverageReturn              -1293.06
Evaluation/Iteration                    592
Evaluation/MaxReturn                  -1210.08
Evaluation/MinReturn                  -1351.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     59.8032
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.88125
GaussianMLPPolicy/KL                      0.00994134
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              31.6815
GaussianMLPPolicy/LossBefore             32.2748
GaussianMLPPolicy/dLoss                   0.593376
GaussianMLPValueFunction/LossAfter        6.53981
GaussianMLPValueFunction/LossBefore       6.5441
GaussianMLPValueFunction/dLoss            0.00429201
TotalEnvSteps                        711600
-----------------------------------  ---------------
2022-08-17 18:10:59 | [trpo_pendulum] epoch #593 | Saving snapshot...
2022-08-17 18:10:59 | [trpo_pendulum] epoch #593 | Saved
2022-08-17 18:10:59 | [trpo_pendulum] epoch #593 | Time 374.92 s
2022-08-17 18:10:59 | [trpo_pendulum] epoch #593 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -446.225
Evaluation/AverageReturn              -1101.88
Evaluation/Iteration                    593
Evaluation/MaxReturn                   -896.277
Evaluation/MinReturn                  -1217.83
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    104.992
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.89008
GaussianMLPPolicy/KL                      0.00727932
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               4.10552
GaussianMLPPolicy/LossBefore              5.56529
GaussianMLPPolicy/dLoss                   1.45978
GaussianMLPValueFunction/LossAfter        6.39756
GaussianMLPValueFunction/LossBefore       6.40352
GaussianMLPValueFunction/dLoss            0.00595951
TotalEnvSteps                        712800
-----------------------------------  ---------------
2022-08-17 18:10:59 | [trpo_pendulum] epoch #594 | Saving snapshot...
2022-08-17 18:10:59 | [trpo_pendulum] epoch #594 | Saved
2022-08-17 18:10:59 | [trpo_pendulum] epoch #594 | Time 375.59 s
2022-08-17 18:10:59 | [trpo_pendulum] epoch #594 | EpochTime 0.66 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -498.47
Evaluation/AverageReturn              -1268.54
Evaluation/Iteration                    594
Evaluation/MaxReturn                  -1205.76
Evaluation/MinReturn                  -1375.46
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     63.3751
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.88785
GaussianMLPPolicy/KL                      0.0061828
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              28.8412
GaussianMLPPolicy/LossBefore             30.1407
GaussianMLPPolicy/dLoss                   1.29949
GaussianMLPValueFunction/LossAfter        6.47674
GaussianMLPValueFunction/LossBefore       6.47937
GaussianMLPValueFunction/dLoss            0.002635
TotalEnvSteps                        714000
-----------------------------------  --------------
2022-08-17 18:11:00 | [trpo_pendulum] epoch #595 | Saving snapshot...
2022-08-17 18:11:00 | [trpo_pendulum] epoch #595 | Saved
2022-08-17 18:11:00 | [trpo_pendulum] epoch #595 | Time 376.22 s
2022-08-17 18:11:00 | [trpo_pendulum] epoch #595 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -688.772
Evaluation/AverageReturn              -1599.49
Evaluation/Iteration                    595
Evaluation/MaxReturn                  -1543.77
Evaluation/MinReturn                  -1653.69
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     34.1819
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.89976
GaussianMLPPolicy/KL                      0.00936974
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              67.3674
GaussianMLPPolicy/LossBefore             70.2566
GaussianMLPPolicy/dLoss                   2.88921
GaussianMLPValueFunction/LossAfter        6.90159
GaussianMLPValueFunction/LossBefore       7.01442
GaussianMLPValueFunction/dLoss            0.112831
TotalEnvSteps                        715200
-----------------------------------  ---------------
2022-08-17 18:11:01 | [trpo_pendulum] epoch #596 | Saving snapshot...
2022-08-17 18:11:01 | [trpo_pendulum] epoch #596 | Saved
2022-08-17 18:11:01 | [trpo_pendulum] epoch #596 | Time 376.91 s
2022-08-17 18:11:01 | [trpo_pendulum] epoch #596 | EpochTime 0.68 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -548.742
Evaluation/AverageReturn              -1347.2
Evaluation/Iteration                    596
Evaluation/MaxReturn                  -1333.13
Evaluation/MinReturn                  -1368.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     11.7629
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.92031
GaussianMLPPolicy/KL                      0.00699438
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              38.6012
GaussianMLPPolicy/LossBefore             38.9247
GaussianMLPPolicy/dLoss                   0.323467
GaussianMLPValueFunction/LossAfter        6.56024
GaussianMLPValueFunction/LossBefore       6.56233
GaussianMLPValueFunction/dLoss            0.00208998
TotalEnvSteps                        716400
-----------------------------------  ---------------
2022-08-17 18:11:01 | [trpo_pendulum] epoch #597 | Saving snapshot...
2022-08-17 18:11:01 | [trpo_pendulum] epoch #597 | Saved
2022-08-17 18:11:01 | [trpo_pendulum] epoch #597 | Time 377.56 s
2022-08-17 18:11:01 | [trpo_pendulum] epoch #597 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -518.561
Evaluation/AverageReturn              -1300.66
Evaluation/Iteration                    597
Evaluation/MaxReturn                  -1186.32
Evaluation/MinReturn                  -1342
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     53.3146
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.93969
GaussianMLPPolicy/KL                      0.00703803
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              29.5098
GaussianMLPPolicy/LossBefore             30.7249
GaussianMLPPolicy/dLoss                   1.21511
GaussianMLPValueFunction/LossAfter        6.48889
GaussianMLPValueFunction/LossBefore       6.4937
GaussianMLPValueFunction/dLoss            0.00480938
TotalEnvSteps                        717600
-----------------------------------  ---------------
2022-08-17 18:11:02 | [trpo_pendulum] epoch #598 | Saving snapshot...
2022-08-17 18:11:02 | [trpo_pendulum] epoch #598 | Saved
2022-08-17 18:11:02 | [trpo_pendulum] epoch #598 | Time 378.23 s
2022-08-17 18:11:02 | [trpo_pendulum] epoch #598 | EpochTime 0.67 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -682.603
Evaluation/AverageReturn              -1539.05
Evaluation/Iteration                    598
Evaluation/MaxReturn                  -1239.38
Evaluation/MinReturn                  -1631.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    136.032
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.91972
GaussianMLPPolicy/KL                      0.00664649
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              53.8064
GaussianMLPPolicy/LossBefore             56.2005
GaussianMLPPolicy/dLoss                   2.3941
GaussianMLPValueFunction/LossAfter        6.79948
GaussianMLPValueFunction/LossBefore       6.82881
GaussianMLPValueFunction/dLoss            0.0293283
TotalEnvSteps                        718800
-----------------------------------  ---------------
2022-08-17 18:11:03 | [trpo_pendulum] epoch #599 | Saving snapshot...
2022-08-17 18:11:03 | [trpo_pendulum] epoch #599 | Saved
2022-08-17 18:11:03 | [trpo_pendulum] epoch #599 | Time 378.89 s
2022-08-17 18:11:03 | [trpo_pendulum] epoch #599 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -533.414
Evaluation/AverageReturn              -1242.89
Evaluation/Iteration                    599
Evaluation/MaxReturn                  -1064.68
Evaluation/MinReturn                  -1528.46
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    146.75
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.90809
GaussianMLPPolicy/KL                      0.00969119
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              12.2131
GaussianMLPPolicy/LossBefore             14.5284
GaussianMLPPolicy/dLoss                   2.31524
GaussianMLPValueFunction/LossAfter        6.42619
GaussianMLPValueFunction/LossBefore       6.43914
GaussianMLPValueFunction/dLoss            0.0129576
TotalEnvSteps                        720000
-----------------------------------  ---------------
2022-08-17 18:11:03 | [trpo_pendulum] epoch #600 | Saving snapshot...
2022-08-17 18:11:03 | [trpo_pendulum] epoch #600 | Saved
2022-08-17 18:11:03 | [trpo_pendulum] epoch #600 | Time 379.54 s
2022-08-17 18:11:03 | [trpo_pendulum] epoch #600 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -512.534
Evaluation/AverageReturn              -1291.63
Evaluation/Iteration                    600
Evaluation/MaxReturn                  -1186.08
Evaluation/MinReturn                  -1428.5
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     83.7333
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.89127
GaussianMLPPolicy/KL                      0.00883165
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              30.596
GaussianMLPPolicy/LossBefore             32.3186
GaussianMLPPolicy/dLoss                   1.72266
GaussianMLPValueFunction/LossAfter        6.55729
GaussianMLPValueFunction/LossBefore       6.5586
GaussianMLPValueFunction/dLoss            0.00131512
TotalEnvSteps                        721200
-----------------------------------  ---------------
2022-08-17 18:11:04 | [trpo_pendulum] epoch #601 | Saving snapshot...
2022-08-17 18:11:04 | [trpo_pendulum] epoch #601 | Saved
2022-08-17 18:11:04 | [trpo_pendulum] epoch #601 | Time 380.22 s
2022-08-17 18:11:04 | [trpo_pendulum] epoch #601 | EpochTime 0.68 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -542.358
Evaluation/AverageReturn              -1266.17
Evaluation/Iteration                    601
Evaluation/MaxReturn                  -1184.85
Evaluation/MinReturn                  -1524.86
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    117.788
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.91739
GaussianMLPPolicy/KL                      0.00676734
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              16.0291
GaussianMLPPolicy/LossBefore             18.3337
GaussianMLPPolicy/dLoss                   2.30469
GaussianMLPValueFunction/LossAfter        6.45959
GaussianMLPValueFunction/LossBefore       6.46491
GaussianMLPValueFunction/dLoss            0.00532103
TotalEnvSteps                        722400
-----------------------------------  ---------------
2022-08-17 18:11:05 | [trpo_pendulum] epoch #602 | Saving snapshot...
2022-08-17 18:11:05 | [trpo_pendulum] epoch #602 | Saved
2022-08-17 18:11:05 | [trpo_pendulum] epoch #602 | Time 380.88 s
2022-08-17 18:11:05 | [trpo_pendulum] epoch #602 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -516.231
Evaluation/AverageReturn              -1294.31
Evaluation/Iteration                    602
Evaluation/MaxReturn                  -1087.01
Evaluation/MinReturn                  -1359.47
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     94.9996
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.91065
GaussianMLPPolicy/KL                      0.00861131
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              30.5081
GaussianMLPPolicy/LossBefore             30.6143
GaussianMLPPolicy/dLoss                   0.106161
GaussianMLPValueFunction/LossAfter        6.52094
GaussianMLPValueFunction/LossBefore       6.52248
GaussianMLPValueFunction/dLoss            0.00153971
TotalEnvSteps                        723600
-----------------------------------  ---------------
2022-08-17 18:11:05 | [trpo_pendulum] epoch #603 | Saving snapshot...
2022-08-17 18:11:05 | [trpo_pendulum] epoch #603 | Saved
2022-08-17 18:11:05 | [trpo_pendulum] epoch #603 | Time 381.50 s
2022-08-17 18:11:05 | [trpo_pendulum] epoch #603 | EpochTime 0.62 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -572.094
Evaluation/AverageReturn              -1290.93
Evaluation/Iteration                    603
Evaluation/MaxReturn                  -1087.29
Evaluation/MinReturn                  -1477.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    155.011
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.9402
GaussianMLPPolicy/KL                      0.00957736
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              16.184
GaussianMLPPolicy/LossBefore             18.8839
GaussianMLPPolicy/dLoss                   2.69994
GaussianMLPValueFunction/LossAfter        6.52761
GaussianMLPValueFunction/LossBefore       6.5277
GaussianMLPValueFunction/dLoss            8.39233e-05
TotalEnvSteps                        724800
-----------------------------------  ----------------
2022-08-17 18:11:06 | [trpo_pendulum] epoch #604 | Saving snapshot...
2022-08-17 18:11:06 | [trpo_pendulum] epoch #604 | Saved
2022-08-17 18:11:06 | [trpo_pendulum] epoch #604 | Time 382.19 s
2022-08-17 18:11:06 | [trpo_pendulum] epoch #604 | EpochTime 0.68 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -580.215
Evaluation/AverageReturn              -1279.54
Evaluation/Iteration                    604
Evaluation/MaxReturn                  -1147
Evaluation/MinReturn                  -1607.71
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    158.04
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.93702
GaussianMLPPolicy/KL                      0.00812641
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              12.583
GaussianMLPPolicy/LossBefore             15.6909
GaussianMLPPolicy/dLoss                   3.10782
GaussianMLPValueFunction/LossAfter        6.5169
GaussianMLPValueFunction/LossBefore       6.51711
GaussianMLPValueFunction/dLoss            0.000215054
TotalEnvSteps                        726000
-----------------------------------  ----------------
2022-08-17 18:11:07 | [trpo_pendulum] epoch #605 | Saving snapshot...
2022-08-17 18:11:07 | [trpo_pendulum] epoch #605 | Saved
2022-08-17 18:11:07 | [trpo_pendulum] epoch #605 | Time 382.85 s
2022-08-17 18:11:07 | [trpo_pendulum] epoch #605 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -479.793
Evaluation/AverageReturn              -1160.86
Evaluation/Iteration                    605
Evaluation/MaxReturn                  -1050.83
Evaluation/MinReturn                  -1230.85
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     57.7725
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.93426
GaussianMLPPolicy/KL                      0.00620869
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               6.84291
GaussianMLPPolicy/LossBefore              7.89133
GaussianMLPPolicy/dLoss                   1.04842
GaussianMLPValueFunction/LossAfter        6.43256
GaussianMLPValueFunction/LossBefore       6.43761
GaussianMLPValueFunction/dLoss            0.00504732
TotalEnvSteps                        727200
-----------------------------------  ---------------
2022-08-17 18:11:07 | [trpo_pendulum] epoch #606 | Saving snapshot...
2022-08-17 18:11:07 | [trpo_pendulum] epoch #606 | Saved
2022-08-17 18:11:07 | [trpo_pendulum] epoch #606 | Time 383.53 s
2022-08-17 18:11:07 | [trpo_pendulum] epoch #606 | EpochTime 0.68 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -470.764
Evaluation/AverageReturn              -1130.81
Evaluation/Iteration                    606
Evaluation/MaxReturn                  -1039.12
Evaluation/MinReturn                  -1221.29
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     66.6521
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.921
GaussianMLPPolicy/KL                      0.00756159
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -1.30663
GaussianMLPPolicy/LossBefore              0.128782
GaussianMLPPolicy/dLoss                   1.43541
GaussianMLPValueFunction/LossAfter        6.32133
GaussianMLPValueFunction/LossBefore       6.33775
GaussianMLPValueFunction/dLoss            0.0164204
TotalEnvSteps                        728400
-----------------------------------  ---------------
2022-08-17 18:11:08 | [trpo_pendulum] epoch #607 | Saving snapshot...
2022-08-17 18:11:08 | [trpo_pendulum] epoch #607 | Saved
2022-08-17 18:11:08 | [trpo_pendulum] epoch #607 | Time 384.19 s
2022-08-17 18:11:08 | [trpo_pendulum] epoch #607 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -486.34
Evaluation/AverageReturn              -1173.96
Evaluation/Iteration                    607
Evaluation/MaxReturn                  -1113.81
Evaluation/MinReturn                  -1192.71
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     27.3621
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.91916
GaussianMLPPolicy/KL                      0.00668378
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               9.64163
GaussianMLPPolicy/LossBefore             10.4556
GaussianMLPPolicy/dLoss                   0.813978
GaussianMLPValueFunction/LossAfter        6.38656
GaussianMLPValueFunction/LossBefore       6.38883
GaussianMLPValueFunction/dLoss            0.00227261
TotalEnvSteps                        729600
-----------------------------------  ---------------
2022-08-17 18:11:09 | [trpo_pendulum] epoch #608 | Saving snapshot...
2022-08-17 18:11:09 | [trpo_pendulum] epoch #608 | Saved
2022-08-17 18:11:09 | [trpo_pendulum] epoch #608 | Time 384.89 s
2022-08-17 18:11:09 | [trpo_pendulum] epoch #608 | EpochTime 0.69 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -442.948
Evaluation/AverageReturn              -1089.03
Evaluation/Iteration                    608
Evaluation/MaxReturn                  -1054.77
Evaluation/MinReturn                  -1198.74
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.4118
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.89703
GaussianMLPPolicy/KL                      0.00855744
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.0589935
GaussianMLPPolicy/LossBefore              0.467373
GaussianMLPPolicy/dLoss                   0.408379
GaussianMLPValueFunction/LossAfter        6.3897
GaussianMLPValueFunction/LossBefore       6.39261
GaussianMLPValueFunction/dLoss            0.00291204
TotalEnvSteps                        730800
-----------------------------------  ---------------
2022-08-17 18:11:09 | [trpo_pendulum] epoch #609 | Saving snapshot...
2022-08-17 18:11:09 | [trpo_pendulum] epoch #609 | Saved
2022-08-17 18:11:09 | [trpo_pendulum] epoch #609 | Time 385.54 s
2022-08-17 18:11:09 | [trpo_pendulum] epoch #609 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -689.33
Evaluation/AverageReturn              -1614.57
Evaluation/Iteration                    609
Evaluation/MaxReturn                  -1589.77
Evaluation/MinReturn                  -1644.11
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     17.9726
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.89777
GaussianMLPPolicy/KL                      0.00799961
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              68.3244
GaussianMLPPolicy/LossBefore             70.4495
GaussianMLPPolicy/dLoss                   2.12505
GaussianMLPValueFunction/LossAfter        6.94323
GaussianMLPValueFunction/LossBefore       7.08651
GaussianMLPValueFunction/dLoss            0.143282
TotalEnvSteps                        732000
-----------------------------------  ---------------
2022-08-17 18:11:10 | [trpo_pendulum] epoch #610 | Saving snapshot...
2022-08-17 18:11:10 | [trpo_pendulum] epoch #610 | Saved
2022-08-17 18:11:10 | [trpo_pendulum] epoch #610 | Time 386.16 s
2022-08-17 18:11:10 | [trpo_pendulum] epoch #610 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -372.874
Evaluation/AverageReturn               -976.483
Evaluation/Iteration                    610
Evaluation/MaxReturn                   -917.078
Evaluation/MinReturn                  -1045.11
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     48.2134
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.89659
GaussianMLPPolicy/KL                      0.00830299
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -13.699
GaussianMLPPolicy/LossBefore            -13.2343
GaussianMLPPolicy/dLoss                   0.464615
GaussianMLPValueFunction/LossAfter        6.36699
GaussianMLPValueFunction/LossBefore       6.377
GaussianMLPValueFunction/dLoss            0.0100045
TotalEnvSteps                        733200
-----------------------------------  ---------------
2022-08-17 18:11:11 | [trpo_pendulum] epoch #611 | Saving snapshot...
2022-08-17 18:11:11 | [trpo_pendulum] epoch #611 | Saved
2022-08-17 18:11:11 | [trpo_pendulum] epoch #611 | Time 386.82 s
2022-08-17 18:11:11 | [trpo_pendulum] epoch #611 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -717.224
Evaluation/AverageReturn              -1647.37
Evaluation/Iteration                    611
Evaluation/MaxReturn                  -1597.58
Evaluation/MinReturn                  -1702.81
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     32.9985
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.87591
GaussianMLPPolicy/KL                      0.00984948
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              69.2725
GaussianMLPPolicy/LossBefore             71.1993
GaussianMLPPolicy/dLoss                   1.92675
GaussianMLPValueFunction/LossAfter        6.92678
GaussianMLPValueFunction/LossBefore       6.99434
GaussianMLPValueFunction/dLoss            0.0675569
TotalEnvSteps                        734400
-----------------------------------  ---------------
2022-08-17 18:11:11 | [trpo_pendulum] epoch #612 | Saving snapshot...
2022-08-17 18:11:11 | [trpo_pendulum] epoch #612 | Saved
2022-08-17 18:11:11 | [trpo_pendulum] epoch #612 | Time 387.52 s
2022-08-17 18:11:11 | [trpo_pendulum] epoch #612 | EpochTime 0.69 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -450.779
Evaluation/AverageReturn              -1137.46
Evaluation/Iteration                    612
Evaluation/MaxReturn                   -772.668
Evaluation/MinReturn                  -1365.16
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    214.235
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.85082
GaussianMLPPolicy/KL                      0.00719737
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               3.83715
GaussianMLPPolicy/LossBefore              5.21527
GaussianMLPPolicy/dLoss                   1.37812
GaussianMLPValueFunction/LossAfter        6.48779
GaussianMLPValueFunction/LossBefore       6.48997
GaussianMLPValueFunction/dLoss            0.00218201
TotalEnvSteps                        735600
-----------------------------------  ---------------
2022-08-17 18:11:12 | [trpo_pendulum] epoch #613 | Saving snapshot...
2022-08-17 18:11:12 | [trpo_pendulum] epoch #613 | Saved
2022-08-17 18:11:12 | [trpo_pendulum] epoch #613 | Time 388.19 s
2022-08-17 18:11:12 | [trpo_pendulum] epoch #613 | EpochTime 0.67 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -668.738
Evaluation/AverageReturn              -1562.73
Evaluation/Iteration                    613
Evaluation/MaxReturn                  -1497.58
Evaluation/MinReturn                  -1604.88
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     39.8499
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.85896
GaussianMLPPolicy/KL                      0.00869885
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              58.2461
GaussianMLPPolicy/LossBefore             60.6819
GaussianMLPPolicy/dLoss                   2.43573
GaussianMLPValueFunction/LossAfter        6.77854
GaussianMLPValueFunction/LossBefore       6.79799
GaussianMLPValueFunction/dLoss            0.019443
TotalEnvSteps                        736800
-----------------------------------  ---------------
2022-08-17 18:11:13 | [trpo_pendulum] epoch #614 | Saving snapshot...
2022-08-17 18:11:13 | [trpo_pendulum] epoch #614 | Saved
2022-08-17 18:11:13 | [trpo_pendulum] epoch #614 | Time 388.86 s
2022-08-17 18:11:13 | [trpo_pendulum] epoch #614 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -682.687
Evaluation/AverageReturn              -1585.46
Evaluation/Iteration                    614
Evaluation/MaxReturn                  -1498.85
Evaluation/MinReturn                  -1634.96
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     51.008
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.8615
GaussianMLPPolicy/KL                      0.00633465
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              59.9412
GaussianMLPPolicy/LossBefore             62.2324
GaussianMLPPolicy/dLoss                   2.29123
GaussianMLPValueFunction/LossAfter        6.79589
GaussianMLPValueFunction/LossBefore       6.8136
GaussianMLPValueFunction/dLoss            0.017714
TotalEnvSteps                        738000
-----------------------------------  ---------------
2022-08-17 18:11:13 | [trpo_pendulum] epoch #615 | Saving snapshot...
2022-08-17 18:11:13 | [trpo_pendulum] epoch #615 | Saved
2022-08-17 18:11:13 | [trpo_pendulum] epoch #615 | Time 389.51 s
2022-08-17 18:11:13 | [trpo_pendulum] epoch #615 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -378.843
Evaluation/AverageReturn               -953.199
Evaluation/Iteration                    615
Evaluation/MaxReturn                   -858.815
Evaluation/MinReturn                  -1155.07
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     98.7534
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.86777
GaussianMLPPolicy/KL                      0.00625266
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -22.9739
GaussianMLPPolicy/LossBefore            -21.5513
GaussianMLPPolicy/dLoss                   1.42264
GaussianMLPValueFunction/LossAfter        6.41428
GaussianMLPValueFunction/LossBefore       6.43162
GaussianMLPValueFunction/dLoss            0.0173368
TotalEnvSteps                        739200
-----------------------------------  ---------------
2022-08-17 18:11:14 | [trpo_pendulum] epoch #616 | Saving snapshot...
2022-08-17 18:11:14 | [trpo_pendulum] epoch #616 | Saved
2022-08-17 18:11:14 | [trpo_pendulum] epoch #616 | Time 390.16 s
2022-08-17 18:11:14 | [trpo_pendulum] epoch #616 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -538.591
Evaluation/AverageReturn              -1234.23
Evaluation/Iteration                    616
Evaluation/MaxReturn                  -1132.37
Evaluation/MinReturn                  -1436.63
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    112.071
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.84945
GaussianMLPPolicy/KL                      0.00945341
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               8.57547
GaussianMLPPolicy/LossBefore             11.9721
GaussianMLPPolicy/dLoss                   3.39666
GaussianMLPValueFunction/LossAfter        6.51534
GaussianMLPValueFunction/LossBefore       6.51822
GaussianMLPValueFunction/dLoss            0.00287437
TotalEnvSteps                        740400
-----------------------------------  ---------------
2022-08-17 18:11:14 | [trpo_pendulum] epoch #617 | Saving snapshot...
2022-08-17 18:11:15 | [trpo_pendulum] epoch #617 | Saved
2022-08-17 18:11:15 | [trpo_pendulum] epoch #617 | Time 390.80 s
2022-08-17 18:11:15 | [trpo_pendulum] epoch #617 | EpochTime 0.63 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -572.944
Evaluation/AverageReturn              -1327.04
Evaluation/Iteration                    617
Evaluation/MaxReturn                  -1061.74
Evaluation/MinReturn                  -1618.74
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    208.308
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.87979
GaussianMLPPolicy/KL                      0.00922975
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              19.6135
GaussianMLPPolicy/LossBefore             24.7805
GaussianMLPPolicy/dLoss                   5.167
GaussianMLPValueFunction/LossAfter        6.57487
GaussianMLPValueFunction/LossBefore       6.57516
GaussianMLPValueFunction/dLoss            0.000289917
TotalEnvSteps                        741600
-----------------------------------  ----------------
2022-08-17 18:11:15 | [trpo_pendulum] epoch #618 | Saving snapshot...
2022-08-17 18:11:15 | [trpo_pendulum] epoch #618 | Saved
2022-08-17 18:11:15 | [trpo_pendulum] epoch #618 | Time 391.45 s
2022-08-17 18:11:15 | [trpo_pendulum] epoch #618 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -518.86
Evaluation/AverageReturn              -1307.38
Evaluation/Iteration                    618
Evaluation/MaxReturn                  -1085.03
Evaluation/MinReturn                  -1422.66
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    120.026
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.90174
GaussianMLPPolicy/KL                      0.00585056
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              28.358
GaussianMLPPolicy/LossBefore             29.4208
GaussianMLPPolicy/dLoss                   1.0628
GaussianMLPValueFunction/LossAfter        6.54305
GaussianMLPValueFunction/LossBefore       6.54464
GaussianMLPValueFunction/dLoss            0.00159025
TotalEnvSteps                        742800
-----------------------------------  ---------------
2022-08-17 18:11:16 | [trpo_pendulum] epoch #619 | Saving snapshot...
2022-08-17 18:11:16 | [trpo_pendulum] epoch #619 | Saved
2022-08-17 18:11:16 | [trpo_pendulum] epoch #619 | Time 392.11 s
2022-08-17 18:11:16 | [trpo_pendulum] epoch #619 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -411.711
Evaluation/AverageReturn              -1054.38
Evaluation/Iteration                    619
Evaluation/MaxReturn                   -758.774
Evaluation/MinReturn                  -1201.38
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    168.077
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.92212
GaussianMLPPolicy/KL                      0.00701298
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -10.8588
GaussianMLPPolicy/LossBefore             -8.94961
GaussianMLPPolicy/dLoss                   1.9092
GaussianMLPValueFunction/LossAfter        6.42594
GaussianMLPValueFunction/LossBefore       6.43563
GaussianMLPValueFunction/dLoss            0.00969267
TotalEnvSteps                        744000
-----------------------------------  ---------------
2022-08-17 18:11:16 | [trpo_pendulum] epoch #620 | Saving snapshot...
2022-08-17 18:11:16 | [trpo_pendulum] epoch #620 | Saved
2022-08-17 18:11:16 | [trpo_pendulum] epoch #620 | Time 392.77 s
2022-08-17 18:11:16 | [trpo_pendulum] epoch #620 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -337.33
Evaluation/AverageReturn               -861.604
Evaluation/Iteration                    620
Evaluation/MaxReturn                   -760.827
Evaluation/MinReturn                   -985.035
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     98.0856
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.90878
GaussianMLPPolicy/KL                      0.00571561
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -35.5772
GaussianMLPPolicy/LossBefore            -34.1318
GaussianMLPPolicy/dLoss                   1.44539
GaussianMLPValueFunction/LossAfter        6.40655
GaussianMLPValueFunction/LossBefore       6.42234
GaussianMLPValueFunction/dLoss            0.0157962
TotalEnvSteps                        745200
-----------------------------------  ---------------
2022-08-17 18:11:17 | [trpo_pendulum] epoch #621 | Saving snapshot...
2022-08-17 18:11:17 | [trpo_pendulum] epoch #621 | Saved
2022-08-17 18:11:17 | [trpo_pendulum] epoch #621 | Time 393.43 s
2022-08-17 18:11:17 | [trpo_pendulum] epoch #621 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -537.379
Evaluation/AverageReturn              -1328.96
Evaluation/Iteration                    621
Evaluation/MaxReturn                  -1181.9
Evaluation/MinReturn                  -1430.03
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     79.67
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.94041
GaussianMLPPolicy/KL                      0.00643465
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              31.381
GaussianMLPPolicy/LossBefore             32.1606
GaussianMLPPolicy/dLoss                   0.779625
GaussianMLPValueFunction/LossAfter        6.52046
GaussianMLPValueFunction/LossBefore       6.52176
GaussianMLPValueFunction/dLoss            0.00130558
TotalEnvSteps                        746400
-----------------------------------  ---------------
2022-08-17 18:11:18 | [trpo_pendulum] epoch #622 | Saving snapshot...
2022-08-17 18:11:18 | [trpo_pendulum] epoch #622 | Saved
2022-08-17 18:11:18 | [trpo_pendulum] epoch #622 | Time 394.08 s
2022-08-17 18:11:18 | [trpo_pendulum] epoch #622 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -374.374
Evaluation/AverageReturn              -1048.1
Evaluation/Iteration                    622
Evaluation/MaxReturn                   -773.875
Evaluation/MinReturn                  -1252.16
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    142.81
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.92556
GaussianMLPPolicy/KL                      0.00547864
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -1.71848
GaussianMLPPolicy/LossBefore             -0.977689
GaussianMLPPolicy/dLoss                   0.740792
GaussianMLPValueFunction/LossAfter        6.36158
GaussianMLPValueFunction/LossBefore       6.37151
GaussianMLPValueFunction/dLoss            0.00992298
TotalEnvSteps                        747600
-----------------------------------  ---------------
2022-08-17 18:11:18 | [trpo_pendulum] epoch #623 | Saving snapshot...
2022-08-17 18:11:18 | [trpo_pendulum] epoch #623 | Saved
2022-08-17 18:11:18 | [trpo_pendulum] epoch #623 | Time 394.73 s
2022-08-17 18:11:18 | [trpo_pendulum] epoch #623 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -644.312
Evaluation/AverageReturn              -1492.87
Evaluation/Iteration                    623
Evaluation/MaxReturn                  -1132.22
Evaluation/MinReturn                  -1609.28
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    163.772
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.91725
GaussianMLPPolicy/KL                      0.00986691
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              47.293
GaussianMLPPolicy/LossBefore             49.9209
GaussianMLPPolicy/dLoss                   2.62798
GaussianMLPValueFunction/LossAfter        6.76612
GaussianMLPValueFunction/LossBefore       6.80961
GaussianMLPValueFunction/dLoss            0.0434937
TotalEnvSteps                        748800
-----------------------------------  ---------------
2022-08-17 18:11:19 | [trpo_pendulum] epoch #624 | Saving snapshot...
2022-08-17 18:11:19 | [trpo_pendulum] epoch #624 | Saved
2022-08-17 18:11:19 | [trpo_pendulum] epoch #624 | Time 395.38 s
2022-08-17 18:11:19 | [trpo_pendulum] epoch #624 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -688.279
Evaluation/AverageReturn              -1594.17
Evaluation/Iteration                    624
Evaluation/MaxReturn                  -1575.82
Evaluation/MinReturn                  -1610.86
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.7964
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.92262
GaussianMLPPolicy/KL                      0.00642256
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              61.198
GaussianMLPPolicy/LossBefore             63.2968
GaussianMLPPolicy/dLoss                   2.09885
GaussianMLPValueFunction/LossAfter        6.82134
GaussianMLPValueFunction/LossBefore       6.86117
GaussianMLPValueFunction/dLoss            0.0398259
TotalEnvSteps                        750000
-----------------------------------  ---------------
2022-08-17 18:11:20 | [trpo_pendulum] epoch #625 | Saving snapshot...
2022-08-17 18:11:20 | [trpo_pendulum] epoch #625 | Saved
2022-08-17 18:11:20 | [trpo_pendulum] epoch #625 | Time 396.01 s
2022-08-17 18:11:20 | [trpo_pendulum] epoch #625 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -490.144
Evaluation/AverageReturn              -1277.07
Evaluation/Iteration                    625
Evaluation/MaxReturn                  -1214.38
Evaluation/MinReturn                  -1358.6
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     54.0329
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.93539
GaussianMLPPolicy/KL                      0.00654962
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              24.1572
GaussianMLPPolicy/LossBefore             25.4517
GaussianMLPPolicy/dLoss                   1.2945
GaussianMLPValueFunction/LossAfter        6.48643
GaussianMLPValueFunction/LossBefore       6.49223
GaussianMLPValueFunction/dLoss            0.00580311
TotalEnvSteps                        751200
-----------------------------------  ---------------
2022-08-17 18:11:20 | [trpo_pendulum] epoch #626 | Saving snapshot...
2022-08-17 18:11:20 | [trpo_pendulum] epoch #626 | Saved
2022-08-17 18:11:20 | [trpo_pendulum] epoch #626 | Time 396.64 s
2022-08-17 18:11:20 | [trpo_pendulum] epoch #626 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -564.806
Evaluation/AverageReturn              -1396.44
Evaluation/Iteration                    626
Evaluation/MaxReturn                  -1282.97
Evaluation/MinReturn                  -1490.02
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     79.0551
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.92672
GaussianMLPPolicy/KL                      0.00986017
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              37.4314
GaussianMLPPolicy/LossBefore             38.7659
GaussianMLPPolicy/dLoss                   1.33458
GaussianMLPValueFunction/LossAfter        6.57093
GaussianMLPValueFunction/LossBefore       6.57323
GaussianMLPValueFunction/dLoss            0.00229359
TotalEnvSteps                        752400
-----------------------------------  ---------------
2022-08-17 18:11:21 | [trpo_pendulum] epoch #627 | Saving snapshot...
2022-08-17 18:11:21 | [trpo_pendulum] epoch #627 | Saved
2022-08-17 18:11:21 | [trpo_pendulum] epoch #627 | Time 397.30 s
2022-08-17 18:11:21 | [trpo_pendulum] epoch #627 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -581.532
Evaluation/AverageReturn              -1434.28
Evaluation/Iteration                    627
Evaluation/MaxReturn                  -1122.84
Evaluation/MinReturn                  -1527.16
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    140.558
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.89242
GaussianMLPPolicy/KL                      0.00626855
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              45.819
GaussianMLPPolicy/LossBefore             47.0295
GaussianMLPPolicy/dLoss                   1.21054
GaussianMLPValueFunction/LossAfter        6.69539
GaussianMLPValueFunction/LossBefore       6.70408
GaussianMLPValueFunction/dLoss            0.00869226
TotalEnvSteps                        753600
-----------------------------------  ---------------
2022-08-17 18:11:22 | [trpo_pendulum] epoch #628 | Saving snapshot...
2022-08-17 18:11:22 | [trpo_pendulum] epoch #628 | Saved
2022-08-17 18:11:22 | [trpo_pendulum] epoch #628 | Time 398.07 s
2022-08-17 18:11:22 | [trpo_pendulum] epoch #628 | EpochTime 0.77 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -674.056
Evaluation/AverageReturn              -1528.92
Evaluation/Iteration                    628
Evaluation/MaxReturn                  -1309.59
Evaluation/MinReturn                  -1641.38
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    137.924
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.90843
GaussianMLPPolicy/KL                      0.00635356
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              46.4534
GaussianMLPPolicy/LossBefore             49.0437
GaussianMLPPolicy/dLoss                   2.59029
GaussianMLPValueFunction/LossAfter        6.74358
GaussianMLPValueFunction/LossBefore       6.75474
GaussianMLPValueFunction/dLoss            0.0111566
TotalEnvSteps                        754800
-----------------------------------  ---------------
2022-08-17 18:11:22 | [trpo_pendulum] epoch #629 | Saving snapshot...
2022-08-17 18:11:22 | [trpo_pendulum] epoch #629 | Saved
2022-08-17 18:11:22 | [trpo_pendulum] epoch #629 | Time 398.71 s
2022-08-17 18:11:22 | [trpo_pendulum] epoch #629 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -648.49
Evaluation/AverageReturn              -1494.66
Evaluation/Iteration                    629
Evaluation/MaxReturn                  -1164.38
Evaluation/MinReturn                  -1625.02
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    170.305
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.89428
GaussianMLPPolicy/KL                      0.00974712
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              43.209
GaussianMLPPolicy/LossBefore             45.5635
GaussianMLPPolicy/dLoss                   2.35449
GaussianMLPValueFunction/LossAfter        6.7085
GaussianMLPValueFunction/LossBefore       6.71251
GaussianMLPValueFunction/dLoss            0.00401211
TotalEnvSteps                        756000
-----------------------------------  ---------------
2022-08-17 18:11:23 | [trpo_pendulum] epoch #630 | Saving snapshot...
2022-08-17 18:11:23 | [trpo_pendulum] epoch #630 | Saved
2022-08-17 18:11:23 | [trpo_pendulum] epoch #630 | Time 399.37 s
2022-08-17 18:11:23 | [trpo_pendulum] epoch #630 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -638.859
Evaluation/AverageReturn              -1511.06
Evaluation/Iteration                    630
Evaluation/MaxReturn                  -1499.86
Evaluation/MinReturn                  -1521.04
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      7.01216
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.90337
GaussianMLPPolicy/KL                      0.00946147
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              51.0692
GaussianMLPPolicy/LossBefore             51.3658
GaussianMLPPolicy/dLoss                   0.296612
GaussianMLPValueFunction/LossAfter        6.72856
GaussianMLPValueFunction/LossBefore       6.73354
GaussianMLPValueFunction/dLoss            0.00497484
TotalEnvSteps                        757200
-----------------------------------  ---------------
2022-08-17 18:11:24 | [trpo_pendulum] epoch #631 | Saving snapshot...
2022-08-17 18:11:24 | [trpo_pendulum] epoch #631 | Saved
2022-08-17 18:11:24 | [trpo_pendulum] epoch #631 | Time 400.03 s
2022-08-17 18:11:24 | [trpo_pendulum] epoch #631 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -738.211
Evaluation/AverageReturn              -1710.72
Evaluation/Iteration                    631
Evaluation/MaxReturn                  -1680.64
Evaluation/MinReturn                  -1730.5
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     17.1363
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.90253
GaussianMLPPolicy/KL                      0.00835884
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              73.0549
GaussianMLPPolicy/LossBefore             75.5274
GaussianMLPPolicy/dLoss                   2.47248
GaussianMLPValueFunction/LossAfter        6.91411
GaussianMLPValueFunction/LossBefore       6.94823
GaussianMLPValueFunction/dLoss            0.0341229
TotalEnvSteps                        758400
-----------------------------------  ---------------
2022-08-17 18:11:24 | [trpo_pendulum] epoch #632 | Saving snapshot...
2022-08-17 18:11:24 | [trpo_pendulum] epoch #632 | Saved
2022-08-17 18:11:24 | [trpo_pendulum] epoch #632 | Time 400.66 s
2022-08-17 18:11:24 | [trpo_pendulum] epoch #632 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -708.414
Evaluation/AverageReturn              -1654.26
Evaluation/Iteration                    632
Evaluation/MaxReturn                  -1581.31
Evaluation/MinReturn                  -1727.74
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     53.8302
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.88417
GaussianMLPPolicy/KL                      0.00916053
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              65.7383
GaussianMLPPolicy/LossBefore             68.1869
GaussianMLPPolicy/dLoss                   2.44863
GaussianMLPValueFunction/LossAfter        6.85094
GaussianMLPValueFunction/LossBefore       6.86047
GaussianMLPValueFunction/dLoss            0.00952959
TotalEnvSteps                        759600
-----------------------------------  ---------------
2022-08-17 18:11:25 | [trpo_pendulum] epoch #633 | Saving snapshot...
2022-08-17 18:11:25 | [trpo_pendulum] epoch #633 | Saved
2022-08-17 18:11:25 | [trpo_pendulum] epoch #633 | Time 401.36 s
2022-08-17 18:11:25 | [trpo_pendulum] epoch #633 | EpochTime 0.69 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -646.141
Evaluation/AverageReturn              -1543.37
Evaluation/Iteration                    633
Evaluation/MaxReturn                  -1526.07
Evaluation/MinReturn                  -1580.16
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     17.3527
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.89527
GaussianMLPPolicy/KL                      0.00582117
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              54.3663
GaussianMLPPolicy/LossBefore             55.2639
GaussianMLPPolicy/dLoss                   0.897663
GaussianMLPValueFunction/LossAfter        6.76683
GaussianMLPValueFunction/LossBefore       6.76892
GaussianMLPValueFunction/dLoss            0.00208712
TotalEnvSteps                        760800
-----------------------------------  ---------------
2022-08-17 18:11:26 | [trpo_pendulum] epoch #634 | Saving snapshot...
2022-08-17 18:11:26 | [trpo_pendulum] epoch #634 | Saved
2022-08-17 18:11:26 | [trpo_pendulum] epoch #634 | Time 401.99 s
2022-08-17 18:11:26 | [trpo_pendulum] epoch #634 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -651.334
Evaluation/AverageReturn              -1529.46
Evaluation/Iteration                    634
Evaluation/MaxReturn                  -1507.47
Evaluation/MinReturn                  -1548.35
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.0784
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.91212
GaussianMLPPolicy/KL                      0.00437768
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              49.6194
GaussianMLPPolicy/LossBefore             50.6753
GaussianMLPPolicy/dLoss                   1.05589
GaussianMLPValueFunction/LossAfter        6.74712
GaussianMLPValueFunction/LossBefore       6.74909
GaussianMLPValueFunction/dLoss            0.00196981
TotalEnvSteps                        762000
-----------------------------------  ---------------
2022-08-17 18:11:26 | [trpo_pendulum] epoch #635 | Saving snapshot...
2022-08-17 18:11:26 | [trpo_pendulum] epoch #635 | Saved
2022-08-17 18:11:26 | [trpo_pendulum] epoch #635 | Time 402.63 s
2022-08-17 18:11:26 | [trpo_pendulum] epoch #635 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -513.22
Evaluation/AverageReturn              -1246.29
Evaluation/Iteration                    635
Evaluation/MaxReturn                   -900.58
Evaluation/MinReturn                  -1360.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    158.248
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.9424
GaussianMLPPolicy/KL                      0.00828351
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               6.3887
GaussianMLPPolicy/LossBefore              9.07587
GaussianMLPPolicy/dLoss                   2.68717
GaussianMLPValueFunction/LossAfter        6.49475
GaussianMLPValueFunction/LossBefore       6.52642
GaussianMLPValueFunction/dLoss            0.0316753
TotalEnvSteps                        763200
-----------------------------------  ---------------
2022-08-17 18:11:27 | [trpo_pendulum] epoch #636 | Saving snapshot...
2022-08-17 18:11:27 | [trpo_pendulum] epoch #636 | Saved
2022-08-17 18:11:27 | [trpo_pendulum] epoch #636 | Time 403.28 s
2022-08-17 18:11:27 | [trpo_pendulum] epoch #636 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -763.574
Evaluation/AverageReturn              -1766.38
Evaluation/Iteration                    636
Evaluation/MaxReturn                  -1753.06
Evaluation/MinReturn                  -1790.53
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     12.1839
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.94628
GaussianMLPPolicy/KL                      0.00819761
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              77.6556
GaussianMLPPolicy/LossBefore             79.8001
GaussianMLPPolicy/dLoss                   2.14445
GaussianMLPValueFunction/LossAfter        6.94788
GaussianMLPValueFunction/LossBefore       6.9854
GaussianMLPValueFunction/dLoss            0.0375156
TotalEnvSteps                        764400
-----------------------------------  ---------------
2022-08-17 18:11:28 | [trpo_pendulum] epoch #637 | Saving snapshot...
2022-08-17 18:11:28 | [trpo_pendulum] epoch #637 | Saved
2022-08-17 18:11:28 | [trpo_pendulum] epoch #637 | Time 403.96 s
2022-08-17 18:11:28 | [trpo_pendulum] epoch #637 | EpochTime 0.68 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -618.15
Evaluation/AverageReturn              -1504.39
Evaluation/Iteration                    637
Evaluation/MaxReturn                  -1492.15
Evaluation/MinReturn                  -1516.06
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.53839
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.9469
GaussianMLPPolicy/KL                      0.00501748
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              49.3981
GaussianMLPPolicy/LossBefore             49.6923
GaussianMLPPolicy/dLoss                   0.294197
GaussianMLPValueFunction/LossAfter        6.71088
GaussianMLPValueFunction/LossBefore       6.7135
GaussianMLPValueFunction/dLoss            0.00262499
TotalEnvSteps                        765600
-----------------------------------  ---------------
2022-08-17 18:11:28 | [trpo_pendulum] epoch #638 | Saving snapshot...
2022-08-17 18:11:28 | [trpo_pendulum] epoch #638 | Saved
2022-08-17 18:11:28 | [trpo_pendulum] epoch #638 | Time 404.65 s
2022-08-17 18:11:28 | [trpo_pendulum] epoch #638 | EpochTime 0.68 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -744.59
Evaluation/AverageReturn              -1731.03
Evaluation/Iteration                    638
Evaluation/MaxReturn                  -1677.66
Evaluation/MinReturn                  -1767.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     31.0663
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.9435
GaussianMLPPolicy/KL                      0.00709202
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              72.2402
GaussianMLPPolicy/LossBefore             74.5288
GaussianMLPPolicy/dLoss                   2.28866
GaussianMLPValueFunction/LossAfter        6.90848
GaussianMLPValueFunction/LossBefore       6.92546
GaussianMLPValueFunction/dLoss            0.0169764
TotalEnvSteps                        766800
-----------------------------------  ---------------
2022-08-17 18:11:29 | [trpo_pendulum] epoch #639 | Saving snapshot...
2022-08-17 18:11:29 | [trpo_pendulum] epoch #639 | Saved
2022-08-17 18:11:29 | [trpo_pendulum] epoch #639 | Time 405.31 s
2022-08-17 18:11:29 | [trpo_pendulum] epoch #639 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -642.575
Evaluation/AverageReturn              -1534.8
Evaluation/Iteration                    639
Evaluation/MaxReturn                  -1515.06
Evaluation/MinReturn                  -1562.21
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     16.5211
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.94953
GaussianMLPPolicy/KL                      0.00692701
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              49.3733
GaussianMLPPolicy/LossBefore             50.4145
GaussianMLPPolicy/dLoss                   1.04118
GaussianMLPValueFunction/LossAfter        6.75363
GaussianMLPValueFunction/LossBefore       6.75574
GaussianMLPValueFunction/dLoss            0.00211525
TotalEnvSteps                        768000
-----------------------------------  ---------------
2022-08-17 18:11:30 | [trpo_pendulum] epoch #640 | Saving snapshot...
2022-08-17 18:11:30 | [trpo_pendulum] epoch #640 | Saved
2022-08-17 18:11:30 | [trpo_pendulum] epoch #640 | Time 405.96 s
2022-08-17 18:11:30 | [trpo_pendulum] epoch #640 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -547.303
Evaluation/AverageReturn              -1367.39
Evaluation/Iteration                    640
Evaluation/MaxReturn                   -812.734
Evaluation/MinReturn                  -1518.63
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    252.712
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.94226
GaussianMLPPolicy/KL                      0.00715184
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              29.9579
GaussianMLPPolicy/LossBefore             30.9604
GaussianMLPPolicy/dLoss                   1.00249
GaussianMLPValueFunction/LossAfter        6.70344
GaussianMLPValueFunction/LossBefore       6.70673
GaussianMLPValueFunction/dLoss            0.0032835
TotalEnvSteps                        769200
-----------------------------------  ---------------
2022-08-17 18:11:30 | [trpo_pendulum] epoch #641 | Saving snapshot...
2022-08-17 18:11:30 | [trpo_pendulum] epoch #641 | Saved
2022-08-17 18:11:30 | [trpo_pendulum] epoch #641 | Time 406.61 s
2022-08-17 18:11:30 | [trpo_pendulum] epoch #641 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -557.482
Evaluation/AverageReturn              -1375.42
Evaluation/Iteration                    641
Evaluation/MaxReturn                   -850.404
Evaluation/MinReturn                  -1512.52
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    235.977
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.89779
GaussianMLPPolicy/KL                      0.00757097
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              26.9797
GaussianMLPPolicy/LossBefore             28.4152
GaussianMLPPolicy/dLoss                   1.43555
GaussianMLPValueFunction/LossAfter        6.6542
GaussianMLPValueFunction/LossBefore       6.65998
GaussianMLPValueFunction/dLoss            0.00578403
TotalEnvSteps                        770400
-----------------------------------  ---------------
2022-08-17 18:11:31 | [trpo_pendulum] epoch #642 | Saving snapshot...
2022-08-17 18:11:31 | [trpo_pendulum] epoch #642 | Saved
2022-08-17 18:11:31 | [trpo_pendulum] epoch #642 | Time 407.23 s
2022-08-17 18:11:31 | [trpo_pendulum] epoch #642 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -609.504
Evaluation/AverageReturn              -1470.55
Evaluation/Iteration                    642
Evaluation/MaxReturn                  -1286.84
Evaluation/MinReturn                  -1581.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    105.475
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.90089
GaussianMLPPolicy/KL                      0.00643659
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              36.1745
GaussianMLPPolicy/LossBefore             39.0046
GaussianMLPPolicy/dLoss                   2.83007
GaussianMLPValueFunction/LossAfter        6.63545
GaussianMLPValueFunction/LossBefore       6.64119
GaussianMLPValueFunction/dLoss            0.00574064
TotalEnvSteps                        771600
-----------------------------------  ---------------
2022-08-17 18:11:32 | [trpo_pendulum] epoch #643 | Saving snapshot...
2022-08-17 18:11:32 | [trpo_pendulum] epoch #643 | Saved
2022-08-17 18:11:32 | [trpo_pendulum] epoch #643 | Time 407.88 s
2022-08-17 18:11:32 | [trpo_pendulum] epoch #643 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -709.964
Evaluation/AverageReturn              -1649.13
Evaluation/Iteration                    643
Evaluation/MaxReturn                  -1620.11
Evaluation/MinReturn                  -1671.02
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     16.0142
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.9081
GaussianMLPPolicy/KL                      0.00670738
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              58.6915
GaussianMLPPolicy/LossBefore             60.2372
GaussianMLPPolicy/dLoss                   1.54573
GaussianMLPValueFunction/LossAfter        6.79564
GaussianMLPValueFunction/LossBefore       6.80472
GaussianMLPValueFunction/dLoss            0.00908375
TotalEnvSteps                        772800
-----------------------------------  ---------------
2022-08-17 18:11:32 | [trpo_pendulum] epoch #644 | Saving snapshot...
2022-08-17 18:11:32 | [trpo_pendulum] epoch #644 | Saved
2022-08-17 18:11:32 | [trpo_pendulum] epoch #644 | Time 408.51 s
2022-08-17 18:11:32 | [trpo_pendulum] epoch #644 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -693.797
Evaluation/AverageReturn              -1611.66
Evaluation/Iteration                    644
Evaluation/MaxReturn                  -1522.79
Evaluation/MinReturn                  -1671.57
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     57.1195
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.88638
GaussianMLPPolicy/KL                      0.0070443
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              53.258
GaussianMLPPolicy/LossBefore             54.8034
GaussianMLPPolicy/dLoss                   1.54539
GaussianMLPValueFunction/LossAfter        6.7688
GaussianMLPValueFunction/LossBefore       6.77244
GaussianMLPValueFunction/dLoss            0.00363874
TotalEnvSteps                        774000
-----------------------------------  ---------------
2022-08-17 18:11:33 | [trpo_pendulum] epoch #645 | Saving snapshot...
2022-08-17 18:11:33 | [trpo_pendulum] epoch #645 | Saved
2022-08-17 18:11:33 | [trpo_pendulum] epoch #645 | Time 409.14 s
2022-08-17 18:11:33 | [trpo_pendulum] epoch #645 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -586.881
Evaluation/AverageReturn              -1472.39
Evaluation/Iteration                    645
Evaluation/MaxReturn                  -1388.51
Evaluation/MinReturn                  -1495.31
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     37.686
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.87208
GaussianMLPPolicy/KL                      0.00871767
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              39.7628
GaussianMLPPolicy/LossBefore             41.2393
GaussianMLPPolicy/dLoss                   1.47652
GaussianMLPValueFunction/LossAfter        6.65597
GaussianMLPValueFunction/LossBefore       6.66182
GaussianMLPValueFunction/dLoss            0.00584936
TotalEnvSteps                        775200
-----------------------------------  ---------------
2022-08-17 18:11:33 | [trpo_pendulum] epoch #646 | Saving snapshot...
2022-08-17 18:11:34 | [trpo_pendulum] epoch #646 | Saved
2022-08-17 18:11:34 | [trpo_pendulum] epoch #646 | Time 409.79 s
2022-08-17 18:11:34 | [trpo_pendulum] epoch #646 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -411.947
Evaluation/AverageReturn              -1067.38
Evaluation/Iteration                    646
Evaluation/MaxReturn                   -946.261
Evaluation/MinReturn                  -1182.66
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     82.261
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.86596
GaussianMLPPolicy/KL                      0.00909733
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -14.9615
GaussianMLPPolicy/LossBefore            -14.259
GaussianMLPPolicy/dLoss                   0.702522
GaussianMLPValueFunction/LossAfter        6.46212
GaussianMLPValueFunction/LossBefore       6.49439
GaussianMLPValueFunction/dLoss            0.0322738
TotalEnvSteps                        776400
-----------------------------------  ---------------
2022-08-17 18:11:34 | [trpo_pendulum] epoch #647 | Saving snapshot...
2022-08-17 18:11:34 | [trpo_pendulum] epoch #647 | Saved
2022-08-17 18:11:34 | [trpo_pendulum] epoch #647 | Time 410.44 s
2022-08-17 18:11:34 | [trpo_pendulum] epoch #647 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -591.778
Evaluation/AverageReturn              -1486.31
Evaluation/Iteration                    647
Evaluation/MaxReturn                  -1379.08
Evaluation/MinReturn                  -1520.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     48.8203
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.86354
GaussianMLPPolicy/KL                      0.00751847
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              42.5076
GaussianMLPPolicy/LossBefore             43.9351
GaussianMLPPolicy/dLoss                   1.42744
GaussianMLPValueFunction/LossAfter        6.69543
GaussianMLPValueFunction/LossBefore       6.69939
GaussianMLPValueFunction/dLoss            0.00395679
TotalEnvSteps                        777600
-----------------------------------  ---------------
2022-08-17 18:11:35 | [trpo_pendulum] epoch #648 | Saving snapshot...
2022-08-17 18:11:35 | [trpo_pendulum] epoch #648 | Saved
2022-08-17 18:11:35 | [trpo_pendulum] epoch #648 | Time 411.08 s
2022-08-17 18:11:35 | [trpo_pendulum] epoch #648 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -646.637
Evaluation/AverageReturn              -1570.32
Evaluation/Iteration                    648
Evaluation/MaxReturn                  -1549.64
Evaluation/MinReturn                  -1588.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.7021
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.86157
GaussianMLPPolicy/KL                      0.00581392
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              52.6547
GaussianMLPPolicy/LossBefore             53.9244
GaussianMLPPolicy/dLoss                   1.26962
GaussianMLPValueFunction/LossAfter        6.77135
GaussianMLPValueFunction/LossBefore       6.78263
GaussianMLPValueFunction/dLoss            0.0112834
TotalEnvSteps                        778800
-----------------------------------  ---------------
2022-08-17 18:11:35 | [trpo_pendulum] epoch #649 | Saving snapshot...
2022-08-17 18:11:35 | [trpo_pendulum] epoch #649 | Saved
2022-08-17 18:11:35 | [trpo_pendulum] epoch #649 | Time 411.72 s
2022-08-17 18:11:35 | [trpo_pendulum] epoch #649 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -502.289
Evaluation/AverageReturn              -1234.94
Evaluation/Iteration                    649
Evaluation/MaxReturn                  -1011.06
Evaluation/MinReturn                  -1466.98
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    139.049
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.85439
GaussianMLPPolicy/KL                      0.0066721
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.676641
GaussianMLPPolicy/LossBefore              2.21549
GaussianMLPPolicy/dLoss                   1.53885
GaussianMLPValueFunction/LossAfter        6.46781
GaussianMLPValueFunction/LossBefore       6.49101
GaussianMLPValueFunction/dLoss            0.0232062
TotalEnvSteps                        780000
-----------------------------------  --------------
2022-08-17 18:11:36 | [trpo_pendulum] epoch #650 | Saving snapshot...
2022-08-17 18:11:36 | [trpo_pendulum] epoch #650 | Saved
2022-08-17 18:11:36 | [trpo_pendulum] epoch #650 | Time 412.38 s
2022-08-17 18:11:36 | [trpo_pendulum] epoch #650 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -619.43
Evaluation/AverageReturn              -1534.58
Evaluation/Iteration                    650
Evaluation/MaxReturn                  -1514.8
Evaluation/MinReturn                  -1553.96
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.5234
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.8759
GaussianMLPPolicy/KL                      0.00766858
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              49.6778
GaussianMLPPolicy/LossBefore             51.1809
GaussianMLPPolicy/dLoss                   1.50308
GaussianMLPValueFunction/LossAfter        6.77009
GaussianMLPValueFunction/LossBefore       6.78322
GaussianMLPValueFunction/dLoss            0.0131283
TotalEnvSteps                        781200
-----------------------------------  ---------------
2022-08-17 18:11:37 | [trpo_pendulum] epoch #651 | Saving snapshot...
2022-08-17 18:11:37 | [trpo_pendulum] epoch #651 | Saved
2022-08-17 18:11:37 | [trpo_pendulum] epoch #651 | Time 413.02 s
2022-08-17 18:11:37 | [trpo_pendulum] epoch #651 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -735.437
Evaluation/AverageReturn              -1670.02
Evaluation/Iteration                    651
Evaluation/MaxReturn                  -1624.73
Evaluation/MinReturn                  -1733.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     35.6759
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.85879
GaussianMLPPolicy/KL                      0.00653177
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              55.4379
GaussianMLPPolicy/LossBefore             57.0443
GaussianMLPPolicy/dLoss                   1.60638
GaussianMLPValueFunction/LossAfter        6.80685
GaussianMLPValueFunction/LossBefore       6.82053
GaussianMLPValueFunction/dLoss            0.0136814
TotalEnvSteps                        782400
-----------------------------------  ---------------
2022-08-17 18:11:37 | [trpo_pendulum] epoch #652 | Saving snapshot...
2022-08-17 18:11:37 | [trpo_pendulum] epoch #652 | Saved
2022-08-17 18:11:37 | [trpo_pendulum] epoch #652 | Time 413.68 s
2022-08-17 18:11:37 | [trpo_pendulum] epoch #652 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -549.219
Evaluation/AverageReturn              -1308.47
Evaluation/Iteration                    652
Evaluation/MaxReturn                  -1242.54
Evaluation/MinReturn                  -1348.02
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     40.1039
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.84439
GaussianMLPPolicy/KL                      0.0054896
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              11.7002
GaussianMLPPolicy/LossBefore             12.1734
GaussianMLPPolicy/dLoss                   0.473231
GaussianMLPValueFunction/LossAfter        6.54174
GaussianMLPValueFunction/LossBefore       6.55448
GaussianMLPValueFunction/dLoss            0.0127306
TotalEnvSteps                        783600
-----------------------------------  --------------
2022-08-17 18:11:38 | [trpo_pendulum] epoch #653 | Saving snapshot...
2022-08-17 18:11:38 | [trpo_pendulum] epoch #653 | Saved
2022-08-17 18:11:38 | [trpo_pendulum] epoch #653 | Time 414.32 s
2022-08-17 18:11:38 | [trpo_pendulum] epoch #653 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -520.815
Evaluation/AverageReturn              -1276.26
Evaluation/Iteration                    653
Evaluation/MaxReturn                  -1188.33
Evaluation/MinReturn                  -1347.58
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     61.1145
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.84234
GaussianMLPPolicy/KL                      0.00745227
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               7.87145
GaussianMLPPolicy/LossBefore              8.71031
GaussianMLPPolicy/dLoss                   0.838858
GaussianMLPValueFunction/LossAfter        6.51411
GaussianMLPValueFunction/LossBefore       6.52509
GaussianMLPValueFunction/dLoss            0.0109801
TotalEnvSteps                        784800
-----------------------------------  ---------------
2022-08-17 18:11:39 | [trpo_pendulum] epoch #654 | Saving snapshot...
2022-08-17 18:11:39 | [trpo_pendulum] epoch #654 | Saved
2022-08-17 18:11:39 | [trpo_pendulum] epoch #654 | Time 414.97 s
2022-08-17 18:11:39 | [trpo_pendulum] epoch #654 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -682.394
Evaluation/AverageReturn              -1605.99
Evaluation/Iteration                    654
Evaluation/MaxReturn                  -1561.94
Evaluation/MinReturn                  -1690.27
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     43.4507
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.81368
GaussianMLPPolicy/KL                      0.00919008
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              50.4215
GaussianMLPPolicy/LossBefore             52.4413
GaussianMLPPolicy/dLoss                   2.01977
GaussianMLPValueFunction/LossAfter        6.76535
GaussianMLPValueFunction/LossBefore       6.77928
GaussianMLPValueFunction/dLoss            0.0139236
TotalEnvSteps                        786000
-----------------------------------  ---------------
2022-08-17 18:11:39 | [trpo_pendulum] epoch #655 | Saving snapshot...
2022-08-17 18:11:39 | [trpo_pendulum] epoch #655 | Saved
2022-08-17 18:11:39 | [trpo_pendulum] epoch #655 | Time 415.62 s
2022-08-17 18:11:39 | [trpo_pendulum] epoch #655 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -668.041
Evaluation/AverageReturn              -1617.18
Evaluation/Iteration                    655
Evaluation/MaxReturn                  -1607.38
Evaluation/MinReturn                  -1623.35
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.70377
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.77552
GaussianMLPPolicy/KL                      0.00990116
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              56.886
GaussianMLPPolicy/LossBefore             57.3273
GaussianMLPPolicy/dLoss                   0.441383
GaussianMLPValueFunction/LossAfter        6.78147
GaussianMLPValueFunction/LossBefore       6.79323
GaussianMLPValueFunction/dLoss            0.0117607
TotalEnvSteps                        787200
-----------------------------------  ---------------
2022-08-17 18:11:40 | [trpo_pendulum] epoch #656 | Saving snapshot...
2022-08-17 18:11:40 | [trpo_pendulum] epoch #656 | Saved
2022-08-17 18:11:40 | [trpo_pendulum] epoch #656 | Time 416.27 s
2022-08-17 18:11:40 | [trpo_pendulum] epoch #656 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -603.237
Evaluation/AverageReturn              -1443.14
Evaluation/Iteration                    656
Evaluation/MaxReturn                  -1199.74
Evaluation/MinReturn                  -1714.56
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    183.1
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.79731
GaussianMLPPolicy/KL                      0.00962005
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              25.1548
GaussianMLPPolicy/LossBefore             27.647
GaussianMLPPolicy/dLoss                   2.49214
GaussianMLPValueFunction/LossAfter        6.62197
GaussianMLPValueFunction/LossBefore       6.6252
GaussianMLPValueFunction/dLoss            0.00322533
TotalEnvSteps                        788400
-----------------------------------  ---------------
2022-08-17 18:11:41 | [trpo_pendulum] epoch #657 | Saving snapshot...
2022-08-17 18:11:41 | [trpo_pendulum] epoch #657 | Saved
2022-08-17 18:11:41 | [trpo_pendulum] epoch #657 | Time 416.91 s
2022-08-17 18:11:41 | [trpo_pendulum] epoch #657 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -562.885
Evaluation/AverageReturn              -1389.06
Evaluation/Iteration                    657
Evaluation/MaxReturn                  -1197.99
Evaluation/MinReturn                  -1488.58
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    110.19
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.80909
GaussianMLPPolicy/KL                      0.00901218
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              20.4402
GaussianMLPPolicy/LossBefore             21.7385
GaussianMLPPolicy/dLoss                   1.29828
GaussianMLPValueFunction/LossAfter        6.53956
GaussianMLPValueFunction/LossBefore       6.54915
GaussianMLPValueFunction/dLoss            0.0095892
TotalEnvSteps                        789600
-----------------------------------  ---------------
2022-08-17 18:11:41 | [trpo_pendulum] epoch #658 | Saving snapshot...
2022-08-17 18:11:41 | [trpo_pendulum] epoch #658 | Saved
2022-08-17 18:11:41 | [trpo_pendulum] epoch #658 | Time 417.56 s
2022-08-17 18:11:41 | [trpo_pendulum] epoch #658 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -608.172
Evaluation/AverageReturn              -1514.47
Evaluation/Iteration                    658
Evaluation/MaxReturn                  -1498.79
Evaluation/MinReturn                  -1526.89
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.21397
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.81857
GaussianMLPPolicy/KL                      0.00812678
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              41.1792
GaussianMLPPolicy/LossBefore             42.8535
GaussianMLPPolicy/dLoss                   1.67428
GaussianMLPValueFunction/LossAfter        6.6973
GaussianMLPValueFunction/LossBefore       6.70176
GaussianMLPValueFunction/dLoss            0.0044651
TotalEnvSteps                        790800
-----------------------------------  ---------------
2022-08-17 18:11:42 | [trpo_pendulum] epoch #659 | Saving snapshot...
2022-08-17 18:11:42 | [trpo_pendulum] epoch #659 | Saved
2022-08-17 18:11:42 | [trpo_pendulum] epoch #659 | Time 418.20 s
2022-08-17 18:11:42 | [trpo_pendulum] epoch #659 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -424.336
Evaluation/AverageReturn              -1189.61
Evaluation/Iteration                    659
Evaluation/MaxReturn                  -1063.91
Evaluation/MinReturn                  -1239.18
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     59.3688
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.81599
GaussianMLPPolicy/KL                      0.00681615
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               3.93842
GaussianMLPPolicy/LossBefore              5.12784
GaussianMLPPolicy/dLoss                   1.18942
GaussianMLPValueFunction/LossAfter        6.50654
GaussianMLPValueFunction/LossBefore       6.51747
GaussianMLPValueFunction/dLoss            0.0109339
TotalEnvSteps                        792000
-----------------------------------  ---------------
2022-08-17 18:11:43 | [trpo_pendulum] epoch #660 | Saving snapshot...
2022-08-17 18:11:43 | [trpo_pendulum] epoch #660 | Saved
2022-08-17 18:11:43 | [trpo_pendulum] epoch #660 | Time 418.87 s
2022-08-17 18:11:43 | [trpo_pendulum] epoch #660 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -709.508
Evaluation/AverageReturn              -1614.84
Evaluation/Iteration                    660
Evaluation/MaxReturn                  -1571.7
Evaluation/MinReturn                  -1661.82
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     33.8263
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.81621
GaussianMLPPolicy/KL                      0.00673531
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              44.794
GaussianMLPPolicy/LossBefore             46.6158
GaussianMLPPolicy/dLoss                   1.8218
GaussianMLPValueFunction/LossAfter        6.72971
GaussianMLPValueFunction/LossBefore       6.74004
GaussianMLPValueFunction/dLoss            0.0103364
TotalEnvSteps                        793200
-----------------------------------  ---------------
2022-08-17 18:11:43 | [trpo_pendulum] epoch #661 | Saving snapshot...
2022-08-17 18:11:43 | [trpo_pendulum] epoch #661 | Saved
2022-08-17 18:11:43 | [trpo_pendulum] epoch #661 | Time 419.51 s
2022-08-17 18:11:43 | [trpo_pendulum] epoch #661 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -666.587
Evaluation/AverageReturn              -1604.43
Evaluation/Iteration                    661
Evaluation/MaxReturn                  -1585.51
Evaluation/MinReturn                  -1621.51
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.5912
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.82728
GaussianMLPPolicy/KL                      0.00583571
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              50.0323
GaussianMLPPolicy/LossBefore             51.4034
GaussianMLPPolicy/dLoss                   1.37107
GaussianMLPValueFunction/LossAfter        6.74849
GaussianMLPValueFunction/LossBefore       6.75811
GaussianMLPValueFunction/dLoss            0.00961494
TotalEnvSteps                        794400
-----------------------------------  ---------------
2022-08-17 18:11:44 | [trpo_pendulum] epoch #662 | Saving snapshot...
2022-08-17 18:11:44 | [trpo_pendulum] epoch #662 | Saved
2022-08-17 18:11:44 | [trpo_pendulum] epoch #662 | Time 420.15 s
2022-08-17 18:11:44 | [trpo_pendulum] epoch #662 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -537.391
Evaluation/AverageReturn              -1335.99
Evaluation/Iteration                    662
Evaluation/MaxReturn                  -1189.31
Evaluation/MinReturn                  -1506.8
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    129.249
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.8175
GaussianMLPPolicy/KL                      0.00682486
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              13.3871
GaussianMLPPolicy/LossBefore             14.7464
GaussianMLPPolicy/dLoss                   1.35926
GaussianMLPValueFunction/LossAfter        6.56888
GaussianMLPValueFunction/LossBefore       6.57512
GaussianMLPValueFunction/dLoss            0.00624275
TotalEnvSteps                        795600
-----------------------------------  ---------------
2022-08-17 18:11:44 | [trpo_pendulum] epoch #663 | Saving snapshot...
2022-08-17 18:11:45 | [trpo_pendulum] epoch #663 | Saved
2022-08-17 18:11:45 | [trpo_pendulum] epoch #663 | Time 420.78 s
2022-08-17 18:11:45 | [trpo_pendulum] epoch #663 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -714.975
Evaluation/AverageReturn              -1623.55
Evaluation/Iteration                    663
Evaluation/MaxReturn                  -1560.02
Evaluation/MinReturn                  -1680.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.3417
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.81122
GaussianMLPPolicy/KL                      0.008872
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              43.8176
GaussianMLPPolicy/LossBefore             45.9201
GaussianMLPPolicy/dLoss                   2.10241
GaussianMLPValueFunction/LossAfter        6.73701
GaussianMLPValueFunction/LossBefore       6.74371
GaussianMLPValueFunction/dLoss            0.00669861
TotalEnvSteps                        796800
-----------------------------------  ---------------
2022-08-17 18:11:45 | [trpo_pendulum] epoch #664 | Saving snapshot...
2022-08-17 18:11:45 | [trpo_pendulum] epoch #664 | Saved
2022-08-17 18:11:45 | [trpo_pendulum] epoch #664 | Time 421.40 s
2022-08-17 18:11:45 | [trpo_pendulum] epoch #664 | EpochTime 0.62 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -696.353
Evaluation/AverageReturn              -1567.36
Evaluation/Iteration                    664
Evaluation/MaxReturn                  -1532.3
Evaluation/MinReturn                  -1643.85
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     35.6549
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.8023
GaussianMLPPolicy/KL                      0.00621556
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              35.0176
GaussianMLPPolicy/LossBefore             36.3946
GaussianMLPPolicy/dLoss                   1.37691
GaussianMLPValueFunction/LossAfter        6.68328
GaussianMLPValueFunction/LossBefore       6.68421
GaussianMLPValueFunction/dLoss            0.000923157
TotalEnvSteps                        798000
-----------------------------------  ----------------
2022-08-17 18:11:46 | [trpo_pendulum] epoch #665 | Saving snapshot...
2022-08-17 18:11:46 | [trpo_pendulum] epoch #665 | Saved
2022-08-17 18:11:46 | [trpo_pendulum] epoch #665 | Time 422.04 s
2022-08-17 18:11:46 | [trpo_pendulum] epoch #665 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -602.702
Evaluation/AverageReturn              -1489.59
Evaluation/Iteration                    665
Evaluation/MaxReturn                  -1477.78
Evaluation/MinReturn                  -1529.73
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     18.3982
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.82196
GaussianMLPPolicy/KL                      0.00541936
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              33.6865
GaussianMLPPolicy/LossBefore             34.8864
GaussianMLPPolicy/dLoss                   1.19989
GaussianMLPValueFunction/LossAfter        6.63022
GaussianMLPValueFunction/LossBefore       6.63287
GaussianMLPValueFunction/dLoss            0.00264788
TotalEnvSteps                        799200
-----------------------------------  ---------------
2022-08-17 18:11:46 | [trpo_pendulum] epoch #666 | Saving snapshot...
2022-08-17 18:11:46 | [trpo_pendulum] epoch #666 | Saved
2022-08-17 18:11:46 | [trpo_pendulum] epoch #666 | Time 422.72 s
2022-08-17 18:11:46 | [trpo_pendulum] epoch #666 | EpochTime 0.67 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -608.289
Evaluation/AverageReturn              -1491.84
Evaluation/Iteration                    666
Evaluation/MaxReturn                  -1460.03
Evaluation/MinReturn                  -1521.26
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     20.9467
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.83176
GaussianMLPPolicy/KL                      0.0068584
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              35.1847
GaussianMLPPolicy/LossBefore             35.8574
GaussianMLPPolicy/dLoss                   0.672653
GaussianMLPValueFunction/LossAfter        6.6551
GaussianMLPValueFunction/LossBefore       6.65633
GaussianMLPValueFunction/dLoss            0.00122881
TotalEnvSteps                        800400
-----------------------------------  ---------------
2022-08-17 18:11:47 | [trpo_pendulum] epoch #667 | Saving snapshot...
2022-08-17 18:11:47 | [trpo_pendulum] epoch #667 | Saved
2022-08-17 18:11:47 | [trpo_pendulum] epoch #667 | Time 423.41 s
2022-08-17 18:11:47 | [trpo_pendulum] epoch #667 | EpochTime 0.68 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -585.839
Evaluation/AverageReturn              -1434.87
Evaluation/Iteration                    667
Evaluation/MaxReturn                  -1385.28
Evaluation/MinReturn                  -1481.9
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     40.1962
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.85303
GaussianMLPPolicy/KL                      0.00668787
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              24.0051
GaussianMLPPolicy/LossBefore             25.5058
GaussianMLPPolicy/dLoss                   1.50077
GaussianMLPValueFunction/LossAfter        6.60185
GaussianMLPValueFunction/LossBefore       6.6042
GaussianMLPValueFunction/dLoss            0.00235415
TotalEnvSteps                        801600
-----------------------------------  ---------------
2022-08-17 18:11:48 | [trpo_pendulum] epoch #668 | Saving snapshot...
2022-08-17 18:11:48 | [trpo_pendulum] epoch #668 | Saved
2022-08-17 18:11:48 | [trpo_pendulum] epoch #668 | Time 424.06 s
2022-08-17 18:11:48 | [trpo_pendulum] epoch #668 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -503.767
Evaluation/AverageReturn              -1348.18
Evaluation/Iteration                    668
Evaluation/MaxReturn                  -1301.25
Evaluation/MinReturn                  -1378.69
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     27.2801
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.84052
GaussianMLPPolicy/KL                      0.00833922
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              21.685
GaussianMLPPolicy/LossBefore             22.397
GaussianMLPPolicy/dLoss                   0.712091
GaussianMLPValueFunction/LossAfter        6.58034
GaussianMLPValueFunction/LossBefore       6.58263
GaussianMLPValueFunction/dLoss            0.0022831
TotalEnvSteps                        802800
-----------------------------------  ---------------
2022-08-17 18:11:48 | [trpo_pendulum] epoch #669 | Saving snapshot...
2022-08-17 18:11:48 | [trpo_pendulum] epoch #669 | Saved
2022-08-17 18:11:48 | [trpo_pendulum] epoch #669 | Time 424.71 s
2022-08-17 18:11:48 | [trpo_pendulum] epoch #669 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -601.038
Evaluation/AverageReturn              -1483.12
Evaluation/Iteration                    669
Evaluation/MaxReturn                  -1384.32
Evaluation/MinReturn                  -1561.33
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     69.2679
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.87566
GaussianMLPPolicy/KL                      0.00818356
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              30.8529
GaussianMLPPolicy/LossBefore             32.7393
GaussianMLPPolicy/dLoss                   1.88645
GaussianMLPValueFunction/LossAfter        6.67034
GaussianMLPValueFunction/LossBefore       6.67373
GaussianMLPValueFunction/dLoss            0.00338554
TotalEnvSteps                        804000
-----------------------------------  ---------------
2022-08-17 18:11:49 | [trpo_pendulum] epoch #670 | Saving snapshot...
2022-08-17 18:11:49 | [trpo_pendulum] epoch #670 | Saved
2022-08-17 18:11:49 | [trpo_pendulum] epoch #670 | Time 425.37 s
2022-08-17 18:11:49 | [trpo_pendulum] epoch #670 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -702.231
Evaluation/AverageReturn              -1617.55
Evaluation/Iteration                    670
Evaluation/MaxReturn                  -1555.49
Evaluation/MinReturn                  -1661.26
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     31.7354
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.8493
GaussianMLPPolicy/KL                      0.00762806
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              41.5354
GaussianMLPPolicy/LossBefore             43.7868
GaussianMLPPolicy/dLoss                   2.25142
GaussianMLPValueFunction/LossAfter        6.73767
GaussianMLPValueFunction/LossBefore       6.74703
GaussianMLPValueFunction/dLoss            0.00935745
TotalEnvSteps                        805200
-----------------------------------  ---------------
2022-08-17 18:11:50 | [trpo_pendulum] epoch #671 | Saving snapshot...
2022-08-17 18:11:50 | [trpo_pendulum] epoch #671 | Saved
2022-08-17 18:11:50 | [trpo_pendulum] epoch #671 | Time 426.02 s
2022-08-17 18:11:50 | [trpo_pendulum] epoch #671 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -667.482
Evaluation/AverageReturn              -1570.82
Evaluation/Iteration                    671
Evaluation/MaxReturn                  -1519.63
Evaluation/MinReturn                  -1622.68
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     40.3082
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.8868
GaussianMLPPolicy/KL                      0.00669412
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              36.3121
GaussianMLPPolicy/LossBefore             39.0524
GaussianMLPPolicy/dLoss                   2.74029
GaussianMLPValueFunction/LossAfter        6.68464
GaussianMLPValueFunction/LossBefore       6.68622
GaussianMLPValueFunction/dLoss            0.00158167
TotalEnvSteps                        806400
-----------------------------------  ---------------
2022-08-17 18:11:50 | [trpo_pendulum] epoch #672 | Saving snapshot...
2022-08-17 18:11:50 | [trpo_pendulum] epoch #672 | Saved
2022-08-17 18:11:50 | [trpo_pendulum] epoch #672 | Time 426.66 s
2022-08-17 18:11:50 | [trpo_pendulum] epoch #672 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -492.135
Evaluation/AverageReturn              -1284.81
Evaluation/Iteration                    672
Evaluation/MaxReturn                  -1213.05
Evaluation/MinReturn                  -1337.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     41.857
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.85081
GaussianMLPPolicy/KL                      0.00813156
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               7.99476
GaussianMLPPolicy/LossBefore              8.58594
GaussianMLPPolicy/dLoss                   0.591179
GaussianMLPValueFunction/LossAfter        6.53218
GaussianMLPValueFunction/LossBefore       6.54566
GaussianMLPValueFunction/dLoss            0.0134807
TotalEnvSteps                        807600
-----------------------------------  ---------------
2022-08-17 18:11:51 | [trpo_pendulum] epoch #673 | Saving snapshot...
2022-08-17 18:11:51 | [trpo_pendulum] epoch #673 | Saved
2022-08-17 18:11:51 | [trpo_pendulum] epoch #673 | Time 427.29 s
2022-08-17 18:11:51 | [trpo_pendulum] epoch #673 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -526.968
Evaluation/AverageReturn              -1292.88
Evaluation/Iteration                    673
Evaluation/MaxReturn                  -1197.48
Evaluation/MinReturn                  -1353.63
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     52.7386
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.8409
GaussianMLPPolicy/KL                      0.00995027
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               1.40693
GaussianMLPPolicy/LossBefore              3.09548
GaussianMLPPolicy/dLoss                   1.68855
GaussianMLPValueFunction/LossAfter        6.52604
GaussianMLPValueFunction/LossBefore       6.53288
GaussianMLPValueFunction/dLoss            0.00683928
TotalEnvSteps                        808800
-----------------------------------  ---------------
2022-08-17 18:11:52 | [trpo_pendulum] epoch #674 | Saving snapshot...
2022-08-17 18:11:52 | [trpo_pendulum] epoch #674 | Saved
2022-08-17 18:11:52 | [trpo_pendulum] epoch #674 | Time 427.94 s
2022-08-17 18:11:52 | [trpo_pendulum] epoch #674 | EpochTime 0.65 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -539.717
Evaluation/AverageReturn              -1373.49
Evaluation/Iteration                    674
Evaluation/MaxReturn                  -1278.76
Evaluation/MinReturn                  -1444.56
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     54.3064
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.85685
GaussianMLPPolicy/KL                      0.00909569
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              16.0908
GaussianMLPPolicy/LossBefore             17.7851
GaussianMLPPolicy/dLoss                   1.69429
GaussianMLPValueFunction/LossAfter        6.5557
GaussianMLPValueFunction/LossBefore       6.5564
GaussianMLPValueFunction/dLoss            0.000697613
TotalEnvSteps                        810000
-----------------------------------  ----------------
2022-08-17 18:11:52 | [trpo_pendulum] epoch #675 | Saving snapshot...
2022-08-17 18:11:52 | [trpo_pendulum] epoch #675 | Saved
2022-08-17 18:11:52 | [trpo_pendulum] epoch #675 | Time 428.63 s
2022-08-17 18:11:52 | [trpo_pendulum] epoch #675 | EpochTime 0.69 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -559.508
Evaluation/AverageReturn              -1441.27
Evaluation/Iteration                    675
Evaluation/MaxReturn                  -1319.35
Evaluation/MinReturn                  -1511.87
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     72.4665
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.83541
GaussianMLPPolicy/KL                      0.00648248
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              29.6319
GaussianMLPPolicy/LossBefore             30.86
GaussianMLPPolicy/dLoss                   1.22815
GaussianMLPValueFunction/LossAfter        6.62943
GaussianMLPValueFunction/LossBefore       6.63275
GaussianMLPValueFunction/dLoss            0.00332022
TotalEnvSteps                        811200
-----------------------------------  ---------------
2022-08-17 18:11:53 | [trpo_pendulum] epoch #676 | Saving snapshot...
2022-08-17 18:11:53 | [trpo_pendulum] epoch #676 | Saved
2022-08-17 18:11:53 | [trpo_pendulum] epoch #676 | Time 429.29 s
2022-08-17 18:11:53 | [trpo_pendulum] epoch #676 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -493.964
Evaluation/AverageReturn              -1221.62
Evaluation/Iteration                    676
Evaluation/MaxReturn                  -1131.52
Evaluation/MinReturn                  -1384.09
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     80.7107
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.82659
GaussianMLPPolicy/KL                      0.00712343
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -10.6763
GaussianMLPPolicy/LossBefore             -9.76755
GaussianMLPPolicy/dLoss                   0.908759
GaussianMLPValueFunction/LossAfter        6.4412
GaussianMLPValueFunction/LossBefore       6.45724
GaussianMLPValueFunction/dLoss            0.0160418
TotalEnvSteps                        812400
-----------------------------------  ---------------
2022-08-17 18:11:54 | [trpo_pendulum] epoch #677 | Saving snapshot...
2022-08-17 18:11:54 | [trpo_pendulum] epoch #677 | Saved
2022-08-17 18:11:54 | [trpo_pendulum] epoch #677 | Time 429.94 s
2022-08-17 18:11:54 | [trpo_pendulum] epoch #677 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -598.712
Evaluation/AverageReturn              -1474.9
Evaluation/Iteration                    677
Evaluation/MaxReturn                  -1253
Evaluation/MinReturn                  -1528.78
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     99.498
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.85325
GaussianMLPPolicy/KL                      0.00739554
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              28.8647
GaussianMLPPolicy/LossBefore             30.8607
GaussianMLPPolicy/dLoss                   1.996
GaussianMLPValueFunction/LossAfter        6.66452
GaussianMLPValueFunction/LossBefore       6.67485
GaussianMLPValueFunction/dLoss            0.0103264
TotalEnvSteps                        813600
-----------------------------------  ---------------
2022-08-17 18:11:54 | [trpo_pendulum] epoch #678 | Saving snapshot...
2022-08-17 18:11:54 | [trpo_pendulum] epoch #678 | Saved
2022-08-17 18:11:54 | [trpo_pendulum] epoch #678 | Time 430.60 s
2022-08-17 18:11:54 | [trpo_pendulum] epoch #678 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -505.968
Evaluation/AverageReturn              -1271.21
Evaluation/Iteration                    678
Evaluation/MaxReturn                  -1188.97
Evaluation/MinReturn                  -1349.42
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     59.962
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.83821
GaussianMLPPolicy/KL                      0.00778939
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               1.31196
GaussianMLPPolicy/LossBefore              1.91493
GaussianMLPPolicy/dLoss                   0.602972
GaussianMLPValueFunction/LossAfter        6.49583
GaussianMLPValueFunction/LossBefore       6.50104
GaussianMLPValueFunction/dLoss            0.00521183
TotalEnvSteps                        814800
-----------------------------------  ---------------
2022-08-17 18:11:55 | [trpo_pendulum] epoch #679 | Saving snapshot...
2022-08-17 18:11:55 | [trpo_pendulum] epoch #679 | Saved
2022-08-17 18:11:55 | [trpo_pendulum] epoch #679 | Time 431.26 s
2022-08-17 18:11:55 | [trpo_pendulum] epoch #679 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -509.27
Evaluation/AverageReturn              -1285.34
Evaluation/Iteration                    679
Evaluation/MaxReturn                  -1199.61
Evaluation/MinReturn                  -1375.44
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     70.5682
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.82217
GaussianMLPPolicy/KL                      0.00766369
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               3.89175
GaussianMLPPolicy/LossBefore              5.08639
GaussianMLPPolicy/dLoss                   1.19464
GaussianMLPValueFunction/LossAfter        6.52886
GaussianMLPValueFunction/LossBefore       6.53
GaussianMLPValueFunction/dLoss            0.00113297
TotalEnvSteps                        816000
-----------------------------------  ---------------
2022-08-17 18:11:56 | [trpo_pendulum] epoch #680 | Saving snapshot...
2022-08-17 18:11:56 | [trpo_pendulum] epoch #680 | Saved
2022-08-17 18:11:56 | [trpo_pendulum] epoch #680 | Time 431.91 s
2022-08-17 18:11:56 | [trpo_pendulum] epoch #680 | EpochTime 0.64 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -563.243
Evaluation/AverageReturn              -1395.92
Evaluation/Iteration                    680
Evaluation/MaxReturn                  -1190.86
Evaluation/MinReturn                  -1739.02
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    181.248
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.83998
GaussianMLPPolicy/KL                      0.00879095
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              15.3147
GaussianMLPPolicy/LossBefore             17.9359
GaussianMLPPolicy/dLoss                   2.62126
GaussianMLPValueFunction/LossAfter        6.58078
GaussianMLPValueFunction/LossBefore       6.58158
GaussianMLPValueFunction/dLoss            0.000804424
TotalEnvSteps                        817200
-----------------------------------  ----------------
2022-08-17 18:11:56 | [trpo_pendulum] epoch #681 | Saving snapshot...
2022-08-17 18:11:56 | [trpo_pendulum] epoch #681 | Saved
2022-08-17 18:11:56 | [trpo_pendulum] epoch #681 | Time 432.57 s
2022-08-17 18:11:56 | [trpo_pendulum] epoch #681 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -709.505
Evaluation/AverageReturn              -1633
Evaluation/Iteration                    681
Evaluation/MaxReturn                  -1522.93
Evaluation/MinReturn                  -1773.29
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     87.4256
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.83531
GaussianMLPPolicy/KL                      0.00742091
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              44.0652
GaussianMLPPolicy/LossBefore             46.1363
GaussianMLPPolicy/dLoss                   2.07119
GaussianMLPValueFunction/LossAfter        6.7988
GaussianMLPValueFunction/LossBefore       6.83737
GaussianMLPValueFunction/dLoss            0.0385723
TotalEnvSteps                        818400
-----------------------------------  ---------------
2022-08-17 18:11:57 | [trpo_pendulum] epoch #682 | Saving snapshot...
2022-08-17 18:11:57 | [trpo_pendulum] epoch #682 | Saved
2022-08-17 18:11:57 | [trpo_pendulum] epoch #682 | Time 433.21 s
2022-08-17 18:11:57 | [trpo_pendulum] epoch #682 | EpochTime 0.64 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -581.758
Evaluation/AverageReturn              -1433.55
Evaluation/Iteration                    682
Evaluation/MaxReturn                  -1179.25
Evaluation/MinReturn                  -1540.58
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    129.828
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.82775
GaussianMLPPolicy/KL                      0.00855077
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              22.0268
GaussianMLPPolicy/LossBefore             23.1592
GaussianMLPPolicy/dLoss                   1.13245
GaussianMLPValueFunction/LossAfter        6.6136
GaussianMLPValueFunction/LossBefore       6.61414
GaussianMLPValueFunction/dLoss            0.000539303
TotalEnvSteps                        819600
-----------------------------------  ----------------
2022-08-17 18:11:58 | [trpo_pendulum] epoch #683 | Saving snapshot...
2022-08-17 18:11:58 | [trpo_pendulum] epoch #683 | Saved
2022-08-17 18:11:58 | [trpo_pendulum] epoch #683 | Time 433.86 s
2022-08-17 18:11:58 | [trpo_pendulum] epoch #683 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -717.161
Evaluation/AverageReturn              -1694.31
Evaluation/Iteration                    683
Evaluation/MaxReturn                  -1641.65
Evaluation/MinReturn                  -1790.36
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.9247
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.83082
GaussianMLPPolicy/KL                      0.00793343
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              53.9179
GaussianMLPPolicy/LossBefore             56.4755
GaussianMLPPolicy/dLoss                   2.55767
GaussianMLPValueFunction/LossAfter        6.83745
GaussianMLPValueFunction/LossBefore       6.86581
GaussianMLPValueFunction/dLoss            0.0283608
TotalEnvSteps                        820800
-----------------------------------  ---------------
2022-08-17 18:11:58 | [trpo_pendulum] epoch #684 | Saving snapshot...
2022-08-17 18:11:58 | [trpo_pendulum] epoch #684 | Saved
2022-08-17 18:11:58 | [trpo_pendulum] epoch #684 | Time 434.49 s
2022-08-17 18:11:58 | [trpo_pendulum] epoch #684 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -559.501
Evaluation/AverageReturn              -1369.91
Evaluation/Iteration                    684
Evaluation/MaxReturn                  -1192.59
Evaluation/MinReturn                  -1632.54
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    130.921
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.82327
GaussianMLPPolicy/KL                      0.00839232
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               9.41605
GaussianMLPPolicy/LossBefore             11.5093
GaussianMLPPolicy/dLoss                   2.09325
GaussianMLPValueFunction/LossAfter        6.57308
GaussianMLPValueFunction/LossBefore       6.57975
GaussianMLPValueFunction/dLoss            0.00667143
TotalEnvSteps                        822000
-----------------------------------  ---------------
2022-08-17 18:11:59 | [trpo_pendulum] epoch #685 | Saving snapshot...
2022-08-17 18:11:59 | [trpo_pendulum] epoch #685 | Saved
2022-08-17 18:11:59 | [trpo_pendulum] epoch #685 | Time 435.14 s
2022-08-17 18:11:59 | [trpo_pendulum] epoch #685 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -702.597
Evaluation/AverageReturn              -1609.87
Evaluation/Iteration                    685
Evaluation/MaxReturn                  -1527.25
Evaluation/MinReturn                  -1696.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     64.1467
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.81056
GaussianMLPPolicy/KL                      0.00691077
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              37.3662
GaussianMLPPolicy/LossBefore             39.7432
GaussianMLPPolicy/dLoss                   2.37702
GaussianMLPValueFunction/LossAfter        6.72921
GaussianMLPValueFunction/LossBefore       6.73267
GaussianMLPValueFunction/dLoss            0.00345373
TotalEnvSteps                        823200
-----------------------------------  ---------------
2022-08-17 18:12:00 | [trpo_pendulum] epoch #686 | Saving snapshot...
2022-08-17 18:12:00 | [trpo_pendulum] epoch #686 | Saved
2022-08-17 18:12:00 | [trpo_pendulum] epoch #686 | Time 435.81 s
2022-08-17 18:12:00 | [trpo_pendulum] epoch #686 | EpochTime 0.67 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -504.332
Evaluation/AverageReturn              -1244.85
Evaluation/Iteration                    686
Evaluation/MaxReturn                  -1144.44
Evaluation/MinReturn                  -1407.98
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    109.895
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.79622
GaussianMLPPolicy/KL                      0.00854895
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -8.83282
GaussianMLPPolicy/LossBefore             -7.27962
GaussianMLPPolicy/dLoss                   1.55321
GaussianMLPValueFunction/LossAfter        6.50426
GaussianMLPValueFunction/LossBefore       6.52025
GaussianMLPValueFunction/dLoss            0.0159883
TotalEnvSteps                        824400
-----------------------------------  ---------------
2022-08-17 18:12:00 | [trpo_pendulum] epoch #687 | Saving snapshot...
2022-08-17 18:12:00 | [trpo_pendulum] epoch #687 | Saved
2022-08-17 18:12:00 | [trpo_pendulum] epoch #687 | Time 436.44 s
2022-08-17 18:12:00 | [trpo_pendulum] epoch #687 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -723.51
Evaluation/AverageReturn              -1678.96
Evaluation/Iteration                    687
Evaluation/MaxReturn                  -1571.29
Evaluation/MinReturn                  -1757.79
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     56.9216
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.8238
GaussianMLPPolicy/KL                      0.00836131
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              49.1202
GaussianMLPPolicy/LossBefore             50.6975
GaussianMLPPolicy/dLoss                   1.57724
GaussianMLPValueFunction/LossAfter        6.79454
GaussianMLPValueFunction/LossBefore       6.81132
GaussianMLPValueFunction/dLoss            0.0167847
TotalEnvSteps                        825600
-----------------------------------  ---------------
2022-08-17 18:12:01 | [trpo_pendulum] epoch #688 | Saving snapshot...
2022-08-17 18:12:01 | [trpo_pendulum] epoch #688 | Saved
2022-08-17 18:12:01 | [trpo_pendulum] epoch #688 | Time 437.10 s
2022-08-17 18:12:01 | [trpo_pendulum] epoch #688 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -540.249
Evaluation/AverageReturn              -1349.69
Evaluation/Iteration                    688
Evaluation/MaxReturn                  -1289.94
Evaluation/MinReturn                  -1469.63
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     63.2116
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.81601
GaussianMLPPolicy/KL                      0.00639951
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               7.12804
GaussianMLPPolicy/LossBefore              8.52022
GaussianMLPPolicy/dLoss                   1.39218
GaussianMLPValueFunction/LossAfter        6.5112
GaussianMLPValueFunction/LossBefore       6.52357
GaussianMLPValueFunction/dLoss            0.0123663
TotalEnvSteps                        826800
-----------------------------------  ---------------
2022-08-17 18:12:01 | [trpo_pendulum] epoch #689 | Saving snapshot...
2022-08-17 18:12:01 | [trpo_pendulum] epoch #689 | Saved
2022-08-17 18:12:01 | [trpo_pendulum] epoch #689 | Time 437.74 s
2022-08-17 18:12:01 | [trpo_pendulum] epoch #689 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -551.435
Evaluation/AverageReturn              -1378.86
Evaluation/Iteration                    689
Evaluation/MaxReturn                  -1224.75
Evaluation/MinReturn                  -1527.37
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    105.963
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.81836
GaussianMLPPolicy/KL                      0.00983619
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              13.0751
GaussianMLPPolicy/LossBefore             14.7125
GaussianMLPPolicy/dLoss                   1.63742
GaussianMLPValueFunction/LossAfter        6.56666
GaussianMLPValueFunction/LossBefore       6.56908
GaussianMLPValueFunction/dLoss            0.00242043
TotalEnvSteps                        828000
-----------------------------------  ---------------
2022-08-17 18:12:02 | [trpo_pendulum] epoch #690 | Saving snapshot...
2022-08-17 18:12:02 | [trpo_pendulum] epoch #690 | Saved
2022-08-17 18:12:02 | [trpo_pendulum] epoch #690 | Time 438.39 s
2022-08-17 18:12:02 | [trpo_pendulum] epoch #690 | EpochTime 0.65 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -571.581
Evaluation/AverageReturn              -1421.67
Evaluation/Iteration                    690
Evaluation/MaxReturn                  -1227.86
Evaluation/MinReturn                  -1525.69
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    127.502
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.80667
GaussianMLPPolicy/KL                      0.00816232
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              18.5215
GaussianMLPPolicy/LossBefore             20.2509
GaussianMLPPolicy/dLoss                   1.72941
GaussianMLPValueFunction/LossAfter        6.60517
GaussianMLPValueFunction/LossBefore       6.60535
GaussianMLPValueFunction/dLoss            0.000175476
TotalEnvSteps                        829200
-----------------------------------  ----------------
2022-08-17 18:12:03 | [trpo_pendulum] epoch #691 | Saving snapshot...
2022-08-17 18:12:03 | [trpo_pendulum] epoch #691 | Saved
2022-08-17 18:12:03 | [trpo_pendulum] epoch #691 | Time 439.04 s
2022-08-17 18:12:03 | [trpo_pendulum] epoch #691 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -634.284
Evaluation/AverageReturn              -1536.41
Evaluation/Iteration                    691
Evaluation/MaxReturn                  -1499.67
Evaluation/MinReturn                  -1572.85
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     24.4178
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.78521
GaussianMLPPolicy/KL                      0.00663676
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              34.5349
GaussianMLPPolicy/LossBefore             36.0502
GaussianMLPPolicy/dLoss                   1.51531
GaussianMLPValueFunction/LossAfter        6.70363
GaussianMLPValueFunction/LossBefore       6.70977
GaussianMLPValueFunction/dLoss            0.00613356
TotalEnvSteps                        830400
-----------------------------------  ---------------
2022-08-17 18:12:03 | [trpo_pendulum] epoch #692 | Saving snapshot...
2022-08-17 18:12:03 | [trpo_pendulum] epoch #692 | Saved
2022-08-17 18:12:03 | [trpo_pendulum] epoch #692 | Time 439.69 s
2022-08-17 18:12:03 | [trpo_pendulum] epoch #692 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -553.879
Evaluation/AverageReturn              -1372.98
Evaluation/Iteration                    692
Evaluation/MaxReturn                  -1037.73
Evaluation/MinReturn                  -1493.65
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    161.77
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.77934
GaussianMLPPolicy/KL                      0.00917984
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               8.65864
GaussianMLPPolicy/LossBefore             10.8253
GaussianMLPPolicy/dLoss                   2.16667
GaussianMLPValueFunction/LossAfter        6.56693
GaussianMLPValueFunction/LossBefore       6.56971
GaussianMLPValueFunction/dLoss            0.00278091
TotalEnvSteps                        831600
-----------------------------------  ---------------
2022-08-17 18:12:04 | [trpo_pendulum] epoch #693 | Saving snapshot...
2022-08-17 18:12:04 | [trpo_pendulum] epoch #693 | Saved
2022-08-17 18:12:04 | [trpo_pendulum] epoch #693 | Time 440.34 s
2022-08-17 18:12:04 | [trpo_pendulum] epoch #693 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -597.809
Evaluation/AverageReturn              -1511.29
Evaluation/Iteration                    693
Evaluation/MaxReturn                  -1484.87
Evaluation/MinReturn                  -1534.87
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     18.7853
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.80277
GaussianMLPPolicy/KL                      0.009182
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              35.4326
GaussianMLPPolicy/LossBefore             36.7022
GaussianMLPPolicy/dLoss                   1.26958
GaussianMLPValueFunction/LossAfter        6.68398
GaussianMLPValueFunction/LossBefore       6.68819
GaussianMLPValueFunction/dLoss            0.00421238
TotalEnvSteps                        832800
-----------------------------------  ---------------
2022-08-17 18:12:05 | [trpo_pendulum] epoch #694 | Saving snapshot...
2022-08-17 18:12:05 | [trpo_pendulum] epoch #694 | Saved
2022-08-17 18:12:05 | [trpo_pendulum] epoch #694 | Time 441.00 s
2022-08-17 18:12:05 | [trpo_pendulum] epoch #694 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -705.906
Evaluation/AverageReturn              -1618.84
Evaluation/Iteration                    694
Evaluation/MaxReturn                  -1575.15
Evaluation/MinReturn                  -1700.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     42.1739
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.79778
GaussianMLPPolicy/KL                      0.00665412
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              37.3646
GaussianMLPPolicy/LossBefore             38.933
GaussianMLPPolicy/dLoss                   1.56831
GaussianMLPValueFunction/LossAfter        6.72696
GaussianMLPValueFunction/LossBefore       6.73308
GaussianMLPValueFunction/dLoss            0.00612736
TotalEnvSteps                        834000
-----------------------------------  ---------------
2022-08-17 18:12:05 | [trpo_pendulum] epoch #695 | Saving snapshot...
2022-08-17 18:12:05 | [trpo_pendulum] epoch #695 | Saved
2022-08-17 18:12:05 | [trpo_pendulum] epoch #695 | Time 441.63 s
2022-08-17 18:12:05 | [trpo_pendulum] epoch #695 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -588.87
Evaluation/AverageReturn              -1464.43
Evaluation/Iteration                    695
Evaluation/MaxReturn                  -1379.62
Evaluation/MinReturn                  -1503.03
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     40.4045
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.74324
GaussianMLPPolicy/KL                      0.00871237
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              22.4069
GaussianMLPPolicy/LossBefore             24.067
GaussianMLPPolicy/dLoss                   1.66001
GaussianMLPValueFunction/LossAfter        6.59088
GaussianMLPValueFunction/LossBefore       6.59464
GaussianMLPValueFunction/dLoss            0.00375891
TotalEnvSteps                        835200
-----------------------------------  ---------------
2022-08-17 18:12:06 | [trpo_pendulum] epoch #696 | Saving snapshot...
2022-08-17 18:12:06 | [trpo_pendulum] epoch #696 | Saved
2022-08-17 18:12:06 | [trpo_pendulum] epoch #696 | Time 442.28 s
2022-08-17 18:12:06 | [trpo_pendulum] epoch #696 | EpochTime 0.65 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -649.369
Evaluation/AverageReturn              -1498.12
Evaluation/Iteration                    696
Evaluation/MaxReturn                  -1491.99
Evaluation/MinReturn                  -1507.37
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.13814
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.74422
GaussianMLPPolicy/KL                      0.00964504
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              19.6011
GaussianMLPPolicy/LossBefore             21.4975
GaussianMLPPolicy/dLoss                   1.89631
GaussianMLPValueFunction/LossAfter        6.62185
GaussianMLPValueFunction/LossBefore       6.6222
GaussianMLPValueFunction/dLoss            0.000348568
TotalEnvSteps                        836400
-----------------------------------  ----------------
2022-08-17 18:12:07 | [trpo_pendulum] epoch #697 | Saving snapshot...
2022-08-17 18:12:07 | [trpo_pendulum] epoch #697 | Saved
2022-08-17 18:12:07 | [trpo_pendulum] epoch #697 | Time 442.97 s
2022-08-17 18:12:07 | [trpo_pendulum] epoch #697 | EpochTime 0.68 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -595.2
Evaluation/AverageReturn              -1484.61
Evaluation/Iteration                    697
Evaluation/MaxReturn                  -1460.25
Evaluation/MinReturn                  -1498.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.0721
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.75448
GaussianMLPPolicy/KL                      0.00665481
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              26.1495
GaussianMLPPolicy/LossBefore             28.0361
GaussianMLPPolicy/dLoss                   1.8866
GaussianMLPValueFunction/LossAfter        6.6209
GaussianMLPValueFunction/LossBefore       6.62177
GaussianMLPValueFunction/dLoss            0.000864506
TotalEnvSteps                        837600
-----------------------------------  ----------------
2022-08-17 18:12:07 | [trpo_pendulum] epoch #698 | Saving snapshot...
2022-08-17 18:12:07 | [trpo_pendulum] epoch #698 | Saved
2022-08-17 18:12:07 | [trpo_pendulum] epoch #698 | Time 443.61 s
2022-08-17 18:12:07 | [trpo_pendulum] epoch #698 | EpochTime 0.64 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -649.203
Evaluation/AverageReturn              -1495.09
Evaluation/Iteration                    698
Evaluation/MaxReturn                  -1493.72
Evaluation/MinReturn                  -1496.26
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      0.801425
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.75253
GaussianMLPPolicy/KL                      0.00846731
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              19.433
GaussianMLPPolicy/LossBefore             20.2336
GaussianMLPPolicy/dLoss                   0.800653
GaussianMLPValueFunction/LossAfter        6.61299
GaussianMLPValueFunction/LossBefore       6.61317
GaussianMLPValueFunction/dLoss            0.000181198
TotalEnvSteps                        838800
-----------------------------------  ----------------
2022-08-17 18:12:08 | [trpo_pendulum] epoch #699 | Saving snapshot...
2022-08-17 18:12:08 | [trpo_pendulum] epoch #699 | Saved
2022-08-17 18:12:08 | [trpo_pendulum] epoch #699 | Time 444.26 s
2022-08-17 18:12:08 | [trpo_pendulum] epoch #699 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -532.298
Evaluation/AverageReturn              -1360.96
Evaluation/Iteration                    699
Evaluation/MaxReturn                  -1327.94
Evaluation/MinReturn                  -1386.92
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     20.7819
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.74196
GaussianMLPPolicy/KL                      0.00720115
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               8.00394
GaussianMLPPolicy/LossBefore              9.14698
GaussianMLPPolicy/dLoss                   1.14304
GaussianMLPValueFunction/LossAfter        6.51524
GaussianMLPValueFunction/LossBefore       6.52229
GaussianMLPValueFunction/dLoss            0.00704479
TotalEnvSteps                        840000
-----------------------------------  ---------------
2022-08-17 18:12:09 | [trpo_pendulum] epoch #700 | Saving snapshot...
2022-08-17 18:12:09 | [trpo_pendulum] epoch #700 | Saved
2022-08-17 18:12:09 | [trpo_pendulum] epoch #700 | Time 444.90 s
2022-08-17 18:12:09 | [trpo_pendulum] epoch #700 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -671.758
Evaluation/AverageReturn              -1529.93
Evaluation/Iteration                    700
Evaluation/MaxReturn                  -1524.91
Evaluation/MinReturn                  -1537.69
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      4.64754
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.72813
GaussianMLPPolicy/KL                      0.00679467
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              22.1761
GaussianMLPPolicy/LossBefore             23.811
GaussianMLPPolicy/dLoss                   1.63489
GaussianMLPValueFunction/LossAfter        6.62274
GaussianMLPValueFunction/LossBefore       6.62385
GaussianMLPValueFunction/dLoss            0.00111246
TotalEnvSteps                        841200
-----------------------------------  ---------------
2022-08-17 18:12:09 | [trpo_pendulum] epoch #701 | Saving snapshot...
2022-08-17 18:12:09 | [trpo_pendulum] epoch #701 | Saved
2022-08-17 18:12:09 | [trpo_pendulum] epoch #701 | Time 445.57 s
2022-08-17 18:12:09 | [trpo_pendulum] epoch #701 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -562.682
Evaluation/AverageReturn              -1351.94
Evaluation/Iteration                    701
Evaluation/MaxReturn                  -1308.2
Evaluation/MinReturn                  -1390.8
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     24.8442
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.71512
GaussianMLPPolicy/KL                      0.00615
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               4.519
GaussianMLPPolicy/LossBefore              5.4474
GaussianMLPPolicy/dLoss                   0.928401
GaussianMLPValueFunction/LossAfter        6.55927
GaussianMLPValueFunction/LossBefore       6.56129
GaussianMLPValueFunction/dLoss            0.00201416
TotalEnvSteps                        842400
-----------------------------------  ---------------
2022-08-17 18:12:10 | [trpo_pendulum] epoch #702 | Saving snapshot...
2022-08-17 18:12:10 | [trpo_pendulum] epoch #702 | Saved
2022-08-17 18:12:10 | [trpo_pendulum] epoch #702 | Time 446.22 s
2022-08-17 18:12:10 | [trpo_pendulum] epoch #702 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -657.591
Evaluation/AverageReturn              -1578.31
Evaluation/Iteration                    702
Evaluation/MaxReturn                  -1548.71
Evaluation/MinReturn                  -1604.2
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     18.3996
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.73279
GaussianMLPPolicy/KL                      0.00782056
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              38.1316
GaussianMLPPolicy/LossBefore             38.9815
GaussianMLPPolicy/dLoss                   0.849857
GaussianMLPValueFunction/LossAfter        6.73478
GaussianMLPValueFunction/LossBefore       6.75241
GaussianMLPValueFunction/dLoss            0.0176311
TotalEnvSteps                        843600
-----------------------------------  ---------------
2022-08-17 18:12:11 | [trpo_pendulum] epoch #703 | Saving snapshot...
2022-08-17 18:12:11 | [trpo_pendulum] epoch #703 | Saved
2022-08-17 18:12:11 | [trpo_pendulum] epoch #703 | Time 446.88 s
2022-08-17 18:12:11 | [trpo_pendulum] epoch #703 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -533.522
Evaluation/AverageReturn              -1310.88
Evaluation/Iteration                    703
Evaluation/MaxReturn                  -1166.37
Evaluation/MinReturn                  -1426.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    107.021
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.76758
GaussianMLPPolicy/KL                      0.00668579
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.02693
GaussianMLPPolicy/LossBefore             -1.12802
GaussianMLPPolicy/dLoss                   1.89891
GaussianMLPValueFunction/LossAfter        6.51272
GaussianMLPValueFunction/LossBefore       6.52274
GaussianMLPValueFunction/dLoss            0.0100245
TotalEnvSteps                        844800
-----------------------------------  ---------------
2022-08-17 18:12:11 | [trpo_pendulum] epoch #704 | Saving snapshot...
2022-08-17 18:12:11 | [trpo_pendulum] epoch #704 | Saved
2022-08-17 18:12:11 | [trpo_pendulum] epoch #704 | Time 447.54 s
2022-08-17 18:12:11 | [trpo_pendulum] epoch #704 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -636.843
Evaluation/AverageReturn              -1546.13
Evaluation/Iteration                    704
Evaluation/MaxReturn                  -1503.54
Evaluation/MinReturn                  -1586.2
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     24.9808
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.77836
GaussianMLPPolicy/KL                      0.00780322
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              34.2159
GaussianMLPPolicy/LossBefore             34.4278
GaussianMLPPolicy/dLoss                   0.211895
GaussianMLPValueFunction/LossAfter        6.69951
GaussianMLPValueFunction/LossBefore       6.70684
GaussianMLPValueFunction/dLoss            0.00733471
TotalEnvSteps                        846000
-----------------------------------  ---------------
2022-08-17 18:12:12 | [trpo_pendulum] epoch #705 | Saving snapshot...
2022-08-17 18:12:12 | [trpo_pendulum] epoch #705 | Saved
2022-08-17 18:12:12 | [trpo_pendulum] epoch #705 | Time 448.21 s
2022-08-17 18:12:12 | [trpo_pendulum] epoch #705 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -595.234
Evaluation/AverageReturn              -1467.17
Evaluation/Iteration                    705
Evaluation/MaxReturn                  -1226.34
Evaluation/MinReturn                  -1522.6
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    107.831
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.78628
GaussianMLPPolicy/KL                      0.00781864
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              21.858
GaussianMLPPolicy/LossBefore             22.9119
GaussianMLPPolicy/dLoss                   1.05389
GaussianMLPValueFunction/LossAfter        6.62709
GaussianMLPValueFunction/LossBefore       6.62736
GaussianMLPValueFunction/dLoss            0.00027132
TotalEnvSteps                        847200
-----------------------------------  ---------------
2022-08-17 18:12:13 | [trpo_pendulum] epoch #706 | Saving snapshot...
2022-08-17 18:12:13 | [trpo_pendulum] epoch #706 | Saved
2022-08-17 18:12:13 | [trpo_pendulum] epoch #706 | Time 448.85 s
2022-08-17 18:12:13 | [trpo_pendulum] epoch #706 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -634.221
Evaluation/AverageReturn              -1542.56
Evaluation/Iteration                    706
Evaluation/MaxReturn                  -1521.92
Evaluation/MinReturn                  -1560.27
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     11.7752
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.77748
GaussianMLPPolicy/KL                      0.00917989
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              34.5841
GaussianMLPPolicy/LossBefore             34.7747
GaussianMLPPolicy/dLoss                   0.19062
GaussianMLPValueFunction/LossAfter        6.71905
GaussianMLPValueFunction/LossBefore       6.72492
GaussianMLPValueFunction/dLoss            0.00586987
TotalEnvSteps                        848400
-----------------------------------  ---------------
2022-08-17 18:12:13 | [trpo_pendulum] epoch #707 | Saving snapshot...
2022-08-17 18:12:13 | [trpo_pendulum] epoch #707 | Saved
2022-08-17 18:12:13 | [trpo_pendulum] epoch #707 | Time 449.48 s
2022-08-17 18:12:13 | [trpo_pendulum] epoch #707 | EpochTime 0.63 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -651.685
Evaluation/AverageReturn              -1498.77
Evaluation/Iteration                    707
Evaluation/MaxReturn                  -1496.21
Evaluation/MinReturn                  -1503.31
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      2.32339
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.7923
GaussianMLPPolicy/KL                      0.00800165
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              17.5595
GaussianMLPPolicy/LossBefore             19.5417
GaussianMLPPolicy/dLoss                   1.98219
GaussianMLPValueFunction/LossAfter        6.62638
GaussianMLPValueFunction/LossBefore       6.62723
GaussianMLPValueFunction/dLoss            0.000855446
TotalEnvSteps                        849600
-----------------------------------  ----------------
2022-08-17 18:12:14 | [trpo_pendulum] epoch #708 | Saving snapshot...
2022-08-17 18:12:14 | [trpo_pendulum] epoch #708 | Saved
2022-08-17 18:12:14 | [trpo_pendulum] epoch #708 | Time 450.12 s
2022-08-17 18:12:14 | [trpo_pendulum] epoch #708 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -541.741
Evaluation/AverageReturn              -1310.21
Evaluation/Iteration                    708
Evaluation/MaxReturn                  -1246.79
Evaluation/MinReturn                  -1354.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     34.0329
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.80652
GaussianMLPPolicy/KL                      0.00780002
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -6.58127
GaussianMLPPolicy/LossBefore             -4.47406
GaussianMLPPolicy/dLoss                   2.10722
GaussianMLPValueFunction/LossAfter        6.47492
GaussianMLPValueFunction/LossBefore       6.49339
GaussianMLPValueFunction/dLoss            0.0184674
TotalEnvSteps                        850800
-----------------------------------  ---------------
2022-08-17 18:12:14 | [trpo_pendulum] epoch #709 | Saving snapshot...
2022-08-17 18:12:14 | [trpo_pendulum] epoch #709 | Saved
2022-08-17 18:12:14 | [trpo_pendulum] epoch #709 | Time 450.77 s
2022-08-17 18:12:14 | [trpo_pendulum] epoch #709 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -524.867
Evaluation/AverageReturn              -1289.51
Evaluation/Iteration                    709
Evaluation/MaxReturn                  -1141
Evaluation/MinReturn                  -1398.79
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     90.3865
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.81776
GaussianMLPPolicy/KL                      0.00817547
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -6.6312
GaussianMLPPolicy/LossBefore             -4.2995
GaussianMLPPolicy/dLoss                   2.3317
GaussianMLPValueFunction/LossAfter        6.48177
GaussianMLPValueFunction/LossBefore       6.49063
GaussianMLPValueFunction/dLoss            0.00886202
TotalEnvSteps                        852000
-----------------------------------  ---------------
2022-08-17 18:12:15 | [trpo_pendulum] epoch #710 | Saving snapshot...
2022-08-17 18:12:15 | [trpo_pendulum] epoch #710 | Saved
2022-08-17 18:12:15 | [trpo_pendulum] epoch #710 | Time 451.45 s
2022-08-17 18:12:15 | [trpo_pendulum] epoch #710 | EpochTime 0.67 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -567.828
Evaluation/AverageReturn              -1410.09
Evaluation/Iteration                    710
Evaluation/MaxReturn                  -1366.43
Evaluation/MinReturn                  -1453.27
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     35.3439
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.82716
GaussianMLPPolicy/KL                      0.00757929
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              17.3918
GaussianMLPPolicy/LossBefore             18.5284
GaussianMLPPolicy/dLoss                   1.13665
GaussianMLPValueFunction/LossAfter        6.61765
GaussianMLPValueFunction/LossBefore       6.61996
GaussianMLPValueFunction/dLoss            0.00230503
TotalEnvSteps                        853200
-----------------------------------  ---------------
2022-08-17 18:12:16 | [trpo_pendulum] epoch #711 | Saving snapshot...
2022-08-17 18:12:16 | [trpo_pendulum] epoch #711 | Saved
2022-08-17 18:12:16 | [trpo_pendulum] epoch #711 | Time 452.09 s
2022-08-17 18:12:16 | [trpo_pendulum] epoch #711 | EpochTime 0.64 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -558.607
Evaluation/AverageReturn              -1385.87
Evaluation/Iteration                    711
Evaluation/MaxReturn                  -1330.17
Evaluation/MinReturn                  -1412.57
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     29.7993
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.8118
GaussianMLPPolicy/KL                      0.00912614
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              10.1459
GaussianMLPPolicy/LossBefore             11.9964
GaussianMLPPolicy/dLoss                   1.85047
GaussianMLPValueFunction/LossAfter        6.54629
GaussianMLPValueFunction/LossBefore       6.5468
GaussianMLPValueFunction/dLoss            0.000506401
TotalEnvSteps                        854400
-----------------------------------  ----------------
2022-08-17 18:12:16 | [trpo_pendulum] epoch #712 | Saving snapshot...
2022-08-17 18:12:16 | [trpo_pendulum] epoch #712 | Saved
2022-08-17 18:12:16 | [trpo_pendulum] epoch #712 | Time 452.72 s
2022-08-17 18:12:16 | [trpo_pendulum] epoch #712 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -622.366
Evaluation/AverageReturn              -1503
Evaluation/Iteration                    712
Evaluation/MaxReturn                  -1474.42
Evaluation/MinReturn                  -1514.56
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.0183
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.80799
GaussianMLPPolicy/KL                      0.00825314
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              27.2881
GaussianMLPPolicy/LossBefore             28.3517
GaussianMLPPolicy/dLoss                   1.06362
GaussianMLPValueFunction/LossAfter        6.64638
GaussianMLPValueFunction/LossBefore       6.651
GaussianMLPValueFunction/dLoss            0.00462008
TotalEnvSteps                        855600
-----------------------------------  ---------------
2022-08-17 18:12:17 | [trpo_pendulum] epoch #713 | Saving snapshot...
2022-08-17 18:12:17 | [trpo_pendulum] epoch #713 | Saved
2022-08-17 18:12:17 | [trpo_pendulum] epoch #713 | Time 453.34 s
2022-08-17 18:12:17 | [trpo_pendulum] epoch #713 | EpochTime 0.61 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -588.733
Evaluation/AverageReturn              -1403.43
Evaluation/Iteration                    713
Evaluation/MaxReturn                  -1200
Evaluation/MinReturn                  -1571.68
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    137.819
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.79384
GaussianMLPPolicy/KL                      0.00684116
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               8.76028
GaussianMLPPolicy/LossBefore             10.3147
GaussianMLPPolicy/dLoss                   1.55438
GaussianMLPValueFunction/LossAfter        6.56434
GaussianMLPValueFunction/LossBefore       6.56509
GaussianMLPValueFunction/dLoss            0.000745773
TotalEnvSteps                        856800
-----------------------------------  ----------------
2022-08-17 18:12:18 | [trpo_pendulum] epoch #714 | Saving snapshot...
2022-08-17 18:12:18 | [trpo_pendulum] epoch #714 | Saved
2022-08-17 18:12:18 | [trpo_pendulum] epoch #714 | Time 453.97 s
2022-08-17 18:12:18 | [trpo_pendulum] epoch #714 | EpochTime 0.63 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -582.867
Evaluation/AverageReturn              -1447.38
Evaluation/Iteration                    714
Evaluation/MaxReturn                  -1417.73
Evaluation/MinReturn                  -1470.47
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     16.6373
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.81892
GaussianMLPPolicy/KL                      0.00492548
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              22.7221
GaussianMLPPolicy/LossBefore             23.7793
GaussianMLPPolicy/dLoss                   1.05713
GaussianMLPValueFunction/LossAfter        6.61616
GaussianMLPValueFunction/LossBefore       6.61697
GaussianMLPValueFunction/dLoss            0.000809669
TotalEnvSteps                        858000
-----------------------------------  ----------------
2022-08-17 18:12:18 | [trpo_pendulum] epoch #715 | Saving snapshot...
2022-08-17 18:12:18 | [trpo_pendulum] epoch #715 | Saved
2022-08-17 18:12:18 | [trpo_pendulum] epoch #715 | Time 454.62 s
2022-08-17 18:12:18 | [trpo_pendulum] epoch #715 | EpochTime 0.65 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -650.09
Evaluation/AverageReturn              -1503.22
Evaluation/Iteration                    715
Evaluation/MaxReturn                  -1502.05
Evaluation/MinReturn                  -1506.14
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      1.43182
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.81284
GaussianMLPPolicy/KL                      0.00599059
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              20.5389
GaussianMLPPolicy/LossBefore             22.0737
GaussianMLPPolicy/dLoss                   1.53487
GaussianMLPValueFunction/LossAfter        6.61458
GaussianMLPValueFunction/LossBefore       6.61485
GaussianMLPValueFunction/dLoss            0.000274658
TotalEnvSteps                        859200
-----------------------------------  ----------------
2022-08-17 18:12:19 | [trpo_pendulum] epoch #716 | Saving snapshot...
2022-08-17 18:12:19 | [trpo_pendulum] epoch #716 | Saved
2022-08-17 18:12:19 | [trpo_pendulum] epoch #716 | Time 455.26 s
2022-08-17 18:12:19 | [trpo_pendulum] epoch #716 | EpochTime 0.63 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -668.467
Evaluation/AverageReturn              -1521.55
Evaluation/Iteration                    716
Evaluation/MaxReturn                  -1504.39
Evaluation/MinReturn                  -1544.46
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     16.6205
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.83042
GaussianMLPPolicy/KL                      0.00628213
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              20.4438
GaussianMLPPolicy/LossBefore             22.3779
GaussianMLPPolicy/dLoss                   1.93413
GaussianMLPValueFunction/LossAfter        6.62786
GaussianMLPValueFunction/LossBefore       6.62829
GaussianMLPValueFunction/dLoss            0.000434399
TotalEnvSteps                        860400
-----------------------------------  ----------------
2022-08-17 18:12:20 | [trpo_pendulum] epoch #717 | Saving snapshot...
2022-08-17 18:12:20 | [trpo_pendulum] epoch #717 | Saved
2022-08-17 18:12:20 | [trpo_pendulum] epoch #717 | Time 455.90 s
2022-08-17 18:12:20 | [trpo_pendulum] epoch #717 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -554.548
Evaluation/AverageReturn              -1383.7
Evaluation/Iteration                    717
Evaluation/MaxReturn                  -1326.33
Evaluation/MinReturn                  -1427.27
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     34.6233
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.85478
GaussianMLPPolicy/KL                      0.00782404
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               9.34473
GaussianMLPPolicy/LossBefore             11.2437
GaussianMLPPolicy/dLoss                   1.89892
GaussianMLPValueFunction/LossAfter        6.53571
GaussianMLPValueFunction/LossBefore       6.5395
GaussianMLPValueFunction/dLoss            0.00378323
TotalEnvSteps                        861600
-----------------------------------  ---------------
2022-08-17 18:12:20 | [trpo_pendulum] epoch #718 | Saving snapshot...
2022-08-17 18:12:20 | [trpo_pendulum] epoch #718 | Saved
2022-08-17 18:12:20 | [trpo_pendulum] epoch #718 | Time 456.53 s
2022-08-17 18:12:20 | [trpo_pendulum] epoch #718 | EpochTime 0.63 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -576.76
Evaluation/AverageReturn              -1437.63
Evaluation/Iteration                    718
Evaluation/MaxReturn                  -1356.81
Evaluation/MinReturn                  -1518
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     64.648
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.85602
GaussianMLPPolicy/KL                      0.00753231
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              18.685
GaussianMLPPolicy/LossBefore             20.4106
GaussianMLPPolicy/dLoss                   1.72558
GaussianMLPValueFunction/LossAfter        6.60619
GaussianMLPValueFunction/LossBefore       6.60667
GaussianMLPValueFunction/dLoss            0.000483513
TotalEnvSteps                        862800
-----------------------------------  ----------------
2022-08-17 18:12:21 | [trpo_pendulum] epoch #719 | Saving snapshot...
2022-08-17 18:12:21 | [trpo_pendulum] epoch #719 | Saved
2022-08-17 18:12:21 | [trpo_pendulum] epoch #719 | Time 457.17 s
2022-08-17 18:12:21 | [trpo_pendulum] epoch #719 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -661.734
Evaluation/AverageReturn              -1526.44
Evaluation/Iteration                    719
Evaluation/MaxReturn                  -1486.55
Evaluation/MinReturn                  -1561.86
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     25.3891
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.83475
GaussianMLPPolicy/KL                      0.00961111
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              23.324
GaussianMLPPolicy/LossBefore             25.5372
GaussianMLPPolicy/dLoss                   2.21318
GaussianMLPValueFunction/LossAfter        6.65137
GaussianMLPValueFunction/LossBefore       6.65399
GaussianMLPValueFunction/dLoss            0.00261784
TotalEnvSteps                        864000
-----------------------------------  ---------------
2022-08-17 18:12:22 | [trpo_pendulum] epoch #720 | Saving snapshot...
2022-08-17 18:12:22 | [trpo_pendulum] epoch #720 | Saved
2022-08-17 18:12:22 | [trpo_pendulum] epoch #720 | Time 457.80 s
2022-08-17 18:12:22 | [trpo_pendulum] epoch #720 | EpochTime 0.63 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -653.764
Evaluation/AverageReturn              -1512.58
Evaluation/Iteration                    720
Evaluation/MaxReturn                  -1508.86
Evaluation/MinReturn                  -1517.16
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      2.86093
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.86411
GaussianMLPPolicy/KL                      0.00681365
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              21.9239
GaussianMLPPolicy/LossBefore             23.2468
GaussianMLPPolicy/dLoss                   1.32293
GaussianMLPValueFunction/LossAfter        6.6287
GaussianMLPValueFunction/LossBefore       6.62889
GaussianMLPValueFunction/dLoss            0.000195026
TotalEnvSteps                        865200
-----------------------------------  ----------------
2022-08-17 18:12:22 | [trpo_pendulum] epoch #721 | Saving snapshot...
2022-08-17 18:12:22 | [trpo_pendulum] epoch #721 | Saved
2022-08-17 18:12:22 | [trpo_pendulum] epoch #721 | Time 458.43 s
2022-08-17 18:12:22 | [trpo_pendulum] epoch #721 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -544.226
Evaluation/AverageReturn              -1398.49
Evaluation/Iteration                    721
Evaluation/MaxReturn                  -1273.28
Evaluation/MinReturn                  -1488.29
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     87.8432
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.89491
GaussianMLPPolicy/KL                      0.00764809
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              12.3118
GaussianMLPPolicy/LossBefore             15.1024
GaussianMLPPolicy/dLoss                   2.79057
GaussianMLPValueFunction/LossAfter        6.54228
GaussianMLPValueFunction/LossBefore       6.54645
GaussianMLPValueFunction/dLoss            0.00416899
TotalEnvSteps                        866400
-----------------------------------  ---------------
2022-08-17 18:12:23 | [trpo_pendulum] epoch #722 | Saving snapshot...
2022-08-17 18:12:23 | [trpo_pendulum] epoch #722 | Saved
2022-08-17 18:12:23 | [trpo_pendulum] epoch #722 | Time 459.06 s
2022-08-17 18:12:23 | [trpo_pendulum] epoch #722 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -590.227
Evaluation/AverageReturn              -1468.03
Evaluation/Iteration                    722
Evaluation/MaxReturn                  -1406.2
Evaluation/MinReturn                  -1514.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     36.215
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.91916
GaussianMLPPolicy/KL                      0.00683064
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              22.2099
GaussianMLPPolicy/LossBefore             24.086
GaussianMLPPolicy/dLoss                   1.87615
GaussianMLPValueFunction/LossAfter        6.61133
GaussianMLPValueFunction/LossBefore       6.61212
GaussianMLPValueFunction/dLoss            0.00079155
TotalEnvSteps                        867600
-----------------------------------  ---------------
2022-08-17 18:12:23 | [trpo_pendulum] epoch #723 | Saving snapshot...
2022-08-17 18:12:23 | [trpo_pendulum] epoch #723 | Saved
2022-08-17 18:12:23 | [trpo_pendulum] epoch #723 | Time 459.71 s
2022-08-17 18:12:23 | [trpo_pendulum] epoch #723 | EpochTime 0.64 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -673.434
Evaluation/AverageReturn              -1528.71
Evaluation/Iteration                    723
Evaluation/MaxReturn                  -1519.9
Evaluation/MinReturn                  -1540.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      7.81836
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.94283
GaussianMLPPolicy/KL                      0.00941746
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              20.055
GaussianMLPPolicy/LossBefore             22.0108
GaussianMLPPolicy/dLoss                   1.95571
GaussianMLPValueFunction/LossAfter        6.6298
GaussianMLPValueFunction/LossBefore       6.63054
GaussianMLPValueFunction/dLoss            0.000737667
TotalEnvSteps                        868800
-----------------------------------  ----------------
2022-08-17 18:12:24 | [trpo_pendulum] epoch #724 | Saving snapshot...
2022-08-17 18:12:24 | [trpo_pendulum] epoch #724 | Saved
2022-08-17 18:12:24 | [trpo_pendulum] epoch #724 | Time 460.34 s
2022-08-17 18:12:24 | [trpo_pendulum] epoch #724 | EpochTime 0.63 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -640.64
Evaluation/AverageReturn              -1497.96
Evaluation/Iteration                    724
Evaluation/MaxReturn                  -1373.93
Evaluation/MinReturn                  -1527.61
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     55.5881
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.91819
GaussianMLPPolicy/KL                      0.00963278
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              19.3566
GaussianMLPPolicy/LossBefore             21.797
GaussianMLPPolicy/dLoss                   2.44041
GaussianMLPValueFunction/LossAfter        6.6441
GaussianMLPValueFunction/LossBefore       6.64482
GaussianMLPValueFunction/dLoss            0.000716209
TotalEnvSteps                        870000
-----------------------------------  ----------------
2022-08-17 18:12:25 | [trpo_pendulum] epoch #725 | Saving snapshot...
2022-08-17 18:12:25 | [trpo_pendulum] epoch #725 | Saved
2022-08-17 18:12:25 | [trpo_pendulum] epoch #725 | Time 461.01 s
2022-08-17 18:12:25 | [trpo_pendulum] epoch #725 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -642.951
Evaluation/AverageReturn              -1529.92
Evaluation/Iteration                    725
Evaluation/MaxReturn                  -1512.2
Evaluation/MinReturn                  -1549.6
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     12.9768
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.92302
GaussianMLPPolicy/KL                      0.00980969
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              27.8453
GaussianMLPPolicy/LossBefore             29.2721
GaussianMLPPolicy/dLoss                   1.42674
GaussianMLPValueFunction/LossAfter        6.69875
GaussianMLPValueFunction/LossBefore       6.7031
GaussianMLPValueFunction/dLoss            0.00435829
TotalEnvSteps                        871200
-----------------------------------  ---------------
2022-08-17 18:12:25 | [trpo_pendulum] epoch #726 | Saving snapshot...
2022-08-17 18:12:25 | [trpo_pendulum] epoch #726 | Saved
2022-08-17 18:12:25 | [trpo_pendulum] epoch #726 | Time 461.68 s
2022-08-17 18:12:25 | [trpo_pendulum] epoch #726 | EpochTime 0.66 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -655.731
Evaluation/AverageReturn              -1558.47
Evaluation/Iteration                    726
Evaluation/MaxReturn                  -1524.13
Evaluation/MinReturn                  -1599.57
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     25.2021
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.92
GaussianMLPPolicy/KL                      0.000408865
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              32.5332
GaussianMLPPolicy/LossBefore             32.5617
GaussianMLPPolicy/dLoss                   0.028511
GaussianMLPValueFunction/LossAfter        6.71397
GaussianMLPValueFunction/LossBefore       6.71716
GaussianMLPValueFunction/dLoss            0.00319052
TotalEnvSteps                        872400
-----------------------------------  ----------------
2022-08-17 18:12:26 | [trpo_pendulum] epoch #727 | Saving snapshot...
2022-08-17 18:12:26 | [trpo_pendulum] epoch #727 | Saved
2022-08-17 18:12:26 | [trpo_pendulum] epoch #727 | Time 462.34 s
2022-08-17 18:12:26 | [trpo_pendulum] epoch #727 | EpochTime 0.66 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -629.4
Evaluation/AverageReturn              -1514.03
Evaluation/Iteration                    727
Evaluation/MaxReturn                  -1495.96
Evaluation/MinReturn                  -1550.83
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     18.0924
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.92823
GaussianMLPPolicy/KL                      0.00495958
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              25.2915
GaussianMLPPolicy/LossBefore             25.9929
GaussianMLPPolicy/dLoss                   0.701351
GaussianMLPValueFunction/LossAfter        6.65951
GaussianMLPValueFunction/LossBefore       6.66023
GaussianMLPValueFunction/dLoss            0.000722408
TotalEnvSteps                        873600
-----------------------------------  ----------------
2022-08-17 18:12:27 | [trpo_pendulum] epoch #728 | Saving snapshot...
2022-08-17 18:12:27 | [trpo_pendulum] epoch #728 | Saved
2022-08-17 18:12:27 | [trpo_pendulum] epoch #728 | Time 462.99 s
2022-08-17 18:12:27 | [trpo_pendulum] epoch #728 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -576.66
Evaluation/AverageReturn              -1428.68
Evaluation/Iteration                    728
Evaluation/MaxReturn                  -1357.36
Evaluation/MinReturn                  -1495.94
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     52.2252
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.94403
GaussianMLPPolicy/KL                      0.00628595
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              12.7314
GaussianMLPPolicy/LossBefore             14.1904
GaussianMLPPolicy/dLoss                   1.45901
GaussianMLPValueFunction/LossAfter        6.54916
GaussianMLPValueFunction/LossBefore       6.57284
GaussianMLPValueFunction/dLoss            0.0236835
TotalEnvSteps                        874800
-----------------------------------  ---------------
2022-08-17 18:12:27 | [trpo_pendulum] epoch #729 | Saving snapshot...
2022-08-17 18:12:27 | [trpo_pendulum] epoch #729 | Saved
2022-08-17 18:12:27 | [trpo_pendulum] epoch #729 | Time 463.61 s
2022-08-17 18:12:27 | [trpo_pendulum] epoch #729 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -596.728
Evaluation/AverageReturn              -1479.1
Evaluation/Iteration                    729
Evaluation/MaxReturn                  -1431.79
Evaluation/MinReturn                  -1523.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     28.0534
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.92485
GaussianMLPPolicy/KL                      0.00910652
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              25.3955
GaussianMLPPolicy/LossBefore             26.8786
GaussianMLPPolicy/dLoss                   1.48313
GaussianMLPValueFunction/LossAfter        6.60476
GaussianMLPValueFunction/LossBefore       6.60598
GaussianMLPValueFunction/dLoss            0.00121641
TotalEnvSteps                        876000
-----------------------------------  ---------------
2022-08-17 18:12:28 | [trpo_pendulum] epoch #730 | Saving snapshot...
2022-08-17 18:12:28 | [trpo_pendulum] epoch #730 | Saved
2022-08-17 18:12:28 | [trpo_pendulum] epoch #730 | Time 464.26 s
2022-08-17 18:12:28 | [trpo_pendulum] epoch #730 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -575.735
Evaluation/AverageReturn              -1461.47
Evaluation/Iteration                    730
Evaluation/MaxReturn                  -1378.02
Evaluation/MinReturn                  -1519.96
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     56.8632
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.94253
GaussianMLPPolicy/KL                      0.00814259
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              22.4122
GaussianMLPPolicy/LossBefore             23.5613
GaussianMLPPolicy/dLoss                   1.14915
GaussianMLPValueFunction/LossAfter        6.61693
GaussianMLPValueFunction/LossBefore       6.61779
GaussianMLPValueFunction/dLoss            0.0008564
TotalEnvSteps                        877200
-----------------------------------  ---------------
2022-08-17 18:12:29 | [trpo_pendulum] epoch #731 | Saving snapshot...
2022-08-17 18:12:29 | [trpo_pendulum] epoch #731 | Saved
2022-08-17 18:12:29 | [trpo_pendulum] epoch #731 | Time 464.88 s
2022-08-17 18:12:29 | [trpo_pendulum] epoch #731 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -580.142
Evaluation/AverageReturn              -1466.67
Evaluation/Iteration                    731
Evaluation/MaxReturn                  -1399.56
Evaluation/MinReturn                  -1505.73
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     37.2575
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.95187
GaussianMLPPolicy/KL                      0.00900644
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              21.4225
GaussianMLPPolicy/LossBefore             23.7219
GaussianMLPPolicy/dLoss                   2.29944
GaussianMLPValueFunction/LossAfter        6.5883
GaussianMLPValueFunction/LossBefore       6.59748
GaussianMLPValueFunction/dLoss            0.0091753
TotalEnvSteps                        878400
-----------------------------------  ---------------
2022-08-17 18:12:29 | [trpo_pendulum] epoch #732 | Saving snapshot...
2022-08-17 18:12:29 | [trpo_pendulum] epoch #732 | Saved
2022-08-17 18:12:29 | [trpo_pendulum] epoch #732 | Time 465.51 s
2022-08-17 18:12:29 | [trpo_pendulum] epoch #732 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -653.491
Evaluation/AverageReturn              -1514.48
Evaluation/Iteration                    732
Evaluation/MaxReturn                  -1481.62
Evaluation/MinReturn                  -1554.37
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     24.3113
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.95544
GaussianMLPPolicy/KL                      0.00817779
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              18.0659
GaussianMLPPolicy/LossBefore             20.1801
GaussianMLPPolicy/dLoss                   2.11419
GaussianMLPValueFunction/LossAfter        6.65887
GaussianMLPValueFunction/LossBefore       6.66091
GaussianMLPValueFunction/dLoss            0.00204134
TotalEnvSteps                        879600
-----------------------------------  ---------------
2022-08-17 18:12:30 | [trpo_pendulum] epoch #733 | Saving snapshot...
2022-08-17 18:12:30 | [trpo_pendulum] epoch #733 | Saved
2022-08-17 18:12:30 | [trpo_pendulum] epoch #733 | Time 466.17 s
2022-08-17 18:12:30 | [trpo_pendulum] epoch #733 | EpochTime 0.65 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -688.919
Evaluation/AverageReturn              -1546.33
Evaluation/Iteration                    733
Evaluation/MaxReturn                  -1538.64
Evaluation/MinReturn                  -1556.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.27691
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.97281
GaussianMLPPolicy/KL                      0.00905671
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              16.7288
GaussianMLPPolicy/LossBefore             19.4131
GaussianMLPPolicy/dLoss                   2.68431
GaussianMLPValueFunction/LossAfter        6.63564
GaussianMLPValueFunction/LossBefore       6.63568
GaussianMLPValueFunction/dLoss            4.24385e-05
TotalEnvSteps                        880800
-----------------------------------  ----------------
2022-08-17 18:12:31 | [trpo_pendulum] epoch #734 | Saving snapshot...
2022-08-17 18:12:31 | [trpo_pendulum] epoch #734 | Saved
2022-08-17 18:12:31 | [trpo_pendulum] epoch #734 | Time 466.82 s
2022-08-17 18:12:31 | [trpo_pendulum] epoch #734 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -680.073
Evaluation/AverageReturn              -1627.88
Evaluation/Iteration                    734
Evaluation/MaxReturn                  -1614.13
Evaluation/MinReturn                  -1644.65
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.3412
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.98004
GaussianMLPPolicy/KL                      0.00569569
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              38.694
GaussianMLPPolicy/LossBefore             39.7939
GaussianMLPPolicy/dLoss                   1.0999
GaussianMLPValueFunction/LossAfter        6.71601
GaussianMLPValueFunction/LossBefore       6.7236
GaussianMLPValueFunction/dLoss            0.00759125
TotalEnvSteps                        882000
-----------------------------------  ---------------
2022-08-17 18:12:31 | [trpo_pendulum] epoch #735 | Saving snapshot...
2022-08-17 18:12:31 | [trpo_pendulum] epoch #735 | Saved
2022-08-17 18:12:31 | [trpo_pendulum] epoch #735 | Time 467.47 s
2022-08-17 18:12:31 | [trpo_pendulum] epoch #735 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -593.96
Evaluation/AverageReturn              -1461.18
Evaluation/Iteration                    735
Evaluation/MaxReturn                  -1338.5
Evaluation/MinReturn                  -1516.98
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     65.2952
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.99603
GaussianMLPPolicy/KL                      0.00904765
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              13.8781
GaussianMLPPolicy/LossBefore             17.6449
GaussianMLPPolicy/dLoss                   3.76674
GaussianMLPValueFunction/LossAfter        6.59603
GaussianMLPValueFunction/LossBefore       6.6004
GaussianMLPValueFunction/dLoss            0.00436354
TotalEnvSteps                        883200
-----------------------------------  ---------------
2022-08-17 18:12:32 | [trpo_pendulum] epoch #736 | Saving snapshot...
2022-08-17 18:12:32 | [trpo_pendulum] epoch #736 | Saved
2022-08-17 18:12:32 | [trpo_pendulum] epoch #736 | Time 468.09 s
2022-08-17 18:12:32 | [trpo_pendulum] epoch #736 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -659.485
Evaluation/AverageReturn              -1577.94
Evaluation/Iteration                    736
Evaluation/MaxReturn                  -1554.72
Evaluation/MinReturn                  -1603.26
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.7599
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.00886
GaussianMLPPolicy/KL                      0.00498015
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              32.0139
GaussianMLPPolicy/LossBefore             32.4604
GaussianMLPPolicy/dLoss                   0.446499
GaussianMLPValueFunction/LossAfter        6.71892
GaussianMLPValueFunction/LossBefore       6.72417
GaussianMLPValueFunction/dLoss            0.00524998
TotalEnvSteps                        884400
-----------------------------------  ---------------
2022-08-17 18:12:32 | [trpo_pendulum] epoch #737 | Saving snapshot...
2022-08-17 18:12:32 | [trpo_pendulum] epoch #737 | Saved
2022-08-17 18:12:32 | [trpo_pendulum] epoch #737 | Time 468.73 s
2022-08-17 18:12:32 | [trpo_pendulum] epoch #737 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -597.893
Evaluation/AverageReturn              -1523.61
Evaluation/Iteration                    737
Evaluation/MaxReturn                  -1514.76
Evaluation/MinReturn                  -1533.09
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      6.23031
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.00335
GaussianMLPPolicy/KL                      0.00653025
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              30.1215
GaussianMLPPolicy/LossBefore             31.2811
GaussianMLPPolicy/dLoss                   1.15956
GaussianMLPValueFunction/LossAfter        6.68741
GaussianMLPValueFunction/LossBefore       6.68848
GaussianMLPValueFunction/dLoss            0.0010705
TotalEnvSteps                        885600
-----------------------------------  ---------------
2022-08-17 18:12:33 | [trpo_pendulum] epoch #738 | Saving snapshot...
2022-08-17 18:12:33 | [trpo_pendulum] epoch #738 | Saved
2022-08-17 18:12:33 | [trpo_pendulum] epoch #738 | Time 469.36 s
2022-08-17 18:12:33 | [trpo_pendulum] epoch #738 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -627.964
Evaluation/AverageReturn              -1498.75
Evaluation/Iteration                    738
Evaluation/MaxReturn                  -1432.26
Evaluation/MinReturn                  -1520.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     30.1296
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.98611
GaussianMLPPolicy/KL                      0.00830004
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              30.2134
GaussianMLPPolicy/LossBefore             30.671
GaussianMLPPolicy/dLoss                   0.457615
GaussianMLPValueFunction/LossAfter        6.6405
GaussianMLPValueFunction/LossBefore       6.65282
GaussianMLPValueFunction/dLoss            0.0123248
TotalEnvSteps                        886800
-----------------------------------  ---------------
2022-08-17 18:12:34 | [trpo_pendulum] epoch #739 | Saving snapshot...
2022-08-17 18:12:34 | [trpo_pendulum] epoch #739 | Saved
2022-08-17 18:12:34 | [trpo_pendulum] epoch #739 | Time 469.99 s
2022-08-17 18:12:34 | [trpo_pendulum] epoch #739 | EpochTime 0.62 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -617.414
Evaluation/AverageReturn              -1503.23
Evaluation/Iteration                    739
Evaluation/MaxReturn                  -1477.13
Evaluation/MinReturn                  -1525.34
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     16.6017
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.97404
GaussianMLPPolicy/KL                      0.00924866
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              23.2813
GaussianMLPPolicy/LossBefore             25.1659
GaussianMLPPolicy/dLoss                   1.8846
GaussianMLPValueFunction/LossAfter        6.64268
GaussianMLPValueFunction/LossBefore       6.64363
GaussianMLPValueFunction/dLoss            0.000957966
TotalEnvSteps                        888000
-----------------------------------  ----------------
2022-08-17 18:12:34 | [trpo_pendulum] epoch #740 | Saving snapshot...
2022-08-17 18:12:34 | [trpo_pendulum] epoch #740 | Saved
2022-08-17 18:12:34 | [trpo_pendulum] epoch #740 | Time 470.63 s
2022-08-17 18:12:34 | [trpo_pendulum] epoch #740 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -566.992
Evaluation/AverageReturn              -1423.94
Evaluation/Iteration                    740
Evaluation/MaxReturn                  -1335.94
Evaluation/MinReturn                  -1501.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     61.7864
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.96919
GaussianMLPPolicy/KL                      0.00690234
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               7.65127
GaussianMLPPolicy/LossBefore             11.2289
GaussianMLPPolicy/dLoss                   3.57765
GaussianMLPValueFunction/LossAfter        6.55961
GaussianMLPValueFunction/LossBefore       6.56687
GaussianMLPValueFunction/dLoss            0.00726748
TotalEnvSteps                        889200
-----------------------------------  ---------------
2022-08-17 18:12:35 | [trpo_pendulum] epoch #741 | Saving snapshot...
2022-08-17 18:12:35 | [trpo_pendulum] epoch #741 | Saved
2022-08-17 18:12:35 | [trpo_pendulum] epoch #741 | Time 471.26 s
2022-08-17 18:12:35 | [trpo_pendulum] epoch #741 | EpochTime 0.62 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -654.156
Evaluation/AverageReturn              -1513.13
Evaluation/Iteration                    741
Evaluation/MaxReturn                  -1510.05
Evaluation/MinReturn                  -1516.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      2.468
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.98325
GaussianMLPPolicy/KL                      0.00727272
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              14.79
GaussianMLPPolicy/LossBefore             16.433
GaussianMLPPolicy/dLoss                   1.64294
GaussianMLPValueFunction/LossAfter        6.61747
GaussianMLPValueFunction/LossBefore       6.61756
GaussianMLPValueFunction/dLoss            9.01222e-05
TotalEnvSteps                        890400
-----------------------------------  ----------------
2022-08-17 18:12:36 | [trpo_pendulum] epoch #742 | Saving snapshot...
2022-08-17 18:12:36 | [trpo_pendulum] epoch #742 | Saved
2022-08-17 18:12:36 | [trpo_pendulum] epoch #742 | Time 471.92 s
2022-08-17 18:12:36 | [trpo_pendulum] epoch #742 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -671.89
Evaluation/AverageReturn              -1546.74
Evaluation/Iteration                    742
Evaluation/MaxReturn                  -1530.76
Evaluation/MinReturn                  -1570.44
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     15.5245
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.96271
GaussianMLPPolicy/KL                      0.00688219
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              19.5121
GaussianMLPPolicy/LossBefore             21.8672
GaussianMLPPolicy/dLoss                   2.35513
GaussianMLPValueFunction/LossAfter        6.67689
GaussianMLPValueFunction/LossBefore       6.67969
GaussianMLPValueFunction/dLoss            0.00279713
TotalEnvSteps                        891600
-----------------------------------  ---------------
2022-08-17 18:12:36 | [trpo_pendulum] epoch #743 | Saving snapshot...
2022-08-17 18:12:36 | [trpo_pendulum] epoch #743 | Saved
2022-08-17 18:12:36 | [trpo_pendulum] epoch #743 | Time 472.57 s
2022-08-17 18:12:36 | [trpo_pendulum] epoch #743 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -653.707
Evaluation/AverageReturn              -1502.31
Evaluation/Iteration                    743
Evaluation/MaxReturn                  -1494.75
Evaluation/MinReturn                  -1513.44
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.72736
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.96504
GaussianMLPPolicy/KL                      0.00546044
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              12.5505
GaussianMLPPolicy/LossBefore             14.0764
GaussianMLPPolicy/dLoss                   1.52589
GaussianMLPValueFunction/LossAfter        6.62181
GaussianMLPValueFunction/LossBefore       6.62228
GaussianMLPValueFunction/dLoss            0.00047493
TotalEnvSteps                        892800
-----------------------------------  ---------------
2022-08-17 18:12:37 | [trpo_pendulum] epoch #744 | Saving snapshot...
2022-08-17 18:12:37 | [trpo_pendulum] epoch #744 | Saved
2022-08-17 18:12:37 | [trpo_pendulum] epoch #744 | Time 473.22 s
2022-08-17 18:12:37 | [trpo_pendulum] epoch #744 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -667.964
Evaluation/AverageReturn              -1578.22
Evaluation/Iteration                    744
Evaluation/MaxReturn                  -1536.19
Evaluation/MinReturn                  -1614.87
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     29.7804
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.96787
GaussianMLPPolicy/KL                      0.00667266
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              27.3918
GaussianMLPPolicy/LossBefore             29.5798
GaussianMLPPolicy/dLoss                   2.18802
GaussianMLPValueFunction/LossAfter        6.72247
GaussianMLPValueFunction/LossBefore       6.72866
GaussianMLPValueFunction/dLoss            0.00618219
TotalEnvSteps                        894000
-----------------------------------  ---------------
2022-08-17 18:12:38 | [trpo_pendulum] epoch #745 | Saving snapshot...
2022-08-17 18:12:38 | [trpo_pendulum] epoch #745 | Saved
2022-08-17 18:12:38 | [trpo_pendulum] epoch #745 | Time 473.85 s
2022-08-17 18:12:38 | [trpo_pendulum] epoch #745 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -551.691
Evaluation/AverageReturn              -1380.88
Evaluation/Iteration                    745
Evaluation/MaxReturn                  -1354.29
Evaluation/MinReturn                  -1410.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     19.7045
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.99672
GaussianMLPPolicy/KL                      0.00564519
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               5.12504
GaussianMLPPolicy/LossBefore              5.96632
GaussianMLPPolicy/dLoss                   0.841274
GaussianMLPValueFunction/LossAfter        6.57114
GaussianMLPValueFunction/LossBefore       6.57993
GaussianMLPValueFunction/dLoss            0.00879574
TotalEnvSteps                        895200
-----------------------------------  ---------------
2022-08-17 18:12:38 | [trpo_pendulum] epoch #746 | Saving snapshot...
2022-08-17 18:12:38 | [trpo_pendulum] epoch #746 | Saved
2022-08-17 18:12:38 | [trpo_pendulum] epoch #746 | Time 474.50 s
2022-08-17 18:12:38 | [trpo_pendulum] epoch #746 | EpochTime 0.65 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -678.577
Evaluation/AverageReturn              -1544.39
Evaluation/Iteration                    746
Evaluation/MaxReturn                  -1533.22
Evaluation/MinReturn                  -1561.34
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     11.1751
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.00803
GaussianMLPPolicy/KL                      0.00947378
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              17.9875
GaussianMLPPolicy/LossBefore             19.3049
GaussianMLPPolicy/dLoss                   1.31739
GaussianMLPValueFunction/LossAfter        6.65152
GaussianMLPValueFunction/LossBefore       6.65175
GaussianMLPValueFunction/dLoss            0.000226498
TotalEnvSteps                        896400
-----------------------------------  ----------------
2022-08-17 18:12:39 | [trpo_pendulum] epoch #747 | Saving snapshot...
2022-08-17 18:12:39 | [trpo_pendulum] epoch #747 | Saved
2022-08-17 18:12:39 | [trpo_pendulum] epoch #747 | Time 475.14 s
2022-08-17 18:12:39 | [trpo_pendulum] epoch #747 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -613.152
Evaluation/AverageReturn              -1516.79
Evaluation/Iteration                    747
Evaluation/MaxReturn                  -1326
Evaluation/MinReturn                  -1595.71
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     91.0707
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.0271
GaussianMLPPolicy/KL                      0.00996445
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              21.4169
GaussianMLPPolicy/LossBefore             24.2671
GaussianMLPPolicy/dLoss                   2.85016
GaussianMLPValueFunction/LossAfter        6.67831
GaussianMLPValueFunction/LossBefore       6.67974
GaussianMLPValueFunction/dLoss            0.00142908
TotalEnvSteps                        897600
-----------------------------------  ---------------
2022-08-17 18:12:39 | [trpo_pendulum] epoch #748 | Saving snapshot...
2022-08-17 18:12:40 | [trpo_pendulum] epoch #748 | Saved
2022-08-17 18:12:40 | [trpo_pendulum] epoch #748 | Time 475.78 s
2022-08-17 18:12:40 | [trpo_pendulum] epoch #748 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -716.25
Evaluation/AverageReturn              -1622.25
Evaluation/Iteration                    748
Evaluation/MaxReturn                  -1589.88
Evaluation/MinReturn                  -1653.29
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     23.1162
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.02367
GaussianMLPPolicy/KL                      0.00787212
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              29.6928
GaussianMLPPolicy/LossBefore             31.2825
GaussianMLPPolicy/dLoss                   1.58967
GaussianMLPValueFunction/LossAfter        6.75277
GaussianMLPValueFunction/LossBefore       6.75969
GaussianMLPValueFunction/dLoss            0.00691414
TotalEnvSteps                        898800
-----------------------------------  ---------------
2022-08-17 18:12:40 | [trpo_pendulum] epoch #749 | Saving snapshot...
2022-08-17 18:12:40 | [trpo_pendulum] epoch #749 | Saved
2022-08-17 18:12:40 | [trpo_pendulum] epoch #749 | Time 476.39 s
2022-08-17 18:12:40 | [trpo_pendulum] epoch #749 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -617.042
Evaluation/AverageReturn              -1500.42
Evaluation/Iteration                    749
Evaluation/MaxReturn                  -1492.42
Evaluation/MinReturn                  -1511.5
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      7.48406
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.00326
GaussianMLPPolicy/KL                      0.00911497
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              18.9409
GaussianMLPPolicy/LossBefore             19.7934
GaussianMLPPolicy/dLoss                   0.852528
GaussianMLPValueFunction/LossAfter        6.62163
GaussianMLPValueFunction/LossBefore       6.62517
GaussianMLPValueFunction/dLoss            0.0035367
TotalEnvSteps                        900000
-----------------------------------  ---------------
2022-08-17 18:12:41 | [trpo_pendulum] epoch #750 | Saving snapshot...
2022-08-17 18:12:41 | [trpo_pendulum] epoch #750 | Saved
2022-08-17 18:12:41 | [trpo_pendulum] epoch #750 | Time 477.03 s
2022-08-17 18:12:41 | [trpo_pendulum] epoch #750 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -707.855
Evaluation/AverageReturn              -1610.57
Evaluation/Iteration                    750
Evaluation/MaxReturn                  -1563.77
Evaluation/MinReturn                  -1725.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     53.2836
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.95548
GaussianMLPPolicy/KL                      0.00818742
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              26.9963
GaussianMLPPolicy/LossBefore             29.1567
GaussianMLPPolicy/dLoss                   2.16043
GaussianMLPValueFunction/LossAfter        6.73008
GaussianMLPValueFunction/LossBefore       6.73287
GaussianMLPValueFunction/dLoss            0.00278616
TotalEnvSteps                        901200
-----------------------------------  ---------------
2022-08-17 18:12:41 | [trpo_pendulum] epoch #751 | Saving snapshot...
2022-08-17 18:12:41 | [trpo_pendulum] epoch #751 | Saved
2022-08-17 18:12:41 | [trpo_pendulum] epoch #751 | Time 477.70 s
2022-08-17 18:12:41 | [trpo_pendulum] epoch #751 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -555.128
Evaluation/AverageReturn              -1399.65
Evaluation/Iteration                    751
Evaluation/MaxReturn                  -1350.08
Evaluation/MinReturn                  -1477.66
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     43.7976
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.94623
GaussianMLPPolicy/KL                      0.00758625
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              13.8533
GaussianMLPPolicy/LossBefore             15.1958
GaussianMLPPolicy/dLoss                   1.34253
GaussianMLPValueFunction/LossAfter        6.55111
GaussianMLPValueFunction/LossBefore       6.56593
GaussianMLPValueFunction/dLoss            0.0148177
TotalEnvSteps                        902400
-----------------------------------  ---------------
2022-08-17 18:12:42 | [trpo_pendulum] epoch #752 | Saving snapshot...
2022-08-17 18:12:42 | [trpo_pendulum] epoch #752 | Saved
2022-08-17 18:12:42 | [trpo_pendulum] epoch #752 | Time 478.33 s
2022-08-17 18:12:42 | [trpo_pendulum] epoch #752 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -603.106
Evaluation/AverageReturn              -1467.25
Evaluation/Iteration                    752
Evaluation/MaxReturn                  -1365.53
Evaluation/MinReturn                  -1510.76
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.9231
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.95866
GaussianMLPPolicy/KL                      0.00487294
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              36.1623
GaussianMLPPolicy/LossBefore             36.8238
GaussianMLPPolicy/dLoss                   0.661499
GaussianMLPValueFunction/LossAfter        6.62472
GaussianMLPValueFunction/LossBefore       6.66185
GaussianMLPValueFunction/dLoss            0.0371308
TotalEnvSteps                        903600
-----------------------------------  ---------------
2022-08-17 18:12:43 | [trpo_pendulum] epoch #753 | Saving snapshot...
2022-08-17 18:12:43 | [trpo_pendulum] epoch #753 | Saved
2022-08-17 18:12:43 | [trpo_pendulum] epoch #753 | Time 478.98 s
2022-08-17 18:12:43 | [trpo_pendulum] epoch #753 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -606.519
Evaluation/AverageReturn              -1496.22
Evaluation/Iteration                    753
Evaluation/MaxReturn                  -1461.64
Evaluation/MinReturn                  -1514.61
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     18.0443
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.97702
GaussianMLPPolicy/KL                      0.00933334
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              19.9325
GaussianMLPPolicy/LossBefore             21.2912
GaussianMLPPolicy/dLoss                   1.35871
GaussianMLPValueFunction/LossAfter        6.6292
GaussianMLPValueFunction/LossBefore       6.62927
GaussianMLPValueFunction/dLoss            6.7234e-05
TotalEnvSteps                        904800
-----------------------------------  ---------------
2022-08-17 18:12:43 | [trpo_pendulum] epoch #754 | Saving snapshot...
2022-08-17 18:12:43 | [trpo_pendulum] epoch #754 | Saved
2022-08-17 18:12:43 | [trpo_pendulum] epoch #754 | Time 479.64 s
2022-08-17 18:12:43 | [trpo_pendulum] epoch #754 | EpochTime 0.66 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -632.242
Evaluation/AverageReturn              -1506.57
Evaluation/Iteration                    754
Evaluation/MaxReturn                  -1486.51
Evaluation/MinReturn                  -1521.83
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     11.1992
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.98073
GaussianMLPPolicy/KL                      0.00536399
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              18.1806
GaussianMLPPolicy/LossBefore             18.6084
GaussianMLPPolicy/dLoss                   0.427811
GaussianMLPValueFunction/LossAfter        6.64632
GaussianMLPValueFunction/LossBefore       6.64647
GaussianMLPValueFunction/dLoss            0.000151157
TotalEnvSteps                        906000
-----------------------------------  ----------------
2022-08-17 18:12:44 | [trpo_pendulum] epoch #755 | Saving snapshot...
2022-08-17 18:12:44 | [trpo_pendulum] epoch #755 | Saved
2022-08-17 18:12:44 | [trpo_pendulum] epoch #755 | Time 480.31 s
2022-08-17 18:12:44 | [trpo_pendulum] epoch #755 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -629.464
Evaluation/AverageReturn              -1554.72
Evaluation/Iteration                    755
Evaluation/MaxReturn                  -1543.05
Evaluation/MinReturn                  -1576.58
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.9633
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.98267
GaussianMLPPolicy/KL                      0.00475904
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              36.3756
GaussianMLPPolicy/LossBefore             36.9645
GaussianMLPPolicy/dLoss                   0.588951
GaussianMLPValueFunction/LossAfter        6.7302
GaussianMLPValueFunction/LossBefore       6.74234
GaussianMLPValueFunction/dLoss            0.0121441
TotalEnvSteps                        907200
-----------------------------------  ---------------
2022-08-17 18:12:45 | [trpo_pendulum] epoch #756 | Saving snapshot...
2022-08-17 18:12:45 | [trpo_pendulum] epoch #756 | Saved
2022-08-17 18:12:45 | [trpo_pendulum] epoch #756 | Time 480.98 s
2022-08-17 18:12:45 | [trpo_pendulum] epoch #756 | EpochTime 0.67 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -614.793
Evaluation/AverageReturn              -1516.6
Evaluation/Iteration                    756
Evaluation/MaxReturn                  -1477.95
Evaluation/MinReturn                  -1551.86
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     24.7221
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.01639
GaussianMLPPolicy/KL                      0.00692499
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              20.9592
GaussianMLPPolicy/LossBefore             22.6752
GaussianMLPPolicy/dLoss                   1.71601
GaussianMLPValueFunction/LossAfter        6.64723
GaussianMLPValueFunction/LossBefore       6.65518
GaussianMLPValueFunction/dLoss            0.0079546
TotalEnvSteps                        908400
-----------------------------------  ---------------
2022-08-17 18:12:45 | [trpo_pendulum] epoch #757 | Saving snapshot...
2022-08-17 18:12:45 | [trpo_pendulum] epoch #757 | Saved
2022-08-17 18:12:45 | [trpo_pendulum] epoch #757 | Time 481.64 s
2022-08-17 18:12:45 | [trpo_pendulum] epoch #757 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -551.32
Evaluation/AverageReturn              -1399.72
Evaluation/Iteration                    757
Evaluation/MaxReturn                  -1323.36
Evaluation/MinReturn                  -1487.43
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     63.2082
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.02563
GaussianMLPPolicy/KL                      0.00724349
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               5.06261
GaussianMLPPolicy/LossBefore              6.4705
GaussianMLPPolicy/dLoss                   1.40789
GaussianMLPValueFunction/LossAfter        6.52414
GaussianMLPValueFunction/LossBefore       6.5406
GaussianMLPValueFunction/dLoss            0.0164614
TotalEnvSteps                        909600
-----------------------------------  ---------------
2022-08-17 18:12:46 | [trpo_pendulum] epoch #758 | Saving snapshot...
2022-08-17 18:12:46 | [trpo_pendulum] epoch #758 | Saved
2022-08-17 18:12:46 | [trpo_pendulum] epoch #758 | Time 482.30 s
2022-08-17 18:12:46 | [trpo_pendulum] epoch #758 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -728.611
Evaluation/AverageReturn              -1606.9
Evaluation/Iteration                    758
Evaluation/MaxReturn                  -1568.55
Evaluation/MinReturn                  -1652.43
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     31.9989
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.00278
GaussianMLPPolicy/KL                      0.00853153
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              20.0822
GaussianMLPPolicy/LossBefore             21.6369
GaussianMLPPolicy/dLoss                   1.55474
GaussianMLPValueFunction/LossAfter        6.6896
GaussianMLPValueFunction/LossBefore       6.69332
GaussianMLPValueFunction/dLoss            0.00371838
TotalEnvSteps                        910800
-----------------------------------  ---------------
2022-08-17 18:12:47 | [trpo_pendulum] epoch #759 | Saving snapshot...
2022-08-17 18:12:47 | [trpo_pendulum] epoch #759 | Saved
2022-08-17 18:12:47 | [trpo_pendulum] epoch #759 | Time 482.94 s
2022-08-17 18:12:47 | [trpo_pendulum] epoch #759 | EpochTime 0.64 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -598.243
Evaluation/AverageReturn              -1439.13
Evaluation/Iteration                    759
Evaluation/MaxReturn                  -1362.1
Evaluation/MinReturn                  -1499.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     51.5081
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.00778
GaussianMLPPolicy/KL                      0.000617826
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               8.64174
GaussianMLPPolicy/LossBefore              8.70534
GaussianMLPPolicy/dLoss                   0.0636015
GaussianMLPValueFunction/LossAfter        6.60578
GaussianMLPValueFunction/LossBefore       6.6072
GaussianMLPValueFunction/dLoss            0.00141573
TotalEnvSteps                        912000
-----------------------------------  ----------------
2022-08-17 18:12:47 | [trpo_pendulum] epoch #760 | Saving snapshot...
2022-08-17 18:12:47 | [trpo_pendulum] epoch #760 | Saved
2022-08-17 18:12:47 | [trpo_pendulum] epoch #760 | Time 483.58 s
2022-08-17 18:12:47 | [trpo_pendulum] epoch #760 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -580.027
Evaluation/AverageReturn              -1415.68
Evaluation/Iteration                    760
Evaluation/MaxReturn                  -1380.32
Evaluation/MinReturn                  -1498.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     39.6693
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.00608
GaussianMLPPolicy/KL                      0.00932962
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               9.79868
GaussianMLPPolicy/LossBefore             10.618
GaussianMLPPolicy/dLoss                   0.819274
GaussianMLPValueFunction/LossAfter        6.61429
GaussianMLPValueFunction/LossBefore       6.62167
GaussianMLPValueFunction/dLoss            0.00738096
TotalEnvSteps                        913200
-----------------------------------  ---------------
2022-08-17 18:12:48 | [trpo_pendulum] epoch #761 | Saving snapshot...
2022-08-17 18:12:48 | [trpo_pendulum] epoch #761 | Saved
2022-08-17 18:12:48 | [trpo_pendulum] epoch #761 | Time 484.20 s
2022-08-17 18:12:48 | [trpo_pendulum] epoch #761 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -703.059
Evaluation/AverageReturn              -1589.78
Evaluation/Iteration                    761
Evaluation/MaxReturn                  -1534.18
Evaluation/MinReturn                  -1618.45
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     28.2595
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.01432
GaussianMLPPolicy/KL                      0.00917071
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              20.9429
GaussianMLPPolicy/LossBefore             24.3599
GaussianMLPPolicy/dLoss                   3.41703
GaussianMLPValueFunction/LossAfter        6.69956
GaussianMLPValueFunction/LossBefore       6.70348
GaussianMLPValueFunction/dLoss            0.0039134
TotalEnvSteps                        914400
-----------------------------------  ---------------
2022-08-17 18:12:49 | [trpo_pendulum] epoch #762 | Saving snapshot...
2022-08-17 18:12:49 | [trpo_pendulum] epoch #762 | Saved
2022-08-17 18:12:49 | [trpo_pendulum] epoch #762 | Time 484.84 s
2022-08-17 18:12:49 | [trpo_pendulum] epoch #762 | EpochTime 0.63 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -694.636
Evaluation/AverageReturn              -1570.26
Evaluation/Iteration                    762
Evaluation/MaxReturn                  -1523.87
Evaluation/MinReturn                  -1597.39
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     26.1825
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.00603
GaussianMLPPolicy/KL                      0.00831892
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              19.9504
GaussianMLPPolicy/LossBefore             21.3639
GaussianMLPPolicy/dLoss                   1.41348
GaussianMLPValueFunction/LossAfter        6.68784
GaussianMLPValueFunction/LossBefore       6.68863
GaussianMLPValueFunction/dLoss            0.000787258
TotalEnvSteps                        915600
-----------------------------------  ----------------
2022-08-17 18:12:49 | [trpo_pendulum] epoch #763 | Saving snapshot...
2022-08-17 18:12:49 | [trpo_pendulum] epoch #763 | Saved
2022-08-17 18:12:49 | [trpo_pendulum] epoch #763 | Time 485.47 s
2022-08-17 18:12:49 | [trpo_pendulum] epoch #763 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -607.927
Evaluation/AverageReturn              -1494.75
Evaluation/Iteration                    763
Evaluation/MaxReturn                  -1468.58
Evaluation/MinReturn                  -1519.46
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     17.7014
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.00498
GaussianMLPPolicy/KL                      0.00548527
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              19.7689
GaussianMLPPolicy/LossBefore             20.9746
GaussianMLPPolicy/dLoss                   1.2057
GaussianMLPValueFunction/LossAfter        6.63676
GaussianMLPValueFunction/LossBefore       6.63739
GaussianMLPValueFunction/dLoss            0.00063467
TotalEnvSteps                        916800
-----------------------------------  ---------------
2022-08-17 18:12:50 | [trpo_pendulum] epoch #764 | Saving snapshot...
2022-08-17 18:12:50 | [trpo_pendulum] epoch #764 | Saved
2022-08-17 18:12:50 | [trpo_pendulum] epoch #764 | Time 486.11 s
2022-08-17 18:12:50 | [trpo_pendulum] epoch #764 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -645.151
Evaluation/AverageReturn              -1559.03
Evaluation/Iteration                    764
Evaluation/MaxReturn                  -1547.68
Evaluation/MinReturn                  -1584.28
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.2098
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.95457
GaussianMLPPolicy/KL                      0.00733069
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              34.583
GaussianMLPPolicy/LossBefore             35.8956
GaussianMLPPolicy/dLoss                   1.31255
GaussianMLPValueFunction/LossAfter        6.69128
GaussianMLPValueFunction/LossBefore       6.6957
GaussianMLPValueFunction/dLoss            0.00441551
TotalEnvSteps                        918000
-----------------------------------  ---------------
2022-08-17 18:12:50 | [trpo_pendulum] epoch #765 | Saving snapshot...
2022-08-17 18:12:50 | [trpo_pendulum] epoch #765 | Saved
2022-08-17 18:12:50 | [trpo_pendulum] epoch #765 | Time 486.73 s
2022-08-17 18:12:50 | [trpo_pendulum] epoch #765 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -593.598
Evaluation/AverageReturn              -1374.84
Evaluation/Iteration                    765
Evaluation/MaxReturn                  -1173.39
Evaluation/MinReturn                  -1546.23
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    108.614
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.96017
GaussianMLPPolicy/KL                      0.00634523
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -7.84756
GaussianMLPPolicy/LossBefore             -6.12915
GaussianMLPPolicy/dLoss                   1.71841
GaussianMLPValueFunction/LossAfter        6.51037
GaussianMLPValueFunction/LossBefore       6.55463
GaussianMLPValueFunction/dLoss            0.0442634
TotalEnvSteps                        919200
-----------------------------------  ---------------
2022-08-17 18:12:51 | [trpo_pendulum] epoch #766 | Saving snapshot...
2022-08-17 18:12:51 | [trpo_pendulum] epoch #766 | Saved
2022-08-17 18:12:51 | [trpo_pendulum] epoch #766 | Time 487.35 s
2022-08-17 18:12:51 | [trpo_pendulum] epoch #766 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -591.324
Evaluation/AverageReturn              -1457.51
Evaluation/Iteration                    766
Evaluation/MaxReturn                  -1381.88
Evaluation/MinReturn                  -1496.61
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     39.4354
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.94309
GaussianMLPPolicy/KL                      0.00662018
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              33.2902
GaussianMLPPolicy/LossBefore             34.3376
GaussianMLPPolicy/dLoss                   1.04742
GaussianMLPValueFunction/LossAfter        6.60262
GaussianMLPValueFunction/LossBefore       6.75226
GaussianMLPValueFunction/dLoss            0.149638
TotalEnvSteps                        920400
-----------------------------------  ---------------
2022-08-17 18:12:52 | [trpo_pendulum] epoch #767 | Saving snapshot...
2022-08-17 18:12:52 | [trpo_pendulum] epoch #767 | Saved
2022-08-17 18:12:52 | [trpo_pendulum] epoch #767 | Time 487.99 s
2022-08-17 18:12:52 | [trpo_pendulum] epoch #767 | EpochTime 0.63 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -609.609
Evaluation/AverageReturn              -1481.58
Evaluation/Iteration                    767
Evaluation/MaxReturn                  -1451.36
Evaluation/MinReturn                  -1504.29
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     16.4733
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.96181
GaussianMLPPolicy/KL                      0.00539823
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              16.5933
GaussianMLPPolicy/LossBefore             17.169
GaussianMLPPolicy/dLoss                   0.575722
GaussianMLPValueFunction/LossAfter        6.61371
GaussianMLPValueFunction/LossBefore       6.61374
GaussianMLPValueFunction/dLoss            2.95639e-05
TotalEnvSteps                        921600
-----------------------------------  ----------------
2022-08-17 18:12:52 | [trpo_pendulum] epoch #768 | Saving snapshot...
2022-08-17 18:12:52 | [trpo_pendulum] epoch #768 | Saved
2022-08-17 18:12:52 | [trpo_pendulum] epoch #768 | Time 488.62 s
2022-08-17 18:12:52 | [trpo_pendulum] epoch #768 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -596.884
Evaluation/AverageReturn              -1425.68
Evaluation/Iteration                    768
Evaluation/MaxReturn                  -1366.95
Evaluation/MinReturn                  -1473.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     35.5548
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.95165
GaussianMLPPolicy/KL                      0.00556616
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               6.88973
GaussianMLPPolicy/LossBefore              7.50434
GaussianMLPPolicy/dLoss                   0.614607
GaussianMLPValueFunction/LossAfter        6.59229
GaussianMLPValueFunction/LossBefore       6.59346
GaussianMLPValueFunction/dLoss            0.00116539
TotalEnvSteps                        922800
-----------------------------------  ---------------
2022-08-17 18:12:53 | [trpo_pendulum] epoch #769 | Saving snapshot...
2022-08-17 18:12:53 | [trpo_pendulum] epoch #769 | Saved
2022-08-17 18:12:53 | [trpo_pendulum] epoch #769 | Time 489.26 s
2022-08-17 18:12:53 | [trpo_pendulum] epoch #769 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -643.517
Evaluation/AverageReturn              -1492.84
Evaluation/Iteration                    769
Evaluation/MaxReturn                  -1284.39
Evaluation/MinReturn                  -1579.41
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     96.5264
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.96291
GaussianMLPPolicy/KL                      0.00849345
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              11.6517
GaussianMLPPolicy/LossBefore             13.6202
GaussianMLPPolicy/dLoss                   1.96855
GaussianMLPValueFunction/LossAfter        6.64039
GaussianMLPValueFunction/LossBefore       6.64156
GaussianMLPValueFunction/dLoss            0.00117826
TotalEnvSteps                        924000
-----------------------------------  ---------------
2022-08-17 18:12:54 | [trpo_pendulum] epoch #770 | Saving snapshot...
2022-08-17 18:12:54 | [trpo_pendulum] epoch #770 | Saved
2022-08-17 18:12:54 | [trpo_pendulum] epoch #770 | Time 489.93 s
2022-08-17 18:12:54 | [trpo_pendulum] epoch #770 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -702.883
Evaluation/AverageReturn              -1598.74
Evaluation/Iteration                    770
Evaluation/MaxReturn                  -1517.29
Evaluation/MinReturn                  -1679.46
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     55.5269
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.96996
GaussianMLPPolicy/KL                      0.00643811
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              25.1219
GaussianMLPPolicy/LossBefore             27.2379
GaussianMLPPolicy/dLoss                   2.11599
GaussianMLPValueFunction/LossAfter        6.73495
GaussianMLPValueFunction/LossBefore       6.74436
GaussianMLPValueFunction/dLoss            0.0094018
TotalEnvSteps                        925200
-----------------------------------  ---------------
2022-08-17 18:12:54 | [trpo_pendulum] epoch #771 | Saving snapshot...
2022-08-17 18:12:54 | [trpo_pendulum] epoch #771 | Saved
2022-08-17 18:12:54 | [trpo_pendulum] epoch #771 | Time 490.59 s
2022-08-17 18:12:54 | [trpo_pendulum] epoch #771 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -580.24
Evaluation/AverageReturn              -1449.69
Evaluation/Iteration                    771
Evaluation/MaxReturn                  -1406.86
Evaluation/MinReturn                  -1503.12
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     31.8157
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.00713
GaussianMLPPolicy/KL                      0.00701355
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              13.0198
GaussianMLPPolicy/LossBefore             14.4308
GaussianMLPPolicy/dLoss                   1.41094
GaussianMLPValueFunction/LossAfter        6.60212
GaussianMLPValueFunction/LossBefore       6.6046
GaussianMLPValueFunction/dLoss            0.00247622
TotalEnvSteps                        926400
-----------------------------------  ---------------
2022-08-17 18:12:55 | [trpo_pendulum] epoch #772 | Saving snapshot...
2022-08-17 18:12:55 | [trpo_pendulum] epoch #772 | Saved
2022-08-17 18:12:55 | [trpo_pendulum] epoch #772 | Time 491.25 s
2022-08-17 18:12:55 | [trpo_pendulum] epoch #772 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -718.071
Evaluation/AverageReturn              -1684.35
Evaluation/Iteration                    772
Evaluation/MaxReturn                  -1555.69
Evaluation/MinReturn                  -1743.2
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     63.3256
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.00193
GaussianMLPPolicy/KL                      0.009517
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              41.0502
GaussianMLPPolicy/LossBefore             43.7663
GaussianMLPPolicy/dLoss                   2.71608
GaussianMLPValueFunction/LossAfter        6.85071
GaussianMLPValueFunction/LossBefore       6.88088
GaussianMLPValueFunction/dLoss            0.0301757
TotalEnvSteps                        927600
-----------------------------------  --------------
2022-08-17 18:12:56 | [trpo_pendulum] epoch #773 | Saving snapshot...
2022-08-17 18:12:56 | [trpo_pendulum] epoch #773 | Saved
2022-08-17 18:12:56 | [trpo_pendulum] epoch #773 | Time 491.92 s
2022-08-17 18:12:56 | [trpo_pendulum] epoch #773 | EpochTime 0.67 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -680.276
Evaluation/AverageReturn              -1602.91
Evaluation/Iteration                    773
Evaluation/MaxReturn                  -1586.81
Evaluation/MinReturn                  -1621.25
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     12.8658
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.96361
GaussianMLPPolicy/KL                      0.00852108
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              38.5792
GaussianMLPPolicy/LossBefore             39.1934
GaussianMLPPolicy/dLoss                   0.614193
GaussianMLPValueFunction/LossAfter        6.68666
GaussianMLPValueFunction/LossBefore       6.7021
GaussianMLPValueFunction/dLoss            0.0154467
TotalEnvSteps                        928800
-----------------------------------  ---------------
2022-08-17 18:12:56 | [trpo_pendulum] epoch #774 | Saving snapshot...
2022-08-17 18:12:56 | [trpo_pendulum] epoch #774 | Saved
2022-08-17 18:12:56 | [trpo_pendulum] epoch #774 | Time 492.56 s
2022-08-17 18:12:56 | [trpo_pendulum] epoch #774 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -627.396
Evaluation/AverageReturn              -1520.96
Evaluation/Iteration                    774
Evaluation/MaxReturn                  -1498.84
Evaluation/MinReturn                  -1567.52
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     22.8191
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.95555
GaussianMLPPolicy/KL                      0.00711628
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              21.4462
GaussianMLPPolicy/LossBefore             22.1881
GaussianMLPPolicy/dLoss                   0.741829
GaussianMLPValueFunction/LossAfter        6.65821
GaussianMLPValueFunction/LossBefore       6.66586
GaussianMLPValueFunction/dLoss            0.00765371
TotalEnvSteps                        930000
-----------------------------------  ---------------
2022-08-17 18:12:57 | [trpo_pendulum] epoch #775 | Saving snapshot...
2022-08-17 18:12:57 | [trpo_pendulum] epoch #775 | Saved
2022-08-17 18:12:57 | [trpo_pendulum] epoch #775 | Time 493.25 s
2022-08-17 18:12:57 | [trpo_pendulum] epoch #775 | EpochTime 0.68 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -667.723
Evaluation/AverageReturn              -1573.66
Evaluation/Iteration                    775
Evaluation/MaxReturn                  -1542.82
Evaluation/MinReturn                  -1589.91
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     15.4878
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.94991
GaussianMLPPolicy/KL                      0.00947901
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              25.5903
GaussianMLPPolicy/LossBefore             26.0743
GaussianMLPPolicy/dLoss                   0.483984
GaussianMLPValueFunction/LossAfter        6.68424
GaussianMLPValueFunction/LossBefore       6.68447
GaussianMLPValueFunction/dLoss            0.000235081
TotalEnvSteps                        931200
-----------------------------------  ----------------
2022-08-17 18:12:58 | [trpo_pendulum] epoch #776 | Saving snapshot...
2022-08-17 18:12:58 | [trpo_pendulum] epoch #776 | Saved
2022-08-17 18:12:58 | [trpo_pendulum] epoch #776 | Time 493.92 s
2022-08-17 18:12:58 | [trpo_pendulum] epoch #776 | EpochTime 0.67 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -690.103
Evaluation/AverageReturn              -1563.76
Evaluation/Iteration                    776
Evaluation/MaxReturn                  -1540.98
Evaluation/MinReturn                  -1586.53
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     16.2908
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.96497
GaussianMLPPolicy/KL                      0.0077903
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              18.3765
GaussianMLPPolicy/LossBefore             20.3986
GaussianMLPPolicy/dLoss                   2.02207
GaussianMLPValueFunction/LossAfter        6.68556
GaussianMLPValueFunction/LossBefore       6.68559
GaussianMLPValueFunction/dLoss            2.52724e-05
TotalEnvSteps                        932400
-----------------------------------  ----------------
2022-08-17 18:12:58 | [trpo_pendulum] epoch #777 | Saving snapshot...
2022-08-17 18:12:58 | [trpo_pendulum] epoch #777 | Saved
2022-08-17 18:12:58 | [trpo_pendulum] epoch #777 | Time 494.56 s
2022-08-17 18:12:58 | [trpo_pendulum] epoch #777 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -566.712
Evaluation/AverageReturn              -1431.33
Evaluation/Iteration                    777
Evaluation/MaxReturn                  -1378.81
Evaluation/MinReturn                  -1484.93
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     42.421
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.9617
GaussianMLPPolicy/KL                      0.00973822
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              11.5482
GaussianMLPPolicy/LossBefore             12.8625
GaussianMLPPolicy/dLoss                   1.31426
GaussianMLPValueFunction/LossAfter        6.57269
GaussianMLPValueFunction/LossBefore       6.59202
GaussianMLPValueFunction/dLoss            0.0193262
TotalEnvSteps                        933600
-----------------------------------  ---------------
2022-08-17 18:12:59 | [trpo_pendulum] epoch #778 | Saving snapshot...
2022-08-17 18:12:59 | [trpo_pendulum] epoch #778 | Saved
2022-08-17 18:12:59 | [trpo_pendulum] epoch #778 | Time 495.21 s
2022-08-17 18:12:59 | [trpo_pendulum] epoch #778 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -615.295
Evaluation/AverageReturn              -1503.98
Evaluation/Iteration                    778
Evaluation/MaxReturn                  -1492.81
Evaluation/MinReturn                  -1520.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.39456
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.95066
GaussianMLPPolicy/KL                      0.00922679
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              43.2174
GaussianMLPPolicy/LossBefore             44.6208
GaussianMLPPolicy/dLoss                   1.40339
GaussianMLPValueFunction/LossAfter        6.641
GaussianMLPValueFunction/LossBefore       6.68542
GaussianMLPValueFunction/dLoss            0.0444212
TotalEnvSteps                        934800
-----------------------------------  ---------------
2022-08-17 18:13:00 | [trpo_pendulum] epoch #779 | Saving snapshot...
2022-08-17 18:13:00 | [trpo_pendulum] epoch #779 | Saved
2022-08-17 18:13:00 | [trpo_pendulum] epoch #779 | Time 495.84 s
2022-08-17 18:13:00 | [trpo_pendulum] epoch #779 | EpochTime 0.63 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -637.801
Evaluation/AverageReturn              -1521.49
Evaluation/Iteration                    779
Evaluation/MaxReturn                  -1507.91
Evaluation/MinReturn                  -1540.91
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.6493
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.91297
GaussianMLPPolicy/KL                      0.00759058
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              19.3996
GaussianMLPPolicy/LossBefore             19.8755
GaussianMLPPolicy/dLoss                   0.475904
GaussianMLPValueFunction/LossAfter        6.68145
GaussianMLPValueFunction/LossBefore       6.68235
GaussianMLPValueFunction/dLoss            0.000895023
TotalEnvSteps                        936000
-----------------------------------  ----------------
2022-08-17 18:13:00 | [trpo_pendulum] epoch #780 | Saving snapshot...
2022-08-17 18:13:00 | [trpo_pendulum] epoch #780 | Saved
2022-08-17 18:13:00 | [trpo_pendulum] epoch #780 | Time 496.51 s
2022-08-17 18:13:00 | [trpo_pendulum] epoch #780 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -582.969
Evaluation/AverageReturn              -1459.56
Evaluation/Iteration                    780
Evaluation/MaxReturn                  -1361.67
Evaluation/MinReturn                  -1503.65
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     45.6753
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.8982
GaussianMLPPolicy/KL                      0.00711423
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              13.0475
GaussianMLPPolicy/LossBefore             14.4167
GaussianMLPPolicy/dLoss                   1.36919
GaussianMLPValueFunction/LossAfter        6.5745
GaussianMLPValueFunction/LossBefore       6.5838
GaussianMLPValueFunction/dLoss            0.0092988
TotalEnvSteps                        937200
-----------------------------------  ---------------
2022-08-17 18:13:01 | [trpo_pendulum] epoch #781 | Saving snapshot...
2022-08-17 18:13:01 | [trpo_pendulum] epoch #781 | Saved
2022-08-17 18:13:01 | [trpo_pendulum] epoch #781 | Time 497.14 s
2022-08-17 18:13:01 | [trpo_pendulum] epoch #781 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -662.49
Evaluation/AverageReturn              -1550.19
Evaluation/Iteration                    781
Evaluation/MaxReturn                  -1524.46
Evaluation/MinReturn                  -1573.71
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     17.9635
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.89683
GaussianMLPPolicy/KL                      0.00776384
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              20.1911
GaussianMLPPolicy/LossBefore             21.1184
GaussianMLPPolicy/dLoss                   0.927322
GaussianMLPValueFunction/LossAfter        6.67809
GaussianMLPValueFunction/LossBefore       6.67974
GaussianMLPValueFunction/dLoss            0.00164843
TotalEnvSteps                        938400
-----------------------------------  ---------------
2022-08-17 18:13:01 | [trpo_pendulum] epoch #782 | Saving snapshot...
2022-08-17 18:13:01 | [trpo_pendulum] epoch #782 | Saved
2022-08-17 18:13:01 | [trpo_pendulum] epoch #782 | Time 497.76 s
2022-08-17 18:13:01 | [trpo_pendulum] epoch #782 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -624.004
Evaluation/AverageReturn              -1510.59
Evaluation/Iteration                    782
Evaluation/MaxReturn                  -1495.76
Evaluation/MinReturn                  -1534.2
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     11.8256
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.8842
GaussianMLPPolicy/KL                      0.00981336
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              18.1438
GaussianMLPPolicy/LossBefore             20.0911
GaussianMLPPolicy/dLoss                   1.94732
GaussianMLPValueFunction/LossAfter        6.66996
GaussianMLPValueFunction/LossBefore       6.67035
GaussianMLPValueFunction/dLoss            0.0003829
TotalEnvSteps                        939600
-----------------------------------  ---------------
2022-08-17 18:13:02 | [trpo_pendulum] epoch #783 | Saving snapshot...
2022-08-17 18:13:02 | [trpo_pendulum] epoch #783 | Saved
2022-08-17 18:13:02 | [trpo_pendulum] epoch #783 | Time 498.38 s
2022-08-17 18:13:02 | [trpo_pendulum] epoch #783 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -603.683
Evaluation/AverageReturn              -1464.78
Evaluation/Iteration                    783
Evaluation/MaxReturn                  -1408.42
Evaluation/MinReturn                  -1499.7
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     33.9758
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.88246
GaussianMLPPolicy/KL                      0.00692072
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              28.6398
GaussianMLPPolicy/LossBefore             30.2476
GaussianMLPPolicy/dLoss                   1.60775
GaussianMLPValueFunction/LossAfter        6.59118
GaussianMLPValueFunction/LossBefore       6.60105
GaussianMLPValueFunction/dLoss            0.00987577
TotalEnvSteps                        940800
-----------------------------------  ---------------
2022-08-17 18:13:03 | [trpo_pendulum] epoch #784 | Saving snapshot...
2022-08-17 18:13:03 | [trpo_pendulum] epoch #784 | Saved
2022-08-17 18:13:03 | [trpo_pendulum] epoch #784 | Time 499.00 s
2022-08-17 18:13:03 | [trpo_pendulum] epoch #784 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -641.507
Evaluation/AverageReturn              -1524.72
Evaluation/Iteration                    784
Evaluation/MaxReturn                  -1515.12
Evaluation/MinReturn                  -1531.96
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      6.56839
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.91776
GaussianMLPPolicy/KL                      0.00958536
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              17.9151
GaussianMLPPolicy/LossBefore             19.236
GaussianMLPPolicy/dLoss                   1.32092
GaussianMLPValueFunction/LossAfter        6.68523
GaussianMLPValueFunction/LossBefore       6.68724
GaussianMLPValueFunction/dLoss            0.00201082
TotalEnvSteps                        942000
-----------------------------------  ---------------
2022-08-17 18:13:03 | [trpo_pendulum] epoch #785 | Saving snapshot...
2022-08-17 18:13:03 | [trpo_pendulum] epoch #785 | Saved
2022-08-17 18:13:03 | [trpo_pendulum] epoch #785 | Time 499.65 s
2022-08-17 18:13:03 | [trpo_pendulum] epoch #785 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -599.61
Evaluation/AverageReturn              -1483.87
Evaluation/Iteration                    785
Evaluation/MaxReturn                  -1461.94
Evaluation/MinReturn                  -1499.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     12.0534
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.91064
GaussianMLPPolicy/KL                      0.00706207
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              19.7836
GaussianMLPPolicy/LossBefore             21.12
GaussianMLPPolicy/dLoss                   1.33638
GaussianMLPValueFunction/LossAfter        6.60091
GaussianMLPValueFunction/LossBefore       6.60328
GaussianMLPValueFunction/dLoss            0.00236607
TotalEnvSteps                        943200
-----------------------------------  ---------------
2022-08-17 18:13:04 | [trpo_pendulum] epoch #786 | Saving snapshot...
2022-08-17 18:13:04 | [trpo_pendulum] epoch #786 | Saved
2022-08-17 18:13:04 | [trpo_pendulum] epoch #786 | Time 500.29 s
2022-08-17 18:13:04 | [trpo_pendulum] epoch #786 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -608.116
Evaluation/AverageReturn              -1487.05
Evaluation/Iteration                    786
Evaluation/MaxReturn                  -1450.28
Evaluation/MinReturn                  -1541.24
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     30.8925
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.9202
GaussianMLPPolicy/KL                      0.00646608
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              16.3903
GaussianMLPPolicy/LossBefore             18.2482
GaussianMLPPolicy/dLoss                   1.85795
GaussianMLPValueFunction/LossAfter        6.59218
GaussianMLPValueFunction/LossBefore       6.59479
GaussianMLPValueFunction/dLoss            0.00261021
TotalEnvSteps                        944400
-----------------------------------  ---------------
2022-08-17 18:13:05 | [trpo_pendulum] epoch #787 | Saving snapshot...
2022-08-17 18:13:05 | [trpo_pendulum] epoch #787 | Saved
2022-08-17 18:13:05 | [trpo_pendulum] epoch #787 | Time 500.91 s
2022-08-17 18:13:05 | [trpo_pendulum] epoch #787 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -667.976
Evaluation/AverageReturn              -1561.05
Evaluation/Iteration                    787
Evaluation/MaxReturn                  -1529.03
Evaluation/MinReturn                  -1609.63
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     28.195
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.93014
GaussianMLPPolicy/KL                      0.00510821
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              21.0524
GaussianMLPPolicy/LossBefore             21.248
GaussianMLPPolicy/dLoss                   0.195616
GaussianMLPValueFunction/LossAfter        6.6765
GaussianMLPValueFunction/LossBefore       6.67908
GaussianMLPValueFunction/dLoss            0.00258064
TotalEnvSteps                        945600
-----------------------------------  ---------------
2022-08-17 18:13:05 | [trpo_pendulum] epoch #788 | Saving snapshot...
2022-08-17 18:13:05 | [trpo_pendulum] epoch #788 | Saved
2022-08-17 18:13:05 | [trpo_pendulum] epoch #788 | Time 501.54 s
2022-08-17 18:13:05 | [trpo_pendulum] epoch #788 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -675.197
Evaluation/AverageReturn              -1621.11
Evaluation/Iteration                    788
Evaluation/MaxReturn                  -1608.32
Evaluation/MinReturn                  -1636.61
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     11.4137
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.95104
GaussianMLPPolicy/KL                      0.00718103
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              58.0494
GaussianMLPPolicy/LossBefore             59.0351
GaussianMLPPolicy/dLoss                   0.985767
GaussianMLPValueFunction/LossAfter        6.71066
GaussianMLPValueFunction/LossBefore       6.81371
GaussianMLPValueFunction/dLoss            0.103053
TotalEnvSteps                        946800
-----------------------------------  ---------------
2022-08-17 18:13:06 | [trpo_pendulum] epoch #789 | Saving snapshot...
2022-08-17 18:13:06 | [trpo_pendulum] epoch #789 | Saved
2022-08-17 18:13:06 | [trpo_pendulum] epoch #789 | Time 502.20 s
2022-08-17 18:13:06 | [trpo_pendulum] epoch #789 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -635.434
Evaluation/AverageReturn              -1509.88
Evaluation/Iteration                    789
Evaluation/MaxReturn                  -1450.08
Evaluation/MinReturn                  -1554.28
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     35.0995
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.96943
GaussianMLPPolicy/KL                      0.00716005
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              11.8789
GaussianMLPPolicy/LossBefore             14.4832
GaussianMLPPolicy/dLoss                   2.60427
GaussianMLPValueFunction/LossAfter        6.62357
GaussianMLPValueFunction/LossBefore       6.62659
GaussianMLPValueFunction/dLoss            0.00302887
TotalEnvSteps                        948000
-----------------------------------  ---------------
2022-08-17 18:13:07 | [trpo_pendulum] epoch #790 | Saving snapshot...
2022-08-17 18:13:07 | [trpo_pendulum] epoch #790 | Saved
2022-08-17 18:13:07 | [trpo_pendulum] epoch #790 | Time 502.81 s
2022-08-17 18:13:07 | [trpo_pendulum] epoch #790 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -683.922
Evaluation/AverageReturn              -1635.37
Evaluation/Iteration                    790
Evaluation/MaxReturn                  -1630.66
Evaluation/MinReturn                  -1640.3
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      3.89468
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.99345
GaussianMLPPolicy/KL                      0.00500266
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              35.0701
GaussianMLPPolicy/LossBefore             35.9884
GaussianMLPPolicy/dLoss                   0.918316
GaussianMLPValueFunction/LossAfter        6.70978
GaussianMLPValueFunction/LossBefore       6.7151
GaussianMLPValueFunction/dLoss            0.00531864
TotalEnvSteps                        949200
-----------------------------------  ---------------
2022-08-17 18:13:07 | [trpo_pendulum] epoch #791 | Saving snapshot...
2022-08-17 18:13:07 | [trpo_pendulum] epoch #791 | Saved
2022-08-17 18:13:07 | [trpo_pendulum] epoch #791 | Time 503.42 s
2022-08-17 18:13:07 | [trpo_pendulum] epoch #791 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -600.962
Evaluation/AverageReturn              -1488.71
Evaluation/Iteration                    791
Evaluation/MaxReturn                  -1345.23
Evaluation/MinReturn                  -1523.19
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     64.2674
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.9806
GaussianMLPPolicy/KL                      0.0096943
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              13.824
GaussianMLPPolicy/LossBefore             15.6592
GaussianMLPPolicy/dLoss                   1.83516
GaussianMLPValueFunction/LossAfter        6.64776
GaussianMLPValueFunction/LossBefore       6.65087
GaussianMLPValueFunction/dLoss            0.00310612
TotalEnvSteps                        950400
-----------------------------------  ---------------
2022-08-17 18:13:08 | [trpo_pendulum] epoch #792 | Saving snapshot...
2022-08-17 18:13:08 | [trpo_pendulum] epoch #792 | Saved
2022-08-17 18:13:08 | [trpo_pendulum] epoch #792 | Time 504.04 s
2022-08-17 18:13:08 | [trpo_pendulum] epoch #792 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -571.681
Evaluation/AverageReturn              -1387.71
Evaluation/Iteration                    792
Evaluation/MaxReturn                  -1348.28
Evaluation/MinReturn                  -1432.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     28.5654
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.97095
GaussianMLPPolicy/KL                      0.00564323
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.00842
GaussianMLPPolicy/LossBefore             -1.73101
GaussianMLPPolicy/dLoss                   1.2774
GaussianMLPValueFunction/LossAfter        6.59454
GaussianMLPValueFunction/LossBefore       6.59991
GaussianMLPValueFunction/dLoss            0.00536919
TotalEnvSteps                        951600
-----------------------------------  ---------------
2022-08-17 18:13:08 | [trpo_pendulum] epoch #793 | Saving snapshot...
2022-08-17 18:13:08 | [trpo_pendulum] epoch #793 | Saved
2022-08-17 18:13:08 | [trpo_pendulum] epoch #793 | Time 504.65 s
2022-08-17 18:13:08 | [trpo_pendulum] epoch #793 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -582.348
Evaluation/AverageReturn              -1447.24
Evaluation/Iteration                    793
Evaluation/MaxReturn                  -1331.08
Evaluation/MinReturn                  -1534.42
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     68.4593
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.9613
GaussianMLPPolicy/KL                      0.00913147
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               9.1804
GaussianMLPPolicy/LossBefore             10.598
GaussianMLPPolicy/dLoss                   1.41761
GaussianMLPValueFunction/LossAfter        6.59469
GaussianMLPValueFunction/LossBefore       6.59765
GaussianMLPValueFunction/dLoss            0.00296211
TotalEnvSteps                        952800
-----------------------------------  ---------------
2022-08-17 18:13:09 | [trpo_pendulum] epoch #794 | Saving snapshot...
2022-08-17 18:13:09 | [trpo_pendulum] epoch #794 | Saved
2022-08-17 18:13:09 | [trpo_pendulum] epoch #794 | Time 505.27 s
2022-08-17 18:13:09 | [trpo_pendulum] epoch #794 | EpochTime 0.61 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -656.935
Evaluation/AverageReturn              -1510.35
Evaluation/Iteration                    794
Evaluation/MaxReturn                  -1502.28
Evaluation/MinReturn                  -1524.35
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      7.13284
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.95945
GaussianMLPPolicy/KL                      0.0077571
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               9.88854
GaussianMLPPolicy/LossBefore             11.1569
GaussianMLPPolicy/dLoss                   1.26838
GaussianMLPValueFunction/LossAfter        6.62506
GaussianMLPValueFunction/LossBefore       6.62561
GaussianMLPValueFunction/dLoss            0.000549316
TotalEnvSteps                        954000
-----------------------------------  ----------------
2022-08-17 18:13:10 | [trpo_pendulum] epoch #795 | Saving snapshot...
2022-08-17 18:13:10 | [trpo_pendulum] epoch #795 | Saved
2022-08-17 18:13:10 | [trpo_pendulum] epoch #795 | Time 505.92 s
2022-08-17 18:13:10 | [trpo_pendulum] epoch #795 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -609.143
Evaluation/AverageReturn              -1489.77
Evaluation/Iteration                    795
Evaluation/MaxReturn                  -1439.64
Evaluation/MinReturn                  -1521.6
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     25.4446
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.96701
GaussianMLPPolicy/KL                      0.00458531
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              17.2266
GaussianMLPPolicy/LossBefore             17.3915
GaussianMLPPolicy/dLoss                   0.164907
GaussianMLPValueFunction/LossAfter        6.63557
GaussianMLPValueFunction/LossBefore       6.63574
GaussianMLPValueFunction/dLoss            0.0001688
TotalEnvSteps                        955200
-----------------------------------  ---------------
2022-08-17 18:13:10 | [trpo_pendulum] epoch #796 | Saving snapshot...
2022-08-17 18:13:10 | [trpo_pendulum] epoch #796 | Saved
2022-08-17 18:13:10 | [trpo_pendulum] epoch #796 | Time 506.53 s
2022-08-17 18:13:10 | [trpo_pendulum] epoch #796 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -688.922
Evaluation/AverageReturn              -1600.63
Evaluation/Iteration                    796
Evaluation/MaxReturn                  -1374.99
Evaluation/MinReturn                  -1713.74
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    114.11
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.94052
GaussianMLPPolicy/KL                      0.00981774
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              24.3894
GaussianMLPPolicy/LossBefore             27.0791
GaussianMLPPolicy/dLoss                   2.6897
GaussianMLPValueFunction/LossAfter        6.77199
GaussianMLPValueFunction/LossBefore       6.78673
GaussianMLPValueFunction/dLoss            0.0147452
TotalEnvSteps                        956400
-----------------------------------  ---------------
2022-08-17 18:13:11 | [trpo_pendulum] epoch #797 | Saving snapshot...
2022-08-17 18:13:11 | [trpo_pendulum] epoch #797 | Saved
2022-08-17 18:13:11 | [trpo_pendulum] epoch #797 | Time 507.17 s
2022-08-17 18:13:11 | [trpo_pendulum] epoch #797 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -729.08
Evaluation/AverageReturn              -1693.87
Evaluation/Iteration                    797
Evaluation/MaxReturn                  -1534.42
Evaluation/MinReturn                  -1756.51
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     74.227
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.95119
GaussianMLPPolicy/KL                      0.00784378
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              37.2529
GaussianMLPPolicy/LossBefore             39.6219
GaussianMLPPolicy/dLoss                   2.36898
GaussianMLPValueFunction/LossAfter        6.79614
GaussianMLPValueFunction/LossBefore       6.80571
GaussianMLPValueFunction/dLoss            0.00956821
TotalEnvSteps                        957600
-----------------------------------  ---------------
2022-08-17 18:13:12 | [trpo_pendulum] epoch #798 | Saving snapshot...
2022-08-17 18:13:12 | [trpo_pendulum] epoch #798 | Saved
2022-08-17 18:13:12 | [trpo_pendulum] epoch #798 | Time 507.80 s
2022-08-17 18:13:12 | [trpo_pendulum] epoch #798 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -647
Evaluation/AverageReturn              -1536.79
Evaluation/Iteration                    798
Evaluation/MaxReturn                  -1506.38
Evaluation/MinReturn                  -1562.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     19.4848
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.94395
GaussianMLPPolicy/KL                      0.00570542
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              19.9528
GaussianMLPPolicy/LossBefore             20.024
GaussianMLPPolicy/dLoss                   0.0712013
GaussianMLPValueFunction/LossAfter        6.68388
GaussianMLPValueFunction/LossBefore       6.68524
GaussianMLPValueFunction/dLoss            0.00136137
TotalEnvSteps                        958800
-----------------------------------  ---------------
2022-08-17 18:13:12 | [trpo_pendulum] epoch #799 | Saving snapshot...
2022-08-17 18:13:12 | [trpo_pendulum] epoch #799 | Saved
2022-08-17 18:13:12 | [trpo_pendulum] epoch #799 | Time 508.43 s
2022-08-17 18:13:12 | [trpo_pendulum] epoch #799 | EpochTime 0.63 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -646.534
Evaluation/AverageReturn              -1531.65
Evaluation/Iteration                    799
Evaluation/MaxReturn                  -1513.76
Evaluation/MinReturn                  -1552.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     11.9838
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.93654
GaussianMLPPolicy/KL                      0.0060613
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              17.6413
GaussianMLPPolicy/LossBefore             18.7204
GaussianMLPPolicy/dLoss                   1.07908
GaussianMLPValueFunction/LossAfter        6.68188
GaussianMLPValueFunction/LossBefore       6.68257
GaussianMLPValueFunction/dLoss            0.000693321
TotalEnvSteps                        960000
-----------------------------------  ----------------
2022-08-17 18:13:13 | [trpo_pendulum] epoch #800 | Saving snapshot...
2022-08-17 18:13:13 | [trpo_pendulum] epoch #800 | Saved
2022-08-17 18:13:13 | [trpo_pendulum] epoch #800 | Time 509.07 s
2022-08-17 18:13:13 | [trpo_pendulum] epoch #800 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -675.419
Evaluation/AverageReturn              -1627.21
Evaluation/Iteration                    800
Evaluation/MaxReturn                  -1617.2
Evaluation/MinReturn                  -1635.11
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      6.44945
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.94807
GaussianMLPPolicy/KL                      0.00780639
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              40.6906
GaussianMLPPolicy/LossBefore             41.2402
GaussianMLPPolicy/dLoss                   0.549637
GaussianMLPValueFunction/LossAfter        6.70091
GaussianMLPValueFunction/LossBefore       6.7109
GaussianMLPValueFunction/dLoss            0.00998306
TotalEnvSteps                        961200
-----------------------------------  ---------------
2022-08-17 18:13:13 | [trpo_pendulum] epoch #801 | Saving snapshot...
2022-08-17 18:13:13 | [trpo_pendulum] epoch #801 | Saved
2022-08-17 18:13:13 | [trpo_pendulum] epoch #801 | Time 509.70 s
2022-08-17 18:13:13 | [trpo_pendulum] epoch #801 | EpochTime 0.62 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -646.14
Evaluation/AverageReturn              -1585.76
Evaluation/Iteration                    801
Evaluation/MaxReturn                  -1574.3
Evaluation/MinReturn                  -1596.2
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.10824
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.99895
GaussianMLPPolicy/KL                      0.00737669
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              29.3057
GaussianMLPPolicy/LossBefore             31.1497
GaussianMLPPolicy/dLoss                   1.84403
GaussianMLPValueFunction/LossAfter        6.71833
GaussianMLPValueFunction/LossBefore       6.71923
GaussianMLPValueFunction/dLoss            0.000902176
TotalEnvSteps                        962400
-----------------------------------  ----------------
2022-08-17 18:13:14 | [trpo_pendulum] epoch #802 | Saving snapshot...
2022-08-17 18:13:14 | [trpo_pendulum] epoch #802 | Saved
2022-08-17 18:13:14 | [trpo_pendulum] epoch #802 | Time 510.33 s
2022-08-17 18:13:14 | [trpo_pendulum] epoch #802 | EpochTime 0.62 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -593.566
Evaluation/AverageReturn              -1514.68
Evaluation/Iteration                    802
Evaluation/MaxReturn                  -1483.18
Evaluation/MinReturn                  -1524.68
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.337
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.01711
GaussianMLPPolicy/KL                      0.00817464
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              23.4371
GaussianMLPPolicy/LossBefore             24.1313
GaussianMLPPolicy/dLoss                   0.694187
GaussianMLPValueFunction/LossAfter        6.68553
GaussianMLPValueFunction/LossBefore       6.68605
GaussianMLPValueFunction/dLoss            0.000516891
TotalEnvSteps                        963600
-----------------------------------  ----------------
2022-08-17 18:13:15 | [trpo_pendulum] epoch #803 | Saving snapshot...
2022-08-17 18:13:15 | [trpo_pendulum] epoch #803 | Saved
2022-08-17 18:13:15 | [trpo_pendulum] epoch #803 | Time 510.95 s
2022-08-17 18:13:15 | [trpo_pendulum] epoch #803 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -654.9
Evaluation/AverageReturn              -1507.78
Evaluation/Iteration                    803
Evaluation/MaxReturn                  -1500.2
Evaluation/MinReturn                  -1513.53
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      4.3642
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.00714
GaussianMLPPolicy/KL                      0.00957403
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               7.73175
GaussianMLPPolicy/LossBefore              9.25914
GaussianMLPPolicy/dLoss                   1.52739
GaussianMLPValueFunction/LossAfter        6.62851
GaussianMLPValueFunction/LossBefore       6.63243
GaussianMLPValueFunction/dLoss            0.00391388
TotalEnvSteps                        964800
-----------------------------------  ---------------
2022-08-17 18:13:15 | [trpo_pendulum] epoch #804 | Saving snapshot...
2022-08-17 18:13:15 | [trpo_pendulum] epoch #804 | Saved
2022-08-17 18:13:15 | [trpo_pendulum] epoch #804 | Time 511.57 s
2022-08-17 18:13:15 | [trpo_pendulum] epoch #804 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -655.328
Evaluation/AverageReturn              -1581.69
Evaluation/Iteration                    804
Evaluation/MaxReturn                  -1455.89
Evaluation/MinReturn                  -1726.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     90.6903
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.99184
GaussianMLPPolicy/KL                      0.00714193
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              23.0815
GaussianMLPPolicy/LossBefore             25.2884
GaussianMLPPolicy/dLoss                   2.20694
GaussianMLPValueFunction/LossAfter        6.67869
GaussianMLPValueFunction/LossBefore       6.68857
GaussianMLPValueFunction/dLoss            0.00988245
TotalEnvSteps                        966000
-----------------------------------  ---------------
2022-08-17 18:13:16 | [trpo_pendulum] epoch #805 | Saving snapshot...
2022-08-17 18:13:16 | [trpo_pendulum] epoch #805 | Saved
2022-08-17 18:13:16 | [trpo_pendulum] epoch #805 | Time 512.23 s
2022-08-17 18:13:16 | [trpo_pendulum] epoch #805 | EpochTime 0.66 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -664.415
Evaluation/AverageReturn              -1581.56
Evaluation/Iteration                    805
Evaluation/MaxReturn                  -1557.31
Evaluation/MinReturn                  -1619.72
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     20.412
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.00079
GaussianMLPPolicy/KL                      0.00974083
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              24.0163
GaussianMLPPolicy/LossBefore             24.4924
GaussianMLPPolicy/dLoss                   0.476004
GaussianMLPValueFunction/LossAfter        6.68867
GaussianMLPValueFunction/LossBefore       6.68891
GaussianMLPValueFunction/dLoss            0.000244141
TotalEnvSteps                        967200
-----------------------------------  ----------------
2022-08-17 18:13:17 | [trpo_pendulum] epoch #806 | Saving snapshot...
2022-08-17 18:13:17 | [trpo_pendulum] epoch #806 | Saved
2022-08-17 18:13:17 | [trpo_pendulum] epoch #806 | Time 512.86 s
2022-08-17 18:13:17 | [trpo_pendulum] epoch #806 | EpochTime 0.62 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -626.476
Evaluation/AverageReturn              -1513.86
Evaluation/Iteration                    806
Evaluation/MaxReturn                  -1496.19
Evaluation/MinReturn                  -1543.29
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     15.1276
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.99443
GaussianMLPPolicy/KL                      0.00693617
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              16.3456
GaussianMLPPolicy/LossBefore             17.0064
GaussianMLPPolicy/dLoss                   0.660851
GaussianMLPValueFunction/LossAfter        6.66451
GaussianMLPValueFunction/LossBefore       6.66476
GaussianMLPValueFunction/dLoss            0.000248432
TotalEnvSteps                        968400
-----------------------------------  ----------------
2022-08-17 18:13:17 | [trpo_pendulum] epoch #807 | Saving snapshot...
2022-08-17 18:13:17 | [trpo_pendulum] epoch #807 | Saved
2022-08-17 18:13:17 | [trpo_pendulum] epoch #807 | Time 513.48 s
2022-08-17 18:13:17 | [trpo_pendulum] epoch #807 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -607.093
Evaluation/AverageReturn              -1522.12
Evaluation/Iteration                    807
Evaluation/MaxReturn                  -1513.55
Evaluation/MinReturn                  -1527.16
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      4.33453
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.01427
GaussianMLPPolicy/KL                      0.00844478
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              38.5043
GaussianMLPPolicy/LossBefore             39.1306
GaussianMLPPolicy/dLoss                   0.62635
GaussianMLPValueFunction/LossAfter        6.65673
GaussianMLPValueFunction/LossBefore       6.6724
GaussianMLPValueFunction/dLoss            0.0156674
TotalEnvSteps                        969600
-----------------------------------  ---------------
2022-08-17 18:13:18 | [trpo_pendulum] epoch #808 | Saving snapshot...
2022-08-17 18:13:18 | [trpo_pendulum] epoch #808 | Saved
2022-08-17 18:13:18 | [trpo_pendulum] epoch #808 | Time 514.14 s
2022-08-17 18:13:18 | [trpo_pendulum] epoch #808 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -629.231
Evaluation/AverageReturn              -1522.61
Evaluation/Iteration                    808
Evaluation/MaxReturn                  -1400.57
Evaluation/MinReturn                  -1656.8
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     79.3398
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.99309
GaussianMLPPolicy/KL                      0.00791708
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              14.6114
GaussianMLPPolicy/LossBefore             16.7753
GaussianMLPPolicy/dLoss                   2.1639
GaussianMLPValueFunction/LossAfter        6.6454
GaussianMLPValueFunction/LossBefore       6.64645
GaussianMLPValueFunction/dLoss            0.00104475
TotalEnvSteps                        970800
-----------------------------------  ---------------
2022-08-17 18:13:18 | [trpo_pendulum] epoch #809 | Saving snapshot...
2022-08-17 18:13:18 | [trpo_pendulum] epoch #809 | Saved
2022-08-17 18:13:18 | [trpo_pendulum] epoch #809 | Time 514.77 s
2022-08-17 18:13:18 | [trpo_pendulum] epoch #809 | EpochTime 0.63 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -625.141
Evaluation/AverageReturn              -1531.54
Evaluation/Iteration                    809
Evaluation/MaxReturn                  -1489.59
Evaluation/MinReturn                  -1551.72
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     21.1442
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.99057
GaussianMLPPolicy/KL                      0.00705234
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              18.1111
GaussianMLPPolicy/LossBefore             19.0217
GaussianMLPPolicy/dLoss                   0.910629
GaussianMLPValueFunction/LossAfter        6.66309
GaussianMLPValueFunction/LossBefore       6.66312
GaussianMLPValueFunction/dLoss            3.67165e-05
TotalEnvSteps                        972000
-----------------------------------  ----------------
2022-08-17 18:13:19 | [trpo_pendulum] epoch #810 | Saving snapshot...
2022-08-17 18:13:19 | [trpo_pendulum] epoch #810 | Saved
2022-08-17 18:13:19 | [trpo_pendulum] epoch #810 | Time 515.43 s
2022-08-17 18:13:19 | [trpo_pendulum] epoch #810 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -604.894
Evaluation/AverageReturn              -1514.01
Evaluation/Iteration                    810
Evaluation/MaxReturn                  -1493.12
Evaluation/MinReturn                  -1538.79
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.2494
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.97005
GaussianMLPPolicy/KL                      0.00640627
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              19.3314
GaussianMLPPolicy/LossBefore             20.843
GaussianMLPPolicy/dLoss                   1.51158
GaussianMLPValueFunction/LossAfter        6.64954
GaussianMLPValueFunction/LossBefore       6.65115
GaussianMLPValueFunction/dLoss            0.00160837
TotalEnvSteps                        973200
-----------------------------------  ---------------
2022-08-17 18:13:20 | [trpo_pendulum] epoch #811 | Saving snapshot...
2022-08-17 18:13:20 | [trpo_pendulum] epoch #811 | Saved
2022-08-17 18:13:20 | [trpo_pendulum] epoch #811 | Time 516.08 s
2022-08-17 18:13:20 | [trpo_pendulum] epoch #811 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -616.611
Evaluation/AverageReturn              -1533.13
Evaluation/Iteration                    811
Evaluation/MaxReturn                  -1521.48
Evaluation/MinReturn                  -1539.88
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      6.43121
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.97188
GaussianMLPPolicy/KL                      0.00967101
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              22.4382
GaussianMLPPolicy/LossBefore             22.9616
GaussianMLPPolicy/dLoss                   0.523405
GaussianMLPValueFunction/LossAfter        6.70627
GaussianMLPValueFunction/LossBefore       6.70826
GaussianMLPValueFunction/dLoss            0.00198793
TotalEnvSteps                        974400
-----------------------------------  ---------------
2022-08-17 18:13:20 | [trpo_pendulum] epoch #812 | Saving snapshot...
2022-08-17 18:13:20 | [trpo_pendulum] epoch #812 | Saved
2022-08-17 18:13:20 | [trpo_pendulum] epoch #812 | Time 516.74 s
2022-08-17 18:13:20 | [trpo_pendulum] epoch #812 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -655.393
Evaluation/AverageReturn              -1598.6
Evaluation/Iteration                    812
Evaluation/MaxReturn                  -1585.64
Evaluation/MinReturn                  -1612.21
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.26289
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.99247
GaussianMLPPolicy/KL                      0.00684272
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              36.5193
GaussianMLPPolicy/LossBefore             37.3495
GaussianMLPPolicy/dLoss                   0.830219
GaussianMLPValueFunction/LossAfter        6.70099
GaussianMLPValueFunction/LossBefore       6.70684
GaussianMLPValueFunction/dLoss            0.00584984
TotalEnvSteps                        975600
-----------------------------------  ---------------
2022-08-17 18:13:21 | [trpo_pendulum] epoch #813 | Saving snapshot...
2022-08-17 18:13:21 | [trpo_pendulum] epoch #813 | Saved
2022-08-17 18:13:21 | [trpo_pendulum] epoch #813 | Time 517.35 s
2022-08-17 18:13:21 | [trpo_pendulum] epoch #813 | EpochTime 0.61 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -637.011
Evaluation/AverageReturn              -1550.8
Evaluation/Iteration                    813
Evaluation/MaxReturn                  -1534.32
Evaluation/MinReturn                  -1563.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.74563
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.01335
GaussianMLPPolicy/KL                      0.00973114
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              20.5227
GaussianMLPPolicy/LossBefore             22.2616
GaussianMLPPolicy/dLoss                   1.73891
GaussianMLPValueFunction/LossAfter        6.71424
GaussianMLPValueFunction/LossBefore       6.71468
GaussianMLPValueFunction/dLoss            0.000443459
TotalEnvSteps                        976800
-----------------------------------  ----------------
2022-08-17 18:13:22 | [trpo_pendulum] epoch #814 | Saving snapshot...
2022-08-17 18:13:22 | [trpo_pendulum] epoch #814 | Saved
2022-08-17 18:13:22 | [trpo_pendulum] epoch #814 | Time 517.96 s
2022-08-17 18:13:22 | [trpo_pendulum] epoch #814 | EpochTime 0.61 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -666.452
Evaluation/AverageReturn              -1579.64
Evaluation/Iteration                    814
Evaluation/MaxReturn                  -1525.73
Evaluation/MinReturn                  -1637.02
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     33.0513
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.06361
GaussianMLPPolicy/KL                      0.00634339
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              21.5347
GaussianMLPPolicy/LossBefore             22.4649
GaussianMLPPolicy/dLoss                   0.930267
GaussianMLPValueFunction/LossAfter        6.70089
GaussianMLPValueFunction/LossBefore       6.7009
GaussianMLPValueFunction/dLoss            1.43051e-05
TotalEnvSteps                        978000
-----------------------------------  ----------------
2022-08-17 18:13:22 | [trpo_pendulum] epoch #815 | Saving snapshot...
2022-08-17 18:13:22 | [trpo_pendulum] epoch #815 | Saved
2022-08-17 18:13:22 | [trpo_pendulum] epoch #815 | Time 518.58 s
2022-08-17 18:13:22 | [trpo_pendulum] epoch #815 | EpochTime 0.61 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -621.453
Evaluation/AverageReturn              -1518.2
Evaluation/Iteration                    815
Evaluation/MaxReturn                  -1504.68
Evaluation/MinReturn                  -1540.99
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     11.7169
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.09684
GaussianMLPPolicy/KL                      0.00652132
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              16.3503
GaussianMLPPolicy/LossBefore             17.7092
GaussianMLPPolicy/dLoss                   1.35893
GaussianMLPValueFunction/LossAfter        6.68361
GaussianMLPValueFunction/LossBefore       6.68389
GaussianMLPValueFunction/dLoss            0.000277996
TotalEnvSteps                        979200
-----------------------------------  ----------------
2022-08-17 18:13:23 | [trpo_pendulum] epoch #816 | Saving snapshot...
2022-08-17 18:13:23 | [trpo_pendulum] epoch #816 | Saved
2022-08-17 18:13:23 | [trpo_pendulum] epoch #816 | Time 519.24 s
2022-08-17 18:13:23 | [trpo_pendulum] epoch #816 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -638.902
Evaluation/AverageReturn              -1532.01
Evaluation/Iteration                    816
Evaluation/MaxReturn                  -1509.15
Evaluation/MinReturn                  -1573.82
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     20.7464
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.09481
GaussianMLPPolicy/KL                      0.00586273
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              15.0759
GaussianMLPPolicy/LossBefore             16.9077
GaussianMLPPolicy/dLoss                   1.83185
GaussianMLPValueFunction/LossAfter        6.68326
GaussianMLPValueFunction/LossBefore       6.68339
GaussianMLPValueFunction/dLoss            0.0001297
TotalEnvSteps                        980400
-----------------------------------  ---------------
2022-08-17 18:13:24 | [trpo_pendulum] epoch #817 | Saving snapshot...
2022-08-17 18:13:24 | [trpo_pendulum] epoch #817 | Saved
2022-08-17 18:13:24 | [trpo_pendulum] epoch #817 | Time 519.85 s
2022-08-17 18:13:24 | [trpo_pendulum] epoch #817 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -677.528
Evaluation/AverageReturn              -1634.8
Evaluation/Iteration                    817
Evaluation/MaxReturn                  -1624.92
Evaluation/MinReturn                  -1638.68
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      4.83504
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.10229
GaussianMLPPolicy/KL                      0.00749576
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              34.9672
GaussianMLPPolicy/LossBefore             35.6535
GaussianMLPPolicy/dLoss                   0.686325
GaussianMLPValueFunction/LossAfter        6.7067
GaussianMLPValueFunction/LossBefore       6.71063
GaussianMLPValueFunction/dLoss            0.00392056
TotalEnvSteps                        981600
-----------------------------------  ---------------
2022-08-17 18:13:24 | [trpo_pendulum] epoch #818 | Saving snapshot...
2022-08-17 18:13:24 | [trpo_pendulum] epoch #818 | Saved
2022-08-17 18:13:24 | [trpo_pendulum] epoch #818 | Time 520.48 s
2022-08-17 18:13:24 | [trpo_pendulum] epoch #818 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -604.443
Evaluation/AverageReturn              -1471.36
Evaluation/Iteration                    818
Evaluation/MaxReturn                  -1374.48
Evaluation/MinReturn                  -1510.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     45.3696
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.08082
GaussianMLPPolicy/KL                      0.00973186
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               6.80682
GaussianMLPPolicy/LossBefore              8.34302
GaussianMLPPolicy/dLoss                   1.53619
GaussianMLPValueFunction/LossAfter        6.61531
GaussianMLPValueFunction/LossBefore       6.62045
GaussianMLPValueFunction/dLoss            0.00513649
TotalEnvSteps                        982800
-----------------------------------  ---------------
2022-08-17 18:13:25 | [trpo_pendulum] epoch #819 | Saving snapshot...
2022-08-17 18:13:25 | [trpo_pendulum] epoch #819 | Saved
2022-08-17 18:13:25 | [trpo_pendulum] epoch #819 | Time 521.12 s
2022-08-17 18:13:25 | [trpo_pendulum] epoch #819 | EpochTime 0.63 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -634.672
Evaluation/AverageReturn              -1510.8
Evaluation/Iteration                    819
Evaluation/MaxReturn                  -1489.52
Evaluation/MinReturn                  -1527
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     11.9178
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.0759
GaussianMLPPolicy/KL                      0.00429926
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              12.846
GaussianMLPPolicy/LossBefore             13.05
GaussianMLPPolicy/dLoss                   0.204023
GaussianMLPValueFunction/LossAfter        6.66704
GaussianMLPValueFunction/LossBefore       6.66745
GaussianMLPValueFunction/dLoss            0.000405788
TotalEnvSteps                        984000
-----------------------------------  ----------------
2022-08-17 18:13:25 | [trpo_pendulum] epoch #820 | Saving snapshot...
2022-08-17 18:13:25 | [trpo_pendulum] epoch #820 | Saved
2022-08-17 18:13:25 | [trpo_pendulum] epoch #820 | Time 521.74 s
2022-08-17 18:13:25 | [trpo_pendulum] epoch #820 | EpochTime 0.61 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -643.636
Evaluation/AverageReturn              -1519.13
Evaluation/Iteration                    820
Evaluation/MaxReturn                  -1509.22
Evaluation/MinReturn                  -1532.12
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      7.96832
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.13922
GaussianMLPPolicy/KL                      0.0072915
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              12.6375
GaussianMLPPolicy/LossBefore             13.869
GaussianMLPPolicy/dLoss                   1.2315
GaussianMLPValueFunction/LossAfter        6.68068
GaussianMLPValueFunction/LossBefore       6.68121
GaussianMLPValueFunction/dLoss            0.000529766
TotalEnvSteps                        985200
-----------------------------------  ----------------
2022-08-17 18:13:26 | [trpo_pendulum] epoch #821 | Saving snapshot...
2022-08-17 18:13:26 | [trpo_pendulum] epoch #821 | Saved
2022-08-17 18:13:26 | [trpo_pendulum] epoch #821 | Time 522.36 s
2022-08-17 18:13:26 | [trpo_pendulum] epoch #821 | EpochTime 0.62 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -629.742
Evaluation/AverageReturn              -1510.15
Evaluation/Iteration                    821
Evaluation/MaxReturn                  -1497.81
Evaluation/MinReturn                  -1528.47
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.101
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.16176
GaussianMLPPolicy/KL                      0.00552869
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              13.4492
GaussianMLPPolicy/LossBefore             14.6245
GaussianMLPPolicy/dLoss                   1.17525
GaussianMLPValueFunction/LossAfter        6.66612
GaussianMLPValueFunction/LossBefore       6.66633
GaussianMLPValueFunction/dLoss            0.000217438
TotalEnvSteps                        986400
-----------------------------------  ----------------
2022-08-17 18:13:27 | [trpo_pendulum] epoch #822 | Saving snapshot...
2022-08-17 18:13:27 | [trpo_pendulum] epoch #822 | Saved
2022-08-17 18:13:27 | [trpo_pendulum] epoch #822 | Time 523.00 s
2022-08-17 18:13:27 | [trpo_pendulum] epoch #822 | EpochTime 0.64 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -627.03
Evaluation/AverageReturn              -1506.41
Evaluation/Iteration                    822
Evaluation/MaxReturn                  -1491.93
Evaluation/MinReturn                  -1519.53
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.9355
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.16301
GaussianMLPPolicy/KL                      0.00558153
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              13.9112
GaussianMLPPolicy/LossBefore             14.7996
GaussianMLPPolicy/dLoss                   0.888394
GaussianMLPValueFunction/LossAfter        6.66253
GaussianMLPValueFunction/LossBefore       6.66275
GaussianMLPValueFunction/dLoss            0.000223637
TotalEnvSteps                        987600
-----------------------------------  ----------------
2022-08-17 18:13:27 | [trpo_pendulum] epoch #823 | Saving snapshot...
2022-08-17 18:13:27 | [trpo_pendulum] epoch #823 | Saved
2022-08-17 18:13:27 | [trpo_pendulum] epoch #823 | Time 523.63 s
2022-08-17 18:13:27 | [trpo_pendulum] epoch #823 | EpochTime 0.62 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -677.149
Evaluation/AverageReturn              -1573.6
Evaluation/Iteration                    823
Evaluation/MaxReturn                  -1459.24
Evaluation/MinReturn                  -1677.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     67.774
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.13854
GaussianMLPPolicy/KL                      0.00735567
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              18.4202
GaussianMLPPolicy/LossBefore             19.8311
GaussianMLPPolicy/dLoss                   1.4109
GaussianMLPValueFunction/LossAfter        6.70017
GaussianMLPValueFunction/LossBefore       6.70105
GaussianMLPValueFunction/dLoss            0.000881195
TotalEnvSteps                        988800
-----------------------------------  ----------------
2022-08-17 18:13:28 | [trpo_pendulum] epoch #824 | Saving snapshot...
2022-08-17 18:13:28 | [trpo_pendulum] epoch #824 | Saved
2022-08-17 18:13:28 | [trpo_pendulum] epoch #824 | Time 524.28 s
2022-08-17 18:13:28 | [trpo_pendulum] epoch #824 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -615.711
Evaluation/AverageReturn              -1524.81
Evaluation/Iteration                    824
Evaluation/MaxReturn                  -1502.22
Evaluation/MinReturn                  -1548.43
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     17.0243
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.15027
GaussianMLPPolicy/KL                      0.00718229
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              17.7599
GaussianMLPPolicy/LossBefore             19.1771
GaussianMLPPolicy/dLoss                   1.41717
GaussianMLPValueFunction/LossAfter        6.62436
GaussianMLPValueFunction/LossBefore       6.64991
GaussianMLPValueFunction/dLoss            0.0255537
TotalEnvSteps                        990000
-----------------------------------  ---------------
2022-08-17 18:13:29 | [trpo_pendulum] epoch #825 | Saving snapshot...
2022-08-17 18:13:29 | [trpo_pendulum] epoch #825 | Saved
2022-08-17 18:13:29 | [trpo_pendulum] epoch #825 | Time 524.90 s
2022-08-17 18:13:29 | [trpo_pendulum] epoch #825 | EpochTime 0.61 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -696.517
Evaluation/AverageReturn              -1585.38
Evaluation/Iteration                    825
Evaluation/MaxReturn                  -1552.66
Evaluation/MinReturn                  -1625.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     24.6313
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.13903
GaussianMLPPolicy/KL                      0.00653392
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              17.0462
GaussianMLPPolicy/LossBefore             18.4187
GaussianMLPPolicy/dLoss                   1.37254
GaussianMLPValueFunction/LossAfter        6.68476
GaussianMLPValueFunction/LossBefore       6.68527
GaussianMLPValueFunction/dLoss            0.000502586
TotalEnvSteps                        991200
-----------------------------------  ----------------
2022-08-17 18:13:29 | [trpo_pendulum] epoch #826 | Saving snapshot...
2022-08-17 18:13:29 | [trpo_pendulum] epoch #826 | Saved
2022-08-17 18:13:29 | [trpo_pendulum] epoch #826 | Time 525.53 s
2022-08-17 18:13:29 | [trpo_pendulum] epoch #826 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -502.706
Evaluation/AverageReturn              -1188.7
Evaluation/Iteration                    826
Evaluation/MaxReturn                  -1035.68
Evaluation/MinReturn                  -1515.87
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    161.06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.14694
GaussianMLPPolicy/KL                      0.00705399
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter             -33.1815
GaussianMLPPolicy/LossBefore            -30.5921
GaussianMLPPolicy/dLoss                   2.58939
GaussianMLPValueFunction/LossAfter        6.69175
GaussianMLPValueFunction/LossBefore       6.70269
GaussianMLPValueFunction/dLoss            0.0109406
TotalEnvSteps                        992400
-----------------------------------  ---------------
2022-08-17 18:13:30 | [trpo_pendulum] epoch #827 | Saving snapshot...
2022-08-17 18:13:30 | [trpo_pendulum] epoch #827 | Saved
2022-08-17 18:13:30 | [trpo_pendulum] epoch #827 | Time 526.17 s
2022-08-17 18:13:30 | [trpo_pendulum] epoch #827 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -597.258
Evaluation/AverageReturn              -1435.31
Evaluation/Iteration                    827
Evaluation/MaxReturn                  -1108.24
Evaluation/MinReturn                  -1599.86
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    173.186
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.15769
GaussianMLPPolicy/KL                      0.0086288
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               2.96497
GaussianMLPPolicy/LossBefore              5.59544
GaussianMLPPolicy/dLoss                   2.63047
GaussianMLPValueFunction/LossAfter        6.5871
GaussianMLPValueFunction/LossBefore       6.60992
GaussianMLPValueFunction/dLoss            0.0228195
TotalEnvSteps                        993600
-----------------------------------  --------------
2022-08-17 18:13:31 | [trpo_pendulum] epoch #828 | Saving snapshot...
2022-08-17 18:13:31 | [trpo_pendulum] epoch #828 | Saved
2022-08-17 18:13:31 | [trpo_pendulum] epoch #828 | Time 526.81 s
2022-08-17 18:13:31 | [trpo_pendulum] epoch #828 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -694.763
Evaluation/AverageReturn              -1600.21
Evaluation/Iteration                    828
Evaluation/MaxReturn                  -1548.47
Evaluation/MinReturn                  -1637.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     38.579
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.15155
GaussianMLPPolicy/KL                      0.006639
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              22.7873
GaussianMLPPolicy/LossBefore             24.3564
GaussianMLPPolicy/dLoss                   1.5691
GaussianMLPValueFunction/LossAfter        6.72187
GaussianMLPValueFunction/LossBefore       6.72619
GaussianMLPValueFunction/dLoss            0.00431681
TotalEnvSteps                        994800
-----------------------------------  ---------------
2022-08-17 18:13:31 | [trpo_pendulum] epoch #829 | Saving snapshot...
2022-08-17 18:13:31 | [trpo_pendulum] epoch #829 | Saved
2022-08-17 18:13:31 | [trpo_pendulum] epoch #829 | Time 527.44 s
2022-08-17 18:13:31 | [trpo_pendulum] epoch #829 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -660.841
Evaluation/AverageReturn              -1586.31
Evaluation/Iteration                    829
Evaluation/MaxReturn                  -1408.92
Evaluation/MinReturn                  -1732.97
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    127.89
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.17564
GaussianMLPPolicy/KL                      0.00964128
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              29.3778
GaussianMLPPolicy/LossBefore             32.5448
GaussianMLPPolicy/dLoss                   3.167
GaussianMLPValueFunction/LossAfter        6.66874
GaussianMLPValueFunction/LossBefore       6.67083
GaussianMLPValueFunction/dLoss            0.00208759
TotalEnvSteps                        996000
-----------------------------------  ---------------
2022-08-17 18:13:32 | [trpo_pendulum] epoch #830 | Saving snapshot...
2022-08-17 18:13:32 | [trpo_pendulum] epoch #830 | Saved
2022-08-17 18:13:32 | [trpo_pendulum] epoch #830 | Time 528.09 s
2022-08-17 18:13:32 | [trpo_pendulum] epoch #830 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -684.871
Evaluation/AverageReturn              -1636.4
Evaluation/Iteration                    830
Evaluation/MaxReturn                  -1629.72
Evaluation/MinReturn                  -1645.25
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      5.46356
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.18946
GaussianMLPPolicy/KL                      0.00620981
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              75.9157
GaussianMLPPolicy/LossBefore             76.2377
GaussianMLPPolicy/dLoss                   0.322037
GaussianMLPValueFunction/LossAfter        6.70729
GaussianMLPValueFunction/LossBefore       6.91433
GaussianMLPValueFunction/dLoss            0.207037
TotalEnvSteps                        997200
-----------------------------------  ---------------
2022-08-17 18:13:32 | [trpo_pendulum] epoch #831 | Saving snapshot...
2022-08-17 18:13:32 | [trpo_pendulum] epoch #831 | Saved
2022-08-17 18:13:32 | [trpo_pendulum] epoch #831 | Time 528.72 s
2022-08-17 18:13:32 | [trpo_pendulum] epoch #831 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -723.726
Evaluation/AverageReturn              -1686.87
Evaluation/Iteration                    831
Evaluation/MaxReturn                  -1618.04
Evaluation/MinReturn                  -1746.03
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     53.6596
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.19559
GaussianMLPPolicy/KL                      0.00712476
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              34.4808
GaussianMLPPolicy/LossBefore             36.888
GaussianMLPPolicy/dLoss                   2.40713
GaussianMLPValueFunction/LossAfter        6.79499
GaussianMLPValueFunction/LossBefore       6.80359
GaussianMLPValueFunction/dLoss            0.00860262
TotalEnvSteps                        998400
-----------------------------------  ---------------
2022-08-17 18:13:33 | [trpo_pendulum] epoch #832 | Saving snapshot...
2022-08-17 18:13:33 | [trpo_pendulum] epoch #832 | Saved
2022-08-17 18:13:33 | [trpo_pendulum] epoch #832 | Time 529.34 s
2022-08-17 18:13:33 | [trpo_pendulum] epoch #832 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -550.067
Evaluation/AverageReturn              -1354.24
Evaluation/Iteration                    832
Evaluation/MaxReturn                  -1320.07
Evaluation/MinReturn                  -1393.31
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     22.1041
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 2.15463
GaussianMLPPolicy/KL                      0.0067117
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -5.61669
GaussianMLPPolicy/LossBefore             -5.34271
GaussianMLPPolicy/dLoss                   0.273982
GaussianMLPValueFunction/LossAfter        6.59987
GaussianMLPValueFunction/LossBefore       6.61267
GaussianMLPValueFunction/dLoss            0.0127983
TotalEnvSteps                        999600
-----------------------------------  --------------
2022-08-17 18:13:34 | [trpo_pendulum] epoch #833 | Saving snapshot...
2022-08-17 18:13:34 | [trpo_pendulum] epoch #833 | Saved
2022-08-17 18:13:34 | [trpo_pendulum] epoch #833 | Time 529.99 s
2022-08-17 18:13:34 | [trpo_pendulum] epoch #833 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -584.198
Evaluation/AverageReturn             -1453.36
Evaluation/Iteration                   833
Evaluation/MaxReturn                 -1345.08
Evaluation/MinReturn                 -1536.29
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    72.9132
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.16125
GaussianMLPPolicy/KL                     0.00654155
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              8.11067
GaussianMLPPolicy/LossBefore             8.71834
GaussianMLPPolicy/dLoss                  0.607668
GaussianMLPValueFunction/LossAfter       6.53768
GaussianMLPValueFunction/LossBefore      6.577
GaussianMLPValueFunction/dLoss           0.0393167
TotalEnvSteps                            1.0008e+06
-----------------------------------  --------------
2022-08-17 18:13:34 | [trpo_pendulum] epoch #834 | Saving snapshot...
2022-08-17 18:13:34 | [trpo_pendulum] epoch #834 | Saved
2022-08-17 18:13:34 | [trpo_pendulum] epoch #834 | Time 530.63 s
2022-08-17 18:13:34 | [trpo_pendulum] epoch #834 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -662.62
Evaluation/AverageReturn             -1531.23
Evaluation/Iteration                   834
Evaluation/MaxReturn                 -1524.12
Evaluation/MinReturn                 -1549.3
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     8.49619
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.15639
GaussianMLPPolicy/KL                     0.00666665
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             12.0322
GaussianMLPPolicy/LossBefore            13.1215
GaussianMLPPolicy/dLoss                  1.08928
GaussianMLPValueFunction/LossAfter       6.64184
GaussianMLPValueFunction/LossBefore      6.6421
GaussianMLPValueFunction/dLoss           0.000254631
TotalEnvSteps                            1.002e+06
-----------------------------------  ---------------
2022-08-17 18:13:35 | [trpo_pendulum] epoch #835 | Saving snapshot...
2022-08-17 18:13:35 | [trpo_pendulum] epoch #835 | Saved
2022-08-17 18:13:35 | [trpo_pendulum] epoch #835 | Time 531.27 s
2022-08-17 18:13:35 | [trpo_pendulum] epoch #835 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -659.496
Evaluation/AverageReturn             -1530.37
Evaluation/Iteration                   835
Evaluation/MaxReturn                 -1521.56
Evaluation/MinReturn                 -1546.1
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     8.34026
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.18444
GaussianMLPPolicy/KL                     0.00634022
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             12.4257
GaussianMLPPolicy/LossBefore            13.9218
GaussianMLPPolicy/dLoss                  1.4961
GaussianMLPValueFunction/LossAfter       6.6426
GaussianMLPValueFunction/LossBefore      6.64284
GaussianMLPValueFunction/dLoss           0.000240803
TotalEnvSteps                            1.0032e+06
-----------------------------------  ---------------
2022-08-17 18:13:36 | [trpo_pendulum] epoch #836 | Saving snapshot...
2022-08-17 18:13:36 | [trpo_pendulum] epoch #836 | Saved
2022-08-17 18:13:36 | [trpo_pendulum] epoch #836 | Time 531.91 s
2022-08-17 18:13:36 | [trpo_pendulum] epoch #836 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -728.013
Evaluation/AverageReturn             -1686.89
Evaluation/Iteration                   836
Evaluation/MaxReturn                 -1659.73
Evaluation/MinReturn                 -1718.21
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    17.4236
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.17396
GaussianMLPPolicy/KL                     0.00740494
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             33.782
GaussianMLPPolicy/LossBefore            35.63
GaussianMLPPolicy/dLoss                  1.84797
GaussianMLPValueFunction/LossAfter       6.7508
GaussianMLPValueFunction/LossBefore      6.76016
GaussianMLPValueFunction/dLoss           0.00935411
TotalEnvSteps                            1.0044e+06
-----------------------------------  --------------
2022-08-17 18:13:36 | [trpo_pendulum] epoch #837 | Saving snapshot...
2022-08-17 18:13:36 | [trpo_pendulum] epoch #837 | Saved
2022-08-17 18:13:36 | [trpo_pendulum] epoch #837 | Time 532.55 s
2022-08-17 18:13:36 | [trpo_pendulum] epoch #837 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -650.229
Evaluation/AverageReturn             -1569.57
Evaluation/Iteration                   837
Evaluation/MaxReturn                 -1537.12
Evaluation/MinReturn                 -1588.41
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    16.9961
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.16194
GaussianMLPPolicy/KL                     0.00507218
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             45.3018
GaussianMLPPolicy/LossBefore            46.0345
GaussianMLPPolicy/dLoss                  0.732658
GaussianMLPValueFunction/LossAfter       6.69572
GaussianMLPValueFunction/LossBefore      6.72546
GaussianMLPValueFunction/dLoss           0.0297437
TotalEnvSteps                            1.0056e+06
-----------------------------------  --------------
2022-08-17 18:13:37 | [trpo_pendulum] epoch #838 | Saving snapshot...
2022-08-17 18:13:37 | [trpo_pendulum] epoch #838 | Saved
2022-08-17 18:13:37 | [trpo_pendulum] epoch #838 | Time 533.20 s
2022-08-17 18:13:37 | [trpo_pendulum] epoch #838 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -635.87
Evaluation/AverageReturn             -1544.19
Evaluation/Iteration                   838
Evaluation/MaxReturn                 -1356.59
Evaluation/MinReturn                 -1732.6
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   150.544
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.17483
GaussianMLPPolicy/KL                     0.00745485
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             17.227
GaussianMLPPolicy/LossBefore            19.5747
GaussianMLPPolicy/dLoss                  2.34775
GaussianMLPValueFunction/LossAfter       6.66814
GaussianMLPValueFunction/LossBefore      6.67183
GaussianMLPValueFunction/dLoss           0.00369644
TotalEnvSteps                            1.0068e+06
-----------------------------------  --------------
2022-08-17 18:13:38 | [trpo_pendulum] epoch #839 | Saving snapshot...
2022-08-17 18:13:38 | [trpo_pendulum] epoch #839 | Saved
2022-08-17 18:13:38 | [trpo_pendulum] epoch #839 | Time 533.86 s
2022-08-17 18:13:38 | [trpo_pendulum] epoch #839 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -657.935
Evaluation/AverageReturn             -1516.41
Evaluation/Iteration                   839
Evaluation/MaxReturn                 -1511.09
Evaluation/MinReturn                 -1528.43
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     5.5742
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.17065
GaussianMLPPolicy/KL                     0.00776915
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              9.03138
GaussianMLPPolicy/LossBefore             9.98708
GaussianMLPPolicy/dLoss                  0.955692
GaussianMLPValueFunction/LossAfter       6.63222
GaussianMLPValueFunction/LossBefore      6.63428
GaussianMLPValueFunction/dLoss           0.00206852
TotalEnvSteps                            1.008e+06
-----------------------------------  --------------
2022-08-17 18:13:38 | [trpo_pendulum] epoch #840 | Saving snapshot...
2022-08-17 18:13:38 | [trpo_pendulum] epoch #840 | Saved
2022-08-17 18:13:38 | [trpo_pendulum] epoch #840 | Time 534.48 s
2022-08-17 18:13:38 | [trpo_pendulum] epoch #840 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -700.83
Evaluation/AverageReturn             -1593.52
Evaluation/Iteration                   840
Evaluation/MaxReturn                 -1555.86
Evaluation/MinReturn                 -1640.88
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    27.2084
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.18747
GaussianMLPPolicy/KL                     0.00901188
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             18.444
GaussianMLPPolicy/LossBefore            21.1064
GaussianMLPPolicy/dLoss                  2.6624
GaussianMLPValueFunction/LossAfter       6.70499
GaussianMLPValueFunction/LossBefore      6.70622
GaussianMLPValueFunction/dLoss           0.00123215
TotalEnvSteps                            1.0092e+06
-----------------------------------  --------------
2022-08-17 18:13:39 | [trpo_pendulum] epoch #841 | Saving snapshot...
2022-08-17 18:13:39 | [trpo_pendulum] epoch #841 | Saved
2022-08-17 18:13:39 | [trpo_pendulum] epoch #841 | Time 535.23 s
2022-08-17 18:13:39 | [trpo_pendulum] epoch #841 | EpochTime 0.74 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -628.244
Evaluation/AverageReturn             -1533.84
Evaluation/Iteration                   841
Evaluation/MaxReturn                 -1505.04
Evaluation/MinReturn                 -1556.05
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    20.4284
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.16979
GaussianMLPPolicy/KL                     0.00665494
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             35.3365
GaussianMLPPolicy/LossBefore            35.9311
GaussianMLPPolicy/dLoss                  0.59462
GaussianMLPValueFunction/LossAfter       6.69061
GaussianMLPValueFunction/LossBefore      6.70093
GaussianMLPValueFunction/dLoss           0.0103135
TotalEnvSteps                            1.0104e+06
-----------------------------------  --------------
2022-08-17 18:13:40 | [trpo_pendulum] epoch #842 | Saving snapshot...
2022-08-17 18:13:40 | [trpo_pendulum] epoch #842 | Saved
2022-08-17 18:13:40 | [trpo_pendulum] epoch #842 | Time 535.85 s
2022-08-17 18:13:40 | [trpo_pendulum] epoch #842 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -663.718
Evaluation/AverageReturn             -1565.01
Evaluation/Iteration                   842
Evaluation/MaxReturn                 -1530.85
Evaluation/MinReturn                 -1605.69
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    23.6471
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.18812
GaussianMLPPolicy/KL                     0.00639399
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             26.0133
GaussianMLPPolicy/LossBefore            26.1372
GaussianMLPPolicy/dLoss                  0.123987
GaussianMLPValueFunction/LossAfter       6.6912
GaussianMLPValueFunction/LossBefore      6.6919
GaussianMLPValueFunction/dLoss           0.000696659
TotalEnvSteps                            1.0116e+06
-----------------------------------  ---------------
2022-08-17 18:13:40 | [trpo_pendulum] epoch #843 | Saving snapshot...
2022-08-17 18:13:40 | [trpo_pendulum] epoch #843 | Saved
2022-08-17 18:13:40 | [trpo_pendulum] epoch #843 | Time 536.49 s
2022-08-17 18:13:40 | [trpo_pendulum] epoch #843 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -551.56
Evaluation/AverageReturn             -1410.85
Evaluation/Iteration                   843
Evaluation/MaxReturn                 -1327.66
Evaluation/MinReturn                 -1458.23
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    50.469
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.15642
GaussianMLPPolicy/KL                     0.00630355
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              4.73652
GaussianMLPPolicy/LossBefore             5.93679
GaussianMLPPolicy/dLoss                  1.20028
GaussianMLPValueFunction/LossAfter       6.49684
GaussianMLPValueFunction/LossBefore      6.55343
GaussianMLPValueFunction/dLoss           0.0565906
TotalEnvSteps                            1.0128e+06
-----------------------------------  --------------
2022-08-17 18:13:41 | [trpo_pendulum] epoch #844 | Saving snapshot...
2022-08-17 18:13:41 | [trpo_pendulum] epoch #844 | Saved
2022-08-17 18:13:41 | [trpo_pendulum] epoch #844 | Time 537.13 s
2022-08-17 18:13:41 | [trpo_pendulum] epoch #844 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -661.716
Evaluation/AverageReturn             -1566.5
Evaluation/Iteration                   844
Evaluation/MaxReturn                 -1533.97
Evaluation/MinReturn                 -1595.82
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    21.9887
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.16275
GaussianMLPPolicy/KL                     0.00184083
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             48.2031
GaussianMLPPolicy/LossBefore            48.3942
GaussianMLPPolicy/dLoss                  0.191158
GaussianMLPValueFunction/LossAfter       6.69533
GaussianMLPValueFunction/LossBefore      6.7571
GaussianMLPValueFunction/dLoss           0.0617743
TotalEnvSteps                            1.014e+06
-----------------------------------  --------------
2022-08-17 18:13:41 | [trpo_pendulum] epoch #845 | Saving snapshot...
2022-08-17 18:13:41 | [trpo_pendulum] epoch #845 | Saved
2022-08-17 18:13:41 | [trpo_pendulum] epoch #845 | Time 537.75 s
2022-08-17 18:13:41 | [trpo_pendulum] epoch #845 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -526.658
Evaluation/AverageReturn             -1368.75
Evaluation/Iteration                   845
Evaluation/MaxReturn                 -1354.84
Evaluation/MinReturn                 -1378.63
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     8.73442
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.14853
GaussianMLPPolicy/KL                     0.00397703
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              0.690313
GaussianMLPPolicy/LossBefore             0.771862
GaussianMLPPolicy/dLoss                  0.0815489
GaussianMLPValueFunction/LossAfter       6.58075
GaussianMLPValueFunction/LossBefore      6.58469
GaussianMLPValueFunction/dLoss           0.00394249
TotalEnvSteps                            1.0152e+06
-----------------------------------  --------------
2022-08-17 18:13:42 | [trpo_pendulum] epoch #846 | Saving snapshot...
2022-08-17 18:13:42 | [trpo_pendulum] epoch #846 | Saved
2022-08-17 18:13:42 | [trpo_pendulum] epoch #846 | Time 538.38 s
2022-08-17 18:13:42 | [trpo_pendulum] epoch #846 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -734.446
Evaluation/AverageReturn             -1664.15
Evaluation/Iteration                   846
Evaluation/MaxReturn                 -1549.04
Evaluation/MinReturn                 -1746.61
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    71.8016
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.15167
GaussianMLPPolicy/KL                     0.0068944
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             27.3824
GaussianMLPPolicy/LossBefore            29.5059
GaussianMLPPolicy/dLoss                  2.12353
GaussianMLPValueFunction/LossAfter       6.7705
GaussianMLPValueFunction/LossBefore      6.78456
GaussianMLPValueFunction/dLoss           0.0140576
TotalEnvSteps                            1.0164e+06
-----------------------------------  --------------
2022-08-17 18:13:43 | [trpo_pendulum] epoch #847 | Saving snapshot...
2022-08-17 18:13:43 | [trpo_pendulum] epoch #847 | Saved
2022-08-17 18:13:43 | [trpo_pendulum] epoch #847 | Time 539.00 s
2022-08-17 18:13:43 | [trpo_pendulum] epoch #847 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -576.347
Evaluation/AverageReturn             -1443.55
Evaluation/Iteration                   847
Evaluation/MaxReturn                 -1273.34
Evaluation/MinReturn                 -1525.21
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    88.8106
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.15123
GaussianMLPPolicy/KL                     0.00654185
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              8.80788
GaussianMLPPolicy/LossBefore             9.46712
GaussianMLPPolicy/dLoss                  0.659245
GaussianMLPValueFunction/LossAfter       6.54591
GaussianMLPValueFunction/LossBefore      6.59018
GaussianMLPValueFunction/dLoss           0.0442653
TotalEnvSteps                            1.0176e+06
-----------------------------------  --------------
2022-08-17 18:13:43 | [trpo_pendulum] epoch #848 | Saving snapshot...
2022-08-17 18:13:43 | [trpo_pendulum] epoch #848 | Saved
2022-08-17 18:13:43 | [trpo_pendulum] epoch #848 | Time 539.65 s
2022-08-17 18:13:43 | [trpo_pendulum] epoch #848 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -542.725
Evaluation/AverageReturn             -1407.16
Evaluation/Iteration                   848
Evaluation/MaxReturn                 -1370.22
Evaluation/MinReturn                 -1517.62
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    50.7009
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.17723
GaussianMLPPolicy/KL                     0.00689384
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             10.8329
GaussianMLPPolicy/LossBefore            12.0138
GaussianMLPPolicy/dLoss                  1.18089
GaussianMLPValueFunction/LossAfter       6.63952
GaussianMLPValueFunction/LossBefore      6.64574
GaussianMLPValueFunction/dLoss           0.00621891
TotalEnvSteps                            1.0188e+06
-----------------------------------  --------------
2022-08-17 18:13:44 | [trpo_pendulum] epoch #849 | Saving snapshot...
2022-08-17 18:13:44 | [trpo_pendulum] epoch #849 | Saved
2022-08-17 18:13:44 | [trpo_pendulum] epoch #849 | Time 540.28 s
2022-08-17 18:13:44 | [trpo_pendulum] epoch #849 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -703.63
Evaluation/AverageReturn             -1607.93
Evaluation/Iteration                   849
Evaluation/MaxReturn                 -1569.47
Evaluation/MinReturn                 -1678.14
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    35.7901
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.14563
GaussianMLPPolicy/KL                     0.00749835
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             20.6274
GaussianMLPPolicy/LossBefore            22.1323
GaussianMLPPolicy/dLoss                  1.50488
GaussianMLPValueFunction/LossAfter       6.70314
GaussianMLPValueFunction/LossBefore      6.70584
GaussianMLPValueFunction/dLoss           0.00269318
TotalEnvSteps                            1.02e+06
-----------------------------------  --------------
2022-08-17 18:13:45 | [trpo_pendulum] epoch #850 | Saving snapshot...
2022-08-17 18:13:45 | [trpo_pendulum] epoch #850 | Saved
2022-08-17 18:13:45 | [trpo_pendulum] epoch #850 | Time 540.90 s
2022-08-17 18:13:45 | [trpo_pendulum] epoch #850 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -603.877
Evaluation/AverageReturn             -1504.88
Evaluation/Iteration                   850
Evaluation/MaxReturn                 -1353.51
Evaluation/MinReturn                 -1572.48
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    70.9968
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.16075
GaussianMLPPolicy/KL                     0.00610563
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             25.2694
GaussianMLPPolicy/LossBefore            26.4439
GaussianMLPPolicy/dLoss                  1.17452
GaussianMLPValueFunction/LossAfter       6.68127
GaussianMLPValueFunction/LossBefore      6.68508
GaussianMLPValueFunction/dLoss           0.00380611
TotalEnvSteps                            1.0212e+06
-----------------------------------  --------------
2022-08-17 18:13:45 | [trpo_pendulum] epoch #851 | Saving snapshot...
2022-08-17 18:13:45 | [trpo_pendulum] epoch #851 | Saved
2022-08-17 18:13:45 | [trpo_pendulum] epoch #851 | Time 541.51 s
2022-08-17 18:13:45 | [trpo_pendulum] epoch #851 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -677.434
Evaluation/AverageReturn             -1596.83
Evaluation/Iteration                   851
Evaluation/MaxReturn                 -1558.24
Evaluation/MinReturn                 -1622.29
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    25.0963
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.16559
GaussianMLPPolicy/KL                     0.00641634
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             21.596
GaussianMLPPolicy/LossBefore            23.6109
GaussianMLPPolicy/dLoss                  2.0149
GaussianMLPValueFunction/LossAfter       6.69687
GaussianMLPValueFunction/LossBefore      6.69742
GaussianMLPValueFunction/dLoss           0.000551701
TotalEnvSteps                            1.0224e+06
-----------------------------------  ---------------
2022-08-17 18:13:46 | [trpo_pendulum] epoch #852 | Saving snapshot...
2022-08-17 18:13:46 | [trpo_pendulum] epoch #852 | Saved
2022-08-17 18:13:46 | [trpo_pendulum] epoch #852 | Time 542.13 s
2022-08-17 18:13:46 | [trpo_pendulum] epoch #852 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -698.864
Evaluation/AverageReturn             -1605.52
Evaluation/Iteration                   852
Evaluation/MaxReturn                 -1529.94
Evaluation/MinReturn                 -1662.49
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    47.4218
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.18349
GaussianMLPPolicy/KL                     0.00911305
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             19.6494
GaussianMLPPolicy/LossBefore            22.1192
GaussianMLPPolicy/dLoss                  2.46979
GaussianMLPValueFunction/LossAfter       6.71216
GaussianMLPValueFunction/LossBefore      6.71283
GaussianMLPValueFunction/dLoss           0.000671864
TotalEnvSteps                            1.0236e+06
-----------------------------------  ---------------
2022-08-17 18:13:46 | [trpo_pendulum] epoch #853 | Saving snapshot...
2022-08-17 18:13:46 | [trpo_pendulum] epoch #853 | Saved
2022-08-17 18:13:46 | [trpo_pendulum] epoch #853 | Time 542.75 s
2022-08-17 18:13:46 | [trpo_pendulum] epoch #853 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -464.681
Evaluation/AverageReturn             -1232.99
Evaluation/Iteration                   853
Evaluation/MaxReturn                 -1015.93
Evaluation/MinReturn                 -1382.4
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   109.812
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.18802
GaussianMLPPolicy/KL                     0.0096403
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            -19.3293
GaussianMLPPolicy/LossBefore           -18.2757
GaussianMLPPolicy/dLoss                  1.05366
GaussianMLPValueFunction/LossAfter       6.57467
GaussianMLPValueFunction/LossBefore      6.58805
GaussianMLPValueFunction/dLoss           0.0133829
TotalEnvSteps                            1.0248e+06
-----------------------------------  --------------
2022-08-17 18:13:47 | [trpo_pendulum] epoch #854 | Saving snapshot...
2022-08-17 18:13:47 | [trpo_pendulum] epoch #854 | Saved
2022-08-17 18:13:47 | [trpo_pendulum] epoch #854 | Time 543.38 s
2022-08-17 18:13:47 | [trpo_pendulum] epoch #854 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -692.756
Evaluation/AverageReturn             -1600.53
Evaluation/Iteration                   854
Evaluation/MaxReturn                 -1525.21
Evaluation/MinReturn                 -1716.41
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    61.6369
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.17959
GaussianMLPPolicy/KL                     0.00672356
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             21.3471
GaussianMLPPolicy/LossBefore            23.1614
GaussianMLPPolicy/dLoss                  1.8143
GaussianMLPValueFunction/LossAfter       6.70492
GaussianMLPValueFunction/LossBefore      6.70683
GaussianMLPValueFunction/dLoss           0.00190687
TotalEnvSteps                            1.026e+06
-----------------------------------  --------------
2022-08-17 18:13:48 | [trpo_pendulum] epoch #855 | Saving snapshot...
2022-08-17 18:13:48 | [trpo_pendulum] epoch #855 | Saved
2022-08-17 18:13:48 | [trpo_pendulum] epoch #855 | Time 544.03 s
2022-08-17 18:13:48 | [trpo_pendulum] epoch #855 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -634.332
Evaluation/AverageReturn             -1528.93
Evaluation/Iteration                   855
Evaluation/MaxReturn                 -1498
Evaluation/MinReturn                 -1564.38
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    22.2073
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.19444
GaussianMLPPolicy/KL                     0.00396987
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             22.5505
GaussianMLPPolicy/LossBefore            22.7566
GaussianMLPPolicy/dLoss                  0.206051
GaussianMLPValueFunction/LossAfter       6.68147
GaussianMLPValueFunction/LossBefore      6.68215
GaussianMLPValueFunction/dLoss           0.000676632
TotalEnvSteps                            1.0272e+06
-----------------------------------  ---------------
2022-08-17 18:13:48 | [trpo_pendulum] epoch #856 | Saving snapshot...
2022-08-17 18:13:48 | [trpo_pendulum] epoch #856 | Saved
2022-08-17 18:13:48 | [trpo_pendulum] epoch #856 | Time 544.66 s
2022-08-17 18:13:48 | [trpo_pendulum] epoch #856 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -517.889
Evaluation/AverageReturn             -1315.54
Evaluation/Iteration                   856
Evaluation/MaxReturn                 -1048.78
Evaluation/MinReturn                 -1479.06
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   145.556
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.20031
GaussianMLPPolicy/KL                     0.00914004
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -7.72417
GaussianMLPPolicy/LossBefore            -6.07454
GaussianMLPPolicy/dLoss                  1.64963
GaussianMLPValueFunction/LossAfter       6.59194
GaussianMLPValueFunction/LossBefore      6.60587
GaussianMLPValueFunction/dLoss           0.0139251
TotalEnvSteps                            1.0284e+06
-----------------------------------  --------------
2022-08-17 18:13:49 | [trpo_pendulum] epoch #857 | Saving snapshot...
2022-08-17 18:13:49 | [trpo_pendulum] epoch #857 | Saved
2022-08-17 18:13:49 | [trpo_pendulum] epoch #857 | Time 545.30 s
2022-08-17 18:13:49 | [trpo_pendulum] epoch #857 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -627.285
Evaluation/AverageReturn             -1519.88
Evaluation/Iteration                   857
Evaluation/MaxReturn                 -1504.14
Evaluation/MinReturn                 -1545.35
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    13.8092
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.15069
GaussianMLPPolicy/KL                     0.00661121
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             38.3194
GaussianMLPPolicy/LossBefore            38.4477
GaussianMLPPolicy/dLoss                  0.128304
GaussianMLPValueFunction/LossAfter       6.67181
GaussianMLPValueFunction/LossBefore      6.6889
GaussianMLPValueFunction/dLoss           0.0170937
TotalEnvSteps                            1.0296e+06
-----------------------------------  --------------
2022-08-17 18:13:50 | [trpo_pendulum] epoch #858 | Saving snapshot...
2022-08-17 18:13:50 | [trpo_pendulum] epoch #858 | Saved
2022-08-17 18:13:50 | [trpo_pendulum] epoch #858 | Time 545.94 s
2022-08-17 18:13:50 | [trpo_pendulum] epoch #858 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -605.312
Evaluation/AverageReturn             -1482.52
Evaluation/Iteration                   858
Evaluation/MaxReturn                 -1396.29
Evaluation/MinReturn                 -1529.16
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    44.1632
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.16756
GaussianMLPPolicy/KL                     0.00697625
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             13.1958
GaussianMLPPolicy/LossBefore            15.3301
GaussianMLPPolicy/dLoss                  2.13437
GaussianMLPValueFunction/LossAfter       6.60027
GaussianMLPValueFunction/LossBefore      6.61028
GaussianMLPValueFunction/dLoss           0.010006
TotalEnvSteps                            1.0308e+06
-----------------------------------  --------------
2022-08-17 18:13:50 | [trpo_pendulum] epoch #859 | Saving snapshot...
2022-08-17 18:13:50 | [trpo_pendulum] epoch #859 | Saved
2022-08-17 18:13:50 | [trpo_pendulum] epoch #859 | Time 546.57 s
2022-08-17 18:13:50 | [trpo_pendulum] epoch #859 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -645.442
Evaluation/AverageReturn             -1541.66
Evaluation/Iteration                   859
Evaluation/MaxReturn                 -1517.08
Evaluation/MinReturn                 -1572.07
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    17.0554
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.15354
GaussianMLPPolicy/KL                     0.00544408
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             41.2004
GaussianMLPPolicy/LossBefore            41.4002
GaussianMLPPolicy/dLoss                  0.199844
GaussianMLPValueFunction/LossAfter       6.6841
GaussianMLPValueFunction/LossBefore      6.70836
GaussianMLPValueFunction/dLoss           0.0242586
TotalEnvSteps                            1.032e+06
-----------------------------------  --------------
2022-08-17 18:13:51 | [trpo_pendulum] epoch #860 | Saving snapshot...
2022-08-17 18:13:51 | [trpo_pendulum] epoch #860 | Saved
2022-08-17 18:13:51 | [trpo_pendulum] epoch #860 | Time 547.19 s
2022-08-17 18:13:51 | [trpo_pendulum] epoch #860 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -554.309
Evaluation/AverageReturn             -1418.55
Evaluation/Iteration                   860
Evaluation/MaxReturn                 -1348.45
Evaluation/MinReturn                 -1489.18
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    53.916
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.11569
GaussianMLPPolicy/KL                     0.00677666
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              9.13389
GaussianMLPPolicy/LossBefore            10.2459
GaussianMLPPolicy/dLoss                  1.11199
GaussianMLPValueFunction/LossAfter       6.5433
GaussianMLPValueFunction/LossBefore      6.55714
GaussianMLPValueFunction/dLoss           0.0138388
TotalEnvSteps                            1.0332e+06
-----------------------------------  --------------
2022-08-17 18:13:52 | [trpo_pendulum] epoch #861 | Saving snapshot...
2022-08-17 18:13:52 | [trpo_pendulum] epoch #861 | Saved
2022-08-17 18:13:52 | [trpo_pendulum] epoch #861 | Time 547.85 s
2022-08-17 18:13:52 | [trpo_pendulum] epoch #861 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -600.511
Evaluation/AverageReturn             -1482.46
Evaluation/Iteration                   861
Evaluation/MaxReturn                 -1378.08
Evaluation/MinReturn                 -1513.83
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    47.0805
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.12181
GaussianMLPPolicy/KL                     0.00707349
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             12.2542
GaussianMLPPolicy/LossBefore            13.5044
GaussianMLPPolicy/dLoss                  1.25018
GaussianMLPValueFunction/LossAfter       6.64114
GaussianMLPValueFunction/LossBefore      6.64181
GaussianMLPValueFunction/dLoss           0.000669003
TotalEnvSteps                            1.0344e+06
-----------------------------------  ---------------
2022-08-17 18:13:52 | [trpo_pendulum] epoch #862 | Saving snapshot...
2022-08-17 18:13:52 | [trpo_pendulum] epoch #862 | Saved
2022-08-17 18:13:52 | [trpo_pendulum] epoch #862 | Time 548.48 s
2022-08-17 18:13:52 | [trpo_pendulum] epoch #862 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -702.66
Evaluation/AverageReturn             -1598.77
Evaluation/Iteration                   862
Evaluation/MaxReturn                 -1575.54
Evaluation/MinReturn                 -1619.89
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    13.8527
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.10628
GaussianMLPPolicy/KL                     0.00648443
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             18.0797
GaussianMLPPolicy/LossBefore            19.8457
GaussianMLPPolicy/dLoss                  1.76606
GaussianMLPValueFunction/LossAfter       6.68157
GaussianMLPValueFunction/LossBefore      6.68393
GaussianMLPValueFunction/dLoss           0.00236607
TotalEnvSteps                            1.0356e+06
-----------------------------------  --------------
2022-08-17 18:13:53 | [trpo_pendulum] epoch #863 | Saving snapshot...
2022-08-17 18:13:53 | [trpo_pendulum] epoch #863 | Saved
2022-08-17 18:13:53 | [trpo_pendulum] epoch #863 | Time 549.13 s
2022-08-17 18:13:53 | [trpo_pendulum] epoch #863 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -648.881
Evaluation/AverageReturn             -1565.54
Evaluation/Iteration                   863
Evaluation/MaxReturn                 -1540.94
Evaluation/MinReturn                 -1596.62
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    20.4811
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.1197
GaussianMLPPolicy/KL                     0.00744812
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             43.6707
GaussianMLPPolicy/LossBefore            45.2984
GaussianMLPPolicy/dLoss                  1.62775
GaussianMLPValueFunction/LossAfter       6.70083
GaussianMLPValueFunction/LossBefore      6.73482
GaussianMLPValueFunction/dLoss           0.0339975
TotalEnvSteps                            1.0368e+06
-----------------------------------  --------------
2022-08-17 18:13:53 | [trpo_pendulum] epoch #864 | Saving snapshot...
2022-08-17 18:13:53 | [trpo_pendulum] epoch #864 | Saved
2022-08-17 18:13:53 | [trpo_pendulum] epoch #864 | Time 549.76 s
2022-08-17 18:13:53 | [trpo_pendulum] epoch #864 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -606.256
Evaluation/AverageReturn             -1484.7
Evaluation/Iteration                   864
Evaluation/MaxReturn                 -1462.96
Evaluation/MinReturn                 -1502.02
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    14.1746
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.11457
GaussianMLPPolicy/KL                     0.00672472
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             11.8711
GaussianMLPPolicy/LossBefore            12.6417
GaussianMLPPolicy/dLoss                  0.770576
GaussianMLPValueFunction/LossAfter       6.61277
GaussianMLPValueFunction/LossBefore      6.61505
GaussianMLPValueFunction/dLoss           0.0022769
TotalEnvSteps                            1.038e+06
-----------------------------------  --------------
2022-08-17 18:13:54 | [trpo_pendulum] epoch #865 | Saving snapshot...
2022-08-17 18:13:54 | [trpo_pendulum] epoch #865 | Saved
2022-08-17 18:13:54 | [trpo_pendulum] epoch #865 | Time 550.37 s
2022-08-17 18:13:54 | [trpo_pendulum] epoch #865 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -589.395
Evaluation/AverageReturn             -1474.65
Evaluation/Iteration                   865
Evaluation/MaxReturn                 -1425.03
Evaluation/MinReturn                 -1511.06
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    28.3088
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.131
GaussianMLPPolicy/KL                     0.00934228
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             11.5355
GaussianMLPPolicy/LossBefore            14.5033
GaussianMLPPolicy/dLoss                  2.96783
GaussianMLPValueFunction/LossAfter       6.60272
GaussianMLPValueFunction/LossBefore      6.61243
GaussianMLPValueFunction/dLoss           0.0097084
TotalEnvSteps                            1.0392e+06
-----------------------------------  --------------
2022-08-17 18:13:55 | [trpo_pendulum] epoch #866 | Saving snapshot...
2022-08-17 18:13:55 | [trpo_pendulum] epoch #866 | Saved
2022-08-17 18:13:55 | [trpo_pendulum] epoch #866 | Time 551.02 s
2022-08-17 18:13:55 | [trpo_pendulum] epoch #866 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -702.142
Evaluation/AverageReturn             -1600.24
Evaluation/Iteration                   866
Evaluation/MaxReturn                 -1557.78
Evaluation/MinReturn                 -1640.42
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    27.9631
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.14643
GaussianMLPPolicy/KL                     0.00748912
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             18.3275
GaussianMLPPolicy/LossBefore            20.21
GaussianMLPPolicy/dLoss                  1.88251
GaussianMLPValueFunction/LossAfter       6.68699
GaussianMLPValueFunction/LossBefore      6.68922
GaussianMLPValueFunction/dLoss           0.00223064
TotalEnvSteps                            1.0404e+06
-----------------------------------  --------------
2022-08-17 18:13:55 | [trpo_pendulum] epoch #867 | Saving snapshot...
2022-08-17 18:13:55 | [trpo_pendulum] epoch #867 | Saved
2022-08-17 18:13:55 | [trpo_pendulum] epoch #867 | Time 551.64 s
2022-08-17 18:13:55 | [trpo_pendulum] epoch #867 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -693.206
Evaluation/AverageReturn             -1571.7
Evaluation/Iteration                   867
Evaluation/MaxReturn                 -1540.41
Evaluation/MinReturn                 -1595.36
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    16.5736
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.13833
GaussianMLPPolicy/KL                     0.00637074
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             13.4663
GaussianMLPPolicy/LossBefore            15.9569
GaussianMLPPolicy/dLoss                  2.49052
GaussianMLPValueFunction/LossAfter       6.67701
GaussianMLPValueFunction/LossBefore      6.6776
GaussianMLPValueFunction/dLoss           0.000585079
TotalEnvSteps                            1.0416e+06
-----------------------------------  ---------------
2022-08-17 18:13:56 | [trpo_pendulum] epoch #868 | Saving snapshot...
2022-08-17 18:13:56 | [trpo_pendulum] epoch #868 | Saved
2022-08-17 18:13:56 | [trpo_pendulum] epoch #868 | Time 552.26 s
2022-08-17 18:13:56 | [trpo_pendulum] epoch #868 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -693.425
Evaluation/AverageReturn             -1578.03
Evaluation/Iteration                   868
Evaluation/MaxReturn                 -1552.38
Evaluation/MinReturn                 -1598.15
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    17.223
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.15191
GaussianMLPPolicy/KL                     0.00850343
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             14.1462
GaussianMLPPolicy/LossBefore            16.7651
GaussianMLPPolicy/dLoss                  2.61887
GaussianMLPValueFunction/LossAfter       6.65541
GaussianMLPValueFunction/LossBefore      6.65555
GaussianMLPValueFunction/dLoss           0.000139236
TotalEnvSteps                            1.0428e+06
-----------------------------------  ---------------
2022-08-17 18:13:57 | [trpo_pendulum] epoch #869 | Saving snapshot...
2022-08-17 18:13:57 | [trpo_pendulum] epoch #869 | Saved
2022-08-17 18:13:57 | [trpo_pendulum] epoch #869 | Time 552.91 s
2022-08-17 18:13:57 | [trpo_pendulum] epoch #869 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -551.323
Evaluation/AverageReturn             -1466.55
Evaluation/Iteration                   869
Evaluation/MaxReturn                 -1379.57
Evaluation/MinReturn                 -1531.14
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    48.7676
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.1528
GaussianMLPPolicy/KL                     0.00614691
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             30.7998
GaussianMLPPolicy/LossBefore            31.8339
GaussianMLPPolicy/dLoss                  1.03414
GaussianMLPValueFunction/LossAfter       6.65622
GaussianMLPValueFunction/LossBefore      6.67164
GaussianMLPValueFunction/dLoss           0.0154204
TotalEnvSteps                            1.044e+06
-----------------------------------  --------------
2022-08-17 18:13:57 | [trpo_pendulum] epoch #870 | Saving snapshot...
2022-08-17 18:13:57 | [trpo_pendulum] epoch #870 | Saved
2022-08-17 18:13:57 | [trpo_pendulum] epoch #870 | Time 553.56 s
2022-08-17 18:13:57 | [trpo_pendulum] epoch #870 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -613.286
Evaluation/AverageReturn             -1507.94
Evaluation/Iteration                   870
Evaluation/MaxReturn                 -1482.41
Evaluation/MinReturn                 -1523.9
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    14.2865
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.14444
GaussianMLPPolicy/KL                     0.00949953
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             15.0856
GaussianMLPPolicy/LossBefore            17.1802
GaussianMLPPolicy/dLoss                  2.09457
GaussianMLPValueFunction/LossAfter       6.6024
GaussianMLPValueFunction/LossBefore      6.61638
GaussianMLPValueFunction/dLoss           0.0139799
TotalEnvSteps                            1.0452e+06
-----------------------------------  --------------
2022-08-17 18:13:58 | [trpo_pendulum] epoch #871 | Saving snapshot...
2022-08-17 18:13:58 | [trpo_pendulum] epoch #871 | Saved
2022-08-17 18:13:58 | [trpo_pendulum] epoch #871 | Time 554.21 s
2022-08-17 18:13:58 | [trpo_pendulum] epoch #871 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -662.636
Evaluation/AverageReturn             -1551.19
Evaluation/Iteration                   871
Evaluation/MaxReturn                 -1533.81
Evaluation/MinReturn                 -1571.57
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    13.2376
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.12702
GaussianMLPPolicy/KL                     0.00708933
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             15.5861
GaussianMLPPolicy/LossBefore            16.8267
GaussianMLPPolicy/dLoss                  1.24059
GaussianMLPValueFunction/LossAfter       6.65997
GaussianMLPValueFunction/LossBefore      6.66047
GaussianMLPValueFunction/dLoss           0.000501156
TotalEnvSteps                            1.0464e+06
-----------------------------------  ---------------
2022-08-17 18:13:59 | [trpo_pendulum] epoch #872 | Saving snapshot...
2022-08-17 18:13:59 | [trpo_pendulum] epoch #872 | Saved
2022-08-17 18:13:59 | [trpo_pendulum] epoch #872 | Time 554.85 s
2022-08-17 18:13:59 | [trpo_pendulum] epoch #872 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -686.558
Evaluation/AverageReturn             -1576.34
Evaluation/Iteration                   872
Evaluation/MaxReturn                 -1555.84
Evaluation/MinReturn                 -1585.28
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    11.0586
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.15049
GaussianMLPPolicy/KL                     0.00896209
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             15.7627
GaussianMLPPolicy/LossBefore            18.3299
GaussianMLPPolicy/dLoss                  2.56715
GaussianMLPValueFunction/LossAfter       6.6764
GaussianMLPValueFunction/LossBefore      6.67713
GaussianMLPValueFunction/dLoss           0.000735283
TotalEnvSteps                            1.0476e+06
-----------------------------------  ---------------
2022-08-17 18:13:59 | [trpo_pendulum] epoch #873 | Saving snapshot...
2022-08-17 18:13:59 | [trpo_pendulum] epoch #873 | Saved
2022-08-17 18:13:59 | [trpo_pendulum] epoch #873 | Time 555.50 s
2022-08-17 18:13:59 | [trpo_pendulum] epoch #873 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -703.257
Evaluation/AverageReturn             -1604.08
Evaluation/Iteration                   873
Evaluation/MaxReturn                 -1573.75
Evaluation/MinReturn                 -1633.18
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    19.6102
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.15999
GaussianMLPPolicy/KL                     0.00660146
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             19.232
GaussianMLPPolicy/LossBefore            21.1844
GaussianMLPPolicy/dLoss                  1.95233
GaussianMLPValueFunction/LossAfter       6.68286
GaussianMLPValueFunction/LossBefore      6.68323
GaussianMLPValueFunction/dLoss           0.000368118
TotalEnvSteps                            1.0488e+06
-----------------------------------  ---------------
2022-08-17 18:14:00 | [trpo_pendulum] epoch #874 | Saving snapshot...
2022-08-17 18:14:00 | [trpo_pendulum] epoch #874 | Saved
2022-08-17 18:14:00 | [trpo_pendulum] epoch #874 | Time 556.14 s
2022-08-17 18:14:00 | [trpo_pendulum] epoch #874 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -682.66
Evaluation/AverageReturn             -1577.63
Evaluation/Iteration                   874
Evaluation/MaxReturn                 -1555.68
Evaluation/MinReturn                 -1589.21
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    11.0801
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.1389
GaussianMLPPolicy/KL                     0.0070356
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             17.4215
GaussianMLPPolicy/LossBefore            19.2833
GaussianMLPPolicy/dLoss                  1.86178
GaussianMLPValueFunction/LossAfter       6.67272
GaussianMLPValueFunction/LossBefore      6.67273
GaussianMLPValueFunction/dLoss           1.7643e-05
TotalEnvSteps                            1.05e+06
-----------------------------------  --------------
2022-08-17 18:14:00 | [trpo_pendulum] epoch #875 | Saving snapshot...
2022-08-17 18:14:01 | [trpo_pendulum] epoch #875 | Saved
2022-08-17 18:14:01 | [trpo_pendulum] epoch #875 | Time 556.79 s
2022-08-17 18:14:01 | [trpo_pendulum] epoch #875 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -617.538
Evaluation/AverageReturn             -1511.04
Evaluation/Iteration                   875
Evaluation/MaxReturn                 -1498.85
Evaluation/MinReturn                 -1522.23
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     8.03788
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.16087
GaussianMLPPolicy/KL                     0.00560869
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             16.1436
GaussianMLPPolicy/LossBefore            16.9063
GaussianMLPPolicy/dLoss                  0.762697
GaussianMLPValueFunction/LossAfter       6.65528
GaussianMLPValueFunction/LossBefore      6.6555
GaussianMLPValueFunction/dLoss           0.000216484
TotalEnvSteps                            1.0512e+06
-----------------------------------  ---------------
2022-08-17 18:14:01 | [trpo_pendulum] epoch #876 | Saving snapshot...
2022-08-17 18:14:01 | [trpo_pendulum] epoch #876 | Saved
2022-08-17 18:14:01 | [trpo_pendulum] epoch #876 | Time 557.45 s
2022-08-17 18:14:01 | [trpo_pendulum] epoch #876 | EpochTime 0.66 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -666.947
Evaluation/AverageReturn             -1536.46
Evaluation/Iteration                   876
Evaluation/MaxReturn                 -1518.94
Evaluation/MinReturn                 -1583.76
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    21.8889
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.18464
GaussianMLPPolicy/KL                     0.00781606
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             10.6003
GaussianMLPPolicy/LossBefore            12.6068
GaussianMLPPolicy/dLoss                  2.00652
GaussianMLPValueFunction/LossAfter       6.63745
GaussianMLPValueFunction/LossBefore      6.63834
GaussianMLPValueFunction/dLoss           0.000894547
TotalEnvSteps                            1.0524e+06
-----------------------------------  ---------------
2022-08-17 18:14:02 | [trpo_pendulum] epoch #877 | Saving snapshot...
2022-08-17 18:14:02 | [trpo_pendulum] epoch #877 | Saved
2022-08-17 18:14:02 | [trpo_pendulum] epoch #877 | Time 558.09 s
2022-08-17 18:14:02 | [trpo_pendulum] epoch #877 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -615.693
Evaluation/AverageReturn             -1488.53
Evaluation/Iteration                   877
Evaluation/MaxReturn                 -1399.06
Evaluation/MinReturn                 -1553.15
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    59.5311
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.19318
GaussianMLPPolicy/KL                     0.00682732
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             15.0267
GaussianMLPPolicy/LossBefore            16.6633
GaussianMLPPolicy/dLoss                  1.63668
GaussianMLPValueFunction/LossAfter       6.58541
GaussianMLPValueFunction/LossBefore      6.59538
GaussianMLPValueFunction/dLoss           0.00996971
TotalEnvSteps                            1.0536e+06
-----------------------------------  --------------
2022-08-17 18:14:02 | [trpo_pendulum] epoch #878 | Saving snapshot...
2022-08-17 18:14:02 | [trpo_pendulum] epoch #878 | Saved
2022-08-17 18:14:02 | [trpo_pendulum] epoch #878 | Time 558.71 s
2022-08-17 18:14:02 | [trpo_pendulum] epoch #878 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -665.997
Evaluation/AverageReturn             -1550.48
Evaluation/Iteration                   878
Evaluation/MaxReturn                 -1526.73
Evaluation/MinReturn                 -1562.93
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    11.8606
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.1877
GaussianMLPPolicy/KL                     0.00987408
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             15.3023
GaussianMLPPolicy/LossBefore            16.681
GaussianMLPPolicy/dLoss                  1.37866
GaussianMLPValueFunction/LossAfter       6.65835
GaussianMLPValueFunction/LossBefore      6.65929
GaussianMLPValueFunction/dLoss           0.000941753
TotalEnvSteps                            1.0548e+06
-----------------------------------  ---------------
2022-08-17 18:14:03 | [trpo_pendulum] epoch #879 | Saving snapshot...
2022-08-17 18:14:03 | [trpo_pendulum] epoch #879 | Saved
2022-08-17 18:14:03 | [trpo_pendulum] epoch #879 | Time 559.33 s
2022-08-17 18:14:03 | [trpo_pendulum] epoch #879 | EpochTime 0.61 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -613.448
Evaluation/AverageReturn             -1502.45
Evaluation/Iteration                   879
Evaluation/MaxReturn                 -1490.89
Evaluation/MinReturn                 -1509.28
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     6.59525
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.20868
GaussianMLPPolicy/KL                     0.00940544
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             14.4759
GaussianMLPPolicy/LossBefore            15.9261
GaussianMLPPolicy/dLoss                  1.45015
GaussianMLPValueFunction/LossAfter       6.63273
GaussianMLPValueFunction/LossBefore      6.6328
GaussianMLPValueFunction/dLoss           7.24792e-05
TotalEnvSteps                            1.056e+06
-----------------------------------  ---------------
2022-08-17 18:14:04 | [trpo_pendulum] epoch #880 | Saving snapshot...
2022-08-17 18:14:04 | [trpo_pendulum] epoch #880 | Saved
2022-08-17 18:14:04 | [trpo_pendulum] epoch #880 | Time 559.97 s
2022-08-17 18:14:04 | [trpo_pendulum] epoch #880 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -677.864
Evaluation/AverageReturn             -1628.46
Evaluation/Iteration                   880
Evaluation/MaxReturn                 -1614.07
Evaluation/MinReturn                 -1640.36
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     9.50479
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.20727
GaussianMLPPolicy/KL                     0.00841708
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             66.3232
GaussianMLPPolicy/LossBefore            66.5014
GaussianMLPPolicy/dLoss                  0.178276
GaussianMLPValueFunction/LossAfter       6.70702
GaussianMLPValueFunction/LossBefore      6.85813
GaussianMLPValueFunction/dLoss           0.151111
TotalEnvSteps                            1.0572e+06
-----------------------------------  --------------
2022-08-17 18:14:04 | [trpo_pendulum] epoch #881 | Saving snapshot...
2022-08-17 18:14:04 | [trpo_pendulum] epoch #881 | Saved
2022-08-17 18:14:04 | [trpo_pendulum] epoch #881 | Time 560.65 s
2022-08-17 18:14:04 | [trpo_pendulum] epoch #881 | EpochTime 0.68 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -611.543
Evaluation/AverageReturn             -1510.02
Evaluation/Iteration                   881
Evaluation/MaxReturn                 -1494.37
Evaluation/MinReturn                 -1520.38
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     9.33224
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.16702
GaussianMLPPolicy/KL                     0.00713898
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             15.8286
GaussianMLPPolicy/LossBefore            16.8628
GaussianMLPPolicy/dLoss                  1.03415
GaussianMLPValueFunction/LossAfter       6.63554
GaussianMLPValueFunction/LossBefore      6.63635
GaussianMLPValueFunction/dLoss           0.000807285
TotalEnvSteps                            1.0584e+06
-----------------------------------  ---------------
2022-08-17 18:14:05 | [trpo_pendulum] epoch #882 | Saving snapshot...
2022-08-17 18:14:05 | [trpo_pendulum] epoch #882 | Saved
2022-08-17 18:14:05 | [trpo_pendulum] epoch #882 | Time 561.28 s
2022-08-17 18:14:05 | [trpo_pendulum] epoch #882 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -612.832
Evaluation/AverageReturn             -1506.82
Evaluation/Iteration                   882
Evaluation/MaxReturn                 -1493.7
Evaluation/MinReturn                 -1521.75
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     9.27306
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.18419
GaussianMLPPolicy/KL                     0.00979061
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             16.8401
GaussianMLPPolicy/LossBefore            17.2447
GaussianMLPPolicy/dLoss                  0.404522
GaussianMLPValueFunction/LossAfter       6.64031
GaussianMLPValueFunction/LossBefore      6.64049
GaussianMLPValueFunction/dLoss           0.000187397
TotalEnvSteps                            1.0596e+06
-----------------------------------  ---------------
2022-08-17 18:14:06 | [trpo_pendulum] epoch #883 | Saving snapshot...
2022-08-17 18:14:06 | [trpo_pendulum] epoch #883 | Saved
2022-08-17 18:14:06 | [trpo_pendulum] epoch #883 | Time 561.92 s
2022-08-17 18:14:06 | [trpo_pendulum] epoch #883 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -517.586
Evaluation/AverageReturn             -1406.32
Evaluation/Iteration                   883
Evaluation/MaxReturn                 -1374.66
Evaluation/MinReturn                 -1509.38
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    47.3752
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.17507
GaussianMLPPolicy/KL                     0.00778525
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             10.562
GaussianMLPPolicy/LossBefore            12.0169
GaussianMLPPolicy/dLoss                  1.4549
GaussianMLPValueFunction/LossAfter       6.62118
GaussianMLPValueFunction/LossBefore      6.62249
GaussianMLPValueFunction/dLoss           0.00131083
TotalEnvSteps                            1.0608e+06
-----------------------------------  --------------
2022-08-17 18:14:06 | [trpo_pendulum] epoch #884 | Saving snapshot...
2022-08-17 18:14:06 | [trpo_pendulum] epoch #884 | Saved
2022-08-17 18:14:06 | [trpo_pendulum] epoch #884 | Time 562.59 s
2022-08-17 18:14:06 | [trpo_pendulum] epoch #884 | EpochTime 0.67 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -677.297
Evaluation/AverageReturn             -1548.87
Evaluation/Iteration                   884
Evaluation/MaxReturn                 -1540.93
Evaluation/MinReturn                 -1568.23
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     9.22684
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.16375
GaussianMLPPolicy/KL                     0.0081464
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             11.6956
GaussianMLPPolicy/LossBefore            13.4095
GaussianMLPPolicy/dLoss                  1.71396
GaussianMLPValueFunction/LossAfter       6.64412
GaussianMLPValueFunction/LossBefore      6.64453
GaussianMLPValueFunction/dLoss           0.000402927
TotalEnvSteps                            1.062e+06
-----------------------------------  ---------------
2022-08-17 18:14:07 | [trpo_pendulum] epoch #885 | Saving snapshot...
2022-08-17 18:14:07 | [trpo_pendulum] epoch #885 | Saved
2022-08-17 18:14:07 | [trpo_pendulum] epoch #885 | Time 563.23 s
2022-08-17 18:14:07 | [trpo_pendulum] epoch #885 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -655.201
Evaluation/AverageReturn             -1514.87
Evaluation/Iteration                   885
Evaluation/MaxReturn                 -1502.43
Evaluation/MinReturn                 -1536.29
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    12.0894
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.18654
GaussianMLPPolicy/KL                     0.00579834
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              9.03549
GaussianMLPPolicy/LossBefore            10.4706
GaussianMLPPolicy/dLoss                  1.4351
GaussianMLPValueFunction/LossAfter       6.62898
GaussianMLPValueFunction/LossBefore      6.62972
GaussianMLPValueFunction/dLoss           0.000733376
TotalEnvSteps                            1.0632e+06
-----------------------------------  ---------------
2022-08-17 18:14:08 | [trpo_pendulum] epoch #886 | Saving snapshot...
2022-08-17 18:14:08 | [trpo_pendulum] epoch #886 | Saved
2022-08-17 18:14:08 | [trpo_pendulum] epoch #886 | Time 563.86 s
2022-08-17 18:14:08 | [trpo_pendulum] epoch #886 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -572.745
Evaluation/AverageReturn             -1392.4
Evaluation/Iteration                   886
Evaluation/MaxReturn                 -1365.33
Evaluation/MinReturn                 -1448.86
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    26.5459
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.17639
GaussianMLPPolicy/KL                     0.00888953
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -1.33906
GaussianMLPPolicy/LossBefore             0.132369
GaussianMLPPolicy/dLoss                  1.47143
GaussianMLPValueFunction/LossAfter       6.61095
GaussianMLPValueFunction/LossBefore      6.6137
GaussianMLPValueFunction/dLoss           0.00274181
TotalEnvSteps                            1.0644e+06
-----------------------------------  --------------
2022-08-17 18:14:08 | [trpo_pendulum] epoch #887 | Saving snapshot...
2022-08-17 18:14:08 | [trpo_pendulum] epoch #887 | Saved
2022-08-17 18:14:08 | [trpo_pendulum] epoch #887 | Time 564.48 s
2022-08-17 18:14:08 | [trpo_pendulum] epoch #887 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -669.614
Evaluation/AverageReturn             -1549.71
Evaluation/Iteration                   887
Evaluation/MaxReturn                 -1535.51
Evaluation/MinReturn                 -1561.99
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     8.91296
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.18235
GaussianMLPPolicy/KL                     0.00929123
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             15.9204
GaussianMLPPolicy/LossBefore            17.8312
GaussianMLPPolicy/dLoss                  1.91083
GaussianMLPValueFunction/LossAfter       6.67175
GaussianMLPValueFunction/LossBefore      6.67335
GaussianMLPValueFunction/dLoss           0.00159264
TotalEnvSteps                            1.0656e+06
-----------------------------------  --------------
2022-08-17 18:14:09 | [trpo_pendulum] epoch #888 | Saving snapshot...
2022-08-17 18:14:09 | [trpo_pendulum] epoch #888 | Saved
2022-08-17 18:14:09 | [trpo_pendulum] epoch #888 | Time 565.13 s
2022-08-17 18:14:09 | [trpo_pendulum] epoch #888 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -600.699
Evaluation/AverageReturn             -1511.45
Evaluation/Iteration                   888
Evaluation/MaxReturn                 -1495.66
Evaluation/MinReturn                 -1523.54
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     8.8191
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.20656
GaussianMLPPolicy/KL                     0.00759084
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             21.2893
GaussianMLPPolicy/LossBefore            22.9039
GaussianMLPPolicy/dLoss                  1.61467
GaussianMLPValueFunction/LossAfter       6.65563
GaussianMLPValueFunction/LossBefore      6.65582
GaussianMLPValueFunction/dLoss           0.000188828
TotalEnvSteps                            1.0668e+06
-----------------------------------  ---------------
2022-08-17 18:14:09 | [trpo_pendulum] epoch #889 | Saving snapshot...
2022-08-17 18:14:09 | [trpo_pendulum] epoch #889 | Saved
2022-08-17 18:14:09 | [trpo_pendulum] epoch #889 | Time 565.76 s
2022-08-17 18:14:09 | [trpo_pendulum] epoch #889 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -607.65
Evaluation/AverageReturn             -1539.29
Evaluation/Iteration                   889
Evaluation/MaxReturn                 -1525.91
Evaluation/MinReturn                 -1575.81
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    17.5222
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.21529
GaussianMLPPolicy/KL                     0.00896414
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             28.012
GaussianMLPPolicy/LossBefore            29.696
GaussianMLPPolicy/dLoss                  1.68398
GaussianMLPValueFunction/LossAfter       6.70914
GaussianMLPValueFunction/LossBefore      6.71302
GaussianMLPValueFunction/dLoss           0.0038867
TotalEnvSteps                            1.068e+06
-----------------------------------  --------------
2022-08-17 18:14:10 | [trpo_pendulum] epoch #890 | Saving snapshot...
2022-08-17 18:14:10 | [trpo_pendulum] epoch #890 | Saved
2022-08-17 18:14:10 | [trpo_pendulum] epoch #890 | Time 566.41 s
2022-08-17 18:14:10 | [trpo_pendulum] epoch #890 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -652.363
Evaluation/AverageReturn             -1518.01
Evaluation/Iteration                   890
Evaluation/MaxReturn                 -1492.31
Evaluation/MinReturn                 -1551.89
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    19.4961
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.20461
GaussianMLPPolicy/KL                     0.00677826
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             11.3352
GaussianMLPPolicy/LossBefore            13.4523
GaussianMLPPolicy/dLoss                  2.11714
GaussianMLPValueFunction/LossAfter       6.65225
GaussianMLPValueFunction/LossBefore      6.65293
GaussianMLPValueFunction/dLoss           0.000678539
TotalEnvSteps                            1.0692e+06
-----------------------------------  ---------------
2022-08-17 18:14:11 | [trpo_pendulum] epoch #891 | Saving snapshot...
2022-08-17 18:14:11 | [trpo_pendulum] epoch #891 | Saved
2022-08-17 18:14:11 | [trpo_pendulum] epoch #891 | Time 567.03 s
2022-08-17 18:14:11 | [trpo_pendulum] epoch #891 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -587.075
Evaluation/AverageReturn             -1466.75
Evaluation/Iteration                   891
Evaluation/MaxReturn                 -1278.17
Evaluation/MinReturn                 -1540.38
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    88.0218
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.19573
GaussianMLPPolicy/KL                     0.00741511
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             13.0268
GaussianMLPPolicy/LossBefore            13.9727
GaussianMLPPolicy/dLoss                  0.945912
GaussianMLPValueFunction/LossAfter       6.58344
GaussianMLPValueFunction/LossBefore      6.60129
GaussianMLPValueFunction/dLoss           0.0178466
TotalEnvSteps                            1.0704e+06
-----------------------------------  --------------
2022-08-17 18:14:11 | [trpo_pendulum] epoch #892 | Saving snapshot...
2022-08-17 18:14:11 | [trpo_pendulum] epoch #892 | Saved
2022-08-17 18:14:11 | [trpo_pendulum] epoch #892 | Time 567.67 s
2022-08-17 18:14:11 | [trpo_pendulum] epoch #892 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -562.14
Evaluation/AverageReturn             -1435.52
Evaluation/Iteration                   892
Evaluation/MaxReturn                 -1071.05
Evaluation/MinReturn                 -1523.52
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   163.336
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.21444
GaussianMLPPolicy/KL                     0.00627337
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             19.0898
GaussianMLPPolicy/LossBefore            20.2606
GaussianMLPPolicy/dLoss                  1.17084
GaussianMLPValueFunction/LossAfter       6.60266
GaussianMLPValueFunction/LossBefore      6.60454
GaussianMLPValueFunction/dLoss           0.00188208
TotalEnvSteps                            1.0716e+06
-----------------------------------  --------------
2022-08-17 18:14:12 | [trpo_pendulum] epoch #893 | Saving snapshot...
2022-08-17 18:14:12 | [trpo_pendulum] epoch #893 | Saved
2022-08-17 18:14:12 | [trpo_pendulum] epoch #893 | Time 568.33 s
2022-08-17 18:14:12 | [trpo_pendulum] epoch #893 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -586.752
Evaluation/AverageReturn             -1417.71
Evaluation/Iteration                   893
Evaluation/MaxReturn                 -1277.38
Evaluation/MinReturn                 -1503.98
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    81.2295
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.22318
GaussianMLPPolicy/KL                     0.00644794
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              1.57095
GaussianMLPPolicy/LossBefore             2.63875
GaussianMLPPolicy/dLoss                  1.0678
GaussianMLPValueFunction/LossAfter       6.55223
GaussianMLPValueFunction/LossBefore      6.55845
GaussianMLPValueFunction/dLoss           0.00622272
TotalEnvSteps                            1.0728e+06
-----------------------------------  --------------
2022-08-17 18:14:13 | [trpo_pendulum] epoch #894 | Saving snapshot...
2022-08-17 18:14:13 | [trpo_pendulum] epoch #894 | Saved
2022-08-17 18:14:13 | [trpo_pendulum] epoch #894 | Time 568.95 s
2022-08-17 18:14:13 | [trpo_pendulum] epoch #894 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -484.534
Evaluation/AverageReturn             -1248.87
Evaluation/Iteration                   894
Evaluation/MaxReturn                 -1199.47
Evaluation/MinReturn                 -1303.33
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    38.1916
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.21337
GaussianMLPPolicy/KL                     0.00848852
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            -15.4929
GaussianMLPPolicy/LossBefore           -14.0577
GaussianMLPPolicy/dLoss                  1.43521
GaussianMLPValueFunction/LossAfter       6.56879
GaussianMLPValueFunction/LossBefore      6.57544
GaussianMLPValueFunction/dLoss           0.00664902
TotalEnvSteps                            1.074e+06
-----------------------------------  --------------
2022-08-17 18:14:13 | [trpo_pendulum] epoch #895 | Saving snapshot...
2022-08-17 18:14:13 | [trpo_pendulum] epoch #895 | Saved
2022-08-17 18:14:13 | [trpo_pendulum] epoch #895 | Time 569.57 s
2022-08-17 18:14:13 | [trpo_pendulum] epoch #895 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -672.724
Evaluation/AverageReturn             -1531.83
Evaluation/Iteration                   895
Evaluation/MaxReturn                 -1516.27
Evaluation/MinReturn                 -1543.74
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     9.39145
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.2185
GaussianMLPPolicy/KL                     0.00707683
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             12.3103
GaussianMLPPolicy/LossBefore            13.3668
GaussianMLPPolicy/dLoss                  1.05645
GaussianMLPValueFunction/LossAfter       6.63525
GaussianMLPValueFunction/LossBefore      6.63764
GaussianMLPValueFunction/dLoss           0.00238848
TotalEnvSteps                            1.0752e+06
-----------------------------------  --------------
2022-08-17 18:14:14 | [trpo_pendulum] epoch #896 | Saving snapshot...
2022-08-17 18:14:14 | [trpo_pendulum] epoch #896 | Saved
2022-08-17 18:14:14 | [trpo_pendulum] epoch #896 | Time 570.20 s
2022-08-17 18:14:14 | [trpo_pendulum] epoch #896 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -654.885
Evaluation/AverageReturn             -1515.4
Evaluation/Iteration                   896
Evaluation/MaxReturn                 -1507.65
Evaluation/MinReturn                 -1522.94
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     5.04444
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.21824
GaussianMLPPolicy/KL                     0.006104
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             12.1706
GaussianMLPPolicy/LossBefore            13.7539
GaussianMLPPolicy/dLoss                  1.58322
GaussianMLPValueFunction/LossAfter       6.62895
GaussianMLPValueFunction/LossBefore      6.62959
GaussianMLPValueFunction/dLoss           0.000641823
TotalEnvSteps                            1.0764e+06
-----------------------------------  ---------------
2022-08-17 18:14:15 | [trpo_pendulum] epoch #897 | Saving snapshot...
2022-08-17 18:14:15 | [trpo_pendulum] epoch #897 | Saved
2022-08-17 18:14:15 | [trpo_pendulum] epoch #897 | Time 570.81 s
2022-08-17 18:14:15 | [trpo_pendulum] epoch #897 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -551.579
Evaluation/AverageReturn             -1438.39
Evaluation/Iteration                   897
Evaluation/MaxReturn                 -1371.2
Evaluation/MinReturn                 -1492.73
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    41.5603
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.23457
GaussianMLPPolicy/KL                     0.00894984
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             18.2397
GaussianMLPPolicy/LossBefore            20.6898
GaussianMLPPolicy/dLoss                  2.45005
GaussianMLPValueFunction/LossAfter       6.58188
GaussianMLPValueFunction/LossBefore      6.58955
GaussianMLPValueFunction/dLoss           0.00766945
TotalEnvSteps                            1.0776e+06
-----------------------------------  --------------
2022-08-17 18:14:15 | [trpo_pendulum] epoch #898 | Saving snapshot...
2022-08-17 18:14:15 | [trpo_pendulum] epoch #898 | Saved
2022-08-17 18:14:15 | [trpo_pendulum] epoch #898 | Time 571.46 s
2022-08-17 18:14:15 | [trpo_pendulum] epoch #898 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -667.964
Evaluation/AverageReturn             -1595.67
Evaluation/Iteration                   898
Evaluation/MaxReturn                 -1545.74
Evaluation/MinReturn                 -1627.5
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    32.1481
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.2635
GaussianMLPPolicy/KL                     0.00886637
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             28.0954
GaussianMLPPolicy/LossBefore            29.6745
GaussianMLPPolicy/dLoss                  1.57907
GaussianMLPValueFunction/LossAfter       6.70473
GaussianMLPValueFunction/LossBefore      6.71276
GaussianMLPValueFunction/dLoss           0.00803137
TotalEnvSteps                            1.0788e+06
-----------------------------------  --------------
2022-08-17 18:14:16 | [trpo_pendulum] epoch #899 | Saving snapshot...
2022-08-17 18:14:16 | [trpo_pendulum] epoch #899 | Saved
2022-08-17 18:14:16 | [trpo_pendulum] epoch #899 | Time 572.08 s
2022-08-17 18:14:16 | [trpo_pendulum] epoch #899 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -656.084
Evaluation/AverageReturn             -1514.28
Evaluation/Iteration                   899
Evaluation/MaxReturn                 -1508.48
Evaluation/MinReturn                 -1520.15
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     4.70962
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.25876
GaussianMLPPolicy/KL                     0.00550056
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             12.7072
GaussianMLPPolicy/LossBefore            13.1329
GaussianMLPPolicy/dLoss                  0.425721
GaussianMLPValueFunction/LossAfter       6.63628
GaussianMLPValueFunction/LossBefore      6.63659
GaussianMLPValueFunction/dLoss           0.000309467
TotalEnvSteps                            1.08e+06
-----------------------------------  ---------------
2022-08-17 18:14:16 | [trpo_pendulum] epoch #900 | Saving snapshot...
2022-08-17 18:14:16 | [trpo_pendulum] epoch #900 | Saved
2022-08-17 18:14:16 | [trpo_pendulum] epoch #900 | Time 572.73 s
2022-08-17 18:14:16 | [trpo_pendulum] epoch #900 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -646.856
Evaluation/AverageReturn             -1578.21
Evaluation/Iteration                   900
Evaluation/MaxReturn                 -1552.47
Evaluation/MinReturn                 -1599.6
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    15.6808
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.28102
GaussianMLPPolicy/KL                     0.00676004
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             27.237
GaussianMLPPolicy/LossBefore            29.2841
GaussianMLPPolicy/dLoss                  2.04712
GaussianMLPValueFunction/LossAfter       6.70415
GaussianMLPValueFunction/LossBefore      6.70738
GaussianMLPValueFunction/dLoss           0.00322962
TotalEnvSteps                            1.0812e+06
-----------------------------------  --------------
2022-08-17 18:14:17 | [trpo_pendulum] epoch #901 | Saving snapshot...
2022-08-17 18:14:17 | [trpo_pendulum] epoch #901 | Saved
2022-08-17 18:14:17 | [trpo_pendulum] epoch #901 | Time 573.40 s
2022-08-17 18:14:17 | [trpo_pendulum] epoch #901 | EpochTime 0.67 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -653.428
Evaluation/AverageReturn             -1594.8
Evaluation/Iteration                   901
Evaluation/MaxReturn                 -1582.15
Evaluation/MinReturn                 -1605.52
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     7.93055
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.25782
GaussianMLPPolicy/KL                     0.00863306
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             30.8789
GaussianMLPPolicy/LossBefore            32.3548
GaussianMLPPolicy/dLoss                  1.4759
GaussianMLPValueFunction/LossAfter       6.72219
GaussianMLPValueFunction/LossBefore      6.72494
GaussianMLPValueFunction/dLoss           0.00275946
TotalEnvSteps                            1.0824e+06
-----------------------------------  --------------
2022-08-17 18:14:18 | [trpo_pendulum] epoch #902 | Saving snapshot...
2022-08-17 18:14:18 | [trpo_pendulum] epoch #902 | Saved
2022-08-17 18:14:18 | [trpo_pendulum] epoch #902 | Time 574.04 s
2022-08-17 18:14:18 | [trpo_pendulum] epoch #902 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -653.101
Evaluation/AverageReturn             -1514.31
Evaluation/Iteration                   902
Evaluation/MaxReturn                 -1502.91
Evaluation/MinReturn                 -1524.27
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     8.67739
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.25323
GaussianMLPPolicy/KL                     0.00892316
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             11.3744
GaussianMLPPolicy/LossBefore            12.8408
GaussianMLPPolicy/dLoss                  1.46641
GaussianMLPValueFunction/LossAfter       6.63308
GaussianMLPValueFunction/LossBefore      6.6356
GaussianMLPValueFunction/dLoss           0.00252008
TotalEnvSteps                            1.0836e+06
-----------------------------------  --------------
2022-08-17 18:14:18 | [trpo_pendulum] epoch #903 | Saving snapshot...
2022-08-17 18:14:18 | [trpo_pendulum] epoch #903 | Saved
2022-08-17 18:14:18 | [trpo_pendulum] epoch #903 | Time 574.68 s
2022-08-17 18:14:18 | [trpo_pendulum] epoch #903 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -593.007
Evaluation/AverageReturn             -1515.87
Evaluation/Iteration                   903
Evaluation/MaxReturn                 -1313.18
Evaluation/MinReturn                 -1567.3
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    91.211
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.27797
GaussianMLPPolicy/KL                     0.00869762
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             36.0583
GaussianMLPPolicy/LossBefore            38.1119
GaussianMLPPolicy/dLoss                  2.05357
GaussianMLPValueFunction/LossAfter       6.70848
GaussianMLPValueFunction/LossBefore      6.72428
GaussianMLPValueFunction/dLoss           0.0157995
TotalEnvSteps                            1.0848e+06
-----------------------------------  --------------
2022-08-17 18:14:19 | [trpo_pendulum] epoch #904 | Saving snapshot...
2022-08-17 18:14:19 | [trpo_pendulum] epoch #904 | Saved
2022-08-17 18:14:19 | [trpo_pendulum] epoch #904 | Time 575.34 s
2022-08-17 18:14:19 | [trpo_pendulum] epoch #904 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -600.644
Evaluation/AverageReturn             -1494.63
Evaluation/Iteration                   904
Evaluation/MaxReturn                 -1420.93
Evaluation/MinReturn                 -1537.88
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    40.4872
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.26753
GaussianMLPPolicy/KL                     0.00949611
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             12.8497
GaussianMLPPolicy/LossBefore            15.8298
GaussianMLPPolicy/dLoss                  2.98008
GaussianMLPValueFunction/LossAfter       6.58387
GaussianMLPValueFunction/LossBefore      6.59642
GaussianMLPValueFunction/dLoss           0.0125499
TotalEnvSteps                            1.086e+06
-----------------------------------  --------------
2022-08-17 18:14:20 | [trpo_pendulum] epoch #905 | Saving snapshot...
2022-08-17 18:14:20 | [trpo_pendulum] epoch #905 | Saved
2022-08-17 18:14:20 | [trpo_pendulum] epoch #905 | Time 575.98 s
2022-08-17 18:14:20 | [trpo_pendulum] epoch #905 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -563.193
Evaluation/AverageReturn             -1413.44
Evaluation/Iteration                   905
Evaluation/MaxReturn                 -1308.48
Evaluation/MinReturn                 -1492.08
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    61.2503
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.26315
GaussianMLPPolicy/KL                     0.00934729
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              9.1991
GaussianMLPPolicy/LossBefore            11.2024
GaussianMLPPolicy/dLoss                  2.00334
GaussianMLPValueFunction/LossAfter       6.42248
GaussianMLPValueFunction/LossBefore      6.47072
GaussianMLPValueFunction/dLoss           0.0482359
TotalEnvSteps                            1.0872e+06
-----------------------------------  --------------
2022-08-17 18:14:20 | [trpo_pendulum] epoch #906 | Saving snapshot...
2022-08-17 18:14:20 | [trpo_pendulum] epoch #906 | Saved
2022-08-17 18:14:20 | [trpo_pendulum] epoch #906 | Time 576.62 s
2022-08-17 18:14:20 | [trpo_pendulum] epoch #906 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -660.56
Evaluation/AverageReturn             -1607.27
Evaluation/Iteration                   906
Evaluation/MaxReturn                 -1578.44
Evaluation/MinReturn                 -1613.86
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    12.9095
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.28842
GaussianMLPPolicy/KL                     0.00811364
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             30.3941
GaussianMLPPolicy/LossBefore            32.1081
GaussianMLPPolicy/dLoss                  1.71404
GaussianMLPValueFunction/LossAfter       6.72912
GaussianMLPValueFunction/LossBefore      6.74564
GaussianMLPValueFunction/dLoss           0.0165176
TotalEnvSteps                            1.0884e+06
-----------------------------------  --------------
2022-08-17 18:14:21 | [trpo_pendulum] epoch #907 | Saving snapshot...
2022-08-17 18:14:21 | [trpo_pendulum] epoch #907 | Saved
2022-08-17 18:14:21 | [trpo_pendulum] epoch #907 | Time 577.26 s
2022-08-17 18:14:21 | [trpo_pendulum] epoch #907 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -621.361
Evaluation/AverageReturn             -1543.45
Evaluation/Iteration                   907
Evaluation/MaxReturn                 -1501.34
Evaluation/MinReturn                 -1575.97
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    29.4079
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.27842
GaussianMLPPolicy/KL                     0.00733961
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             26.9944
GaussianMLPPolicy/LossBefore            28.4147
GaussianMLPPolicy/dLoss                  1.42031
GaussianMLPValueFunction/LossAfter       6.67598
GaussianMLPValueFunction/LossBefore      6.68847
GaussianMLPValueFunction/dLoss           0.0124931
TotalEnvSteps                            1.0896e+06
-----------------------------------  --------------
2022-08-17 18:14:22 | [trpo_pendulum] epoch #908 | Saving snapshot...
2022-08-17 18:14:22 | [trpo_pendulum] epoch #908 | Saved
2022-08-17 18:14:22 | [trpo_pendulum] epoch #908 | Time 577.90 s
2022-08-17 18:14:22 | [trpo_pendulum] epoch #908 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -672.391
Evaluation/AverageReturn             -1623.07
Evaluation/Iteration                   908
Evaluation/MaxReturn                 -1601.25
Evaluation/MinReturn                 -1649.68
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    15.15
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.30886
GaussianMLPPolicy/KL                     0.00772699
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             46.8057
GaussianMLPPolicy/LossBefore            48.8843
GaussianMLPPolicy/dLoss                  2.07857
GaussianMLPValueFunction/LossAfter       6.70524
GaussianMLPValueFunction/LossBefore      6.74308
GaussianMLPValueFunction/dLoss           0.0378418
TotalEnvSteps                            1.0908e+06
-----------------------------------  --------------
2022-08-17 18:14:22 | [trpo_pendulum] epoch #909 | Saving snapshot...
2022-08-17 18:14:22 | [trpo_pendulum] epoch #909 | Saved
2022-08-17 18:14:22 | [trpo_pendulum] epoch #909 | Time 578.53 s
2022-08-17 18:14:22 | [trpo_pendulum] epoch #909 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -578.949
Evaluation/AverageReturn             -1472.83
Evaluation/Iteration                   909
Evaluation/MaxReturn                 -1382.22
Evaluation/MinReturn                 -1512.84
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    46.5769
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.29962
GaussianMLPPolicy/KL                     0.00674141
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             10.9505
GaussianMLPPolicy/LossBefore            12.7925
GaussianMLPPolicy/dLoss                  1.84195
GaussianMLPValueFunction/LossAfter       6.54617
GaussianMLPValueFunction/LossBefore      6.57953
GaussianMLPValueFunction/dLoss           0.0333667
TotalEnvSteps                            1.092e+06
-----------------------------------  --------------
2022-08-17 18:14:23 | [trpo_pendulum] epoch #910 | Saving snapshot...
2022-08-17 18:14:23 | [trpo_pendulum] epoch #910 | Saved
2022-08-17 18:14:23 | [trpo_pendulum] epoch #910 | Time 579.19 s
2022-08-17 18:14:23 | [trpo_pendulum] epoch #910 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -605.293
Evaluation/AverageReturn             -1512.9
Evaluation/Iteration                   910
Evaluation/MaxReturn                 -1457.61
Evaluation/MinReturn                 -1557.57
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    30.148
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.30021
GaussianMLPPolicy/KL                     0.00854416
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             22.8683
GaussianMLPPolicy/LossBefore            25.2174
GaussianMLPPolicy/dLoss                  2.34914
GaussianMLPValueFunction/LossAfter       6.64096
GaussianMLPValueFunction/LossBefore      6.64251
GaussianMLPValueFunction/dLoss           0.00154924
TotalEnvSteps                            1.0932e+06
-----------------------------------  --------------
2022-08-17 18:14:24 | [trpo_pendulum] epoch #911 | Saving snapshot...
2022-08-17 18:14:24 | [trpo_pendulum] epoch #911 | Saved
2022-08-17 18:14:24 | [trpo_pendulum] epoch #911 | Time 579.87 s
2022-08-17 18:14:24 | [trpo_pendulum] epoch #911 | EpochTime 0.68 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -604.388
Evaluation/AverageReturn             -1515.44
Evaluation/Iteration                   911
Evaluation/MaxReturn                 -1506.85
Evaluation/MinReturn                 -1529.37
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     7.61553
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.31065
GaussianMLPPolicy/KL                     0.00758302
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             28.694
GaussianMLPPolicy/LossBefore            29.6574
GaussianMLPPolicy/dLoss                  0.963392
GaussianMLPValueFunction/LossAfter       6.60566
GaussianMLPValueFunction/LossBefore      6.60992
GaussianMLPValueFunction/dLoss           0.00425816
TotalEnvSteps                            1.0944e+06
-----------------------------------  --------------
2022-08-17 18:14:24 | [trpo_pendulum] epoch #912 | Saving snapshot...
2022-08-17 18:14:24 | [trpo_pendulum] epoch #912 | Saved
2022-08-17 18:14:24 | [trpo_pendulum] epoch #912 | Time 580.64 s
2022-08-17 18:14:24 | [trpo_pendulum] epoch #912 | EpochTime 0.76 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -628.089
Evaluation/AverageReturn             -1504.42
Evaluation/Iteration                   912
Evaluation/MaxReturn                 -1431.01
Evaluation/MinReturn                 -1537.51
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    35.7539
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.31665
GaussianMLPPolicy/KL                     0.00696627
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              8.13701
GaussianMLPPolicy/LossBefore            10.4075
GaussianMLPPolicy/dLoss                  2.27053
GaussianMLPValueFunction/LossAfter       6.62192
GaussianMLPValueFunction/LossBefore      6.62227
GaussianMLPValueFunction/dLoss           0.000347137
TotalEnvSteps                            1.0956e+06
-----------------------------------  ---------------
2022-08-17 18:14:25 | [trpo_pendulum] epoch #913 | Saving snapshot...
2022-08-17 18:14:25 | [trpo_pendulum] epoch #913 | Saved
2022-08-17 18:14:25 | [trpo_pendulum] epoch #913 | Time 581.31 s
2022-08-17 18:14:25 | [trpo_pendulum] epoch #913 | EpochTime 0.67 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -562.632
Evaluation/AverageReturn             -1458.41
Evaluation/Iteration                   913
Evaluation/MaxReturn                 -1369.89
Evaluation/MinReturn                 -1512.15
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    48.3956
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.31519
GaussianMLPPolicy/KL                     0.00661445
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             21.2432
GaussianMLPPolicy/LossBefore            22.5401
GaussianMLPPolicy/dLoss                  1.29689
GaussianMLPValueFunction/LossAfter       6.56628
GaussianMLPValueFunction/LossBefore      6.57019
GaussianMLPValueFunction/dLoss           0.00391197
TotalEnvSteps                            1.0968e+06
-----------------------------------  --------------
2022-08-17 18:14:26 | [trpo_pendulum] epoch #914 | Saving snapshot...
2022-08-17 18:14:26 | [trpo_pendulum] epoch #914 | Saved
2022-08-17 18:14:26 | [trpo_pendulum] epoch #914 | Time 582.00 s
2022-08-17 18:14:26 | [trpo_pendulum] epoch #914 | EpochTime 0.68 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -595.482
Evaluation/AverageReturn             -1490.05
Evaluation/Iteration                   914
Evaluation/MaxReturn                 -1470.45
Evaluation/MinReturn                 -1511.83
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    15.4469
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.33117
GaussianMLPPolicy/KL                     0.00745046
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             12.7902
GaussianMLPPolicy/LossBefore            14.9935
GaussianMLPPolicy/dLoss                  2.20327
GaussianMLPValueFunction/LossAfter       6.59717
GaussianMLPValueFunction/LossBefore      6.59734
GaussianMLPValueFunction/dLoss           0.000165939
TotalEnvSteps                            1.098e+06
-----------------------------------  ---------------
2022-08-17 18:14:26 | [trpo_pendulum] epoch #915 | Saving snapshot...
2022-08-17 18:14:26 | [trpo_pendulum] epoch #915 | Saved
2022-08-17 18:14:26 | [trpo_pendulum] epoch #915 | Time 582.70 s
2022-08-17 18:14:26 | [trpo_pendulum] epoch #915 | EpochTime 0.70 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -560.519
Evaluation/AverageReturn             -1451.14
Evaluation/Iteration                   915
Evaluation/MaxReturn                 -1386.89
Evaluation/MinReturn                 -1504.95
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    39.2529
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.35087
GaussianMLPPolicy/KL                     0.00616364
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             11.1507
GaussianMLPPolicy/LossBefore            12.9642
GaussianMLPPolicy/dLoss                  1.81359
GaussianMLPValueFunction/LossAfter       6.65145
GaussianMLPValueFunction/LossBefore      6.65347
GaussianMLPValueFunction/dLoss           0.00201797
TotalEnvSteps                            1.0992e+06
-----------------------------------  --------------
2022-08-17 18:14:27 | [trpo_pendulum] epoch #916 | Saving snapshot...
2022-08-17 18:14:27 | [trpo_pendulum] epoch #916 | Saved
2022-08-17 18:14:27 | [trpo_pendulum] epoch #916 | Time 583.34 s
2022-08-17 18:14:27 | [trpo_pendulum] epoch #916 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -583.551
Evaluation/AverageReturn             -1441.83
Evaluation/Iteration                   916
Evaluation/MaxReturn                 -1368.15
Evaluation/MinReturn                 -1535.64
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    52.9129
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.34687
GaussianMLPPolicy/KL                     0.00702501
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              6.43498
GaussianMLPPolicy/LossBefore             8.39293
GaussianMLPPolicy/dLoss                  1.95795
GaussianMLPValueFunction/LossAfter       6.52896
GaussianMLPValueFunction/LossBefore      6.55144
GaussianMLPValueFunction/dLoss           0.0224814
TotalEnvSteps                            1.1004e+06
-----------------------------------  --------------
2022-08-17 18:14:28 | [trpo_pendulum] epoch #917 | Saving snapshot...
2022-08-17 18:14:28 | [trpo_pendulum] epoch #917 | Saved
2022-08-17 18:14:28 | [trpo_pendulum] epoch #917 | Time 583.98 s
2022-08-17 18:14:28 | [trpo_pendulum] epoch #917 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -648.991
Evaluation/AverageReturn             -1500.71
Evaluation/Iteration                   917
Evaluation/MaxReturn                 -1497.12
Evaluation/MinReturn                 -1505.83
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     3.67262
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.34552
GaussianMLPPolicy/KL                     0.00712887
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              5.27603
GaussianMLPPolicy/LossBefore             6.46544
GaussianMLPPolicy/dLoss                  1.1894
GaussianMLPValueFunction/LossAfter       6.63537
GaussianMLPValueFunction/LossBefore      6.63827
GaussianMLPValueFunction/dLoss           0.00289392
TotalEnvSteps                            1.1016e+06
-----------------------------------  --------------
2022-08-17 18:14:28 | [trpo_pendulum] epoch #918 | Saving snapshot...
2022-08-17 18:14:28 | [trpo_pendulum] epoch #918 | Saved
2022-08-17 18:14:28 | [trpo_pendulum] epoch #918 | Time 584.62 s
2022-08-17 18:14:28 | [trpo_pendulum] epoch #918 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -623.894
Evaluation/AverageReturn             -1528.03
Evaluation/Iteration                   918
Evaluation/MaxReturn                 -1518.18
Evaluation/MinReturn                 -1542.83
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    10.0732
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.33673
GaussianMLPPolicy/KL                     0.00848527
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             18.2263
GaussianMLPPolicy/LossBefore            19.1029
GaussianMLPPolicy/dLoss                  0.876648
GaussianMLPValueFunction/LossAfter       6.69132
GaussianMLPValueFunction/LossBefore      6.69632
GaussianMLPValueFunction/dLoss           0.00499439
TotalEnvSteps                            1.1028e+06
-----------------------------------  --------------
2022-08-17 18:14:29 | [trpo_pendulum] epoch #919 | Saving snapshot...
2022-08-17 18:14:29 | [trpo_pendulum] epoch #919 | Saved
2022-08-17 18:14:29 | [trpo_pendulum] epoch #919 | Time 585.26 s
2022-08-17 18:14:29 | [trpo_pendulum] epoch #919 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -582.545
Evaluation/AverageReturn             -1498.33
Evaluation/Iteration                   919
Evaluation/MaxReturn                 -1481.92
Evaluation/MinReturn                 -1510.08
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     9.8223
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.33462
GaussianMLPPolicy/KL                     0.009791
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             19.5109
GaussianMLPPolicy/LossBefore            19.7871
GaussianMLPPolicy/dLoss                  0.276148
GaussianMLPValueFunction/LossAfter       6.63509
GaussianMLPValueFunction/LossBefore      6.63512
GaussianMLPValueFunction/dLoss           3.33786e-05
TotalEnvSteps                            1.104e+06
-----------------------------------  ---------------
2022-08-17 18:14:30 | [trpo_pendulum] epoch #920 | Saving snapshot...
2022-08-17 18:14:30 | [trpo_pendulum] epoch #920 | Saved
2022-08-17 18:14:30 | [trpo_pendulum] epoch #920 | Time 585.90 s
2022-08-17 18:14:30 | [trpo_pendulum] epoch #920 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -548.249
Evaluation/AverageReturn             -1357.93
Evaluation/Iteration                   920
Evaluation/MaxReturn                 -1225.63
Evaluation/MinReturn                 -1499.33
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   109.729
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.34689
GaussianMLPPolicy/KL                     0.00767203
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -5.35325
GaussianMLPPolicy/LossBefore            -3.4212
GaussianMLPPolicy/dLoss                  1.93206
GaussianMLPValueFunction/LossAfter       6.46737
GaussianMLPValueFunction/LossBefore      6.49652
GaussianMLPValueFunction/dLoss           0.029151
TotalEnvSteps                            1.1052e+06
-----------------------------------  --------------
2022-08-17 18:14:30 | [trpo_pendulum] epoch #921 | Saving snapshot...
2022-08-17 18:14:30 | [trpo_pendulum] epoch #921 | Saved
2022-08-17 18:14:30 | [trpo_pendulum] epoch #921 | Time 586.54 s
2022-08-17 18:14:30 | [trpo_pendulum] epoch #921 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -675.8
Evaluation/AverageReturn             -1534.85
Evaluation/Iteration                   921
Evaluation/MaxReturn                 -1512.04
Evaluation/MinReturn                 -1573.7
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    19.9234
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.34832
GaussianMLPPolicy/KL                     0.00701114
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              8.22882
GaussianMLPPolicy/LossBefore             9.9359
GaussianMLPPolicy/dLoss                  1.70709
GaussianMLPValueFunction/LossAfter       6.64721
GaussianMLPValueFunction/LossBefore      6.65096
GaussianMLPValueFunction/dLoss           0.00374556
TotalEnvSteps                            1.1064e+06
-----------------------------------  --------------
2022-08-17 18:14:31 | [trpo_pendulum] epoch #922 | Saving snapshot...
2022-08-17 18:14:31 | [trpo_pendulum] epoch #922 | Saved
2022-08-17 18:14:31 | [trpo_pendulum] epoch #922 | Time 587.19 s
2022-08-17 18:14:31 | [trpo_pendulum] epoch #922 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -526.376
Evaluation/AverageReturn             -1354.77
Evaluation/Iteration                   922
Evaluation/MaxReturn                 -1219.89
Evaluation/MinReturn                 -1468.01
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    99.0232
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.37585
GaussianMLPPolicy/KL                     0.0075312
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              5.2398
GaussianMLPPolicy/LossBefore             7.09965
GaussianMLPPolicy/dLoss                  1.85985
GaussianMLPValueFunction/LossAfter       6.50103
GaussianMLPValueFunction/LossBefore      6.51216
GaussianMLPValueFunction/dLoss           0.011126
TotalEnvSteps                            1.1076e+06
-----------------------------------  --------------
2022-08-17 18:14:32 | [trpo_pendulum] epoch #923 | Saving snapshot...
2022-08-17 18:14:32 | [trpo_pendulum] epoch #923 | Saved
2022-08-17 18:14:32 | [trpo_pendulum] epoch #923 | Time 587.84 s
2022-08-17 18:14:32 | [trpo_pendulum] epoch #923 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -500.141
Evaluation/AverageReturn             -1240.2
Evaluation/Iteration                   923
Evaluation/MaxReturn                 -1183.94
Evaluation/MinReturn                 -1392.98
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    70.0952
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.38601
GaussianMLPPolicy/KL                     0.00585934
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter            -22.2923
GaussianMLPPolicy/LossBefore           -21.6055
GaussianMLPPolicy/dLoss                  0.686796
GaussianMLPValueFunction/LossAfter       6.43807
GaussianMLPValueFunction/LossBefore      6.45584
GaussianMLPValueFunction/dLoss           0.0177755
TotalEnvSteps                            1.1088e+06
-----------------------------------  --------------
2022-08-17 18:14:32 | [trpo_pendulum] epoch #924 | Saving snapshot...
2022-08-17 18:14:32 | [trpo_pendulum] epoch #924 | Saved
2022-08-17 18:14:32 | [trpo_pendulum] epoch #924 | Time 588.48 s
2022-08-17 18:14:32 | [trpo_pendulum] epoch #924 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -663.862
Evaluation/AverageReturn             -1516.03
Evaluation/Iteration                   924
Evaluation/MaxReturn                 -1511.12
Evaluation/MinReturn                 -1526.07
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     5.37481
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.40949
GaussianMLPPolicy/KL                     0.00590118
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              9.43379
GaussianMLPPolicy/LossBefore            10.5023
GaussianMLPPolicy/dLoss                  1.06852
GaussianMLPValueFunction/LossAfter       6.63688
GaussianMLPValueFunction/LossBefore      6.6448
GaussianMLPValueFunction/dLoss           0.00791645
TotalEnvSteps                            1.11e+06
-----------------------------------  --------------
2022-08-17 18:14:33 | [trpo_pendulum] epoch #925 | Saving snapshot...
2022-08-17 18:14:33 | [trpo_pendulum] epoch #925 | Saved
2022-08-17 18:14:33 | [trpo_pendulum] epoch #925 | Time 589.11 s
2022-08-17 18:14:33 | [trpo_pendulum] epoch #925 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -572.684
Evaluation/AverageReturn             -1463.09
Evaluation/Iteration                   925
Evaluation/MaxReturn                 -1388.99
Evaluation/MinReturn                 -1513.06
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    40.5146
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.44782
GaussianMLPPolicy/KL                     0.00898451
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             58.1648
GaussianMLPPolicy/LossBefore            59.5079
GaussianMLPPolicy/dLoss                  1.34303
GaussianMLPValueFunction/LossAfter       6.58578
GaussianMLPValueFunction/LossBefore      6.75064
GaussianMLPValueFunction/dLoss           0.164863
TotalEnvSteps                            1.1112e+06
-----------------------------------  --------------
2022-08-17 18:14:33 | [trpo_pendulum] epoch #926 | Saving snapshot...
2022-08-17 18:14:34 | [trpo_pendulum] epoch #926 | Saved
2022-08-17 18:14:34 | [trpo_pendulum] epoch #926 | Time 589.78 s
2022-08-17 18:14:34 | [trpo_pendulum] epoch #926 | EpochTime 0.66 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -622.585
Evaluation/AverageReturn             -1533.04
Evaluation/Iteration                   926
Evaluation/MaxReturn                 -1502.52
Evaluation/MinReturn                 -1565
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    19.774
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.44456
GaussianMLPPolicy/KL                     0.00631572
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             35.5177
GaussianMLPPolicy/LossBefore            36.0424
GaussianMLPPolicy/dLoss                  0.524727
GaussianMLPValueFunction/LossAfter       6.64647
GaussianMLPValueFunction/LossBefore      6.65455
GaussianMLPValueFunction/dLoss           0.00808573
TotalEnvSteps                            1.1124e+06
-----------------------------------  --------------
2022-08-17 18:14:34 | [trpo_pendulum] epoch #927 | Saving snapshot...
2022-08-17 18:14:34 | [trpo_pendulum] epoch #927 | Saved
2022-08-17 18:14:34 | [trpo_pendulum] epoch #927 | Time 590.42 s
2022-08-17 18:14:34 | [trpo_pendulum] epoch #927 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -609.796
Evaluation/AverageReturn             -1523.95
Evaluation/Iteration                   927
Evaluation/MaxReturn                 -1424.82
Evaluation/MinReturn                 -1580.9
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    48.6624
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.44537
GaussianMLPPolicy/KL                     0.0059732
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             21.1198
GaussianMLPPolicy/LossBefore            21.6774
GaussianMLPPolicy/dLoss                  0.557556
GaussianMLPValueFunction/LossAfter       6.67717
GaussianMLPValueFunction/LossBefore      6.68104
GaussianMLPValueFunction/dLoss           0.00386667
TotalEnvSteps                            1.1136e+06
-----------------------------------  --------------
2022-08-17 18:14:35 | [trpo_pendulum] epoch #928 | Saving snapshot...
2022-08-17 18:14:35 | [trpo_pendulum] epoch #928 | Saved
2022-08-17 18:14:35 | [trpo_pendulum] epoch #928 | Time 591.05 s
2022-08-17 18:14:35 | [trpo_pendulum] epoch #928 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -648.713
Evaluation/AverageReturn             -1572.37
Evaluation/Iteration                   928
Evaluation/MaxReturn                 -1546.75
Evaluation/MinReturn                 -1588.73
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    13.8197
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.43134
GaussianMLPPolicy/KL                     0.00829326
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             25.9804
GaussianMLPPolicy/LossBefore            26.4299
GaussianMLPPolicy/dLoss                  0.449505
GaussianMLPValueFunction/LossAfter       6.71732
GaussianMLPValueFunction/LossBefore      6.72246
GaussianMLPValueFunction/dLoss           0.0051446
TotalEnvSteps                            1.1148e+06
-----------------------------------  --------------
2022-08-17 18:14:35 | [trpo_pendulum] epoch #929 | Saving snapshot...
2022-08-17 18:14:35 | [trpo_pendulum] epoch #929 | Saved
2022-08-17 18:14:35 | [trpo_pendulum] epoch #929 | Time 591.70 s
2022-08-17 18:14:35 | [trpo_pendulum] epoch #929 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -507.703
Evaluation/AverageReturn             -1305.51
Evaluation/Iteration                   929
Evaluation/MaxReturn                 -1067.72
Evaluation/MinReturn                 -1517.81
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   139.141
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.42699
GaussianMLPPolicy/KL                     0.00923807
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -8.1978
GaussianMLPPolicy/LossBefore            -6.95144
GaussianMLPPolicy/dLoss                  1.24635
GaussianMLPValueFunction/LossAfter       6.39881
GaussianMLPValueFunction/LossBefore      6.49904
GaussianMLPValueFunction/dLoss           0.100226
TotalEnvSteps                            1.116e+06
-----------------------------------  --------------
2022-08-17 18:14:36 | [trpo_pendulum] epoch #930 | Saving snapshot...
2022-08-17 18:14:36 | [trpo_pendulum] epoch #930 | Saved
2022-08-17 18:14:36 | [trpo_pendulum] epoch #930 | Time 592.34 s
2022-08-17 18:14:36 | [trpo_pendulum] epoch #930 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -605.512
Evaluation/AverageReturn             -1531.12
Evaluation/Iteration                   930
Evaluation/MaxReturn                 -1520.46
Evaluation/MinReturn                 -1538.58
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     5.44761
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.40877
GaussianMLPPolicy/KL                     0.00670836
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             24.9309
GaussianMLPPolicy/LossBefore            25.0983
GaussianMLPPolicy/dLoss                  0.167368
GaussianMLPValueFunction/LossAfter       6.69886
GaussianMLPValueFunction/LossBefore      6.70563
GaussianMLPValueFunction/dLoss           0.00676823
TotalEnvSteps                            1.1172e+06
-----------------------------------  --------------
2022-08-17 18:14:37 | [trpo_pendulum] epoch #931 | Saving snapshot...
2022-08-17 18:14:37 | [trpo_pendulum] epoch #931 | Saved
2022-08-17 18:14:37 | [trpo_pendulum] epoch #931 | Time 592.99 s
2022-08-17 18:14:37 | [trpo_pendulum] epoch #931 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -578.388
Evaluation/AverageReturn             -1486.38
Evaluation/Iteration                   931
Evaluation/MaxReturn                 -1418.55
Evaluation/MinReturn                 -1532.49
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    36.5035
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.41307
GaussianMLPPolicy/KL                     0.00714801
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             65.4849
GaussianMLPPolicy/LossBefore            67.1854
GaussianMLPPolicy/dLoss                  1.70051
GaussianMLPValueFunction/LossAfter       6.62084
GaussianMLPValueFunction/LossBefore      6.8106
GaussianMLPValueFunction/dLoss           0.189752
TotalEnvSteps                            1.1184e+06
-----------------------------------  --------------
2022-08-17 18:14:37 | [trpo_pendulum] epoch #932 | Saving snapshot...
2022-08-17 18:14:37 | [trpo_pendulum] epoch #932 | Saved
2022-08-17 18:14:37 | [trpo_pendulum] epoch #932 | Time 593.62 s
2022-08-17 18:14:37 | [trpo_pendulum] epoch #932 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -675.638
Evaluation/AverageReturn             -1537.53
Evaluation/Iteration                   932
Evaluation/MaxReturn                 -1520.13
Evaluation/MinReturn                 -1570.51
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    16.0806
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.40159
GaussianMLPPolicy/KL                     0.00681052
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              9.56875
GaussianMLPPolicy/LossBefore            11.006
GaussianMLPPolicy/dLoss                  1.43723
GaussianMLPValueFunction/LossAfter       6.65309
GaussianMLPValueFunction/LossBefore      6.65411
GaussianMLPValueFunction/dLoss           0.00101233
TotalEnvSteps                            1.1196e+06
-----------------------------------  --------------
2022-08-17 18:14:38 | [trpo_pendulum] epoch #933 | Saving snapshot...
2022-08-17 18:14:38 | [trpo_pendulum] epoch #933 | Saved
2022-08-17 18:14:38 | [trpo_pendulum] epoch #933 | Time 594.25 s
2022-08-17 18:14:38 | [trpo_pendulum] epoch #933 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -556.692
Evaluation/AverageReturn             -1428.8
Evaluation/Iteration                   933
Evaluation/MaxReturn                 -1399.21
Evaluation/MinReturn                 -1475.08
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    25.2771
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.40429
GaussianMLPPolicy/KL                     0.00990784
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             10.9996
GaussianMLPPolicy/LossBefore            13.1078
GaussianMLPPolicy/dLoss                  2.10824
GaussianMLPValueFunction/LossAfter       6.57891
GaussianMLPValueFunction/LossBefore      6.58592
GaussianMLPValueFunction/dLoss           0.00700569
TotalEnvSteps                            1.1208e+06
-----------------------------------  --------------
2022-08-17 18:14:39 | [trpo_pendulum] epoch #934 | Saving snapshot...
2022-08-17 18:14:39 | [trpo_pendulum] epoch #934 | Saved
2022-08-17 18:14:39 | [trpo_pendulum] epoch #934 | Time 594.88 s
2022-08-17 18:14:39 | [trpo_pendulum] epoch #934 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -521.682
Evaluation/AverageReturn             -1342.45
Evaluation/Iteration                   934
Evaluation/MaxReturn                  -983.887
Evaluation/MinReturn                 -1437.05
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   160.897
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.40602
GaussianMLPPolicy/KL                     0.00682452
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -3.35184
GaussianMLPPolicy/LossBefore            -1.8119
GaussianMLPPolicy/dLoss                  1.53994
GaussianMLPValueFunction/LossAfter       6.5447
GaussianMLPValueFunction/LossBefore      6.56059
GaussianMLPValueFunction/dLoss           0.015893
TotalEnvSteps                            1.122e+06
-----------------------------------  --------------
2022-08-17 18:14:39 | [trpo_pendulum] epoch #935 | Saving snapshot...
2022-08-17 18:14:39 | [trpo_pendulum] epoch #935 | Saved
2022-08-17 18:14:39 | [trpo_pendulum] epoch #935 | Time 595.51 s
2022-08-17 18:14:39 | [trpo_pendulum] epoch #935 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -549.33
Evaluation/AverageReturn             -1436.45
Evaluation/Iteration                   935
Evaluation/MaxReturn                 -1342.89
Evaluation/MinReturn                 -1525.46
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    70.4679
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.39408
GaussianMLPPolicy/KL                     0.00561861
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             49.4027
GaussianMLPPolicy/LossBefore            50.2938
GaussianMLPPolicy/dLoss                  0.89106
GaussianMLPValueFunction/LossAfter       6.55605
GaussianMLPValueFunction/LossBefore      6.64167
GaussianMLPValueFunction/dLoss           0.0856152
TotalEnvSteps                            1.1232e+06
-----------------------------------  --------------
2022-08-17 18:14:40 | [trpo_pendulum] epoch #936 | Saving snapshot...
2022-08-17 18:14:40 | [trpo_pendulum] epoch #936 | Saved
2022-08-17 18:14:40 | [trpo_pendulum] epoch #936 | Time 596.16 s
2022-08-17 18:14:40 | [trpo_pendulum] epoch #936 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -645.801
Evaluation/AverageReturn             -1492.97
Evaluation/Iteration                   936
Evaluation/MaxReturn                 -1491.44
Evaluation/MinReturn                 -1496.19
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     1.70099
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.39508
GaussianMLPPolicy/KL                     0.00854867
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              6.23006
GaussianMLPPolicy/LossBefore             6.67064
GaussianMLPPolicy/dLoss                  0.440578
GaussianMLPValueFunction/LossAfter       6.62413
GaussianMLPValueFunction/LossBefore      6.6265
GaussianMLPValueFunction/dLoss           0.00236797
TotalEnvSteps                            1.1244e+06
-----------------------------------  --------------
2022-08-17 18:14:41 | [trpo_pendulum] epoch #937 | Saving snapshot...
2022-08-17 18:14:41 | [trpo_pendulum] epoch #937 | Saved
2022-08-17 18:14:41 | [trpo_pendulum] epoch #937 | Time 596.80 s
2022-08-17 18:14:41 | [trpo_pendulum] epoch #937 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -643.952
Evaluation/AverageReturn             -1580.11
Evaluation/Iteration                   937
Evaluation/MaxReturn                 -1573.04
Evaluation/MinReturn                 -1585.25
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     4.14276
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.40925
GaussianMLPPolicy/KL                     0.00652604
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             27.8909
GaussianMLPPolicy/LossBefore            28.557
GaussianMLPPolicy/dLoss                  0.666103
GaussianMLPValueFunction/LossAfter       6.7349
GaussianMLPValueFunction/LossBefore      6.74744
GaussianMLPValueFunction/dLoss           0.0125408
TotalEnvSteps                            1.1256e+06
-----------------------------------  --------------
2022-08-17 18:14:41 | [trpo_pendulum] epoch #938 | Saving snapshot...
2022-08-17 18:14:41 | [trpo_pendulum] epoch #938 | Saved
2022-08-17 18:14:41 | [trpo_pendulum] epoch #938 | Time 597.45 s
2022-08-17 18:14:41 | [trpo_pendulum] epoch #938 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -613.531
Evaluation/AverageReturn             -1527.47
Evaluation/Iteration                   938
Evaluation/MaxReturn                 -1445.24
Evaluation/MinReturn                 -1556.67
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    38.7102
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.38206
GaussianMLPPolicy/KL                     0.00888701
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             21.0169
GaussianMLPPolicy/LossBefore            23
GaussianMLPPolicy/dLoss                  1.98313
GaussianMLPValueFunction/LossAfter       6.66666
GaussianMLPValueFunction/LossBefore      6.66719
GaussianMLPValueFunction/dLoss           0.000530243
TotalEnvSteps                            1.1268e+06
-----------------------------------  ---------------
2022-08-17 18:14:42 | [trpo_pendulum] epoch #939 | Saving snapshot...
2022-08-17 18:14:42 | [trpo_pendulum] epoch #939 | Saved
2022-08-17 18:14:42 | [trpo_pendulum] epoch #939 | Time 598.10 s
2022-08-17 18:14:42 | [trpo_pendulum] epoch #939 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -623.661
Evaluation/AverageReturn             -1549.12
Evaluation/Iteration                   939
Evaluation/MaxReturn                 -1536.97
Evaluation/MinReturn                 -1566.65
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     9.12033
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.39249
GaussianMLPPolicy/KL                     0.00760799
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             45.7719
GaussianMLPPolicy/LossBefore            46.7808
GaussianMLPPolicy/dLoss                  1.00895
GaussianMLPValueFunction/LossAfter       6.69793
GaussianMLPValueFunction/LossBefore      6.72924
GaussianMLPValueFunction/dLoss           0.0313144
TotalEnvSteps                            1.128e+06
-----------------------------------  --------------
2022-08-17 18:14:42 | [trpo_pendulum] epoch #940 | Saving snapshot...
2022-08-17 18:14:42 | [trpo_pendulum] epoch #940 | Saved
2022-08-17 18:14:42 | [trpo_pendulum] epoch #940 | Time 598.72 s
2022-08-17 18:14:42 | [trpo_pendulum] epoch #940 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -573.644
Evaluation/AverageReturn             -1444.76
Evaluation/Iteration                   940
Evaluation/MaxReturn                 -1390.42
Evaluation/MinReturn                 -1506.3
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    43.6522
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.38496
GaussianMLPPolicy/KL                     0.00717509
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              7.51539
GaussianMLPPolicy/LossBefore             9.26023
GaussianMLPPolicy/dLoss                  1.74484
GaussianMLPValueFunction/LossAfter       6.5096
GaussianMLPValueFunction/LossBefore      6.53939
GaussianMLPValueFunction/dLoss           0.0297866
TotalEnvSteps                            1.1292e+06
-----------------------------------  --------------
2022-08-17 18:14:43 | [trpo_pendulum] epoch #941 | Saving snapshot...
2022-08-17 18:14:43 | [trpo_pendulum] epoch #941 | Saved
2022-08-17 18:14:43 | [trpo_pendulum] epoch #941 | Time 599.36 s
2022-08-17 18:14:43 | [trpo_pendulum] epoch #941 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -609.319
Evaluation/AverageReturn             -1539.86
Evaluation/Iteration                   941
Evaluation/MaxReturn                 -1532.56
Evaluation/MinReturn                 -1549.4
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     5.40497
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.3744
GaussianMLPPolicy/KL                     0.00954934
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             49.4131
GaussianMLPPolicy/LossBefore            50.7507
GaussianMLPPolicy/dLoss                  1.33762
GaussianMLPValueFunction/LossAfter       6.69362
GaussianMLPValueFunction/LossBefore      6.74377
GaussianMLPValueFunction/dLoss           0.0501533
TotalEnvSteps                            1.1304e+06
-----------------------------------  --------------
2022-08-17 18:14:44 | [trpo_pendulum] epoch #942 | Saving snapshot...
2022-08-17 18:14:44 | [trpo_pendulum] epoch #942 | Saved
2022-08-17 18:14:44 | [trpo_pendulum] epoch #942 | Time 600.00 s
2022-08-17 18:14:44 | [trpo_pendulum] epoch #942 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -657.68
Evaluation/AverageReturn             -1516.63
Evaluation/Iteration                   942
Evaluation/MaxReturn                 -1420.85
Evaluation/MinReturn                 -1592.2
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    51.4626
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.36128
GaussianMLPPolicy/KL                     0.00729187
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              6.46889
GaussianMLPPolicy/LossBefore             8.29612
GaussianMLPPolicy/dLoss                  1.82722
GaussianMLPValueFunction/LossAfter       6.64735
GaussianMLPValueFunction/LossBefore      6.64809
GaussianMLPValueFunction/dLoss           0.000747204
TotalEnvSteps                            1.1316e+06
-----------------------------------  ---------------
2022-08-17 18:14:44 | [trpo_pendulum] epoch #943 | Saving snapshot...
2022-08-17 18:14:44 | [trpo_pendulum] epoch #943 | Saved
2022-08-17 18:14:44 | [trpo_pendulum] epoch #943 | Time 600.63 s
2022-08-17 18:14:44 | [trpo_pendulum] epoch #943 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -647.252
Evaluation/AverageReturn             -1575.24
Evaluation/Iteration                   943
Evaluation/MaxReturn                 -1556.23
Evaluation/MinReturn                 -1596.43
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    14.0177
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.38218
GaussianMLPPolicy/KL                     0.00677355
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             23.5364
GaussianMLPPolicy/LossBefore            25.0502
GaussianMLPPolicy/dLoss                  1.51384
GaussianMLPValueFunction/LossAfter       6.72144
GaussianMLPValueFunction/LossBefore      6.72504
GaussianMLPValueFunction/dLoss           0.00360394
TotalEnvSteps                            1.1328e+06
-----------------------------------  --------------
2022-08-17 18:14:45 | [trpo_pendulum] epoch #944 | Saving snapshot...
2022-08-17 18:14:45 | [trpo_pendulum] epoch #944 | Saved
2022-08-17 18:14:45 | [trpo_pendulum] epoch #944 | Time 601.27 s
2022-08-17 18:14:45 | [trpo_pendulum] epoch #944 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -563.157
Evaluation/AverageReturn             -1457.53
Evaluation/Iteration                   944
Evaluation/MaxReturn                 -1268.25
Evaluation/MinReturn                 -1544.57
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    90.5739
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.36728
GaussianMLPPolicy/KL                     0.00745358
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             13.8743
GaussianMLPPolicy/LossBefore            15.6986
GaussianMLPPolicy/dLoss                  1.82427
GaussianMLPValueFunction/LossAfter       6.6015
GaussianMLPValueFunction/LossBefore      6.6057
GaussianMLPValueFunction/dLoss           0.00419188
TotalEnvSteps                            1.134e+06
-----------------------------------  --------------
2022-08-17 18:14:46 | [trpo_pendulum] epoch #945 | Saving snapshot...
2022-08-17 18:14:46 | [trpo_pendulum] epoch #945 | Saved
2022-08-17 18:14:46 | [trpo_pendulum] epoch #945 | Time 601.92 s
2022-08-17 18:14:46 | [trpo_pendulum] epoch #945 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -651.478
Evaluation/AverageReturn             -1584.74
Evaluation/Iteration                   945
Evaluation/MaxReturn                 -1532.58
Evaluation/MinReturn                 -1625.35
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    27.6508
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.36145
GaussianMLPPolicy/KL                     0.00478189
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             25.2961
GaussianMLPPolicy/LossBefore            25.7668
GaussianMLPPolicy/dLoss                  0.47061
GaussianMLPValueFunction/LossAfter       6.71357
GaussianMLPValueFunction/LossBefore      6.71639
GaussianMLPValueFunction/dLoss           0.00281763
TotalEnvSteps                            1.1352e+06
-----------------------------------  --------------
2022-08-17 18:14:46 | [trpo_pendulum] epoch #946 | Saving snapshot...
2022-08-17 18:14:46 | [trpo_pendulum] epoch #946 | Saved
2022-08-17 18:14:46 | [trpo_pendulum] epoch #946 | Time 602.56 s
2022-08-17 18:14:46 | [trpo_pendulum] epoch #946 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -576.61
Evaluation/AverageReturn             -1483.56
Evaluation/Iteration                   946
Evaluation/MaxReturn                 -1408.87
Evaluation/MinReturn                 -1541.1
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    45.4821
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.36924
GaussianMLPPolicy/KL                     0.00927382
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             24.5541
GaussianMLPPolicy/LossBefore            24.9594
GaussianMLPPolicy/dLoss                  0.405283
GaussianMLPValueFunction/LossAfter       6.61124
GaussianMLPValueFunction/LossBefore      6.61468
GaussianMLPValueFunction/dLoss           0.00344181
TotalEnvSteps                            1.1364e+06
-----------------------------------  --------------
2022-08-17 18:14:47 | [trpo_pendulum] epoch #947 | Saving snapshot...
2022-08-17 18:14:47 | [trpo_pendulum] epoch #947 | Saved
2022-08-17 18:14:47 | [trpo_pendulum] epoch #947 | Time 603.19 s
2022-08-17 18:14:47 | [trpo_pendulum] epoch #947 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -559.661
Evaluation/AverageReturn             -1408.92
Evaluation/Iteration                   947
Evaluation/MaxReturn                 -1355.18
Evaluation/MinReturn                 -1492.4
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    52.2353
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.33186
GaussianMLPPolicy/KL                     0.00968281
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              1.44744
GaussianMLPPolicy/LossBefore             2.91718
GaussianMLPPolicy/dLoss                  1.46973
GaussianMLPValueFunction/LossAfter       6.49466
GaussianMLPValueFunction/LossBefore      6.51786
GaussianMLPValueFunction/dLoss           0.0231996
TotalEnvSteps                            1.1376e+06
-----------------------------------  --------------
2022-08-17 18:14:48 | [trpo_pendulum] epoch #948 | Saving snapshot...
2022-08-17 18:14:48 | [trpo_pendulum] epoch #948 | Saved
2022-08-17 18:14:48 | [trpo_pendulum] epoch #948 | Time 603.82 s
2022-08-17 18:14:48 | [trpo_pendulum] epoch #948 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -654.569
Evaluation/AverageReturn             -1603.92
Evaluation/Iteration                   948
Evaluation/MaxReturn                 -1599.4
Evaluation/MinReturn                 -1606.02
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     2.36455
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.32069
GaussianMLPPolicy/KL                     0.00628287
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             59.3838
GaussianMLPPolicy/LossBefore            60.4562
GaussianMLPPolicy/dLoss                  1.07237
GaussianMLPValueFunction/LossAfter       6.72087
GaussianMLPValueFunction/LossBefore      6.84109
GaussianMLPValueFunction/dLoss           0.120217
TotalEnvSteps                            1.1388e+06
-----------------------------------  --------------
2022-08-17 18:14:48 | [trpo_pendulum] epoch #949 | Saving snapshot...
2022-08-17 18:14:48 | [trpo_pendulum] epoch #949 | Saved
2022-08-17 18:14:48 | [trpo_pendulum] epoch #949 | Time 604.45 s
2022-08-17 18:14:48 | [trpo_pendulum] epoch #949 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -658.815
Evaluation/AverageReturn             -1517.82
Evaluation/Iteration                   949
Evaluation/MaxReturn                 -1501.48
Evaluation/MinReturn                 -1568.81
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    23.7557
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.30136
GaussianMLPPolicy/KL                     0.00791389
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              5.17664
GaussianMLPPolicy/LossBefore             7.22532
GaussianMLPPolicy/dLoss                  2.04868
GaussianMLPValueFunction/LossAfter       6.64901
GaussianMLPValueFunction/LossBefore      6.65008
GaussianMLPValueFunction/dLoss           0.00106907
TotalEnvSteps                            1.14e+06
-----------------------------------  --------------
2022-08-17 18:14:49 | [trpo_pendulum] epoch #950 | Saving snapshot...
2022-08-17 18:14:49 | [trpo_pendulum] epoch #950 | Saved
2022-08-17 18:14:49 | [trpo_pendulum] epoch #950 | Time 605.09 s
2022-08-17 18:14:49 | [trpo_pendulum] epoch #950 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -659.439
Evaluation/AverageReturn             -1505.78
Evaluation/Iteration                   950
Evaluation/MaxReturn                 -1373.24
Evaluation/MinReturn                 -1542.26
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    60.1342
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.30782
GaussianMLPPolicy/KL                     0.00816068
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              3.16942
GaussianMLPPolicy/LossBefore             5.60707
GaussianMLPPolicy/dLoss                  2.43765
GaussianMLPValueFunction/LossAfter       6.66602
GaussianMLPValueFunction/LossBefore      6.66794
GaussianMLPValueFunction/dLoss           0.00192356
TotalEnvSteps                            1.1412e+06
-----------------------------------  --------------
2022-08-17 18:14:49 | [trpo_pendulum] epoch #951 | Saving snapshot...
2022-08-17 18:14:49 | [trpo_pendulum] epoch #951 | Saved
2022-08-17 18:14:49 | [trpo_pendulum] epoch #951 | Time 605.71 s
2022-08-17 18:14:49 | [trpo_pendulum] epoch #951 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -628.95
Evaluation/AverageReturn             -1450.58
Evaluation/Iteration                   951
Evaluation/MaxReturn                 -1313.35
Evaluation/MinReturn                 -1560.17
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    94.1536
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.33309
GaussianMLPPolicy/KL                     0.00871351
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -4.48158
GaussianMLPPolicy/LossBefore            -1.13896
GaussianMLPPolicy/dLoss                  3.34261
GaussianMLPValueFunction/LossAfter       6.64388
GaussianMLPValueFunction/LossBefore      6.64626
GaussianMLPValueFunction/dLoss           0.00238705
TotalEnvSteps                            1.1424e+06
-----------------------------------  --------------
2022-08-17 18:14:50 | [trpo_pendulum] epoch #952 | Saving snapshot...
2022-08-17 18:14:50 | [trpo_pendulum] epoch #952 | Saved
2022-08-17 18:14:50 | [trpo_pendulum] epoch #952 | Time 606.34 s
2022-08-17 18:14:50 | [trpo_pendulum] epoch #952 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -639.724
Evaluation/AverageReturn             -1482.44
Evaluation/Iteration                   952
Evaluation/MaxReturn                 -1371.93
Evaluation/MinReturn                 -1516.54
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    50.2308
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.35822
GaussianMLPPolicy/KL                     0.00948428
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              1.70123
GaussianMLPPolicy/LossBefore             4.76082
GaussianMLPPolicy/dLoss                  3.05959
GaussianMLPValueFunction/LossAfter       6.60799
GaussianMLPValueFunction/LossBefore      6.61747
GaussianMLPValueFunction/dLoss           0.00948
TotalEnvSteps                            1.1436e+06
-----------------------------------  --------------
2022-08-17 18:14:51 | [trpo_pendulum] epoch #953 | Saving snapshot...
2022-08-17 18:14:51 | [trpo_pendulum] epoch #953 | Saved
2022-08-17 18:14:51 | [trpo_pendulum] epoch #953 | Time 606.97 s
2022-08-17 18:14:51 | [trpo_pendulum] epoch #953 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -580.973
Evaluation/AverageReturn             -1454.72
Evaluation/Iteration                   953
Evaluation/MaxReturn                 -1382.14
Evaluation/MinReturn                 -1615.02
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    78.701
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.33276
GaussianMLPPolicy/KL                     0.00922595
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             12.9016
GaussianMLPPolicy/LossBefore            14.1646
GaussianMLPPolicy/dLoss                  1.263
GaussianMLPValueFunction/LossAfter       6.6565
GaussianMLPValueFunction/LossBefore      6.66129
GaussianMLPValueFunction/dLoss           0.00479555
TotalEnvSteps                            1.1448e+06
-----------------------------------  --------------
2022-08-17 18:14:51 | [trpo_pendulum] epoch #954 | Saving snapshot...
2022-08-17 18:14:51 | [trpo_pendulum] epoch #954 | Saved
2022-08-17 18:14:51 | [trpo_pendulum] epoch #954 | Time 607.63 s
2022-08-17 18:14:51 | [trpo_pendulum] epoch #954 | EpochTime 0.66 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -564.676
Evaluation/AverageReturn             -1413.05
Evaluation/Iteration                   954
Evaluation/MaxReturn                 -1363.4
Evaluation/MinReturn                 -1507.58
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    50.3287
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.32185
GaussianMLPPolicy/KL                     0.00848383
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              3.58065
GaussianMLPPolicy/LossBefore             4.1033
GaussianMLPPolicy/dLoss                  0.522651
GaussianMLPValueFunction/LossAfter       6.59665
GaussianMLPValueFunction/LossBefore      6.60331
GaussianMLPValueFunction/dLoss           0.00666714
TotalEnvSteps                            1.146e+06
-----------------------------------  --------------
2022-08-17 18:14:52 | [trpo_pendulum] epoch #955 | Saving snapshot...
2022-08-17 18:14:52 | [trpo_pendulum] epoch #955 | Saved
2022-08-17 18:14:52 | [trpo_pendulum] epoch #955 | Time 608.26 s
2022-08-17 18:14:52 | [trpo_pendulum] epoch #955 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -594.945
Evaluation/AverageReturn             -1500.87
Evaluation/Iteration                   955
Evaluation/MaxReturn                 -1363.39
Evaluation/MinReturn                 -1548.05
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    70.7536
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.33925
GaussianMLPPolicy/KL                     0.00811361
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             28.3454
GaussianMLPPolicy/LossBefore            30.3761
GaussianMLPPolicy/dLoss                  2.03069
GaussianMLPValueFunction/LossAfter       6.69077
GaussianMLPValueFunction/LossBefore      6.70505
GaussianMLPValueFunction/dLoss           0.0142732
TotalEnvSteps                            1.1472e+06
-----------------------------------  --------------
2022-08-17 18:14:53 | [trpo_pendulum] epoch #956 | Saving snapshot...
2022-08-17 18:14:53 | [trpo_pendulum] epoch #956 | Saved
2022-08-17 18:14:53 | [trpo_pendulum] epoch #956 | Time 608.87 s
2022-08-17 18:14:53 | [trpo_pendulum] epoch #956 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -553.011
Evaluation/AverageReturn             -1415.01
Evaluation/Iteration                   956
Evaluation/MaxReturn                 -1153.93
Evaluation/MinReturn                 -1531.53
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   129.378
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.35605
GaussianMLPPolicy/KL                     0.00933678
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              5.67948
GaussianMLPPolicy/LossBefore             7.09671
GaussianMLPPolicy/dLoss                  1.41723
GaussianMLPValueFunction/LossAfter       6.59148
GaussianMLPValueFunction/LossBefore      6.6012
GaussianMLPValueFunction/dLoss           0.00972033
TotalEnvSteps                            1.1484e+06
-----------------------------------  --------------
2022-08-17 18:14:53 | [trpo_pendulum] epoch #957 | Saving snapshot...
2022-08-17 18:14:53 | [trpo_pendulum] epoch #957 | Saved
2022-08-17 18:14:53 | [trpo_pendulum] epoch #957 | Time 609.51 s
2022-08-17 18:14:53 | [trpo_pendulum] epoch #957 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -598.485
Evaluation/AverageReturn             -1446.85
Evaluation/Iteration                   957
Evaluation/MaxReturn                 -1341.29
Evaluation/MinReturn                 -1495.98
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    51.1715
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.35889
GaussianMLPPolicy/KL                     0.00601323
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              5.51587
GaussianMLPPolicy/LossBefore             6.51079
GaussianMLPPolicy/dLoss                  0.994919
GaussianMLPValueFunction/LossAfter       6.61727
GaussianMLPValueFunction/LossBefore      6.61837
GaussianMLPValueFunction/dLoss           0.00109863
TotalEnvSteps                            1.1496e+06
-----------------------------------  --------------
2022-08-17 18:14:54 | [trpo_pendulum] epoch #958 | Saving snapshot...
2022-08-17 18:14:54 | [trpo_pendulum] epoch #958 | Saved
2022-08-17 18:14:54 | [trpo_pendulum] epoch #958 | Time 610.16 s
2022-08-17 18:14:54 | [trpo_pendulum] epoch #958 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -559.699
Evaluation/AverageReturn             -1427.24
Evaluation/Iteration                   958
Evaluation/MaxReturn                 -1188.37
Evaluation/MinReturn                 -1570.86
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   129.129
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.39572
GaussianMLPPolicy/KL                     0.00776047
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             14.3334
GaussianMLPPolicy/LossBefore            15.7922
GaussianMLPPolicy/dLoss                  1.45886
GaussianMLPValueFunction/LossAfter       6.60659
GaussianMLPValueFunction/LossBefore      6.60853
GaussianMLPValueFunction/dLoss           0.00194025
TotalEnvSteps                            1.1508e+06
-----------------------------------  --------------
2022-08-17 18:14:54 | [trpo_pendulum] epoch #959 | Saving snapshot...
2022-08-17 18:14:55 | [trpo_pendulum] epoch #959 | Saved
2022-08-17 18:14:55 | [trpo_pendulum] epoch #959 | Time 610.79 s
2022-08-17 18:14:55 | [trpo_pendulum] epoch #959 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -583.965
Evaluation/AverageReturn             -1429.81
Evaluation/Iteration                   959
Evaluation/MaxReturn                 -1374.8
Evaluation/MinReturn                 -1483.89
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    44.4903
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.41102
GaussianMLPPolicy/KL                     0.00567092
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              6.46808
GaussianMLPPolicy/LossBefore             7.04607
GaussianMLPPolicy/dLoss                  0.577989
GaussianMLPValueFunction/LossAfter       6.62752
GaussianMLPValueFunction/LossBefore      6.62921
GaussianMLPValueFunction/dLoss           0.00168896
TotalEnvSteps                            1.152e+06
-----------------------------------  --------------
2022-08-17 18:14:55 | [trpo_pendulum] epoch #960 | Saving snapshot...
2022-08-17 18:14:55 | [trpo_pendulum] epoch #960 | Saved
2022-08-17 18:14:55 | [trpo_pendulum] epoch #960 | Time 611.43 s
2022-08-17 18:14:55 | [trpo_pendulum] epoch #960 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -594.865
Evaluation/AverageReturn             -1441.77
Evaluation/Iteration                   960
Evaluation/MaxReturn                 -1381.29
Evaluation/MinReturn                 -1498.75
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    39.6762
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.40558
GaussianMLPPolicy/KL                     0.00543181
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              6.27728
GaussianMLPPolicy/LossBefore             7.04899
GaussianMLPPolicy/dLoss                  0.771702
GaussianMLPValueFunction/LossAfter       6.60039
GaussianMLPValueFunction/LossBefore      6.60166
GaussianMLPValueFunction/dLoss           0.00126553
TotalEnvSteps                            1.1532e+06
-----------------------------------  --------------
2022-08-17 18:14:56 | [trpo_pendulum] epoch #961 | Saving snapshot...
2022-08-17 18:14:56 | [trpo_pendulum] epoch #961 | Saved
2022-08-17 18:14:56 | [trpo_pendulum] epoch #961 | Time 612.05 s
2022-08-17 18:14:56 | [trpo_pendulum] epoch #961 | EpochTime 0.62 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -674.541
Evaluation/AverageReturn             -1529.99
Evaluation/Iteration                   961
Evaluation/MaxReturn                 -1515.25
Evaluation/MinReturn                 -1551.83
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    14.4146
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.37353
GaussianMLPPolicy/KL                     0.0084339
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              9.87431
GaussianMLPPolicy/LossBefore            11.4188
GaussianMLPPolicy/dLoss                  1.54449
GaussianMLPValueFunction/LossAfter       6.63552
GaussianMLPValueFunction/LossBefore      6.63648
GaussianMLPValueFunction/dLoss           0.000951767
TotalEnvSteps                            1.1544e+06
-----------------------------------  ---------------
2022-08-17 18:14:56 | [trpo_pendulum] epoch #962 | Saving snapshot...
2022-08-17 18:14:56 | [trpo_pendulum] epoch #962 | Saved
2022-08-17 18:14:56 | [trpo_pendulum] epoch #962 | Time 612.71 s
2022-08-17 18:14:56 | [trpo_pendulum] epoch #962 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -591.77
Evaluation/AverageReturn             -1526.16
Evaluation/Iteration                   962
Evaluation/MaxReturn                 -1523.15
Evaluation/MinReturn                 -1530.66
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     2.66206
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.38976
GaussianMLPPolicy/KL                     0.0077445
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             42.0864
GaussianMLPPolicy/LossBefore            43.0418
GaussianMLPPolicy/dLoss                  0.955379
GaussianMLPValueFunction/LossAfter       6.69248
GaussianMLPValueFunction/LossBefore      6.71366
GaussianMLPValueFunction/dLoss           0.0211802
TotalEnvSteps                            1.1556e+06
-----------------------------------  --------------
2022-08-17 18:14:57 | [trpo_pendulum] epoch #963 | Saving snapshot...
2022-08-17 18:14:57 | [trpo_pendulum] epoch #963 | Saved
2022-08-17 18:14:57 | [trpo_pendulum] epoch #963 | Time 613.34 s
2022-08-17 18:14:57 | [trpo_pendulum] epoch #963 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -596.05
Evaluation/AverageReturn             -1527.45
Evaluation/Iteration                   963
Evaluation/MaxReturn                 -1524.45
Evaluation/MinReturn                 -1531.85
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     2.5343
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.39467
GaussianMLPPolicy/KL                     0.00667397
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             30.7315
GaussianMLPPolicy/LossBefore            31.6831
GaussianMLPPolicy/dLoss                  0.951632
GaussianMLPValueFunction/LossAfter       6.68568
GaussianMLPValueFunction/LossBefore      6.68895
GaussianMLPValueFunction/dLoss           0.00327539
TotalEnvSteps                            1.1568e+06
-----------------------------------  --------------
2022-08-17 18:14:58 | [trpo_pendulum] epoch #964 | Saving snapshot...
2022-08-17 18:14:58 | [trpo_pendulum] epoch #964 | Saved
2022-08-17 18:14:58 | [trpo_pendulum] epoch #964 | Time 613.99 s
2022-08-17 18:14:58 | [trpo_pendulum] epoch #964 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -644.263
Evaluation/AverageReturn             -1496.41
Evaluation/Iteration                   964
Evaluation/MaxReturn                 -1493.97
Evaluation/MinReturn                 -1498.46
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     1.54427
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.42512
GaussianMLPPolicy/KL                     0.00678367
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              7.72336
GaussianMLPPolicy/LossBefore             9.043
GaussianMLPPolicy/dLoss                  1.31965
GaussianMLPValueFunction/LossAfter       6.62425
GaussianMLPValueFunction/LossBefore      6.62611
GaussianMLPValueFunction/dLoss           0.00185633
TotalEnvSteps                            1.158e+06
-----------------------------------  --------------
2022-08-17 18:14:58 | [trpo_pendulum] epoch #965 | Saving snapshot...
2022-08-17 18:14:58 | [trpo_pendulum] epoch #965 | Saved
2022-08-17 18:14:58 | [trpo_pendulum] epoch #965 | Time 614.64 s
2022-08-17 18:14:58 | [trpo_pendulum] epoch #965 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -648.163
Evaluation/AverageReturn             -1493.03
Evaluation/Iteration                   965
Evaluation/MaxReturn                 -1491.74
Evaluation/MinReturn                 -1496.41
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     1.54558
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.44181
GaussianMLPPolicy/KL                     0.00573017
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              6.7136
GaussianMLPPolicy/LossBefore             7.68575
GaussianMLPPolicy/dLoss                  0.972149
GaussianMLPValueFunction/LossAfter       6.62312
GaussianMLPValueFunction/LossBefore      6.62448
GaussianMLPValueFunction/dLoss           0.00136471
TotalEnvSteps                            1.1592e+06
-----------------------------------  --------------
2022-08-17 18:14:59 | [trpo_pendulum] epoch #966 | Saving snapshot...
2022-08-17 18:14:59 | [trpo_pendulum] epoch #966 | Saved
2022-08-17 18:14:59 | [trpo_pendulum] epoch #966 | Time 615.30 s
2022-08-17 18:14:59 | [trpo_pendulum] epoch #966 | EpochTime 0.66 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -590.676
Evaluation/AverageReturn             -1447.9
Evaluation/Iteration                   966
Evaluation/MaxReturn                 -1361.02
Evaluation/MinReturn                 -1518.16
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    58.6119
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.45472
GaussianMLPPolicy/KL                     0.00659692
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              6.35544
GaussianMLPPolicy/LossBefore             7.83949
GaussianMLPPolicy/dLoss                  1.48405
GaussianMLPValueFunction/LossAfter       6.54128
GaussianMLPValueFunction/LossBefore      6.55546
GaussianMLPValueFunction/dLoss           0.0141797
TotalEnvSteps                            1.1604e+06
-----------------------------------  --------------
2022-08-17 18:15:00 | [trpo_pendulum] epoch #967 | Saving snapshot...
2022-08-17 18:15:00 | [trpo_pendulum] epoch #967 | Saved
2022-08-17 18:15:00 | [trpo_pendulum] epoch #967 | Time 615.95 s
2022-08-17 18:15:00 | [trpo_pendulum] epoch #967 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -654.977
Evaluation/AverageReturn             -1502.89
Evaluation/Iteration                   967
Evaluation/MaxReturn                 -1495.67
Evaluation/MinReturn                 -1510.52
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     5.02868
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.46811
GaussianMLPPolicy/KL                     0.00757541
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              8.56415
GaussianMLPPolicy/LossBefore             9.23725
GaussianMLPPolicy/dLoss                  0.673107
GaussianMLPValueFunction/LossAfter       6.62291
GaussianMLPValueFunction/LossBefore      6.62406
GaussianMLPValueFunction/dLoss           0.00114155
TotalEnvSteps                            1.1616e+06
-----------------------------------  --------------
2022-08-17 18:15:00 | [trpo_pendulum] epoch #968 | Saving snapshot...
2022-08-17 18:15:00 | [trpo_pendulum] epoch #968 | Saved
2022-08-17 18:15:00 | [trpo_pendulum] epoch #968 | Time 616.59 s
2022-08-17 18:15:00 | [trpo_pendulum] epoch #968 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -633.223
Evaluation/AverageReturn             -1564.78
Evaluation/Iteration                   968
Evaluation/MaxReturn                 -1519.21
Evaluation/MinReturn                 -1617.92
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    34.1458
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.48564
GaussianMLPPolicy/KL                     0.00852256
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             59.1377
GaussianMLPPolicy/LossBefore            59.9026
GaussianMLPPolicy/dLoss                  0.764862
GaussianMLPValueFunction/LossAfter       6.69071
GaussianMLPValueFunction/LossBefore      6.79667
GaussianMLPValueFunction/dLoss           0.105962
TotalEnvSteps                            1.1628e+06
-----------------------------------  --------------
2022-08-17 18:15:01 | [trpo_pendulum] epoch #969 | Saving snapshot...
2022-08-17 18:15:01 | [trpo_pendulum] epoch #969 | Saved
2022-08-17 18:15:01 | [trpo_pendulum] epoch #969 | Time 617.25 s
2022-08-17 18:15:01 | [trpo_pendulum] epoch #969 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -550.799
Evaluation/AverageReturn             -1408.02
Evaluation/Iteration                   969
Evaluation/MaxReturn                 -1300.58
Evaluation/MinReturn                 -1506.7
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    73.9489
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.47221
GaussianMLPPolicy/KL                     0.00865191
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              5.09404
GaussianMLPPolicy/LossBefore             6.34685
GaussianMLPPolicy/dLoss                  1.25282
GaussianMLPValueFunction/LossAfter       6.56461
GaussianMLPValueFunction/LossBefore      6.57139
GaussianMLPValueFunction/dLoss           0.00678158
TotalEnvSteps                            1.164e+06
-----------------------------------  --------------
2022-08-17 18:15:02 | [trpo_pendulum] epoch #970 | Saving snapshot...
2022-08-17 18:15:02 | [trpo_pendulum] epoch #970 | Saved
2022-08-17 18:15:02 | [trpo_pendulum] epoch #970 | Time 617.90 s
2022-08-17 18:15:02 | [trpo_pendulum] epoch #970 | EpochTime 0.65 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -667.59
Evaluation/AverageReturn             -1528.98
Evaluation/Iteration                   970
Evaluation/MaxReturn                 -1511.01
Evaluation/MinReturn                 -1558.37
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    15.6375
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.45384
GaussianMLPPolicy/KL                     0.00810133
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             11.4756
GaussianMLPPolicy/LossBefore            13.2351
GaussianMLPPolicy/dLoss                  1.75946
GaussianMLPValueFunction/LossAfter       6.64223
GaussianMLPValueFunction/LossBefore      6.64309
GaussianMLPValueFunction/dLoss           0.000854969
TotalEnvSteps                            1.1652e+06
-----------------------------------  ---------------
2022-08-17 18:15:02 | [trpo_pendulum] epoch #971 | Saving snapshot...
2022-08-17 18:15:02 | [trpo_pendulum] epoch #971 | Saved
2022-08-17 18:15:02 | [trpo_pendulum] epoch #971 | Time 618.54 s
2022-08-17 18:15:02 | [trpo_pendulum] epoch #971 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -613.513
Evaluation/AverageReturn             -1462.49
Evaluation/Iteration                   971
Evaluation/MaxReturn                 -1389.25
Evaluation/MinReturn                 -1515.25
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    43.9202
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.45904
GaussianMLPPolicy/KL                     0.00719448
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              5.26032
GaussianMLPPolicy/LossBefore             7.71423
GaussianMLPPolicy/dLoss                  2.45391
GaussianMLPValueFunction/LossAfter       6.59047
GaussianMLPValueFunction/LossBefore      6.59189
GaussianMLPValueFunction/dLoss           0.00142193
TotalEnvSteps                            1.1664e+06
-----------------------------------  --------------
2022-08-17 18:15:03 | [trpo_pendulum] epoch #972 | Saving snapshot...
2022-08-17 18:15:03 | [trpo_pendulum] epoch #972 | Saved
2022-08-17 18:15:03 | [trpo_pendulum] epoch #972 | Time 619.19 s
2022-08-17 18:15:03 | [trpo_pendulum] epoch #972 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -645.621
Evaluation/AverageReturn             -1491.44
Evaluation/Iteration                   972
Evaluation/MaxReturn                 -1490.89
Evaluation/MinReturn                 -1493.94
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     1.12003
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.45471
GaussianMLPPolicy/KL                     0.00446471
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              8.52692
GaussianMLPPolicy/LossBefore             9.44995
GaussianMLPPolicy/dLoss                  0.923033
GaussianMLPValueFunction/LossAfter       6.6171
GaussianMLPValueFunction/LossBefore      6.61782
GaussianMLPValueFunction/dLoss           0.000720024
TotalEnvSteps                            1.1676e+06
-----------------------------------  ---------------
2022-08-17 18:15:04 | [trpo_pendulum] epoch #973 | Saving snapshot...
2022-08-17 18:15:04 | [trpo_pendulum] epoch #973 | Saved
2022-08-17 18:15:04 | [trpo_pendulum] epoch #973 | Time 619.84 s
2022-08-17 18:15:04 | [trpo_pendulum] epoch #973 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -661.936
Evaluation/AverageReturn             -1559.63
Evaluation/Iteration                   973
Evaluation/MaxReturn                 -1509.69
Evaluation/MinReturn                 -1586.78
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    25.9261
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.49239
GaussianMLPPolicy/KL                     0.00632428
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             21.6653
GaussianMLPPolicy/LossBefore            22.9026
GaussianMLPPolicy/dLoss                  1.23733
GaussianMLPValueFunction/LossAfter       6.68712
GaussianMLPValueFunction/LossBefore      6.69089
GaussianMLPValueFunction/dLoss           0.00376892
TotalEnvSteps                            1.1688e+06
-----------------------------------  --------------
2022-08-17 18:15:04 | [trpo_pendulum] epoch #974 | Saving snapshot...
2022-08-17 18:15:04 | [trpo_pendulum] epoch #974 | Saved
2022-08-17 18:15:04 | [trpo_pendulum] epoch #974 | Time 620.47 s
2022-08-17 18:15:04 | [trpo_pendulum] epoch #974 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -605.393
Evaluation/AverageReturn             -1526.97
Evaluation/Iteration                   974
Evaluation/MaxReturn                 -1513.18
Evaluation/MinReturn                 -1555.95
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    14.3643
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.5049
GaussianMLPPolicy/KL                     0.00778588
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             36.4853
GaussianMLPPolicy/LossBefore            37.6029
GaussianMLPPolicy/dLoss                  1.11766
GaussianMLPValueFunction/LossAfter       6.66578
GaussianMLPValueFunction/LossBefore      6.67214
GaussianMLPValueFunction/dLoss           0.00636482
TotalEnvSteps                            1.17e+06
-----------------------------------  --------------
2022-08-17 18:15:05 | [trpo_pendulum] epoch #975 | Saving snapshot...
2022-08-17 18:15:05 | [trpo_pendulum] epoch #975 | Saved
2022-08-17 18:15:05 | [trpo_pendulum] epoch #975 | Time 621.12 s
2022-08-17 18:15:05 | [trpo_pendulum] epoch #975 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -645.368
Evaluation/AverageReturn             -1495.13
Evaluation/Iteration                   975
Evaluation/MaxReturn                 -1493.8
Evaluation/MinReturn                 -1496.93
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     0.994438
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.51343
GaussianMLPPolicy/KL                     0.00888793
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              8.99625
GaussianMLPPolicy/LossBefore            10.132
GaussianMLPPolicy/dLoss                  1.13575
GaussianMLPValueFunction/LossAfter       6.62113
GaussianMLPValueFunction/LossBefore      6.62233
GaussianMLPValueFunction/dLoss           0.00120354
TotalEnvSteps                            1.1712e+06
-----------------------------------  --------------
2022-08-17 18:15:05 | [trpo_pendulum] epoch #976 | Saving snapshot...
2022-08-17 18:15:05 | [trpo_pendulum] epoch #976 | Saved
2022-08-17 18:15:05 | [trpo_pendulum] epoch #976 | Time 621.75 s
2022-08-17 18:15:05 | [trpo_pendulum] epoch #976 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -555.693
Evaluation/AverageReturn             -1444.4
Evaluation/Iteration                   976
Evaluation/MaxReturn                 -1370.49
Evaluation/MinReturn                 -1505.19
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    48.2104
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.54121
GaussianMLPPolicy/KL                     0.00880433
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             14.6239
GaussianMLPPolicy/LossBefore            16.0786
GaussianMLPPolicy/dLoss                  1.45477
GaussianMLPValueFunction/LossAfter       6.56472
GaussianMLPValueFunction/LossBefore      6.57597
GaussianMLPValueFunction/dLoss           0.0112462
TotalEnvSteps                            1.1724e+06
-----------------------------------  --------------
2022-08-17 18:15:06 | [trpo_pendulum] epoch #977 | Saving snapshot...
2022-08-17 18:15:06 | [trpo_pendulum] epoch #977 | Saved
2022-08-17 18:15:06 | [trpo_pendulum] epoch #977 | Time 622.38 s
2022-08-17 18:15:06 | [trpo_pendulum] epoch #977 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -538.762
Evaluation/AverageReturn             -1438.49
Evaluation/Iteration                   977
Evaluation/MaxReturn                 -1409.33
Evaluation/MinReturn                 -1478.98
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    24.5071
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.53354
GaussianMLPPolicy/KL                     0.00620965
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             19.8153
GaussianMLPPolicy/LossBefore            21.0916
GaussianMLPPolicy/dLoss                  1.27623
GaussianMLPValueFunction/LossAfter       6.64957
GaussianMLPValueFunction/LossBefore      6.65124
GaussianMLPValueFunction/dLoss           0.00167084
TotalEnvSteps                            1.1736e+06
-----------------------------------  --------------
2022-08-17 18:15:07 | [trpo_pendulum] epoch #978 | Saving snapshot...
2022-08-17 18:15:07 | [trpo_pendulum] epoch #978 | Saved
2022-08-17 18:15:07 | [trpo_pendulum] epoch #978 | Time 623.03 s
2022-08-17 18:15:07 | [trpo_pendulum] epoch #978 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -601.975
Evaluation/AverageReturn             -1498.27
Evaluation/Iteration                   978
Evaluation/MaxReturn                 -1430.61
Evaluation/MinReturn                 -1521.28
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    32.1209
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.53057
GaussianMLPPolicy/KL                     0.00950741
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             15.5626
GaussianMLPPolicy/LossBefore            17.0084
GaussianMLPPolicy/dLoss                  1.44587
GaussianMLPValueFunction/LossAfter       6.60938
GaussianMLPValueFunction/LossBefore      6.60956
GaussianMLPValueFunction/dLoss           0.000179768
TotalEnvSteps                            1.1748e+06
-----------------------------------  ---------------
2022-08-17 18:15:07 | [trpo_pendulum] epoch #979 | Saving snapshot...
2022-08-17 18:15:07 | [trpo_pendulum] epoch #979 | Saved
2022-08-17 18:15:07 | [trpo_pendulum] epoch #979 | Time 623.68 s
2022-08-17 18:15:07 | [trpo_pendulum] epoch #979 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -644.606
Evaluation/AverageReturn             -1562.56
Evaluation/Iteration                   979
Evaluation/MaxReturn                 -1533.98
Evaluation/MinReturn                 -1598.14
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    22.8947
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.53648
GaussianMLPPolicy/KL                     0.00564148
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             25.6644
GaussianMLPPolicy/LossBefore            26.1726
GaussianMLPPolicy/dLoss                  0.508221
GaussianMLPValueFunction/LossAfter       6.70013
GaussianMLPValueFunction/LossBefore      6.70487
GaussianMLPValueFunction/dLoss           0.00473833
TotalEnvSteps                            1.176e+06
-----------------------------------  --------------
2022-08-17 18:15:08 | [trpo_pendulum] epoch #980 | Saving snapshot...
2022-08-17 18:15:08 | [trpo_pendulum] epoch #980 | Saved
2022-08-17 18:15:08 | [trpo_pendulum] epoch #980 | Time 624.34 s
2022-08-17 18:15:08 | [trpo_pendulum] epoch #980 | EpochTime 0.66 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -485.484
Evaluation/AverageReturn             -1390.88
Evaluation/Iteration                   980
Evaluation/MaxReturn                 -1388.8
Evaluation/MinReturn                 -1392.6
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     1.37294
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.54229
GaussianMLPPolicy/KL                     0.00698081
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             29.7453
GaussianMLPPolicy/LossBefore            30.0912
GaussianMLPPolicy/dLoss                  0.345875
GaussianMLPValueFunction/LossAfter       6.62059
GaussianMLPValueFunction/LossBefore      6.62852
GaussianMLPValueFunction/dLoss           0.00792313
TotalEnvSteps                            1.1772e+06
-----------------------------------  --------------
2022-08-17 18:15:09 | [trpo_pendulum] epoch #981 | Saving snapshot...
2022-08-17 18:15:09 | [trpo_pendulum] epoch #981 | Saved
2022-08-17 18:15:09 | [trpo_pendulum] epoch #981 | Time 624.97 s
2022-08-17 18:15:09 | [trpo_pendulum] epoch #981 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -684.357
Evaluation/AverageReturn             -1620.79
Evaluation/Iteration                   981
Evaluation/MaxReturn                 -1589.86
Evaluation/MinReturn                 -1643.89
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    19.2792
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.60979
GaussianMLPPolicy/KL                     0.00764624
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             27.9773
GaussianMLPPolicy/LossBefore            29.7297
GaussianMLPPolicy/dLoss                  1.75243
GaussianMLPValueFunction/LossAfter       6.70195
GaussianMLPValueFunction/LossBefore      6.70508
GaussianMLPValueFunction/dLoss           0.00313139
TotalEnvSteps                            1.1784e+06
-----------------------------------  --------------
2022-08-17 18:15:09 | [trpo_pendulum] epoch #982 | Saving snapshot...
2022-08-17 18:15:09 | [trpo_pendulum] epoch #982 | Saved
2022-08-17 18:15:09 | [trpo_pendulum] epoch #982 | Time 625.62 s
2022-08-17 18:15:09 | [trpo_pendulum] epoch #982 | EpochTime 0.64 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -638.027
Evaluation/AverageReturn             -1534.3
Evaluation/Iteration                   982
Evaluation/MaxReturn                 -1524.91
Evaluation/MinReturn                 -1562
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    12.6132
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.59794
GaussianMLPPolicy/KL                     0.00774923
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             18.6575
GaussianMLPPolicy/LossBefore            18.993
GaussianMLPPolicy/dLoss                  0.335411
GaussianMLPValueFunction/LossAfter       6.68295
GaussianMLPValueFunction/LossBefore      6.68312
GaussianMLPValueFunction/dLoss           0.000169277
TotalEnvSteps                            1.1796e+06
-----------------------------------  ---------------
2022-08-17 18:15:10 | [trpo_pendulum] epoch #983 | Saving snapshot...
2022-08-17 18:15:10 | [trpo_pendulum] epoch #983 | Saved
2022-08-17 18:15:10 | [trpo_pendulum] epoch #983 | Time 626.27 s
2022-08-17 18:15:10 | [trpo_pendulum] epoch #983 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -587.499
Evaluation/AverageReturn             -1486.98
Evaluation/Iteration                   983
Evaluation/MaxReturn                 -1427.91
Evaluation/MinReturn                 -1517.01
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    29.3493
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.59802
GaussianMLPPolicy/KL                     0.00568654
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             15.3764
GaussianMLPPolicy/LossBefore            15.567
GaussianMLPPolicy/dLoss                  0.190669
GaussianMLPValueFunction/LossAfter       6.61174
GaussianMLPValueFunction/LossBefore      6.61439
GaussianMLPValueFunction/dLoss           0.00265074
TotalEnvSteps                            1.1808e+06
-----------------------------------  --------------
2022-08-17 18:15:11 | [trpo_pendulum] epoch #984 | Saving snapshot...
2022-08-17 18:15:11 | [trpo_pendulum] epoch #984 | Saved
2022-08-17 18:15:11 | [trpo_pendulum] epoch #984 | Time 626.91 s
2022-08-17 18:15:11 | [trpo_pendulum] epoch #984 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -664.821
Evaluation/AverageReturn             -1592.67
Evaluation/Iteration                   984
Evaluation/MaxReturn                 -1563.58
Evaluation/MinReturn                 -1612.69
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    16.1188
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.60084
GaussianMLPPolicy/KL                     0.00361122
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             26.7311
GaussianMLPPolicy/LossBefore            26.7474
GaussianMLPPolicy/dLoss                  0.0163841
GaussianMLPValueFunction/LossAfter       6.68542
GaussianMLPValueFunction/LossBefore      6.68671
GaussianMLPValueFunction/dLoss           0.00129318
TotalEnvSteps                            1.182e+06
-----------------------------------  --------------
2022-08-17 18:15:11 | [trpo_pendulum] epoch #985 | Saving snapshot...
2022-08-17 18:15:11 | [trpo_pendulum] epoch #985 | Saved
2022-08-17 18:15:11 | [trpo_pendulum] epoch #985 | Time 627.57 s
2022-08-17 18:15:11 | [trpo_pendulum] epoch #985 | EpochTime 0.66 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -643.597
Evaluation/AverageReturn             -1559.69
Evaluation/Iteration                   985
Evaluation/MaxReturn                 -1536.54
Evaluation/MinReturn                 -1588.33
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    15.1607
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.61239
GaussianMLPPolicy/KL                     0.00642968
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             23.5347
GaussianMLPPolicy/LossBefore            24.2529
GaussianMLPPolicy/dLoss                  0.71818
GaussianMLPValueFunction/LossAfter       6.70783
GaussianMLPValueFunction/LossBefore      6.70929
GaussianMLPValueFunction/dLoss           0.00145721
TotalEnvSteps                            1.1832e+06
-----------------------------------  --------------
2022-08-17 18:15:12 | [trpo_pendulum] epoch #986 | Saving snapshot...
2022-08-17 18:15:12 | [trpo_pendulum] epoch #986 | Saved
2022-08-17 18:15:12 | [trpo_pendulum] epoch #986 | Time 628.21 s
2022-08-17 18:15:12 | [trpo_pendulum] epoch #986 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -649.894
Evaluation/AverageReturn             -1590.61
Evaluation/Iteration                   986
Evaluation/MaxReturn                 -1581.21
Evaluation/MinReturn                 -1605.55
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     8.06072
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.61024
GaussianMLPPolicy/KL                     0.00927847
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             38.2069
GaussianMLPPolicy/LossBefore            39.6691
GaussianMLPPolicy/dLoss                  1.46224
GaussianMLPValueFunction/LossAfter       6.71621
GaussianMLPValueFunction/LossBefore      6.7294
GaussianMLPValueFunction/dLoss           0.0131879
TotalEnvSteps                            1.1844e+06
-----------------------------------  --------------
2022-08-17 18:15:13 | [trpo_pendulum] epoch #987 | Saving snapshot...
2022-08-17 18:15:13 | [trpo_pendulum] epoch #987 | Saved
2022-08-17 18:15:13 | [trpo_pendulum] epoch #987 | Time 628.86 s
2022-08-17 18:15:13 | [trpo_pendulum] epoch #987 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -620.125
Evaluation/AverageReturn             -1529.35
Evaluation/Iteration                   987
Evaluation/MaxReturn                 -1515.12
Evaluation/MinReturn                 -1542
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     9.94651
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.60729
GaussianMLPPolicy/KL                     0.00548008
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             19.2283
GaussianMLPPolicy/LossBefore            19.3706
GaussianMLPPolicy/dLoss                  0.142242
GaussianMLPValueFunction/LossAfter       6.63619
GaussianMLPValueFunction/LossBefore      6.66371
GaussianMLPValueFunction/dLoss           0.0275202
TotalEnvSteps                            1.1856e+06
-----------------------------------  --------------
2022-08-17 18:15:13 | [trpo_pendulum] epoch #988 | Saving snapshot...
2022-08-17 18:15:13 | [trpo_pendulum] epoch #988 | Saved
2022-08-17 18:15:13 | [trpo_pendulum] epoch #988 | Time 629.51 s
2022-08-17 18:15:13 | [trpo_pendulum] epoch #988 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -642.283
Evaluation/AverageReturn             -1495.95
Evaluation/Iteration                   988
Evaluation/MaxReturn                 -1404.97
Evaluation/MinReturn                 -1537.71
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    44.3349
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.6099
GaussianMLPPolicy/KL                     0.00946863
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              3.08927
GaussianMLPPolicy/LossBefore             6.51975
GaussianMLPPolicy/dLoss                  3.43048
GaussianMLPValueFunction/LossAfter       6.6014
GaussianMLPValueFunction/LossBefore      6.60583
GaussianMLPValueFunction/dLoss           0.00443125
TotalEnvSteps                            1.1868e+06
-----------------------------------  --------------
2022-08-17 18:15:14 | [trpo_pendulum] epoch #989 | Saving snapshot...
2022-08-17 18:15:14 | [trpo_pendulum] epoch #989 | Saved
2022-08-17 18:15:14 | [trpo_pendulum] epoch #989 | Time 630.14 s
2022-08-17 18:15:14 | [trpo_pendulum] epoch #989 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -611.738
Evaluation/AverageReturn             -1535.5
Evaluation/Iteration                   989
Evaluation/MaxReturn                 -1524.13
Evaluation/MinReturn                 -1549.13
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     7.49908
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.60927
GaussianMLPPolicy/KL                     0.00466909
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             42.1438
GaussianMLPPolicy/LossBefore            42.3397
GaussianMLPPolicy/dLoss                  0.195892
GaussianMLPValueFunction/LossAfter       6.70727
GaussianMLPValueFunction/LossBefore      6.73103
GaussianMLPValueFunction/dLoss           0.0237551
TotalEnvSteps                            1.188e+06
-----------------------------------  --------------
2022-08-17 18:15:14 | [trpo_pendulum] epoch #990 | Saving snapshot...
2022-08-17 18:15:15 | [trpo_pendulum] epoch #990 | Saved
2022-08-17 18:15:15 | [trpo_pendulum] epoch #990 | Time 630.78 s
2022-08-17 18:15:15 | [trpo_pendulum] epoch #990 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -590.328
Evaluation/AverageReturn             -1488.44
Evaluation/Iteration                   990
Evaluation/MaxReturn                 -1383
Evaluation/MinReturn                 -1525.39
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    48.792
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.62945
GaussianMLPPolicy/KL                     0.00794753
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             12.7579
GaussianMLPPolicy/LossBefore            14.1995
GaussianMLPPolicy/dLoss                  1.4416
GaussianMLPValueFunction/LossAfter       6.62357
GaussianMLPValueFunction/LossBefore      6.6255
GaussianMLPValueFunction/dLoss           0.00193405
TotalEnvSteps                            1.1892e+06
-----------------------------------  --------------
2022-08-17 18:15:15 | [trpo_pendulum] epoch #991 | Saving snapshot...
2022-08-17 18:15:15 | [trpo_pendulum] epoch #991 | Saved
2022-08-17 18:15:15 | [trpo_pendulum] epoch #991 | Time 631.39 s
2022-08-17 18:15:15 | [trpo_pendulum] epoch #991 | EpochTime 0.61 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -647.686
Evaluation/AverageReturn             -1495.88
Evaluation/Iteration                   991
Evaluation/MaxReturn                 -1491.81
Evaluation/MinReturn                 -1503.19
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     4.41135
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.64955
GaussianMLPPolicy/KL                     0.00955788
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              4.53449
GaussianMLPPolicy/LossBefore             6.45742
GaussianMLPPolicy/dLoss                  1.92292
GaussianMLPValueFunction/LossAfter       6.62897
GaussianMLPValueFunction/LossBefore      6.63044
GaussianMLPValueFunction/dLoss           0.001472
TotalEnvSteps                            1.1904e+06
-----------------------------------  --------------
2022-08-17 18:15:16 | [trpo_pendulum] epoch #992 | Saving snapshot...
2022-08-17 18:15:16 | [trpo_pendulum] epoch #992 | Saved
2022-08-17 18:15:16 | [trpo_pendulum] epoch #992 | Time 632.03 s
2022-08-17 18:15:16 | [trpo_pendulum] epoch #992 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -672.335
Evaluation/AverageReturn             -1541.23
Evaluation/Iteration                   992
Evaluation/MaxReturn                 -1513.58
Evaluation/MinReturn                 -1584.92
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    28.8778
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.62665
GaussianMLPPolicy/KL                     0.00809388
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             11.4015
GaussianMLPPolicy/LossBefore            13.3548
GaussianMLPPolicy/dLoss                  1.95337
GaussianMLPValueFunction/LossAfter       6.67239
GaussianMLPValueFunction/LossBefore      6.6735
GaussianMLPValueFunction/dLoss           0.00111389
TotalEnvSteps                            1.1916e+06
-----------------------------------  --------------
2022-08-17 18:15:16 | [trpo_pendulum] epoch #993 | Saving snapshot...
2022-08-17 18:15:16 | [trpo_pendulum] epoch #993 | Saved
2022-08-17 18:15:16 | [trpo_pendulum] epoch #993 | Time 632.66 s
2022-08-17 18:15:16 | [trpo_pendulum] epoch #993 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -608.219
Evaluation/AverageReturn             -1530.82
Evaluation/Iteration                   993
Evaluation/MaxReturn                 -1512.29
Evaluation/MinReturn                 -1544.08
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    10.1573
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.63418
GaussianMLPPolicy/KL                     0.00695824
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             22.5901
GaussianMLPPolicy/LossBefore            24.3227
GaussianMLPPolicy/dLoss                  1.73263
GaussianMLPValueFunction/LossAfter       6.70439
GaussianMLPValueFunction/LossBefore      6.70624
GaussianMLPValueFunction/dLoss           0.00185347
TotalEnvSteps                            1.1928e+06
-----------------------------------  --------------
2022-08-17 18:15:17 | [trpo_pendulum] epoch #994 | Saving snapshot...
2022-08-17 18:15:17 | [trpo_pendulum] epoch #994 | Saved
2022-08-17 18:15:17 | [trpo_pendulum] epoch #994 | Time 633.31 s
2022-08-17 18:15:17 | [trpo_pendulum] epoch #994 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -603.774
Evaluation/AverageReturn             -1513.73
Evaluation/Iteration                   994
Evaluation/MaxReturn                 -1477.27
Evaluation/MinReturn                 -1551.26
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    23.9525
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.62234
GaussianMLPPolicy/KL                     0.0070664
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             20.3061
GaussianMLPPolicy/LossBefore            21.9113
GaussianMLPPolicy/dLoss                  1.60527
GaussianMLPValueFunction/LossAfter       6.63199
GaussianMLPValueFunction/LossBefore      6.6346
GaussianMLPValueFunction/dLoss           0.00260353
TotalEnvSteps                            1.194e+06
-----------------------------------  --------------
2022-08-17 18:15:18 | [trpo_pendulum] epoch #995 | Saving snapshot...
2022-08-17 18:15:18 | [trpo_pendulum] epoch #995 | Saved
2022-08-17 18:15:18 | [trpo_pendulum] epoch #995 | Time 633.95 s
2022-08-17 18:15:18 | [trpo_pendulum] epoch #995 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -593.773
Evaluation/AverageReturn             -1476.17
Evaluation/Iteration                   995
Evaluation/MaxReturn                 -1341.41
Evaluation/MinReturn                 -1523.4
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    64.1043
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.6215
GaussianMLPPolicy/KL                     0.0085545
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             10.1113
GaussianMLPPolicy/LossBefore            12.2275
GaussianMLPPolicy/dLoss                  2.11628
GaussianMLPValueFunction/LossAfter       6.55268
GaussianMLPValueFunction/LossBefore      6.57232
GaussianMLPValueFunction/dLoss           0.0196438
TotalEnvSteps                            1.1952e+06
-----------------------------------  --------------
2022-08-17 18:15:18 | [trpo_pendulum] epoch #996 | Saving snapshot...
2022-08-17 18:15:18 | [trpo_pendulum] epoch #996 | Saved
2022-08-17 18:15:18 | [trpo_pendulum] epoch #996 | Time 634.58 s
2022-08-17 18:15:18 | [trpo_pendulum] epoch #996 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -611.025
Evaluation/AverageReturn             -1523.22
Evaluation/Iteration                   996
Evaluation/MaxReturn                 -1500.27
Evaluation/MinReturn                 -1536.31
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    11.6716
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.59908
GaussianMLPPolicy/KL                     0.00748085
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             52.6323
GaussianMLPPolicy/LossBefore            53.2608
GaussianMLPPolicy/dLoss                  0.62849
GaussianMLPValueFunction/LossAfter       6.66007
GaussianMLPValueFunction/LossBefore      6.73349
GaussianMLPValueFunction/dLoss           0.0734186
TotalEnvSteps                            1.1964e+06
-----------------------------------  --------------
2022-08-17 18:15:19 | [trpo_pendulum] epoch #997 | Saving snapshot...
2022-08-17 18:15:19 | [trpo_pendulum] epoch #997 | Saved
2022-08-17 18:15:19 | [trpo_pendulum] epoch #997 | Time 635.24 s
2022-08-17 18:15:19 | [trpo_pendulum] epoch #997 | EpochTime 0.65 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -602.009
Evaluation/AverageReturn             -1506.41
Evaluation/Iteration                   997
Evaluation/MaxReturn                 -1472.54
Evaluation/MinReturn                 -1530.77
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    18.0541
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.5695
GaussianMLPPolicy/KL                     0.0093375
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             25.6669
GaussianMLPPolicy/LossBefore            26.3526
GaussianMLPPolicy/dLoss                  0.685701
GaussianMLPValueFunction/LossAfter       6.61746
GaussianMLPValueFunction/LossBefore      6.62011
GaussianMLPValueFunction/dLoss           0.00264788
TotalEnvSteps                            1.1976e+06
-----------------------------------  --------------
2022-08-17 18:15:20 | [trpo_pendulum] epoch #998 | Saving snapshot...
2022-08-17 18:15:20 | [trpo_pendulum] epoch #998 | Saved
2022-08-17 18:15:20 | [trpo_pendulum] epoch #998 | Time 635.88 s
2022-08-17 18:15:20 | [trpo_pendulum] epoch #998 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -601.494
Evaluation/AverageReturn             -1457.1
Evaluation/Iteration                   998
Evaluation/MaxReturn                 -1409.01
Evaluation/MinReturn                 -1541.03
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    52.874
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.54775
GaussianMLPPolicy/KL                     0.00665077
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              1.27766
GaussianMLPPolicy/LossBefore             3.37023
GaussianMLPPolicy/dLoss                  2.09257
GaussianMLPValueFunction/LossAfter       6.5787
GaussianMLPValueFunction/LossBefore      6.58132
GaussianMLPValueFunction/dLoss           0.00262213
TotalEnvSteps                            1.1988e+06
-----------------------------------  --------------
2022-08-17 18:15:20 | [trpo_pendulum] epoch #999 | Saving snapshot...
2022-08-17 18:15:20 | [trpo_pendulum] epoch #999 | Saved
2022-08-17 18:15:20 | [trpo_pendulum] epoch #999 | Time 636.50 s
2022-08-17 18:15:20 | [trpo_pendulum] epoch #999 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -579.376
Evaluation/AverageReturn             -1491.14
Evaluation/Iteration                   999
Evaluation/MaxReturn                 -1440.52
Evaluation/MinReturn                 -1532.29
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    28.3105
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                2.54645
GaussianMLPPolicy/KL                     0.00806969
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             29.9791
GaussianMLPPolicy/LossBefore            30.2664
GaussianMLPPolicy/dLoss                  0.287354
GaussianMLPValueFunction/LossAfter       6.61658
GaussianMLPValueFunction/LossBefore      6.61892
GaussianMLPValueFunction/dLoss           0.00233889
TotalEnvSteps                            1.2e+06
-----------------------------------  --------------
