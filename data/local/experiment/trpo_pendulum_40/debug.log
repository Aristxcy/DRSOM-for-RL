2022-08-24 10:08:45 | [trpo_pendulum] Logging to d:\Github\DRSOM-for-RL\data/local/experiment/trpo_pendulum_40
2022-08-24 10:08:46 | [trpo_pendulum] Obtaining samples...
2022-08-24 10:08:46 | [trpo_pendulum] epoch #0 | Line search condition violated. Rejecting the step!
2022-08-24 10:08:46 | [trpo_pendulum] epoch #0 | Violated because loss not improving
2022-08-24 10:08:47 | [trpo_pendulum] epoch #0 | Saving snapshot...
2022-08-24 10:08:47 | [trpo_pendulum] epoch #0 | Saved
2022-08-24 10:08:47 | [trpo_pendulum] epoch #0 | Time 1.20 s
2022-08-24 10:08:47 | [trpo_pendulum] epoch #0 | EpochTime 1.20 s
-----------------------------------  ----------
Evaluation/AverageDiscountedReturn    -10.3488
Evaluation/AverageReturn              -96.0899
Evaluation/Iteration                    0
Evaluation/MaxReturn                  -92.4759
Evaluation/MinReturn                  -99.7038
Evaluation/NumEpisodes                  2
Evaluation/StdReturn                    3.61393
Evaluation/TerminationRate              0
GaussianMLPPolicy/Entropy               1.41894
GaussianMLPPolicy/KL                    0
GaussianMLPPolicy/KLBefore              0
GaussianMLPPolicy/LossAfter             3.13474
GaussianMLPPolicy/LossBefore            3.13474
GaussianMLPPolicy/dLoss                 0
GaussianMLPValueFunction/LossAfter      9.61442
GaussianMLPValueFunction/LossBefore    41.0736
GaussianMLPValueFunction/dLoss         31.4592
TotalEnvSteps                        1998
-----------------------------------  ----------
2022-08-24 10:08:48 | [trpo_pendulum] epoch #1 | Saving snapshot...
2022-08-24 10:08:48 | [trpo_pendulum] epoch #1 | Saved
2022-08-24 10:08:48 | [trpo_pendulum] epoch #1 | Time 2.33 s
2022-08-24 10:08:48 | [trpo_pendulum] epoch #1 | EpochTime 1.11 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn     -9.64766
Evaluation/AverageReturn              -99.2244
Evaluation/Iteration                    1
Evaluation/MaxReturn                  -92.6361
Evaluation/MinReturn                 -105.813
Evaluation/NumEpisodes                  2
Evaluation/StdReturn                    6.58833
Evaluation/TerminationRate              0
GaussianMLPPolicy/Entropy               1.34185
GaussianMLPPolicy/KL                    0.00639756
GaussianMLPPolicy/KLBefore              0
GaussianMLPPolicy/LossAfter             1.44793
GaussianMLPPolicy/LossBefore            1.46432
GaussianMLPPolicy/dLoss                 0.0163909
GaussianMLPValueFunction/LossAfter      3.71657
GaussianMLPValueFunction/LossBefore    10.9012
GaussianMLPValueFunction/dLoss          7.18467
TotalEnvSteps                        3996
-----------------------------------  -------------
2022-08-24 10:08:49 | [trpo_pendulum] epoch #2 | Saving snapshot...
2022-08-24 10:08:49 | [trpo_pendulum] epoch #2 | Saved
2022-08-24 10:08:49 | [trpo_pendulum] epoch #2 | Time 3.31 s
2022-08-24 10:08:49 | [trpo_pendulum] epoch #2 | EpochTime 0.98 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn     -8.45623
Evaluation/AverageReturn              -86.1987
Evaluation/Iteration                    2
Evaluation/MaxReturn                  -84.5159
Evaluation/MinReturn                  -87.8814
Evaluation/NumEpisodes                  2
Evaluation/StdReturn                    1.68274
Evaluation/TerminationRate              0
GaussianMLPPolicy/Entropy               1.28706
GaussianMLPPolicy/KL                    0.00602722
GaussianMLPPolicy/KLBefore              0
GaussianMLPPolicy/LossAfter            -0.245531
GaussianMLPPolicy/LossBefore           -0.234107
GaussianMLPPolicy/dLoss                 0.0114246
GaussianMLPValueFunction/LossAfter      2.61335
GaussianMLPValueFunction/LossBefore     2.86108
GaussianMLPValueFunction/dLoss          0.247732
TotalEnvSteps                        5994
-----------------------------------  -------------
2022-08-24 10:08:50 | [trpo_pendulum] epoch #3 | Saving snapshot...
2022-08-24 10:08:50 | [trpo_pendulum] epoch #3 | Saved
2022-08-24 10:08:50 | [trpo_pendulum] epoch #3 | Time 4.26 s
2022-08-24 10:08:50 | [trpo_pendulum] epoch #3 | EpochTime 0.94 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn     -7.14515
Evaluation/AverageReturn              -78.3447
Evaluation/Iteration                    3
Evaluation/MaxReturn                  -77.6949
Evaluation/MinReturn                  -78.9946
Evaluation/NumEpisodes                  2
Evaluation/StdReturn                    0.649861
Evaluation/TerminationRate              0
GaussianMLPPolicy/Entropy               1.26669
GaussianMLPPolicy/KL                    0.00587569
GaussianMLPPolicy/KLBefore              0
GaussianMLPPolicy/LossAfter            -0.255183
GaussianMLPPolicy/LossBefore           -0.251818
GaussianMLPPolicy/dLoss                 0.00336519
GaussianMLPValueFunction/LossAfter      2.31998
GaussianMLPValueFunction/LossBefore     2.5763
GaussianMLPValueFunction/dLoss          0.25632
TotalEnvSteps                        7992
-----------------------------------  -------------
2022-08-24 10:08:51 | [trpo_pendulum] epoch #4 | Saving snapshot...
2022-08-24 10:08:51 | [trpo_pendulum] epoch #4 | Saved
2022-08-24 10:08:51 | [trpo_pendulum] epoch #4 | Time 5.30 s
2022-08-24 10:08:51 | [trpo_pendulum] epoch #4 | EpochTime 1.04 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn     -7.6688
Evaluation/AverageReturn              -75.6697
Evaluation/Iteration                    4
Evaluation/MaxReturn                  -69.6697
Evaluation/MinReturn                  -81.6697
Evaluation/NumEpisodes                  2
Evaluation/StdReturn                    6
Evaluation/TerminationRate              0
GaussianMLPPolicy/Entropy               1.23621
GaussianMLPPolicy/KL                    0.00792015
GaussianMLPPolicy/KLBefore              0
GaussianMLPPolicy/LossAfter            -0.139391
GaussianMLPPolicy/LossBefore           -0.130372
GaussianMLPPolicy/dLoss                 0.00901866
GaussianMLPValueFunction/LossAfter      2.37091
GaussianMLPValueFunction/LossBefore     2.46431
GaussianMLPValueFunction/dLoss          0.0933993
TotalEnvSteps                        9990
-----------------------------------  -------------
2022-08-24 10:08:52 | [trpo_pendulum] epoch #5 | Saving snapshot...
2022-08-24 10:08:52 | [trpo_pendulum] epoch #5 | Saved
2022-08-24 10:08:52 | [trpo_pendulum] epoch #5 | Time 6.20 s
2022-08-24 10:08:52 | [trpo_pendulum] epoch #5 | EpochTime 0.90 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -7.34188
Evaluation/AverageReturn               -83.6743
Evaluation/Iteration                     5
Evaluation/MaxReturn                   -71.6778
Evaluation/MinReturn                   -95.6708
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                    11.9965
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.2025
GaussianMLPPolicy/KL                     0.00998743
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              0.322857
GaussianMLPPolicy/LossBefore             0.326213
GaussianMLPPolicy/dLoss                  0.00335583
GaussianMLPValueFunction/LossAfter       4.27878
GaussianMLPValueFunction/LossBefore      4.97743
GaussianMLPValueFunction/dLoss           0.69865
TotalEnvSteps                        11988
-----------------------------------  --------------
2022-08-24 10:08:53 | [trpo_pendulum] epoch #6 | Saving snapshot...
2022-08-24 10:08:53 | [trpo_pendulum] epoch #6 | Saved
2022-08-24 10:08:53 | [trpo_pendulum] epoch #6 | Time 7.13 s
2022-08-24 10:08:53 | [trpo_pendulum] epoch #6 | EpochTime 0.92 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -7.7121
Evaluation/AverageReturn               -68.0847
Evaluation/Iteration                     6
Evaluation/MaxReturn                   -66.8046
Evaluation/MinReturn                   -69.3648
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     1.28008
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.1851
GaussianMLPPolicy/KL                     0.00340692
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.558247
GaussianMLPPolicy/LossBefore            -0.557852
GaussianMLPPolicy/dLoss                  0.000394881
GaussianMLPValueFunction/LossAfter       1.99481
GaussianMLPValueFunction/LossBefore      3.07323
GaussianMLPValueFunction/dLoss           1.07842
TotalEnvSteps                        13986
-----------------------------------  ---------------
2022-08-24 10:08:54 | [trpo_pendulum] epoch #7 | Saving snapshot...
2022-08-24 10:08:54 | [trpo_pendulum] epoch #7 | Saved
2022-08-24 10:08:54 | [trpo_pendulum] epoch #7 | Time 7.95 s
2022-08-24 10:08:54 | [trpo_pendulum] epoch #7 | EpochTime 0.81 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -7.44241
Evaluation/AverageReturn               -28.7955
Evaluation/Iteration                     7
Evaluation/MaxReturn                    33.9681
Evaluation/MinReturn                   -91.5591
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                    62.7636
Evaluation/TerminationRate               0.5
GaussianMLPPolicy/Entropy                1.1844
GaussianMLPPolicy/KL                     0.00553048
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -1.33164
GaussianMLPPolicy/LossBefore            -1.09
GaussianMLPPolicy/dLoss                  0.241645
GaussianMLPValueFunction/LossAfter      70.3171
GaussianMLPValueFunction/LossBefore    102.89
GaussianMLPValueFunction/dLoss          32.5726
TotalEnvSteps                        15773
-----------------------------------  --------------
2022-08-24 10:08:54 | [trpo_pendulum] epoch #8 | Saving snapshot...
2022-08-24 10:08:54 | [trpo_pendulum] epoch #8 | Saved
2022-08-24 10:08:54 | [trpo_pendulum] epoch #8 | Time 8.67 s
2022-08-24 10:08:54 | [trpo_pendulum] epoch #8 | EpochTime 0.72 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -7.17686
Evaluation/AverageReturn               -10.0078
Evaluation/Iteration                     8
Evaluation/MaxReturn                    54.7182
Evaluation/MinReturn                   -74.7338
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                    64.726
Evaluation/TerminationRate               0.5
GaussianMLPPolicy/Entropy                1.16585
GaussianMLPPolicy/KL                     0.0274475
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.761644
GaussianMLPPolicy/LossBefore            -0.760474
GaussianMLPPolicy/dLoss                  0.00116974
GaussianMLPValueFunction/LossAfter      66.2449
GaussianMLPValueFunction/LossBefore     79.543
GaussianMLPValueFunction/dLoss          13.2981
TotalEnvSteps                        17330
-----------------------------------  --------------
2022-08-24 10:08:55 | [trpo_pendulum] epoch #9 | Saving snapshot...
2022-08-24 10:08:55 | [trpo_pendulum] epoch #9 | Saved
2022-08-24 10:08:55 | [trpo_pendulum] epoch #9 | Time 9.49 s
2022-08-24 10:08:55 | [trpo_pendulum] epoch #9 | EpochTime 0.82 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -6.87165
Evaluation/AverageReturn               -11.0359
Evaluation/Iteration                     9
Evaluation/MaxReturn                    44.459
Evaluation/MinReturn                   -66.5307
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                    55.4948
Evaluation/TerminationRate               0.5
GaussianMLPPolicy/Entropy                1.16096
GaussianMLPPolicy/KL                     0.0048114
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.204521
GaussianMLPPolicy/LossBefore            -0.198467
GaussianMLPPolicy/dLoss                  0.00605406
GaussianMLPValueFunction/LossAfter      53.3125
GaussianMLPValueFunction/LossBefore     61.1677
GaussianMLPValueFunction/dLoss           7.85522
TotalEnvSteps                        19078
-----------------------------------  --------------
2022-08-24 10:08:56 | [trpo_pendulum] epoch #10 | Saving snapshot...
2022-08-24 10:08:56 | [trpo_pendulum] epoch #10 | Saved
2022-08-24 10:08:56 | [trpo_pendulum] epoch #10 | Time 10.43 s
2022-08-24 10:08:56 | [trpo_pendulum] epoch #10 | EpochTime 0.93 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -6.07702
Evaluation/AverageReturn               -63.8276
Evaluation/Iteration                    10
Evaluation/MaxReturn                   -63.7884
Evaluation/MinReturn                   -63.8667
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.0391811
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.15425
GaussianMLPPolicy/KL                     0.00654781
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              1.57751
GaussianMLPPolicy/LossBefore             1.58649
GaussianMLPPolicy/dLoss                  0.0089823
GaussianMLPValueFunction/LossAfter       1.8476
GaussianMLPValueFunction/LossBefore      5.54266
GaussianMLPValueFunction/dLoss           3.69506
TotalEnvSteps                        21076
-----------------------------------  --------------
2022-08-24 10:08:57 | [trpo_pendulum] epoch #11 | Saving snapshot...
2022-08-24 10:08:57 | [trpo_pendulum] epoch #11 | Saved
2022-08-24 10:08:57 | [trpo_pendulum] epoch #11 | Time 10.96 s
2022-08-24 10:08:57 | [trpo_pendulum] epoch #11 | EpochTime 0.53 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -5.89584
Evaluation/AverageReturn                59.6421
Evaluation/Iteration                    11
Evaluation/MaxReturn                    61.1861
Evaluation/MinReturn                    58.098
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     1.54409
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.15631
GaussianMLPPolicy/KL                     0.00369508
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -5.72433
GaussianMLPPolicy/LossBefore            -5.6748
GaussianMLPPolicy/dLoss                  0.0495296
GaussianMLPValueFunction/LossAfter     121.942
GaussianMLPValueFunction/LossBefore    178.723
GaussianMLPValueFunction/dLoss          56.781
TotalEnvSteps                        22147
-----------------------------------  --------------
2022-08-24 10:08:57 | [trpo_pendulum] epoch #12 | Saving snapshot...
2022-08-24 10:08:57 | [trpo_pendulum] epoch #12 | Saved
2022-08-24 10:08:57 | [trpo_pendulum] epoch #12 | Time 11.78 s
2022-08-24 10:08:57 | [trpo_pendulum] epoch #12 | EpochTime 0.82 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -5.4348
Evaluation/AverageReturn                57.7118
Evaluation/Iteration                    12
Evaluation/MaxReturn                    69.1596
Evaluation/MinReturn                    44.4751
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                    10.1565
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.15409
GaussianMLPPolicy/KL                     0.00819802
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -2.83688
GaussianMLPPolicy/LossBefore            -2.66065
GaussianMLPPolicy/dLoss                  0.176224
GaussianMLPValueFunction/LossAfter      89.0157
GaussianMLPValueFunction/LossBefore    114.407
GaussianMLPValueFunction/dLoss          25.3909
TotalEnvSteps                        23905
-----------------------------------  --------------
2022-08-24 10:08:58 | [trpo_pendulum] epoch #13 | Saving snapshot...
2022-08-24 10:08:58 | [trpo_pendulum] epoch #13 | Saved
2022-08-24 10:08:58 | [trpo_pendulum] epoch #13 | Time 12.46 s
2022-08-24 10:08:58 | [trpo_pendulum] epoch #13 | EpochTime 0.68 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn      -6.47073
Evaluation/AverageReturn                44.0838
Evaluation/Iteration                    13
Evaluation/MaxReturn                    52.1139
Evaluation/MinReturn                    36.0537
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     8.03012
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.17186
GaussianMLPPolicy/KL                     0.0116436
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              0.0197967
GaussianMLPPolicy/LossBefore             0.265337
GaussianMLPPolicy/dLoss                  0.245541
GaussianMLPValueFunction/LossAfter      68.7429
GaussianMLPValueFunction/LossBefore     77.2905
GaussianMLPValueFunction/dLoss           8.54763
TotalEnvSteps                        25382
-----------------------------------  -------------
2022-08-24 10:08:59 | [trpo_pendulum] epoch #14 | Saving snapshot...
2022-08-24 10:08:59 | [trpo_pendulum] epoch #14 | Saved
2022-08-24 10:08:59 | [trpo_pendulum] epoch #14 | Time 13.01 s
2022-08-24 10:08:59 | [trpo_pendulum] epoch #14 | EpochTime 0.53 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn      -6.57746
Evaluation/AverageReturn                61.2434
Evaluation/Iteration                    14
Evaluation/MaxReturn                    62.2814
Evaluation/MinReturn                    60.2055
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     1.03797
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.14899
GaussianMLPPolicy/KL                     0.0138677
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -1.68568
GaussianMLPPolicy/LossBefore            -1.67175
GaussianMLPPolicy/dLoss                  0.0139327
GaussianMLPValueFunction/LossAfter      75.8455
GaussianMLPValueFunction/LossBefore     84.8152
GaussianMLPValueFunction/dLoss           8.96976
TotalEnvSteps                        26512
-----------------------------------  -------------
2022-08-24 10:08:59 | [trpo_pendulum] epoch #15 | Saving snapshot...
2022-08-24 10:08:59 | [trpo_pendulum] epoch #15 | Saved
2022-08-24 10:08:59 | [trpo_pendulum] epoch #15 | Time 13.68 s
2022-08-24 10:08:59 | [trpo_pendulum] epoch #15 | EpochTime 0.66 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -4.30557
Evaluation/AverageReturn                 9.4386
Evaluation/Iteration                    15
Evaluation/MaxReturn                    75.8315
Evaluation/MinReturn                   -56.9543
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                    66.3929
Evaluation/TerminationRate               0.5
GaussianMLPPolicy/Entropy                1.15352
GaussianMLPPolicy/KL                     0.00695032
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              2.34948
GaussianMLPPolicy/LossBefore             2.3594
GaussianMLPPolicy/dLoss                  0.00991702
GaussianMLPValueFunction/LossAfter      36.1044
GaussianMLPValueFunction/LossBefore     42.8219
GaussianMLPValueFunction/dLoss           6.71755
TotalEnvSteps                        27921
-----------------------------------  --------------
2022-08-24 10:09:00 | [trpo_pendulum] epoch #16 | Saving snapshot...
2022-08-24 10:09:00 | [trpo_pendulum] epoch #16 | Saved
2022-08-24 10:09:00 | [trpo_pendulum] epoch #16 | Time 14.53 s
2022-08-24 10:09:00 | [trpo_pendulum] epoch #16 | EpochTime 0.85 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -5.3883
Evaluation/AverageReturn                -6.04511
Evaluation/Iteration                    16
Evaluation/MaxReturn                    50.9458
Evaluation/MinReturn                   -63.036
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                    56.9909
Evaluation/TerminationRate               0.5
GaussianMLPPolicy/Entropy                1.14647
GaussianMLPPolicy/KL                     0.0023123
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              1.48842
GaussianMLPPolicy/LossBefore             1.49768
GaussianMLPPolicy/dLoss                  0.00925839
GaussianMLPValueFunction/LossAfter      28.3483
GaussianMLPValueFunction/LossBefore     31.8642
GaussianMLPValueFunction/dLoss           3.51593
TotalEnvSteps                        29737
-----------------------------------  --------------
2022-08-24 10:09:01 | [trpo_pendulum] epoch #17 | Saving snapshot...
2022-08-24 10:09:01 | [trpo_pendulum] epoch #17 | Saved
2022-08-24 10:09:01 | [trpo_pendulum] epoch #17 | Time 15.43 s
2022-08-24 10:09:01 | [trpo_pendulum] epoch #17 | EpochTime 0.89 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -6.14919
Evaluation/AverageReturn               -17.9863
Evaluation/Iteration                    17
Evaluation/MaxReturn                    31.6691
Evaluation/MinReturn                   -67.6416
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                    49.6553
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.14961
GaussianMLPPolicy/KL                     0.00769701
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              0.454984
GaussianMLPPolicy/LossBefore             0.572807
GaussianMLPPolicy/dLoss                  0.117823
GaussianMLPValueFunction/LossAfter      24.1693
GaussianMLPValueFunction/LossBefore     25.8991
GaussianMLPValueFunction/dLoss           1.72975
TotalEnvSteps                        31735
-----------------------------------  --------------
2022-08-24 10:09:02 | [trpo_pendulum] epoch #18 | Saving snapshot...
2022-08-24 10:09:02 | [trpo_pendulum] epoch #18 | Saved
2022-08-24 10:09:02 | [trpo_pendulum] epoch #18 | Time 16.14 s
2022-08-24 10:09:02 | [trpo_pendulum] epoch #18 | EpochTime 0.70 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -5.68307
Evaluation/AverageReturn                 0.49304
Evaluation/Iteration                    18
Evaluation/MaxReturn                    61.8309
Evaluation/MinReturn                   -60.8448
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                    61.3378
Evaluation/TerminationRate               0.5
GaussianMLPPolicy/Entropy                1.14642
GaussianMLPPolicy/KL                     0.00778867
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.574641
GaussianMLPPolicy/LossBefore            -0.5084
GaussianMLPPolicy/dLoss                  0.0662413
GaussianMLPValueFunction/LossAfter      27.6286
GaussianMLPValueFunction/LossBefore     29.446
GaussianMLPValueFunction/dLoss           1.81744
TotalEnvSteps                        33345
-----------------------------------  --------------
2022-08-24 10:09:02 | [trpo_pendulum] epoch #19 | Saving snapshot...
2022-08-24 10:09:02 | [trpo_pendulum] epoch #19 | Saved
2022-08-24 10:09:02 | [trpo_pendulum] epoch #19 | Time 16.84 s
2022-08-24 10:09:02 | [trpo_pendulum] epoch #19 | EpochTime 0.70 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -5.52423
Evaluation/AverageReturn                 5.84162
Evaluation/Iteration                    19
Evaluation/MaxReturn                    68.132
Evaluation/MinReturn                   -56.4488
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                    62.2904
Evaluation/TerminationRate               0.5
GaussianMLPPolicy/Entropy                1.14501
GaussianMLPPolicy/KL                     0.00435579
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.402139
GaussianMLPPolicy/LossBefore            -0.395211
GaussianMLPPolicy/dLoss                  0.00692719
GaussianMLPValueFunction/LossAfter      27.3632
GaussianMLPValueFunction/LossBefore     29.1063
GaussianMLPValueFunction/dLoss           1.74307
TotalEnvSteps                        34841
-----------------------------------  --------------
2022-08-24 10:09:03 | [trpo_pendulum] epoch #20 | Saving snapshot...
2022-08-24 10:09:03 | [trpo_pendulum] epoch #20 | Saved
2022-08-24 10:09:03 | [trpo_pendulum] epoch #20 | Time 17.42 s
2022-08-24 10:09:03 | [trpo_pendulum] epoch #20 | EpochTime 0.57 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -5.28131
Evaluation/AverageReturn                66.3521
Evaluation/Iteration                    20
Evaluation/MaxReturn                    68.4205
Evaluation/MinReturn                    64.2837
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     2.06842
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.13295
GaussianMLPPolicy/KL                     0.00172671
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -3.87127
GaussianMLPPolicy/LossBefore            -3.86382
GaussianMLPPolicy/dLoss                  0.00744653
GaussianMLPValueFunction/LossAfter      50.0361
GaussianMLPValueFunction/LossBefore     61.7557
GaussianMLPValueFunction/dLoss          11.7196
TotalEnvSteps                        36035
-----------------------------------  --------------
2022-08-24 10:09:03 | [trpo_pendulum] epoch #21 | Saving snapshot...
2022-08-24 10:09:04 | [trpo_pendulum] epoch #21 | Saved
2022-08-24 10:09:04 | [trpo_pendulum] epoch #21 | Time 17.94 s
2022-08-24 10:09:04 | [trpo_pendulum] epoch #21 | EpochTime 0.52 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -5.40785
Evaluation/AverageReturn                67.4011
Evaluation/Iteration                    21
Evaluation/MaxReturn                    73.8967
Evaluation/MinReturn                    60.9055
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     6.49558
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.11924
GaussianMLPPolicy/KL                     0.00245566
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -2.51625
GaussianMLPPolicy/LossBefore            -2.50704
GaussianMLPPolicy/dLoss                  0.00921082
GaussianMLPValueFunction/LossAfter      49.9647
GaussianMLPValueFunction/LossBefore     56.3542
GaussianMLPValueFunction/dLoss           6.38956
TotalEnvSteps                        37065
-----------------------------------  --------------
2022-08-24 10:09:04 | [trpo_pendulum] epoch #22 | Saving snapshot...
2022-08-24 10:09:04 | [trpo_pendulum] epoch #22 | Saved
2022-08-24 10:09:04 | [trpo_pendulum] epoch #22 | Time 18.52 s
2022-08-24 10:09:04 | [trpo_pendulum] epoch #22 | EpochTime 0.58 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -5.13933
Evaluation/AverageReturn                64.6071
Evaluation/Iteration                    22
Evaluation/MaxReturn                    69.3321
Evaluation/MinReturn                    59.8821
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     4.72498
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.11724
GaussianMLPPolicy/KL                     0.00988235
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.923466
GaussianMLPPolicy/LossBefore            -0.688308
GaussianMLPPolicy/dLoss                  0.235158
GaussianMLPValueFunction/LossAfter      41.7547
GaussianMLPValueFunction/LossBefore     45.3969
GaussianMLPValueFunction/dLoss           3.64217
TotalEnvSteps                        38276
-----------------------------------  --------------
2022-08-24 10:09:05 | [trpo_pendulum] epoch #23 | Saving snapshot...
2022-08-24 10:09:05 | [trpo_pendulum] epoch #23 | Saved
2022-08-24 10:09:05 | [trpo_pendulum] epoch #23 | Time 19.29 s
2022-08-24 10:09:05 | [trpo_pendulum] epoch #23 | EpochTime 0.77 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -5.89508
Evaluation/AverageReturn                 3.21159
Evaluation/Iteration                    23
Evaluation/MaxReturn                    62.4517
Evaluation/MinReturn                   -56.0286
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                    59.2401
Evaluation/TerminationRate               0.5
GaussianMLPPolicy/Entropy                1.09738
GaussianMLPPolicy/KL                     0.00518097
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              3.03669
GaussianMLPPolicy/LossBefore             3.10887
GaussianMLPPolicy/dLoss                  0.0721874
GaussianMLPValueFunction/LossAfter      19.9227
GaussianMLPValueFunction/LossBefore     25.2503
GaussianMLPValueFunction/dLoss           5.32764
TotalEnvSteps                        39939
-----------------------------------  --------------
2022-08-24 10:09:05 | [trpo_pendulum] epoch #24 | Saving snapshot...
2022-08-24 10:09:05 | [trpo_pendulum] epoch #24 | Saved
2022-08-24 10:09:05 | [trpo_pendulum] epoch #24 | Time 19.89 s
2022-08-24 10:09:05 | [trpo_pendulum] epoch #24 | EpochTime 0.60 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -2.67006
Evaluation/AverageReturn                77.7202
Evaluation/Iteration                    24
Evaluation/MaxReturn                    83.3459
Evaluation/MinReturn                    72.7418
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     4.35322
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.10068
GaussianMLPPolicy/KL                     0.00937656
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -5.34507
GaussianMLPPolicy/LossBefore            -5.29266
GaussianMLPPolicy/dLoss                  0.0524058
GaussianMLPValueFunction/LossAfter      44.7664
GaussianMLPValueFunction/LossBefore     57.3374
GaussianMLPValueFunction/dLoss          12.571
TotalEnvSteps                        41192
-----------------------------------  --------------
2022-08-24 10:09:06 | [trpo_pendulum] epoch #25 | Saving snapshot...
2022-08-24 10:09:06 | [trpo_pendulum] epoch #25 | Saved
2022-08-24 10:09:06 | [trpo_pendulum] epoch #25 | Time 20.49 s
2022-08-24 10:09:06 | [trpo_pendulum] epoch #25 | EpochTime 0.59 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn      -3.51187
Evaluation/AverageReturn                75.785
Evaluation/Iteration                    25
Evaluation/MaxReturn                    79.0942
Evaluation/MinReturn                    73.3093
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     2.43412
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.11118
GaussianMLPPolicy/KL                     0.0112566
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -3.00236
GaussianMLPPolicy/LossBefore            -2.90702
GaussianMLPPolicy/dLoss                  0.0953329
GaussianMLPValueFunction/LossAfter      38.3923
GaussianMLPValueFunction/LossBefore     43.6872
GaussianMLPValueFunction/dLoss           5.29488
TotalEnvSteps                        42483
-----------------------------------  -------------
2022-08-24 10:09:07 | [trpo_pendulum] epoch #26 | Saving snapshot...
2022-08-24 10:09:07 | [trpo_pendulum] epoch #26 | Saved
2022-08-24 10:09:07 | [trpo_pendulum] epoch #26 | Time 21.06 s
2022-08-24 10:09:07 | [trpo_pendulum] epoch #26 | EpochTime 0.57 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -3.27204
Evaluation/AverageReturn                76.153
Evaluation/Iteration                    26
Evaluation/MaxReturn                    76.4253
Evaluation/MinReturn                    75.9401
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     0.202461
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.09881
GaussianMLPPolicy/KL                     0.00378234
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -3.14737
GaussianMLPPolicy/LossBefore            -2.92898
GaussianMLPPolicy/dLoss                  0.218389
GaussianMLPValueFunction/LossAfter      38.1173
GaussianMLPValueFunction/LossBefore     42.3268
GaussianMLPValueFunction/dLoss           4.20957
TotalEnvSteps                        43597
-----------------------------------  --------------
2022-08-24 10:09:07 | [trpo_pendulum] epoch #27 | Saving snapshot...
2022-08-24 10:09:07 | [trpo_pendulum] epoch #27 | Saved
2022-08-24 10:09:07 | [trpo_pendulum] epoch #27 | Time 21.61 s
2022-08-24 10:09:07 | [trpo_pendulum] epoch #27 | EpochTime 0.54 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn      -2.55508
Evaluation/AverageReturn                76.2767
Evaluation/Iteration                    27
Evaluation/MaxReturn                    77.5419
Evaluation/MinReturn                    73.8988
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     1.6826
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.10345
GaussianMLPPolicy/KL                     0.0191853
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -2.61308
GaussianMLPPolicy/LossBefore            -2.4985
GaussianMLPPolicy/dLoss                  0.114584
GaussianMLPValueFunction/LossAfter      35.0839
GaussianMLPValueFunction/LossBefore     38.3741
GaussianMLPValueFunction/dLoss           3.29016
TotalEnvSteps                        44692
-----------------------------------  -------------
2022-08-24 10:09:08 | [trpo_pendulum] epoch #28 | Saving snapshot...
2022-08-24 10:09:08 | [trpo_pendulum] epoch #28 | Saved
2022-08-24 10:09:08 | [trpo_pendulum] epoch #28 | Time 22.24 s
2022-08-24 10:09:08 | [trpo_pendulum] epoch #28 | EpochTime 0.63 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn      -1.88784
Evaluation/AverageReturn                77.7544
Evaluation/Iteration                    28
Evaluation/MaxReturn                    81.7338
Evaluation/MinReturn                    72.6374
Evaluation/NumEpisodes                   4
Evaluation/StdReturn                     3.72958
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.10527
GaussianMLPPolicy/KL                     0.0176713
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -2.94691
GaussianMLPPolicy/LossBefore            -2.79457
GaussianMLPPolicy/dLoss                  0.152334
GaussianMLPValueFunction/LossAfter      32.543
GaussianMLPValueFunction/LossBefore     36.1071
GaussianMLPValueFunction/dLoss           3.56406
TotalEnvSteps                        46075
-----------------------------------  -------------
2022-08-24 10:09:08 | [trpo_pendulum] epoch #29 | Saving snapshot...
2022-08-24 10:09:08 | [trpo_pendulum] epoch #29 | Saved
2022-08-24 10:09:08 | [trpo_pendulum] epoch #29 | Time 22.77 s
2022-08-24 10:09:08 | [trpo_pendulum] epoch #29 | EpochTime 0.53 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn      -2.67676
Evaluation/AverageReturn                76.415
Evaluation/Iteration                    29
Evaluation/MaxReturn                    80.8021
Evaluation/MinReturn                    73.9616
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     3.10942
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.09936
GaussianMLPPolicy/KL                     0.003307
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -2.25589
GaussianMLPPolicy/LossBefore            -2.21287
GaussianMLPPolicy/dLoss                  0.0430191
GaussianMLPValueFunction/LossAfter      30.0975
GaussianMLPValueFunction/LossBefore     32.3001
GaussianMLPValueFunction/dLoss           2.20259
TotalEnvSteps                        47118
-----------------------------------  -------------
2022-08-24 10:09:09 | [trpo_pendulum] epoch #30 | Saving snapshot...
2022-08-24 10:09:09 | [trpo_pendulum] epoch #30 | Saved
2022-08-24 10:09:09 | [trpo_pendulum] epoch #30 | Time 23.41 s
2022-08-24 10:09:09 | [trpo_pendulum] epoch #30 | EpochTime 0.63 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -4.45418
Evaluation/AverageReturn                70.3139
Evaluation/Iteration                    30
Evaluation/MaxReturn                    73.6891
Evaluation/MinReturn                    68.3824
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     2.39495
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.09724
GaussianMLPPolicy/KL                     0.00217395
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.0505165
GaussianMLPPolicy/LossBefore             0.0764038
GaussianMLPPolicy/dLoss                  0.12692
GaussianMLPValueFunction/LossAfter      25.455
GaussianMLPValueFunction/LossBefore     27.2412
GaussianMLPValueFunction/dLoss           1.78624
TotalEnvSteps                        48453
-----------------------------------  --------------
2022-08-24 10:09:10 | [trpo_pendulum] epoch #31 | Saving snapshot...
2022-08-24 10:09:10 | [trpo_pendulum] epoch #31 | Saved
2022-08-24 10:09:10 | [trpo_pendulum] epoch #31 | Time 24.00 s
2022-08-24 10:09:10 | [trpo_pendulum] epoch #31 | EpochTime 0.59 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -3.78476
Evaluation/AverageReturn                74.2932
Evaluation/Iteration                    31
Evaluation/MaxReturn                    78.2478
Evaluation/MinReturn                    66.5372
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     5.48469
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.10041
GaussianMLPPolicy/KL                     0.00261306
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.865061
GaussianMLPPolicy/LossBefore            -0.829828
GaussianMLPPolicy/dLoss                  0.0352324
GaussianMLPValueFunction/LossAfter      24.6027
GaussianMLPValueFunction/LossBefore     26.2553
GaussianMLPValueFunction/dLoss           1.65254
TotalEnvSteps                        49690
-----------------------------------  --------------
2022-08-24 10:09:10 | [trpo_pendulum] epoch #32 | Saving snapshot...
2022-08-24 10:09:10 | [trpo_pendulum] epoch #32 | Saved
2022-08-24 10:09:10 | [trpo_pendulum] epoch #32 | Time 24.74 s
2022-08-24 10:09:10 | [trpo_pendulum] epoch #32 | EpochTime 0.74 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -3.62354
Evaluation/AverageReturn                69.4344
Evaluation/Iteration                    32
Evaluation/MaxReturn                    78.8544
Evaluation/MinReturn                    56.429
Evaluation/NumEpisodes                   4
Evaluation/StdReturn                     8.49073
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.09812
GaussianMLPPolicy/KL                     0.00317484
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.550788
GaussianMLPPolicy/LossBefore            -0.535563
GaussianMLPPolicy/dLoss                  0.015225
GaussianMLPValueFunction/LossAfter      23.4698
GaussianMLPValueFunction/LossBefore     25.5138
GaussianMLPValueFunction/dLoss           2.04408
TotalEnvSteps                        51322
-----------------------------------  --------------
2022-08-24 10:09:11 | [trpo_pendulum] epoch #33 | Saving snapshot...
2022-08-24 10:09:11 | [trpo_pendulum] epoch #33 | Saved
2022-08-24 10:09:11 | [trpo_pendulum] epoch #33 | Time 25.34 s
2022-08-24 10:09:11 | [trpo_pendulum] epoch #33 | EpochTime 0.58 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -4.2371
Evaluation/AverageReturn                72.4096
Evaluation/Iteration                    33
Evaluation/MaxReturn                    74.8463
Evaluation/MinReturn                    68.406
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     2.85318
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.11346
GaussianMLPPolicy/KL                     0.00890093
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.824115
GaussianMLPPolicy/LossBefore            -0.74422
GaussianMLPPolicy/dLoss                  0.0798951
GaussianMLPValueFunction/LossAfter      21.2537
GaussianMLPValueFunction/LossBefore     22.5441
GaussianMLPValueFunction/dLoss           1.29041
TotalEnvSteps                        52540
-----------------------------------  --------------
2022-08-24 10:09:11 | [trpo_pendulum] epoch #34 | Saving snapshot...
2022-08-24 10:09:11 | [trpo_pendulum] epoch #34 | Saved
2022-08-24 10:09:11 | [trpo_pendulum] epoch #34 | Time 25.87 s
2022-08-24 10:09:11 | [trpo_pendulum] epoch #34 | EpochTime 0.53 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -3.70039
Evaluation/AverageReturn                72.737
Evaluation/Iteration                    34
Evaluation/MaxReturn                    78.9008
Evaluation/MinReturn                    64.1036
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     6.28829
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.11443
GaussianMLPPolicy/KL                     0.00585702
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -1.88381
GaussianMLPPolicy/LossBefore            -1.57578
GaussianMLPPolicy/dLoss                  0.30803
GaussianMLPValueFunction/LossAfter      21.7228
GaussianMLPValueFunction/LossBefore     22.9598
GaussianMLPValueFunction/dLoss           1.23699
TotalEnvSteps                        53626
-----------------------------------  --------------
2022-08-24 10:09:12 | [trpo_pendulum] epoch #35 | Saving snapshot...
2022-08-24 10:09:12 | [trpo_pendulum] epoch #35 | Saved
2022-08-24 10:09:12 | [trpo_pendulum] epoch #35 | Time 26.49 s
2022-08-24 10:09:12 | [trpo_pendulum] epoch #35 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -5.61199
Evaluation/AverageReturn                67.4892
Evaluation/Iteration                    35
Evaluation/MaxReturn                    74.2205
Evaluation/MinReturn                    56.7551
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     7.67148
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.11328
GaussianMLPPolicy/KL                     0.00671683
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.0873853
GaussianMLPPolicy/LossBefore             0.138772
GaussianMLPPolicy/dLoss                  0.226157
GaussianMLPValueFunction/LossAfter      19.0825
GaussianMLPValueFunction/LossBefore     20.31
GaussianMLPValueFunction/dLoss           1.22749
TotalEnvSteps                        54942
-----------------------------------  --------------
2022-08-24 10:09:13 | [trpo_pendulum] epoch #36 | Saving snapshot...
2022-08-24 10:09:13 | [trpo_pendulum] epoch #36 | Saved
2022-08-24 10:09:13 | [trpo_pendulum] epoch #36 | Time 27.04 s
2022-08-24 10:09:13 | [trpo_pendulum] epoch #36 | EpochTime 0.54 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -3.08424
Evaluation/AverageReturn                74.5031
Evaluation/Iteration                    36
Evaluation/MaxReturn                    82.7876
Evaluation/MinReturn                    66.7038
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     6.57515
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.11308
GaussianMLPPolicy/KL                     0.00650511
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -2.11194
GaussianMLPPolicy/LossBefore            -1.87525
GaussianMLPPolicy/dLoss                  0.236681
GaussianMLPValueFunction/LossAfter      19.4874
GaussianMLPValueFunction/LossBefore     20.6104
GaussianMLPValueFunction/dLoss           1.12292
TotalEnvSteps                        56013
-----------------------------------  --------------
2022-08-24 10:09:13 | [trpo_pendulum] epoch #37 | Saving snapshot...
2022-08-24 10:09:13 | [trpo_pendulum] epoch #37 | Saved
2022-08-24 10:09:13 | [trpo_pendulum] epoch #37 | Time 27.57 s
2022-08-24 10:09:13 | [trpo_pendulum] epoch #37 | EpochTime 0.53 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -1.80948
Evaluation/AverageReturn                76.9233
Evaluation/Iteration                    37
Evaluation/MaxReturn                    85.1114
Evaluation/MinReturn                    71.927
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     5.83654
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.10039
GaussianMLPPolicy/KL                     0.00266911
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -1.91938
GaussianMLPPolicy/LossBefore            -1.76177
GaussianMLPPolicy/dLoss                  0.157603
GaussianMLPValueFunction/LossAfter      18.2631
GaussianMLPValueFunction/LossBefore     19.3229
GaussianMLPValueFunction/dLoss           1.05984
TotalEnvSteps                        57102
-----------------------------------  --------------
2022-08-24 10:09:14 | [trpo_pendulum] epoch #38 | Saving snapshot...
2022-08-24 10:09:14 | [trpo_pendulum] epoch #38 | Saved
2022-08-24 10:09:14 | [trpo_pendulum] epoch #38 | Time 28.21 s
2022-08-24 10:09:14 | [trpo_pendulum] epoch #38 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -1.15121
Evaluation/AverageReturn                77.2693
Evaluation/Iteration                    38
Evaluation/MaxReturn                    85.2788
Evaluation/MinReturn                    70.3178
Evaluation/NumEpisodes                   4
Evaluation/StdReturn                     5.80508
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.08173
GaussianMLPPolicy/KL                     0.00460671
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -2.51076
GaussianMLPPolicy/LossBefore            -2.32586
GaussianMLPPolicy/dLoss                  0.184902
GaussianMLPValueFunction/LossAfter      17.9737
GaussianMLPValueFunction/LossBefore     19.2659
GaussianMLPValueFunction/dLoss           1.29221
TotalEnvSteps                        58437
-----------------------------------  --------------
2022-08-24 10:09:14 | [trpo_pendulum] epoch #39 | Saving snapshot...
2022-08-24 10:09:14 | [trpo_pendulum] epoch #39 | Saved
2022-08-24 10:09:14 | [trpo_pendulum] epoch #39 | Time 28.74 s
2022-08-24 10:09:14 | [trpo_pendulum] epoch #39 | EpochTime 0.53 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn      -2.16145
Evaluation/AverageReturn                79.0527
Evaluation/Iteration                    39
Evaluation/MaxReturn                    84.1638
Evaluation/MinReturn                    76.1529
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     3.62499
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.08195
GaussianMLPPolicy/KL                     0.0379596
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -1.98547
GaussianMLPPolicy/LossBefore            -1.76797
GaussianMLPPolicy/dLoss                  0.217508
GaussianMLPValueFunction/LossAfter      16.1459
GaussianMLPValueFunction/LossBefore     16.9554
GaussianMLPValueFunction/dLoss           0.8095
TotalEnvSteps                        59509
-----------------------------------  -------------
2022-08-24 10:09:15 | [trpo_pendulum] epoch #40 | Saving snapshot...
2022-08-24 10:09:15 | [trpo_pendulum] epoch #40 | Saved
2022-08-24 10:09:15 | [trpo_pendulum] epoch #40 | Time 29.31 s
2022-08-24 10:09:15 | [trpo_pendulum] epoch #40 | EpochTime 0.56 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn      -3.48597
Evaluation/AverageReturn                74.8066
Evaluation/Iteration                    40
Evaluation/MaxReturn                    79.3527
Evaluation/MinReturn                    71.2597
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     3.37868
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.07708
GaussianMLPPolicy/KL                     0.0136585
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.875914
GaussianMLPPolicy/LossBefore            -0.35739
GaussianMLPPolicy/dLoss                  0.518524
GaussianMLPValueFunction/LossAfter      14.957
GaussianMLPValueFunction/LossBefore     15.7173
GaussianMLPValueFunction/dLoss           0.760298
TotalEnvSteps                        60708
-----------------------------------  -------------
2022-08-24 10:09:15 | [trpo_pendulum] epoch #41 | Saving snapshot...
2022-08-24 10:09:15 | [trpo_pendulum] epoch #41 | Saved
2022-08-24 10:09:15 | [trpo_pendulum] epoch #41 | Time 29.83 s
2022-08-24 10:09:15 | [trpo_pendulum] epoch #41 | EpochTime 0.52 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -2.79541
Evaluation/AverageReturn                76.1154
Evaluation/Iteration                    41
Evaluation/MaxReturn                    80.3718
Evaluation/MinReturn                    71.2419
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     3.75269
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.08306
GaussianMLPPolicy/KL                     0.00503634
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -1.67329
GaussianMLPPolicy/LossBefore            -1.58859
GaussianMLPPolicy/dLoss                  0.0846944
GaussianMLPValueFunction/LossAfter      14.6986
GaussianMLPValueFunction/LossBefore     15.3928
GaussianMLPValueFunction/dLoss           0.694219
TotalEnvSteps                        61767
-----------------------------------  --------------
2022-08-24 10:09:16 | [trpo_pendulum] epoch #42 | Saving snapshot...
2022-08-24 10:09:16 | [trpo_pendulum] epoch #42 | Saved
2022-08-24 10:09:16 | [trpo_pendulum] epoch #42 | Time 30.47 s
2022-08-24 10:09:16 | [trpo_pendulum] epoch #42 | EpochTime 0.63 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn      -1.34027
Evaluation/AverageReturn                78.0826
Evaluation/Iteration                    42
Evaluation/MaxReturn                    82.7135
Evaluation/MinReturn                    73.1156
Evaluation/NumEpisodes                   4
Evaluation/StdReturn                     3.39972
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.06436
GaussianMLPPolicy/KL                     0.0176091
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -2.17724
GaussianMLPPolicy/LossBefore            -2.15261
GaussianMLPPolicy/dLoss                  0.0246296
GaussianMLPValueFunction/LossAfter      14.2681
GaussianMLPValueFunction/LossBefore     15.1486
GaussianMLPValueFunction/dLoss           0.880493
TotalEnvSteps                        63080
-----------------------------------  -------------
2022-08-24 10:09:17 | [trpo_pendulum] epoch #43 | Saving snapshot...
2022-08-24 10:09:17 | [trpo_pendulum] epoch #43 | Saved
2022-08-24 10:09:17 | [trpo_pendulum] epoch #43 | Time 31.09 s
2022-08-24 10:09:17 | [trpo_pendulum] epoch #43 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -2.4155
Evaluation/AverageReturn                78.6391
Evaluation/Iteration                    43
Evaluation/MaxReturn                    81.0265
Evaluation/MinReturn                    75.2475
Evaluation/NumEpisodes                   4
Evaluation/StdReturn                     2.44905
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.03175
GaussianMLPPolicy/KL                     0.00906198
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -1.96981
GaussianMLPPolicy/LossBefore            -1.776
GaussianMLPPolicy/dLoss                  0.193804
GaussianMLPValueFunction/LossAfter      13.6041
GaussianMLPValueFunction/LossBefore     14.3885
GaussianMLPValueFunction/dLoss           0.784436
TotalEnvSteps                        64420
-----------------------------------  --------------
2022-08-24 10:09:17 | [trpo_pendulum] epoch #44 | Saving snapshot...
2022-08-24 10:09:17 | [trpo_pendulum] epoch #44 | Saved
2022-08-24 10:09:17 | [trpo_pendulum] epoch #44 | Time 31.67 s
2022-08-24 10:09:17 | [trpo_pendulum] epoch #44 | EpochTime 0.58 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -3.48832
Evaluation/AverageReturn                77.8675
Evaluation/Iteration                    44
Evaluation/MaxReturn                    84.0707
Evaluation/MinReturn                    73.8953
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     4.44356
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.984122
GaussianMLPPolicy/KL                     0.00765497
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.285358
GaussianMLPPolicy/LossBefore            -0.0901119
GaussianMLPPolicy/dLoss                  0.195246
GaussianMLPValueFunction/LossAfter      12.1986
GaussianMLPValueFunction/LossBefore     12.7915
GaussianMLPValueFunction/dLoss           0.5929
TotalEnvSteps                        65665
-----------------------------------  --------------
2022-08-24 10:09:18 | [trpo_pendulum] epoch #45 | Saving snapshot...
2022-08-24 10:09:18 | [trpo_pendulum] epoch #45 | Saved
2022-08-24 10:09:18 | [trpo_pendulum] epoch #45 | Time 32.19 s
2022-08-24 10:09:18 | [trpo_pendulum] epoch #45 | EpochTime 0.51 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -1.73604
Evaluation/AverageReturn                80.674
Evaluation/Iteration                    45
Evaluation/MaxReturn                    81.6913
Evaluation/MinReturn                    78.7429
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     1.36613
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.99913
GaussianMLPPolicy/KL                     0.00128771
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -1.78525
GaussianMLPPolicy/LossBefore            -1.5823
GaussianMLPPolicy/dLoss                  0.20295
GaussianMLPValueFunction/LossAfter      11.6275
GaussianMLPValueFunction/LossBefore     12.1129
GaussianMLPValueFunction/dLoss           0.485423
TotalEnvSteps                        66724
-----------------------------------  --------------
2022-08-24 10:09:18 | [trpo_pendulum] epoch #46 | Saving snapshot...
2022-08-24 10:09:18 | [trpo_pendulum] epoch #46 | Saved
2022-08-24 10:09:18 | [trpo_pendulum] epoch #46 | Time 32.91 s
2022-08-24 10:09:18 | [trpo_pendulum] epoch #46 | EpochTime 0.71 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -1.31721
Evaluation/AverageReturn                79.4329
Evaluation/Iteration                    46
Evaluation/MaxReturn                    84.0947
Evaluation/MinReturn                    74.392
Evaluation/NumEpisodes                   4
Evaluation/StdReturn                     4.02291
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.997681
GaussianMLPPolicy/KL                     0.00195654
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -1.11004
GaussianMLPPolicy/LossBefore            -1.04952
GaussianMLPPolicy/dLoss                  0.0605141
GaussianMLPValueFunction/LossAfter      11.406
GaussianMLPValueFunction/LossBefore     12.0416
GaussianMLPValueFunction/dLoss           0.63556
TotalEnvSteps                        68208
-----------------------------------  --------------
2022-08-24 10:09:19 | [trpo_pendulum] epoch #47 | Saving snapshot...
2022-08-24 10:09:19 | [trpo_pendulum] epoch #47 | Saved
2022-08-24 10:09:19 | [trpo_pendulum] epoch #47 | Time 33.44 s
2022-08-24 10:09:19 | [trpo_pendulum] epoch #47 | EpochTime 0.53 s
-----------------------------------  ------------
Evaluation/AverageDiscountedReturn      -0.625835
Evaluation/AverageReturn                82.4325
Evaluation/Iteration                    47
Evaluation/MaxReturn                    83.9754
Evaluation/MinReturn                    80.1015
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     1.67681
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.994831
GaussianMLPPolicy/KL                     0.010869
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -1.97585
GaussianMLPPolicy/LossBefore            -1.71837
GaussianMLPPolicy/dLoss                  0.257478
GaussianMLPValueFunction/LossAfter      10.9286
GaussianMLPValueFunction/LossBefore     11.3729
GaussianMLPValueFunction/dLoss           0.444343
TotalEnvSteps                        69273
-----------------------------------  ------------
2022-08-24 10:09:20 | [trpo_pendulum] epoch #48 | Saving snapshot...
2022-08-24 10:09:20 | [trpo_pendulum] epoch #48 | Saved
2022-08-24 10:09:20 | [trpo_pendulum] epoch #48 | Time 33.96 s
2022-08-24 10:09:20 | [trpo_pendulum] epoch #48 | EpochTime 0.51 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn      -4.2772
Evaluation/AverageReturn                71.7159
Evaluation/Iteration                    48
Evaluation/MaxReturn                    73.0368
Evaluation/MinReturn                    70.3949
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     1.32097
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.00846
GaussianMLPPolicy/KL                     0.0055738
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              1.89457
GaussianMLPPolicy/LossBefore             2.06752
GaussianMLPPolicy/dLoss                  0.172949
GaussianMLPValueFunction/LossAfter       9.80049
GaussianMLPValueFunction/LossBefore     10.3744
GaussianMLPValueFunction/dLoss           0.573937
TotalEnvSteps                        70367
-----------------------------------  -------------
2022-08-24 10:09:20 | [trpo_pendulum] epoch #49 | Saving snapshot...
2022-08-24 10:09:20 | [trpo_pendulum] epoch #49 | Saved
2022-08-24 10:09:20 | [trpo_pendulum] epoch #49 | Time 34.62 s
2022-08-24 10:09:20 | [trpo_pendulum] epoch #49 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -3.62054
Evaluation/AverageReturn                76.6239
Evaluation/Iteration                    49
Evaluation/MaxReturn                    78.2581
Evaluation/MinReturn                    74.7716
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     1.4317
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.970177
GaussianMLPPolicy/KL                     0.00434959
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              0.121905
GaussianMLPPolicy/LossBefore             0.280504
GaussianMLPPolicy/dLoss                  0.158599
GaussianMLPValueFunction/LossAfter       9.61947
GaussianMLPValueFunction/LossBefore     10.0713
GaussianMLPValueFunction/dLoss           0.451835
TotalEnvSteps                        71751
-----------------------------------  --------------
2022-08-24 10:09:21 | [trpo_pendulum] epoch #50 | Saving snapshot...
2022-08-24 10:09:21 | [trpo_pendulum] epoch #50 | Saved
2022-08-24 10:09:21 | [trpo_pendulum] epoch #50 | Time 35.27 s
2022-08-24 10:09:21 | [trpo_pendulum] epoch #50 | EpochTime 0.64 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -1.03314
Evaluation/AverageReturn                81.2354
Evaluation/Iteration                    50
Evaluation/MaxReturn                    83.1778
Evaluation/MinReturn                    80.1043
Evaluation/NumEpisodes                   4
Evaluation/StdReturn                     1.18519
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.972175
GaussianMLPPolicy/KL                     0.00422714
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -2.85341
GaussianMLPPolicy/LossBefore            -2.39807
GaussianMLPPolicy/dLoss                  0.455345
GaussianMLPValueFunction/LossAfter       9.61514
GaussianMLPValueFunction/LossBefore     10.1255
GaussianMLPValueFunction/dLoss           0.510318
TotalEnvSteps                        73105
-----------------------------------  --------------
2022-08-24 10:09:21 | [trpo_pendulum] epoch #51 | Saving snapshot...
2022-08-24 10:09:21 | [trpo_pendulum] epoch #51 | Saved
2022-08-24 10:09:21 | [trpo_pendulum] epoch #51 | Time 35.84 s
2022-08-24 10:09:21 | [trpo_pendulum] epoch #51 | EpochTime 0.57 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn       1.08207
Evaluation/AverageReturn                84.3518
Evaluation/Iteration                    51
Evaluation/MaxReturn                    87.1699
Evaluation/MinReturn                    81.7708
Evaluation/NumEpisodes                   4
Evaluation/StdReturn                     2.47328
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.974875
GaussianMLPPolicy/KL                     0.00388212
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -3.84491
GaussianMLPPolicy/LossBefore            -3.64482
GaussianMLPPolicy/dLoss                  0.200091
GaussianMLPValueFunction/LossAfter       9.32623
GaussianMLPValueFunction/LossBefore      9.84879
GaussianMLPValueFunction/dLoss           0.522566
TotalEnvSteps                        74314
-----------------------------------  --------------
2022-08-24 10:09:22 | [trpo_pendulum] epoch #52 | Saving snapshot...
2022-08-24 10:09:22 | [trpo_pendulum] epoch #52 | Saved
2022-08-24 10:09:22 | [trpo_pendulum] epoch #52 | Time 36.46 s
2022-08-24 10:09:22 | [trpo_pendulum] epoch #52 | EpochTime 0.60 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn      -1.64448
Evaluation/AverageReturn                80.2457
Evaluation/Iteration                    52
Evaluation/MaxReturn                    83.0407
Evaluation/MinReturn                    76.9992
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     2.48699
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.974854
GaussianMLPPolicy/KL                     0.0025182
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.394665
GaussianMLPPolicy/LossBefore            -0.269688
GaussianMLPPolicy/dLoss                  0.124977
GaussianMLPValueFunction/LossAfter       8.36642
GaussianMLPValueFunction/LossBefore      8.69411
GaussianMLPValueFunction/dLoss           0.327691
TotalEnvSteps                        75545
-----------------------------------  -------------
2022-08-24 10:09:23 | [trpo_pendulum] epoch #53 | Saving snapshot...
2022-08-24 10:09:23 | [trpo_pendulum] epoch #53 | Saved
2022-08-24 10:09:23 | [trpo_pendulum] epoch #53 | Time 37.10 s
2022-08-24 10:09:23 | [trpo_pendulum] epoch #53 | EpochTime 0.64 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn      -2.83853
Evaluation/AverageReturn                78.1082
Evaluation/Iteration                    53
Evaluation/MaxReturn                    82.7259
Evaluation/MinReturn                    75.197
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     3.30206
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.963795
GaussianMLPPolicy/KL                     0.0102406
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              0.432437
GaussianMLPPolicy/LossBefore             0.462117
GaussianMLPPolicy/dLoss                  0.02968
GaussianMLPValueFunction/LossAfter       8.0872
GaussianMLPValueFunction/LossBefore      8.43746
GaussianMLPValueFunction/dLoss           0.350262
TotalEnvSteps                        76901
-----------------------------------  -------------
2022-08-24 10:09:23 | [trpo_pendulum] epoch #54 | Saving snapshot...
2022-08-24 10:09:23 | [trpo_pendulum] epoch #54 | Saved
2022-08-24 10:09:23 | [trpo_pendulum] epoch #54 | Time 37.78 s
2022-08-24 10:09:23 | [trpo_pendulum] epoch #54 | EpochTime 0.67 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -2.22549
Evaluation/AverageReturn                75.7191
Evaluation/Iteration                    54
Evaluation/MaxReturn                    80.2282
Evaluation/MinReturn                    67.099
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     6.09749
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.966504
GaussianMLPPolicy/KL                     0.00307711
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              0.461194
GaussianMLPPolicy/LossBefore             0.692862
GaussianMLPPolicy/dLoss                  0.231669
GaussianMLPValueFunction/LossAfter       7.43602
GaussianMLPValueFunction/LossBefore      7.78781
GaussianMLPValueFunction/dLoss           0.35179
TotalEnvSteps                        78374
-----------------------------------  --------------
2022-08-24 10:09:24 | [trpo_pendulum] epoch #55 | Saving snapshot...
2022-08-24 10:09:24 | [trpo_pendulum] epoch #55 | Saved
2022-08-24 10:09:24 | [trpo_pendulum] epoch #55 | Time 38.34 s
2022-08-24 10:09:24 | [trpo_pendulum] epoch #55 | EpochTime 0.56 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -0.394189
Evaluation/AverageReturn                80.0828
Evaluation/Iteration                    55
Evaluation/MaxReturn                    86.6859
Evaluation/MinReturn                    75.1726
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     4.85035
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.967357
GaussianMLPPolicy/KL                     0.00797077
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -2.2287
GaussianMLPPolicy/LossBefore            -1.78316
GaussianMLPPolicy/dLoss                  0.445542
GaussianMLPValueFunction/LossAfter       7.79109
GaussianMLPValueFunction/LossBefore      8.06348
GaussianMLPValueFunction/dLoss           0.272395
TotalEnvSteps                        79503
-----------------------------------  --------------
2022-08-24 10:09:25 | [trpo_pendulum] epoch #56 | Saving snapshot...
2022-08-24 10:09:25 | [trpo_pendulum] epoch #56 | Saved
2022-08-24 10:09:25 | [trpo_pendulum] epoch #56 | Time 38.94 s
2022-08-24 10:09:25 | [trpo_pendulum] epoch #56 | EpochTime 0.60 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -2.43012
Evaluation/AverageReturn                74.3358
Evaluation/Iteration                    56
Evaluation/MaxReturn                    77.4596
Evaluation/MinReturn                    70.6268
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     2.82003
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.962798
GaussianMLPPolicy/KL                     0.00353587
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.566599
GaussianMLPPolicy/LossBefore            -0.250955
GaussianMLPPolicy/dLoss                  0.315644
GaussianMLPValueFunction/LossAfter       7.05327
GaussianMLPValueFunction/LossBefore      7.27292
GaussianMLPValueFunction/dLoss           0.219649
TotalEnvSteps                        80808
-----------------------------------  --------------
2022-08-24 10:09:25 | [trpo_pendulum] epoch #57 | Saving snapshot...
2022-08-24 10:09:25 | [trpo_pendulum] epoch #57 | Saved
2022-08-24 10:09:25 | [trpo_pendulum] epoch #57 | Time 39.64 s
2022-08-24 10:09:25 | [trpo_pendulum] epoch #57 | EpochTime 0.68 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -2.78595
Evaluation/AverageReturn                69.613
Evaluation/Iteration                    57
Evaluation/MaxReturn                    80.4805
Evaluation/MinReturn                    61.6917
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     7.94836
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.955845
GaussianMLPPolicy/KL                     0.00945913
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              0.352302
GaussianMLPPolicy/LossBefore             0.813007
GaussianMLPPolicy/dLoss                  0.460705
GaussianMLPValueFunction/LossAfter       6.54459
GaussianMLPValueFunction/LossBefore      6.84256
GaussianMLPValueFunction/dLoss           0.29797
TotalEnvSteps                        82338
-----------------------------------  --------------
2022-08-24 10:09:26 | [trpo_pendulum] epoch #58 | Saving snapshot...
2022-08-24 10:09:26 | [trpo_pendulum] epoch #58 | Saved
2022-08-24 10:09:26 | [trpo_pendulum] epoch #58 | Time 40.36 s
2022-08-24 10:09:26 | [trpo_pendulum] epoch #58 | EpochTime 0.72 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -3.18015
Evaluation/AverageReturn                67.4085
Evaluation/Iteration                    58
Evaluation/MaxReturn                    73.3526
Evaluation/MinReturn                    63.6344
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     4.25385
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.94806
GaussianMLPPolicy/KL                     0.00515361
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              0.48588
GaussianMLPPolicy/LossBefore             0.569161
GaussianMLPPolicy/dLoss                  0.0832814
GaussianMLPValueFunction/LossAfter       6.49981
GaussianMLPValueFunction/LossBefore      6.80247
GaussianMLPValueFunction/dLoss           0.302658
TotalEnvSteps                        83872
-----------------------------------  --------------
2022-08-24 10:09:26 | [trpo_pendulum] epoch #59 | Saving snapshot...
2022-08-24 10:09:27 | [trpo_pendulum] epoch #59 | Saved
2022-08-24 10:09:27 | [trpo_pendulum] epoch #59 | Time 40.92 s
2022-08-24 10:09:27 | [trpo_pendulum] epoch #59 | EpochTime 0.56 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -2.70516
Evaluation/AverageReturn                75.3697
Evaluation/Iteration                    59
Evaluation/MaxReturn                    79.143
Evaluation/MinReturn                    70.8466
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     3.42826
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.930071
GaussianMLPPolicy/KL                     0.00977986
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -2.34423
GaussianMLPPolicy/LossBefore            -2.12564
GaussianMLPPolicy/dLoss                  0.218597
GaussianMLPValueFunction/LossAfter       6.7434
GaussianMLPValueFunction/LossBefore      7.06533
GaussianMLPValueFunction/dLoss           0.321928
TotalEnvSteps                        85151
-----------------------------------  --------------
2022-08-24 10:09:27 | [trpo_pendulum] epoch #60 | Saving snapshot...
2022-08-24 10:09:27 | [trpo_pendulum] epoch #60 | Saved
2022-08-24 10:09:27 | [trpo_pendulum] epoch #60 | Time 41.51 s
2022-08-24 10:09:27 | [trpo_pendulum] epoch #60 | EpochTime 0.57 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -2.24632
Evaluation/AverageReturn                72.2262
Evaluation/Iteration                    60
Evaluation/MaxReturn                    83.1361
Evaluation/MinReturn                    61.3164
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                    10.9098
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.930815
GaussianMLPPolicy/KL                     0.00173714
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              0.272182
GaussianMLPPolicy/LossBefore             0.56068
GaussianMLPPolicy/dLoss                  0.288497
GaussianMLPValueFunction/LossAfter       5.92293
GaussianMLPValueFunction/LossBefore      6.1719
GaussianMLPValueFunction/dLoss           0.248973
TotalEnvSteps                        86354
-----------------------------------  --------------
2022-08-24 10:09:28 | [trpo_pendulum] epoch #61 | Saving snapshot...
2022-08-24 10:09:28 | [trpo_pendulum] epoch #61 | Saved
2022-08-24 10:09:28 | [trpo_pendulum] epoch #61 | Time 42.09 s
2022-08-24 10:09:28 | [trpo_pendulum] epoch #61 | EpochTime 0.58 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -1.4042
Evaluation/AverageReturn                79.7941
Evaluation/Iteration                    61
Evaluation/MaxReturn                    83.1264
Evaluation/MinReturn                    75.1305
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     3.39734
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.926049
GaussianMLPPolicy/KL                     0.00240031
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -2.8693
GaussianMLPPolicy/LossBefore            -2.69237
GaussianMLPPolicy/dLoss                  0.176935
GaussianMLPValueFunction/LossAfter       6.42324
GaussianMLPValueFunction/LossBefore      6.70351
GaussianMLPValueFunction/dLoss           0.280272
TotalEnvSteps                        87557
-----------------------------------  --------------
2022-08-24 10:09:28 | [trpo_pendulum] epoch #62 | Saving snapshot...
2022-08-24 10:09:28 | [trpo_pendulum] epoch #62 | Saved
2022-08-24 10:09:28 | [trpo_pendulum] epoch #62 | Time 42.76 s
2022-08-24 10:09:28 | [trpo_pendulum] epoch #62 | EpochTime 0.66 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -3.40272
Evaluation/AverageReturn                74.201
Evaluation/Iteration                    62
Evaluation/MaxReturn                    77.7637
Evaluation/MinReturn                    70.3762
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     3.02162
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.922387
GaussianMLPPolicy/KL                     0.00222086
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.689223
GaussianMLPPolicy/LossBefore            -0.591018
GaussianMLPPolicy/dLoss                  0.0982054
GaussianMLPValueFunction/LossAfter       6.19141
GaussianMLPValueFunction/LossBefore      6.37438
GaussianMLPValueFunction/dLoss           0.182971
TotalEnvSteps                        88904
-----------------------------------  --------------
2022-08-24 10:09:29 | [trpo_pendulum] epoch #63 | Saving snapshot...
2022-08-24 10:09:29 | [trpo_pendulum] epoch #63 | Saved
2022-08-24 10:09:29 | [trpo_pendulum] epoch #63 | Time 43.32 s
2022-08-24 10:09:29 | [trpo_pendulum] epoch #63 | EpochTime 0.56 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -2.72295
Evaluation/AverageReturn                77.6947
Evaluation/Iteration                    63
Evaluation/MaxReturn                    78.5825
Evaluation/MinReturn                    75.9784
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     1.21386
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.921607
GaussianMLPPolicy/KL                     0.00480436
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -2.30691
GaussianMLPPolicy/LossBefore            -2.2774
GaussianMLPPolicy/dLoss                  0.0295126
GaussianMLPValueFunction/LossAfter       6.0885
GaussianMLPValueFunction/LossBefore      6.27404
GaussianMLPValueFunction/dLoss           0.185544
TotalEnvSteps                        90072
-----------------------------------  --------------
2022-08-24 10:09:30 | [trpo_pendulum] epoch #64 | Saving snapshot...
2022-08-24 10:09:30 | [trpo_pendulum] epoch #64 | Saved
2022-08-24 10:09:30 | [trpo_pendulum] epoch #64 | Time 44.01 s
2022-08-24 10:09:30 | [trpo_pendulum] epoch #64 | EpochTime 0.68 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn      -1.10369
Evaluation/AverageReturn                81.9424
Evaluation/Iteration                    64
Evaluation/MaxReturn                    83.9601
Evaluation/MinReturn                    79.7016
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     1.74567
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.912674
GaussianMLPPolicy/KL                     0.0155043
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -2.67382
GaussianMLPPolicy/LossBefore            -2.49833
GaussianMLPPolicy/dLoss                  0.175491
GaussianMLPValueFunction/LossAfter       6.01357
GaussianMLPValueFunction/LossBefore      6.17979
GaussianMLPValueFunction/dLoss           0.166221
TotalEnvSteps                        91198
-----------------------------------  -------------
2022-08-24 10:09:30 | [trpo_pendulum] epoch #65 | Saving snapshot...
2022-08-24 10:09:30 | [trpo_pendulum] epoch #65 | Saved
2022-08-24 10:09:30 | [trpo_pendulum] epoch #65 | Time 44.58 s
2022-08-24 10:09:30 | [trpo_pendulum] epoch #65 | EpochTime 0.57 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn      -1.64289
Evaluation/AverageReturn                79.2866
Evaluation/Iteration                    65
Evaluation/MaxReturn                    81.95
Evaluation/MinReturn                    74.0588
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     3.69684
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.898163
GaussianMLPPolicy/KL                     0.01475
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -1.4849
GaussianMLPPolicy/LossBefore            -1.40884
GaussianMLPPolicy/dLoss                  0.0760629
GaussianMLPValueFunction/LossAfter       5.96415
GaussianMLPValueFunction/LossBefore      6.12291
GaussianMLPValueFunction/dLoss           0.158762
TotalEnvSteps                        92352
-----------------------------------  -------------
2022-08-24 10:09:31 | [trpo_pendulum] epoch #66 | Saving snapshot...
2022-08-24 10:09:31 | [trpo_pendulum] epoch #66 | Saved
2022-08-24 10:09:31 | [trpo_pendulum] epoch #66 | Time 45.16 s
2022-08-24 10:09:31 | [trpo_pendulum] epoch #66 | EpochTime 0.57 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn      -0.107891
Evaluation/AverageReturn                81.2701
Evaluation/Iteration                    66
Evaluation/MaxReturn                    86.2614
Evaluation/MinReturn                    78.6736
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     3.53038
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.949956
GaussianMLPPolicy/KL                     0.0117587
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -1.7809
GaussianMLPPolicy/LossBefore            -1.61398
GaussianMLPPolicy/dLoss                  0.166915
GaussianMLPValueFunction/LossAfter       5.79786
GaussianMLPValueFunction/LossBefore      5.92664
GaussianMLPValueFunction/dLoss           0.128777
TotalEnvSteps                        93518
-----------------------------------  -------------
2022-08-24 10:09:31 | [trpo_pendulum] epoch #67 | Saving snapshot...
2022-08-24 10:09:31 | [trpo_pendulum] epoch #67 | Saved
2022-08-24 10:09:31 | [trpo_pendulum] epoch #67 | Time 45.88 s
2022-08-24 10:09:31 | [trpo_pendulum] epoch #67 | EpochTime 0.72 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -2.63308
Evaluation/AverageReturn                77.2763
Evaluation/Iteration                    67
Evaluation/MaxReturn                    81.8099
Evaluation/MinReturn                    70.1577
Evaluation/NumEpisodes                   3
Evaluation/StdReturn                     5.09609
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.949227
GaussianMLPPolicy/KL                     0.00415985
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              0.100972
GaussianMLPPolicy/LossBefore             0.129327
GaussianMLPPolicy/dLoss                  0.0283559
GaussianMLPValueFunction/LossAfter       5.43011
GaussianMLPValueFunction/LossBefore      5.57589
GaussianMLPValueFunction/dLoss           0.145772
TotalEnvSteps                        95019
-----------------------------------  --------------
2022-08-24 10:09:32 | [trpo_pendulum] epoch #68 | Saving snapshot...
2022-08-24 10:09:32 | [trpo_pendulum] epoch #68 | Saved
2022-08-24 10:09:32 | [trpo_pendulum] epoch #68 | Time 46.39 s
2022-08-24 10:09:32 | [trpo_pendulum] epoch #68 | EpochTime 0.51 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn      -3.33033
Evaluation/AverageReturn                72.4984
Evaluation/Iteration                    68
Evaluation/MaxReturn                    74.5119
Evaluation/MinReturn                    70.485
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     2.01344
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                1.00701
GaussianMLPPolicy/KL                     0.0059156
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.0954206
GaussianMLPPolicy/LossBefore             0.581566
GaussianMLPPolicy/dLoss                  0.676986
GaussianMLPValueFunction/LossAfter       5.31695
GaussianMLPValueFunction/LossBefore      5.4284
GaussianMLPValueFunction/dLoss           0.111456
TotalEnvSteps                        96074
-----------------------------------  -------------
2022-08-24 10:09:33 | [trpo_pendulum] epoch #69 | Saving snapshot...
2022-08-24 10:09:33 | [trpo_pendulum] epoch #69 | Saved
2022-08-24 10:09:33 | [trpo_pendulum] epoch #69 | Time 46.94 s
2022-08-24 10:09:33 | [trpo_pendulum] epoch #69 | EpochTime 0.54 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -5.0648
Evaluation/AverageReturn                66.6715
Evaluation/Iteration                    69
Evaluation/MaxReturn                    70.3389
Evaluation/MinReturn                    63.0041
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     3.6674
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.992732
GaussianMLPPolicy/KL                     0.00563398
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              1.02611
GaussianMLPPolicy/LossBefore             1.15264
GaussianMLPPolicy/dLoss                  0.126534
GaussianMLPValueFunction/LossAfter       5.25758
GaussianMLPValueFunction/LossBefore      5.44894
GaussianMLPValueFunction/dLoss           0.191359
TotalEnvSteps                        97231
-----------------------------------  --------------
2022-08-24 10:09:33 | [trpo_pendulum] epoch #70 | Saving snapshot...
2022-08-24 10:09:33 | [trpo_pendulum] epoch #70 | Saved
2022-08-24 10:09:33 | [trpo_pendulum] epoch #70 | Time 47.51 s
2022-08-24 10:09:33 | [trpo_pendulum] epoch #70 | EpochTime 0.55 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -3.89992
Evaluation/AverageReturn                71.9617
Evaluation/Iteration                    70
Evaluation/MaxReturn                    74.736
Evaluation/MinReturn                    69.1875
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     2.77425
Evaluation/TerminationRate               1
GaussianMLPPolicy/Entropy                0.975353
GaussianMLPPolicy/KL                     0.00400059
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.88961
GaussianMLPPolicy/LossBefore            -0.873895
GaussianMLPPolicy/dLoss                  0.0157148
GaussianMLPValueFunction/LossAfter       5.23252
GaussianMLPValueFunction/LossBefore      5.31307
GaussianMLPValueFunction/dLoss           0.080544
TotalEnvSteps                        98338
-----------------------------------  --------------
2022-08-24 10:09:34 | [trpo_pendulum] epoch #71 | Saving snapshot...
2022-08-24 10:09:34 | [trpo_pendulum] epoch #71 | Saved
2022-08-24 10:09:34 | [trpo_pendulum] epoch #71 | Time 48.30 s
2022-08-24 10:09:34 | [trpo_pendulum] epoch #71 | EpochTime 0.77 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -3.37207
Evaluation/AverageReturn                 73.8869
Evaluation/Iteration                     71
Evaluation/MaxReturn                     81.4139
Evaluation/MinReturn                     59.9511
Evaluation/NumEpisodes                    3
Evaluation/StdReturn                      9.86469
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 0.977296
GaussianMLPPolicy/KL                      0.00607234
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -1.05962
GaussianMLPPolicy/LossBefore             -0.911518
GaussianMLPPolicy/dLoss                   0.148105
GaussianMLPValueFunction/LossAfter        5.09288
GaussianMLPValueFunction/LossBefore       5.1841
GaussianMLPValueFunction/dLoss            0.0912156
TotalEnvSteps                        100011
-----------------------------------  ---------------
2022-08-24 10:09:34 | [trpo_pendulum] epoch #72 | Saving snapshot...
2022-08-24 10:09:35 | [trpo_pendulum] epoch #72 | Saved
2022-08-24 10:09:35 | [trpo_pendulum] epoch #72 | Time 48.92 s
2022-08-24 10:09:35 | [trpo_pendulum] epoch #72 | EpochTime 0.62 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn       -3.88966
Evaluation/AverageReturn                 70.8311
Evaluation/Iteration                     72
Evaluation/MaxReturn                     75.1743
Evaluation/MinReturn                     66.4879
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.3432
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 0.977494
GaussianMLPPolicy/KL                      0.0062082
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.0344154
GaussianMLPPolicy/LossBefore              0.0835179
GaussianMLPPolicy/dLoss                   0.0491024
GaussianMLPValueFunction/LossAfter        4.94564
GaussianMLPValueFunction/LossBefore       5.01888
GaussianMLPValueFunction/dLoss            0.0732417
TotalEnvSteps                        101286
-----------------------------------  --------------
2022-08-24 10:09:35 | [trpo_pendulum] epoch #73 | Saving snapshot...
2022-08-24 10:09:35 | [trpo_pendulum] epoch #73 | Saved
2022-08-24 10:09:35 | [trpo_pendulum] epoch #73 | Time 49.61 s
2022-08-24 10:09:35 | [trpo_pendulum] epoch #73 | EpochTime 0.69 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -4.85518
Evaluation/AverageReturn                 67.0543
Evaluation/Iteration                     73
Evaluation/MaxReturn                     69.6658
Evaluation/MinReturn                     64.4428
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.61149
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 0.981099
GaussianMLPPolicy/KL                      0.00429213
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.0955323
GaussianMLPPolicy/LossBefore             -0.0580858
GaussianMLPPolicy/dLoss                   0.0374465
GaussianMLPValueFunction/LossAfter        4.8606
GaussianMLPValueFunction/LossBefore       4.93622
GaussianMLPValueFunction/dLoss            0.0756192
TotalEnvSteps                        102690
-----------------------------------  ---------------
2022-08-24 10:09:36 | [trpo_pendulum] epoch #74 | Saving snapshot...
2022-08-24 10:09:36 | [trpo_pendulum] epoch #74 | Saved
2022-08-24 10:09:36 | [trpo_pendulum] epoch #74 | Time 50.14 s
2022-08-24 10:09:36 | [trpo_pendulum] epoch #74 | EpochTime 0.53 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -4.37857
Evaluation/AverageReturn                 71.104
Evaluation/Iteration                     74
Evaluation/MaxReturn                     74.7427
Evaluation/MinReturn                     67.4654
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.63864
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 0.983299
GaussianMLPPolicy/KL                      0.00924113
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -1.9213
GaussianMLPPolicy/LossBefore             -1.8231
GaussianMLPPolicy/dLoss                   0.0982026
GaussianMLPValueFunction/LossAfter        4.94194
GaussianMLPValueFunction/LossBefore       5.05908
GaussianMLPValueFunction/dLoss            0.117142
TotalEnvSteps                        103799
-----------------------------------  ---------------
2022-08-24 10:09:36 | [trpo_pendulum] epoch #75 | Saving snapshot...
2022-08-24 10:09:36 | [trpo_pendulum] epoch #75 | Saved
2022-08-24 10:09:36 | [trpo_pendulum] epoch #75 | Time 50.72 s
2022-08-24 10:09:36 | [trpo_pendulum] epoch #75 | EpochTime 0.58 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -3.6929
Evaluation/AverageReturn                 73.8486
Evaluation/Iteration                     75
Evaluation/MaxReturn                     75.4787
Evaluation/MinReturn                     72.2185
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.63011
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 0.987269
GaussianMLPPolicy/KL                      0.00863067
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.675414
GaussianMLPPolicy/LossBefore             -0.474821
GaussianMLPPolicy/dLoss                   0.200592
GaussianMLPValueFunction/LossAfter        4.80486
GaussianMLPValueFunction/LossBefore       4.86292
GaussianMLPValueFunction/dLoss            0.058064
TotalEnvSteps                        104952
-----------------------------------  ---------------
2022-08-24 10:09:37 | [trpo_pendulum] epoch #76 | Saving snapshot...
2022-08-24 10:09:37 | [trpo_pendulum] epoch #76 | Saved
2022-08-24 10:09:37 | [trpo_pendulum] epoch #76 | Time 51.51 s
2022-08-24 10:09:37 | [trpo_pendulum] epoch #76 | EpochTime 0.79 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -3.84312
Evaluation/AverageReturn                 62.7138
Evaluation/Iteration                     76
Evaluation/MaxReturn                     63.5236
Evaluation/MinReturn                     61.904
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.809777
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 0.984058
GaussianMLPPolicy/KL                      0.00161406
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.297345
GaussianMLPPolicy/LossBefore              0.297794
GaussianMLPPolicy/dLoss                   0.000448674
GaussianMLPValueFunction/LossAfter        4.57246
GaussianMLPValueFunction/LossBefore       4.62901
GaussianMLPValueFunction/dLoss            0.0565562
TotalEnvSteps                        106619
-----------------------------------  ----------------
2022-08-24 10:09:38 | [trpo_pendulum] epoch #77 | Line search condition violated. Rejecting the step!
2022-08-24 10:09:38 | [trpo_pendulum] epoch #77 | Violated because loss not improving
2022-08-24 10:09:38 | [trpo_pendulum] epoch #77 | Saving snapshot...
2022-08-24 10:09:38 | [trpo_pendulum] epoch #77 | Saved
2022-08-24 10:09:38 | [trpo_pendulum] epoch #77 | Time 52.25 s
2022-08-24 10:09:38 | [trpo_pendulum] epoch #77 | EpochTime 0.74 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn       -4.09773
Evaluation/AverageReturn                 15.5687
Evaluation/Iteration                     77
Evaluation/MaxReturn                     75.131
Evaluation/MinReturn                    -43.9935
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                     59.5623
Evaluation/TerminationRate                0.5
GaussianMLPPolicy/Entropy                 0.984058
GaussianMLPPolicy/KL                      0
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               1.79777
GaussianMLPPolicy/LossBefore              1.79777
GaussianMLPPolicy/dLoss                   0
GaussianMLPValueFunction/LossAfter        4.1721
GaussianMLPValueFunction/LossBefore       4.26606
GaussianMLPValueFunction/dLoss            0.0939627
TotalEnvSteps                        108173
-----------------------------------  --------------
2022-08-24 10:09:39 | [trpo_pendulum] epoch #78 | Saving snapshot...
2022-08-24 10:09:39 | [trpo_pendulum] epoch #78 | Saved
2022-08-24 10:09:39 | [trpo_pendulum] epoch #78 | Time 53.07 s
2022-08-24 10:09:39 | [trpo_pendulum] epoch #78 | EpochTime 0.82 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -4.6041
Evaluation/AverageReturn                 57.5705
Evaluation/Iteration                     78
Evaluation/MaxReturn                     63.0346
Evaluation/MinReturn                     52.1064
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.4641
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 0.980882
GaussianMLPPolicy/KL                      0.00848763
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -1.34445
GaussianMLPPolicy/LossBefore             -1.29334
GaussianMLPPolicy/dLoss                   0.0511096
GaussianMLPValueFunction/LossAfter        4.49027
GaussianMLPValueFunction/LossBefore       4.53944
GaussianMLPValueFunction/dLoss            0.0491762
TotalEnvSteps                        109909
-----------------------------------  ---------------
2022-08-24 10:09:39 | [trpo_pendulum] epoch #79 | Saving snapshot...
2022-08-24 10:09:40 | [trpo_pendulum] epoch #79 | Saved
2022-08-24 10:09:40 | [trpo_pendulum] epoch #79 | Time 53.92 s
2022-08-24 10:09:40 | [trpo_pendulum] epoch #79 | EpochTime 0.84 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -4.1918
Evaluation/AverageReturn                 10.5514
Evaluation/Iteration                     79
Evaluation/MaxReturn                     63.1916
Evaluation/MinReturn                    -42.0889
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                     52.6402
Evaluation/TerminationRate                0.5
GaussianMLPPolicy/Entropy                 0.983962
GaussianMLPPolicy/KL                      0.00675179
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.889322
GaussianMLPPolicy/LossBefore              0.912237
GaussianMLPPolicy/dLoss                   0.0229145
GaussianMLPValueFunction/LossAfter        4.09745
GaussianMLPValueFunction/LossBefore       4.12577
GaussianMLPValueFunction/dLoss            0.0283213
TotalEnvSteps                        111713
-----------------------------------  ---------------
2022-08-24 10:09:40 | [trpo_pendulum] epoch #80 | Saving snapshot...
2022-08-24 10:09:40 | [trpo_pendulum] epoch #80 | Saved
2022-08-24 10:09:40 | [trpo_pendulum] epoch #80 | Time 54.61 s
2022-08-24 10:09:40 | [trpo_pendulum] epoch #80 | EpochTime 0.69 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn       -4.26937
Evaluation/AverageReturn                 69.3011
Evaluation/Iteration                     80
Evaluation/MaxReturn                     74.5008
Evaluation/MinReturn                     64.1015
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.19968
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 0.977849
GaussianMLPPolicy/KL                      0.0065113
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -2.49287
GaussianMLPPolicy/LossBefore             -2.48089
GaussianMLPPolicy/dLoss                   0.011977
GaussianMLPValueFunction/LossAfter        4.53952
GaussianMLPValueFunction/LossBefore       4.63289
GaussianMLPValueFunction/dLoss            0.0933719
TotalEnvSteps                        113139
-----------------------------------  --------------
2022-08-24 10:09:41 | [trpo_pendulum] epoch #81 | Saving snapshot...
2022-08-24 10:09:41 | [trpo_pendulum] epoch #81 | Saved
2022-08-24 10:09:41 | [trpo_pendulum] epoch #81 | Time 55.44 s
2022-08-24 10:09:41 | [trpo_pendulum] epoch #81 | EpochTime 0.83 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn       -4.12985
Evaluation/AverageReturn                 10.3648
Evaluation/Iteration                     81
Evaluation/MaxReturn                     65.641
Evaluation/MinReturn                    -44.9113
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                     55.2762
Evaluation/TerminationRate                0.5
GaussianMLPPolicy/Entropy                 0.958908
GaussianMLPPolicy/KL                      0.0110496
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               1.6094
GaussianMLPPolicy/LossBefore              1.64195
GaussianMLPPolicy/dLoss                   0.0325503
GaussianMLPValueFunction/LossAfter        3.99947
GaussianMLPValueFunction/LossBefore       4.07831
GaussianMLPValueFunction/dLoss            0.0788441
TotalEnvSteps                        115037
-----------------------------------  --------------
2022-08-24 10:09:42 | [trpo_pendulum] epoch #82 | Saving snapshot...
2022-08-24 10:09:42 | [trpo_pendulum] epoch #82 | Saved
2022-08-24 10:09:42 | [trpo_pendulum] epoch #82 | Time 56.25 s
2022-08-24 10:09:42 | [trpo_pendulum] epoch #82 | EpochTime 0.79 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -4.40831
Evaluation/AverageReturn                 65.3105
Evaluation/Iteration                     82
Evaluation/MaxReturn                     69.6664
Evaluation/MinReturn                     60.9547
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.35584
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 0.959223
GaussianMLPPolicy/KL                      6.12702e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -2.05687
GaussianMLPPolicy/LossBefore             -2.05467
GaussianMLPPolicy/dLoss                   0.00219917
GaussianMLPValueFunction/LossAfter        4.4982
GaussianMLPValueFunction/LossBefore       4.59918
GaussianMLPValueFunction/dLoss            0.100987
TotalEnvSteps                        116717
-----------------------------------  ----------------
2022-08-24 10:09:43 | [trpo_pendulum] epoch #83 | Saving snapshot...
2022-08-24 10:09:43 | [trpo_pendulum] epoch #83 | Saved
2022-08-24 10:09:43 | [trpo_pendulum] epoch #83 | Time 57.19 s
2022-08-24 10:09:43 | [trpo_pendulum] epoch #83 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -4.49677
Evaluation/AverageReturn                -43.6037
Evaluation/Iteration                     83
Evaluation/MaxReturn                    -42.5109
Evaluation/MinReturn                    -44.6965
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.09281
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 0.957304
GaussianMLPPolicy/KL                      9.50944e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               3.08877
GaussianMLPPolicy/LossBefore              3.0889
GaussianMLPPolicy/dLoss                   0.000133038
GaussianMLPValueFunction/LossAfter        3.5871
GaussianMLPValueFunction/LossBefore       3.80143
GaussianMLPValueFunction/dLoss            0.214328
TotalEnvSteps                        118715
-----------------------------------  ----------------
2022-08-24 10:09:44 | [trpo_pendulum] epoch #84 | Saving snapshot...
2022-08-24 10:09:44 | [trpo_pendulum] epoch #84 | Saved
2022-08-24 10:09:44 | [trpo_pendulum] epoch #84 | Time 58.00 s
2022-08-24 10:09:44 | [trpo_pendulum] epoch #84 | EpochTime 0.80 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -4.97777
Evaluation/AverageReturn                 10.1971
Evaluation/Iteration                     84
Evaluation/MaxReturn                     63.226
Evaluation/MinReturn                    -42.8318
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                     53.0289
Evaluation/TerminationRate                0.5
GaussianMLPPolicy/Entropy                 0.953806
GaussianMLPPolicy/KL                      0.00573269
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -1.51842
GaussianMLPPolicy/LossBefore             -1.45131
GaussianMLPPolicy/dLoss                   0.0671027
GaussianMLPValueFunction/LossAfter        4.10867
GaussianMLPValueFunction/LossBefore       4.14985
GaussianMLPValueFunction/dLoss            0.0411787
TotalEnvSteps                        120532
-----------------------------------  ---------------
2022-08-24 10:09:44 | [trpo_pendulum] epoch #85 | Saving snapshot...
2022-08-24 10:09:44 | [trpo_pendulum] epoch #85 | Saved
2022-08-24 10:09:44 | [trpo_pendulum] epoch #85 | Time 58.69 s
2022-08-24 10:09:44 | [trpo_pendulum] epoch #85 | EpochTime 0.67 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -3.77632
Evaluation/AverageReturn                 65.9415
Evaluation/Iteration                     85
Evaluation/MaxReturn                     79.4698
Evaluation/MinReturn                     52.4133
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                     13.5282
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 0.951069
GaussianMLPPolicy/KL                      0.000303131
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -2.4773
GaussianMLPPolicy/LossBefore             -2.47469
GaussianMLPPolicy/dLoss                   0.00260782
GaussianMLPValueFunction/LossAfter        4.58138
GaussianMLPValueFunction/LossBefore       4.72278
GaussianMLPValueFunction/dLoss            0.141401
TotalEnvSteps                        121985
-----------------------------------  ----------------
2022-08-24 10:09:45 | [trpo_pendulum] epoch #86 | Saving snapshot...
2022-08-24 10:09:45 | [trpo_pendulum] epoch #86 | Saved
2022-08-24 10:09:45 | [trpo_pendulum] epoch #86 | Time 59.28 s
2022-08-24 10:09:45 | [trpo_pendulum] epoch #86 | EpochTime 0.59 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn       -4.57293
Evaluation/AverageReturn                 71.7385
Evaluation/Iteration                     86
Evaluation/MaxReturn                     78.0773
Evaluation/MinReturn                     65.3997
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.3388
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 0.957232
GaussianMLPPolicy/KL                      0.0104894
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -2.09439
GaussianMLPPolicy/LossBefore             -1.96602
GaussianMLPPolicy/dLoss                   0.128374
GaussianMLPValueFunction/LossAfter        4.6283
GaussianMLPValueFunction/LossBefore       4.7133
GaussianMLPValueFunction/dLoss            0.0850015
TotalEnvSteps                        123181
-----------------------------------  --------------
2022-08-24 10:09:45 | [trpo_pendulum] epoch #87 | Saving snapshot...
2022-08-24 10:09:46 | [trpo_pendulum] epoch #87 | Saved
2022-08-24 10:09:46 | [trpo_pendulum] epoch #87 | Time 59.94 s
2022-08-24 10:09:46 | [trpo_pendulum] epoch #87 | EpochTime 0.66 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -2.96842
Evaluation/AverageReturn                 80.3297
Evaluation/Iteration                     87
Evaluation/MaxReturn                     82.3349
Evaluation/MinReturn                     77.2322
Evaluation/NumEpisodes                    3
Evaluation/StdReturn                      2.22175
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 0.956492
GaussianMLPPolicy/KL                      0.0116819
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -2.83723
GaussianMLPPolicy/LossBefore             -2.83668
GaussianMLPPolicy/dLoss                   0.000550508
GaussianMLPValueFunction/LossAfter        4.73445
GaussianMLPValueFunction/LossBefore       4.84521
GaussianMLPValueFunction/dLoss            0.110762
TotalEnvSteps                        124538
-----------------------------------  ----------------
2022-08-24 10:09:46 | [trpo_pendulum] epoch #88 | Saving snapshot...
2022-08-24 10:09:46 | [trpo_pendulum] epoch #88 | Saved
2022-08-24 10:09:46 | [trpo_pendulum] epoch #88 | Time 60.54 s
2022-08-24 10:09:46 | [trpo_pendulum] epoch #88 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -4.19692
Evaluation/AverageReturn                 71.4018
Evaluation/Iteration                     88
Evaluation/MaxReturn                     71.9577
Evaluation/MinReturn                     70.846
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.555826
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 0.960189
GaussianMLPPolicy/KL                      0.00591564
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.810598
GaussianMLPPolicy/LossBefore              0.822673
GaussianMLPPolicy/dLoss                   0.0120755
GaussianMLPValueFunction/LossAfter        4.50717
GaussianMLPValueFunction/LossBefore       4.58279
GaussianMLPValueFunction/dLoss            0.075623
TotalEnvSteps                        125839
-----------------------------------  ---------------
2022-08-24 10:09:47 | [trpo_pendulum] epoch #89 | Saving snapshot...
2022-08-24 10:09:47 | [trpo_pendulum] epoch #89 | Saved
2022-08-24 10:09:47 | [trpo_pendulum] epoch #89 | Time 61.21 s
2022-08-24 10:09:47 | [trpo_pendulum] epoch #89 | EpochTime 0.67 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -3.75885
Evaluation/AverageReturn                 70.7911
Evaluation/Iteration                     89
Evaluation/MaxReturn                     75.8668
Evaluation/MinReturn                     65.7153
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.07572
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 0.979464
GaussianMLPPolicy/KL                      0.00549236
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.74127
GaussianMLPPolicy/LossBefore             -0.627401
GaussianMLPPolicy/dLoss                   0.11387
GaussianMLPValueFunction/LossAfter        4.4237
GaussianMLPValueFunction/LossBefore       4.44211
GaussianMLPValueFunction/dLoss            0.018405
TotalEnvSteps                        127231
-----------------------------------  ---------------
2022-08-24 10:09:47 | [trpo_pendulum] epoch #90 | Saving snapshot...
2022-08-24 10:09:47 | [trpo_pendulum] epoch #90 | Saved
2022-08-24 10:09:47 | [trpo_pendulum] epoch #90 | Time 61.91 s
2022-08-24 10:09:47 | [trpo_pendulum] epoch #90 | EpochTime 0.70 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -3.31838
Evaluation/AverageReturn                 75.8723
Evaluation/Iteration                     90
Evaluation/MaxReturn                     79.1653
Evaluation/MinReturn                     69.56
Evaluation/NumEpisodes                    3
Evaluation/StdReturn                      4.46486
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 0.982771
GaussianMLPPolicy/KL                      0.00521926
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.16516
GaussianMLPPolicy/LossBefore             -2.98832
GaussianMLPPolicy/dLoss                   0.176844
GaussianMLPValueFunction/LossAfter        4.58174
GaussianMLPValueFunction/LossBefore       4.65876
GaussianMLPValueFunction/dLoss            0.0770206
TotalEnvSteps                        128757
-----------------------------------  ---------------
2022-08-24 10:09:48 | [trpo_pendulum] epoch #91 | Saving snapshot...
2022-08-24 10:09:48 | [trpo_pendulum] epoch #91 | Saved
2022-08-24 10:09:48 | [trpo_pendulum] epoch #91 | Time 62.51 s
2022-08-24 10:09:48 | [trpo_pendulum] epoch #91 | EpochTime 0.60 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn       -2.46902
Evaluation/AverageReturn                 80.2986
Evaluation/Iteration                     91
Evaluation/MaxReturn                     82.5869
Evaluation/MinReturn                     77.4065
Evaluation/NumEpisodes                    3
Evaluation/StdReturn                      2.15756
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 0.994083
GaussianMLPPolicy/KL                      0.0248318
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.51578
GaussianMLPPolicy/LossBefore             -3.3384
GaussianMLPPolicy/dLoss                   0.177375
GaussianMLPValueFunction/LossAfter        4.59091
GaussianMLPValueFunction/LossBefore       4.66492
GaussianMLPValueFunction/dLoss            0.0740085
TotalEnvSteps                        130009
-----------------------------------  --------------
2022-08-24 10:09:49 | [trpo_pendulum] epoch #92 | Saving snapshot...
2022-08-24 10:09:49 | [trpo_pendulum] epoch #92 | Saved
2022-08-24 10:09:49 | [trpo_pendulum] epoch #92 | Time 63.04 s
2022-08-24 10:09:49 | [trpo_pendulum] epoch #92 | EpochTime 0.53 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -3.90013
Evaluation/AverageReturn                 74.0722
Evaluation/Iteration                     92
Evaluation/MaxReturn                     76.3274
Evaluation/MinReturn                     71.8169
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.25527
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 0.993226
GaussianMLPPolicy/KL                      0.00511345
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.254712
GaussianMLPPolicy/LossBefore              0.419851
GaussianMLPPolicy/dLoss                   0.165139
GaussianMLPValueFunction/LossAfter        4.52346
GaussianMLPValueFunction/LossBefore       4.58154
GaussianMLPValueFunction/dLoss            0.0580831
TotalEnvSteps                        131077
-----------------------------------  ---------------
2022-08-24 10:09:49 | [trpo_pendulum] epoch #93 | Saving snapshot...
2022-08-24 10:09:49 | [trpo_pendulum] epoch #93 | Saved
2022-08-24 10:09:49 | [trpo_pendulum] epoch #93 | Time 63.60 s
2022-08-24 10:09:49 | [trpo_pendulum] epoch #93 | EpochTime 0.56 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn       -1.32123
Evaluation/AverageReturn                 80.5578
Evaluation/Iteration                     93
Evaluation/MaxReturn                     82.86
Evaluation/MinReturn                     78.0893
Evaluation/NumEpisodes                    3
Evaluation/StdReturn                      1.95122
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 0.997023
GaussianMLPPolicy/KL                      0.0100529
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -4.81142
GaussianMLPPolicy/LossBefore             -4.64073
GaussianMLPPolicy/dLoss                   0.170692
GaussianMLPValueFunction/LossAfter        4.53818
GaussianMLPValueFunction/LossBefore       4.63455
GaussianMLPValueFunction/dLoss            0.0963702
TotalEnvSteps                        132178
-----------------------------------  --------------
2022-08-24 10:09:50 | [trpo_pendulum] epoch #94 | Saving snapshot...
2022-08-24 10:09:50 | [trpo_pendulum] epoch #94 | Saved
2022-08-24 10:09:50 | [trpo_pendulum] epoch #94 | Time 64.14 s
2022-08-24 10:09:50 | [trpo_pendulum] epoch #94 | EpochTime 0.53 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -2.2001
Evaluation/AverageReturn                 77.2403
Evaluation/Iteration                     94
Evaluation/MaxReturn                     81.8985
Evaluation/MinReturn                     72.3003
Evaluation/NumEpisodes                    3
Evaluation/StdReturn                      3.92348
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 0.999971
GaussianMLPPolicy/KL                      0.00163104
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -1.44484
GaussianMLPPolicy/LossBefore             -1.35263
GaussianMLPPolicy/dLoss                   0.0922123
GaussianMLPValueFunction/LossAfter        4.63326
GaussianMLPValueFunction/LossBefore       4.66415
GaussianMLPValueFunction/dLoss            0.0308948
TotalEnvSteps                        133303
-----------------------------------  ---------------
2022-08-24 10:09:50 | [trpo_pendulum] epoch #95 | Saving snapshot...
2022-08-24 10:09:50 | [trpo_pendulum] epoch #95 | Saved
2022-08-24 10:09:50 | [trpo_pendulum] epoch #95 | Time 64.71 s
2022-08-24 10:09:50 | [trpo_pendulum] epoch #95 | EpochTime 0.57 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn       -1.98034
Evaluation/AverageReturn                 79.834
Evaluation/Iteration                     95
Evaluation/MaxReturn                     81.8207
Evaluation/MinReturn                     76.1033
Evaluation/NumEpisodes                    3
Evaluation/StdReturn                      2.63988
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 1.0035
GaussianMLPPolicy/KL                      0.006858
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.56606
GaussianMLPPolicy/LossBefore             -3.51157
GaussianMLPPolicy/dLoss                   0.0544939
GaussianMLPValueFunction/LossAfter        4.53761
GaussianMLPValueFunction/LossBefore       4.57331
GaussianMLPValueFunction/dLoss            0.0357037
TotalEnvSteps                        134384
-----------------------------------  --------------
2022-08-24 10:09:51 | [trpo_pendulum] epoch #96 | Saving snapshot...
2022-08-24 10:09:51 | [trpo_pendulum] epoch #96 | Saved
2022-08-24 10:09:51 | [trpo_pendulum] epoch #96 | Time 65.31 s
2022-08-24 10:09:51 | [trpo_pendulum] epoch #96 | EpochTime 0.60 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -4.36207
Evaluation/AverageReturn                 69.2101
Evaluation/Iteration                     96
Evaluation/MaxReturn                     74.2433
Evaluation/MinReturn                     64.177
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.03317
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 1.00978
GaussianMLPPolicy/KL                      0.00700062
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               1.6253
GaussianMLPPolicy/LossBefore              1.85564
GaussianMLPPolicy/dLoss                   0.23034
GaussianMLPValueFunction/LossAfter        4.37801
GaussianMLPValueFunction/LossBefore       4.49678
GaussianMLPValueFunction/dLoss            0.118777
TotalEnvSteps                        135636
-----------------------------------  ---------------
2022-08-24 10:09:52 | [trpo_pendulum] epoch #97 | Saving snapshot...
2022-08-24 10:09:52 | [trpo_pendulum] epoch #97 | Saved
2022-08-24 10:09:52 | [trpo_pendulum] epoch #97 | Time 66.00 s
2022-08-24 10:09:52 | [trpo_pendulum] epoch #97 | EpochTime 0.69 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -4.2697
Evaluation/AverageReturn                 10.9532
Evaluation/Iteration                     97
Evaluation/MaxReturn                     73.1236
Evaluation/MinReturn                    -51.2172
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                     62.1704
Evaluation/TerminationRate                0.5
GaussianMLPPolicy/Entropy                 1.00944
GaussianMLPPolicy/KL                      0.00124752
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               2.67222
GaussianMLPPolicy/LossBefore              2.67256
GaussianMLPPolicy/dLoss                   0.000336409
GaussianMLPValueFunction/LossAfter        4.21537
GaussianMLPValueFunction/LossBefore       4.34903
GaussianMLPValueFunction/dLoss            0.133661
TotalEnvSteps                        137093
-----------------------------------  ----------------
2022-08-24 10:09:52 | [trpo_pendulum] epoch #98 | Saving snapshot...
2022-08-24 10:09:52 | [trpo_pendulum] epoch #98 | Saved
2022-08-24 10:09:52 | [trpo_pendulum] epoch #98 | Time 66.64 s
2022-08-24 10:09:52 | [trpo_pendulum] epoch #98 | EpochTime 0.63 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -3.83863
Evaluation/AverageReturn                 73.3871
Evaluation/Iteration                     98
Evaluation/MaxReturn                     73.8614
Evaluation/MinReturn                     72.7574
Evaluation/NumEpisodes                    3
Evaluation/StdReturn                      0.463919
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 1.01321
GaussianMLPPolicy/KL                      0.00544778
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -5.91892
GaussianMLPPolicy/LossBefore             -5.78109
GaussianMLPPolicy/dLoss                   0.137829
GaussianMLPValueFunction/LossAfter        4.4369
GaussianMLPValueFunction/LossBefore       4.66922
GaussianMLPValueFunction/dLoss            0.232319
TotalEnvSteps                        138486
-----------------------------------  ---------------
2022-08-24 10:09:53 | [trpo_pendulum] epoch #99 | Saving snapshot...
2022-08-24 10:09:53 | [trpo_pendulum] epoch #99 | Saved
2022-08-24 10:09:53 | [trpo_pendulum] epoch #99 | Time 67.22 s
2022-08-24 10:09:53 | [trpo_pendulum] epoch #99 | EpochTime 0.58 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn       -5.50814
Evaluation/AverageReturn                 61.7945
Evaluation/Iteration                     99
Evaluation/MaxReturn                     65.1398
Evaluation/MinReturn                     58.4492
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.34529
Evaluation/TerminationRate                1
GaussianMLPPolicy/Entropy                 1.01503
GaussianMLPPolicy/KL                      0.0116992
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.112952
GaussianMLPPolicy/LossBefore              0.20804
GaussianMLPPolicy/dLoss                   0.0950881
GaussianMLPValueFunction/LossAfter        4.42135
GaussianMLPValueFunction/LossBefore       4.45783
GaussianMLPValueFunction/dLoss            0.036479
TotalEnvSteps                        139650
-----------------------------------  --------------
