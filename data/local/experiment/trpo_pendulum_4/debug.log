2022-08-23 10:37:18 | [trpo_pendulum] Logging to d:\Github\DRSOM-for-RL\data/local/experiment/trpo_pendulum_4
2022-08-23 10:37:18 | [trpo_pendulum] Obtaining samples...
2022-08-23 10:37:19 | [trpo_pendulum] epoch #0 | Saving snapshot...
2022-08-23 10:37:19 | [trpo_pendulum] epoch #0 | Saved
2022-08-23 10:37:19 | [trpo_pendulum] epoch #0 | Time 1.00 s
2022-08-23 10:37:19 | [trpo_pendulum] epoch #0 | EpochTime 1.00 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn    -10.8561
Evaluation/AverageReturn             -108.645
Evaluation/Iteration                    0
Evaluation/MaxReturn                 -103.75
Evaluation/MinReturn                 -113.54
Evaluation/NumEpisodes                  2
Evaluation/StdReturn                    4.89498
Evaluation/TerminationRate              0
GaussianMLPPolicy/Entropy               1.39514
GaussianMLPPolicy/KL                    0.00960769
GaussianMLPPolicy/KLBefore              0
GaussianMLPPolicy/LossAfter             3.40337
GaussianMLPPolicy/LossBefore            3.41378
GaussianMLPPolicy/dLoss                 0.010407
GaussianMLPValueFunction/LossAfter     12.9548
GaussianMLPValueFunction/LossBefore    49.6662
GaussianMLPValueFunction/dLoss         36.7114
TotalEnvSteps                        1998
-----------------------------------  -------------
2022-08-23 10:37:20 | [trpo_pendulum] epoch #1 | Saving snapshot...
2022-08-23 10:37:20 | [trpo_pendulum] epoch #1 | Saved
2022-08-23 10:37:20 | [trpo_pendulum] epoch #1 | Time 2.08 s
2022-08-23 10:37:20 | [trpo_pendulum] epoch #1 | EpochTime 1.07 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn    -11.8717
Evaluation/AverageReturn             -101.668
Evaluation/Iteration                    1
Evaluation/MaxReturn                 -100.811
Evaluation/MinReturn                 -102.525
Evaluation/NumEpisodes                  2
Evaluation/StdReturn                    0.856765
Evaluation/TerminationRate              0
GaussianMLPPolicy/Entropy               1.37277
GaussianMLPPolicy/KL                    0.00549847
GaussianMLPPolicy/KLBefore              0
GaussianMLPPolicy/LossAfter             1.29548
GaussianMLPPolicy/LossBefore            1.30608
GaussianMLPPolicy/dLoss                 0.0106019
GaussianMLPValueFunction/LossAfter      3.46681
GaussianMLPValueFunction/LossBefore     8.95755
GaussianMLPValueFunction/dLoss          5.49074
TotalEnvSteps                        3996
-----------------------------------  -------------
2022-08-23 10:37:21 | [trpo_pendulum] epoch #2 | Saving snapshot...
2022-08-23 10:37:21 | [trpo_pendulum] epoch #2 | Saved
2022-08-23 10:37:21 | [trpo_pendulum] epoch #2 | Time 3.10 s
2022-08-23 10:37:21 | [trpo_pendulum] epoch #2 | EpochTime 1.01 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn     -8.49506
Evaluation/AverageReturn              -89.9575
Evaluation/Iteration                    2
Evaluation/MaxReturn                  -88.6702
Evaluation/MinReturn                  -91.2448
Evaluation/NumEpisodes                  2
Evaluation/StdReturn                    1.2873
Evaluation/TerminationRate              0
GaussianMLPPolicy/Entropy               1.36438
GaussianMLPPolicy/KL                    0.00527914
GaussianMLPPolicy/KLBefore              0
GaussianMLPPolicy/LossAfter            -0.1206
GaussianMLPPolicy/LossBefore           -0.115099
GaussianMLPPolicy/dLoss                 0.00550057
GaussianMLPValueFunction/LossAfter      2.59192
GaussianMLPValueFunction/LossBefore     2.66226
GaussianMLPValueFunction/dLoss          0.0703344
TotalEnvSteps                        5994
-----------------------------------  -------------
2022-08-23 10:37:22 | [trpo_pendulum] epoch #3 | Saving snapshot...
2022-08-23 10:37:22 | [trpo_pendulum] epoch #3 | Saved
2022-08-23 10:37:22 | [trpo_pendulum] epoch #3 | Time 4.10 s
2022-08-23 10:37:22 | [trpo_pendulum] epoch #3 | EpochTime 1.00 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn    -10.1278
Evaluation/AverageReturn              -93.5668
Evaluation/Iteration                    3
Evaluation/MaxReturn                  -87.6105
Evaluation/MinReturn                  -99.5232
Evaluation/NumEpisodes                  2
Evaluation/StdReturn                    5.95638
Evaluation/TerminationRate              0
GaussianMLPPolicy/Entropy               1.3062
GaussianMLPPolicy/KL                    0.00635229
GaussianMLPPolicy/KLBefore              0
GaussianMLPPolicy/LossAfter             0.143751
GaussianMLPPolicy/LossBefore            0.153462
GaussianMLPPolicy/dLoss                 0.00971094
GaussianMLPValueFunction/LossAfter      2.65853
GaussianMLPValueFunction/LossBefore     2.73948
GaussianMLPValueFunction/dLoss          0.0809443
TotalEnvSteps                        7992
-----------------------------------  -------------
2022-08-23 10:37:23 | [trpo_pendulum] epoch #4 | Saving snapshot...
2022-08-23 10:37:23 | [trpo_pendulum] epoch #4 | Saved
2022-08-23 10:37:23 | [trpo_pendulum] epoch #4 | Time 5.19 s
2022-08-23 10:37:23 | [trpo_pendulum] epoch #4 | EpochTime 1.08 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn     -8.0509
Evaluation/AverageReturn              -83.6893
Evaluation/Iteration                    4
Evaluation/MaxReturn                  -82.6741
Evaluation/MinReturn                  -84.7045
Evaluation/NumEpisodes                  2
Evaluation/StdReturn                    1.01517
Evaluation/TerminationRate              0
GaussianMLPPolicy/Entropy               1.28989
GaussianMLPPolicy/KL                    0.00626884
GaussianMLPPolicy/KLBefore              0
GaussianMLPPolicy/LossAfter            -0.165601
GaussianMLPPolicy/LossBefore           -0.158239
GaussianMLPPolicy/dLoss                 0.00736222
GaussianMLPValueFunction/LossAfter      2.67918
GaussianMLPValueFunction/LossBefore     3.10281
GaussianMLPValueFunction/dLoss          0.423627
TotalEnvSteps                        9990
-----------------------------------  -------------
2022-08-23 10:37:24 | [trpo_pendulum] epoch #5 | Saving snapshot...
2022-08-23 10:37:24 | [trpo_pendulum] epoch #5 | Saved
2022-08-23 10:37:24 | [trpo_pendulum] epoch #5 | Time 6.20 s
2022-08-23 10:37:24 | [trpo_pendulum] epoch #5 | EpochTime 1.01 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -9.26518
Evaluation/AverageReturn               -85.2306
Evaluation/Iteration                     5
Evaluation/MaxReturn                   -83.1431
Evaluation/MinReturn                   -87.3181
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     2.08749
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.24904
GaussianMLPPolicy/KL                     0.00568646
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.0573434
GaussianMLPPolicy/LossBefore            -0.0412846
GaussianMLPPolicy/dLoss                  0.0160589
GaussianMLPValueFunction/LossAfter       2.92091
GaussianMLPValueFunction/LossBefore      3.0486
GaussianMLPValueFunction/dLoss           0.127682
TotalEnvSteps                        11988
-----------------------------------  --------------
2022-08-23 10:37:25 | [trpo_pendulum] epoch #6 | Saving snapshot...
2022-08-23 10:37:25 | [trpo_pendulum] epoch #6 | Saved
2022-08-23 10:37:25 | [trpo_pendulum] epoch #6 | Time 7.26 s
2022-08-23 10:37:25 | [trpo_pendulum] epoch #6 | EpochTime 1.05 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -6.98805
Evaluation/AverageReturn               -71.9176
Evaluation/Iteration                     6
Evaluation/MaxReturn                   -68.6166
Evaluation/MinReturn                   -75.2185
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     3.30093
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.23033
GaussianMLPPolicy/KL                     0.00616349
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.411202
GaussianMLPPolicy/LossBefore            -0.408253
GaussianMLPPolicy/dLoss                  0.00294873
GaussianMLPValueFunction/LossAfter       2.08272
GaussianMLPValueFunction/LossBefore      2.67239
GaussianMLPValueFunction/dLoss           0.589674
TotalEnvSteps                        13986
-----------------------------------  --------------
2022-08-23 10:37:26 | [trpo_pendulum] epoch #7 | Saving snapshot...
2022-08-23 10:37:26 | [trpo_pendulum] epoch #7 | Saved
2022-08-23 10:37:26 | [trpo_pendulum] epoch #7 | Time 8.18 s
2022-08-23 10:37:26 | [trpo_pendulum] epoch #7 | EpochTime 0.92 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -6.18341
Evaluation/AverageReturn               -70.6878
Evaluation/Iteration                     7
Evaluation/MaxReturn                   -70.6583
Evaluation/MinReturn                   -70.7172
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.0294764
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.14955
GaussianMLPPolicy/KL                     0.00771476
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.0526313
GaussianMLPPolicy/LossBefore            -0.0412238
GaussianMLPPolicy/dLoss                  0.0114076
GaussianMLPValueFunction/LossAfter       2.08484
GaussianMLPValueFunction/LossBefore      2.12386
GaussianMLPValueFunction/dLoss           0.0390272
TotalEnvSteps                        15984
-----------------------------------  --------------
2022-08-23 10:37:27 | [trpo_pendulum] epoch #8 | Saving snapshot...
2022-08-23 10:37:27 | [trpo_pendulum] epoch #8 | Saved
2022-08-23 10:37:27 | [trpo_pendulum] epoch #8 | Time 9.12 s
2022-08-23 10:37:27 | [trpo_pendulum] epoch #8 | EpochTime 0.93 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -6.80442
Evaluation/AverageReturn               -62.9695
Evaluation/Iteration                     8
Evaluation/MaxReturn                   -61.2251
Evaluation/MinReturn                   -64.7139
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     1.74438
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.12121
GaussianMLPPolicy/KL                     0.00548653
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.299928
GaussianMLPPolicy/LossBefore            -0.292456
GaussianMLPPolicy/dLoss                  0.00747213
GaussianMLPValueFunction/LossAfter       1.66706
GaussianMLPValueFunction/LossBefore      1.96635
GaussianMLPValueFunction/dLoss           0.299291
TotalEnvSteps                        17982
-----------------------------------  --------------
2022-08-23 10:37:28 | [trpo_pendulum] epoch #9 | Saving snapshot...
2022-08-23 10:37:28 | [trpo_pendulum] epoch #9 | Saved
2022-08-23 10:37:28 | [trpo_pendulum] epoch #9 | Time 10.09 s
2022-08-23 10:37:28 | [trpo_pendulum] epoch #9 | EpochTime 0.96 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -5.59162
Evaluation/AverageReturn               -58.47
Evaluation/Iteration                     9
Evaluation/MaxReturn                   -53.352
Evaluation/MinReturn                   -63.5881
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     5.11804
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.06217
GaussianMLPPolicy/KL                     0.00593051
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.099497
GaussianMLPPolicy/LossBefore            -0.0916207
GaussianMLPPolicy/dLoss                  0.00787625
GaussianMLPValueFunction/LossAfter       1.88214
GaussianMLPValueFunction/LossBefore      1.93667
GaussianMLPValueFunction/dLoss           0.0545368
TotalEnvSteps                        19980
-----------------------------------  --------------
2022-08-23 10:37:29 | [trpo_pendulum] epoch #10 | Saving snapshot...
2022-08-23 10:37:29 | [trpo_pendulum] epoch #10 | Saved
2022-08-23 10:37:29 | [trpo_pendulum] epoch #10 | Time 11.06 s
2022-08-23 10:37:29 | [trpo_pendulum] epoch #10 | EpochTime 0.97 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -5.18649
Evaluation/AverageReturn               -53.831
Evaluation/Iteration                    10
Evaluation/MaxReturn                   -53.4116
Evaluation/MinReturn                   -54.2504
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.419422
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.0519
GaussianMLPPolicy/KL                     0.0066739
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.160051
GaussianMLPPolicy/LossBefore            -0.153332
GaussianMLPPolicy/dLoss                  0.00671819
GaussianMLPValueFunction/LossAfter       1.6409
GaussianMLPValueFunction/LossBefore      1.71715
GaussianMLPValueFunction/dLoss           0.0762445
TotalEnvSteps                        21978
-----------------------------------  --------------
2022-08-23 10:37:30 | [trpo_pendulum] epoch #11 | Saving snapshot...
2022-08-23 10:37:30 | [trpo_pendulum] epoch #11 | Saved
2022-08-23 10:37:30 | [trpo_pendulum] epoch #11 | Time 12.09 s
2022-08-23 10:37:30 | [trpo_pendulum] epoch #11 | EpochTime 1.02 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -5.28123
Evaluation/AverageReturn               -49.0465
Evaluation/Iteration                    11
Evaluation/MaxReturn                   -48.8773
Evaluation/MinReturn                   -49.2157
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.169186
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.0287
GaussianMLPPolicy/KL                     0.00474701
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.149037
GaussianMLPPolicy/LossBefore            -0.145146
GaussianMLPPolicy/dLoss                  0.0038915
GaussianMLPValueFunction/LossAfter       1.50821
GaussianMLPValueFunction/LossBefore      1.58851
GaussianMLPValueFunction/dLoss           0.0803012
TotalEnvSteps                        23976
-----------------------------------  --------------
2022-08-23 10:37:31 | [trpo_pendulum] epoch #12 | Saving snapshot...
2022-08-23 10:37:31 | [trpo_pendulum] epoch #12 | Saved
2022-08-23 10:37:31 | [trpo_pendulum] epoch #12 | Time 13.05 s
2022-08-23 10:37:31 | [trpo_pendulum] epoch #12 | EpochTime 0.96 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -4.97156
Evaluation/AverageReturn               -46.9639
Evaluation/Iteration                    12
Evaluation/MaxReturn                   -46.2729
Evaluation/MinReturn                   -47.6549
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.690988
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.991793
GaussianMLPPolicy/KL                     0.00852013
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.0221783
GaussianMLPPolicy/LossBefore            -0.0187478
GaussianMLPPolicy/dLoss                  0.00343051
GaussianMLPValueFunction/LossAfter       1.44543
GaussianMLPValueFunction/LossBefore      1.48709
GaussianMLPValueFunction/dLoss           0.0416512
TotalEnvSteps                        25974
-----------------------------------  --------------
2022-08-23 10:37:32 | [trpo_pendulum] epoch #13 | Saving snapshot...
2022-08-23 10:37:32 | [trpo_pendulum] epoch #13 | Saved
2022-08-23 10:37:32 | [trpo_pendulum] epoch #13 | Time 14.02 s
2022-08-23 10:37:32 | [trpo_pendulum] epoch #13 | EpochTime 0.97 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -4.31098
Evaluation/AverageReturn               -44.4243
Evaluation/Iteration                    13
Evaluation/MaxReturn                   -43.7455
Evaluation/MinReturn                   -45.1031
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.678812
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.979525
GaussianMLPPolicy/KL                     0.00618918
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.0743996
GaussianMLPPolicy/LossBefore            -0.0736815
GaussianMLPPolicy/dLoss                  0.000718102
GaussianMLPValueFunction/LossAfter       1.36682
GaussianMLPValueFunction/LossBefore      1.392
GaussianMLPValueFunction/dLoss           0.0251802
TotalEnvSteps                        27972
-----------------------------------  ---------------
2022-08-23 10:37:33 | [trpo_pendulum] epoch #14 | Saving snapshot...
2022-08-23 10:37:33 | [trpo_pendulum] epoch #14 | Saved
2022-08-23 10:37:33 | [trpo_pendulum] epoch #14 | Time 15.01 s
2022-08-23 10:37:33 | [trpo_pendulum] epoch #14 | EpochTime 0.98 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -4.37502
Evaluation/AverageReturn               -42.595
Evaluation/Iteration                    14
Evaluation/MaxReturn                   -42.5212
Evaluation/MinReturn                   -42.6687
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.0737716
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.963182
GaussianMLPPolicy/KL                     0.00335075
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.0470175
GaussianMLPPolicy/LossBefore            -0.0449395
GaussianMLPPolicy/dLoss                  0.002078
GaussianMLPValueFunction/LossAfter       1.34838
GaussianMLPValueFunction/LossBefore      1.36338
GaussianMLPValueFunction/dLoss           0.0150036
TotalEnvSteps                        29970
-----------------------------------  --------------
2022-08-23 10:37:34 | [trpo_pendulum] epoch #15 | Saving snapshot...
2022-08-23 10:37:34 | [trpo_pendulum] epoch #15 | Saved
2022-08-23 10:37:34 | [trpo_pendulum] epoch #15 | Time 16.00 s
2022-08-23 10:37:34 | [trpo_pendulum] epoch #15 | EpochTime 0.98 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -4.69227
Evaluation/AverageReturn               -41.6703
Evaluation/Iteration                    15
Evaluation/MaxReturn                   -41.2292
Evaluation/MinReturn                   -42.1113
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.441062
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.946036
GaussianMLPPolicy/KL                     0.00117773
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.0256862
GaussianMLPPolicy/LossBefore            -0.0253653
GaussianMLPPolicy/dLoss                  0.000320889
GaussianMLPValueFunction/LossAfter       1.40075
GaussianMLPValueFunction/LossBefore      1.40898
GaussianMLPValueFunction/dLoss           0.00822711
TotalEnvSteps                        31968
-----------------------------------  ---------------
2022-08-23 10:37:35 | [trpo_pendulum] epoch #16 | Saving snapshot...
2022-08-23 10:37:35 | [trpo_pendulum] epoch #16 | Saved
2022-08-23 10:37:35 | [trpo_pendulum] epoch #16 | Time 16.97 s
2022-08-23 10:37:35 | [trpo_pendulum] epoch #16 | EpochTime 0.97 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -3.70991
Evaluation/AverageReturn               -39.3664
Evaluation/Iteration                    16
Evaluation/MaxReturn                   -37.9424
Evaluation/MinReturn                   -40.7903
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     1.42399
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.907581
GaussianMLPPolicy/KL                     0.0094564
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.0410555
GaussianMLPPolicy/LossBefore            -0.0396074
GaussianMLPPolicy/dLoss                  0.00144809
GaussianMLPValueFunction/LossAfter       1.30753
GaussianMLPValueFunction/LossBefore      1.31967
GaussianMLPValueFunction/dLoss           0.0121481
TotalEnvSteps                        33966
-----------------------------------  --------------
2022-08-23 10:37:36 | [trpo_pendulum] epoch #17 | Saving snapshot...
2022-08-23 10:37:36 | [trpo_pendulum] epoch #17 | Saved
2022-08-23 10:37:36 | [trpo_pendulum] epoch #17 | Time 17.97 s
2022-08-23 10:37:36 | [trpo_pendulum] epoch #17 | EpochTime 0.99 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -4.01228
Evaluation/AverageReturn               -38.366
Evaluation/Iteration                    17
Evaluation/MaxReturn                   -38.1595
Evaluation/MinReturn                   -38.5724
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.206464
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.891801
GaussianMLPPolicy/KL                     0.00521545
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.0349353
GaussianMLPPolicy/LossBefore            -0.03376
GaussianMLPPolicy/dLoss                  0.00117525
GaussianMLPValueFunction/LossAfter       1.32177
GaussianMLPValueFunction/LossBefore      1.3337
GaussianMLPValueFunction/dLoss           0.0119312
TotalEnvSteps                        35964
-----------------------------------  --------------
2022-08-23 10:37:37 | [trpo_pendulum] epoch #18 | Saving snapshot...
2022-08-23 10:37:37 | [trpo_pendulum] epoch #18 | Saved
2022-08-23 10:37:37 | [trpo_pendulum] epoch #18 | Time 18.99 s
2022-08-23 10:37:37 | [trpo_pendulum] epoch #18 | EpochTime 1.02 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -4.41002
Evaluation/AverageReturn               -43.3344
Evaluation/Iteration                    18
Evaluation/MaxReturn                   -43.1843
Evaluation/MinReturn                   -43.4845
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.150092
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.8178
GaussianMLPPolicy/KL                     0.00845653
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              0.163524
GaussianMLPPolicy/LossBefore             0.170359
GaussianMLPPolicy/dLoss                  0.00683449
GaussianMLPValueFunction/LossAfter       1.30467
GaussianMLPValueFunction/LossBefore      1.39687
GaussianMLPValueFunction/dLoss           0.0922076
TotalEnvSteps                        37962
-----------------------------------  --------------
2022-08-23 10:37:38 | [trpo_pendulum] epoch #19 | Saving snapshot...
2022-08-23 10:37:38 | [trpo_pendulum] epoch #19 | Saved
2022-08-23 10:37:38 | [trpo_pendulum] epoch #19 | Time 19.93 s
2022-08-23 10:37:38 | [trpo_pendulum] epoch #19 | EpochTime 0.94 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -3.85523
Evaluation/AverageReturn               -36.1214
Evaluation/Iteration                    19
Evaluation/MaxReturn                   -34.5997
Evaluation/MinReturn                   -37.6431
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     1.52171
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.799482
GaussianMLPPolicy/KL                     0.00592494
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.231484
GaussianMLPPolicy/LossBefore            -0.231275
GaussianMLPPolicy/dLoss                  0.000208259
GaussianMLPValueFunction/LossAfter       1.23945
GaussianMLPValueFunction/LossBefore      1.45125
GaussianMLPValueFunction/dLoss           0.2118
TotalEnvSteps                        39960
-----------------------------------  ---------------
2022-08-23 10:37:39 | [trpo_pendulum] epoch #20 | Saving snapshot...
2022-08-23 10:37:39 | [trpo_pendulum] epoch #20 | Saved
2022-08-23 10:37:39 | [trpo_pendulum] epoch #20 | Time 20.96 s
2022-08-23 10:37:39 | [trpo_pendulum] epoch #20 | EpochTime 1.02 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -3.58838
Evaluation/AverageReturn               -37.1
Evaluation/Iteration                    20
Evaluation/MaxReturn                   -37.0452
Evaluation/MinReturn                   -37.1548
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.0547651
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.786821
GaussianMLPPolicy/KL                     0.00588041
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              0.0512604
GaussianMLPPolicy/LossBefore             0.0522634
GaussianMLPPolicy/dLoss                  0.00100302
GaussianMLPValueFunction/LossAfter       1.16938
GaussianMLPValueFunction/LossBefore      1.19471
GaussianMLPValueFunction/dLoss           0.0253297
TotalEnvSteps                        41958
-----------------------------------  --------------
2022-08-23 10:37:40 | [trpo_pendulum] epoch #21 | Saving snapshot...
2022-08-23 10:37:40 | [trpo_pendulum] epoch #21 | Saved
2022-08-23 10:37:40 | [trpo_pendulum] epoch #21 | Time 21.96 s
2022-08-23 10:37:40 | [trpo_pendulum] epoch #21 | EpochTime 1.00 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -3.48463
Evaluation/AverageReturn               -35.4419
Evaluation/Iteration                    21
Evaluation/MaxReturn                   -34.942
Evaluation/MinReturn                   -35.9417
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.49988
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.732727
GaussianMLPPolicy/KL                     0.00914708
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.0552833
GaussianMLPPolicy/LossBefore            -0.051047
GaussianMLPPolicy/dLoss                  0.00423626
GaussianMLPValueFunction/LossAfter       1.17993
GaussianMLPValueFunction/LossBefore      1.20555
GaussianMLPValueFunction/dLoss           0.0256143
TotalEnvSteps                        43956
-----------------------------------  --------------
2022-08-23 10:37:41 | [trpo_pendulum] epoch #22 | Saving snapshot...
2022-08-23 10:37:41 | [trpo_pendulum] epoch #22 | Saved
2022-08-23 10:37:41 | [trpo_pendulum] epoch #22 | Time 22.95 s
2022-08-23 10:37:41 | [trpo_pendulum] epoch #22 | EpochTime 0.98 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -3.12863
Evaluation/AverageReturn               -68.5475
Evaluation/Iteration                    22
Evaluation/MaxReturn                   -33.8067
Evaluation/MinReturn                  -103.288
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                    34.7408
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.707505
GaussianMLPPolicy/KL                     0.00788899
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              1.11952
GaussianMLPPolicy/LossBefore             1.1501
GaussianMLPPolicy/dLoss                  0.0305797
GaussianMLPValueFunction/LossAfter      11.0482
GaussianMLPValueFunction/LossBefore     22.5534
GaussianMLPValueFunction/dLoss          11.5052
TotalEnvSteps                        45954
-----------------------------------  --------------
2022-08-23 10:37:42 | [trpo_pendulum] epoch #23 | Saving snapshot...
2022-08-23 10:37:42 | [trpo_pendulum] epoch #23 | Saved
2022-08-23 10:37:42 | [trpo_pendulum] epoch #23 | Time 23.95 s
2022-08-23 10:37:42 | [trpo_pendulum] epoch #23 | EpochTime 0.99 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -3.24637
Evaluation/AverageReturn               -40.526
Evaluation/Iteration                    23
Evaluation/MaxReturn                   -28.7071
Evaluation/MinReturn                   -52.3448
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                    11.8189
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.696688
GaussianMLPPolicy/KL                     0.00586281
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -1.00629
GaussianMLPPolicy/LossBefore            -0.99206
GaussianMLPPolicy/dLoss                  0.0142257
GaussianMLPValueFunction/LossAfter       2.63764
GaussianMLPValueFunction/LossBefore      5.22527
GaussianMLPValueFunction/dLoss           2.58764
TotalEnvSteps                        47952
-----------------------------------  --------------
2022-08-23 10:37:43 | [trpo_pendulum] epoch #24 | Saving snapshot...
2022-08-23 10:37:43 | [trpo_pendulum] epoch #24 | Saved
2022-08-23 10:37:43 | [trpo_pendulum] epoch #24 | Time 24.93 s
2022-08-23 10:37:43 | [trpo_pendulum] epoch #24 | EpochTime 0.97 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -2.86183
Evaluation/AverageReturn               -53.2631
Evaluation/Iteration                    24
Evaluation/MaxReturn                   -51.9086
Evaluation/MinReturn                   -54.6175
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     1.35444
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.694903
GaussianMLPPolicy/KL                     0.00655504
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              0.401485
GaussianMLPPolicy/LossBefore             0.414483
GaussianMLPPolicy/dLoss                  0.0129984
GaussianMLPValueFunction/LossAfter       2.77198
GaussianMLPValueFunction/LossBefore      3.35974
GaussianMLPValueFunction/dLoss           0.587753
TotalEnvSteps                        49950
-----------------------------------  --------------
2022-08-23 10:37:44 | [trpo_pendulum] epoch #25 | Saving snapshot...
2022-08-23 10:37:44 | [trpo_pendulum] epoch #25 | Saved
2022-08-23 10:37:44 | [trpo_pendulum] epoch #25 | Time 25.89 s
2022-08-23 10:37:44 | [trpo_pendulum] epoch #25 | EpochTime 0.95 s
-----------------------------------  -------------
Evaluation/AverageDiscountedReturn      -2.37921
Evaluation/AverageReturn               -43.9367
Evaluation/Iteration                    25
Evaluation/MaxReturn                   -41.3754
Evaluation/MinReturn                   -46.498
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     2.56127
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.650084
GaussianMLPPolicy/KL                     0.0078909
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.353314
GaussianMLPPolicy/LossBefore            -0.34234
GaussianMLPPolicy/dLoss                  0.0109742
GaussianMLPValueFunction/LossAfter       1.96218
GaussianMLPValueFunction/LossBefore      2.20713
GaussianMLPValueFunction/dLoss           0.244955
TotalEnvSteps                        51948
-----------------------------------  -------------
2022-08-23 10:37:45 | [trpo_pendulum] epoch #26 | Saving snapshot...
2022-08-23 10:37:45 | [trpo_pendulum] epoch #26 | Saved
2022-08-23 10:37:45 | [trpo_pendulum] epoch #26 | Time 26.89 s
2022-08-23 10:37:45 | [trpo_pendulum] epoch #26 | EpochTime 1.00 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -2.06704
Evaluation/AverageReturn               -24.1301
Evaluation/Iteration                    26
Evaluation/MaxReturn                   -23.3211
Evaluation/MinReturn                   -24.9392
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.809076
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.574768
GaussianMLPPolicy/KL                     0.00948643
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.700807
GaussianMLPPolicy/LossBefore            -0.693467
GaussianMLPPolicy/dLoss                  0.00733978
GaussianMLPValueFunction/LossAfter       1.26432
GaussianMLPValueFunction/LossBefore      2.41655
GaussianMLPValueFunction/dLoss           1.15223
TotalEnvSteps                        53946
-----------------------------------  --------------
2022-08-23 10:37:46 | [trpo_pendulum] epoch #27 | Saving snapshot...
2022-08-23 10:37:46 | [trpo_pendulum] epoch #27 | Saved
2022-08-23 10:37:46 | [trpo_pendulum] epoch #27 | Time 27.91 s
2022-08-23 10:37:46 | [trpo_pendulum] epoch #27 | EpochTime 1.02 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -2.13361
Evaluation/AverageReturn               -20.6274
Evaluation/Iteration                    27
Evaluation/MaxReturn                   -20.529
Evaluation/MinReturn                   -20.7259
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.0984662
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.526024
GaussianMLPPolicy/KL                     0.00722389
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.121127
GaussianMLPPolicy/LossBefore            -0.120459
GaussianMLPPolicy/dLoss                  0.000668392
GaussianMLPValueFunction/LossAfter       1.21005
GaussianMLPValueFunction/LossBefore      1.25827
GaussianMLPValueFunction/dLoss           0.0482206
TotalEnvSteps                        55944
-----------------------------------  ---------------
2022-08-23 10:37:47 | [trpo_pendulum] epoch #28 | Saving snapshot...
2022-08-23 10:37:47 | [trpo_pendulum] epoch #28 | Saved
2022-08-23 10:37:47 | [trpo_pendulum] epoch #28 | Time 28.90 s
2022-08-23 10:37:47 | [trpo_pendulum] epoch #28 | EpochTime 0.98 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -2.11883
Evaluation/AverageReturn               -25.8707
Evaluation/Iteration                    28
Evaluation/MaxReturn                   -19.6724
Evaluation/MinReturn                   -32.0691
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     6.19837
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.47793
GaussianMLPPolicy/KL                     0.00773468
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              0.166513
GaussianMLPPolicy/LossBefore             0.1713
GaussianMLPPolicy/dLoss                  0.00478749
GaussianMLPValueFunction/LossAfter       1.40963
GaussianMLPValueFunction/LossBefore      1.50987
GaussianMLPValueFunction/dLoss           0.100247
TotalEnvSteps                        57942
-----------------------------------  --------------
2022-08-23 10:37:48 | [trpo_pendulum] epoch #29 | Saving snapshot...
2022-08-23 10:37:48 | [trpo_pendulum] epoch #29 | Saved
2022-08-23 10:37:48 | [trpo_pendulum] epoch #29 | Time 29.86 s
2022-08-23 10:37:48 | [trpo_pendulum] epoch #29 | EpochTime 0.95 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -1.72198
Evaluation/AverageReturn               -20.7262
Evaluation/Iteration                    29
Evaluation/MaxReturn                   -20.2465
Evaluation/MinReturn                   -21.2058
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.47967
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.429621
GaussianMLPPolicy/KL                     0.00857614
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.176691
GaussianMLPPolicy/LossBefore            -0.171727
GaussianMLPPolicy/dLoss                  0.00496332
GaussianMLPValueFunction/LossAfter       1.18648
GaussianMLPValueFunction/LossBefore      1.27342
GaussianMLPValueFunction/dLoss           0.0869439
TotalEnvSteps                        59940
-----------------------------------  --------------
2022-08-23 10:37:49 | [trpo_pendulum] epoch #30 | Saving snapshot...
2022-08-23 10:37:49 | [trpo_pendulum] epoch #30 | Saved
2022-08-23 10:37:49 | [trpo_pendulum] epoch #30 | Time 30.95 s
2022-08-23 10:37:49 | [trpo_pendulum] epoch #30 | EpochTime 1.09 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -1.76166
Evaluation/AverageReturn               -17.446
Evaluation/Iteration                    30
Evaluation/MaxReturn                   -16.2023
Evaluation/MinReturn                   -18.6897
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     1.24371
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.410249
GaussianMLPPolicy/KL                     0.00455887
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.117248
GaussianMLPPolicy/LossBefore            -0.11594
GaussianMLPPolicy/dLoss                  0.00130754
GaussianMLPValueFunction/LossAfter       1.15331
GaussianMLPValueFunction/LossBefore      1.20704
GaussianMLPValueFunction/dLoss           0.0537295
TotalEnvSteps                        61938
-----------------------------------  --------------
2022-08-23 10:37:50 | [trpo_pendulum] epoch #31 | Saving snapshot...
2022-08-23 10:37:50 | [trpo_pendulum] epoch #31 | Saved
2022-08-23 10:37:50 | [trpo_pendulum] epoch #31 | Time 31.92 s
2022-08-23 10:37:50 | [trpo_pendulum] epoch #31 | EpochTime 0.97 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -1.54256
Evaluation/AverageReturn               -15.6826
Evaluation/Iteration                    31
Evaluation/MaxReturn                   -15.3486
Evaluation/MinReturn                   -16.0165
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.333968
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.403991
GaussianMLPPolicy/KL                     0.000259196
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.0490224
GaussianMLPPolicy/LossBefore            -0.0490188
GaussianMLPPolicy/dLoss                  3.58745e-06
GaussianMLPValueFunction/LossAfter       1.12111
GaussianMLPValueFunction/LossBefore      1.14867
GaussianMLPValueFunction/dLoss           0.027558
TotalEnvSteps                        63936
-----------------------------------  ---------------
2022-08-23 10:37:51 | [trpo_pendulum] epoch #32 | Saving snapshot...
2022-08-23 10:37:51 | [trpo_pendulum] epoch #32 | Saved
2022-08-23 10:37:51 | [trpo_pendulum] epoch #32 | Time 32.98 s
2022-08-23 10:37:51 | [trpo_pendulum] epoch #32 | EpochTime 1.06 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -1.53226
Evaluation/AverageReturn               -16.9144
Evaluation/Iteration                    32
Evaluation/MaxReturn                   -16.8
Evaluation/MinReturn                   -17.0288
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.114392
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.391484
GaussianMLPPolicy/KL                     0.00130081
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              0.0429658
GaussianMLPPolicy/LossBefore             0.0429909
GaussianMLPPolicy/dLoss                  2.51196e-05
GaussianMLPValueFunction/LossAfter       1.10202
GaussianMLPValueFunction/LossBefore      1.13051
GaussianMLPValueFunction/dLoss           0.0284904
TotalEnvSteps                        65934
-----------------------------------  ---------------
2022-08-23 10:37:52 | [trpo_pendulum] epoch #33 | Saving snapshot...
2022-08-23 10:37:52 | [trpo_pendulum] epoch #33 | Saved
2022-08-23 10:37:52 | [trpo_pendulum] epoch #33 | Time 33.96 s
2022-08-23 10:37:52 | [trpo_pendulum] epoch #33 | EpochTime 0.97 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -1.65705
Evaluation/AverageReturn               -19.9173
Evaluation/Iteration                    33
Evaluation/MaxReturn                   -16.2186
Evaluation/MinReturn                   -23.616
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     3.69872
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.348062
GaussianMLPPolicy/KL                     0.00800107
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              0.0909089
GaussianMLPPolicy/LossBefore             0.0927692
GaussianMLPPolicy/dLoss                  0.0018603
GaussianMLPValueFunction/LossAfter       1.16947
GaussianMLPValueFunction/LossBefore      1.21747
GaussianMLPValueFunction/dLoss           0.0479996
TotalEnvSteps                        67932
-----------------------------------  --------------
2022-08-23 10:37:53 | [trpo_pendulum] epoch #34 | Saving snapshot...
2022-08-23 10:37:53 | [trpo_pendulum] epoch #34 | Saved
2022-08-23 10:37:53 | [trpo_pendulum] epoch #34 | Time 34.96 s
2022-08-23 10:37:53 | [trpo_pendulum] epoch #34 | EpochTime 0.99 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -1.55702
Evaluation/AverageReturn               -15.8397
Evaluation/Iteration                    34
Evaluation/MaxReturn                   -15.384
Evaluation/MinReturn                   -16.2953
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.455658
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.327904
GaussianMLPPolicy/KL                     0.00608511
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.138493
GaussianMLPPolicy/LossBefore            -0.137375
GaussianMLPPolicy/dLoss                  0.00111797
GaussianMLPValueFunction/LossAfter       1.05992
GaussianMLPValueFunction/LossBefore      1.14773
GaussianMLPValueFunction/dLoss           0.0878071
TotalEnvSteps                        69930
-----------------------------------  --------------
2022-08-23 10:37:54 | [trpo_pendulum] epoch #35 | Saving snapshot...
2022-08-23 10:37:54 | [trpo_pendulum] epoch #35 | Saved
2022-08-23 10:37:54 | [trpo_pendulum] epoch #35 | Time 35.90 s
2022-08-23 10:37:54 | [trpo_pendulum] epoch #35 | EpochTime 0.94 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -1.39572
Evaluation/AverageReturn               -15.9875
Evaluation/Iteration                    35
Evaluation/MaxReturn                   -15.6676
Evaluation/MinReturn                   -16.3074
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.319894
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.287284
GaussianMLPPolicy/KL                     0.00918092
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              0.000530124
GaussianMLPPolicy/LossBefore             0.00290286
GaussianMLPPolicy/dLoss                  0.00237274
GaussianMLPValueFunction/LossAfter       1.02286
GaussianMLPValueFunction/LossBefore      1.05748
GaussianMLPValueFunction/dLoss           0.0346239
TotalEnvSteps                        71928
-----------------------------------  ---------------
2022-08-23 10:37:55 | [trpo_pendulum] epoch #36 | Saving snapshot...
2022-08-23 10:37:55 | [trpo_pendulum] epoch #36 | Saved
2022-08-23 10:37:55 | [trpo_pendulum] epoch #36 | Time 36.86 s
2022-08-23 10:37:55 | [trpo_pendulum] epoch #36 | EpochTime 0.96 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -1.2739
Evaluation/AverageReturn               -12.6418
Evaluation/Iteration                    36
Evaluation/MaxReturn                   -12.4359
Evaluation/MinReturn                   -12.8477
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.205901
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.271236
GaussianMLPPolicy/KL                     0.00737196
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.112775
GaussianMLPPolicy/LossBefore            -0.110674
GaussianMLPPolicy/dLoss                  0.00210093
GaussianMLPValueFunction/LossAfter       0.961763
GaussianMLPValueFunction/LossBefore      1.0472
GaussianMLPValueFunction/dLoss           0.0854381
TotalEnvSteps                        73926
-----------------------------------  --------------
2022-08-23 10:37:56 | [trpo_pendulum] epoch #37 | Saving snapshot...
2022-08-23 10:37:56 | [trpo_pendulum] epoch #37 | Saved
2022-08-23 10:37:56 | [trpo_pendulum] epoch #37 | Time 37.85 s
2022-08-23 10:37:56 | [trpo_pendulum] epoch #37 | EpochTime 0.99 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -1.27124
Evaluation/AverageReturn               -11.8927
Evaluation/Iteration                    37
Evaluation/MaxReturn                   -11.7608
Evaluation/MinReturn                   -12.0245
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.131865
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.233535
GaussianMLPPolicy/KL                     0.00542798
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.0289067
GaussianMLPPolicy/LossBefore            -0.0276054
GaussianMLPPolicy/dLoss                  0.00130131
GaussianMLPValueFunction/LossAfter       0.907333
GaussianMLPValueFunction/LossBefore      0.956381
GaussianMLPValueFunction/dLoss           0.0490479
TotalEnvSteps                        75924
-----------------------------------  --------------
2022-08-23 10:37:57 | [trpo_pendulum] epoch #38 | Saving snapshot...
2022-08-23 10:37:57 | [trpo_pendulum] epoch #38 | Saved
2022-08-23 10:37:57 | [trpo_pendulum] epoch #38 | Time 38.85 s
2022-08-23 10:37:57 | [trpo_pendulum] epoch #38 | EpochTime 0.99 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -1.12274
Evaluation/AverageReturn               -11.4219
Evaluation/Iteration                    38
Evaluation/MaxReturn                   -11.0972
Evaluation/MinReturn                   -11.7465
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.324648
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.219737
GaussianMLPPolicy/KL                     0.00563307
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.0172903
GaussianMLPPolicy/LossBefore            -0.0165058
GaussianMLPPolicy/dLoss                  0.000784533
GaussianMLPValueFunction/LossAfter       0.855513
GaussianMLPValueFunction/LossBefore      0.906706
GaussianMLPValueFunction/dLoss           0.0511932
TotalEnvSteps                        77922
-----------------------------------  ---------------
2022-08-23 10:37:58 | [trpo_pendulum] epoch #39 | Saving snapshot...
2022-08-23 10:37:58 | [trpo_pendulum] epoch #39 | Saved
2022-08-23 10:37:58 | [trpo_pendulum] epoch #39 | Time 39.83 s
2022-08-23 10:37:58 | [trpo_pendulum] epoch #39 | EpochTime 0.97 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -0.890313
Evaluation/AverageReturn                -9.68333
Evaluation/Iteration                    39
Evaluation/MaxReturn                    -9.56263
Evaluation/MinReturn                    -9.80403
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.120699
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.204846
GaussianMLPPolicy/KL                     0.00265433
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.0552999
GaussianMLPPolicy/LossBefore            -0.055196
GaussianMLPPolicy/dLoss                  0.000103839
GaussianMLPValueFunction/LossAfter       0.798615
GaussianMLPValueFunction/LossBefore      0.867623
GaussianMLPValueFunction/dLoss           0.0690085
TotalEnvSteps                        79920
-----------------------------------  ---------------
2022-08-23 10:37:59 | [trpo_pendulum] epoch #40 | Saving snapshot...
2022-08-23 10:37:59 | [trpo_pendulum] epoch #40 | Saved
2022-08-23 10:37:59 | [trpo_pendulum] epoch #40 | Time 40.85 s
2022-08-23 10:37:59 | [trpo_pendulum] epoch #40 | EpochTime 1.02 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -0.933573
Evaluation/AverageReturn                -9.73778
Evaluation/Iteration                    40
Evaluation/MaxReturn                    -9.16395
Evaluation/MinReturn                   -10.3116
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.573825
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.149538
GaussianMLPPolicy/KL                     0.00911239
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter              0.000637153
GaussianMLPPolicy/LossBefore             0.00261578
GaussianMLPPolicy/dLoss                  0.00197863
GaussianMLPValueFunction/LossAfter       0.747416
GaussianMLPValueFunction/LossBefore      0.803113
GaussianMLPValueFunction/dLoss           0.0556971
TotalEnvSteps                        81918
-----------------------------------  ---------------
2022-08-23 10:38:00 | [trpo_pendulum] epoch #41 | Saving snapshot...
2022-08-23 10:38:00 | [trpo_pendulum] epoch #41 | Saved
2022-08-23 10:38:00 | [trpo_pendulum] epoch #41 | Time 41.85 s
2022-08-23 10:38:00 | [trpo_pendulum] epoch #41 | EpochTime 0.99 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -0.811484
Evaluation/AverageReturn                -8.74036
Evaluation/Iteration                    41
Evaluation/MaxReturn                    -8.60884
Evaluation/MinReturn                    -8.87187
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.131513
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.0859016
GaussianMLPPolicy/KL                     0.00679246
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.0333654
GaussianMLPPolicy/LossBefore            -0.0321475
GaussianMLPPolicy/dLoss                  0.00121789
GaussianMLPValueFunction/LossAfter       0.659705
GaussianMLPValueFunction/LossBefore      0.730679
GaussianMLPValueFunction/dLoss           0.0709744
TotalEnvSteps                        83916
-----------------------------------  --------------
2022-08-23 10:38:01 | [trpo_pendulum] epoch #42 | Saving snapshot...
2022-08-23 10:38:01 | [trpo_pendulum] epoch #42 | Saved
2022-08-23 10:38:01 | [trpo_pendulum] epoch #42 | Time 42.89 s
2022-08-23 10:38:01 | [trpo_pendulum] epoch #42 | EpochTime 1.04 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -0.754523
Evaluation/AverageReturn                -7.52964
Evaluation/Iteration                    42
Evaluation/MaxReturn                    -7.36317
Evaluation/MinReturn                    -7.69612
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.166475
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.0762758
GaussianMLPPolicy/KL                     0.00933621
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.042508
GaussianMLPPolicy/LossBefore            -0.0421142
GaussianMLPPolicy/dLoss                  0.000393786
GaussianMLPValueFunction/LossAfter       0.589045
GaussianMLPValueFunction/LossBefore      0.66979
GaussianMLPValueFunction/dLoss           0.0807452
TotalEnvSteps                        85914
-----------------------------------  ---------------
2022-08-23 10:38:02 | [trpo_pendulum] epoch #43 | Saving snapshot...
2022-08-23 10:38:02 | [trpo_pendulum] epoch #43 | Saved
2022-08-23 10:38:02 | [trpo_pendulum] epoch #43 | Time 43.86 s
2022-08-23 10:38:02 | [trpo_pendulum] epoch #43 | EpochTime 0.96 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -0.650263
Evaluation/AverageReturn                -7.07724
Evaluation/Iteration                    43
Evaluation/MaxReturn                    -6.86538
Evaluation/MinReturn                    -7.28909
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.211853
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                0.0224892
GaussianMLPPolicy/KL                     0.00589256
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.014315
GaussianMLPPolicy/LossBefore            -0.0134533
GaussianMLPPolicy/dLoss                  0.00086171
GaussianMLPValueFunction/LossAfter       0.518833
GaussianMLPValueFunction/LossBefore      0.588884
GaussianMLPValueFunction/dLoss           0.0700513
TotalEnvSteps                        87912
-----------------------------------  --------------
2022-08-23 10:38:03 | [trpo_pendulum] epoch #44 | Saving snapshot...
2022-08-23 10:38:03 | [trpo_pendulum] epoch #44 | Saved
2022-08-23 10:38:03 | [trpo_pendulum] epoch #44 | Time 44.85 s
2022-08-23 10:38:03 | [trpo_pendulum] epoch #44 | EpochTime 0.98 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -0.589872
Evaluation/AverageReturn                -6.38669
Evaluation/Iteration                    44
Evaluation/MaxReturn                    -6.34343
Evaluation/MinReturn                    -6.42995
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.0432596
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy               -0.0494977
GaussianMLPPolicy/KL                     0.0081594
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.0164472
GaussianMLPPolicy/LossBefore            -0.0151173
GaussianMLPPolicy/dLoss                  0.00132984
GaussianMLPValueFunction/LossAfter       0.449272
GaussianMLPValueFunction/LossBefore      0.52092
GaussianMLPValueFunction/dLoss           0.071648
TotalEnvSteps                        89910
-----------------------------------  --------------
2022-08-23 10:38:04 | [trpo_pendulum] epoch #45 | Saving snapshot...
2022-08-23 10:38:04 | [trpo_pendulum] epoch #45 | Saved
2022-08-23 10:38:04 | [trpo_pendulum] epoch #45 | Time 45.81 s
2022-08-23 10:38:04 | [trpo_pendulum] epoch #45 | EpochTime 0.95 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn      -0.519679
Evaluation/AverageReturn                -5.50255
Evaluation/Iteration                    45
Evaluation/MaxReturn                    -5.24206
Evaluation/MinReturn                    -5.76304
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.260491
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy               -0.0872039
GaussianMLPPolicy/KL                     0.00695351
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.0322902
GaussianMLPPolicy/LossBefore            -0.0310249
GaussianMLPPolicy/dLoss                  0.00126536
GaussianMLPValueFunction/LossAfter       0.368433
GaussianMLPValueFunction/LossBefore      0.451442
GaussianMLPValueFunction/dLoss           0.0830097
TotalEnvSteps                        91908
-----------------------------------  --------------
2022-08-23 10:38:05 | [trpo_pendulum] epoch #46 | Saving snapshot...
2022-08-23 10:38:05 | [trpo_pendulum] epoch #46 | Saved
2022-08-23 10:38:05 | [trpo_pendulum] epoch #46 | Time 46.80 s
2022-08-23 10:38:05 | [trpo_pendulum] epoch #46 | EpochTime 0.99 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -0.473701
Evaluation/AverageReturn                -4.96241
Evaluation/Iteration                    46
Evaluation/MaxReturn                    -4.81956
Evaluation/MinReturn                    -5.10527
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.142856
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy               -0.122022
GaussianMLPPolicy/KL                     0.00840575
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.022809
GaussianMLPPolicy/LossBefore            -0.0224015
GaussianMLPPolicy/dLoss                  0.000407463
GaussianMLPValueFunction/LossAfter       0.288954
GaussianMLPValueFunction/LossBefore      0.369355
GaussianMLPValueFunction/dLoss           0.0804008
TotalEnvSteps                        93906
-----------------------------------  ---------------
2022-08-23 10:38:06 | [trpo_pendulum] epoch #47 | Saving snapshot...
2022-08-23 10:38:06 | [trpo_pendulum] epoch #47 | Saved
2022-08-23 10:38:06 | [trpo_pendulum] epoch #47 | Time 47.76 s
2022-08-23 10:38:06 | [trpo_pendulum] epoch #47 | EpochTime 0.96 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -0.457425
Evaluation/AverageReturn                -4.87561
Evaluation/Iteration                    47
Evaluation/MaxReturn                    -4.71473
Evaluation/MinReturn                    -5.0365
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.160884
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy               -0.133237
GaussianMLPPolicy/KL                     0.00614521
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.00372328
GaussianMLPPolicy/LossBefore            -0.00342831
GaussianMLPPolicy/dLoss                  0.000294978
GaussianMLPValueFunction/LossAfter       0.214831
GaussianMLPValueFunction/LossBefore      0.289331
GaussianMLPValueFunction/dLoss           0.0744997
TotalEnvSteps                        95904
-----------------------------------  ---------------
2022-08-23 10:38:07 | [trpo_pendulum] epoch #48 | Saving snapshot...
2022-08-23 10:38:07 | [trpo_pendulum] epoch #48 | Saved
2022-08-23 10:38:07 | [trpo_pendulum] epoch #48 | Time 48.79 s
2022-08-23 10:38:07 | [trpo_pendulum] epoch #48 | EpochTime 1.03 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -0.415795
Evaluation/AverageReturn                -4.4304
Evaluation/Iteration                    48
Evaluation/MaxReturn                    -4.28723
Evaluation/MinReturn                    -4.57357
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.14317
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy               -0.134775
GaussianMLPPolicy/KL                     0.000107464
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.0180161
GaussianMLPPolicy/LossBefore            -0.0180153
GaussianMLPPolicy/dLoss                  8.25152e-07
GaussianMLPValueFunction/LossAfter       0.125518
GaussianMLPValueFunction/LossBefore      0.20807
GaussianMLPValueFunction/dLoss           0.0825515
TotalEnvSteps                        97902
-----------------------------------  ---------------
2022-08-23 10:38:08 | [trpo_pendulum] epoch #49 | Saving snapshot...
2022-08-23 10:38:08 | [trpo_pendulum] epoch #49 | Saved
2022-08-23 10:38:08 | [trpo_pendulum] epoch #49 | Time 49.75 s
2022-08-23 10:38:08 | [trpo_pendulum] epoch #49 | EpochTime 0.96 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn      -0.432551
Evaluation/AverageReturn                -4.51509
Evaluation/Iteration                    49
Evaluation/MaxReturn                    -4.08122
Evaluation/MinReturn                    -4.94895
Evaluation/NumEpisodes                   2
Evaluation/StdReturn                     0.433865
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy               -0.140455
GaussianMLPPolicy/KL                     0.0097902
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter             -0.000880456
GaussianMLPPolicy/LossBefore            -0.000614306
GaussianMLPPolicy/dLoss                  0.00026615
GaussianMLPValueFunction/LossAfter       0.0625575
GaussianMLPValueFunction/LossBefore      0.136609
GaussianMLPValueFunction/dLoss           0.0740519
TotalEnvSteps                        99900
-----------------------------------  ---------------
2022-08-23 10:38:09 | [trpo_pendulum] epoch #50 | Saving snapshot...
2022-08-23 10:38:09 | [trpo_pendulum] epoch #50 | Saved
2022-08-23 10:38:09 | [trpo_pendulum] epoch #50 | Time 50.74 s
2022-08-23 10:38:09 | [trpo_pendulum] epoch #50 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.42076
Evaluation/AverageReturn                 -4.4967
Evaluation/Iteration                     50
Evaluation/MaxReturn                     -4.42571
Evaluation/MinReturn                     -4.56768
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0709847
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.168952
GaussianMLPPolicy/KL                      0.00960033
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00148563
GaussianMLPPolicy/LossBefore              0.00156479
GaussianMLPPolicy/dLoss                   7.91674e-05
GaussianMLPValueFunction/LossAfter       -0.00945115
GaussianMLPValueFunction/LossBefore       0.0629687
GaussianMLPValueFunction/dLoss            0.0724198
TotalEnvSteps                        101898
-----------------------------------  ----------------
2022-08-23 10:38:10 | [trpo_pendulum] epoch #51 | Saving snapshot...
2022-08-23 10:38:10 | [trpo_pendulum] epoch #51 | Saved
2022-08-23 10:38:10 | [trpo_pendulum] epoch #51 | Time 51.74 s
2022-08-23 10:38:10 | [trpo_pendulum] epoch #51 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.480542
Evaluation/AverageReturn                 -5.39107
Evaluation/Iteration                     51
Evaluation/MaxReturn                     -5.20279
Evaluation/MinReturn                     -5.57935
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.188279
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.195438
GaussianMLPPolicy/KL                      0.00477541
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.0270706
GaussianMLPPolicy/LossBefore              0.0275132
GaussianMLPPolicy/dLoss                   0.000442533
GaussianMLPValueFunction/LossAfter       -0.0762171
GaussianMLPValueFunction/LossBefore       0.0163655
GaussianMLPValueFunction/dLoss            0.0925826
TotalEnvSteps                        103896
-----------------------------------  ----------------
2022-08-23 10:38:11 | [trpo_pendulum] epoch #52 | Line search condition violated. Rejecting the step!
2022-08-23 10:38:11 | [trpo_pendulum] epoch #52 | Violated because loss not improving
2022-08-23 10:38:11 | [trpo_pendulum] epoch #52 | Saving snapshot...
2022-08-23 10:38:11 | [trpo_pendulum] epoch #52 | Saved
2022-08-23 10:38:11 | [trpo_pendulum] epoch #52 | Time 52.74 s
2022-08-23 10:38:11 | [trpo_pendulum] epoch #52 | EpochTime 1.00 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn       -0.38038
Evaluation/AverageReturn                 -4.01732
Evaluation/Iteration                     52
Evaluation/MaxReturn                     -3.78754
Evaluation/MinReturn                     -4.24711
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.229784
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.195438
GaussianMLPPolicy/KL                      0
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.0481897
GaussianMLPPolicy/LossBefore             -0.0481897
GaussianMLPPolicy/dLoss                   0
GaussianMLPValueFunction/LossAfter       -0.168774
GaussianMLPValueFunction/LossBefore      -0.0201908
GaussianMLPValueFunction/dLoss            0.148584
TotalEnvSteps                        105894
-----------------------------------  --------------
2022-08-23 10:38:12 | [trpo_pendulum] epoch #53 | Saving snapshot...
2022-08-23 10:38:12 | [trpo_pendulum] epoch #53 | Saved
2022-08-23 10:38:12 | [trpo_pendulum] epoch #53 | Time 53.74 s
2022-08-23 10:38:12 | [trpo_pendulum] epoch #53 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.432485
Evaluation/AverageReturn                 -4.26465
Evaluation/Iteration                     53
Evaluation/MaxReturn                     -4.08955
Evaluation/MinReturn                     -4.43975
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.175103
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.210836
GaussianMLPPolicy/KL                      0.00997805
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00924988
GaussianMLPPolicy/LossBefore              0.00932942
GaussianMLPPolicy/dLoss                   7.95405e-05
GaussianMLPValueFunction/LossAfter       -0.244568
GaussianMLPValueFunction/LossBefore      -0.16689
GaussianMLPValueFunction/dLoss            0.0776779
TotalEnvSteps                        107892
-----------------------------------  ----------------
2022-08-23 10:38:13 | [trpo_pendulum] epoch #54 | Saving snapshot...
2022-08-23 10:38:13 | [trpo_pendulum] epoch #54 | Saved
2022-08-23 10:38:13 | [trpo_pendulum] epoch #54 | Time 54.72 s
2022-08-23 10:38:13 | [trpo_pendulum] epoch #54 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.363119
Evaluation/AverageReturn                 -3.89404
Evaluation/Iteration                     54
Evaluation/MaxReturn                     -3.78634
Evaluation/MinReturn                     -4.00175
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.107705
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.212979
GaussianMLPPolicy/KL                      0.000597267
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.0146522
GaussianMLPPolicy/LossBefore             -0.0146419
GaussianMLPPolicy/dLoss                   1.03032e-05
GaussianMLPValueFunction/LossAfter       -0.324099
GaussianMLPValueFunction/LossBefore      -0.240141
GaussianMLPValueFunction/dLoss            0.0839581
TotalEnvSteps                        109890
-----------------------------------  ----------------
2022-08-23 10:38:14 | [trpo_pendulum] epoch #55 | Line search condition violated. Rejecting the step!
2022-08-23 10:38:14 | [trpo_pendulum] epoch #55 | Violated because loss not improving
2022-08-23 10:38:14 | [trpo_pendulum] epoch #55 | Saving snapshot...
2022-08-23 10:38:14 | [trpo_pendulum] epoch #55 | Saved
2022-08-23 10:38:14 | [trpo_pendulum] epoch #55 | Time 55.71 s
2022-08-23 10:38:14 | [trpo_pendulum] epoch #55 | EpochTime 0.99 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -0.371802
Evaluation/AverageReturn                 -4.15517
Evaluation/Iteration                     55
Evaluation/MaxReturn                     -4.05151
Evaluation/MinReturn                     -4.25884
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.103661
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.212979
GaussianMLPPolicy/KL                      0
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00668783
GaussianMLPPolicy/LossBefore              0.00668783
GaussianMLPPolicy/dLoss                   0
GaussianMLPValueFunction/LossAfter       -0.388605
GaussianMLPValueFunction/LossBefore      -0.315678
GaussianMLPValueFunction/dLoss            0.0729272
TotalEnvSteps                        111888
-----------------------------------  ---------------
2022-08-23 10:38:15 | [trpo_pendulum] epoch #56 | Saving snapshot...
2022-08-23 10:38:15 | [trpo_pendulum] epoch #56 | Saved
2022-08-23 10:38:15 | [trpo_pendulum] epoch #56 | Time 56.82 s
2022-08-23 10:38:15 | [trpo_pendulum] epoch #56 | EpochTime 1.10 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.462011
Evaluation/AverageReturn                 -4.64029
Evaluation/Iteration                     56
Evaluation/MaxReturn                     -4.49684
Evaluation/MinReturn                     -4.78374
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.143451
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.225688
GaussianMLPPolicy/KL                      0.00217009
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.02105
GaussianMLPPolicy/LossBefore              0.0210556
GaussianMLPPolicy/dLoss                   5.65872e-06
GaussianMLPValueFunction/LossAfter       -0.445319
GaussianMLPValueFunction/LossBefore      -0.351601
GaussianMLPValueFunction/dLoss            0.0937189
TotalEnvSteps                        113886
-----------------------------------  ----------------
2022-08-23 10:38:16 | [trpo_pendulum] epoch #57 | Saving snapshot...
2022-08-23 10:38:16 | [trpo_pendulum] epoch #57 | Saved
2022-08-23 10:38:16 | [trpo_pendulum] epoch #57 | Time 57.73 s
2022-08-23 10:38:16 | [trpo_pendulum] epoch #57 | EpochTime 0.91 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.42258
Evaluation/AverageReturn                 -4.47857
Evaluation/Iteration                     57
Evaluation/MaxReturn                     -3.96652
Evaluation/MinReturn                     -4.99063
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.512057
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.25078
GaussianMLPPolicy/KL                      0.00899523
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00931444
GaussianMLPPolicy/LossBefore             -0.00901289
GaussianMLPPolicy/dLoss                   0.000301547
GaussianMLPValueFunction/LossAfter       -0.45954
GaussianMLPValueFunction/LossBefore      -0.40239
GaussianMLPValueFunction/dLoss            0.0571497
TotalEnvSteps                        115884
-----------------------------------  ----------------
2022-08-23 10:38:17 | [trpo_pendulum] epoch #58 | Saving snapshot...
2022-08-23 10:38:17 | [trpo_pendulum] epoch #58 | Saved
2022-08-23 10:38:17 | [trpo_pendulum] epoch #58 | Time 58.70 s
2022-08-23 10:38:17 | [trpo_pendulum] epoch #58 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.407066
Evaluation/AverageReturn                 -4.25639
Evaluation/Iteration                     58
Evaluation/MaxReturn                     -4.21137
Evaluation/MinReturn                     -4.30142
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0450261
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.254681
GaussianMLPPolicy/KL                      7.15564e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.0148084
GaussianMLPPolicy/LossBefore             -0.0148075
GaussianMLPPolicy/dLoss                   8.56817e-07
GaussianMLPValueFunction/LossAfter       -0.546074
GaussianMLPValueFunction/LossBefore      -0.470267
GaussianMLPValueFunction/dLoss            0.0758075
TotalEnvSteps                        117882
-----------------------------------  ----------------
2022-08-23 10:38:18 | [trpo_pendulum] epoch #59 | Saving snapshot...
2022-08-23 10:38:18 | [trpo_pendulum] epoch #59 | Saved
2022-08-23 10:38:18 | [trpo_pendulum] epoch #59 | Time 59.68 s
2022-08-23 10:38:18 | [trpo_pendulum] epoch #59 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.410737
Evaluation/AverageReturn                 -4.19127
Evaluation/Iteration                     59
Evaluation/MaxReturn                     -3.91312
Evaluation/MinReturn                     -4.46943
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.278157
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.308573
GaussianMLPPolicy/KL                      0.0091072
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00449385
GaussianMLPPolicy/LossBefore              0.00505769
GaussianMLPPolicy/dLoss                   0.000563839
GaussianMLPValueFunction/LossAfter       -0.62052
GaussianMLPValueFunction/LossBefore      -0.558868
GaussianMLPValueFunction/dLoss            0.0616519
TotalEnvSteps                        119880
-----------------------------------  ----------------
2022-08-23 10:38:19 | [trpo_pendulum] epoch #60 | Saving snapshot...
2022-08-23 10:38:19 | [trpo_pendulum] epoch #60 | Saved
2022-08-23 10:38:19 | [trpo_pendulum] epoch #60 | Time 60.64 s
2022-08-23 10:38:19 | [trpo_pendulum] epoch #60 | EpochTime 0.96 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -0.405864
Evaluation/AverageReturn                 -4.01161
Evaluation/Iteration                     60
Evaluation/MaxReturn                     -3.85532
Evaluation/MinReturn                     -4.16791
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.156294
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.327865
GaussianMLPPolicy/KL                      0.00586285
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00569813
GaussianMLPPolicy/LossBefore             -0.00535663
GaussianMLPPolicy/dLoss                   0.0003415
GaussianMLPValueFunction/LossAfter       -0.705383
GaussianMLPValueFunction/LossBefore      -0.63457
GaussianMLPValueFunction/dLoss            0.0708128
TotalEnvSteps                        121878
-----------------------------------  ---------------
2022-08-23 10:38:20 | [trpo_pendulum] epoch #61 | Saving snapshot...
2022-08-23 10:38:20 | [trpo_pendulum] epoch #61 | Saved
2022-08-23 10:38:20 | [trpo_pendulum] epoch #61 | Time 61.68 s
2022-08-23 10:38:20 | [trpo_pendulum] epoch #61 | EpochTime 1.03 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.383184
Evaluation/AverageReturn                 -3.81986
Evaluation/Iteration                     61
Evaluation/MaxReturn                     -3.78656
Evaluation/MinReturn                     -3.85317
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0333022
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.334068
GaussianMLPPolicy/KL                      0.00468927
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00950766
GaussianMLPPolicy/LossBefore             -0.00909795
GaussianMLPPolicy/dLoss                   0.000409712
GaussianMLPValueFunction/LossAfter       -0.774677
GaussianMLPValueFunction/LossBefore      -0.700452
GaussianMLPValueFunction/dLoss            0.0742245
TotalEnvSteps                        123876
-----------------------------------  ----------------
2022-08-23 10:38:20 | [trpo_pendulum] epoch #62 | Line search condition violated. Rejecting the step!
2022-08-23 10:38:20 | [trpo_pendulum] epoch #62 | Violated because loss not improving
2022-08-23 10:38:20 | [trpo_pendulum] epoch #62 | Violated because constraint is violated
2022-08-23 10:38:21 | [trpo_pendulum] epoch #62 | Saving snapshot...
2022-08-23 10:38:21 | [trpo_pendulum] epoch #62 | Saved
2022-08-23 10:38:21 | [trpo_pendulum] epoch #62 | Time 62.70 s
2022-08-23 10:38:21 | [trpo_pendulum] epoch #62 | EpochTime 1.01 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn       -0.347879
Evaluation/AverageReturn                 -3.53091
Evaluation/Iteration                     62
Evaluation/MaxReturn                     -3.48891
Evaluation/MinReturn                     -3.57292
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0420057
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.334068
GaussianMLPPolicy/KL                      0
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.0123921
GaussianMLPPolicy/LossBefore             -0.0123921
GaussianMLPPolicy/dLoss                   0
GaussianMLPValueFunction/LossAfter       -0.852013
GaussianMLPValueFunction/LossBefore      -0.767708
GaussianMLPValueFunction/dLoss            0.0843045
TotalEnvSteps                        125874
-----------------------------------  --------------
2022-08-23 10:38:22 | [trpo_pendulum] epoch #63 | Saving snapshot...
2022-08-23 10:38:22 | [trpo_pendulum] epoch #63 | Saved
2022-08-23 10:38:22 | [trpo_pendulum] epoch #63 | Time 63.69 s
2022-08-23 10:38:22 | [trpo_pendulum] epoch #63 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.344315
Evaluation/AverageReturn                 -3.3663
Evaluation/Iteration                     63
Evaluation/MaxReturn                     -3.30585
Evaluation/MinReturn                     -3.42676
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0604543
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.339742
GaussianMLPPolicy/KL                      0.00696465
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00153121
GaussianMLPPolicy/LossBefore             -0.00105708
GaussianMLPPolicy/dLoss                   0.000474126
GaussianMLPValueFunction/LossAfter       -0.93208
GaussianMLPValueFunction/LossBefore      -0.868117
GaussianMLPValueFunction/dLoss            0.0639631
TotalEnvSteps                        127872
-----------------------------------  ----------------
2022-08-23 10:38:23 | [trpo_pendulum] epoch #64 | Saving snapshot...
2022-08-23 10:38:23 | [trpo_pendulum] epoch #64 | Saved
2022-08-23 10:38:23 | [trpo_pendulum] epoch #64 | Time 64.73 s
2022-08-23 10:38:23 | [trpo_pendulum] epoch #64 | EpochTime 1.03 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.301043
Evaluation/AverageReturn                 -3.39759
Evaluation/Iteration                     64
Evaluation/MaxReturn                     -3.3936
Evaluation/MinReturn                     -3.40158
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00399283
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.345317
GaussianMLPPolicy/KL                      0.000578903
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000579233
GaussianMLPPolicy/LossBefore             -0.000572341
GaussianMLPPolicy/dLoss                   6.89243e-06
GaussianMLPValueFunction/LossAfter       -0.988592
GaussianMLPValueFunction/LossBefore      -0.931633
GaussianMLPValueFunction/dLoss            0.0569591
TotalEnvSteps                        129870
-----------------------------------  ----------------
2022-08-23 10:38:24 | [trpo_pendulum] epoch #65 | Saving snapshot...
2022-08-23 10:38:24 | [trpo_pendulum] epoch #65 | Saved
2022-08-23 10:38:24 | [trpo_pendulum] epoch #65 | Time 65.70 s
2022-08-23 10:38:24 | [trpo_pendulum] epoch #65 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.32359
Evaluation/AverageReturn                 -3.42599
Evaluation/Iteration                     65
Evaluation/MaxReturn                     -3.3461
Evaluation/MinReturn                     -3.50588
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0798888
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.372448
GaussianMLPPolicy/KL                      0.00850081
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00318951
GaussianMLPPolicy/LossBefore              0.00329526
GaussianMLPPolicy/dLoss                   0.000105753
GaussianMLPValueFunction/LossAfter       -1.02521
GaussianMLPValueFunction/LossBefore      -0.974658
GaussianMLPValueFunction/dLoss            0.0505499
TotalEnvSteps                        131868
-----------------------------------  ----------------
2022-08-23 10:38:25 | [trpo_pendulum] epoch #66 | Saving snapshot...
2022-08-23 10:38:25 | [trpo_pendulum] epoch #66 | Saved
2022-08-23 10:38:25 | [trpo_pendulum] epoch #66 | Time 66.68 s
2022-08-23 10:38:25 | [trpo_pendulum] epoch #66 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.341625
Evaluation/AverageReturn                 -3.5114
Evaluation/Iteration                     66
Evaluation/MaxReturn                     -3.46752
Evaluation/MinReturn                     -3.55527
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0438772
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.387585
GaussianMLPPolicy/KL                      0.00225282
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00687822
GaussianMLPPolicy/LossBefore              0.00689045
GaussianMLPPolicy/dLoss                   1.22329e-05
GaussianMLPValueFunction/LossAfter       -1.05802
GaussianMLPValueFunction/LossBefore      -1.00023
GaussianMLPValueFunction/dLoss            0.0577829
TotalEnvSteps                        133866
-----------------------------------  ----------------
2022-08-23 10:38:26 | [trpo_pendulum] epoch #67 | Saving snapshot...
2022-08-23 10:38:26 | [trpo_pendulum] epoch #67 | Saved
2022-08-23 10:38:26 | [trpo_pendulum] epoch #67 | Time 67.66 s
2022-08-23 10:38:26 | [trpo_pendulum] epoch #67 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.380706
Evaluation/AverageReturn                 -3.66396
Evaluation/Iteration                     67
Evaluation/MaxReturn                     -3.64681
Evaluation/MinReturn                     -3.68112
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0171576
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.425198
GaussianMLPPolicy/KL                      0.00387268
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00305831
GaussianMLPPolicy/LossBefore              0.00309023
GaussianMLPPolicy/dLoss                   3.19125e-05
GaussianMLPValueFunction/LossAfter       -0.992399
GaussianMLPValueFunction/LossBefore      -0.970668
GaussianMLPValueFunction/dLoss            0.0217313
TotalEnvSteps                        135864
-----------------------------------  ----------------
2022-08-23 10:38:27 | [trpo_pendulum] epoch #68 | Saving snapshot...
2022-08-23 10:38:27 | [trpo_pendulum] epoch #68 | Saved
2022-08-23 10:38:27 | [trpo_pendulum] epoch #68 | Time 68.61 s
2022-08-23 10:38:27 | [trpo_pendulum] epoch #68 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.403837
Evaluation/AverageReturn                 -3.53426
Evaluation/Iteration                     68
Evaluation/MaxReturn                     -3.461
Evaluation/MinReturn                     -3.60752
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0732601
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.479253
GaussianMLPPolicy/KL                      0.00802657
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00817633
GaussianMLPPolicy/LossBefore             -0.00740555
GaussianMLPPolicy/dLoss                   0.000770775
GaussianMLPValueFunction/LossAfter       -1.02356
GaussianMLPValueFunction/LossBefore      -0.975356
GaussianMLPValueFunction/dLoss            0.0482084
TotalEnvSteps                        137862
-----------------------------------  ----------------
2022-08-23 10:38:28 | [trpo_pendulum] epoch #69 | Saving snapshot...
2022-08-23 10:38:28 | [trpo_pendulum] epoch #69 | Saved
2022-08-23 10:38:28 | [trpo_pendulum] epoch #69 | Time 69.60 s
2022-08-23 10:38:28 | [trpo_pendulum] epoch #69 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.308535
Evaluation/AverageReturn                 -2.93798
Evaluation/Iteration                     69
Evaluation/MaxReturn                     -2.91366
Evaluation/MinReturn                     -2.96229
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0243135
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.509145
GaussianMLPPolicy/KL                      0.00935822
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.0219073
GaussianMLPPolicy/LossBefore             -0.0213956
GaussianMLPPolicy/dLoss                   0.000511726
GaussianMLPValueFunction/LossAfter       -1.23035
GaussianMLPValueFunction/LossBefore      -1.00942
GaussianMLPValueFunction/dLoss            0.220932
TotalEnvSteps                        139860
-----------------------------------  ----------------
2022-08-23 10:38:29 | [trpo_pendulum] epoch #70 | Saving snapshot...
2022-08-23 10:38:29 | [trpo_pendulum] epoch #70 | Saved
2022-08-23 10:38:29 | [trpo_pendulum] epoch #70 | Time 70.56 s
2022-08-23 10:38:29 | [trpo_pendulum] epoch #70 | EpochTime 0.96 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -0.252316
Evaluation/AverageReturn                 -2.77732
Evaluation/Iteration                     70
Evaluation/MaxReturn                     -2.74968
Evaluation/MinReturn                     -2.80496
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0276409
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.527715
GaussianMLPPolicy/KL                      0.00535742
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00526076
GaussianMLPPolicy/LossBefore             -0.00494868
GaussianMLPPolicy/dLoss                   0.00031208
GaussianMLPValueFunction/LossAfter       -1.3338
GaussianMLPValueFunction/LossBefore      -1.26823
GaussianMLPValueFunction/dLoss            0.0655756
TotalEnvSteps                        141858
-----------------------------------  ---------------
2022-08-23 10:38:30 | [trpo_pendulum] epoch #71 | Saving snapshot...
2022-08-23 10:38:30 | [trpo_pendulum] epoch #71 | Saved
2022-08-23 10:38:30 | [trpo_pendulum] epoch #71 | Time 71.54 s
2022-08-23 10:38:30 | [trpo_pendulum] epoch #71 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.265033
Evaluation/AverageReturn                 -2.63711
Evaluation/Iteration                     71
Evaluation/MaxReturn                     -2.42565
Evaluation/MinReturn                     -2.84856
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.211457
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.534321
GaussianMLPPolicy/KL                      0.00518969
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.0054613
GaussianMLPPolicy/LossBefore             -0.00510702
GaussianMLPPolicy/dLoss                   0.000354277
GaussianMLPValueFunction/LossAfter       -1.34933
GaussianMLPValueFunction/LossBefore      -1.29071
GaussianMLPValueFunction/dLoss            0.0586185
TotalEnvSteps                        143856
-----------------------------------  ----------------
2022-08-23 10:38:31 | [trpo_pendulum] epoch #72 | Saving snapshot...
2022-08-23 10:38:31 | [trpo_pendulum] epoch #72 | Saved
2022-08-23 10:38:31 | [trpo_pendulum] epoch #72 | Time 72.50 s
2022-08-23 10:38:31 | [trpo_pendulum] epoch #72 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.243232
Evaluation/AverageReturn                 -2.36304
Evaluation/Iteration                     72
Evaluation/MaxReturn                     -2.19845
Evaluation/MinReturn                     -2.52762
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.164583
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.550122
GaussianMLPPolicy/KL                      0.00801521
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00913231
GaussianMLPPolicy/LossBefore             -0.00891683
GaussianMLPPolicy/dLoss                   0.000215479
GaussianMLPValueFunction/LossAfter       -1.37758
GaussianMLPValueFunction/LossBefore      -1.28955
GaussianMLPValueFunction/dLoss            0.0880295
TotalEnvSteps                        145854
-----------------------------------  ----------------
2022-08-23 10:38:32 | [trpo_pendulum] epoch #73 | Saving snapshot...
2022-08-23 10:38:32 | [trpo_pendulum] epoch #73 | Saved
2022-08-23 10:38:32 | [trpo_pendulum] epoch #73 | Time 73.50 s
2022-08-23 10:38:32 | [trpo_pendulum] epoch #73 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.211311
Evaluation/AverageReturn                 -2.2001
Evaluation/Iteration                     73
Evaluation/MaxReturn                     -2.07353
Evaluation/MinReturn                     -2.32666
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.126563
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.615136
GaussianMLPPolicy/KL                      0.00869554
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00357815
GaussianMLPPolicy/LossBefore             -0.00299174
GaussianMLPPolicy/dLoss                   0.000586406
GaussianMLPValueFunction/LossAfter       -1.40635
GaussianMLPValueFunction/LossBefore      -1.37518
GaussianMLPValueFunction/dLoss            0.0311694
TotalEnvSteps                        147852
-----------------------------------  ----------------
2022-08-23 10:38:33 | [trpo_pendulum] epoch #74 | Saving snapshot...
2022-08-23 10:38:33 | [trpo_pendulum] epoch #74 | Saved
2022-08-23 10:38:33 | [trpo_pendulum] epoch #74 | Time 74.46 s
2022-08-23 10:38:33 | [trpo_pendulum] epoch #74 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.161892
Evaluation/AverageReturn                 -1.83808
Evaluation/Iteration                     74
Evaluation/MaxReturn                     -1.78796
Evaluation/MinReturn                     -1.8882
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0501196
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.685005
GaussianMLPPolicy/KL                      0.00632544
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.0104755
GaussianMLPPolicy/LossBefore             -0.0102382
GaussianMLPPolicy/dLoss                   0.000237313
GaussianMLPValueFunction/LossAfter       -1.62391
GaussianMLPValueFunction/LossBefore      -1.48084
GaussianMLPValueFunction/dLoss            0.143075
TotalEnvSteps                        149850
-----------------------------------  ----------------
2022-08-23 10:38:34 | [trpo_pendulum] epoch #75 | Saving snapshot...
2022-08-23 10:38:34 | [trpo_pendulum] epoch #75 | Saved
2022-08-23 10:38:34 | [trpo_pendulum] epoch #75 | Time 75.47 s
2022-08-23 10:38:34 | [trpo_pendulum] epoch #75 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.168632
Evaluation/AverageReturn                 -1.57306
Evaluation/Iteration                     75
Evaluation/MaxReturn                     -1.56929
Evaluation/MinReturn                     -1.57684
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00377225
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.699389
GaussianMLPPolicy/KL                      0.00406417
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00914727
GaussianMLPPolicy/LossBefore             -0.0091335
GaussianMLPPolicy/dLoss                   1.37659e-05
GaussianMLPValueFunction/LossAfter       -1.73542
GaussianMLPValueFunction/LossBefore      -1.58686
GaussianMLPValueFunction/dLoss            0.148562
TotalEnvSteps                        151848
-----------------------------------  ----------------
2022-08-23 10:38:35 | [trpo_pendulum] epoch #76 | Saving snapshot...
2022-08-23 10:38:35 | [trpo_pendulum] epoch #76 | Saved
2022-08-23 10:38:35 | [trpo_pendulum] epoch #76 | Time 76.43 s
2022-08-23 10:38:35 | [trpo_pendulum] epoch #76 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.134656
Evaluation/AverageReturn                 -1.4365
Evaluation/Iteration                     76
Evaluation/MaxReturn                     -1.3635
Evaluation/MinReturn                     -1.5095
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0730021
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.777582
GaussianMLPPolicy/KL                      0.00705119
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00432842
GaussianMLPPolicy/LossBefore             -0.00417793
GaussianMLPPolicy/dLoss                   0.000150493
GaussianMLPValueFunction/LossAfter       -1.83953
GaussianMLPValueFunction/LossBefore      -1.75236
GaussianMLPValueFunction/dLoss            0.0871731
TotalEnvSteps                        153846
-----------------------------------  ----------------
2022-08-23 10:38:36 | [trpo_pendulum] epoch #77 | Saving snapshot...
2022-08-23 10:38:36 | [trpo_pendulum] epoch #77 | Saved
2022-08-23 10:38:36 | [trpo_pendulum] epoch #77 | Time 77.44 s
2022-08-23 10:38:36 | [trpo_pendulum] epoch #77 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.125281
Evaluation/AverageReturn                 -1.30298
Evaluation/Iteration                     77
Evaluation/MaxReturn                     -1.28565
Evaluation/MinReturn                     -1.3203
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0173262
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.78192
GaussianMLPPolicy/KL                      0.00488794
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00524889
GaussianMLPPolicy/LossBefore             -0.00519496
GaussianMLPPolicy/dLoss                   5.39236e-05
GaussianMLPValueFunction/LossAfter       -1.91042
GaussianMLPValueFunction/LossBefore      -1.81818
GaussianMLPValueFunction/dLoss            0.0922371
TotalEnvSteps                        155844
-----------------------------------  ----------------
2022-08-23 10:38:37 | [trpo_pendulum] epoch #78 | Saving snapshot...
2022-08-23 10:38:37 | [trpo_pendulum] epoch #78 | Saved
2022-08-23 10:38:37 | [trpo_pendulum] epoch #78 | Time 78.40 s
2022-08-23 10:38:37 | [trpo_pendulum] epoch #78 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.132438
Evaluation/AverageReturn                 -1.35234
Evaluation/Iteration                     78
Evaluation/MaxReturn                     -1.28811
Evaluation/MinReturn                     -1.41658
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0642351
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.856747
GaussianMLPPolicy/KL                      0.00736974
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000770443
GaussianMLPPolicy/LossBefore             -0.000554503
GaussianMLPPolicy/dLoss                   0.000215939
GaussianMLPValueFunction/LossAfter       -1.96855
GaussianMLPValueFunction/LossBefore      -1.91448
GaussianMLPValueFunction/dLoss            0.0540682
TotalEnvSteps                        157842
-----------------------------------  ----------------
2022-08-23 10:38:38 | [trpo_pendulum] epoch #79 | Saving snapshot...
2022-08-23 10:38:38 | [trpo_pendulum] epoch #79 | Saved
2022-08-23 10:38:38 | [trpo_pendulum] epoch #79 | Time 79.36 s
2022-08-23 10:38:38 | [trpo_pendulum] epoch #79 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.10118
Evaluation/AverageReturn                 -1.07868
Evaluation/Iteration                     79
Evaluation/MaxReturn                     -1.07402
Evaluation/MinReturn                     -1.08334
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00465895
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.927193
GaussianMLPPolicy/KL                      0.00639337
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00812215
GaussianMLPPolicy/LossBefore             -0.00797702
GaussianMLPPolicy/dLoss                   0.000145122
GaussianMLPValueFunction/LossAfter       -2.08257
GaussianMLPValueFunction/LossBefore      -1.90444
GaussianMLPValueFunction/dLoss            0.178137
TotalEnvSteps                        159840
-----------------------------------  ----------------
2022-08-23 10:38:39 | [trpo_pendulum] epoch #80 | Saving snapshot...
2022-08-23 10:38:39 | [trpo_pendulum] epoch #80 | Saved
2022-08-23 10:38:39 | [trpo_pendulum] epoch #80 | Time 80.37 s
2022-08-23 10:38:39 | [trpo_pendulum] epoch #80 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0928094
Evaluation/AverageReturn                 -0.952979
Evaluation/Iteration                     80
Evaluation/MaxReturn                     -0.932087
Evaluation/MinReturn                     -0.97387
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0208916
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -0.931732
GaussianMLPPolicy/KL                      0.00218811
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00268431
GaussianMLPPolicy/LossBefore             -0.00268148
GaussianMLPPolicy/dLoss                   2.82237e-06
GaussianMLPValueFunction/LossAfter       -2.21684
GaussianMLPValueFunction/LossBefore      -2.12395
GaussianMLPValueFunction/dLoss            0.0928936
TotalEnvSteps                        161838
-----------------------------------  ----------------
2022-08-23 10:38:40 | [trpo_pendulum] epoch #81 | Saving snapshot...
2022-08-23 10:38:40 | [trpo_pendulum] epoch #81 | Saved
2022-08-23 10:38:40 | [trpo_pendulum] epoch #81 | Time 81.47 s
2022-08-23 10:38:40 | [trpo_pendulum] epoch #81 | EpochTime 1.10 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0917069
Evaluation/AverageReturn                 -0.931578
Evaluation/Iteration                     81
Evaluation/MaxReturn                     -0.914279
Evaluation/MinReturn                     -0.948877
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0172991
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -1.00927
GaussianMLPPolicy/KL                      0.00737253
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00089627
GaussianMLPPolicy/LossBefore             -0.000719198
GaussianMLPPolicy/dLoss                   0.000177072
GaussianMLPValueFunction/LossAfter       -2.21556
GaussianMLPValueFunction/LossBefore      -2.16418
GaussianMLPValueFunction/dLoss            0.0513797
TotalEnvSteps                        163836
-----------------------------------  ----------------
2022-08-23 10:38:41 | [trpo_pendulum] epoch #82 | Saving snapshot...
2022-08-23 10:38:41 | [trpo_pendulum] epoch #82 | Saved
2022-08-23 10:38:41 | [trpo_pendulum] epoch #82 | Time 82.49 s
2022-08-23 10:38:41 | [trpo_pendulum] epoch #82 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0737675
Evaluation/AverageReturn                 -0.837219
Evaluation/Iteration                     82
Evaluation/MaxReturn                     -0.835281
Evaluation/MinReturn                     -0.839157
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0019379
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -1.09234
GaussianMLPPolicy/KL                      0.00970849
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00192915
GaussianMLPPolicy/LossBefore             -0.00170668
GaussianMLPPolicy/dLoss                   0.000222472
GaussianMLPValueFunction/LossAfter       -2.3228
GaussianMLPValueFunction/LossBefore      -2.25495
GaussianMLPValueFunction/dLoss            0.067848
TotalEnvSteps                        165834
-----------------------------------  ----------------
2022-08-23 10:38:42 | [trpo_pendulum] epoch #83 | Saving snapshot...
2022-08-23 10:38:42 | [trpo_pendulum] epoch #83 | Saved
2022-08-23 10:38:42 | [trpo_pendulum] epoch #83 | Time 83.45 s
2022-08-23 10:38:42 | [trpo_pendulum] epoch #83 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0705821
Evaluation/AverageReturn                 -0.665858
Evaluation/Iteration                     83
Evaluation/MaxReturn                     -0.641295
Evaluation/MinReturn                     -0.690421
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.024563
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -1.16987
GaussianMLPPolicy/KL                      0.00672993
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00626421
GaussianMLPPolicy/LossBefore             -0.00614846
GaussianMLPPolicy/dLoss                   0.000115758
GaussianMLPValueFunction/LossAfter       -2.43331
GaussianMLPValueFunction/LossBefore      -2.24084
GaussianMLPValueFunction/dLoss            0.192476
TotalEnvSteps                        167832
-----------------------------------  ----------------
2022-08-23 10:38:43 | [trpo_pendulum] epoch #84 | Saving snapshot...
2022-08-23 10:38:43 | [trpo_pendulum] epoch #84 | Saved
2022-08-23 10:38:43 | [trpo_pendulum] epoch #84 | Time 84.39 s
2022-08-23 10:38:43 | [trpo_pendulum] epoch #84 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0573982
Evaluation/AverageReturn                 -0.555393
Evaluation/Iteration                     84
Evaluation/MaxReturn                     -0.554935
Evaluation/MinReturn                     -0.55585
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000457456
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -1.24222
GaussianMLPPolicy/KL                      0.00860501
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000571549
GaussianMLPPolicy/LossBefore             -0.000477748
GaussianMLPPolicy/dLoss                   9.38001e-05
GaussianMLPValueFunction/LossAfter       -2.55631
GaussianMLPValueFunction/LossBefore      -2.47722
GaussianMLPValueFunction/dLoss            0.0790873
TotalEnvSteps                        169830
-----------------------------------  ----------------
2022-08-23 10:38:44 | [trpo_pendulum] epoch #85 | Saving snapshot...
2022-08-23 10:38:44 | [trpo_pendulum] epoch #85 | Saved
2022-08-23 10:38:44 | [trpo_pendulum] epoch #85 | Time 85.36 s
2022-08-23 10:38:44 | [trpo_pendulum] epoch #85 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0509821
Evaluation/AverageReturn                 -0.485356
Evaluation/Iteration                     85
Evaluation/MaxReturn                     -0.482222
Evaluation/MinReturn                     -0.488491
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00313444
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -1.31635
GaussianMLPPolicy/KL                      0.00662539
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.0027444
GaussianMLPPolicy/LossBefore             -0.00270489
GaussianMLPPolicy/dLoss                   3.95123e-05
GaussianMLPValueFunction/LossAfter       -2.68282
GaussianMLPValueFunction/LossBefore      -2.56144
GaussianMLPValueFunction/dLoss            0.121382
TotalEnvSteps                        171828
-----------------------------------  ----------------
2022-08-23 10:38:44 | [trpo_pendulum] epoch #86 | Saving snapshot...
2022-08-23 10:38:45 | [trpo_pendulum] epoch #86 | Saved
2022-08-23 10:38:45 | [trpo_pendulum] epoch #86 | Time 86.30 s
2022-08-23 10:38:45 | [trpo_pendulum] epoch #86 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0384615
Evaluation/AverageReturn                 -0.394595
Evaluation/Iteration                     86
Evaluation/MaxReturn                     -0.387239
Evaluation/MinReturn                     -0.40195
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00735574
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -1.39451
GaussianMLPPolicy/KL                      0.0070715
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00295171
GaussianMLPPolicy/LossBefore             -0.00286044
GaussianMLPPolicy/dLoss                   9.12743e-05
GaussianMLPValueFunction/LossAfter       -2.72326
GaussianMLPValueFunction/LossBefore      -2.63225
GaussianMLPValueFunction/dLoss            0.0910158
TotalEnvSteps                        173826
-----------------------------------  ----------------
2022-08-23 10:38:45 | [trpo_pendulum] epoch #87 | Saving snapshot...
2022-08-23 10:38:45 | [trpo_pendulum] epoch #87 | Saved
2022-08-23 10:38:45 | [trpo_pendulum] epoch #87 | Time 87.24 s
2022-08-23 10:38:45 | [trpo_pendulum] epoch #87 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.034946
Evaluation/AverageReturn                 -0.356742
Evaluation/Iteration                     87
Evaluation/MaxReturn                     -0.354006
Evaluation/MinReturn                     -0.359478
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00273576
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -1.45471
GaussianMLPPolicy/KL                      0.00615784
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00259014
GaussianMLPPolicy/LossBefore             -0.00254616
GaussianMLPPolicy/dLoss                   4.39784e-05
GaussianMLPValueFunction/LossAfter       -2.85728
GaussianMLPValueFunction/LossBefore      -2.73397
GaussianMLPValueFunction/dLoss            0.123307
TotalEnvSteps                        175824
-----------------------------------  ----------------
2022-08-23 10:38:46 | [trpo_pendulum] epoch #88 | Line search condition violated. Rejecting the step!
2022-08-23 10:38:46 | [trpo_pendulum] epoch #88 | Violated because loss not improving
2022-08-23 10:38:46 | [trpo_pendulum] epoch #88 | Saving snapshot...
2022-08-23 10:38:46 | [trpo_pendulum] epoch #88 | Saved
2022-08-23 10:38:46 | [trpo_pendulum] epoch #88 | Time 88.24 s
2022-08-23 10:38:46 | [trpo_pendulum] epoch #88 | EpochTime 1.00 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -0.0303163
Evaluation/AverageReturn                 -0.322409
Evaluation/Iteration                     88
Evaluation/MaxReturn                     -0.31366
Evaluation/MinReturn                     -0.331158
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00874911
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -1.45471
GaussianMLPPolicy/KL                      0
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00255988
GaussianMLPPolicy/LossBefore             -0.00255988
GaussianMLPPolicy/dLoss                   0
GaussianMLPValueFunction/LossAfter       -2.93233
GaussianMLPValueFunction/LossBefore      -2.81153
GaussianMLPValueFunction/dLoss            0.120806
TotalEnvSteps                        177822
-----------------------------------  ---------------
2022-08-23 10:38:47 | [trpo_pendulum] epoch #89 | Saving snapshot...
2022-08-23 10:38:47 | [trpo_pendulum] epoch #89 | Saved
2022-08-23 10:38:47 | [trpo_pendulum] epoch #89 | Time 89.20 s
2022-08-23 10:38:47 | [trpo_pendulum] epoch #89 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0336237
Evaluation/AverageReturn                 -0.329594
Evaluation/Iteration                     89
Evaluation/MaxReturn                     -0.328593
Evaluation/MinReturn                     -0.330595
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00100141
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -1.53148
GaussianMLPPolicy/KL                      0.006528
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00123511
GaussianMLPPolicy/LossBefore              0.0013048
GaussianMLPPolicy/dLoss                   6.96942e-05
GaussianMLPValueFunction/LossAfter       -2.97234
GaussianMLPValueFunction/LossBefore      -2.90065
GaussianMLPValueFunction/dLoss            0.0716877
TotalEnvSteps                        179820
-----------------------------------  ----------------
2022-08-23 10:38:48 | [trpo_pendulum] epoch #90 | Saving snapshot...
2022-08-23 10:38:48 | [trpo_pendulum] epoch #90 | Saved
2022-08-23 10:38:48 | [trpo_pendulum] epoch #90 | Time 90.14 s
2022-08-23 10:38:48 | [trpo_pendulum] epoch #90 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0279958
Evaluation/AverageReturn                 -0.295349
Evaluation/Iteration                     90
Evaluation/MaxReturn                     -0.294485
Evaluation/MinReturn                     -0.296213
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00086403
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -1.53576
GaussianMLPPolicy/KL                      0.00037926
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00126543
GaussianMLPPolicy/LossBefore              0.00126578
GaussianMLPPolicy/dLoss                   3.54485e-07
GaussianMLPValueFunction/LossAfter       -3.08002
GaussianMLPValueFunction/LossBefore      -3.00534
GaussianMLPValueFunction/dLoss            0.0746791
TotalEnvSteps                        181818
-----------------------------------  ----------------
2022-08-23 10:38:49 | [trpo_pendulum] epoch #91 | Saving snapshot...
2022-08-23 10:38:49 | [trpo_pendulum] epoch #91 | Saved
2022-08-23 10:38:49 | [trpo_pendulum] epoch #91 | Time 91.09 s
2022-08-23 10:38:49 | [trpo_pendulum] epoch #91 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0300666
Evaluation/AverageReturn                 -0.285015
Evaluation/Iteration                     91
Evaluation/MaxReturn                     -0.279151
Evaluation/MinReturn                     -0.29088
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00586443
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -1.61252
GaussianMLPPolicy/KL                      0.0064365
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.002681
GaussianMLPPolicy/LossBefore             -0.00263567
GaussianMLPPolicy/dLoss                   4.53356e-05
GaussianMLPValueFunction/LossAfter       -3.15702
GaussianMLPValueFunction/LossBefore      -2.99201
GaussianMLPValueFunction/dLoss            0.165012
TotalEnvSteps                        183816
-----------------------------------  ----------------
2022-08-23 10:38:50 | [trpo_pendulum] epoch #92 | Saving snapshot...
2022-08-23 10:38:50 | [trpo_pendulum] epoch #92 | Saved
2022-08-23 10:38:50 | [trpo_pendulum] epoch #92 | Time 92.03 s
2022-08-23 10:38:50 | [trpo_pendulum] epoch #92 | EpochTime 0.93 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -0.0215942
Evaluation/AverageReturn                 -0.236483
Evaluation/Iteration                     92
Evaluation/MaxReturn                     -0.231599
Evaluation/MinReturn                     -0.241366
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00488397
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -1.68039
GaussianMLPPolicy/KL                      0.00720522
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.0016543
GaussianMLPPolicy/LossBefore             -0.00161672
GaussianMLPPolicy/dLoss                   3.7576e-05
GaussianMLPValueFunction/LossAfter       -3.24383
GaussianMLPValueFunction/LossBefore      -3.14033
GaussianMLPValueFunction/dLoss            0.103501
TotalEnvSteps                        185814
-----------------------------------  ---------------
2022-08-23 10:38:51 | [trpo_pendulum] epoch #93 | Saving snapshot...
2022-08-23 10:38:51 | [trpo_pendulum] epoch #93 | Saved
2022-08-23 10:38:51 | [trpo_pendulum] epoch #93 | Time 92.99 s
2022-08-23 10:38:51 | [trpo_pendulum] epoch #93 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0218787
Evaluation/AverageReturn                 -0.215255
Evaluation/Iteration                     93
Evaluation/MaxReturn                     -0.207527
Evaluation/MinReturn                     -0.222982
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00772791
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -1.77176
GaussianMLPPolicy/KL                      0.00961203
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00151652
GaussianMLPPolicy/LossBefore             -0.0014768
GaussianMLPPolicy/dLoss                   3.97263e-05
GaussianMLPValueFunction/LossAfter       -3.34396
GaussianMLPValueFunction/LossBefore      -3.2299
GaussianMLPValueFunction/dLoss            0.114066
TotalEnvSteps                        187812
-----------------------------------  ----------------
2022-08-23 10:38:52 | [trpo_pendulum] epoch #94 | Saving snapshot...
2022-08-23 10:38:52 | [trpo_pendulum] epoch #94 | Saved
2022-08-23 10:38:52 | [trpo_pendulum] epoch #94 | Time 93.89 s
2022-08-23 10:38:52 | [trpo_pendulum] epoch #94 | EpochTime 0.90 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0159842
Evaluation/AverageReturn                 -0.171557
Evaluation/Iteration                     94
Evaluation/MaxReturn                     -0.168701
Evaluation/MinReturn                     -0.174412
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0028558
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -1.86333
GaussianMLPPolicy/KL                      0.00947361
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00171976
GaussianMLPPolicy/LossBefore             -0.00168473
GaussianMLPPolicy/dLoss                   3.50368e-05
GaussianMLPValueFunction/LossAfter       -3.43881
GaussianMLPValueFunction/LossBefore      -3.2984
GaussianMLPValueFunction/dLoss            0.140412
TotalEnvSteps                        189810
-----------------------------------  ----------------
2022-08-23 10:38:53 | [trpo_pendulum] epoch #95 | Saving snapshot...
2022-08-23 10:38:53 | [trpo_pendulum] epoch #95 | Saved
2022-08-23 10:38:53 | [trpo_pendulum] epoch #95 | Time 94.87 s
2022-08-23 10:38:53 | [trpo_pendulum] epoch #95 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0159768
Evaluation/AverageReturn                 -0.159386
Evaluation/Iteration                     95
Evaluation/MaxReturn                     -0.157263
Evaluation/MinReturn                     -0.161508
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00212221
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -1.92414
GaussianMLPPolicy/KL                      0.00784985
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               6.03125e-05
GaussianMLPPolicy/LossBefore              9.18674e-05
GaussianMLPPolicy/dLoss                   3.15549e-05
GaussianMLPValueFunction/LossAfter       -3.51521
GaussianMLPValueFunction/LossBefore      -3.43843
GaussianMLPValueFunction/dLoss            0.0767775
TotalEnvSteps                        191808
-----------------------------------  ----------------
2022-08-23 10:38:54 | [trpo_pendulum] epoch #96 | Saving snapshot...
2022-08-23 10:38:54 | [trpo_pendulum] epoch #96 | Saved
2022-08-23 10:38:54 | [trpo_pendulum] epoch #96 | Time 95.85 s
2022-08-23 10:38:54 | [trpo_pendulum] epoch #96 | EpochTime 0.98 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn       -0.0129371
Evaluation/AverageReturn                 -0.133763
Evaluation/Iteration                     96
Evaluation/MaxReturn                     -0.128362
Evaluation/MinReturn                     -0.139165
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00540116
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -1.96931
GaussianMLPPolicy/KL                      0.00974007
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00117909
GaussianMLPPolicy/LossBefore             -0.00115955
GaussianMLPPolicy/dLoss                   1.9538e-05
GaussianMLPValueFunction/LossAfter       -3.60758
GaussianMLPValueFunction/LossBefore      -3.48906
GaussianMLPValueFunction/dLoss            0.118515
TotalEnvSteps                        193806
-----------------------------------  ---------------
2022-08-23 10:38:55 | [trpo_pendulum] epoch #97 | Saving snapshot...
2022-08-23 10:38:55 | [trpo_pendulum] epoch #97 | Saved
2022-08-23 10:38:55 | [trpo_pendulum] epoch #97 | Time 96.81 s
2022-08-23 10:38:55 | [trpo_pendulum] epoch #97 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0119664
Evaluation/AverageReturn                 -0.11879
Evaluation/Iteration                     97
Evaluation/MaxReturn                     -0.11335
Evaluation/MinReturn                     -0.12423
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00544005
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.03271
GaussianMLPPolicy/KL                      0.00618004
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000774001
GaussianMLPPolicy/LossBefore             -0.000754284
GaussianMLPPolicy/dLoss                   1.97173e-05
GaussianMLPValueFunction/LossAfter       -3.68059
GaussianMLPValueFunction/LossBefore      -3.59409
GaussianMLPValueFunction/dLoss            0.0864942
TotalEnvSteps                        195804
-----------------------------------  ----------------
2022-08-23 10:38:56 | [trpo_pendulum] epoch #98 | Saving snapshot...
2022-08-23 10:38:56 | [trpo_pendulum] epoch #98 | Saved
2022-08-23 10:38:56 | [trpo_pendulum] epoch #98 | Time 97.75 s
2022-08-23 10:38:56 | [trpo_pendulum] epoch #98 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.012057
Evaluation/AverageReturn                 -0.110393
Evaluation/Iteration                     98
Evaluation/MaxReturn                     -0.10764
Evaluation/MinReturn                     -0.113146
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00275286
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.11846
GaussianMLPPolicy/KL                      0.00810633
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000237078
GaussianMLPPolicy/LossBefore              0.000256214
GaussianMLPPolicy/dLoss                   1.91362e-05
GaussianMLPValueFunction/LossAfter       -3.76951
GaussianMLPValueFunction/LossBefore      -3.69767
GaussianMLPValueFunction/dLoss            0.0718369
TotalEnvSteps                        197802
-----------------------------------  ----------------
2022-08-23 10:38:57 | [trpo_pendulum] epoch #99 | Saving snapshot...
2022-08-23 10:38:57 | [trpo_pendulum] epoch #99 | Saved
2022-08-23 10:38:57 | [trpo_pendulum] epoch #99 | Time 98.71 s
2022-08-23 10:38:57 | [trpo_pendulum] epoch #99 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00964351
Evaluation/AverageReturn                 -0.0927792
Evaluation/Iteration                     99
Evaluation/MaxReturn                     -0.0917167
Evaluation/MinReturn                     -0.0938417
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00106252
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.16468
GaussianMLPPolicy/KL                      0.00783564
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000208869
GaussianMLPPolicy/LossBefore              0.000229465
GaussianMLPPolicy/dLoss                   2.05959e-05
GaussianMLPValueFunction/LossAfter       -3.81981
GaussianMLPValueFunction/LossBefore      -3.75297
GaussianMLPValueFunction/dLoss            0.0668375
TotalEnvSteps                        199800
-----------------------------------  ----------------
2022-08-23 10:38:58 | [trpo_pendulum] epoch #100 | Saving snapshot...
2022-08-23 10:38:58 | [trpo_pendulum] epoch #100 | Saved
2022-08-23 10:38:58 | [trpo_pendulum] epoch #100 | Time 99.67 s
2022-08-23 10:38:58 | [trpo_pendulum] epoch #100 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00780249
Evaluation/AverageReturn                 -0.0838455
Evaluation/Iteration                    100
Evaluation/MaxReturn                     -0.081671
Evaluation/MinReturn                     -0.08602
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00217446
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.20468
GaussianMLPPolicy/KL                      0.00245531
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000443877
GaussianMLPPolicy/LossBefore             -0.000440424
GaussianMLPPolicy/dLoss                   3.45288e-06
GaussianMLPValueFunction/LossAfter       -3.93914
GaussianMLPValueFunction/LossBefore      -3.85248
GaussianMLPValueFunction/dLoss            0.086664
TotalEnvSteps                        201798
-----------------------------------  ----------------
2022-08-23 10:38:59 | [trpo_pendulum] epoch #101 | Saving snapshot...
2022-08-23 10:38:59 | [trpo_pendulum] epoch #101 | Saved
2022-08-23 10:38:59 | [trpo_pendulum] epoch #101 | Time 100.62 s
2022-08-23 10:38:59 | [trpo_pendulum] epoch #101 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00695582
Evaluation/AverageReturn                 -0.0735244
Evaluation/Iteration                    101
Evaluation/MaxReturn                     -0.0728742
Evaluation/MinReturn                     -0.0741746
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000650216
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.25285
GaussianMLPPolicy/KL                      0.00610406
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000225766
GaussianMLPPolicy/LossBefore              0.000238996
GaussianMLPPolicy/dLoss                   1.32307e-05
GaussianMLPValueFunction/LossAfter       -3.96918
GaussianMLPValueFunction/LossBefore      -3.8966
GaussianMLPValueFunction/dLoss            0.0725789
TotalEnvSteps                        203796
-----------------------------------  ----------------
2022-08-23 10:39:00 | [trpo_pendulum] epoch #102 | Saving snapshot...
2022-08-23 10:39:00 | [trpo_pendulum] epoch #102 | Saved
2022-08-23 10:39:00 | [trpo_pendulum] epoch #102 | Time 101.57 s
2022-08-23 10:39:00 | [trpo_pendulum] epoch #102 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00733126
Evaluation/AverageReturn                 -0.0697101
Evaluation/Iteration                    102
Evaluation/MaxReturn                     -0.0677626
Evaluation/MinReturn                     -0.0716576
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00194752
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.32441
GaussianMLPPolicy/KL                      0.00543851
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00119533
GaussianMLPPolicy/LossBefore             -0.00118527
GaussianMLPPolicy/dLoss                   1.00632e-05
GaussianMLPValueFunction/LossAfter       -4.09973
GaussianMLPValueFunction/LossBefore      -3.90402
GaussianMLPValueFunction/dLoss            0.195711
TotalEnvSteps                        205794
-----------------------------------  ----------------
2022-08-23 10:39:01 | [trpo_pendulum] epoch #103 | Saving snapshot...
2022-08-23 10:39:01 | [trpo_pendulum] epoch #103 | Saved
2022-08-23 10:39:01 | [trpo_pendulum] epoch #103 | Time 102.57 s
2022-08-23 10:39:01 | [trpo_pendulum] epoch #103 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0064265
Evaluation/AverageReturn                 -0.0597753
Evaluation/Iteration                    103
Evaluation/MaxReturn                     -0.0579983
Evaluation/MinReturn                     -0.0615523
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.001777
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.39056
GaussianMLPPolicy/KL                      0.00587773
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -9.31894e-05
GaussianMLPPolicy/LossBefore             -8.3539e-05
GaussianMLPPolicy/dLoss                   9.65039e-06
GaussianMLPValueFunction/LossAfter       -4.17804
GaussianMLPValueFunction/LossBefore      -4.10227
GaussianMLPValueFunction/dLoss            0.0757675
TotalEnvSteps                        207792
-----------------------------------  ----------------
2022-08-23 10:39:02 | [trpo_pendulum] epoch #104 | Saving snapshot...
2022-08-23 10:39:02 | [trpo_pendulum] epoch #104 | Saved
2022-08-23 10:39:02 | [trpo_pendulum] epoch #104 | Time 103.53 s
2022-08-23 10:39:02 | [trpo_pendulum] epoch #104 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00518755
Evaluation/AverageReturn                 -0.0523314
Evaluation/Iteration                    104
Evaluation/MaxReturn                     -0.050772
Evaluation/MinReturn                     -0.0538908
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0015594
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.42175
GaussianMLPPolicy/KL                      0.00757541
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000494263
GaussianMLPPolicy/LossBefore             -0.000493822
GaussianMLPPolicy/dLoss                   4.4133e-07
GaussianMLPValueFunction/LossAfter       -4.24287
GaussianMLPValueFunction/LossBefore      -4.16321
GaussianMLPValueFunction/dLoss            0.0796652
TotalEnvSteps                        209790
-----------------------------------  ----------------
2022-08-23 10:39:03 | [trpo_pendulum] epoch #105 | Saving snapshot...
2022-08-23 10:39:03 | [trpo_pendulum] epoch #105 | Saved
2022-08-23 10:39:03 | [trpo_pendulum] epoch #105 | Time 104.46 s
2022-08-23 10:39:03 | [trpo_pendulum] epoch #105 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0054466
Evaluation/AverageReturn                 -0.0561397
Evaluation/Iteration                    105
Evaluation/MaxReturn                     -0.0552737
Evaluation/MinReturn                     -0.0570057
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000865981
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.47911
GaussianMLPPolicy/KL                      0.00440301
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000266565
GaussianMLPPolicy/LossBefore              0.000274076
GaussianMLPPolicy/dLoss                   7.51085e-06
GaussianMLPValueFunction/LossAfter       -4.27378
GaussianMLPValueFunction/LossBefore      -4.25515
GaussianMLPValueFunction/dLoss            0.0186334
TotalEnvSteps                        211788
-----------------------------------  ----------------
2022-08-23 10:39:04 | [trpo_pendulum] epoch #106 | Saving snapshot...
2022-08-23 10:39:04 | [trpo_pendulum] epoch #106 | Saved
2022-08-23 10:39:04 | [trpo_pendulum] epoch #106 | Time 105.54 s
2022-08-23 10:39:04 | [trpo_pendulum] epoch #106 | EpochTime 1.07 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00488726
Evaluation/AverageReturn                 -0.0478067
Evaluation/Iteration                    106
Evaluation/MaxReturn                     -0.0458009
Evaluation/MinReturn                     -0.0498126
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00200587
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.51253
GaussianMLPPolicy/KL                      0.00442174
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000849721
GaussianMLPPolicy/LossBefore             -0.000842183
GaussianMLPPolicy/dLoss                   7.5383e-06
GaussianMLPValueFunction/LossAfter       -4.33914
GaussianMLPValueFunction/LossBefore      -4.23949
GaussianMLPValueFunction/dLoss            0.0996513
TotalEnvSteps                        213786
-----------------------------------  ----------------
2022-08-23 10:39:05 | [trpo_pendulum] epoch #107 | Saving snapshot...
2022-08-23 10:39:05 | [trpo_pendulum] epoch #107 | Saved
2022-08-23 10:39:05 | [trpo_pendulum] epoch #107 | Time 106.51 s
2022-08-23 10:39:05 | [trpo_pendulum] epoch #107 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00414127
Evaluation/AverageReturn                 -0.0449274
Evaluation/Iteration                    107
Evaluation/MaxReturn                     -0.043183
Evaluation/MinReturn                     -0.0466719
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00174444
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.57011
GaussianMLPPolicy/KL                      0.00718361
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               7.00048e-05
GaussianMLPPolicy/LossBefore              8.40955e-05
GaussianMLPPolicy/dLoss                   1.40907e-05
GaussianMLPValueFunction/LossAfter       -4.41175
GaussianMLPValueFunction/LossBefore      -4.34832
GaussianMLPValueFunction/dLoss            0.0634308
TotalEnvSteps                        215784
-----------------------------------  ----------------
2022-08-23 10:39:06 | [trpo_pendulum] epoch #108 | Saving snapshot...
2022-08-23 10:39:06 | [trpo_pendulum] epoch #108 | Saved
2022-08-23 10:39:06 | [trpo_pendulum] epoch #108 | Time 107.48 s
2022-08-23 10:39:06 | [trpo_pendulum] epoch #108 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00366432
Evaluation/AverageReturn                 -0.037964
Evaluation/Iteration                    108
Evaluation/MaxReturn                     -0.0358011
Evaluation/MinReturn                     -0.0401268
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00216284
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.64045
GaussianMLPPolicy/KL                      0.00533127
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.0006723
GaussianMLPPolicy/LossBefore             -0.000662331
GaussianMLPPolicy/dLoss                   9.96876e-06
GaussianMLPValueFunction/LossAfter       -4.51317
GaussianMLPValueFunction/LossBefore      -4.37615
GaussianMLPValueFunction/dLoss            0.137013
TotalEnvSteps                        217782
-----------------------------------  ----------------
2022-08-23 10:39:07 | [trpo_pendulum] epoch #109 | Saving snapshot...
2022-08-23 10:39:07 | [trpo_pendulum] epoch #109 | Saved
2022-08-23 10:39:07 | [trpo_pendulum] epoch #109 | Time 108.43 s
2022-08-23 10:39:07 | [trpo_pendulum] epoch #109 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00391687
Evaluation/AverageReturn                 -0.0362965
Evaluation/Iteration                    109
Evaluation/MaxReturn                     -0.0360447
Evaluation/MinReturn                     -0.0365484
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000251857
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.64607
GaussianMLPPolicy/KL                      0.000871038
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000955422
GaussianMLPPolicy/LossBefore             -0.000954266
GaussianMLPPolicy/dLoss                   1.15525e-06
GaussianMLPValueFunction/LossAfter       -4.65842
GaussianMLPValueFunction/LossBefore      -4.35114
GaussianMLPValueFunction/dLoss            0.307283
TotalEnvSteps                        219780
-----------------------------------  ----------------
2022-08-23 10:39:08 | [trpo_pendulum] epoch #110 | Saving snapshot...
2022-08-23 10:39:08 | [trpo_pendulum] epoch #110 | Saved
2022-08-23 10:39:08 | [trpo_pendulum] epoch #110 | Time 109.38 s
2022-08-23 10:39:08 | [trpo_pendulum] epoch #110 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00404361
Evaluation/AverageReturn                 -0.0374206
Evaluation/Iteration                    110
Evaluation/MaxReturn                     -0.0371831
Evaluation/MinReturn                     -0.0376581
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000237506
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.68904
GaussianMLPPolicy/KL                      0.00253539
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000206152
GaussianMLPPolicy/LossBefore              0.000209813
GaussianMLPPolicy/dLoss                   3.66115e-06
GaussianMLPValueFunction/LossAfter       -4.73287
GaussianMLPValueFunction/LossBefore      -4.64444
GaussianMLPValueFunction/dLoss            0.0884228
TotalEnvSteps                        221778
-----------------------------------  ----------------
2022-08-23 10:39:09 | [trpo_pendulum] epoch #111 | Saving snapshot...
2022-08-23 10:39:09 | [trpo_pendulum] epoch #111 | Saved
2022-08-23 10:39:09 | [trpo_pendulum] epoch #111 | Time 110.34 s
2022-08-23 10:39:09 | [trpo_pendulum] epoch #111 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00342736
Evaluation/AverageReturn                 -0.0313134
Evaluation/Iteration                    111
Evaluation/MaxReturn                     -0.0302745
Evaluation/MinReturn                     -0.0323523
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00103889
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.72677
GaussianMLPPolicy/KL                      0.00315018
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000201129
GaussianMLPPolicy/LossBefore             -0.000196162
GaussianMLPPolicy/dLoss                   4.9669e-06
GaussianMLPValueFunction/LossAfter       -4.81472
GaussianMLPValueFunction/LossBefore      -4.72353
GaussianMLPValueFunction/dLoss            0.0911908
TotalEnvSteps                        223776
-----------------------------------  ----------------
2022-08-23 10:39:09 | [trpo_pendulum] epoch #112 | Saving snapshot...
2022-08-23 10:39:09 | [trpo_pendulum] epoch #112 | Saved
2022-08-23 10:39:09 | [trpo_pendulum] epoch #112 | Time 111.28 s
2022-08-23 10:39:09 | [trpo_pendulum] epoch #112 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00307602
Evaluation/AverageReturn                 -0.0295075
Evaluation/Iteration                    112
Evaluation/MaxReturn                     -0.028918
Evaluation/MinReturn                     -0.0300971
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000589527
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.75193
GaussianMLPPolicy/KL                      0.000726164
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -6.45011e-05
GaussianMLPPolicy/LossBefore             -6.34869e-05
GaussianMLPPolicy/dLoss                   1.01416e-06
GaussianMLPValueFunction/LossAfter       -4.88606
GaussianMLPValueFunction/LossBefore      -4.8244
GaussianMLPValueFunction/dLoss            0.061667
TotalEnvSteps                        225774
-----------------------------------  ----------------
2022-08-23 10:39:10 | [trpo_pendulum] epoch #113 | Saving snapshot...
2022-08-23 10:39:10 | [trpo_pendulum] epoch #113 | Saved
2022-08-23 10:39:10 | [trpo_pendulum] epoch #113 | Time 112.23 s
2022-08-23 10:39:10 | [trpo_pendulum] epoch #113 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00262441
Evaluation/AverageReturn                 -0.0310279
Evaluation/Iteration                    113
Evaluation/MaxReturn                     -0.0299163
Evaluation/MinReturn                     -0.0321395
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0011116
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.78617
GaussianMLPPolicy/KL                      0.00210317
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000271673
GaussianMLPPolicy/LossBefore              0.000274878
GaussianMLPPolicy/dLoss                   3.20523e-06
GaussianMLPValueFunction/LossAfter       -4.9294
GaussianMLPValueFunction/LossBefore      -4.8266
GaussianMLPValueFunction/dLoss            0.102799
TotalEnvSteps                        227772
-----------------------------------  ----------------
2022-08-23 10:39:11 | [trpo_pendulum] epoch #114 | Saving snapshot...
2022-08-23 10:39:11 | [trpo_pendulum] epoch #114 | Saved
2022-08-23 10:39:11 | [trpo_pendulum] epoch #114 | Time 113.17 s
2022-08-23 10:39:11 | [trpo_pendulum] epoch #114 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00306724
Evaluation/AverageReturn                 -0.0300979
Evaluation/Iteration                    114
Evaluation/MaxReturn                     -0.0281967
Evaluation/MinReturn                     -0.0319991
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00190117
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.81067
GaussianMLPPolicy/KL                      0.00203886
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               3.24521e-05
GaussianMLPPolicy/LossBefore              3.56538e-05
GaussianMLPPolicy/dLoss                   3.20172e-06
GaussianMLPValueFunction/LossAfter       -4.41329
GaussianMLPValueFunction/LossBefore      -4.89659
GaussianMLPValueFunction/dLoss           -0.483305
TotalEnvSteps                        229770
-----------------------------------  ----------------
2022-08-23 10:39:12 | [trpo_pendulum] epoch #115 | Saving snapshot...
2022-08-23 10:39:12 | [trpo_pendulum] epoch #115 | Saved
2022-08-23 10:39:12 | [trpo_pendulum] epoch #115 | Time 114.19 s
2022-08-23 10:39:12 | [trpo_pendulum] epoch #115 | EpochTime 1.02 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00229488
Evaluation/AverageReturn                 -0.025206
Evaluation/Iteration                    115
Evaluation/MaxReturn                     -0.0240437
Evaluation/MinReturn                     -0.0263683
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0011623
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.82805
GaussianMLPPolicy/KL                      0.00654677
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00138633
GaussianMLPPolicy/LossBefore             -0.00138563
GaussianMLPPolicy/dLoss                   6.99423e-07
GaussianMLPValueFunction/LossAfter       -5.07687
GaussianMLPValueFunction/LossBefore      -3.86341
GaussianMLPValueFunction/dLoss            1.21346
TotalEnvSteps                        231768
-----------------------------------  ----------------
2022-08-23 10:39:13 | [trpo_pendulum] epoch #116 | Saving snapshot...
2022-08-23 10:39:13 | [trpo_pendulum] epoch #116 | Saved
2022-08-23 10:39:13 | [trpo_pendulum] epoch #116 | Time 115.12 s
2022-08-23 10:39:13 | [trpo_pendulum] epoch #116 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00263124
Evaluation/AverageReturn                 -0.024962
Evaluation/Iteration                    116
Evaluation/MaxReturn                     -0.0232999
Evaluation/MinReturn                     -0.0266242
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00166216
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.85969
GaussianMLPPolicy/KL                      0.00118457
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               4.12658e-05
GaussianMLPPolicy/LossBefore              4.29542e-05
GaussianMLPPolicy/dLoss                   1.68847e-06
GaussianMLPValueFunction/LossAfter       -5.08085
GaussianMLPValueFunction/LossBefore      -5.11262
GaussianMLPValueFunction/dLoss           -0.031764
TotalEnvSteps                        233766
-----------------------------------  ----------------
2022-08-23 10:39:14 | [trpo_pendulum] epoch #117 | Saving snapshot...
2022-08-23 10:39:14 | [trpo_pendulum] epoch #117 | Saved
2022-08-23 10:39:14 | [trpo_pendulum] epoch #117 | Time 116.08 s
2022-08-23 10:39:14 | [trpo_pendulum] epoch #117 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00264435
Evaluation/AverageReturn                 -0.0286769
Evaluation/Iteration                    117
Evaluation/MaxReturn                     -0.0283415
Evaluation/MinReturn                     -0.0290123
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000335423
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.81458
GaussianMLPPolicy/KL                      0.00455205
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00114528
GaussianMLPPolicy/LossBefore              0.00115564
GaussianMLPPolicy/dLoss                   1.03575e-05
GaussianMLPValueFunction/LossAfter       -4.81174
GaussianMLPValueFunction/LossBefore      -3.72835
GaussianMLPValueFunction/dLoss            1.08339
TotalEnvSteps                        235764
-----------------------------------  ----------------
2022-08-23 10:39:15 | [trpo_pendulum] epoch #118 | Saving snapshot...
2022-08-23 10:39:15 | [trpo_pendulum] epoch #118 | Saved
2022-08-23 10:39:15 | [trpo_pendulum] epoch #118 | Time 117.11 s
2022-08-23 10:39:15 | [trpo_pendulum] epoch #118 | EpochTime 1.02 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00269796
Evaluation/AverageReturn                 -0.0278545
Evaluation/Iteration                    118
Evaluation/MaxReturn                     -0.0262674
Evaluation/MinReturn                     -0.0294415
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00158703
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.83467
GaussianMLPPolicy/KL                      0.00899748
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000665992
GaussianMLPPolicy/LossBefore             -0.000660849
GaussianMLPPolicy/dLoss                   5.14335e-06
GaussianMLPValueFunction/LossAfter       -5.06684
GaussianMLPValueFunction/LossBefore      -4.72056
GaussianMLPValueFunction/dLoss            0.346274
TotalEnvSteps                        237762
-----------------------------------  ----------------
2022-08-23 10:39:16 | [trpo_pendulum] epoch #119 | Saving snapshot...
2022-08-23 10:39:16 | [trpo_pendulum] epoch #119 | Saved
2022-08-23 10:39:16 | [trpo_pendulum] epoch #119 | Time 118.05 s
2022-08-23 10:39:16 | [trpo_pendulum] epoch #119 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00266216
Evaluation/AverageReturn                 -0.0256223
Evaluation/Iteration                    119
Evaluation/MaxReturn                     -0.0255005
Evaluation/MinReturn                     -0.025744
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00012177
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.85294
GaussianMLPPolicy/KL                      0.000975568
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000325075
GaussianMLPPolicy/LossBefore             -0.000323684
GaussianMLPPolicy/dLoss                   1.39044e-06
GaussianMLPValueFunction/LossAfter       -5.28866
GaussianMLPValueFunction/LossBefore      -5.1358
GaussianMLPValueFunction/dLoss            0.152861
TotalEnvSteps                        239760
-----------------------------------  ----------------
2022-08-23 10:39:17 | [trpo_pendulum] epoch #120 | Saving snapshot...
2022-08-23 10:39:17 | [trpo_pendulum] epoch #120 | Saved
2022-08-23 10:39:17 | [trpo_pendulum] epoch #120 | Time 118.99 s
2022-08-23 10:39:17 | [trpo_pendulum] epoch #120 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00250578
Evaluation/AverageReturn                 -0.0245004
Evaluation/Iteration                    120
Evaluation/MaxReturn                     -0.0240114
Evaluation/MinReturn                     -0.0249894
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000488997
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.87437
GaussianMLPPolicy/KL                      0.000989507
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000181665
GaussianMLPPolicy/LossBefore              0.000183077
GaussianMLPPolicy/dLoss                   1.41183e-06
GaussianMLPValueFunction/LossAfter       -5.19366
GaussianMLPValueFunction/LossBefore      -5.28674
GaussianMLPValueFunction/dLoss           -0.0930743
TotalEnvSteps                        241758
-----------------------------------  ----------------
2022-08-23 10:39:18 | [trpo_pendulum] epoch #121 | Saving snapshot...
2022-08-23 10:39:18 | [trpo_pendulum] epoch #121 | Saved
2022-08-23 10:39:18 | [trpo_pendulum] epoch #121 | Time 120.02 s
2022-08-23 10:39:18 | [trpo_pendulum] epoch #121 | EpochTime 1.02 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00239269
Evaluation/AverageReturn                 -0.0294749
Evaluation/Iteration                    121
Evaluation/MaxReturn                     -0.028107
Evaluation/MinReturn                     -0.0308427
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00136787
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.84639
GaussianMLPPolicy/KL                      0.00317364
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000858916
GaussianMLPPolicy/LossBefore              0.000867037
GaussianMLPPolicy/dLoss                   8.12154e-06
GaussianMLPValueFunction/LossAfter       -3.7442
GaussianMLPValueFunction/LossBefore      -3.30611
GaussianMLPValueFunction/dLoss            0.438094
TotalEnvSteps                        243756
-----------------------------------  ----------------
2022-08-23 10:39:19 | [trpo_pendulum] epoch #122 | Saving snapshot...
2022-08-23 10:39:19 | [trpo_pendulum] epoch #122 | Saved
2022-08-23 10:39:19 | [trpo_pendulum] epoch #122 | Time 120.95 s
2022-08-23 10:39:19 | [trpo_pendulum] epoch #122 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00236979
Evaluation/AverageReturn                 -0.0226357
Evaluation/Iteration                    122
Evaluation/MaxReturn                     -0.0214677
Evaluation/MinReturn                     -0.0238037
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00116803
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.8768
GaussianMLPPolicy/KL                      0.00149261
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000434776
GaussianMLPPolicy/LossBefore             -0.000432531
GaussianMLPPolicy/dLoss                   2.2444e-06
GaussianMLPValueFunction/LossAfter       -5.23497
GaussianMLPValueFunction/LossBefore      -5.09575
GaussianMLPValueFunction/dLoss            0.139219
TotalEnvSteps                        245754
-----------------------------------  ----------------
2022-08-23 10:39:20 | [trpo_pendulum] epoch #123 | Saving snapshot...
2022-08-23 10:39:20 | [trpo_pendulum] epoch #123 | Saved
2022-08-23 10:39:20 | [trpo_pendulum] epoch #123 | Time 121.99 s
2022-08-23 10:39:20 | [trpo_pendulum] epoch #123 | EpochTime 1.04 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00249266
Evaluation/AverageReturn                 -0.0284723
Evaluation/Iteration                    123
Evaluation/MaxReturn                     -0.0284496
Evaluation/MinReturn                     -0.028495
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.26784e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.92216
GaussianMLPPolicy/KL                      0.00261722
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000879445
GaussianMLPPolicy/LossBefore              0.000882888
GaussianMLPPolicy/dLoss                   3.44327e-06
GaussianMLPValueFunction/LossAfter       -5.28597
GaussianMLPValueFunction/LossBefore      -4.30336
GaussianMLPValueFunction/dLoss            0.982612
TotalEnvSteps                        247752
-----------------------------------  ----------------
2022-08-23 10:39:21 | [trpo_pendulum] epoch #124 | Saving snapshot...
2022-08-23 10:39:21 | [trpo_pendulum] epoch #124 | Saved
2022-08-23 10:39:21 | [trpo_pendulum] epoch #124 | Time 122.93 s
2022-08-23 10:39:21 | [trpo_pendulum] epoch #124 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00270887
Evaluation/AverageReturn                 -0.0322679
Evaluation/Iteration                    124
Evaluation/MaxReturn                     -0.0314763
Evaluation/MinReturn                     -0.0330595
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000791594
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.97868
GaussianMLPPolicy/KL                      0.00384466
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000483798
GaussianMLPPolicy/LossBefore              0.000489941
GaussianMLPPolicy/dLoss                   6.14274e-06
GaussianMLPValueFunction/LossAfter       -4.91646
GaussianMLPValueFunction/LossBefore      -4.57326
GaussianMLPValueFunction/dLoss            0.343203
TotalEnvSteps                        249750
-----------------------------------  ----------------
2022-08-23 10:39:22 | [trpo_pendulum] epoch #125 | Saving snapshot...
2022-08-23 10:39:22 | [trpo_pendulum] epoch #125 | Saved
2022-08-23 10:39:22 | [trpo_pendulum] epoch #125 | Time 123.81 s
2022-08-23 10:39:22 | [trpo_pendulum] epoch #125 | EpochTime 0.88 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0020783
Evaluation/AverageReturn                 -0.0200885
Evaluation/Iteration                    125
Evaluation/MaxReturn                     -0.018645
Evaluation/MinReturn                     -0.021532
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00144349
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -2.99401
GaussianMLPPolicy/KL                      0.00030883
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000928987
GaussianMLPPolicy/LossBefore             -0.000928584
GaussianMLPPolicy/dLoss                   4.03088e-07
GaussianMLPValueFunction/LossAfter       -5.42693
GaussianMLPValueFunction/LossBefore      -4.32048
GaussianMLPValueFunction/dLoss            1.10645
TotalEnvSteps                        251748
-----------------------------------  ----------------
2022-08-23 10:39:23 | [trpo_pendulum] epoch #126 | Saving snapshot...
2022-08-23 10:39:23 | [trpo_pendulum] epoch #126 | Saved
2022-08-23 10:39:23 | [trpo_pendulum] epoch #126 | Time 124.77 s
2022-08-23 10:39:23 | [trpo_pendulum] epoch #126 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00207459
Evaluation/AverageReturn                 -0.0205377
Evaluation/Iteration                    126
Evaluation/MaxReturn                     -0.0197627
Evaluation/MinReturn                     -0.0213128
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000775053
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.00988
GaussianMLPPolicy/KL                      0.00252419
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.69944e-06
GaussianMLPPolicy/LossBefore             -3.53333e-06
GaussianMLPPolicy/dLoss                   1.66103e-07
GaussianMLPValueFunction/LossAfter       -5.17313
GaussianMLPValueFunction/LossBefore      -5.41794
GaussianMLPValueFunction/dLoss           -0.244811
TotalEnvSteps                        253746
-----------------------------------  ----------------
2022-08-23 10:39:24 | [trpo_pendulum] epoch #127 | Saving snapshot...
2022-08-23 10:39:24 | [trpo_pendulum] epoch #127 | Saved
2022-08-23 10:39:24 | [trpo_pendulum] epoch #127 | Time 125.73 s
2022-08-23 10:39:24 | [trpo_pendulum] epoch #127 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00199879
Evaluation/AverageReturn                 -0.0190982
Evaluation/Iteration                    127
Evaluation/MaxReturn                     -0.0182716
Evaluation/MinReturn                     -0.0199249
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000826658
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.03704
GaussianMLPPolicy/KL                      0.00091559
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00020208
GaussianMLPPolicy/LossBefore              0.000203358
GaussianMLPPolicy/dLoss                   1.27773e-06
GaussianMLPValueFunction/LossAfter       -5.57906
GaussianMLPValueFunction/LossBefore      -5.45531
GaussianMLPValueFunction/dLoss            0.123754
TotalEnvSteps                        255744
-----------------------------------  ----------------
2022-08-23 10:39:25 | [trpo_pendulum] epoch #128 | Saving snapshot...
2022-08-23 10:39:25 | [trpo_pendulum] epoch #128 | Saved
2022-08-23 10:39:25 | [trpo_pendulum] epoch #128 | Time 126.71 s
2022-08-23 10:39:25 | [trpo_pendulum] epoch #128 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00257984
Evaluation/AverageReturn                 -0.0313123
Evaluation/Iteration                    128
Evaluation/MaxReturn                     -0.0301389
Evaluation/MinReturn                     -0.0324857
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00117344
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.00459
GaussianMLPPolicy/KL                      0.00304898
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00131796
GaussianMLPPolicy/LossBefore              0.0013235
GaussianMLPPolicy/dLoss                   5.54195e-06
GaussianMLPValueFunction/LossAfter       -4.37509
GaussianMLPValueFunction/LossBefore      -1.3367
GaussianMLPValueFunction/dLoss            3.03839
TotalEnvSteps                        257742
-----------------------------------  ----------------
2022-08-23 10:39:26 | [trpo_pendulum] epoch #129 | Saving snapshot...
2022-08-23 10:39:26 | [trpo_pendulum] epoch #129 | Saved
2022-08-23 10:39:26 | [trpo_pendulum] epoch #129 | Time 127.64 s
2022-08-23 10:39:26 | [trpo_pendulum] epoch #129 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00297461
Evaluation/AverageReturn                 -0.0376484
Evaluation/Iteration                    129
Evaluation/MaxReturn                     -0.0344691
Evaluation/MinReturn                     -0.0408278
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00317935
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.05103
GaussianMLPPolicy/KL                      0.00918954
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000946786
GaussianMLPPolicy/LossBefore              0.00095758
GaussianMLPPolicy/dLoss                   1.07943e-05
GaussianMLPValueFunction/LossAfter       -4.53215
GaussianMLPValueFunction/LossBefore      -2.74805
GaussianMLPValueFunction/dLoss            1.7841
TotalEnvSteps                        259740
-----------------------------------  ----------------
2022-08-23 10:39:27 | [trpo_pendulum] epoch #130 | Saving snapshot...
2022-08-23 10:39:27 | [trpo_pendulum] epoch #130 | Saved
2022-08-23 10:39:27 | [trpo_pendulum] epoch #130 | Time 128.57 s
2022-08-23 10:39:27 | [trpo_pendulum] epoch #130 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00266903
Evaluation/AverageReturn                 -0.0284186
Evaluation/Iteration                    130
Evaluation/MaxReturn                     -0.0268705
Evaluation/MinReturn                     -0.0299666
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00154803
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.06708
GaussianMLPPolicy/KL                      0.000835017
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000744318
GaussianMLPPolicy/LossBefore             -0.000743359
GaussianMLPPolicy/dLoss                   9.58855e-07
GaussianMLPValueFunction/LossAfter       -5.15418
GaussianMLPValueFunction/LossBefore      -4.3992
GaussianMLPValueFunction/dLoss            0.754981
TotalEnvSteps                        261738
-----------------------------------  ----------------
2022-08-23 10:39:28 | [trpo_pendulum] epoch #131 | Saving snapshot...
2022-08-23 10:39:28 | [trpo_pendulum] epoch #131 | Saved
2022-08-23 10:39:28 | [trpo_pendulum] epoch #131 | Time 129.63 s
2022-08-23 10:39:28 | [trpo_pendulum] epoch #131 | EpochTime 1.06 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00224162
Evaluation/AverageReturn                 -0.0227409
Evaluation/Iteration                    131
Evaluation/MaxReturn                     -0.0223685
Evaluation/MinReturn                     -0.0231132
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000372373
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.07485
GaussianMLPPolicy/KL                      0.000619676
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000705901
GaussianMLPPolicy/LossBefore             -0.000705786
GaussianMLPPolicy/dLoss                   1.15891e-07
GaussianMLPValueFunction/LossAfter       -5.46434
GaussianMLPValueFunction/LossBefore      -4.71946
GaussianMLPValueFunction/dLoss            0.744885
TotalEnvSteps                        263736
-----------------------------------  ----------------
2022-08-23 10:39:29 | [trpo_pendulum] epoch #132 | Saving snapshot...
2022-08-23 10:39:29 | [trpo_pendulum] epoch #132 | Saved
2022-08-23 10:39:29 | [trpo_pendulum] epoch #132 | Time 130.61 s
2022-08-23 10:39:29 | [trpo_pendulum] epoch #132 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00201781
Evaluation/AverageReturn                 -0.0209137
Evaluation/Iteration                    132
Evaluation/MaxReturn                     -0.0203705
Evaluation/MinReturn                     -0.0214568
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000543151
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.07945
GaussianMLPPolicy/KL                      0.000619588
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -1.56152e-05
GaussianMLPPolicy/LossBefore             -1.47556e-05
GaussianMLPPolicy/dLoss                   8.59576e-07
GaussianMLPValueFunction/LossAfter       -5.53466
GaussianMLPValueFunction/LossBefore      -5.49729
GaussianMLPValueFunction/dLoss            0.0373755
TotalEnvSteps                        265734
-----------------------------------  ----------------
2022-08-23 10:39:30 | [trpo_pendulum] epoch #133 | Saving snapshot...
2022-08-23 10:39:30 | [trpo_pendulum] epoch #133 | Saved
2022-08-23 10:39:30 | [trpo_pendulum] epoch #133 | Time 131.58 s
2022-08-23 10:39:30 | [trpo_pendulum] epoch #133 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00232304
Evaluation/AverageReturn                 -0.0238002
Evaluation/Iteration                    133
Evaluation/MaxReturn                     -0.0229732
Evaluation/MinReturn                     -0.0246273
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000827065
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.12203
GaussianMLPPolicy/KL                      0.00344808
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000317498
GaussianMLPPolicy/LossBefore              0.000322844
GaussianMLPPolicy/dLoss                   5.34626e-06
GaussianMLPValueFunction/LossAfter       -5.42943
GaussianMLPValueFunction/LossBefore      -5.26352
GaussianMLPValueFunction/dLoss            0.165915
TotalEnvSteps                        267732
-----------------------------------  ----------------
2022-08-23 10:39:31 | [trpo_pendulum] epoch #134 | Saving snapshot...
2022-08-23 10:39:31 | [trpo_pendulum] epoch #134 | Saved
2022-08-23 10:39:31 | [trpo_pendulum] epoch #134 | Time 132.52 s
2022-08-23 10:39:31 | [trpo_pendulum] epoch #134 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00193306
Evaluation/AverageReturn                 -0.0227804
Evaluation/Iteration                    134
Evaluation/MaxReturn                     -0.0222938
Evaluation/MinReturn                     -0.023267
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000486579
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.14056
GaussianMLPPolicy/KL                      0.00109362
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000222947
GaussianMLPPolicy/LossBefore              0.000224537
GaussianMLPPolicy/dLoss                   1.58988e-06
GaussianMLPValueFunction/LossAfter       -5.45793
GaussianMLPValueFunction/LossBefore      -5.3407
GaussianMLPValueFunction/dLoss            0.117224
TotalEnvSteps                        269730
-----------------------------------  ----------------
2022-08-23 10:39:32 | [trpo_pendulum] epoch #135 | Saving snapshot...
2022-08-23 10:39:32 | [trpo_pendulum] epoch #135 | Saved
2022-08-23 10:39:32 | [trpo_pendulum] epoch #135 | Time 133.46 s
2022-08-23 10:39:32 | [trpo_pendulum] epoch #135 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00170435
Evaluation/AverageReturn                 -0.0181596
Evaluation/Iteration                    135
Evaluation/MaxReturn                     -0.018094
Evaluation/MinReturn                     -0.0182252
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.56194e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.17316
GaussianMLPPolicy/KL                      0.00164665
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00028221
GaussianMLPPolicy/LossBefore             -0.000279749
GaussianMLPPolicy/dLoss                   2.46067e-06
GaussianMLPValueFunction/LossAfter       -5.18924
GaussianMLPValueFunction/LossBefore      -5.43976
GaussianMLPValueFunction/dLoss           -0.250523
TotalEnvSteps                        271728
-----------------------------------  ----------------
2022-08-23 10:39:33 | [trpo_pendulum] epoch #136 | Saving snapshot...
2022-08-23 10:39:33 | [trpo_pendulum] epoch #136 | Saved
2022-08-23 10:39:33 | [trpo_pendulum] epoch #136 | Time 134.39 s
2022-08-23 10:39:33 | [trpo_pendulum] epoch #136 | EpochTime 0.92 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00146545
Evaluation/AverageReturn                 -0.013763
Evaluation/Iteration                    136
Evaluation/MaxReturn                     -0.0132565
Evaluation/MinReturn                     -0.0142694
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000506428
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.1894
GaussianMLPPolicy/KL                      0.00041497
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000106846
GaussianMLPPolicy/LossBefore              0.000107426
GaussianMLPPolicy/dLoss                   5.79712e-07
GaussianMLPValueFunction/LossAfter       -5.73597
GaussianMLPValueFunction/LossBefore      -5.65947
GaussianMLPValueFunction/dLoss            0.0765023
TotalEnvSteps                        273726
-----------------------------------  ----------------
2022-08-23 10:39:34 | [trpo_pendulum] epoch #137 | Saving snapshot...
2022-08-23 10:39:34 | [trpo_pendulum] epoch #137 | Saved
2022-08-23 10:39:34 | [trpo_pendulum] epoch #137 | Time 135.33 s
2022-08-23 10:39:34 | [trpo_pendulum] epoch #137 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00131444
Evaluation/AverageReturn                 -0.0137228
Evaluation/Iteration                    137
Evaluation/MaxReturn                     -0.0134666
Evaluation/MinReturn                     -0.0139789
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000256125
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.19669
GaussianMLPPolicy/KL                      0.000594092
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -5.82417e-05
GaussianMLPPolicy/LossBefore             -5.73999e-05
GaussianMLPPolicy/dLoss                   8.41832e-07
GaussianMLPValueFunction/LossAfter       -5.79957
GaussianMLPValueFunction/LossBefore      -5.7419
GaussianMLPValueFunction/dLoss            0.057663
TotalEnvSteps                        275724
-----------------------------------  ----------------
2022-08-23 10:39:34 | [trpo_pendulum] epoch #138 | Saving snapshot...
2022-08-23 10:39:34 | [trpo_pendulum] epoch #138 | Saved
2022-08-23 10:39:34 | [trpo_pendulum] epoch #138 | Time 136.29 s
2022-08-23 10:39:34 | [trpo_pendulum] epoch #138 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00150099
Evaluation/AverageReturn                 -0.0153201
Evaluation/Iteration                    138
Evaluation/MaxReturn                     -0.0152472
Evaluation/MinReturn                     -0.0153931
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.29554e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.21389
GaussianMLPPolicy/KL                      0.000396704
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000120666
GaussianMLPPolicy/LossBefore              0.000121232
GaussianMLPPolicy/dLoss                   5.66535e-07
GaussianMLPValueFunction/LossAfter       -5.71333
GaussianMLPValueFunction/LossBefore      -5.74777
GaussianMLPValueFunction/dLoss           -0.0344405
TotalEnvSteps                        277722
-----------------------------------  ----------------
2022-08-23 10:39:35 | [trpo_pendulum] epoch #139 | Saving snapshot...
2022-08-23 10:39:35 | [trpo_pendulum] epoch #139 | Saved
2022-08-23 10:39:35 | [trpo_pendulum] epoch #139 | Time 137.26 s
2022-08-23 10:39:35 | [trpo_pendulum] epoch #139 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00123054
Evaluation/AverageReturn                 -0.0127182
Evaluation/Iteration                    139
Evaluation/MaxReturn                     -0.0124338
Evaluation/MinReturn                     -0.0130026
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000284397
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.22448
GaussianMLPPolicy/KL                      0.000217346
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -1.90819e-05
GaussianMLPPolicy/LossBefore             -1.87793e-05
GaussianMLPPolicy/dLoss                   3.02582e-07
GaussianMLPValueFunction/LossAfter       -5.78665
GaussianMLPValueFunction/LossBefore      -5.85242
GaussianMLPValueFunction/dLoss           -0.0657649
TotalEnvSteps                        279720
-----------------------------------  ----------------
2022-08-23 10:39:36 | [trpo_pendulum] epoch #140 | Saving snapshot...
2022-08-23 10:39:36 | [trpo_pendulum] epoch #140 | Saved
2022-08-23 10:39:36 | [trpo_pendulum] epoch #140 | Time 138.18 s
2022-08-23 10:39:36 | [trpo_pendulum] epoch #140 | EpochTime 0.92 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00142586
Evaluation/AverageReturn                 -0.0183171
Evaluation/Iteration                    140
Evaluation/MaxReturn                     -0.0180276
Evaluation/MinReturn                     -0.0186066
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000289498
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.21625
GaussianMLPPolicy/KL                      0.00539106
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000421433
GaussianMLPPolicy/LossBefore              0.000422851
GaussianMLPPolicy/dLoss                   1.41739e-06
GaussianMLPValueFunction/LossAfter       -5.56334
GaussianMLPValueFunction/LossBefore      -4.88215
GaussianMLPValueFunction/dLoss            0.681184
TotalEnvSteps                        281718
-----------------------------------  ----------------
2022-08-23 10:39:37 | [trpo_pendulum] epoch #141 | Saving snapshot...
2022-08-23 10:39:37 | [trpo_pendulum] epoch #141 | Saved
2022-08-23 10:39:37 | [trpo_pendulum] epoch #141 | Time 139.15 s
2022-08-23 10:39:37 | [trpo_pendulum] epoch #141 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00138813
Evaluation/AverageReturn                 -0.0160941
Evaluation/Iteration                    141
Evaluation/MaxReturn                     -0.0160872
Evaluation/MinReturn                     -0.016101
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.8592e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.21608
GaussianMLPPolicy/KL                      0.00160698
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000329628
GaussianMLPPolicy/LossBefore             -0.000328931
GaussianMLPPolicy/dLoss                   6.97444e-07
GaussianMLPValueFunction/LossAfter       -5.83557
GaussianMLPValueFunction/LossBefore      -5.449
GaussianMLPValueFunction/dLoss            0.386573
TotalEnvSteps                        283716
-----------------------------------  ----------------
2022-08-23 10:39:38 | [trpo_pendulum] epoch #142 | Saving snapshot...
2022-08-23 10:39:38 | [trpo_pendulum] epoch #142 | Saved
2022-08-23 10:39:38 | [trpo_pendulum] epoch #142 | Time 140.07 s
2022-08-23 10:39:38 | [trpo_pendulum] epoch #142 | EpochTime 0.91 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00127668
Evaluation/AverageReturn                 -0.0139698
Evaluation/Iteration                    142
Evaluation/MaxReturn                     -0.0138537
Evaluation/MinReturn                     -0.0140858
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000116006
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.22532
GaussianMLPPolicy/KL                      0.00029112
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00029122
GaussianMLPPolicy/LossBefore             -0.000290812
GaussianMLPPolicy/dLoss                   4.0821e-07
GaussianMLPValueFunction/LossAfter       -5.66484
GaussianMLPValueFunction/LossBefore      -5.61242
GaussianMLPValueFunction/dLoss            0.0524206
TotalEnvSteps                        285714
-----------------------------------  ----------------
2022-08-23 10:39:39 | [trpo_pendulum] epoch #143 | Saving snapshot...
2022-08-23 10:39:39 | [trpo_pendulum] epoch #143 | Saved
2022-08-23 10:39:39 | [trpo_pendulum] epoch #143 | Time 141.08 s
2022-08-23 10:39:39 | [trpo_pendulum] epoch #143 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00135273
Evaluation/AverageReturn                 -0.0135406
Evaluation/Iteration                    143
Evaluation/MaxReturn                     -0.0132252
Evaluation/MinReturn                     -0.013856
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000315375
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.23733
GaussianMLPPolicy/KL                      0.000409019
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000217142
GaussianMLPPolicy/LossBefore              0.000217712
GaussianMLPPolicy/dLoss                   5.7026e-07
GaussianMLPValueFunction/LossAfter       -5.30773
GaussianMLPValueFunction/LossBefore      -5.77798
GaussianMLPValueFunction/dLoss           -0.470248
TotalEnvSteps                        287712
-----------------------------------  ----------------
2022-08-23 10:39:40 | [trpo_pendulum] epoch #144 | Saving snapshot...
2022-08-23 10:39:40 | [trpo_pendulum] epoch #144 | Saved
2022-08-23 10:39:40 | [trpo_pendulum] epoch #144 | Time 142.05 s
2022-08-23 10:39:40 | [trpo_pendulum] epoch #144 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00138414
Evaluation/AverageReturn                 -0.0140177
Evaluation/Iteration                    144
Evaluation/MaxReturn                     -0.013803
Evaluation/MinReturn                     -0.0142325
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000214748
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.26407
GaussianMLPPolicy/KL                      0.00121616
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000430709
GaussianMLPPolicy/LossBefore              0.000432463
GaussianMLPPolicy/dLoss                   1.7545e-06
GaussianMLPValueFunction/LossAfter       -6.01043
GaussianMLPValueFunction/LossBefore      -5.17452
GaussianMLPValueFunction/dLoss            0.835901
TotalEnvSteps                        289710
-----------------------------------  ----------------
2022-08-23 10:39:41 | [trpo_pendulum] epoch #145 | Saving snapshot...
2022-08-23 10:39:41 | [trpo_pendulum] epoch #145 | Saved
2022-08-23 10:39:41 | [trpo_pendulum] epoch #145 | Time 142.99 s
2022-08-23 10:39:41 | [trpo_pendulum] epoch #145 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00122908
Evaluation/AverageReturn                 -0.0124304
Evaluation/Iteration                    145
Evaluation/MaxReturn                     -0.0121046
Evaluation/MinReturn                     -0.0127562
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000325788
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.27214
GaussianMLPPolicy/KL                      0.00029362
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               6.92327e-05
GaussianMLPPolicy/LossBefore              6.96529e-05
GaussianMLPPolicy/dLoss                   4.20187e-07
GaussianMLPValueFunction/LossAfter       -6.08671
GaussianMLPValueFunction/LossBefore      -6.05351
GaussianMLPValueFunction/dLoss            0.0331955
TotalEnvSteps                        291708
-----------------------------------  ----------------
2022-08-23 10:39:42 | [trpo_pendulum] epoch #146 | Saving snapshot...
2022-08-23 10:39:42 | [trpo_pendulum] epoch #146 | Saved
2022-08-23 10:39:42 | [trpo_pendulum] epoch #146 | Time 143.95 s
2022-08-23 10:39:42 | [trpo_pendulum] epoch #146 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00135657
Evaluation/AverageReturn                 -0.0151018
Evaluation/Iteration                    146
Evaluation/MaxReturn                     -0.0149091
Evaluation/MinReturn                     -0.0152945
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000192696
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.2925
GaussianMLPPolicy/KL                      0.000506333
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00044841
GaussianMLPPolicy/LossBefore              0.000449135
GaussianMLPPolicy/dLoss                   7.25064e-07
GaussianMLPValueFunction/LossAfter       -5.29942
GaussianMLPValueFunction/LossBefore      -4.69875
GaussianMLPValueFunction/dLoss            0.600663
TotalEnvSteps                        293706
-----------------------------------  ----------------
2022-08-23 10:39:43 | [trpo_pendulum] epoch #147 | Saving snapshot...
2022-08-23 10:39:43 | [trpo_pendulum] epoch #147 | Saved
2022-08-23 10:39:43 | [trpo_pendulum] epoch #147 | Time 144.93 s
2022-08-23 10:39:43 | [trpo_pendulum] epoch #147 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00126988
Evaluation/AverageReturn                 -0.0147886
Evaluation/Iteration                    147
Evaluation/MaxReturn                     -0.0147231
Evaluation/MinReturn                     -0.0148542
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.55425e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.27183
GaussianMLPPolicy/KL                      0.00103307
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000289497
GaussianMLPPolicy/LossBefore             -0.000287752
GaussianMLPPolicy/dLoss                   1.74472e-06
GaussianMLPValueFunction/LossAfter       -5.60145
GaussianMLPValueFunction/LossBefore      -5.32409
GaussianMLPValueFunction/dLoss            0.277359
TotalEnvSteps                        295704
-----------------------------------  ----------------
2022-08-23 10:39:44 | [trpo_pendulum] epoch #148 | Saving snapshot...
2022-08-23 10:39:44 | [trpo_pendulum] epoch #148 | Saved
2022-08-23 10:39:44 | [trpo_pendulum] epoch #148 | Time 145.96 s
2022-08-23 10:39:44 | [trpo_pendulum] epoch #148 | EpochTime 1.02 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00121154
Evaluation/AverageReturn                 -0.0109529
Evaluation/Iteration                    148
Evaluation/MaxReturn                     -0.0105166
Evaluation/MinReturn                     -0.0113892
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000436284
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.29329
GaussianMLPPolicy/KL                      0.000651298
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000311549
GaussianMLPPolicy/LossBefore             -0.000310632
GaussianMLPPolicy/dLoss                   9.17586e-07
GaussianMLPValueFunction/LossAfter       -6.06678
GaussianMLPValueFunction/LossBefore      -5.58638
GaussianMLPValueFunction/dLoss            0.480395
TotalEnvSteps                        297702
-----------------------------------  ----------------
2022-08-23 10:39:45 | [trpo_pendulum] epoch #149 | Saving snapshot...
2022-08-23 10:39:45 | [trpo_pendulum] epoch #149 | Saved
2022-08-23 10:39:45 | [trpo_pendulum] epoch #149 | Time 146.94 s
2022-08-23 10:39:45 | [trpo_pendulum] epoch #149 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00116878
Evaluation/AverageReturn                 -0.0122607
Evaluation/Iteration                    149
Evaluation/MaxReturn                     -0.0112655
Evaluation/MinReturn                     -0.013256
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000995206
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.29357
GaussianMLPPolicy/KL                      0.000137694
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00031838
GaussianMLPPolicy/LossBefore              0.000318576
GaussianMLPPolicy/dLoss                   1.9549e-07
GaussianMLPValueFunction/LossAfter       -5.78256
GaussianMLPValueFunction/LossBefore      -5.48555
GaussianMLPValueFunction/dLoss            0.297002
TotalEnvSteps                        299700
-----------------------------------  ----------------
2022-08-23 10:39:46 | [trpo_pendulum] epoch #150 | Saving snapshot...
2022-08-23 10:39:46 | [trpo_pendulum] epoch #150 | Saved
2022-08-23 10:39:46 | [trpo_pendulum] epoch #150 | Time 147.91 s
2022-08-23 10:39:46 | [trpo_pendulum] epoch #150 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00133026
Evaluation/AverageReturn                 -0.0137425
Evaluation/Iteration                    150
Evaluation/MaxReturn                     -0.013535
Evaluation/MinReturn                     -0.01395
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000207486
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.29445
GaussianMLPPolicy/KL                      8.88769e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000381341
GaussianMLPPolicy/LossBefore              0.000381465
GaussianMLPPolicy/dLoss                   1.23866e-07
GaussianMLPValueFunction/LossAfter       -5.93362
GaussianMLPValueFunction/LossBefore      -5.05428
GaussianMLPValueFunction/dLoss            0.879339
TotalEnvSteps                        301698
-----------------------------------  ----------------
2022-08-23 10:39:47 | [trpo_pendulum] epoch #151 | Saving snapshot...
2022-08-23 10:39:47 | [trpo_pendulum] epoch #151 | Saved
2022-08-23 10:39:47 | [trpo_pendulum] epoch #151 | Time 148.92 s
2022-08-23 10:39:47 | [trpo_pendulum] epoch #151 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00120781
Evaluation/AverageReturn                 -0.0112304
Evaluation/Iteration                    151
Evaluation/MaxReturn                     -0.0110382
Evaluation/MinReturn                     -0.0114226
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000192207
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.31525
GaussianMLPPolicy/KL                      0.000440677
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000275296
GaussianMLPPolicy/LossBefore             -0.000274683
GaussianMLPPolicy/dLoss                   6.13101e-07
GaussianMLPValueFunction/LossAfter       -6.13812
GaussianMLPValueFunction/LossBefore      -5.69763
GaussianMLPValueFunction/dLoss            0.440492
TotalEnvSteps                        303696
-----------------------------------  ----------------
2022-08-23 10:39:48 | [trpo_pendulum] epoch #152 | Saving snapshot...
2022-08-23 10:39:48 | [trpo_pendulum] epoch #152 | Saved
2022-08-23 10:39:48 | [trpo_pendulum] epoch #152 | Time 149.89 s
2022-08-23 10:39:48 | [trpo_pendulum] epoch #152 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00154001
Evaluation/AverageReturn                 -0.0188124
Evaluation/Iteration                    152
Evaluation/MaxReturn                     -0.0182553
Evaluation/MinReturn                     -0.0193694
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000557078
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.33958
GaussianMLPPolicy/KL                      0.00449399
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00108957
GaussianMLPPolicy/LossBefore              0.00109655
GaussianMLPPolicy/dLoss                   6.98282e-06
GaussianMLPValueFunction/LossAfter       -4.46908
GaussianMLPValueFunction/LossBefore       3.96835
GaussianMLPValueFunction/dLoss            8.43742
TotalEnvSteps                        305694
-----------------------------------  ----------------
2022-08-23 10:39:49 | [trpo_pendulum] epoch #153 | Saving snapshot...
2022-08-23 10:39:49 | [trpo_pendulum] epoch #153 | Saved
2022-08-23 10:39:49 | [trpo_pendulum] epoch #153 | Time 150.85 s
2022-08-23 10:39:49 | [trpo_pendulum] epoch #153 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00145394
Evaluation/AverageReturn                 -0.016831
Evaluation/Iteration                    153
Evaluation/MaxReturn                     -0.0165865
Evaluation/MinReturn                     -0.0170755
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000244523
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.34478
GaussianMLPPolicy/KL                      0.000105936
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000493188
GaussianMLPPolicy/LossBefore             -0.000493027
GaussianMLPPolicy/dLoss                   1.61061e-07
GaussianMLPValueFunction/LossAfter       -5.35499
GaussianMLPValueFunction/LossBefore      -4.25602
GaussianMLPValueFunction/dLoss            1.09898
TotalEnvSteps                        307692
-----------------------------------  ----------------
2022-08-23 10:39:50 | [trpo_pendulum] epoch #154 | Saving snapshot...
2022-08-23 10:39:50 | [trpo_pendulum] epoch #154 | Saved
2022-08-23 10:39:50 | [trpo_pendulum] epoch #154 | Time 151.87 s
2022-08-23 10:39:50 | [trpo_pendulum] epoch #154 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00121292
Evaluation/AverageReturn                 -0.0112851
Evaluation/Iteration                    154
Evaluation/MaxReturn                     -0.0111147
Evaluation/MinReturn                     -0.0114555
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000170373
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.36285
GaussianMLPPolicy/KL                      0.000611111
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000815565
GaussianMLPPolicy/LossBefore             -0.000814735
GaussianMLPPolicy/dLoss                   8.30041e-07
GaussianMLPValueFunction/LossAfter       -6.10388
GaussianMLPValueFunction/LossBefore      -2.42474
GaussianMLPValueFunction/dLoss            3.67914
TotalEnvSteps                        309690
-----------------------------------  ----------------
2022-08-23 10:39:51 | [trpo_pendulum] epoch #155 | Saving snapshot...
2022-08-23 10:39:51 | [trpo_pendulum] epoch #155 | Saved
2022-08-23 10:39:51 | [trpo_pendulum] epoch #155 | Time 152.82 s
2022-08-23 10:39:51 | [trpo_pendulum] epoch #155 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0013932
Evaluation/AverageReturn                 -0.01302
Evaluation/Iteration                    155
Evaluation/MaxReturn                     -0.01294
Evaluation/MinReturn                     -0.0130999
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.99342e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.36285
GaussianMLPPolicy/KL                      0.000366244
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000152275
GaussianMLPPolicy/LossBefore              0.000152802
GaussianMLPPolicy/dLoss                   5.27012e-07
GaussianMLPValueFunction/LossAfter       -6.05256
GaussianMLPValueFunction/LossBefore      -5.91725
GaussianMLPValueFunction/dLoss            0.135307
TotalEnvSteps                        311688
-----------------------------------  ----------------
2022-08-23 10:39:52 | [trpo_pendulum] epoch #156 | Saving snapshot...
2022-08-23 10:39:52 | [trpo_pendulum] epoch #156 | Saved
2022-08-23 10:39:52 | [trpo_pendulum] epoch #156 | Time 153.80 s
2022-08-23 10:39:52 | [trpo_pendulum] epoch #156 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00128467
Evaluation/AverageReturn                 -0.0144631
Evaluation/Iteration                    156
Evaluation/MaxReturn                     -0.0142986
Evaluation/MinReturn                     -0.0146276
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000164484
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.38224
GaussianMLPPolicy/KL                      0.000947243
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00028988
GaussianMLPPolicy/LossBefore              0.000291294
GaussianMLPPolicy/dLoss                   1.4143e-06
GaussianMLPValueFunction/LossAfter       -5.60781
GaussianMLPValueFunction/LossBefore      -5.1749
GaussianMLPValueFunction/dLoss            0.432909
TotalEnvSteps                        313686
-----------------------------------  ----------------
2022-08-23 10:39:53 | [trpo_pendulum] epoch #157 | Saving snapshot...
2022-08-23 10:39:53 | [trpo_pendulum] epoch #157 | Saved
2022-08-23 10:39:53 | [trpo_pendulum] epoch #157 | Time 154.89 s
2022-08-23 10:39:53 | [trpo_pendulum] epoch #157 | EpochTime 1.09 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00145884
Evaluation/AverageReturn                 -0.0183183
Evaluation/Iteration                    157
Evaluation/MaxReturn                     -0.0183039
Evaluation/MinReturn                     -0.0183328
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.44263e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.37533
GaussianMLPPolicy/KL                      0.00916547
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000228332
GaussianMLPPolicy/LossBefore              0.000237014
GaussianMLPPolicy/dLoss                   8.68125e-06
GaussianMLPValueFunction/LossAfter       -5.05471
GaussianMLPValueFunction/LossBefore      -4.52167
GaussianMLPValueFunction/dLoss            0.533047
TotalEnvSteps                        315684
-----------------------------------  ----------------
2022-08-23 10:39:54 | [trpo_pendulum] epoch #158 | Saving snapshot...
2022-08-23 10:39:54 | [trpo_pendulum] epoch #158 | Saved
2022-08-23 10:39:54 | [trpo_pendulum] epoch #158 | Time 155.88 s
2022-08-23 10:39:54 | [trpo_pendulum] epoch #158 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00115766
Evaluation/AverageReturn                 -0.0115969
Evaluation/Iteration                    158
Evaluation/MaxReturn                     -0.0109355
Evaluation/MinReturn                     -0.0122583
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000661433
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.35575
GaussianMLPPolicy/KL                      0.000386094
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000784103
GaussianMLPPolicy/LossBefore             -0.000783525
GaussianMLPPolicy/dLoss                   5.78526e-07
GaussianMLPValueFunction/LossAfter       -5.88092
GaussianMLPValueFunction/LossBefore      -2.98498
GaussianMLPValueFunction/dLoss            2.89594
TotalEnvSteps                        317682
-----------------------------------  ----------------
2022-08-23 10:39:55 | [trpo_pendulum] epoch #159 | Saving snapshot...
2022-08-23 10:39:55 | [trpo_pendulum] epoch #159 | Saved
2022-08-23 10:39:55 | [trpo_pendulum] epoch #159 | Time 156.86 s
2022-08-23 10:39:55 | [trpo_pendulum] epoch #159 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0011951
Evaluation/AverageReturn                 -0.0136712
Evaluation/Iteration                    159
Evaluation/MaxReturn                     -0.0133128
Evaluation/MinReturn                     -0.0140297
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000358482
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.37029
GaussianMLPPolicy/KL                      0.000613947
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               3.70386e-05
GaussianMLPPolicy/LossBefore              3.79033e-05
GaussianMLPPolicy/dLoss                   8.64737e-07
GaussianMLPValueFunction/LossAfter       -6.03713
GaussianMLPValueFunction/LossBefore      -6.00129
GaussianMLPValueFunction/dLoss            0.0358434
TotalEnvSteps                        319680
-----------------------------------  ----------------
2022-08-23 10:39:56 | [trpo_pendulum] epoch #160 | Saving snapshot...
2022-08-23 10:39:56 | [trpo_pendulum] epoch #160 | Saved
2022-08-23 10:39:56 | [trpo_pendulum] epoch #160 | Time 157.81 s
2022-08-23 10:39:56 | [trpo_pendulum] epoch #160 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00102105
Evaluation/AverageReturn                 -0.0105412
Evaluation/Iteration                    160
Evaluation/MaxReturn                     -0.0103325
Evaluation/MinReturn                     -0.01075
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000208784
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.38248
GaussianMLPPolicy/KL                      0.000399557
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000277126
GaussianMLPPolicy/LossBefore             -0.000276566
GaussianMLPPolicy/dLoss                   5.59812e-07
GaussianMLPValueFunction/LossAfter       -5.7131
GaussianMLPValueFunction/LossBefore      -5.6951
GaussianMLPValueFunction/dLoss            0.0180006
TotalEnvSteps                        321678
-----------------------------------  ----------------
2022-08-23 10:39:57 | [trpo_pendulum] epoch #161 | Saving snapshot...
2022-08-23 10:39:57 | [trpo_pendulum] epoch #161 | Saved
2022-08-23 10:39:57 | [trpo_pendulum] epoch #161 | Time 158.82 s
2022-08-23 10:39:57 | [trpo_pendulum] epoch #161 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00112652
Evaluation/AverageReturn                 -0.0106914
Evaluation/Iteration                    161
Evaluation/MaxReturn                     -0.0104272
Evaluation/MinReturn                     -0.0109555
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000264131
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.40162
GaussianMLPPolicy/KL                      0.000505057
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00025706
GaussianMLPPolicy/LossBefore             -0.00025635
GaussianMLPPolicy/dLoss                   7.09842e-07
GaussianMLPValueFunction/LossAfter       -5.70715
GaussianMLPValueFunction/LossBefore      -5.74584
GaussianMLPValueFunction/dLoss           -0.0386982
TotalEnvSteps                        323676
-----------------------------------  ----------------
2022-08-23 10:39:58 | [trpo_pendulum] epoch #162 | Saving snapshot...
2022-08-23 10:39:58 | [trpo_pendulum] epoch #162 | Saved
2022-08-23 10:39:58 | [trpo_pendulum] epoch #162 | Time 159.86 s
2022-08-23 10:39:58 | [trpo_pendulum] epoch #162 | EpochTime 1.03 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00104958
Evaluation/AverageReturn                 -0.0113501
Evaluation/Iteration                    162
Evaluation/MaxReturn                     -0.0111718
Evaluation/MinReturn                     -0.0115283
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000178218
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.41183
GaussianMLPPolicy/KL                      0.00020308
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000125533
GaussianMLPPolicy/LossBefore             -0.00012524
GaussianMLPPolicy/dLoss                   2.92392e-07
GaussianMLPValueFunction/LossAfter       -5.71517
GaussianMLPValueFunction/LossBefore      -6.03902
GaussianMLPValueFunction/dLoss           -0.32385
TotalEnvSteps                        325674
-----------------------------------  ----------------
2022-08-23 10:39:59 | [trpo_pendulum] epoch #163 | Saving snapshot...
2022-08-23 10:39:59 | [trpo_pendulum] epoch #163 | Saved
2022-08-23 10:39:59 | [trpo_pendulum] epoch #163 | Time 160.83 s
2022-08-23 10:39:59 | [trpo_pendulum] epoch #163 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00114589
Evaluation/AverageReturn                 -0.0126476
Evaluation/Iteration                    163
Evaluation/MaxReturn                     -0.0125399
Evaluation/MinReturn                     -0.0127554
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00010774
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.42307
GaussianMLPPolicy/KL                      0.000218773
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000400489
GaussianMLPPolicy/LossBefore              0.000400817
GaussianMLPPolicy/dLoss                   3.28233e-07
GaussianMLPValueFunction/LossAfter       -5.97714
GaussianMLPValueFunction/LossBefore      -4.98506
GaussianMLPValueFunction/dLoss            0.992085
TotalEnvSteps                        327672
-----------------------------------  ----------------
2022-08-23 10:40:00 | [trpo_pendulum] epoch #164 | Saving snapshot...
2022-08-23 10:40:00 | [trpo_pendulum] epoch #164 | Saved
2022-08-23 10:40:00 | [trpo_pendulum] epoch #164 | Time 161.79 s
2022-08-23 10:40:00 | [trpo_pendulum] epoch #164 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000961881
Evaluation/AverageReturn                 -0.0100909
Evaluation/Iteration                    164
Evaluation/MaxReturn                     -0.00958476
Evaluation/MinReturn                     -0.0105971
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000506163
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.43906
GaussianMLPPolicy/KL                      0.000313739
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000382009
GaussianMLPPolicy/LossBefore             -0.000381582
GaussianMLPPolicy/dLoss                   4.26866e-07
GaussianMLPValueFunction/LossAfter       -6.11455
GaussianMLPValueFunction/LossBefore      -5.26298
GaussianMLPValueFunction/dLoss            0.851571
TotalEnvSteps                        329670
-----------------------------------  ----------------
2022-08-23 10:40:01 | [trpo_pendulum] epoch #165 | Saving snapshot...
2022-08-23 10:40:01 | [trpo_pendulum] epoch #165 | Saved
2022-08-23 10:40:01 | [trpo_pendulum] epoch #165 | Time 162.71 s
2022-08-23 10:40:01 | [trpo_pendulum] epoch #165 | EpochTime 0.92 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000959517
Evaluation/AverageReturn                 -0.0104411
Evaluation/Iteration                    165
Evaluation/MaxReturn                     -0.0102626
Evaluation/MinReturn                     -0.0106197
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000178541
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.4516
GaussianMLPPolicy/KL                      0.000232788
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000110035
GaussianMLPPolicy/LossBefore             -0.000109711
GaussianMLPPolicy/dLoss                   3.24952e-07
GaussianMLPValueFunction/LossAfter       -6.20779
GaussianMLPValueFunction/LossBefore      -6.14223
GaussianMLPValueFunction/dLoss            0.0655608
TotalEnvSteps                        331668
-----------------------------------  ----------------
2022-08-23 10:40:02 | [trpo_pendulum] epoch #166 | Saving snapshot...
2022-08-23 10:40:02 | [trpo_pendulum] epoch #166 | Saved
2022-08-23 10:40:02 | [trpo_pendulum] epoch #166 | Time 163.66 s
2022-08-23 10:40:02 | [trpo_pendulum] epoch #166 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000928372
Evaluation/AverageReturn                 -0.00947499
Evaluation/Iteration                    166
Evaluation/MaxReturn                     -0.00941755
Evaluation/MinReturn                     -0.00953244
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.74423e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.4516
GaussianMLPPolicy/KL                      0.00011767
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               3.74732e-05
GaussianMLPPolicy/LossBefore              3.76403e-05
GaussianMLPPolicy/dLoss                   1.671e-07
GaussianMLPValueFunction/LossAfter       -6.30678
GaussianMLPValueFunction/LossBefore      -6.26164
GaussianMLPValueFunction/dLoss            0.0451412
TotalEnvSteps                        333666
-----------------------------------  ----------------
2022-08-23 10:40:03 | [trpo_pendulum] epoch #167 | Saving snapshot...
2022-08-23 10:40:03 | [trpo_pendulum] epoch #167 | Saved
2022-08-23 10:40:03 | [trpo_pendulum] epoch #167 | Time 164.67 s
2022-08-23 10:40:03 | [trpo_pendulum] epoch #167 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0014112
Evaluation/AverageReturn                 -0.0165307
Evaluation/Iteration                    167
Evaluation/MaxReturn                     -0.0161825
Evaluation/MinReturn                     -0.016879
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000348227
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.4265
GaussianMLPPolicy/KL                      0.00326246
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000905335
GaussianMLPPolicy/LossBefore              0.000911596
GaussianMLPPolicy/dLoss                   6.26122e-06
GaussianMLPValueFunction/LossAfter       -4.54956
GaussianMLPValueFunction/LossBefore       2.5826
GaussianMLPValueFunction/dLoss            7.13216
TotalEnvSteps                        335664
-----------------------------------  ----------------
2022-08-23 10:40:04 | [trpo_pendulum] epoch #168 | Saving snapshot...
2022-08-23 10:40:04 | [trpo_pendulum] epoch #168 | Saved
2022-08-23 10:40:04 | [trpo_pendulum] epoch #168 | Time 165.67 s
2022-08-23 10:40:04 | [trpo_pendulum] epoch #168 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00087003
Evaluation/AverageReturn                 -0.00922675
Evaluation/Iteration                    168
Evaluation/MaxReturn                     -0.0092069
Evaluation/MinReturn                     -0.0092466
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.98484e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.40764
GaussianMLPPolicy/KL                      0.00139261
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000853694
GaussianMLPPolicy/LossBefore             -0.00085132
GaussianMLPPolicy/dLoss                   2.37458e-06
GaussianMLPValueFunction/LossAfter       -6.238
GaussianMLPValueFunction/LossBefore      -1.22284
GaussianMLPValueFunction/dLoss            5.01515
TotalEnvSteps                        337662
-----------------------------------  ----------------
2022-08-23 10:40:05 | [trpo_pendulum] epoch #169 | Saving snapshot...
2022-08-23 10:40:05 | [trpo_pendulum] epoch #169 | Saved
2022-08-23 10:40:05 | [trpo_pendulum] epoch #169 | Time 166.69 s
2022-08-23 10:40:05 | [trpo_pendulum] epoch #169 | EpochTime 1.02 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00111333
Evaluation/AverageReturn                 -0.0120255
Evaluation/Iteration                    169
Evaluation/MaxReturn                     -0.0116589
Evaluation/MinReturn                     -0.012392
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00036654
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.42102
GaussianMLPPolicy/KL                      0.000992099
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000305775
GaussianMLPPolicy/LossBefore              0.000307189
GaussianMLPPolicy/dLoss                   1.41404e-06
GaussianMLPValueFunction/LossAfter       -6.1208
GaussianMLPValueFunction/LossBefore      -5.45273
GaussianMLPValueFunction/dLoss            0.668071
TotalEnvSteps                        339660
-----------------------------------  ----------------
2022-08-23 10:40:06 | [trpo_pendulum] epoch #170 | Saving snapshot...
2022-08-23 10:40:06 | [trpo_pendulum] epoch #170 | Saved
2022-08-23 10:40:06 | [trpo_pendulum] epoch #170 | Time 167.68 s
2022-08-23 10:40:06 | [trpo_pendulum] epoch #170 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0010163
Evaluation/AverageReturn                 -0.0101243
Evaluation/Iteration                    170
Evaluation/MaxReturn                     -0.0100423
Evaluation/MinReturn                     -0.0102062
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.19779e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.43664
GaussianMLPPolicy/KL                      0.000384666
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -8.38491e-05
GaussianMLPPolicy/LossBefore             -8.32947e-05
GaussianMLPPolicy/dLoss                   5.54392e-07
GaussianMLPValueFunction/LossAfter       -5.6138
GaussianMLPValueFunction/LossBefore      -6.1597
GaussianMLPValueFunction/dLoss           -0.545897
TotalEnvSteps                        341658
-----------------------------------  ----------------
2022-08-23 10:40:07 | [trpo_pendulum] epoch #171 | Saving snapshot...
2022-08-23 10:40:07 | [trpo_pendulum] epoch #171 | Saved
2022-08-23 10:40:07 | [trpo_pendulum] epoch #171 | Time 168.68 s
2022-08-23 10:40:07 | [trpo_pendulum] epoch #171 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00121605
Evaluation/AverageReturn                 -0.0131632
Evaluation/Iteration                    171
Evaluation/MaxReturn                     -0.0131349
Evaluation/MinReturn                     -0.0131915
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.83091e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.42264
GaussianMLPPolicy/KL                      0.00343948
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000659771
GaussianMLPPolicy/LossBefore              0.000666335
GaussianMLPPolicy/dLoss                   6.56408e-06
GaussianMLPValueFunction/LossAfter       -5.67847
GaussianMLPValueFunction/LossBefore      -2.38788
GaussianMLPValueFunction/dLoss            3.29059
TotalEnvSteps                        343656
-----------------------------------  ----------------
2022-08-23 10:40:08 | [trpo_pendulum] epoch #172 | Saving snapshot...
2022-08-23 10:40:08 | [trpo_pendulum] epoch #172 | Saved
2022-08-23 10:40:08 | [trpo_pendulum] epoch #172 | Time 169.67 s
2022-08-23 10:40:08 | [trpo_pendulum] epoch #172 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00124441
Evaluation/AverageReturn                 -0.0156411
Evaluation/Iteration                    172
Evaluation/MaxReturn                     -0.0149149
Evaluation/MinReturn                     -0.0163674
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000726231
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.46422
GaussianMLPPolicy/KL                      0.00373811
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000372829
GaussianMLPPolicy/LossBefore              0.000377865
GaussianMLPPolicy/dLoss                   5.03554e-06
GaussianMLPValueFunction/LossAfter       -4.92297
GaussianMLPValueFunction/LossBefore      -3.58351
GaussianMLPValueFunction/dLoss            1.33947
TotalEnvSteps                        345654
-----------------------------------  ----------------
2022-08-23 10:40:09 | [trpo_pendulum] epoch #173 | Saving snapshot...
2022-08-23 10:40:09 | [trpo_pendulum] epoch #173 | Saved
2022-08-23 10:40:09 | [trpo_pendulum] epoch #173 | Time 170.68 s
2022-08-23 10:40:09 | [trpo_pendulum] epoch #173 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000948812
Evaluation/AverageReturn                 -0.00980453
Evaluation/Iteration                    173
Evaluation/MaxReturn                     -0.00931416
Evaluation/MinReturn                     -0.0102949
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000490371
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.47746
GaussianMLPPolicy/KL                      0.000984968
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000652353
GaussianMLPPolicy/LossBefore             -0.000650955
GaussianMLPPolicy/dLoss                   1.39768e-06
GaussianMLPValueFunction/LossAfter       -6.15047
GaussianMLPValueFunction/LossBefore      -3.53267
GaussianMLPValueFunction/dLoss            2.6178
TotalEnvSteps                        347652
-----------------------------------  ----------------
2022-08-23 10:40:10 | [trpo_pendulum] epoch #174 | Saving snapshot...
2022-08-23 10:40:10 | [trpo_pendulum] epoch #174 | Saved
2022-08-23 10:40:10 | [trpo_pendulum] epoch #174 | Time 171.68 s
2022-08-23 10:40:10 | [trpo_pendulum] epoch #174 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00102634
Evaluation/AverageReturn                 -0.0108046
Evaluation/Iteration                    174
Evaluation/MaxReturn                     -0.010482
Evaluation/MinReturn                     -0.0111272
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000322605
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.47871
GaussianMLPPolicy/KL                      0.000881843
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000213896
GaussianMLPPolicy/LossBefore              0.000214839
GaussianMLPPolicy/dLoss                   9.43401e-07
GaussianMLPValueFunction/LossAfter       -5.87492
GaussianMLPValueFunction/LossBefore      -5.60625
GaussianMLPValueFunction/dLoss            0.268667
TotalEnvSteps                        349650
-----------------------------------  ----------------
2022-08-23 10:40:11 | [trpo_pendulum] epoch #175 | Saving snapshot...
2022-08-23 10:40:11 | [trpo_pendulum] epoch #175 | Saved
2022-08-23 10:40:11 | [trpo_pendulum] epoch #175 | Time 172.69 s
2022-08-23 10:40:11 | [trpo_pendulum] epoch #175 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000846169
Evaluation/AverageReturn                 -0.0095656
Evaluation/Iteration                    175
Evaluation/MaxReturn                     -0.00928962
Evaluation/MinReturn                     -0.00984158
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000275977
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.496
GaussianMLPPolicy/KL                      0.000832009
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000330412
GaussianMLPPolicy/LossBefore             -0.000329252
GaussianMLPPolicy/dLoss                   1.15921e-06
GaussianMLPValueFunction/LossAfter       -6.12237
GaussianMLPValueFunction/LossBefore      -5.49545
GaussianMLPValueFunction/dLoss            0.626918
TotalEnvSteps                        351648
-----------------------------------  ----------------
2022-08-23 10:40:12 | [trpo_pendulum] epoch #176 | Saving snapshot...
2022-08-23 10:40:12 | [trpo_pendulum] epoch #176 | Saved
2022-08-23 10:40:12 | [trpo_pendulum] epoch #176 | Time 173.67 s
2022-08-23 10:40:12 | [trpo_pendulum] epoch #176 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000849853
Evaluation/AverageReturn                 -0.00844753
Evaluation/Iteration                    176
Evaluation/MaxReturn                     -0.00825418
Evaluation/MinReturn                     -0.00864089
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000193357
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.496
GaussianMLPPolicy/KL                      0.000138925
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -2.61251e-05
GaussianMLPPolicy/LossBefore             -2.59284e-05
GaussianMLPPolicy/dLoss                   1.96695e-07
GaussianMLPValueFunction/LossAfter       -5.44147
GaussianMLPValueFunction/LossBefore      -6.21367
GaussianMLPValueFunction/dLoss           -0.772209
TotalEnvSteps                        353646
-----------------------------------  ----------------
2022-08-23 10:40:13 | [trpo_pendulum] epoch #177 | Saving snapshot...
2022-08-23 10:40:13 | [trpo_pendulum] epoch #177 | Saved
2022-08-23 10:40:13 | [trpo_pendulum] epoch #177 | Time 174.62 s
2022-08-23 10:40:13 | [trpo_pendulum] epoch #177 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000779877
Evaluation/AverageReturn                 -0.00835389
Evaluation/Iteration                    177
Evaluation/MaxReturn                     -0.008102
Evaluation/MinReturn                     -0.00860578
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00025189
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.496
GaussianMLPPolicy/KL                      5.57979e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000343679
GaussianMLPPolicy/LossBefore             -0.0003436
GaussianMLPPolicy/dLoss                   7.86677e-08
GaussianMLPValueFunction/LossAfter       -6.26666
GaussianMLPValueFunction/LossBefore      -5.42913
GaussianMLPValueFunction/dLoss            0.837526
TotalEnvSteps                        355644
-----------------------------------  ----------------
2022-08-23 10:40:14 | [trpo_pendulum] epoch #178 | Saving snapshot...
2022-08-23 10:40:14 | [trpo_pendulum] epoch #178 | Saved
2022-08-23 10:40:14 | [trpo_pendulum] epoch #178 | Time 175.62 s
2022-08-23 10:40:14 | [trpo_pendulum] epoch #178 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000920672
Evaluation/AverageReturn                 -0.00979122
Evaluation/Iteration                    178
Evaluation/MaxReturn                     -0.00966966
Evaluation/MinReturn                     -0.00991278
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000121562
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.5076
GaussianMLPPolicy/KL                      0.000906292
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00013454
GaussianMLPPolicy/LossBefore              0.000135815
GaussianMLPPolicy/dLoss                   1.27534e-06
GaussianMLPValueFunction/LossAfter       -6.13365
GaussianMLPValueFunction/LossBefore      -6.07797
GaussianMLPValueFunction/dLoss            0.0556798
TotalEnvSteps                        357642
-----------------------------------  ----------------
2022-08-23 10:40:15 | [trpo_pendulum] epoch #179 | Saving snapshot...
2022-08-23 10:40:15 | [trpo_pendulum] epoch #179 | Saved
2022-08-23 10:40:15 | [trpo_pendulum] epoch #179 | Time 176.61 s
2022-08-23 10:40:15 | [trpo_pendulum] epoch #179 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000743932
Evaluation/AverageReturn                 -0.00807596
Evaluation/Iteration                    179
Evaluation/MaxReturn                     -0.0076998
Evaluation/MinReturn                     -0.00845213
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000376167
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.5076
GaussianMLPPolicy/KL                      1.57229e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -5.75026e-07
GaussianMLPPolicy/LossBefore             -5.52886e-07
GaussianMLPPolicy/dLoss                   2.21393e-08
GaussianMLPValueFunction/LossAfter       -5.9365
GaussianMLPValueFunction/LossBefore      -6.27611
GaussianMLPValueFunction/dLoss           -0.339611
TotalEnvSteps                        359640
-----------------------------------  ----------------
2022-08-23 10:40:16 | [trpo_pendulum] epoch #180 | Saving snapshot...
2022-08-23 10:40:16 | [trpo_pendulum] epoch #180 | Saved
2022-08-23 10:40:16 | [trpo_pendulum] epoch #180 | Time 177.59 s
2022-08-23 10:40:16 | [trpo_pendulum] epoch #180 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000795148
Evaluation/AverageReturn                 -0.00831162
Evaluation/Iteration                    180
Evaluation/MaxReturn                     -0.00791752
Evaluation/MinReturn                     -0.00870572
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000394104
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.52108
GaussianMLPPolicy/KL                      0.000248821
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000190846
GaussianMLPPolicy/LossBefore              0.000191197
GaussianMLPPolicy/dLoss                   3.514e-07
GaussianMLPValueFunction/LossAfter       -6.297
GaussianMLPValueFunction/LossBefore      -6.02184
GaussianMLPValueFunction/dLoss            0.275155
TotalEnvSteps                        361638
-----------------------------------  ----------------
2022-08-23 10:40:17 | [trpo_pendulum] epoch #181 | Saving snapshot...
2022-08-23 10:40:17 | [trpo_pendulum] epoch #181 | Saved
2022-08-23 10:40:17 | [trpo_pendulum] epoch #181 | Time 178.57 s
2022-08-23 10:40:17 | [trpo_pendulum] epoch #181 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000683914
Evaluation/AverageReturn                 -0.00716446
Evaluation/Iteration                    181
Evaluation/MaxReturn                     -0.00712761
Evaluation/MinReturn                     -0.00720132
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.68518e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.53015
GaussianMLPPolicy/KL                      0.000301179
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000123224
GaussianMLPPolicy/LossBefore             -0.000122788
GaussianMLPPolicy/dLoss                   4.36165e-07
GaussianMLPValueFunction/LossAfter       -5.82754
GaussianMLPValueFunction/LossBefore      -6.21309
GaussianMLPValueFunction/dLoss           -0.385549
TotalEnvSteps                        363636
-----------------------------------  ----------------
2022-08-23 10:40:18 | [trpo_pendulum] epoch #182 | Saving snapshot...
2022-08-23 10:40:18 | [trpo_pendulum] epoch #182 | Saved
2022-08-23 10:40:18 | [trpo_pendulum] epoch #182 | Time 179.67 s
2022-08-23 10:40:18 | [trpo_pendulum] epoch #182 | EpochTime 1.09 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000891779
Evaluation/AverageReturn                 -0.0100331
Evaluation/Iteration                    182
Evaluation/MaxReturn                     -0.00994086
Evaluation/MinReturn                     -0.0101254
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      9.228e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.53015
GaussianMLPPolicy/KL                      8.68708e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000117493
GaussianMLPPolicy/LossBefore              0.000117616
GaussianMLPPolicy/dLoss                   1.2292e-07
GaussianMLPValueFunction/LossAfter       -5.77628
GaussianMLPValueFunction/LossBefore      -5.85691
GaussianMLPValueFunction/dLoss           -0.080626
TotalEnvSteps                        365634
-----------------------------------  ----------------
2022-08-23 10:40:19 | [trpo_pendulum] epoch #183 | Saving snapshot...
2022-08-23 10:40:19 | [trpo_pendulum] epoch #183 | Saved
2022-08-23 10:40:19 | [trpo_pendulum] epoch #183 | Time 180.71 s
2022-08-23 10:40:19 | [trpo_pendulum] epoch #183 | EpochTime 1.04 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000778804
Evaluation/AverageReturn                 -0.00815118
Evaluation/Iteration                    183
Evaluation/MaxReturn                     -0.00790758
Evaluation/MinReturn                     -0.00839477
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000243595
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.53373
GaussianMLPPolicy/KL                      0.00987555
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000461907
GaussianMLPPolicy/LossBefore             -0.000461437
GaussianMLPPolicy/dLoss                   4.7058e-07
GaussianMLPValueFunction/LossAfter       -6.24485
GaussianMLPValueFunction/LossBefore      -4.58296
GaussianMLPValueFunction/dLoss            1.66188
TotalEnvSteps                        367632
-----------------------------------  ----------------
2022-08-23 10:40:20 | [trpo_pendulum] epoch #184 | Saving snapshot...
2022-08-23 10:40:20 | [trpo_pendulum] epoch #184 | Saved
2022-08-23 10:40:20 | [trpo_pendulum] epoch #184 | Time 181.70 s
2022-08-23 10:40:20 | [trpo_pendulum] epoch #184 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000821905
Evaluation/AverageReturn                 -0.00824152
Evaluation/Iteration                    184
Evaluation/MaxReturn                     -0.00802842
Evaluation/MinReturn                     -0.00845461
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000213095
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.54258
GaussianMLPPolicy/KL                      0.000152643
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               5.27031e-05
GaussianMLPPolicy/LossBefore              5.29173e-05
GaussianMLPPolicy/dLoss                   2.14182e-07
GaussianMLPValueFunction/LossAfter       -4.81298
GaussianMLPValueFunction/LossBefore      -6.31311
GaussianMLPValueFunction/dLoss           -1.50013
TotalEnvSteps                        369630
-----------------------------------  ----------------
2022-08-23 10:40:21 | [trpo_pendulum] epoch #185 | Saving snapshot...
2022-08-23 10:40:21 | [trpo_pendulum] epoch #185 | Saved
2022-08-23 10:40:21 | [trpo_pendulum] epoch #185 | Time 182.66 s
2022-08-23 10:40:21 | [trpo_pendulum] epoch #185 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000924379
Evaluation/AverageReturn                 -0.00879134
Evaluation/Iteration                    185
Evaluation/MaxReturn                     -0.00857645
Evaluation/MinReturn                     -0.00900622
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000214882
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.5415
GaussianMLPPolicy/KL                      0.000175337
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00053408
GaussianMLPPolicy/LossBefore              0.000534325
GaussianMLPPolicy/dLoss                   2.4488e-07
GaussianMLPValueFunction/LossAfter       -6.33131
GaussianMLPValueFunction/LossBefore      -3.77431
GaussianMLPValueFunction/dLoss            2.557
TotalEnvSteps                        371628
-----------------------------------  ----------------
2022-08-23 10:40:22 | [trpo_pendulum] epoch #186 | Saving snapshot...
2022-08-23 10:40:22 | [trpo_pendulum] epoch #186 | Saved
2022-08-23 10:40:22 | [trpo_pendulum] epoch #186 | Time 183.63 s
2022-08-23 10:40:22 | [trpo_pendulum] epoch #186 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000975234
Evaluation/AverageReturn                 -0.010437
Evaluation/Iteration                    186
Evaluation/MaxReturn                     -0.0103224
Evaluation/MinReturn                     -0.0105516
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000114597
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.55039
GaussianMLPPolicy/KL                      9.73821e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000142442
GaussianMLPPolicy/LossBefore              0.000142579
GaussianMLPPolicy/dLoss                   1.36657e-07
GaussianMLPValueFunction/LossAfter       -5.91065
GaussianMLPValueFunction/LossBefore      -5.95916
GaussianMLPValueFunction/dLoss           -0.0485115
TotalEnvSteps                        373626
-----------------------------------  ----------------
2022-08-23 10:40:23 | [trpo_pendulum] epoch #187 | Saving snapshot...
2022-08-23 10:40:23 | [trpo_pendulum] epoch #187 | Saved
2022-08-23 10:40:23 | [trpo_pendulum] epoch #187 | Time 184.59 s
2022-08-23 10:40:23 | [trpo_pendulum] epoch #187 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000858342
Evaluation/AverageReturn                 -0.00840724
Evaluation/Iteration                    187
Evaluation/MaxReturn                     -0.00816253
Evaluation/MinReturn                     -0.00865195
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00024471
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.57731
GaussianMLPPolicy/KL                      0.000823449
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000460293
GaussianMLPPolicy/LossBefore             -0.000459137
GaussianMLPPolicy/dLoss                   1.15662e-06
GaussianMLPValueFunction/LossAfter       -6.30899
GaussianMLPValueFunction/LossBefore      -4.45026
GaussianMLPValueFunction/dLoss            1.85872
TotalEnvSteps                        375624
-----------------------------------  ----------------
2022-08-23 10:40:24 | [trpo_pendulum] epoch #188 | Saving snapshot...
2022-08-23 10:40:24 | [trpo_pendulum] epoch #188 | Saved
2022-08-23 10:40:24 | [trpo_pendulum] epoch #188 | Time 185.59 s
2022-08-23 10:40:24 | [trpo_pendulum] epoch #188 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000874208
Evaluation/AverageReturn                 -0.00886437
Evaluation/Iteration                    188
Evaluation/MaxReturn                     -0.0086116
Evaluation/MinReturn                     -0.00911714
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000252766
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.57731
GaussianMLPPolicy/KL                      0.000116786
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000196959
GaussianMLPPolicy/LossBefore              0.000197126
GaussianMLPPolicy/dLoss                   1.66794e-07
GaussianMLPValueFunction/LossAfter       -5.73504
GaussianMLPValueFunction/LossBefore      -5.99882
GaussianMLPValueFunction/dLoss           -0.263775
TotalEnvSteps                        377622
-----------------------------------  ----------------
2022-08-23 10:40:25 | [trpo_pendulum] epoch #189 | Saving snapshot...
2022-08-23 10:40:25 | [trpo_pendulum] epoch #189 | Saved
2022-08-23 10:40:25 | [trpo_pendulum] epoch #189 | Time 186.58 s
2022-08-23 10:40:25 | [trpo_pendulum] epoch #189 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000937643
Evaluation/AverageReturn                 -0.00954559
Evaluation/Iteration                    189
Evaluation/MaxReturn                     -0.0094197
Evaluation/MinReturn                     -0.00967147
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000125883
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.57713
GaussianMLPPolicy/KL                      0.000226048
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000339936
GaussianMLPPolicy/LossBefore              0.000340261
GaussianMLPPolicy/dLoss                   3.25672e-07
GaussianMLPValueFunction/LossAfter       -6.17323
GaussianMLPValueFunction/LossBefore      -5.15828
GaussianMLPValueFunction/dLoss            1.01496
TotalEnvSteps                        379620
-----------------------------------  ----------------
2022-08-23 10:40:26 | [trpo_pendulum] epoch #190 | Saving snapshot...
2022-08-23 10:40:26 | [trpo_pendulum] epoch #190 | Saved
2022-08-23 10:40:26 | [trpo_pendulum] epoch #190 | Time 187.55 s
2022-08-23 10:40:26 | [trpo_pendulum] epoch #190 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00093767
Evaluation/AverageReturn                 -0.00970529
Evaluation/Iteration                    190
Evaluation/MaxReturn                     -0.00944813
Evaluation/MinReturn                     -0.00996244
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000257153
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.58303
GaussianMLPPolicy/KL                      0.000886504
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000196133
GaussianMLPPolicy/LossBefore              0.000197265
GaussianMLPPolicy/dLoss                   1.13249e-06
GaussianMLPValueFunction/LossAfter       -5.82589
GaussianMLPValueFunction/LossBefore      -5.805
GaussianMLPValueFunction/dLoss            0.0208812
TotalEnvSteps                        381618
-----------------------------------  ----------------
2022-08-23 10:40:27 | [trpo_pendulum] epoch #191 | Saving snapshot...
2022-08-23 10:40:27 | [trpo_pendulum] epoch #191 | Saved
2022-08-23 10:40:27 | [trpo_pendulum] epoch #191 | Time 188.48 s
2022-08-23 10:40:27 | [trpo_pendulum] epoch #191 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00081446
Evaluation/AverageReturn                 -0.00837654
Evaluation/Iteration                    191
Evaluation/MaxReturn                     -0.0078556
Evaluation/MinReturn                     -0.00889748
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000520938
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.59196
GaussianMLPPolicy/KL                      0.000263455
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               4.54297e-06
GaussianMLPPolicy/LossBefore              4.91591e-06
GaussianMLPPolicy/dLoss                   3.72934e-07
GaussianMLPValueFunction/LossAfter       -6.34199
GaussianMLPValueFunction/LossBefore      -6.36172
GaussianMLPValueFunction/dLoss           -0.0197272
TotalEnvSteps                        383616
-----------------------------------  ----------------
2022-08-23 10:40:28 | [trpo_pendulum] epoch #192 | Saving snapshot...
2022-08-23 10:40:28 | [trpo_pendulum] epoch #192 | Saved
2022-08-23 10:40:28 | [trpo_pendulum] epoch #192 | Time 189.49 s
2022-08-23 10:40:28 | [trpo_pendulum] epoch #192 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000781398
Evaluation/AverageReturn                 -0.0082089
Evaluation/Iteration                    192
Evaluation/MaxReturn                     -0.00818446
Evaluation/MinReturn                     -0.00823334
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.44407e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.59446
GaussianMLPPolicy/KL                      0.000119047
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               7.87658e-05
GaussianMLPPolicy/LossBefore              7.89336e-05
GaussianMLPPolicy/dLoss                   1.67784e-07
GaussianMLPValueFunction/LossAfter       -5.94409
GaussianMLPValueFunction/LossBefore      -6.33589
GaussianMLPValueFunction/dLoss           -0.391805
TotalEnvSteps                        385614
-----------------------------------  ----------------
2022-08-23 10:40:29 | [trpo_pendulum] epoch #193 | Saving snapshot...
2022-08-23 10:40:29 | [trpo_pendulum] epoch #193 | Saved
2022-08-23 10:40:29 | [trpo_pendulum] epoch #193 | Time 190.56 s
2022-08-23 10:40:29 | [trpo_pendulum] epoch #193 | EpochTime 1.06 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00105787
Evaluation/AverageReturn                 -0.0108887
Evaluation/Iteration                    193
Evaluation/MaxReturn                     -0.0108822
Evaluation/MinReturn                     -0.0108952
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.52355e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.62369
GaussianMLPPolicy/KL                      0.00293043
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000656173
GaussianMLPPolicy/LossBefore              0.000660727
GaussianMLPPolicy/dLoss                   4.55393e-06
GaussianMLPValueFunction/LossAfter       -5.3119
GaussianMLPValueFunction/LossBefore      -0.80289
GaussianMLPValueFunction/dLoss            4.50901
TotalEnvSteps                        387612
-----------------------------------  ----------------
2022-08-23 10:40:30 | [trpo_pendulum] epoch #194 | Saving snapshot...
2022-08-23 10:40:30 | [trpo_pendulum] epoch #194 | Saved
2022-08-23 10:40:30 | [trpo_pendulum] epoch #194 | Time 191.55 s
2022-08-23 10:40:30 | [trpo_pendulum] epoch #194 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000976731
Evaluation/AverageReturn                 -0.00950562
Evaluation/Iteration                    194
Evaluation/MaxReturn                     -0.00928773
Evaluation/MinReturn                     -0.00972352
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000217895
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.62833
GaussianMLPPolicy/KL                      0.000325695
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000301934
GaussianMLPPolicy/LossBefore             -0.000301572
GaussianMLPPolicy/dLoss                   3.61761e-07
GaussianMLPValueFunction/LossAfter       -4.15073
GaussianMLPValueFunction/LossBefore      -5.04379
GaussianMLPValueFunction/dLoss           -0.893065
TotalEnvSteps                        389610
-----------------------------------  ----------------
2022-08-23 10:40:31 | [trpo_pendulum] epoch #195 | Saving snapshot...
2022-08-23 10:40:31 | [trpo_pendulum] epoch #195 | Saved
2022-08-23 10:40:31 | [trpo_pendulum] epoch #195 | Time 192.55 s
2022-08-23 10:40:31 | [trpo_pendulum] epoch #195 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000913617
Evaluation/AverageReturn                 -0.00981005
Evaluation/Iteration                    195
Evaluation/MaxReturn                     -0.00955258
Evaluation/MinReturn                     -0.0100675
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000257477
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.62408
GaussianMLPPolicy/KL                      0.00037025
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000448862
GaussianMLPPolicy/LossBefore              0.000449336
GaussianMLPPolicy/dLoss                   4.73374e-07
GaussianMLPValueFunction/LossAfter       -4.74049
GaussianMLPValueFunction/LossBefore      -4.08442
GaussianMLPValueFunction/dLoss            0.656074
TotalEnvSteps                        391608
-----------------------------------  ----------------
2022-08-23 10:40:32 | [trpo_pendulum] epoch #196 | Saving snapshot...
2022-08-23 10:40:32 | [trpo_pendulum] epoch #196 | Saved
2022-08-23 10:40:32 | [trpo_pendulum] epoch #196 | Time 193.54 s
2022-08-23 10:40:32 | [trpo_pendulum] epoch #196 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000735233
Evaluation/AverageReturn                 -0.00752773
Evaluation/Iteration                    196
Evaluation/MaxReturn                     -0.00745694
Evaluation/MinReturn                     -0.00759851
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.07822e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.63201
GaussianMLPPolicy/KL                      9.23951e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -1.46524e-05
GaussianMLPPolicy/LossBefore             -1.45233e-05
GaussianMLPPolicy/dLoss                   1.29089e-07
GaussianMLPValueFunction/LossAfter       -6.35795
GaussianMLPValueFunction/LossBefore      -6.34646
GaussianMLPValueFunction/dLoss            0.0114927
TotalEnvSteps                        393606
-----------------------------------  ----------------
2022-08-23 10:40:33 | [trpo_pendulum] epoch #197 | Saving snapshot...
2022-08-23 10:40:33 | [trpo_pendulum] epoch #197 | Saved
2022-08-23 10:40:33 | [trpo_pendulum] epoch #197 | Time 194.51 s
2022-08-23 10:40:33 | [trpo_pendulum] epoch #197 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000809906
Evaluation/AverageReturn                 -0.00838826
Evaluation/Iteration                    197
Evaluation/MaxReturn                     -0.00820028
Evaluation/MinReturn                     -0.00857623
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000187977
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.63877
GaussianMLPPolicy/KL                      0.00143101
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00025056
GaussianMLPPolicy/LossBefore              0.000252534
GaussianMLPPolicy/dLoss                   1.97347e-06
GaussianMLPValueFunction/LossAfter       -5.43483
GaussianMLPValueFunction/LossBefore      -5.63996
GaussianMLPValueFunction/dLoss           -0.205133
TotalEnvSteps                        395604
-----------------------------------  ----------------
2022-08-23 10:40:34 | [trpo_pendulum] epoch #198 | Saving snapshot...
2022-08-23 10:40:34 | [trpo_pendulum] epoch #198 | Saved
2022-08-23 10:40:34 | [trpo_pendulum] epoch #198 | Time 195.48 s
2022-08-23 10:40:34 | [trpo_pendulum] epoch #198 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000724466
Evaluation/AverageReturn                 -0.00729138
Evaluation/Iteration                    198
Evaluation/MaxReturn                     -0.00721739
Evaluation/MinReturn                     -0.00736536
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.39817e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.63877
GaussianMLPPolicy/KL                      0.000227916
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00051118
GaussianMLPPolicy/LossBefore             -0.000510856
GaussianMLPPolicy/dLoss                   3.24682e-07
GaussianMLPValueFunction/LossAfter       -5.40849
GaussianMLPValueFunction/LossBefore      -3.99724
GaussianMLPValueFunction/dLoss            1.41124
TotalEnvSteps                        397602
-----------------------------------  ----------------
2022-08-23 10:40:35 | [trpo_pendulum] epoch #199 | Saving snapshot...
2022-08-23 10:40:35 | [trpo_pendulum] epoch #199 | Saved
2022-08-23 10:40:35 | [trpo_pendulum] epoch #199 | Time 196.51 s
2022-08-23 10:40:35 | [trpo_pendulum] epoch #199 | EpochTime 1.02 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000709246
Evaluation/AverageReturn                 -0.00736233
Evaluation/Iteration                    199
Evaluation/MaxReturn                     -0.0071452
Evaluation/MinReturn                     -0.00757945
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000217127
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.63877
GaussianMLPPolicy/KL                      9.39641e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00032968
GaussianMLPPolicy/LossBefore              0.000329813
GaussianMLPPolicy/dLoss                   1.33208e-07
GaussianMLPValueFunction/LossAfter       -6.43006
GaussianMLPValueFunction/LossBefore      -5.37267
GaussianMLPValueFunction/dLoss            1.05739
TotalEnvSteps                        399600
-----------------------------------  ----------------
2022-08-23 10:40:36 | [trpo_pendulum] epoch #200 | Saving snapshot...
2022-08-23 10:40:36 | [trpo_pendulum] epoch #200 | Saved
2022-08-23 10:40:36 | [trpo_pendulum] epoch #200 | Time 197.50 s
2022-08-23 10:40:36 | [trpo_pendulum] epoch #200 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000788358
Evaluation/AverageReturn                 -0.00762975
Evaluation/Iteration                    200
Evaluation/MaxReturn                     -0.00745553
Evaluation/MinReturn                     -0.00780397
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000174218
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.63909
GaussianMLPPolicy/KL                      7.67356e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               7.98035e-05
GaussianMLPPolicy/LossBefore              7.99135e-05
GaussianMLPPolicy/dLoss                   1.09954e-07
GaussianMLPValueFunction/LossAfter       -6.1528
GaussianMLPValueFunction/LossBefore      -6.35919
GaussianMLPValueFunction/dLoss           -0.206391
TotalEnvSteps                        401598
-----------------------------------  ----------------
2022-08-23 10:40:37 | [trpo_pendulum] epoch #201 | Saving snapshot...
2022-08-23 10:40:37 | [trpo_pendulum] epoch #201 | Saved
2022-08-23 10:40:37 | [trpo_pendulum] epoch #201 | Time 198.46 s
2022-08-23 10:40:37 | [trpo_pendulum] epoch #201 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000768745
Evaluation/AverageReturn                 -0.00849334
Evaluation/Iteration                    201
Evaluation/MaxReturn                     -0.00828605
Evaluation/MinReturn                     -0.00870063
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000207289
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.64599
GaussianMLPPolicy/KL                      0.00104984
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000317311
GaussianMLPPolicy/LossBefore              0.000318798
GaussianMLPPolicy/dLoss                   1.48689e-06
GaussianMLPValueFunction/LossAfter       -6.08375
GaussianMLPValueFunction/LossBefore      -5.19436
GaussianMLPValueFunction/dLoss            0.889386
TotalEnvSteps                        403596
-----------------------------------  ----------------
2022-08-23 10:40:38 | [trpo_pendulum] epoch #202 | Saving snapshot...
2022-08-23 10:40:38 | [trpo_pendulum] epoch #202 | Saved
2022-08-23 10:40:38 | [trpo_pendulum] epoch #202 | Time 199.41 s
2022-08-23 10:40:38 | [trpo_pendulum] epoch #202 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000695105
Evaluation/AverageReturn                 -0.00718943
Evaluation/Iteration                    202
Evaluation/MaxReturn                     -0.00706396
Evaluation/MinReturn                     -0.0073149
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000125469
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.64599
GaussianMLPPolicy/KL                      3.89426e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -9.00692e-05
GaussianMLPPolicy/LossBefore             -9.0014e-05
GaussianMLPPolicy/dLoss                   5.51809e-08
GaussianMLPValueFunction/LossAfter       -6.42312
GaussianMLPValueFunction/LossBefore      -6.34581
GaussianMLPValueFunction/dLoss            0.0773115
TotalEnvSteps                        405594
-----------------------------------  ----------------
2022-08-23 10:40:39 | [trpo_pendulum] epoch #203 | Saving snapshot...
2022-08-23 10:40:39 | [trpo_pendulum] epoch #203 | Saved
2022-08-23 10:40:39 | [trpo_pendulum] epoch #203 | Time 200.40 s
2022-08-23 10:40:39 | [trpo_pendulum] epoch #203 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000696582
Evaluation/AverageReturn                 -0.00751246
Evaluation/Iteration                    203
Evaluation/MaxReturn                     -0.00742412
Evaluation/MinReturn                     -0.00760079
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.83344e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.63776
GaussianMLPPolicy/KL                      0.000239064
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000214461
GaussianMLPPolicy/LossBefore              0.000214808
GaussianMLPPolicy/dLoss                   3.47034e-07
GaussianMLPValueFunction/LossAfter       -5.90196
GaussianMLPValueFunction/LossBefore      -5.85475
GaussianMLPValueFunction/dLoss            0.0472116
TotalEnvSteps                        407592
-----------------------------------  ----------------
2022-08-23 10:40:40 | [trpo_pendulum] epoch #204 | Saving snapshot...
2022-08-23 10:40:40 | [trpo_pendulum] epoch #204 | Saved
2022-08-23 10:40:40 | [trpo_pendulum] epoch #204 | Time 201.39 s
2022-08-23 10:40:40 | [trpo_pendulum] epoch #204 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000786213
Evaluation/AverageReturn                 -0.00889203
Evaluation/Iteration                    204
Evaluation/MaxReturn                     -0.00887296
Evaluation/MinReturn                     -0.0089111
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.90701e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.64419
GaussianMLPPolicy/KL                      0.0017399
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000570481
GaussianMLPPolicy/LossBefore              0.000573017
GaussianMLPPolicy/dLoss                   2.53558e-06
GaussianMLPValueFunction/LossAfter       -5.12484
GaussianMLPValueFunction/LossBefore      -1.71264
GaussianMLPValueFunction/dLoss            3.41221
TotalEnvSteps                        409590
-----------------------------------  ----------------
2022-08-23 10:40:41 | [trpo_pendulum] epoch #205 | Saving snapshot...
2022-08-23 10:40:41 | [trpo_pendulum] epoch #205 | Saved
2022-08-23 10:40:41 | [trpo_pendulum] epoch #205 | Time 202.36 s
2022-08-23 10:40:41 | [trpo_pendulum] epoch #205 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00071432
Evaluation/AverageReturn                 -0.00720849
Evaluation/Iteration                    205
Evaluation/MaxReturn                     -0.00701543
Evaluation/MinReturn                     -0.00740154
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000193056
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.63182
GaussianMLPPolicy/KL                      0.000719654
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000711762
GaussianMLPPolicy/LossBefore             -0.000710643
GaussianMLPPolicy/dLoss                   1.11863e-06
GaussianMLPValueFunction/LossAfter       -6.35656
GaussianMLPValueFunction/LossBefore      -1.85201
GaussianMLPValueFunction/dLoss            4.50455
TotalEnvSteps                        411588
-----------------------------------  ----------------
2022-08-23 10:40:42 | [trpo_pendulum] epoch #206 | Saving snapshot...
2022-08-23 10:40:42 | [trpo_pendulum] epoch #206 | Saved
2022-08-23 10:40:42 | [trpo_pendulum] epoch #206 | Time 203.34 s
2022-08-23 10:40:42 | [trpo_pendulum] epoch #206 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000782802
Evaluation/AverageReturn                 -0.00791334
Evaluation/Iteration                    206
Evaluation/MaxReturn                     -0.00774754
Evaluation/MinReturn                     -0.00807914
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000165799
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.63169
GaussianMLPPolicy/KL                      0.000145886
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000159124
GaussianMLPPolicy/LossBefore              0.000159337
GaussianMLPPolicy/dLoss                   2.12414e-07
GaussianMLPValueFunction/LossAfter       -6.07373
GaussianMLPValueFunction/LossBefore      -5.98865
GaussianMLPValueFunction/dLoss            0.0850849
TotalEnvSteps                        413586
-----------------------------------  ----------------
2022-08-23 10:40:43 | [trpo_pendulum] epoch #207 | Saving snapshot...
2022-08-23 10:40:43 | [trpo_pendulum] epoch #207 | Saved
2022-08-23 10:40:43 | [trpo_pendulum] epoch #207 | Time 204.46 s
2022-08-23 10:40:43 | [trpo_pendulum] epoch #207 | EpochTime 1.12 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000791645
Evaluation/AverageReturn                 -0.00803277
Evaluation/Iteration                    207
Evaluation/MaxReturn                     -0.00802243
Evaluation/MinReturn                     -0.00804311
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.03391e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.64233
GaussianMLPPolicy/KL                      0.000310827
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               8.34206e-05
GaussianMLPPolicy/LossBefore              8.38059e-05
GaussianMLPPolicy/dLoss                   3.85233e-07
GaussianMLPValueFunction/LossAfter       -6.1148
GaussianMLPValueFunction/LossBefore      -6.24269
GaussianMLPValueFunction/dLoss           -0.127891
TotalEnvSteps                        415584
-----------------------------------  ----------------
2022-08-23 10:40:44 | [trpo_pendulum] epoch #208 | Saving snapshot...
2022-08-23 10:40:44 | [trpo_pendulum] epoch #208 | Saved
2022-08-23 10:40:44 | [trpo_pendulum] epoch #208 | Time 205.43 s
2022-08-23 10:40:44 | [trpo_pendulum] epoch #208 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000705205
Evaluation/AverageReturn                 -0.00736566
Evaluation/Iteration                    208
Evaluation/MaxReturn                     -0.0071446
Evaluation/MinReturn                     -0.00758672
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000221063
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.64233
GaussianMLPPolicy/KL                      9.5093e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000283151
GaussianMLPPolicy/LossBefore             -0.00028315
GaussianMLPPolicy/dLoss                   1.39698e-09
GaussianMLPValueFunction/LossAfter       -6.36956
GaussianMLPValueFunction/LossBefore      -5.63764
GaussianMLPValueFunction/dLoss            0.731915
TotalEnvSteps                        417582
-----------------------------------  ----------------
2022-08-23 10:40:45 | [trpo_pendulum] epoch #209 | Saving snapshot...
2022-08-23 10:40:45 | [trpo_pendulum] epoch #209 | Saved
2022-08-23 10:40:45 | [trpo_pendulum] epoch #209 | Time 206.43 s
2022-08-23 10:40:45 | [trpo_pendulum] epoch #209 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000801497
Evaluation/AverageReturn                 -0.00734153
Evaluation/Iteration                    209
Evaluation/MaxReturn                     -0.00720554
Evaluation/MinReturn                     -0.00747753
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000135994
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.64233
GaussianMLPPolicy/KL                      0.000203531
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000107462
GaussianMLPPolicy/LossBefore             -0.00010717
GaussianMLPPolicy/dLoss                   2.91555e-07
GaussianMLPValueFunction/LossAfter       -5.98271
GaussianMLPValueFunction/LossBefore      -6.31424
GaussianMLPValueFunction/dLoss           -0.331524
TotalEnvSteps                        419580
-----------------------------------  ----------------
2022-08-23 10:40:46 | [trpo_pendulum] epoch #210 | Saving snapshot...
2022-08-23 10:40:46 | [trpo_pendulum] epoch #210 | Saved
2022-08-23 10:40:46 | [trpo_pendulum] epoch #210 | Time 207.41 s
2022-08-23 10:40:46 | [trpo_pendulum] epoch #210 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00067771
Evaluation/AverageReturn                 -0.00707896
Evaluation/Iteration                    210
Evaluation/MaxReturn                     -0.00702659
Evaluation/MinReturn                     -0.00713132
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.23639e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.64233
GaussianMLPPolicy/KL                      1.87191e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000191499
GaussianMLPPolicy/LossBefore             -0.000191472
GaussianMLPPolicy/dLoss                   2.65718e-08
GaussianMLPValueFunction/LossAfter       -6.17027
GaussianMLPValueFunction/LossBefore      -6.06518
GaussianMLPValueFunction/dLoss            0.105087
TotalEnvSteps                        421578
-----------------------------------  ----------------
2022-08-23 10:40:47 | [trpo_pendulum] epoch #211 | Saving snapshot...
2022-08-23 10:40:47 | [trpo_pendulum] epoch #211 | Saved
2022-08-23 10:40:47 | [trpo_pendulum] epoch #211 | Time 208.39 s
2022-08-23 10:40:47 | [trpo_pendulum] epoch #211 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000777398
Evaluation/AverageReturn                 -0.00889079
Evaluation/Iteration                    211
Evaluation/MaxReturn                     -0.00867894
Evaluation/MinReturn                     -0.00910265
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000211857
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.64226
GaussianMLPPolicy/KL                      0.0018961
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000659548
GaussianMLPPolicy/LossBefore              0.000662538
GaussianMLPPolicy/dLoss                   2.99036e-06
GaussianMLPValueFunction/LossAfter       -5.39715
GaussianMLPValueFunction/LossBefore      -0.387176
GaussianMLPValueFunction/dLoss            5.00997
TotalEnvSteps                        423576
-----------------------------------  ----------------
2022-08-23 10:40:48 | [trpo_pendulum] epoch #212 | Saving snapshot...
2022-08-23 10:40:48 | [trpo_pendulum] epoch #212 | Saved
2022-08-23 10:40:48 | [trpo_pendulum] epoch #212 | Time 209.39 s
2022-08-23 10:40:48 | [trpo_pendulum] epoch #212 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000634235
Evaluation/AverageReturn                 -0.00666216
Evaluation/Iteration                    212
Evaluation/MaxReturn                     -0.00662086
Evaluation/MinReturn                     -0.00670346
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.13018e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.6261
GaussianMLPPolicy/KL                      0.000430975
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000586748
GaussianMLPPolicy/LossBefore             -0.000585961
GaussianMLPPolicy/dLoss                   7.86735e-07
GaussianMLPValueFunction/LossAfter       -6.40907
GaussianMLPValueFunction/LossBefore      -3.14406
GaussianMLPValueFunction/dLoss            3.26501
TotalEnvSteps                        425574
-----------------------------------  ----------------
2022-08-23 10:40:49 | [trpo_pendulum] epoch #213 | Saving snapshot...
2022-08-23 10:40:49 | [trpo_pendulum] epoch #213 | Saved
2022-08-23 10:40:49 | [trpo_pendulum] epoch #213 | Time 210.37 s
2022-08-23 10:40:49 | [trpo_pendulum] epoch #213 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000822312
Evaluation/AverageReturn                 -0.00821846
Evaluation/Iteration                    213
Evaluation/MaxReturn                     -0.00804871
Evaluation/MinReturn                     -0.0083882
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000169745
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.62458
GaussianMLPPolicy/KL                      0.000240932
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000368528
GaussianMLPPolicy/LossBefore              0.000368876
GaussianMLPPolicy/dLoss                   3.4814e-07
GaussianMLPValueFunction/LossAfter       -5.77182
GaussianMLPValueFunction/LossBefore      -4.38123
GaussianMLPValueFunction/dLoss            1.39059
TotalEnvSteps                        427572
-----------------------------------  ----------------
2022-08-23 10:40:50 | [trpo_pendulum] epoch #214 | Saving snapshot...
2022-08-23 10:40:50 | [trpo_pendulum] epoch #214 | Saved
2022-08-23 10:40:50 | [trpo_pendulum] epoch #214 | Time 211.35 s
2022-08-23 10:40:50 | [trpo_pendulum] epoch #214 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000682712
Evaluation/AverageReturn                 -0.00674425
Evaluation/Iteration                    214
Evaluation/MaxReturn                     -0.00661765
Evaluation/MinReturn                     -0.00687086
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000126602
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.62458
GaussianMLPPolicy/KL                      1.57469e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000319406
GaussianMLPPolicy/LossBefore             -0.000319403
GaussianMLPPolicy/dLoss                   2.21189e-09
GaussianMLPValueFunction/LossAfter       -6.38281
GaussianMLPValueFunction/LossBefore      -5.45884
GaussianMLPValueFunction/dLoss            0.923976
TotalEnvSteps                        429570
-----------------------------------  ----------------
2022-08-23 10:40:51 | [trpo_pendulum] epoch #215 | Saving snapshot...
2022-08-23 10:40:51 | [trpo_pendulum] epoch #215 | Saved
2022-08-23 10:40:51 | [trpo_pendulum] epoch #215 | Time 212.34 s
2022-08-23 10:40:51 | [trpo_pendulum] epoch #215 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000637125
Evaluation/AverageReturn                 -0.00640969
Evaluation/Iteration                    215
Evaluation/MaxReturn                     -0.0060674
Evaluation/MinReturn                     -0.00675198
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000342291
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.62458
GaussianMLPPolicy/KL                      2.16573e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               3.4173e-05
GaussianMLPPolicy/LossBefore              3.42036e-05
GaussianMLPPolicy/dLoss                   3.06027e-08
GaussianMLPValueFunction/LossAfter       -6.42737
GaussianMLPValueFunction/LossBefore      -6.39513
GaussianMLPValueFunction/dLoss            0.0322495
TotalEnvSteps                        431568
-----------------------------------  ----------------
2022-08-23 10:40:51 | [trpo_pendulum] epoch #216 | Saving snapshot...
2022-08-23 10:40:51 | [trpo_pendulum] epoch #216 | Saved
2022-08-23 10:40:51 | [trpo_pendulum] epoch #216 | Time 213.27 s
2022-08-23 10:40:51 | [trpo_pendulum] epoch #216 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000561968
Evaluation/AverageReturn                 -0.00638908
Evaluation/Iteration                    216
Evaluation/MaxReturn                     -0.00631994
Evaluation/MinReturn                     -0.00645822
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.91399e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.62458
GaussianMLPPolicy/KL                      6.79167e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -2.91193e-06
GaussianMLPPolicy/LossBefore             -2.81603e-06
GaussianMLPPolicy/dLoss                   9.59019e-08
GaussianMLPValueFunction/LossAfter       -6.23866
GaussianMLPValueFunction/LossBefore      -6.43812
GaussianMLPValueFunction/dLoss           -0.199459
TotalEnvSteps                        433566
-----------------------------------  ----------------
2022-08-23 10:40:52 | [trpo_pendulum] epoch #217 | Saving snapshot...
2022-08-23 10:40:52 | [trpo_pendulum] epoch #217 | Saved
2022-08-23 10:40:52 | [trpo_pendulum] epoch #217 | Time 214.24 s
2022-08-23 10:40:52 | [trpo_pendulum] epoch #217 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00063726
Evaluation/AverageReturn                 -0.00664098
Evaluation/Iteration                    217
Evaluation/MaxReturn                     -0.00644915
Evaluation/MinReturn                     -0.0068328
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000191825
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.62414
GaussianMLPPolicy/KL                      2.40266e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000256376
GaussianMLPPolicy/LossBefore              0.000256411
GaussianMLPPolicy/dLoss                   3.45462e-08
GaussianMLPValueFunction/LossAfter       -6.13347
GaussianMLPValueFunction/LossBefore      -5.71148
GaussianMLPValueFunction/dLoss            0.421987
TotalEnvSteps                        435564
-----------------------------------  ----------------
2022-08-23 10:40:53 | [trpo_pendulum] epoch #218 | Saving snapshot...
2022-08-23 10:40:53 | [trpo_pendulum] epoch #218 | Saved
2022-08-23 10:40:53 | [trpo_pendulum] epoch #218 | Time 215.21 s
2022-08-23 10:40:53 | [trpo_pendulum] epoch #218 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000662232
Evaluation/AverageReturn                 -0.00660176
Evaluation/Iteration                    218
Evaluation/MaxReturn                     -0.00637841
Evaluation/MinReturn                     -0.00682511
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000223354
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.62383
GaussianMLPPolicy/KL                      0.000123055
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000215801
GaussianMLPPolicy/LossBefore             -0.000215625
GaussianMLPPolicy/dLoss                   1.75773e-07
GaussianMLPValueFunction/LossAfter       -6.38351
GaussianMLPValueFunction/LossBefore      -5.95585
GaussianMLPValueFunction/dLoss            0.427661
TotalEnvSteps                        437562
-----------------------------------  ----------------
2022-08-23 10:40:54 | [trpo_pendulum] epoch #219 | Saving snapshot...
2022-08-23 10:40:54 | [trpo_pendulum] epoch #219 | Saved
2022-08-23 10:40:54 | [trpo_pendulum] epoch #219 | Time 216.18 s
2022-08-23 10:40:54 | [trpo_pendulum] epoch #219 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000684692
Evaluation/AverageReturn                 -0.00632558
Evaluation/Iteration                    219
Evaluation/MaxReturn                     -0.00627591
Evaluation/MinReturn                     -0.00637524
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.96691e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.63144
GaussianMLPPolicy/KL                      7.51083e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000149835
GaussianMLPPolicy/LossBefore             -0.000149729
GaussianMLPPolicy/dLoss                   1.05443e-07
GaussianMLPValueFunction/LossAfter       -6.08823
GaussianMLPValueFunction/LossBefore      -6.21874
GaussianMLPValueFunction/dLoss           -0.130508
TotalEnvSteps                        439560
-----------------------------------  ----------------
2022-08-23 10:40:55 | [trpo_pendulum] epoch #220 | Saving snapshot...
2022-08-23 10:40:55 | [trpo_pendulum] epoch #220 | Saved
2022-08-23 10:40:55 | [trpo_pendulum] epoch #220 | Time 217.15 s
2022-08-23 10:40:55 | [trpo_pendulum] epoch #220 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000617032
Evaluation/AverageReturn                 -0.00644542
Evaluation/Iteration                    220
Evaluation/MaxReturn                     -0.00629885
Evaluation/MinReturn                     -0.00659198
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000146567
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.64052
GaussianMLPPolicy/KL                      0.000196995
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000323783
GaussianMLPPolicy/LossBefore              0.000324055
GaussianMLPPolicy/dLoss                   2.7183e-07
GaussianMLPValueFunction/LossAfter       -6.2676
GaussianMLPValueFunction/LossBefore      -5.21285
GaussianMLPValueFunction/dLoss            1.05475
TotalEnvSteps                        441558
-----------------------------------  ----------------
2022-08-23 10:40:56 | [trpo_pendulum] epoch #221 | Saving snapshot...
2022-08-23 10:40:56 | [trpo_pendulum] epoch #221 | Saved
2022-08-23 10:40:56 | [trpo_pendulum] epoch #221 | Time 218.10 s
2022-08-23 10:40:56 | [trpo_pendulum] epoch #221 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000662837
Evaluation/AverageReturn                 -0.00633241
Evaluation/Iteration                    221
Evaluation/MaxReturn                     -0.006223
Evaluation/MinReturn                     -0.00644182
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000109409
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.64052
GaussianMLPPolicy/KL                      2.39403e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000210945
GaussianMLPPolicy/LossBefore             -0.000210945
GaussianMLPPolicy/dLoss                   2.18279e-10
GaussianMLPValueFunction/LossAfter       -6.45622
GaussianMLPValueFunction/LossBefore      -5.98063
GaussianMLPValueFunction/dLoss            0.475585
TotalEnvSteps                        443556
-----------------------------------  ----------------
2022-08-23 10:40:57 | [trpo_pendulum] epoch #222 | Saving snapshot...
2022-08-23 10:40:57 | [trpo_pendulum] epoch #222 | Saved
2022-08-23 10:40:57 | [trpo_pendulum] epoch #222 | Time 219.05 s
2022-08-23 10:40:57 | [trpo_pendulum] epoch #222 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000583233
Evaluation/AverageReturn                 -0.00640595
Evaluation/Iteration                    222
Evaluation/MaxReturn                     -0.00602447
Evaluation/MinReturn                     -0.00678743
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.00038148
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.64052
GaussianMLPPolicy/KL                      8.47992e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -4.95679e-05
GaussianMLPPolicy/LossBefore             -4.94476e-05
GaussianMLPPolicy/dLoss                   1.20279e-07
GaussianMLPValueFunction/LossAfter       -6.24596
GaussianMLPValueFunction/LossBefore      -6.47906
GaussianMLPValueFunction/dLoss           -0.233104
TotalEnvSteps                        445554
-----------------------------------  ----------------
2022-08-23 10:40:58 | [trpo_pendulum] epoch #223 | Saving snapshot...
2022-08-23 10:40:58 | [trpo_pendulum] epoch #223 | Saved
2022-08-23 10:40:58 | [trpo_pendulum] epoch #223 | Time 220.08 s
2022-08-23 10:40:58 | [trpo_pendulum] epoch #223 | EpochTime 1.03 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000629407
Evaluation/AverageReturn                 -0.00596474
Evaluation/Iteration                    223
Evaluation/MaxReturn                     -0.00588423
Evaluation/MinReturn                     -0.00604525
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.05081e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.64052
GaussianMLPPolicy/KL                      3.16317e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000207951
GaussianMLPPolicy/LossBefore             -0.000207906
GaussianMLPPolicy/dLoss                   4.43979e-08
GaussianMLPValueFunction/LossAfter       -5.60204
GaussianMLPValueFunction/LossBefore      -6.0064
GaussianMLPValueFunction/dLoss           -0.404363
TotalEnvSteps                        447552
-----------------------------------  ----------------
2022-08-23 10:40:59 | [trpo_pendulum] epoch #224 | Saving snapshot...
2022-08-23 10:40:59 | [trpo_pendulum] epoch #224 | Saved
2022-08-23 10:40:59 | [trpo_pendulum] epoch #224 | Time 221.05 s
2022-08-23 10:40:59 | [trpo_pendulum] epoch #224 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000701233
Evaluation/AverageReturn                 -0.00644424
Evaluation/Iteration                    224
Evaluation/MaxReturn                     -0.00601498
Evaluation/MinReturn                     -0.0068735
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000429262
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.64156
GaussianMLPPolicy/KL                      0.000115497
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000186534
GaussianMLPPolicy/LossBefore             -0.000186369
GaussianMLPPolicy/dLoss                   1.64859e-07
GaussianMLPValueFunction/LossAfter       -6.14158
GaussianMLPValueFunction/LossBefore      -6.05401
GaussianMLPValueFunction/dLoss            0.0875683
TotalEnvSteps                        449550
-----------------------------------  ----------------
2022-08-23 10:41:00 | [trpo_pendulum] epoch #225 | Saving snapshot...
2022-08-23 10:41:00 | [trpo_pendulum] epoch #225 | Saved
2022-08-23 10:41:00 | [trpo_pendulum] epoch #225 | Time 221.99 s
2022-08-23 10:41:00 | [trpo_pendulum] epoch #225 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00064165
Evaluation/AverageReturn                 -0.00651582
Evaluation/Iteration                    225
Evaluation/MaxReturn                     -0.00650105
Evaluation/MinReturn                     -0.00653058
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.47647e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.65673
GaussianMLPPolicy/KL                      0.000590681
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000232083
GaussianMLPPolicy/LossBefore              0.000232904
GaussianMLPPolicy/dLoss                   8.2035e-07
GaussianMLPValueFunction/LossAfter       -6.18729
GaussianMLPValueFunction/LossBefore      -5.75036
GaussianMLPValueFunction/dLoss            0.436926
TotalEnvSteps                        451548
-----------------------------------  ----------------
2022-08-23 10:41:01 | [trpo_pendulum] epoch #226 | Saving snapshot...
2022-08-23 10:41:01 | [trpo_pendulum] epoch #226 | Saved
2022-08-23 10:41:01 | [trpo_pendulum] epoch #226 | Time 222.94 s
2022-08-23 10:41:01 | [trpo_pendulum] epoch #226 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000612791
Evaluation/AverageReturn                 -0.00586288
Evaluation/Iteration                    226
Evaluation/MaxReturn                     -0.00582556
Evaluation/MinReturn                     -0.00590021
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.73249e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.65673
GaussianMLPPolicy/KL                      5.37325e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -1.08312e-05
GaussianMLPPolicy/LossBefore             -1.07553e-05
GaussianMLPPolicy/dLoss                   7.58928e-08
GaussianMLPValueFunction/LossAfter       -6.54741
GaussianMLPValueFunction/LossBefore      -6.55911
GaussianMLPValueFunction/dLoss           -0.011704
TotalEnvSteps                        453546
-----------------------------------  ----------------
2022-08-23 10:41:02 | [trpo_pendulum] epoch #227 | Saving snapshot...
2022-08-23 10:41:02 | [trpo_pendulum] epoch #227 | Saved
2022-08-23 10:41:02 | [trpo_pendulum] epoch #227 | Time 223.92 s
2022-08-23 10:41:02 | [trpo_pendulum] epoch #227 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000657992
Evaluation/AverageReturn                 -0.00617598
Evaluation/Iteration                    227
Evaluation/MaxReturn                     -0.00606853
Evaluation/MinReturn                     -0.00628342
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000107446
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.66021
GaussianMLPPolicy/KL                      0.000113461
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               8.4058e-05
GaussianMLPPolicy/LossBefore              8.42238e-05
GaussianMLPPolicy/dLoss                   1.65805e-07
GaussianMLPValueFunction/LossAfter       -6.49563
GaussianMLPValueFunction/LossBefore      -6.48125
GaussianMLPValueFunction/dLoss            0.0143771
TotalEnvSteps                        455544
-----------------------------------  ----------------
2022-08-23 10:41:03 | [trpo_pendulum] epoch #228 | Saving snapshot...
2022-08-23 10:41:03 | [trpo_pendulum] epoch #228 | Saved
2022-08-23 10:41:03 | [trpo_pendulum] epoch #228 | Time 224.89 s
2022-08-23 10:41:03 | [trpo_pendulum] epoch #228 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000577166
Evaluation/AverageReturn                 -0.00602152
Evaluation/Iteration                    228
Evaluation/MaxReturn                     -0.00601626
Evaluation/MinReturn                     -0.00602678
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.26242e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.66021
GaussianMLPPolicy/KL                      5.10464e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               9.76475e-05
GaussianMLPPolicy/LossBefore              9.77196e-05
GaussianMLPPolicy/dLoss                   7.21557e-08
GaussianMLPValueFunction/LossAfter       -6.12495
GaussianMLPValueFunction/LossBefore      -6.4504
GaussianMLPValueFunction/dLoss           -0.32545
TotalEnvSteps                        457542
-----------------------------------  ----------------
2022-08-23 10:41:04 | [trpo_pendulum] epoch #229 | Saving snapshot...
2022-08-23 10:41:04 | [trpo_pendulum] epoch #229 | Saved
2022-08-23 10:41:04 | [trpo_pendulum] epoch #229 | Time 225.89 s
2022-08-23 10:41:04 | [trpo_pendulum] epoch #229 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000616536
Evaluation/AverageReturn                 -0.00580059
Evaluation/Iteration                    229
Evaluation/MaxReturn                     -0.00569391
Evaluation/MinReturn                     -0.00590727
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000106681
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.66021
GaussianMLPPolicy/KL                      1.71477e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000234233
GaussianMLPPolicy/LossBefore             -0.000234209
GaussianMLPPolicy/dLoss                   2.41416e-08
GaussianMLPValueFunction/LossAfter       -6.49716
GaussianMLPValueFunction/LossBefore      -5.82586
GaussianMLPValueFunction/dLoss            0.671299
TotalEnvSteps                        459540
-----------------------------------  ----------------
2022-08-23 10:41:05 | [trpo_pendulum] epoch #230 | Saving snapshot...
2022-08-23 10:41:05 | [trpo_pendulum] epoch #230 | Saved
2022-08-23 10:41:05 | [trpo_pendulum] epoch #230 | Time 226.90 s
2022-08-23 10:41:05 | [trpo_pendulum] epoch #230 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000629469
Evaluation/AverageReturn                 -0.00634888
Evaluation/Iteration                    230
Evaluation/MaxReturn                     -0.00618714
Evaluation/MinReturn                     -0.00651062
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000161741
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.6675
GaussianMLPPolicy/KL                      0.000317792
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000116129
GaussianMLPPolicy/LossBefore              0.000116661
GaussianMLPPolicy/dLoss                   5.32105e-07
GaussianMLPValueFunction/LossAfter       -6.14506
GaussianMLPValueFunction/LossBefore      -6.15914
GaussianMLPValueFunction/dLoss           -0.01408
TotalEnvSteps                        461538
-----------------------------------  ----------------
2022-08-23 10:41:06 | [trpo_pendulum] epoch #231 | Saving snapshot...
2022-08-23 10:41:06 | [trpo_pendulum] epoch #231 | Saved
2022-08-23 10:41:06 | [trpo_pendulum] epoch #231 | Time 227.87 s
2022-08-23 10:41:06 | [trpo_pendulum] epoch #231 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000589996
Evaluation/AverageReturn                 -0.00536285
Evaluation/Iteration                    231
Evaluation/MaxReturn                     -0.00530593
Evaluation/MinReturn                     -0.00541977
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.69203e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.6675
GaussianMLPPolicy/KL                      0.000118351
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -6.73602e-05
GaussianMLPPolicy/LossBefore             -6.71929e-05
GaussianMLPPolicy/dLoss                   1.67252e-07
GaussianMLPValueFunction/LossAfter       -6.39104
GaussianMLPValueFunction/LossBefore      -6.50799
GaussianMLPValueFunction/dLoss           -0.116952
TotalEnvSteps                        463536
-----------------------------------  ----------------
2022-08-23 10:41:07 | [trpo_pendulum] epoch #232 | Saving snapshot...
2022-08-23 10:41:07 | [trpo_pendulum] epoch #232 | Saved
2022-08-23 10:41:07 | [trpo_pendulum] epoch #232 | Time 228.92 s
2022-08-23 10:41:07 | [trpo_pendulum] epoch #232 | EpochTime 1.05 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00053958
Evaluation/AverageReturn                 -0.00558722
Evaluation/Iteration                    232
Evaluation/MaxReturn                     -0.00557834
Evaluation/MinReturn                     -0.0055961
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.87945e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.67487
GaussianMLPPolicy/KL                      7.53837e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000101867
GaussianMLPPolicy/LossBefore              0.000101971
GaussianMLPPolicy/dLoss                   1.04905e-07
GaussianMLPValueFunction/LossAfter       -6.37307
GaussianMLPValueFunction/LossBefore      -6.46682
GaussianMLPValueFunction/dLoss           -0.0937538
TotalEnvSteps                        465534
-----------------------------------  ----------------
2022-08-23 10:41:08 | [trpo_pendulum] epoch #233 | Saving snapshot...
2022-08-23 10:41:08 | [trpo_pendulum] epoch #233 | Saved
2022-08-23 10:41:08 | [trpo_pendulum] epoch #233 | Time 229.87 s
2022-08-23 10:41:08 | [trpo_pendulum] epoch #233 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000484249
Evaluation/AverageReturn                 -0.00517824
Evaluation/Iteration                    233
Evaluation/MaxReturn                     -0.0049837
Evaluation/MinReturn                     -0.00537277
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000194538
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.67487
GaussianMLPPolicy/KL                      3.30152e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000129372
GaussianMLPPolicy/LossBefore              0.000129377
GaussianMLPPolicy/dLoss                   4.68572e-09
GaussianMLPValueFunction/LossAfter       -6.62096
GaussianMLPValueFunction/LossBefore      -6.38789
GaussianMLPValueFunction/dLoss            0.233069
TotalEnvSteps                        467532
-----------------------------------  ----------------
2022-08-23 10:41:09 | [trpo_pendulum] epoch #234 | Saving snapshot...
2022-08-23 10:41:09 | [trpo_pendulum] epoch #234 | Saved
2022-08-23 10:41:09 | [trpo_pendulum] epoch #234 | Time 230.86 s
2022-08-23 10:41:09 | [trpo_pendulum] epoch #234 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000564163
Evaluation/AverageReturn                 -0.00543403
Evaluation/Iteration                    234
Evaluation/MaxReturn                     -0.00539066
Evaluation/MinReturn                     -0.00547739
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.33612e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.67487
GaussianMLPPolicy/KL                      2.16385e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.44977e-05
GaussianMLPPolicy/LossBefore             -3.4467e-05
GaussianMLPPolicy/dLoss                   3.065e-08
GaussianMLPValueFunction/LossAfter       -6.4556
GaussianMLPValueFunction/LossBefore      -6.61768
GaussianMLPValueFunction/dLoss           -0.162079
TotalEnvSteps                        469530
-----------------------------------  ----------------
2022-08-23 10:41:10 | [trpo_pendulum] epoch #235 | Saving snapshot...
2022-08-23 10:41:10 | [trpo_pendulum] epoch #235 | Saved
2022-08-23 10:41:10 | [trpo_pendulum] epoch #235 | Time 231.84 s
2022-08-23 10:41:10 | [trpo_pendulum] epoch #235 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000592589
Evaluation/AverageReturn                 -0.0064641
Evaluation/Iteration                    235
Evaluation/MaxReturn                     -0.00634372
Evaluation/MinReturn                     -0.00658447
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000120373
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.69179
GaussianMLPPolicy/KL                      0.00203231
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000445405
GaussianMLPPolicy/LossBefore              0.000448384
GaussianMLPPolicy/dLoss                   2.97945e-06
GaussianMLPValueFunction/LossAfter       -5.65545
GaussianMLPValueFunction/LossBefore      -2.79498
GaussianMLPValueFunction/dLoss            2.86046
TotalEnvSteps                        471528
-----------------------------------  ----------------
2022-08-23 10:41:11 | [trpo_pendulum] epoch #236 | Saving snapshot...
2022-08-23 10:41:11 | [trpo_pendulum] epoch #236 | Saved
2022-08-23 10:41:11 | [trpo_pendulum] epoch #236 | Time 232.78 s
2022-08-23 10:41:11 | [trpo_pendulum] epoch #236 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000543279
Evaluation/AverageReturn                 -0.00552095
Evaluation/Iteration                    236
Evaluation/MaxReturn                     -0.0054555
Evaluation/MinReturn                     -0.0055864
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.54533e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.69179
GaussianMLPPolicy/KL                      6.8233e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000163058
GaussianMLPPolicy/LossBefore             -0.000163048
GaussianMLPPolicy/dLoss                   9.77889e-09
GaussianMLPValueFunction/LossAfter       -6.60424
GaussianMLPValueFunction/LossBefore      -6.2269
GaussianMLPValueFunction/dLoss            0.377338
TotalEnvSteps                        473526
-----------------------------------  ----------------
2022-08-23 10:41:12 | [trpo_pendulum] epoch #237 | Saving snapshot...
2022-08-23 10:41:12 | [trpo_pendulum] epoch #237 | Saved
2022-08-23 10:41:12 | [trpo_pendulum] epoch #237 | Time 233.72 s
2022-08-23 10:41:12 | [trpo_pendulum] epoch #237 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000586613
Evaluation/AverageReturn                 -0.0060861
Evaluation/Iteration                    237
Evaluation/MaxReturn                     -0.00592849
Evaluation/MinReturn                     -0.00624371
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000157612
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.70449
GaussianMLPPolicy/KL                      0.00155017
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000306361
GaussianMLPPolicy/LossBefore              0.000308381
GaussianMLPPolicy/dLoss                   2.02004e-06
GaussianMLPValueFunction/LossAfter       -6.04185
GaussianMLPValueFunction/LossBefore      -4.68246
GaussianMLPValueFunction/dLoss            1.35939
TotalEnvSteps                        475524
-----------------------------------  ----------------
2022-08-23 10:41:13 | [trpo_pendulum] epoch #238 | Saving snapshot...
2022-08-23 10:41:13 | [trpo_pendulum] epoch #238 | Saved
2022-08-23 10:41:13 | [trpo_pendulum] epoch #238 | Time 234.69 s
2022-08-23 10:41:13 | [trpo_pendulum] epoch #238 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000565695
Evaluation/AverageReturn                 -0.00590812
Evaluation/Iteration                    238
Evaluation/MaxReturn                     -0.0058208
Evaluation/MinReturn                     -0.00599545
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.73238e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.71615
GaussianMLPPolicy/KL                      0.000390918
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               1.5275e-05
GaussianMLPPolicy/LossBefore              1.58144e-05
GaussianMLPPolicy/dLoss                   5.39418e-07
GaussianMLPValueFunction/LossAfter       -5.97177
GaussianMLPValueFunction/LossBefore      -6.16412
GaussianMLPValueFunction/dLoss           -0.192348
TotalEnvSteps                        477522
-----------------------------------  ----------------
2022-08-23 10:41:14 | [trpo_pendulum] epoch #239 | Saving snapshot...
2022-08-23 10:41:14 | [trpo_pendulum] epoch #239 | Saved
2022-08-23 10:41:14 | [trpo_pendulum] epoch #239 | Time 235.69 s
2022-08-23 10:41:14 | [trpo_pendulum] epoch #239 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000572073
Evaluation/AverageReturn                 -0.00552707
Evaluation/Iteration                    239
Evaluation/MaxReturn                     -0.00541666
Evaluation/MinReturn                     -0.00563747
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000110404
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.70526
GaussianMLPPolicy/KL                      0.000130348
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00038901
GaussianMLPPolicy/LossBefore             -0.00038882
GaussianMLPPolicy/dLoss                   1.89757e-07
GaussianMLPValueFunction/LossAfter       -6.56048
GaussianMLPValueFunction/LossBefore      -4.65209
GaussianMLPValueFunction/dLoss            1.90839
TotalEnvSteps                        479520
-----------------------------------  ----------------
2022-08-23 10:41:15 | [trpo_pendulum] epoch #240 | Saving snapshot...
2022-08-23 10:41:15 | [trpo_pendulum] epoch #240 | Saved
2022-08-23 10:41:15 | [trpo_pendulum] epoch #240 | Time 236.70 s
2022-08-23 10:41:15 | [trpo_pendulum] epoch #240 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000592698
Evaluation/AverageReturn                 -0.00533867
Evaluation/Iteration                    240
Evaluation/MaxReturn                     -0.00516539
Evaluation/MinReturn                     -0.00551196
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000173284
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.70526
GaussianMLPPolicy/KL                      1.71529e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               4.39779e-05
GaussianMLPPolicy/LossBefore              4.40021e-05
GaussianMLPPolicy/dLoss                   2.41489e-08
GaussianMLPValueFunction/LossAfter       -6.30656
GaussianMLPValueFunction/LossBefore      -6.55237
GaussianMLPValueFunction/dLoss           -0.245807
TotalEnvSteps                        481518
-----------------------------------  ----------------
2022-08-23 10:41:16 | [trpo_pendulum] epoch #241 | Saving snapshot...
2022-08-23 10:41:16 | [trpo_pendulum] epoch #241 | Saved
2022-08-23 10:41:16 | [trpo_pendulum] epoch #241 | Time 237.68 s
2022-08-23 10:41:16 | [trpo_pendulum] epoch #241 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000592656
Evaluation/AverageReturn                 -0.00548444
Evaluation/Iteration                    241
Evaluation/MaxReturn                     -0.00528611
Evaluation/MinReturn                     -0.00568276
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000198325
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.70526
GaussianMLPPolicy/KL                      0.000155463
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000147903
GaussianMLPPolicy/LossBefore             -0.000147681
GaussianMLPPolicy/dLoss                   2.21989e-07
GaussianMLPValueFunction/LossAfter       -6.562
GaussianMLPValueFunction/LossBefore      -6.28988
GaussianMLPValueFunction/dLoss            0.272125
TotalEnvSteps                        483516
-----------------------------------  ----------------
2022-08-23 10:41:17 | [trpo_pendulum] epoch #242 | Saving snapshot...
2022-08-23 10:41:17 | [trpo_pendulum] epoch #242 | Saved
2022-08-23 10:41:17 | [trpo_pendulum] epoch #242 | Time 238.68 s
2022-08-23 10:41:17 | [trpo_pendulum] epoch #242 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000536212
Evaluation/AverageReturn                 -0.00582076
Evaluation/Iteration                    242
Evaluation/MaxReturn                     -0.00578542
Evaluation/MinReturn                     -0.0058561
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.53434e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.69694
GaussianMLPPolicy/KL                      0.000159256
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000141122
GaussianMLPPolicy/LossBefore              0.000141357
GaussianMLPPolicy/dLoss                   2.34621e-07
GaussianMLPValueFunction/LossAfter       -6.28597
GaussianMLPValueFunction/LossBefore      -6.0584
GaussianMLPValueFunction/dLoss            0.227571
TotalEnvSteps                        485514
-----------------------------------  ----------------
2022-08-23 10:41:18 | [trpo_pendulum] epoch #243 | Saving snapshot...
2022-08-23 10:41:18 | [trpo_pendulum] epoch #243 | Saved
2022-08-23 10:41:18 | [trpo_pendulum] epoch #243 | Time 239.63 s
2022-08-23 10:41:18 | [trpo_pendulum] epoch #243 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000572642
Evaluation/AverageReturn                 -0.00559332
Evaluation/Iteration                    243
Evaluation/MaxReturn                     -0.00537232
Evaluation/MinReturn                     -0.00581432
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000221004
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.69694
GaussianMLPPolicy/KL                      1.40028e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000116119
GaussianMLPPolicy/LossBefore             -0.000116099
GaussianMLPPolicy/dLoss                   1.97761e-08
GaussianMLPValueFunction/LossAfter       -5.02991
GaussianMLPValueFunction/LossBefore      -6.39759
GaussianMLPValueFunction/dLoss           -1.36767
TotalEnvSteps                        487512
-----------------------------------  ----------------
2022-08-23 10:41:19 | [trpo_pendulum] epoch #244 | Saving snapshot...
2022-08-23 10:41:19 | [trpo_pendulum] epoch #244 | Saved
2022-08-23 10:41:19 | [trpo_pendulum] epoch #244 | Time 240.56 s
2022-08-23 10:41:19 | [trpo_pendulum] epoch #244 | EpochTime 0.92 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000552107
Evaluation/AverageReturn                 -0.00539118
Evaluation/Iteration                    244
Evaluation/MaxReturn                     -0.00522765
Evaluation/MinReturn                     -0.00555471
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000163532
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.69033
GaussianMLPPolicy/KL                      0.000395791
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000356808
GaussianMLPPolicy/LossBefore             -0.00035656
GaussianMLPPolicy/dLoss                   2.47441e-07
GaussianMLPValueFunction/LossAfter       -6.4083
GaussianMLPValueFunction/LossBefore      -4.79607
GaussianMLPValueFunction/dLoss            1.61223
TotalEnvSteps                        489510
-----------------------------------  ----------------
2022-08-23 10:41:20 | [trpo_pendulum] epoch #245 | Saving snapshot...
2022-08-23 10:41:20 | [trpo_pendulum] epoch #245 | Saved
2022-08-23 10:41:20 | [trpo_pendulum] epoch #245 | Time 241.61 s
2022-08-23 10:41:20 | [trpo_pendulum] epoch #245 | EpochTime 1.04 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000521687
Evaluation/AverageReturn                 -0.00529059
Evaluation/Iteration                    245
Evaluation/MaxReturn                     -0.00521858
Evaluation/MinReturn                     -0.0053626
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.20074e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.6949
GaussianMLPPolicy/KL                      5.19681e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -8.96926e-05
GaussianMLPPolicy/LossBefore             -8.96191e-05
GaussianMLPPolicy/dLoss                   7.35163e-08
GaussianMLPValueFunction/LossAfter       -6.57489
GaussianMLPValueFunction/LossBefore      -6.48961
GaussianMLPValueFunction/dLoss            0.0852795
TotalEnvSteps                        491508
-----------------------------------  ----------------
2022-08-23 10:41:21 | [trpo_pendulum] epoch #246 | Saving snapshot...
2022-08-23 10:41:21 | [trpo_pendulum] epoch #246 | Saved
2022-08-23 10:41:21 | [trpo_pendulum] epoch #246 | Time 242.61 s
2022-08-23 10:41:21 | [trpo_pendulum] epoch #246 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000544051
Evaluation/AverageReturn                 -0.0058151
Evaluation/Iteration                    246
Evaluation/MaxReturn                     -0.00578546
Evaluation/MinReturn                     -0.00584474
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.96428e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.6955
GaussianMLPPolicy/KL                      2.70783e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -7.7251e-06
GaussianMLPPolicy/LossBefore             -7.68703e-06
GaussianMLPPolicy/dLoss                   3.80733e-08
GaussianMLPValueFunction/LossAfter       -6.55848
GaussianMLPValueFunction/LossBefore      -6.59706
GaussianMLPValueFunction/dLoss           -0.0385799
TotalEnvSteps                        493506
-----------------------------------  ----------------
2022-08-23 10:41:22 | [trpo_pendulum] epoch #247 | Saving snapshot...
2022-08-23 10:41:22 | [trpo_pendulum] epoch #247 | Saved
2022-08-23 10:41:22 | [trpo_pendulum] epoch #247 | Time 243.57 s
2022-08-23 10:41:22 | [trpo_pendulum] epoch #247 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000548825
Evaluation/AverageReturn                 -0.0057325
Evaluation/Iteration                    247
Evaluation/MaxReturn                     -0.00567211
Evaluation/MinReturn                     -0.00579289
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.03893e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.6956
GaussianMLPPolicy/KL                      0.000118171
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               2.45503e-06
GaussianMLPPolicy/LossBefore              2.62597e-06
GaussianMLPPolicy/dLoss                   1.70942e-07
GaussianMLPValueFunction/LossAfter       -6.27825
GaussianMLPValueFunction/LossBefore      -6.52385
GaussianMLPValueFunction/dLoss           -0.245599
TotalEnvSteps                        495504
-----------------------------------  ----------------
2022-08-23 10:41:23 | [trpo_pendulum] epoch #248 | Saving snapshot...
2022-08-23 10:41:23 | [trpo_pendulum] epoch #248 | Saved
2022-08-23 10:41:23 | [trpo_pendulum] epoch #248 | Time 244.53 s
2022-08-23 10:41:23 | [trpo_pendulum] epoch #248 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000521799
Evaluation/AverageReturn                 -0.00528508
Evaluation/Iteration                    248
Evaluation/MaxReturn                     -0.00512956
Evaluation/MinReturn                     -0.00544061
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000155527
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.70218
GaussianMLPPolicy/KL                      7.16299e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               1.37876e-05
GaussianMLPPolicy/LossBefore              1.38888e-05
GaussianMLPPolicy/dLoss                   1.01222e-07
GaussianMLPValueFunction/LossAfter       -6.61753
GaussianMLPValueFunction/LossBefore      -6.60979
GaussianMLPValueFunction/dLoss            0.00773764
TotalEnvSteps                        497502
-----------------------------------  ----------------
2022-08-23 10:41:24 | [trpo_pendulum] epoch #249 | Saving snapshot...
2022-08-23 10:41:24 | [trpo_pendulum] epoch #249 | Saved
2022-08-23 10:41:24 | [trpo_pendulum] epoch #249 | Time 245.51 s
2022-08-23 10:41:24 | [trpo_pendulum] epoch #249 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000511941
Evaluation/AverageReturn                 -0.00501634
Evaluation/Iteration                    249
Evaluation/MaxReturn                     -0.00489075
Evaluation/MinReturn                     -0.00514193
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000125589
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.70218
GaussianMLPPolicy/KL                      4.08767e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -5.96347e-05
GaussianMLPPolicy/LossBefore             -5.95771e-05
GaussianMLPPolicy/dLoss                   5.75965e-08
GaussianMLPValueFunction/LossAfter       -6.65245
GaussianMLPValueFunction/LossBefore      -6.58232
GaussianMLPValueFunction/dLoss            0.0701232
TotalEnvSteps                        499500
-----------------------------------  ----------------
2022-08-23 10:41:25 | [trpo_pendulum] epoch #250 | Saving snapshot...
2022-08-23 10:41:25 | [trpo_pendulum] epoch #250 | Saved
2022-08-23 10:41:25 | [trpo_pendulum] epoch #250 | Time 246.47 s
2022-08-23 10:41:25 | [trpo_pendulum] epoch #250 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000548209
Evaluation/AverageReturn                 -0.00537582
Evaluation/Iteration                    250
Evaluation/MaxReturn                     -0.00534371
Evaluation/MinReturn                     -0.00540793
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.21085e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.70221
GaussianMLPPolicy/KL                      1.02147e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000121386
GaussianMLPPolicy/LossBefore              0.0001214
GaussianMLPPolicy/dLoss                   1.44719e-08
GaussianMLPValueFunction/LossAfter       -6.47459
GaussianMLPValueFunction/LossBefore      -6.32195
GaussianMLPValueFunction/dLoss            0.152635
TotalEnvSteps                        501498
-----------------------------------  ----------------
2022-08-23 10:41:26 | [trpo_pendulum] epoch #251 | Saving snapshot...
2022-08-23 10:41:26 | [trpo_pendulum] epoch #251 | Saved
2022-08-23 10:41:26 | [trpo_pendulum] epoch #251 | Time 247.45 s
2022-08-23 10:41:26 | [trpo_pendulum] epoch #251 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000516468
Evaluation/AverageReturn                 -0.00528792
Evaluation/Iteration                    251
Evaluation/MaxReturn                     -0.00513652
Evaluation/MinReturn                     -0.00543932
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000151399
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.69913
GaussianMLPPolicy/KL                      5.08605e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000160535
GaussianMLPPolicy/LossBefore             -0.000160462
GaussianMLPPolicy/dLoss                   7.36472e-08
GaussianMLPValueFunction/LossAfter       -5.53989
GaussianMLPValueFunction/LossBefore      -6.24856
GaussianMLPValueFunction/dLoss           -0.708668
TotalEnvSteps                        503496
-----------------------------------  ----------------
2022-08-23 10:41:27 | [trpo_pendulum] epoch #252 | Saving snapshot...
2022-08-23 10:41:27 | [trpo_pendulum] epoch #252 | Saved
2022-08-23 10:41:27 | [trpo_pendulum] epoch #252 | Time 248.44 s
2022-08-23 10:41:27 | [trpo_pendulum] epoch #252 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000511164
Evaluation/AverageReturn                 -0.00539481
Evaluation/Iteration                    252
Evaluation/MaxReturn                     -0.00516591
Evaluation/MinReturn                     -0.0056237
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000228897
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.69344
GaussianMLPPolicy/KL                      0.000140954
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000286736
GaussianMLPPolicy/LossBefore             -0.000286568
GaussianMLPPolicy/dLoss                   1.6822e-07
GaussianMLPValueFunction/LossAfter       -6.52744
GaussianMLPValueFunction/LossBefore      -5.36372
GaussianMLPValueFunction/dLoss            1.16372
TotalEnvSteps                        505494
-----------------------------------  ----------------
2022-08-23 10:41:28 | [trpo_pendulum] epoch #253 | Saving snapshot...
2022-08-23 10:41:28 | [trpo_pendulum] epoch #253 | Saved
2022-08-23 10:41:28 | [trpo_pendulum] epoch #253 | Time 249.40 s
2022-08-23 10:41:28 | [trpo_pendulum] epoch #253 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000497264
Evaluation/AverageReturn                 -0.0050786
Evaluation/Iteration                    253
Evaluation/MaxReturn                     -0.00498193
Evaluation/MinReturn                     -0.00517528
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      9.6674e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.69344
GaussianMLPPolicy/KL                      2.071e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.0001054
GaussianMLPPolicy/LossBefore              0.000105429
GaussianMLPPolicy/dLoss                   2.93439e-08
GaussianMLPValueFunction/LossAfter       -6.55749
GaussianMLPValueFunction/LossBefore      -6.48513
GaussianMLPValueFunction/dLoss            0.0723562
TotalEnvSteps                        507492
-----------------------------------  ----------------
2022-08-23 10:41:29 | [trpo_pendulum] epoch #254 | Saving snapshot...
2022-08-23 10:41:29 | [trpo_pendulum] epoch #254 | Saved
2022-08-23 10:41:29 | [trpo_pendulum] epoch #254 | Time 250.36 s
2022-08-23 10:41:29 | [trpo_pendulum] epoch #254 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000571173
Evaluation/AverageReturn                 -0.00620408
Evaluation/Iteration                    254
Evaluation/MaxReturn                     -0.00619619
Evaluation/MinReturn                     -0.00621198
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.89657e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.72143
GaussianMLPPolicy/KL                      0.000954213
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000237997
GaussianMLPPolicy/LossBefore              0.000239336
GaussianMLPPolicy/dLoss                   1.33947e-06
GaussianMLPValueFunction/LossAfter       -5.97187
GaussianMLPValueFunction/LossBefore      -4.93072
GaussianMLPValueFunction/dLoss            1.04114
TotalEnvSteps                        509490
-----------------------------------  ----------------
2022-08-23 10:41:29 | [trpo_pendulum] epoch #255 | Saving snapshot...
2022-08-23 10:41:30 | [trpo_pendulum] epoch #255 | Saved
2022-08-23 10:41:30 | [trpo_pendulum] epoch #255 | Time 251.30 s
2022-08-23 10:41:30 | [trpo_pendulum] epoch #255 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000490775
Evaluation/AverageReturn                 -0.00506826
Evaluation/Iteration                    255
Evaluation/MaxReturn                     -0.00506737
Evaluation/MinReturn                     -0.00506915
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.94335e-07
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.7315
GaussianMLPPolicy/KL                      0.000502926
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000113406
GaussianMLPPolicy/LossBefore             -0.000112593
GaussianMLPPolicy/dLoss                   8.13532e-07
GaussianMLPValueFunction/LossAfter       -5.71219
GaussianMLPValueFunction/LossBefore      -6.19944
GaussianMLPValueFunction/dLoss           -0.487251
TotalEnvSteps                        511488
-----------------------------------  ----------------
2022-08-23 10:41:30 | [trpo_pendulum] epoch #256 | Saving snapshot...
2022-08-23 10:41:31 | [trpo_pendulum] epoch #256 | Saved
2022-08-23 10:41:31 | [trpo_pendulum] epoch #256 | Time 252.32 s
2022-08-23 10:41:31 | [trpo_pendulum] epoch #256 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000509279
Evaluation/AverageReturn                 -0.00477769
Evaluation/Iteration                    256
Evaluation/MaxReturn                     -0.00463487
Evaluation/MinReturn                     -0.00492052
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000142823
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.7315
GaussianMLPPolicy/KL                      4.15436e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               1.91495e-05
GaussianMLPPolicy/LossBefore              1.92082e-05
GaussianMLPPolicy/dLoss                   5.87261e-08
GaussianMLPValueFunction/LossAfter       -6.61268
GaussianMLPValueFunction/LossBefore      -6.62092
GaussianMLPValueFunction/dLoss           -0.00824165
TotalEnvSteps                        513486
-----------------------------------  ----------------
2022-08-23 10:41:31 | [trpo_pendulum] epoch #257 | Saving snapshot...
2022-08-23 10:41:31 | [trpo_pendulum] epoch #257 | Saved
2022-08-23 10:41:31 | [trpo_pendulum] epoch #257 | Time 253.24 s
2022-08-23 10:41:31 | [trpo_pendulum] epoch #257 | EpochTime 0.92 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000479553
Evaluation/AverageReturn                 -0.00481385
Evaluation/Iteration                    257
Evaluation/MaxReturn                     -0.00481171
Evaluation/MinReturn                     -0.00481598
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.13317e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.7315
GaussianMLPPolicy/KL                      1.37177e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.7952e-05
GaussianMLPPolicy/LossBefore             -3.79327e-05
GaussianMLPPolicy/dLoss                   1.93359e-08
GaussianMLPValueFunction/LossAfter       -6.49546
GaussianMLPValueFunction/LossBefore      -6.61922
GaussianMLPValueFunction/dLoss           -0.12376
TotalEnvSteps                        515484
-----------------------------------  ----------------
2022-08-23 10:41:33 | [trpo_pendulum] epoch #258 | Saving snapshot...
2022-08-23 10:41:33 | [trpo_pendulum] epoch #258 | Saved
2022-08-23 10:41:33 | [trpo_pendulum] epoch #258 | Time 254.33 s
2022-08-23 10:41:33 | [trpo_pendulum] epoch #258 | EpochTime 1.09 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000469354
Evaluation/AverageReturn                 -0.00463938
Evaluation/Iteration                    258
Evaluation/MaxReturn                     -0.00454395
Evaluation/MinReturn                     -0.00473481
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      9.54293e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.7315
GaussianMLPPolicy/KL                      3.30481e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000110265
GaussianMLPPolicy/LossBefore              0.000110266
GaussianMLPPolicy/dLoss                   4.43833e-10
GaussianMLPValueFunction/LossAfter       -6.40009
GaussianMLPValueFunction/LossBefore      -6.47276
GaussianMLPValueFunction/dLoss           -0.0726771
TotalEnvSteps                        517482
-----------------------------------  ----------------
2022-08-23 10:41:33 | [trpo_pendulum] epoch #259 | Saving snapshot...
2022-08-23 10:41:33 | [trpo_pendulum] epoch #259 | Saved
2022-08-23 10:41:33 | [trpo_pendulum] epoch #259 | Time 255.30 s
2022-08-23 10:41:33 | [trpo_pendulum] epoch #259 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000510022
Evaluation/AverageReturn                 -0.00524641
Evaluation/Iteration                    259
Evaluation/MaxReturn                     -0.00520801
Evaluation/MinReturn                     -0.00528481
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.84006e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.7319
GaussianMLPPolicy/KL                      0.000348773
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               2.54794e-05
GaussianMLPPolicy/LossBefore              2.59835e-05
GaussianMLPPolicy/dLoss                   5.0416e-07
GaussianMLPValueFunction/LossAfter       -6.29543
GaussianMLPValueFunction/LossBefore      -6.46807
GaussianMLPValueFunction/dLoss           -0.172641
TotalEnvSteps                        519480
-----------------------------------  ----------------
2022-08-23 10:41:34 | [trpo_pendulum] epoch #260 | Saving snapshot...
2022-08-23 10:41:34 | [trpo_pendulum] epoch #260 | Saved
2022-08-23 10:41:34 | [trpo_pendulum] epoch #260 | Time 256.25 s
2022-08-23 10:41:34 | [trpo_pendulum] epoch #260 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000499251
Evaluation/AverageReturn                 -0.00488566
Evaluation/Iteration                    260
Evaluation/MaxReturn                     -0.00474837
Evaluation/MinReturn                     -0.00502296
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000137292
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.73272
GaussianMLPPolicy/KL                      8.61848e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000191313
GaussianMLPPolicy/LossBefore             -0.000191192
GaussianMLPPolicy/dLoss                   1.2177e-07
GaussianMLPValueFunction/LossAfter       -6.34674
GaussianMLPValueFunction/LossBefore      -6.04615
GaussianMLPValueFunction/dLoss            0.300591
TotalEnvSteps                        521478
-----------------------------------  ----------------
2022-08-23 10:41:35 | [trpo_pendulum] epoch #261 | Saving snapshot...
2022-08-23 10:41:35 | [trpo_pendulum] epoch #261 | Saved
2022-08-23 10:41:35 | [trpo_pendulum] epoch #261 | Time 257.24 s
2022-08-23 10:41:35 | [trpo_pendulum] epoch #261 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00050722
Evaluation/AverageReturn                 -0.00482844
Evaluation/Iteration                    261
Evaluation/MaxReturn                     -0.00482144
Evaluation/MinReturn                     -0.00483545
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.00345e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.74185
GaussianMLPPolicy/KL                      8.99389e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000183104
GaussianMLPPolicy/LossBefore             -0.00018298
GaussianMLPPolicy/dLoss                   1.2487e-07
GaussianMLPValueFunction/LossAfter       -6.65626
GaussianMLPValueFunction/LossBefore      -6.12555
GaussianMLPValueFunction/dLoss            0.530708
TotalEnvSteps                        523476
-----------------------------------  ----------------
2022-08-23 10:41:36 | [trpo_pendulum] epoch #262 | Saving snapshot...
2022-08-23 10:41:36 | [trpo_pendulum] epoch #262 | Saved
2022-08-23 10:41:36 | [trpo_pendulum] epoch #262 | Time 258.19 s
2022-08-23 10:41:36 | [trpo_pendulum] epoch #262 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000532774
Evaluation/AverageReturn                 -0.00505775
Evaluation/Iteration                    262
Evaluation/MaxReturn                     -0.00496973
Evaluation/MinReturn                     -0.00514578
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.80251e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.74185
GaussianMLPPolicy/KL                      7.81973e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               4.99419e-05
GaussianMLPPolicy/LossBefore              5.00531e-05
GaussianMLPPolicy/dLoss                   1.11111e-07
GaussianMLPValueFunction/LossAfter       -6.29904
GaussianMLPValueFunction/LossBefore      -6.57084
GaussianMLPValueFunction/dLoss           -0.271798
TotalEnvSteps                        525474
-----------------------------------  ----------------
2022-08-23 10:41:37 | [trpo_pendulum] epoch #263 | Saving snapshot...
2022-08-23 10:41:37 | [trpo_pendulum] epoch #263 | Saved
2022-08-23 10:41:37 | [trpo_pendulum] epoch #263 | Time 259.17 s
2022-08-23 10:41:37 | [trpo_pendulum] epoch #263 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000513549
Evaluation/AverageReturn                 -0.0051347
Evaluation/Iteration                    263
Evaluation/MaxReturn                     -0.00500963
Evaluation/MinReturn                     -0.00525977
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000125072
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.74202
GaussianMLPPolicy/KL                      4.87512e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000110224
GaussianMLPPolicy/LossBefore             -0.000110155
GaussianMLPPolicy/dLoss                   6.84231e-08
GaussianMLPValueFunction/LossAfter       -6.52893
GaussianMLPValueFunction/LossBefore      -6.37553
GaussianMLPValueFunction/dLoss            0.153405
TotalEnvSteps                        527472
-----------------------------------  ----------------
2022-08-23 10:41:38 | [trpo_pendulum] epoch #264 | Saving snapshot...
2022-08-23 10:41:38 | [trpo_pendulum] epoch #264 | Saved
2022-08-23 10:41:38 | [trpo_pendulum] epoch #264 | Time 260.17 s
2022-08-23 10:41:38 | [trpo_pendulum] epoch #264 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000497727
Evaluation/AverageReturn                 -0.00491529
Evaluation/Iteration                    264
Evaluation/MaxReturn                     -0.00483205
Evaluation/MinReturn                     -0.00499853
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.32395e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.74967
GaussianMLPPolicy/KL                      0.000224518
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.96286e-05
GaussianMLPPolicy/LossBefore             -3.93109e-05
GaussianMLPPolicy/dLoss                   3.17686e-07
GaussianMLPValueFunction/LossAfter       -6.20096
GaussianMLPValueFunction/LossBefore      -6.51318
GaussianMLPValueFunction/dLoss           -0.312214
TotalEnvSteps                        529470
-----------------------------------  ----------------
2022-08-23 10:41:39 | [trpo_pendulum] epoch #265 | Saving snapshot...
2022-08-23 10:41:39 | [trpo_pendulum] epoch #265 | Saved
2022-08-23 10:41:39 | [trpo_pendulum] epoch #265 | Time 261.20 s
2022-08-23 10:41:39 | [trpo_pendulum] epoch #265 | EpochTime 1.02 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000492866
Evaluation/AverageReturn                 -0.00480354
Evaluation/Iteration                    265
Evaluation/MaxReturn                     -0.0047259
Evaluation/MinReturn                     -0.00488118
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.76406e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.74967
GaussianMLPPolicy/KL                      0.000207239
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -8.87406e-05
GaussianMLPPolicy/LossBefore             -8.84431e-05
GaussianMLPPolicy/dLoss                   2.97507e-07
GaussianMLPValueFunction/LossAfter       -6.35911
GaussianMLPValueFunction/LossBefore      -6.27826
GaussianMLPValueFunction/dLoss            0.0808492
TotalEnvSteps                        531468
-----------------------------------  ----------------
2022-08-23 10:41:40 | [trpo_pendulum] epoch #266 | Saving snapshot...
2022-08-23 10:41:40 | [trpo_pendulum] epoch #266 | Saved
2022-08-23 10:41:40 | [trpo_pendulum] epoch #266 | Time 262.18 s
2022-08-23 10:41:40 | [trpo_pendulum] epoch #266 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000448262
Evaluation/AverageReturn                 -0.00445988
Evaluation/Iteration                    266
Evaluation/MaxReturn                     -0.00439696
Evaluation/MinReturn                     -0.0045228
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.2918e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.76038
GaussianMLPPolicy/KL                      0.00071981
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000205503
GaussianMLPPolicy/LossBefore             -0.000205078
GaussianMLPPolicy/dLoss                   4.248e-07
GaussianMLPValueFunction/LossAfter       -5.04813
GaussianMLPValueFunction/LossBefore      -6.00381
GaussianMLPValueFunction/dLoss           -0.955685
TotalEnvSteps                        533466
-----------------------------------  ----------------
2022-08-23 10:41:41 | [trpo_pendulum] epoch #267 | Saving snapshot...
2022-08-23 10:41:41 | [trpo_pendulum] epoch #267 | Saved
2022-08-23 10:41:41 | [trpo_pendulum] epoch #267 | Time 263.14 s
2022-08-23 10:41:41 | [trpo_pendulum] epoch #267 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000451497
Evaluation/AverageReturn                 -0.00471458
Evaluation/Iteration                    267
Evaluation/MaxReturn                     -0.00469926
Evaluation/MinReturn                     -0.00472991
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.53255e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.76772
GaussianMLPPolicy/KL                      0.000293299
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000394896
GaussianMLPPolicy/LossBefore              0.000395307
GaussianMLPPolicy/dLoss                   4.1051e-07
GaussianMLPValueFunction/LossAfter       -5.33702
GaussianMLPValueFunction/LossBefore      -4.1429
GaussianMLPValueFunction/dLoss            1.19412
TotalEnvSteps                        535464
-----------------------------------  ----------------
2022-08-23 10:41:42 | [trpo_pendulum] epoch #268 | Saving snapshot...
2022-08-23 10:41:42 | [trpo_pendulum] epoch #268 | Saved
2022-08-23 10:41:42 | [trpo_pendulum] epoch #268 | Time 264.07 s
2022-08-23 10:41:42 | [trpo_pendulum] epoch #268 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000435937
Evaluation/AverageReturn                 -0.00441662
Evaluation/Iteration                    268
Evaluation/MaxReturn                     -0.00434541
Evaluation/MinReturn                     -0.00448783
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.12098e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.76772
GaussianMLPPolicy/KL                      4.54427e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000397058
GaussianMLPPolicy/LossBefore             -0.000397052
GaussianMLPPolicy/dLoss                   6.28643e-09
GaussianMLPValueFunction/LossAfter       -6.64457
GaussianMLPValueFunction/LossBefore      -4.23146
GaussianMLPValueFunction/dLoss            2.41311
TotalEnvSteps                        537462
-----------------------------------  ----------------
2022-08-23 10:41:43 | [trpo_pendulum] epoch #269 | Saving snapshot...
2022-08-23 10:41:43 | [trpo_pendulum] epoch #269 | Saved
2022-08-23 10:41:43 | [trpo_pendulum] epoch #269 | Time 265.01 s
2022-08-23 10:41:43 | [trpo_pendulum] epoch #269 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000436302
Evaluation/AverageReturn                 -0.00433114
Evaluation/Iteration                    269
Evaluation/MaxReturn                     -0.00415683
Evaluation/MinReturn                     -0.00450546
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000174313
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.76772
GaussianMLPPolicy/KL                      1.73287e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -4.32189e-05
GaussianMLPPolicy/LossBefore             -4.31944e-05
GaussianMLPPolicy/dLoss                   2.44399e-08
GaussianMLPValueFunction/LossAfter       -6.68085
GaussianMLPValueFunction/LossBefore      -6.64259
GaussianMLPValueFunction/dLoss            0.0382552
TotalEnvSteps                        539460
-----------------------------------  ----------------
2022-08-23 10:41:44 | [trpo_pendulum] epoch #270 | Saving snapshot...
2022-08-23 10:41:44 | [trpo_pendulum] epoch #270 | Saved
2022-08-23 10:41:44 | [trpo_pendulum] epoch #270 | Time 265.97 s
2022-08-23 10:41:44 | [trpo_pendulum] epoch #270 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000474658
Evaluation/AverageReturn                 -0.00446014
Evaluation/Iteration                    270
Evaluation/MaxReturn                     -0.00435742
Evaluation/MinReturn                     -0.00456285
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000102714
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.76772
GaussianMLPPolicy/KL                      2.02428e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               9.26294e-07
GaussianMLPPolicy/LossBefore              9.54909e-07
GaussianMLPPolicy/dLoss                   2.86145e-08
GaussianMLPValueFunction/LossAfter       -6.6079
GaussianMLPValueFunction/LossBefore      -6.68395
GaussianMLPValueFunction/dLoss           -0.0760527
TotalEnvSteps                        541458
-----------------------------------  ----------------
2022-08-23 10:41:45 | [trpo_pendulum] epoch #271 | Saving snapshot...
2022-08-23 10:41:45 | [trpo_pendulum] epoch #271 | Saved
2022-08-23 10:41:45 | [trpo_pendulum] epoch #271 | Time 266.99 s
2022-08-23 10:41:45 | [trpo_pendulum] epoch #271 | EpochTime 1.02 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000432122
Evaluation/AverageReturn                 -0.00437816
Evaluation/Iteration                    271
Evaluation/MaxReturn                     -0.00422902
Evaluation/MinReturn                     -0.0045273
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000149141
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.76188
GaussianMLPPolicy/KL                      0.00047
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000121325
GaussianMLPPolicy/LossBefore              0.000121942
GaussianMLPPolicy/dLoss                   6.1655e-07
GaussianMLPValueFunction/LossAfter       -6.3346
GaussianMLPValueFunction/LossBefore      -6.12523
GaussianMLPValueFunction/dLoss            0.209371
TotalEnvSteps                        543456
-----------------------------------  ----------------
2022-08-23 10:41:46 | [trpo_pendulum] epoch #272 | Saving snapshot...
2022-08-23 10:41:46 | [trpo_pendulum] epoch #272 | Saved
2022-08-23 10:41:46 | [trpo_pendulum] epoch #272 | Time 267.99 s
2022-08-23 10:41:46 | [trpo_pendulum] epoch #272 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000435315
Evaluation/AverageReturn                 -0.00455161
Evaluation/Iteration                    272
Evaluation/MaxReturn                     -0.00444667
Evaluation/MinReturn                     -0.00465655
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000104939
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.76214
GaussianMLPPolicy/KL                      0.000370078
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000227324
GaussianMLPPolicy/LossBefore             -0.000226872
GaussianMLPPolicy/dLoss                   4.52346e-07
GaussianMLPValueFunction/LossAfter       -6.67588
GaussianMLPValueFunction/LossBefore      -5.86138
GaussianMLPValueFunction/dLoss            0.814506
TotalEnvSteps                        545454
-----------------------------------  ----------------
2022-08-23 10:41:47 | [trpo_pendulum] epoch #273 | Saving snapshot...
2022-08-23 10:41:47 | [trpo_pendulum] epoch #273 | Saved
2022-08-23 10:41:47 | [trpo_pendulum] epoch #273 | Time 268.98 s
2022-08-23 10:41:47 | [trpo_pendulum] epoch #273 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000410986
Evaluation/AverageReturn                 -0.00457728
Evaluation/Iteration                    273
Evaluation/MaxReturn                     -0.00455322
Evaluation/MinReturn                     -0.00460134
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.40623e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.76214
GaussianMLPPolicy/KL                      1.93503e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.05287e-06
GaussianMLPPolicy/LossBefore             -3.0255e-06
GaussianMLPPolicy/dLoss                   2.73728e-08
GaussianMLPValueFunction/LossAfter       -6.53689
GaussianMLPValueFunction/LossBefore      -6.67645
GaussianMLPValueFunction/dLoss           -0.139562
TotalEnvSteps                        547452
-----------------------------------  ----------------
2022-08-23 10:41:48 | [trpo_pendulum] epoch #274 | Saving snapshot...
2022-08-23 10:41:48 | [trpo_pendulum] epoch #274 | Saved
2022-08-23 10:41:48 | [trpo_pendulum] epoch #274 | Time 269.94 s
2022-08-23 10:41:48 | [trpo_pendulum] epoch #274 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000446476
Evaluation/AverageReturn                 -0.0046735
Evaluation/Iteration                    274
Evaluation/MaxReturn                     -0.00459609
Evaluation/MinReturn                     -0.00475091
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.74098e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.76214
GaussianMLPPolicy/KL                      4.26489e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000105155
GaussianMLPPolicy/LossBefore             -0.000105149
GaussianMLPPolicy/dLoss                   6.03177e-09
GaussianMLPValueFunction/LossAfter       -6.25799
GaussianMLPValueFunction/LossBefore      -6.49757
GaussianMLPValueFunction/dLoss           -0.239584
TotalEnvSteps                        549450
-----------------------------------  ----------------
2022-08-23 10:41:49 | [trpo_pendulum] epoch #275 | Saving snapshot...
2022-08-23 10:41:49 | [trpo_pendulum] epoch #275 | Saved
2022-08-23 10:41:49 | [trpo_pendulum] epoch #275 | Time 270.93 s
2022-08-23 10:41:49 | [trpo_pendulum] epoch #275 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000467089
Evaluation/AverageReturn                 -0.00462316
Evaluation/Iteration                    275
Evaluation/MaxReturn                     -0.00439786
Evaluation/MinReturn                     -0.00484847
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000225304
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.75625
GaussianMLPPolicy/KL                      0.000107413
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -6.64734e-05
GaussianMLPPolicy/LossBefore             -6.63108e-05
GaussianMLPPolicy/dLoss                   1.62603e-07
GaussianMLPValueFunction/LossAfter       -6.56454
GaussianMLPValueFunction/LossBefore      -6.52879
GaussianMLPValueFunction/dLoss            0.0357442
TotalEnvSteps                        551448
-----------------------------------  ----------------
2022-08-23 10:41:50 | [trpo_pendulum] epoch #276 | Saving snapshot...
2022-08-23 10:41:50 | [trpo_pendulum] epoch #276 | Saved
2022-08-23 10:41:50 | [trpo_pendulum] epoch #276 | Time 271.94 s
2022-08-23 10:41:50 | [trpo_pendulum] epoch #276 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000412468
Evaluation/AverageReturn                 -0.00440138
Evaluation/Iteration                    276
Evaluation/MaxReturn                     -0.00427004
Evaluation/MinReturn                     -0.00453273
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000131345
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.75625
GaussianMLPPolicy/KL                      8.88424e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000158852
GaussianMLPPolicy/LossBefore             -0.000158726
GaussianMLPPolicy/dLoss                   1.26136e-07
GaussianMLPValueFunction/LossAfter       -6.6846
GaussianMLPValueFunction/LossBefore      -6.27054
GaussianMLPValueFunction/dLoss            0.41406
TotalEnvSteps                        553446
-----------------------------------  ----------------
2022-08-23 10:41:51 | [trpo_pendulum] epoch #277 | Saving snapshot...
2022-08-23 10:41:51 | [trpo_pendulum] epoch #277 | Saved
2022-08-23 10:41:51 | [trpo_pendulum] epoch #277 | Time 272.95 s
2022-08-23 10:41:51 | [trpo_pendulum] epoch #277 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000409317
Evaluation/AverageReturn                 -0.00442594
Evaluation/Iteration                    277
Evaluation/MaxReturn                     -0.00416783
Evaluation/MinReturn                     -0.00468405
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000258111
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.75625
GaussianMLPPolicy/KL                      1.26392e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -2.68456e-05
GaussianMLPPolicy/LossBefore             -2.68278e-05
GaussianMLPPolicy/dLoss                   1.7817e-08
GaussianMLPValueFunction/LossAfter       -6.69725
GaussianMLPValueFunction/LossBefore      -6.68393
GaussianMLPValueFunction/dLoss            0.0133166
TotalEnvSteps                        555444
-----------------------------------  ----------------
2022-08-23 10:41:52 | [trpo_pendulum] epoch #278 | Saving snapshot...
2022-08-23 10:41:52 | [trpo_pendulum] epoch #278 | Saved
2022-08-23 10:41:52 | [trpo_pendulum] epoch #278 | Time 273.94 s
2022-08-23 10:41:52 | [trpo_pendulum] epoch #278 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000469057
Evaluation/AverageReturn                 -0.0044959
Evaluation/Iteration                    278
Evaluation/MaxReturn                     -0.00435291
Evaluation/MinReturn                     -0.0046389
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000142995
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.75625
GaussianMLPPolicy/KL                      1.84612e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               2.63306e-05
GaussianMLPPolicy/LossBefore              2.63567e-05
GaussianMLPPolicy/dLoss                   2.60898e-08
GaussianMLPValueFunction/LossAfter       -6.5383
GaussianMLPValueFunction/LossBefore      -6.69663
GaussianMLPValueFunction/dLoss           -0.158339
TotalEnvSteps                        557442
-----------------------------------  ----------------
2022-08-23 10:41:53 | [trpo_pendulum] epoch #279 | Saving snapshot...
2022-08-23 10:41:53 | [trpo_pendulum] epoch #279 | Saved
2022-08-23 10:41:53 | [trpo_pendulum] epoch #279 | Time 274.93 s
2022-08-23 10:41:53 | [trpo_pendulum] epoch #279 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000483673
Evaluation/AverageReturn                 -0.00478035
Evaluation/Iteration                    279
Evaluation/MaxReturn                     -0.00471644
Evaluation/MinReturn                     -0.00484426
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.39099e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.7645
GaussianMLPPolicy/KL                      0.000132423
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000181223
GaussianMLPPolicy/LossBefore              0.00018141
GaussianMLPPolicy/dLoss                   1.87531e-07
GaussianMLPValueFunction/LossAfter       -6.59886
GaussianMLPValueFunction/LossBefore      -6.09982
GaussianMLPValueFunction/dLoss            0.499037
TotalEnvSteps                        559440
-----------------------------------  ----------------
2022-08-23 10:41:54 | [trpo_pendulum] epoch #280 | Saving snapshot...
2022-08-23 10:41:54 | [trpo_pendulum] epoch #280 | Saved
2022-08-23 10:41:54 | [trpo_pendulum] epoch #280 | Time 275.88 s
2022-08-23 10:41:54 | [trpo_pendulum] epoch #280 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000373082
Evaluation/AverageReturn                 -0.00401662
Evaluation/Iteration                    280
Evaluation/MaxReturn                     -0.00394325
Evaluation/MinReturn                     -0.00409
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.33747e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.77515
GaussianMLPPolicy/KL                      0.000182742
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000157176
GaussianMLPPolicy/LossBefore             -0.000156919
GaussianMLPPolicy/dLoss                   2.57438e-07
GaussianMLPValueFunction/LossAfter       -6.49688
GaussianMLPValueFunction/LossBefore      -6.2862
GaussianMLPValueFunction/dLoss            0.210678
TotalEnvSteps                        561438
-----------------------------------  ----------------
2022-08-23 10:41:55 | [trpo_pendulum] epoch #281 | Saving snapshot...
2022-08-23 10:41:55 | [trpo_pendulum] epoch #281 | Saved
2022-08-23 10:41:55 | [trpo_pendulum] epoch #281 | Time 276.87 s
2022-08-23 10:41:55 | [trpo_pendulum] epoch #281 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000475529
Evaluation/AverageReturn                 -0.00459009
Evaluation/Iteration                    281
Evaluation/MaxReturn                     -0.00441545
Evaluation/MinReturn                     -0.00476472
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000174634
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.76682
GaussianMLPPolicy/KL                      0.000243031
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               6.61867e-05
GaussianMLPPolicy/LossBefore              6.65437e-05
GaussianMLPPolicy/dLoss                   3.57002e-07
GaussianMLPValueFunction/LossAfter       -6.49062
GaussianMLPValueFunction/LossBefore      -6.42439
GaussianMLPValueFunction/dLoss            0.0662317
TotalEnvSteps                        563436
-----------------------------------  ----------------
2022-08-23 10:41:56 | [trpo_pendulum] epoch #282 | Saving snapshot...
2022-08-23 10:41:56 | [trpo_pendulum] epoch #282 | Saved
2022-08-23 10:41:56 | [trpo_pendulum] epoch #282 | Time 277.85 s
2022-08-23 10:41:56 | [trpo_pendulum] epoch #282 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00043253
Evaluation/AverageReturn                 -0.00471332
Evaluation/Iteration                    282
Evaluation/MaxReturn                     -0.00464381
Evaluation/MinReturn                     -0.00478282
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.95041e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.76666
GaussianMLPPolicy/KL                      0.000203045
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               2.361e-05
GaussianMLPPolicy/LossBefore              2.3895e-05
GaussianMLPPolicy/dLoss                   2.85077e-07
GaussianMLPValueFunction/LossAfter       -6.25553
GaussianMLPValueFunction/LossBefore      -6.37428
GaussianMLPValueFunction/dLoss           -0.118757
TotalEnvSteps                        565434
-----------------------------------  ----------------
2022-08-23 10:41:57 | [trpo_pendulum] epoch #283 | Saving snapshot...
2022-08-23 10:41:57 | [trpo_pendulum] epoch #283 | Saved
2022-08-23 10:41:57 | [trpo_pendulum] epoch #283 | Time 278.86 s
2022-08-23 10:41:57 | [trpo_pendulum] epoch #283 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000415345
Evaluation/AverageReturn                 -0.0041081
Evaluation/Iteration                    283
Evaluation/MaxReturn                     -0.00389631
Evaluation/MinReturn                     -0.0043199
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000211796
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.77874
GaussianMLPPolicy/KL                      0.000147616
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000110268
GaussianMLPPolicy/LossBefore             -0.000110061
GaussianMLPPolicy/dLoss                   2.07132e-07
GaussianMLPValueFunction/LossAfter       -6.50336
GaussianMLPValueFunction/LossBefore      -6.47598
GaussianMLPValueFunction/dLoss            0.0273819
TotalEnvSteps                        567432
-----------------------------------  ----------------
2022-08-23 10:41:58 | [trpo_pendulum] epoch #284 | Saving snapshot...
2022-08-23 10:41:58 | [trpo_pendulum] epoch #284 | Saved
2022-08-23 10:41:58 | [trpo_pendulum] epoch #284 | Time 280.02 s
2022-08-23 10:41:58 | [trpo_pendulum] epoch #284 | EpochTime 1.15 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000398222
Evaluation/AverageReturn                 -0.00433225
Evaluation/Iteration                    284
Evaluation/MaxReturn                     -0.00423858
Evaluation/MinReturn                     -0.00442592
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      9.36719e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.77874
GaussianMLPPolicy/KL                      7.06064e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -8.82203e-05
GaussianMLPPolicy/LossBefore             -8.82101e-05
GaussianMLPPolicy/dLoss                   1.01281e-08
GaussianMLPValueFunction/LossAfter       -6.69155
GaussianMLPValueFunction/LossBefore      -6.56706
GaussianMLPValueFunction/dLoss            0.12449
TotalEnvSteps                        569430
-----------------------------------  ----------------
2022-08-23 10:41:59 | [trpo_pendulum] epoch #285 | Saving snapshot...
2022-08-23 10:41:59 | [trpo_pendulum] epoch #285 | Saved
2022-08-23 10:41:59 | [trpo_pendulum] epoch #285 | Time 280.97 s
2022-08-23 10:41:59 | [trpo_pendulum] epoch #285 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000394036
Evaluation/AverageReturn                 -0.00425386
Evaluation/Iteration                    285
Evaluation/MaxReturn                     -0.00417228
Evaluation/MinReturn                     -0.00433544
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.15785e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.77874
GaussianMLPPolicy/KL                      1.03073e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -4.52444e-05
GaussianMLPPolicy/LossBefore             -4.52299e-05
GaussianMLPPolicy/dLoss                   1.44501e-08
GaussianMLPValueFunction/LossAfter       -6.58475
GaussianMLPValueFunction/LossBefore      -6.6756
GaussianMLPValueFunction/dLoss           -0.0908537
TotalEnvSteps                        571428
-----------------------------------  ----------------
2022-08-23 10:42:00 | [trpo_pendulum] epoch #286 | Saving snapshot...
2022-08-23 10:42:00 | [trpo_pendulum] epoch #286 | Saved
2022-08-23 10:42:00 | [trpo_pendulum] epoch #286 | Time 281.94 s
2022-08-23 10:42:00 | [trpo_pendulum] epoch #286 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000437827
Evaluation/AverageReturn                 -0.00428334
Evaluation/Iteration                    286
Evaluation/MaxReturn                     -0.00419623
Evaluation/MinReturn                     -0.00437045
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.71079e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.78336
GaussianMLPPolicy/KL                      5.04305e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000101208
GaussianMLPPolicy/LossBefore              0.00010128
GaussianMLPPolicy/dLoss                   7.16173e-08
GaussianMLPValueFunction/LossAfter       -6.70055
GaussianMLPValueFunction/LossBefore      -6.54103
GaussianMLPValueFunction/dLoss            0.159519
TotalEnvSteps                        573426
-----------------------------------  ----------------
2022-08-23 10:42:01 | [trpo_pendulum] epoch #287 | Saving snapshot...
2022-08-23 10:42:01 | [trpo_pendulum] epoch #287 | Saved
2022-08-23 10:42:01 | [trpo_pendulum] epoch #287 | Time 282.88 s
2022-08-23 10:42:01 | [trpo_pendulum] epoch #287 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00042063
Evaluation/AverageReturn                 -0.00410695
Evaluation/Iteration                    287
Evaluation/MaxReturn                     -0.00407801
Evaluation/MinReturn                     -0.00413589
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.89382e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.78336
GaussianMLPPolicy/KL                      1.5435e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -5.7153e-05
GaussianMLPPolicy/LossBefore             -5.71314e-05
GaussianMLPPolicy/dLoss                   2.16824e-08
GaussianMLPValueFunction/LossAfter       -6.66832
GaussianMLPValueFunction/LossBefore      -6.66154
GaussianMLPValueFunction/dLoss            0.00678015
TotalEnvSteps                        575424
-----------------------------------  ----------------
2022-08-23 10:42:02 | [trpo_pendulum] epoch #288 | Saving snapshot...
2022-08-23 10:42:02 | [trpo_pendulum] epoch #288 | Saved
2022-08-23 10:42:02 | [trpo_pendulum] epoch #288 | Time 283.85 s
2022-08-23 10:42:02 | [trpo_pendulum] epoch #288 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000428152
Evaluation/AverageReturn                 -0.00421584
Evaluation/Iteration                    288
Evaluation/MaxReturn                     -0.00410757
Evaluation/MinReturn                     -0.00432411
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000108272
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.78336
GaussianMLPPolicy/KL                      3.9811e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               6.37209e-05
GaussianMLPPolicy/LossBefore              6.37771e-05
GaussianMLPPolicy/dLoss                   5.61922e-08
GaussianMLPValueFunction/LossAfter       -6.72867
GaussianMLPValueFunction/LossBefore      -6.661
GaussianMLPValueFunction/dLoss            0.0676689
TotalEnvSteps                        577422
-----------------------------------  ----------------
2022-08-23 10:42:03 | [trpo_pendulum] epoch #289 | Saving snapshot...
2022-08-23 10:42:03 | [trpo_pendulum] epoch #289 | Saved
2022-08-23 10:42:03 | [trpo_pendulum] epoch #289 | Time 284.82 s
2022-08-23 10:42:03 | [trpo_pendulum] epoch #289 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000427978
Evaluation/AverageReturn                 -0.00423435
Evaluation/Iteration                    289
Evaluation/MaxReturn                     -0.00414198
Evaluation/MinReturn                     -0.00432672
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      9.23727e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.78336
GaussianMLPPolicy/KL                      5.18045e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -9.70442e-06
GaussianMLPPolicy/LossBefore             -9.63133e-06
GaussianMLPPolicy/dLoss                   7.30952e-08
GaussianMLPValueFunction/LossAfter       -6.69405
GaussianMLPValueFunction/LossBefore      -6.72315
GaussianMLPValueFunction/dLoss           -0.0290999
TotalEnvSteps                        579420
-----------------------------------  ----------------
2022-08-23 10:42:04 | [trpo_pendulum] epoch #290 | Saving snapshot...
2022-08-23 10:42:04 | [trpo_pendulum] epoch #290 | Saved
2022-08-23 10:42:04 | [trpo_pendulum] epoch #290 | Time 285.78 s
2022-08-23 10:42:04 | [trpo_pendulum] epoch #290 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00036609
Evaluation/AverageReturn                 -0.00390015
Evaluation/Iteration                    290
Evaluation/MaxReturn                     -0.00369241
Evaluation/MinReturn                     -0.0041079
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000207745
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.783
GaussianMLPPolicy/KL                      5.56392e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000115133
GaussianMLPPolicy/LossBefore              0.000115212
GaussianMLPPolicy/dLoss                   7.89369e-08
GaussianMLPValueFunction/LossAfter       -6.36865
GaussianMLPValueFunction/LossBefore      -6.4427
GaussianMLPValueFunction/dLoss           -0.0740504
TotalEnvSteps                        581418
-----------------------------------  ----------------
2022-08-23 10:42:05 | [trpo_pendulum] epoch #291 | Saving snapshot...
2022-08-23 10:42:05 | [trpo_pendulum] epoch #291 | Saved
2022-08-23 10:42:05 | [trpo_pendulum] epoch #291 | Time 286.78 s
2022-08-23 10:42:05 | [trpo_pendulum] epoch #291 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000410109
Evaluation/AverageReturn                 -0.00439982
Evaluation/Iteration                    291
Evaluation/MaxReturn                     -0.0042921
Evaluation/MinReturn                     -0.00450755
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000107724
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.78857
GaussianMLPPolicy/KL                      0.000134015
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -9.89928e-05
GaussianMLPPolicy/LossBefore             -9.88029e-05
GaussianMLPPolicy/dLoss                   1.89881e-07
GaussianMLPValueFunction/LossAfter       -6.08664
GaussianMLPValueFunction/LossBefore      -6.48429
GaussianMLPValueFunction/dLoss           -0.397645
TotalEnvSteps                        583416
-----------------------------------  ----------------
2022-08-23 10:42:06 | [trpo_pendulum] epoch #292 | Saving snapshot...
2022-08-23 10:42:06 | [trpo_pendulum] epoch #292 | Saved
2022-08-23 10:42:06 | [trpo_pendulum] epoch #292 | Time 287.77 s
2022-08-23 10:42:06 | [trpo_pendulum] epoch #292 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000384492
Evaluation/AverageReturn                 -0.00387661
Evaluation/Iteration                    292
Evaluation/MaxReturn                     -0.00373894
Evaluation/MinReturn                     -0.00401428
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000137672
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.78857
GaussianMLPPolicy/KL                      5.60009e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000133877
GaussianMLPPolicy/LossBefore              0.000133878
GaussianMLPPolicy/dLoss                   8.73115e-10
GaussianMLPValueFunction/LossAfter       -6.66253
GaussianMLPValueFunction/LossBefore      -6.37507
GaussianMLPValueFunction/dLoss            0.287456
TotalEnvSteps                        585414
-----------------------------------  ----------------
2022-08-23 10:42:07 | [trpo_pendulum] epoch #293 | Saving snapshot...
2022-08-23 10:42:07 | [trpo_pendulum] epoch #293 | Saved
2022-08-23 10:42:07 | [trpo_pendulum] epoch #293 | Time 288.75 s
2022-08-23 10:42:07 | [trpo_pendulum] epoch #293 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00040635
Evaluation/AverageReturn                 -0.00433552
Evaluation/Iteration                    293
Evaluation/MaxReturn                     -0.00422692
Evaluation/MinReturn                     -0.00444413
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000108606
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.79955
GaussianMLPPolicy/KL                      0.000155024
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               9.66843e-05
GaussianMLPPolicy/LossBefore              9.68976e-05
GaussianMLPPolicy/dLoss                   2.13302e-07
GaussianMLPValueFunction/LossAfter       -6.21979
GaussianMLPValueFunction/LossBefore      -6.47072
GaussianMLPValueFunction/dLoss           -0.250932
TotalEnvSteps                        587412
-----------------------------------  ----------------
2022-08-23 10:42:08 | [trpo_pendulum] epoch #294 | Saving snapshot...
2022-08-23 10:42:08 | [trpo_pendulum] epoch #294 | Saved
2022-08-23 10:42:08 | [trpo_pendulum] epoch #294 | Time 289.70 s
2022-08-23 10:42:08 | [trpo_pendulum] epoch #294 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000430763
Evaluation/AverageReturn                 -0.00417979
Evaluation/Iteration                    294
Evaluation/MaxReturn                     -0.00409964
Evaluation/MinReturn                     -0.00425994
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.01526e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.80693
GaussianMLPPolicy/KL                      0.000111102
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000107876
GaussianMLPPolicy/LossBefore              0.000108033
GaussianMLPPolicy/dLoss                   1.56324e-07
GaussianMLPValueFunction/LossAfter       -6.70467
GaussianMLPValueFunction/LossBefore      -6.4933
GaussianMLPValueFunction/dLoss            0.211364
TotalEnvSteps                        589410
-----------------------------------  ----------------
2022-08-23 10:42:09 | [trpo_pendulum] epoch #295 | Saving snapshot...
2022-08-23 10:42:09 | [trpo_pendulum] epoch #295 | Saved
2022-08-23 10:42:09 | [trpo_pendulum] epoch #295 | Time 290.64 s
2022-08-23 10:42:09 | [trpo_pendulum] epoch #295 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000405344
Evaluation/AverageReturn                 -0.00365353
Evaluation/Iteration                    295
Evaluation/MaxReturn                     -0.00362032
Evaluation/MinReturn                     -0.00368674
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.32116e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.80693
GaussianMLPPolicy/KL                      7.03595e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -9.72889e-05
GaussianMLPPolicy/LossBefore             -9.71894e-05
GaussianMLPPolicy/dLoss                   9.94405e-08
GaussianMLPValueFunction/LossAfter       -6.72124
GaussianMLPValueFunction/LossBefore      -6.56444
GaussianMLPValueFunction/dLoss            0.156802
TotalEnvSteps                        591408
-----------------------------------  ----------------
2022-08-23 10:42:10 | [trpo_pendulum] epoch #296 | Saving snapshot...
2022-08-23 10:42:10 | [trpo_pendulum] epoch #296 | Saved
2022-08-23 10:42:10 | [trpo_pendulum] epoch #296 | Time 291.63 s
2022-08-23 10:42:10 | [trpo_pendulum] epoch #296 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000372308
Evaluation/AverageReturn                 -0.00374036
Evaluation/Iteration                    296
Evaluation/MaxReturn                     -0.00361639
Evaluation/MinReturn                     -0.00386434
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000123974
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.80693
GaussianMLPPolicy/KL                      4.58898e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               3.07822e-05
GaussianMLPPolicy/LossBefore              3.08471e-05
GaussianMLPPolicy/dLoss                   6.49416e-08
GaussianMLPValueFunction/LossAfter       -5.39501
GaussianMLPValueFunction/LossBefore      -6.69924
GaussianMLPValueFunction/dLoss           -1.30423
TotalEnvSteps                        593406
-----------------------------------  ----------------
2022-08-23 10:42:11 | [trpo_pendulum] epoch #297 | Saving snapshot...
2022-08-23 10:42:11 | [trpo_pendulum] epoch #297 | Saved
2022-08-23 10:42:11 | [trpo_pendulum] epoch #297 | Time 292.66 s
2022-08-23 10:42:11 | [trpo_pendulum] epoch #297 | EpochTime 1.02 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000367591
Evaluation/AverageReturn                 -0.00379167
Evaluation/Iteration                    297
Evaluation/MaxReturn                     -0.0036042
Evaluation/MinReturn                     -0.00397913
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000187464
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.80693
GaussianMLPPolicy/KL                      9.86926e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000319219
GaussianMLPPolicy/LossBefore             -0.000319079
GaussianMLPPolicy/dLoss                   1.40106e-07
GaussianMLPValueFunction/LossAfter       -6.68145
GaussianMLPValueFunction/LossBefore      -4.85783
GaussianMLPValueFunction/dLoss            1.82362
TotalEnvSteps                        595404
-----------------------------------  ----------------
2022-08-23 10:42:12 | [trpo_pendulum] epoch #298 | Saving snapshot...
2022-08-23 10:42:12 | [trpo_pendulum] epoch #298 | Saved
2022-08-23 10:42:12 | [trpo_pendulum] epoch #298 | Time 293.67 s
2022-08-23 10:42:12 | [trpo_pendulum] epoch #298 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000395308
Evaluation/AverageReturn                 -0.00370925
Evaluation/Iteration                    298
Evaluation/MaxReturn                     -0.00365387
Evaluation/MinReturn                     -0.00376462
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.53719e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.80693
GaussianMLPPolicy/KL                      9.32132e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -5.27417e-05
GaussianMLPPolicy/LossBefore             -5.27284e-05
GaussianMLPPolicy/dLoss                   1.32095e-08
GaussianMLPValueFunction/LossAfter       -6.65881
GaussianMLPValueFunction/LossBefore      -6.70234
GaussianMLPValueFunction/dLoss           -0.0435247
TotalEnvSteps                        597402
-----------------------------------  ----------------
2022-08-23 10:42:13 | [trpo_pendulum] epoch #299 | Saving snapshot...
2022-08-23 10:42:13 | [trpo_pendulum] epoch #299 | Saved
2022-08-23 10:42:13 | [trpo_pendulum] epoch #299 | Time 294.66 s
2022-08-23 10:42:13 | [trpo_pendulum] epoch #299 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000351935
Evaluation/AverageReturn                 -0.00386982
Evaluation/Iteration                    299
Evaluation/MaxReturn                     -0.00385813
Evaluation/MinReturn                     -0.0038815
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.16855e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.82266
GaussianMLPPolicy/KL                      0.000344407
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000146445
GaussianMLPPolicy/LossBefore              0.000146925
GaussianMLPPolicy/dLoss                   4.79398e-07
GaussianMLPValueFunction/LossAfter       -6.31761
GaussianMLPValueFunction/LossBefore      -6.27411
GaussianMLPValueFunction/dLoss            0.0435033
TotalEnvSteps                        599400
-----------------------------------  ----------------
2022-08-23 10:42:14 | [trpo_pendulum] epoch #300 | Saving snapshot...
2022-08-23 10:42:14 | [trpo_pendulum] epoch #300 | Saved
2022-08-23 10:42:14 | [trpo_pendulum] epoch #300 | Time 295.62 s
2022-08-23 10:42:14 | [trpo_pendulum] epoch #300 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000327692
Evaluation/AverageReturn                 -0.00410149
Evaluation/Iteration                    300
Evaluation/MaxReturn                     -0.00408156
Evaluation/MinReturn                     -0.00412141
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.99253e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.82262
GaussianMLPPolicy/KL                      3.57585e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -7.07395e-05
GaussianMLPPolicy/LossBefore             -7.06886e-05
GaussianMLPPolicy/dLoss                   5.08589e-08
GaussianMLPValueFunction/LossAfter       -6.25921
GaussianMLPValueFunction/LossBefore      -6.4606
GaussianMLPValueFunction/dLoss           -0.201393
TotalEnvSteps                        601398
-----------------------------------  ----------------
2022-08-23 10:42:15 | [trpo_pendulum] epoch #301 | Saving snapshot...
2022-08-23 10:42:15 | [trpo_pendulum] epoch #301 | Saved
2022-08-23 10:42:15 | [trpo_pendulum] epoch #301 | Time 296.63 s
2022-08-23 10:42:15 | [trpo_pendulum] epoch #301 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00042535
Evaluation/AverageReturn                 -0.00409269
Evaluation/Iteration                    301
Evaluation/MaxReturn                     -0.00376891
Evaluation/MinReturn                     -0.00441648
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000323783
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.82968
GaussianMLPPolicy/KL                      6.92224e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000161187
GaussianMLPPolicy/LossBefore             -0.000161091
GaussianMLPPolicy/dLoss                   9.6552e-08
GaussianMLPValueFunction/LossAfter       -6.61098
GaussianMLPValueFunction/LossBefore      -6.15291
GaussianMLPValueFunction/dLoss            0.458068
TotalEnvSteps                        603396
-----------------------------------  ----------------
2022-08-23 10:42:16 | [trpo_pendulum] epoch #302 | Saving snapshot...
2022-08-23 10:42:16 | [trpo_pendulum] epoch #302 | Saved
2022-08-23 10:42:16 | [trpo_pendulum] epoch #302 | Time 297.61 s
2022-08-23 10:42:16 | [trpo_pendulum] epoch #302 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000360722
Evaluation/AverageReturn                 -0.0035638
Evaluation/Iteration                    302
Evaluation/MaxReturn                     -0.00347924
Evaluation/MinReturn                     -0.00364836
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.45605e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.82968
GaussianMLPPolicy/KL                      2.28962e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000108414
GaussianMLPPolicy/LossBefore             -0.000108381
GaussianMLPPolicy/dLoss                   3.23998e-08
GaussianMLPValueFunction/LossAfter       -6.52448
GaussianMLPValueFunction/LossBefore      -6.52193
GaussianMLPValueFunction/dLoss            0.00254965
TotalEnvSteps                        605394
-----------------------------------  ----------------
2022-08-23 10:42:17 | [trpo_pendulum] epoch #303 | Saving snapshot...
2022-08-23 10:42:17 | [trpo_pendulum] epoch #303 | Saved
2022-08-23 10:42:17 | [trpo_pendulum] epoch #303 | Time 298.59 s
2022-08-23 10:42:17 | [trpo_pendulum] epoch #303 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000313091
Evaluation/AverageReturn                 -0.00354614
Evaluation/Iteration                    303
Evaluation/MaxReturn                     -0.00347739
Evaluation/MinReturn                     -0.0036149
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.87551e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.82968
GaussianMLPPolicy/KL                      4.99996e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000119404
GaussianMLPPolicy/LossBefore              0.000119475
GaussianMLPPolicy/dLoss                   7.09115e-08
GaussianMLPValueFunction/LossAfter       -6.74516
GaussianMLPValueFunction/LossBefore      -6.48268
GaussianMLPValueFunction/dLoss            0.262476
TotalEnvSteps                        607392
-----------------------------------  ----------------
2022-08-23 10:42:18 | [trpo_pendulum] epoch #304 | Saving snapshot...
2022-08-23 10:42:18 | [trpo_pendulum] epoch #304 | Saved
2022-08-23 10:42:18 | [trpo_pendulum] epoch #304 | Time 299.59 s
2022-08-23 10:42:18 | [trpo_pendulum] epoch #304 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00034474
Evaluation/AverageReturn                 -0.0037924
Evaluation/Iteration                    304
Evaluation/MaxReturn                     -0.00376314
Evaluation/MinReturn                     -0.00382165
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.92586e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.83007
GaussianMLPPolicy/KL                      2.68754e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               4.98698e-05
GaussianMLPPolicy/LossBefore              4.99077e-05
GaussianMLPPolicy/dLoss                   3.79077e-08
GaussianMLPValueFunction/LossAfter       -6.58108
GaussianMLPValueFunction/LossBefore      -6.66059
GaussianMLPValueFunction/dLoss           -0.0795045
TotalEnvSteps                        609390
-----------------------------------  ----------------
2022-08-23 10:42:19 | [trpo_pendulum] epoch #305 | Saving snapshot...
2022-08-23 10:42:19 | [trpo_pendulum] epoch #305 | Saved
2022-08-23 10:42:19 | [trpo_pendulum] epoch #305 | Time 300.54 s
2022-08-23 10:42:19 | [trpo_pendulum] epoch #305 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000310825
Evaluation/AverageReturn                 -0.00337465
Evaluation/Iteration                    305
Evaluation/MaxReturn                     -0.003337
Evaluation/MinReturn                     -0.0034123
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.76501e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.8346
GaussianMLPPolicy/KL                      8.08676e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000151147
GaussianMLPPolicy/LossBefore             -0.000151032
GaussianMLPPolicy/dLoss                   1.14916e-07
GaussianMLPValueFunction/LossAfter       -6.5565
GaussianMLPValueFunction/LossBefore      -6.33026
GaussianMLPValueFunction/dLoss            0.226244
TotalEnvSteps                        611388
-----------------------------------  ----------------
2022-08-23 10:42:20 | [trpo_pendulum] epoch #306 | Saving snapshot...
2022-08-23 10:42:20 | [trpo_pendulum] epoch #306 | Saved
2022-08-23 10:42:20 | [trpo_pendulum] epoch #306 | Time 301.50 s
2022-08-23 10:42:20 | [trpo_pendulum] epoch #306 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000330111
Evaluation/AverageReturn                 -0.0039552
Evaluation/Iteration                    306
Evaluation/MaxReturn                     -0.00389445
Evaluation/MinReturn                     -0.00401595
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.0751e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.83526
GaussianMLPPolicy/KL                      0.000236367
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               7.90233e-05
GaussianMLPPolicy/LossBefore              7.93827e-05
GaussianMLPPolicy/dLoss                   3.59374e-07
GaussianMLPValueFunction/LossAfter       -6.45942
GaussianMLPValueFunction/LossBefore      -6.34766
GaussianMLPValueFunction/dLoss            0.111762
TotalEnvSteps                        613386
-----------------------------------  ----------------
2022-08-23 10:42:21 | [trpo_pendulum] epoch #307 | Saving snapshot...
2022-08-23 10:42:21 | [trpo_pendulum] epoch #307 | Saved
2022-08-23 10:42:21 | [trpo_pendulum] epoch #307 | Time 302.49 s
2022-08-23 10:42:21 | [trpo_pendulum] epoch #307 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000325098
Evaluation/AverageReturn                 -0.00346349
Evaluation/Iteration                    307
Evaluation/MaxReturn                     -0.00336264
Evaluation/MinReturn                     -0.00356434
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000100853
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.83542
GaussianMLPPolicy/KL                      1.85761e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000125979
GaussianMLPPolicy/LossBefore             -0.000125953
GaussianMLPPolicy/dLoss                   2.60334e-08
GaussianMLPValueFunction/LossAfter       -5.43582
GaussianMLPValueFunction/LossBefore      -6.37611
GaussianMLPValueFunction/dLoss           -0.940293
TotalEnvSteps                        615384
-----------------------------------  ----------------
2022-08-23 10:42:22 | [trpo_pendulum] epoch #308 | Saving snapshot...
2022-08-23 10:42:22 | [trpo_pendulum] epoch #308 | Saved
2022-08-23 10:42:22 | [trpo_pendulum] epoch #308 | Time 303.45 s
2022-08-23 10:42:22 | [trpo_pendulum] epoch #308 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000372677
Evaluation/AverageReturn                 -0.00376242
Evaluation/Iteration                    308
Evaluation/MaxReturn                     -0.0037348
Evaluation/MinReturn                     -0.00379003
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.76128e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.83601
GaussianMLPPolicy/KL                      0.000194126
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000248223
GaussianMLPPolicy/LossBefore              0.000248505
GaussianMLPPolicy/dLoss                   2.81841e-07
GaussianMLPValueFunction/LossAfter       -6.63786
GaussianMLPValueFunction/LossBefore      -5.5825
GaussianMLPValueFunction/dLoss            1.05536
TotalEnvSteps                        617382
-----------------------------------  ----------------
2022-08-23 10:42:23 | [trpo_pendulum] epoch #309 | Saving snapshot...
2022-08-23 10:42:23 | [trpo_pendulum] epoch #309 | Saved
2022-08-23 10:42:23 | [trpo_pendulum] epoch #309 | Time 304.54 s
2022-08-23 10:42:23 | [trpo_pendulum] epoch #309 | EpochTime 1.09 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000374353
Evaluation/AverageReturn                 -0.00355904
Evaluation/Iteration                    309
Evaluation/MaxReturn                     -0.00352388
Evaluation/MinReturn                     -0.0035942
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.51594e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.83601
GaussianMLPPolicy/KL                      4.28161e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               2.46707e-05
GaussianMLPPolicy/LossBefore              2.47311e-05
GaussianMLPPolicy/dLoss                   6.03959e-08
GaussianMLPValueFunction/LossAfter       -6.72965
GaussianMLPValueFunction/LossBefore      -6.70586
GaussianMLPValueFunction/dLoss            0.0237913
TotalEnvSteps                        619380
-----------------------------------  ----------------
2022-08-23 10:42:24 | [trpo_pendulum] epoch #310 | Saving snapshot...
2022-08-23 10:42:24 | [trpo_pendulum] epoch #310 | Saved
2022-08-23 10:42:24 | [trpo_pendulum] epoch #310 | Time 305.51 s
2022-08-23 10:42:24 | [trpo_pendulum] epoch #310 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000360452
Evaluation/AverageReturn                 -0.00354373
Evaluation/Iteration                    310
Evaluation/MaxReturn                     -0.00353509
Evaluation/MinReturn                     -0.00355237
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.6386e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.83601
GaussianMLPPolicy/KL                      4.87021e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               2.72166e-05
GaussianMLPPolicy/LossBefore              2.72858e-05
GaussianMLPPolicy/dLoss                   6.91398e-08
GaussianMLPValueFunction/LossAfter       -5.83475
GaussianMLPValueFunction/LossBefore      -6.67879
GaussianMLPValueFunction/dLoss           -0.84404
TotalEnvSteps                        621378
-----------------------------------  ----------------
2022-08-23 10:42:25 | [trpo_pendulum] epoch #311 | Saving snapshot...
2022-08-23 10:42:25 | [trpo_pendulum] epoch #311 | Saved
2022-08-23 10:42:25 | [trpo_pendulum] epoch #311 | Time 306.48 s
2022-08-23 10:42:25 | [trpo_pendulum] epoch #311 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000353429
Evaluation/AverageReturn                 -0.00349434
Evaluation/Iteration                    311
Evaluation/MaxReturn                     -0.00326508
Evaluation/MinReturn                     -0.0037236
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000229261
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.83601
GaussianMLPPolicy/KL                      3.0805e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00018311
GaussianMLPPolicy/LossBefore              0.000183114
GaussianMLPPolicy/dLoss                   4.23461e-09
GaussianMLPValueFunction/LossAfter       -6.57638
GaussianMLPValueFunction/LossBefore      -6.1214
GaussianMLPValueFunction/dLoss            0.454979
TotalEnvSteps                        623376
-----------------------------------  ----------------
2022-08-23 10:42:26 | [trpo_pendulum] epoch #312 | Saving snapshot...
2022-08-23 10:42:26 | [trpo_pendulum] epoch #312 | Saved
2022-08-23 10:42:26 | [trpo_pendulum] epoch #312 | Time 307.54 s
2022-08-23 10:42:26 | [trpo_pendulum] epoch #312 | EpochTime 1.06 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000340315
Evaluation/AverageReturn                 -0.0032154
Evaluation/Iteration                    312
Evaluation/MaxReturn                     -0.00317511
Evaluation/MinReturn                     -0.00325569
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.02906e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.83601
GaussianMLPPolicy/KL                      5.23195e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000150452
GaussianMLPPolicy/LossBefore             -0.000150379
GaussianMLPPolicy/dLoss                   7.35163e-08
GaussianMLPValueFunction/LossAfter       -6.44256
GaussianMLPValueFunction/LossBefore      -6.33196
GaussianMLPValueFunction/dLoss            0.110601
TotalEnvSteps                        625374
-----------------------------------  ----------------
2022-08-23 10:42:27 | [trpo_pendulum] epoch #313 | Saving snapshot...
2022-08-23 10:42:27 | [trpo_pendulum] epoch #313 | Saved
2022-08-23 10:42:27 | [trpo_pendulum] epoch #313 | Time 308.52 s
2022-08-23 10:42:27 | [trpo_pendulum] epoch #313 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000367523
Evaluation/AverageReturn                 -0.00387438
Evaluation/Iteration                    313
Evaluation/MaxReturn                     -0.00379199
Evaluation/MinReturn                     -0.00395677
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.23926e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.83545
GaussianMLPPolicy/KL                      0.000292287
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               9.48861e-05
GaussianMLPPolicy/LossBefore              9.52805e-05
GaussianMLPPolicy/dLoss                   3.9435e-07
GaussianMLPValueFunction/LossAfter       -6.42905
GaussianMLPValueFunction/LossBefore      -6.21238
GaussianMLPValueFunction/dLoss            0.216674
TotalEnvSteps                        627372
-----------------------------------  ----------------
2022-08-23 10:42:28 | [trpo_pendulum] epoch #314 | Saving snapshot...
2022-08-23 10:42:28 | [trpo_pendulum] epoch #314 | Saved
2022-08-23 10:42:28 | [trpo_pendulum] epoch #314 | Time 309.55 s
2022-08-23 10:42:28 | [trpo_pendulum] epoch #314 | EpochTime 1.03 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000354943
Evaluation/AverageReturn                 -0.00349559
Evaluation/Iteration                    314
Evaluation/MaxReturn                     -0.00349103
Evaluation/MinReturn                     -0.00350015
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.55966e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.84007
GaussianMLPPolicy/KL                      0.000155059
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000155579
GaussianMLPPolicy/LossBefore             -0.000155384
GaussianMLPPolicy/dLoss                   1.94734e-07
GaussianMLPValueFunction/LossAfter       -6.7047
GaussianMLPValueFunction/LossBefore      -6.29458
GaussianMLPValueFunction/dLoss            0.41012
TotalEnvSteps                        629370
-----------------------------------  ----------------
2022-08-23 10:42:29 | [trpo_pendulum] epoch #315 | Saving snapshot...
2022-08-23 10:42:29 | [trpo_pendulum] epoch #315 | Saved
2022-08-23 10:42:29 | [trpo_pendulum] epoch #315 | Time 310.50 s
2022-08-23 10:42:29 | [trpo_pendulum] epoch #315 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000317916
Evaluation/AverageReturn                 -0.00326379
Evaluation/Iteration                    315
Evaluation/MaxReturn                     -0.00324266
Evaluation/MinReturn                     -0.00328492
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.11305e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.84007
GaussianMLPPolicy/KL                      7.82867e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               5.71318e-07
GaussianMLPPolicy/LossBefore              5.82324e-07
GaussianMLPPolicy/dLoss                   1.1006e-08
GaussianMLPValueFunction/LossAfter       -6.75234
GaussianMLPValueFunction/LossBefore      -6.75445
GaussianMLPValueFunction/dLoss           -0.00211191
TotalEnvSteps                        631368
-----------------------------------  ----------------
2022-08-23 10:42:30 | [trpo_pendulum] epoch #316 | Saving snapshot...
2022-08-23 10:42:30 | [trpo_pendulum] epoch #316 | Saved
2022-08-23 10:42:30 | [trpo_pendulum] epoch #316 | Time 311.51 s
2022-08-23 10:42:30 | [trpo_pendulum] epoch #316 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000363105
Evaluation/AverageReturn                 -0.00320123
Evaluation/Iteration                    316
Evaluation/MaxReturn                     -0.00313139
Evaluation/MinReturn                     -0.00327107
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.98395e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.84007
GaussianMLPPolicy/KL                      5.16702e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               1.9314e-05
GaussianMLPPolicy/LossBefore              1.93213e-05
GaussianMLPPolicy/dLoss                   7.25777e-09
GaussianMLPValueFunction/LossAfter       -6.66001
GaussianMLPValueFunction/LossBefore      -6.75637
GaussianMLPValueFunction/dLoss           -0.0963607
TotalEnvSteps                        633366
-----------------------------------  ----------------
2022-08-23 10:42:31 | [trpo_pendulum] epoch #317 | Saving snapshot...
2022-08-23 10:42:31 | [trpo_pendulum] epoch #317 | Saved
2022-08-23 10:42:31 | [trpo_pendulum] epoch #317 | Time 312.45 s
2022-08-23 10:42:31 | [trpo_pendulum] epoch #317 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000369028
Evaluation/AverageReturn                 -0.00368148
Evaluation/Iteration                    317
Evaluation/MaxReturn                     -0.00340774
Evaluation/MinReturn                     -0.00395522
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000273741
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.84007
GaussianMLPPolicy/KL                      6.34345e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -4.10293e-05
GaussianMLPPolicy/LossBefore             -4.10203e-05
GaussianMLPPolicy/dLoss                   8.96762e-09
GaussianMLPValueFunction/LossAfter       -6.72125
GaussianMLPValueFunction/LossBefore      -6.72498
GaussianMLPValueFunction/dLoss           -0.00373268
TotalEnvSteps                        635364
-----------------------------------  ----------------
2022-08-23 10:42:32 | [trpo_pendulum] epoch #318 | Saving snapshot...
2022-08-23 10:42:32 | [trpo_pendulum] epoch #318 | Saved
2022-08-23 10:42:32 | [trpo_pendulum] epoch #318 | Time 313.46 s
2022-08-23 10:42:32 | [trpo_pendulum] epoch #318 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000318006
Evaluation/AverageReturn                 -0.00305529
Evaluation/Iteration                    318
Evaluation/MaxReturn                     -0.00282294
Evaluation/MinReturn                     -0.00328765
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000232353
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.84728
GaussianMLPPolicy/KL                      9.92777e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -7.39355e-05
GaussianMLPPolicy/LossBefore             -7.3794e-05
GaussianMLPPolicy/dLoss                   1.41452e-07
GaussianMLPValueFunction/LossAfter       -5.58547
GaussianMLPValueFunction/LossBefore      -6.65991
GaussianMLPValueFunction/dLoss           -1.07443
TotalEnvSteps                        637362
-----------------------------------  ----------------
2022-08-23 10:42:33 | [trpo_pendulum] epoch #319 | Saving snapshot...
2022-08-23 10:42:33 | [trpo_pendulum] epoch #319 | Saved
2022-08-23 10:42:33 | [trpo_pendulum] epoch #319 | Time 314.46 s
2022-08-23 10:42:33 | [trpo_pendulum] epoch #319 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000378324
Evaluation/AverageReturn                 -0.00358924
Evaluation/Iteration                    319
Evaluation/MaxReturn                     -0.00331622
Evaluation/MinReturn                     -0.00386227
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000273029
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.85387
GaussianMLPPolicy/KL                      0.000668931
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000340222
GaussianMLPPolicy/LossBefore              0.000341263
GaussianMLPPolicy/dLoss                   1.0409e-06
GaussianMLPValueFunction/LossAfter       -6.645
GaussianMLPValueFunction/LossBefore      -4.49358
GaussianMLPValueFunction/dLoss            2.15142
TotalEnvSteps                        639360
-----------------------------------  ----------------
2022-08-23 10:42:34 | [trpo_pendulum] epoch #320 | Saving snapshot...
2022-08-23 10:42:34 | [trpo_pendulum] epoch #320 | Saved
2022-08-23 10:42:34 | [trpo_pendulum] epoch #320 | Time 315.44 s
2022-08-23 10:42:34 | [trpo_pendulum] epoch #320 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000304205
Evaluation/AverageReturn                 -0.00297855
Evaluation/Iteration                    320
Evaluation/MaxReturn                     -0.0028762
Evaluation/MinReturn                     -0.00308089
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000102346
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.85387
GaussianMLPPolicy/KL                      5.47441e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.73762e-05
GaussianMLPPolicy/LossBefore             -3.73685e-05
GaussianMLPPolicy/dLoss                   7.73434e-09
GaussianMLPValueFunction/LossAfter       -6.75673
GaussianMLPValueFunction/LossBefore      -6.74237
GaussianMLPValueFunction/dLoss            0.0143595
TotalEnvSteps                        641358
-----------------------------------  ----------------
2022-08-23 10:42:35 | [trpo_pendulum] epoch #321 | Saving snapshot...
2022-08-23 10:42:35 | [trpo_pendulum] epoch #321 | Saved
2022-08-23 10:42:35 | [trpo_pendulum] epoch #321 | Time 316.38 s
2022-08-23 10:42:35 | [trpo_pendulum] epoch #321 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000295428
Evaluation/AverageReturn                 -0.00323256
Evaluation/Iteration                    321
Evaluation/MaxReturn                     -0.00322789
Evaluation/MinReturn                     -0.00323723
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.66909e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.85387
GaussianMLPPolicy/KL                      1.14195e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               4.28488e-05
GaussianMLPPolicy/LossBefore              4.2865e-05
GaussianMLPPolicy/dLoss                   1.61563e-08
GaussianMLPValueFunction/LossAfter       -6.46864
GaussianMLPValueFunction/LossBefore      -6.73131
GaussianMLPValueFunction/dLoss           -0.262671
TotalEnvSteps                        643356
-----------------------------------  ----------------
2022-08-23 10:42:36 | [trpo_pendulum] epoch #322 | Saving snapshot...
2022-08-23 10:42:36 | [trpo_pendulum] epoch #322 | Saved
2022-08-23 10:42:36 | [trpo_pendulum] epoch #322 | Time 317.36 s
2022-08-23 10:42:36 | [trpo_pendulum] epoch #322 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00031889
Evaluation/AverageReturn                 -0.00321076
Evaluation/Iteration                    322
Evaluation/MaxReturn                     -0.0031659
Evaluation/MinReturn                     -0.00325562
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.48582e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.85387
GaussianMLPPolicy/KL                      2.62265e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00011765
GaussianMLPPolicy/LossBefore              0.000117687
GaussianMLPPolicy/dLoss                   3.70346e-08
GaussianMLPValueFunction/LossAfter       -6.39023
GaussianMLPValueFunction/LossBefore      -6.51019
GaussianMLPValueFunction/dLoss           -0.119957
TotalEnvSteps                        645354
-----------------------------------  ----------------
2022-08-23 10:42:37 | [trpo_pendulum] epoch #323 | Saving snapshot...
2022-08-23 10:42:37 | [trpo_pendulum] epoch #323 | Saved
2022-08-23 10:42:37 | [trpo_pendulum] epoch #323 | Time 318.36 s
2022-08-23 10:42:37 | [trpo_pendulum] epoch #323 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000313444
Evaluation/AverageReturn                 -0.00322172
Evaluation/Iteration                    323
Evaluation/MaxReturn                     -0.00318808
Evaluation/MinReturn                     -0.00325537
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.36428e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.84618
GaussianMLPPolicy/KL                      0.000122011
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000223458
GaussianMLPPolicy/LossBefore              0.00022364
GaussianMLPPolicy/dLoss                   1.8187e-07
GaussianMLPValueFunction/LossAfter       -6.26128
GaussianMLPValueFunction/LossBefore      -5.74016
GaussianMLPValueFunction/dLoss            0.521112
TotalEnvSteps                        647352
-----------------------------------  ----------------
2022-08-23 10:42:38 | [trpo_pendulum] epoch #324 | Saving snapshot...
2022-08-23 10:42:38 | [trpo_pendulum] epoch #324 | Saved
2022-08-23 10:42:38 | [trpo_pendulum] epoch #324 | Time 319.32 s
2022-08-23 10:42:38 | [trpo_pendulum] epoch #324 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000353268
Evaluation/AverageReturn                 -0.00321125
Evaluation/Iteration                    324
Evaluation/MaxReturn                     -0.00315247
Evaluation/MinReturn                     -0.00327004
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.87842e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.85507
GaussianMLPPolicy/KL                      9.00225e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000205468
GaussianMLPPolicy/LossBefore             -0.000205343
GaussianMLPPolicy/dLoss                   1.25263e-07
GaussianMLPValueFunction/LossAfter       -6.73071
GaussianMLPValueFunction/LossBefore      -5.94921
GaussianMLPValueFunction/dLoss            0.781495
TotalEnvSteps                        649350
-----------------------------------  ----------------
2022-08-23 10:42:38 | [trpo_pendulum] epoch #325 | Saving snapshot...
2022-08-23 10:42:39 | [trpo_pendulum] epoch #325 | Saved
2022-08-23 10:42:39 | [trpo_pendulum] epoch #325 | Time 320.31 s
2022-08-23 10:42:39 | [trpo_pendulum] epoch #325 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000384312
Evaluation/AverageReturn                 -0.00373789
Evaluation/Iteration                    325
Evaluation/MaxReturn                     -0.00371779
Evaluation/MinReturn                     -0.00375799
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.01002e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.86061
GaussianMLPPolicy/KL                      0.000320055
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000202061
GaussianMLPPolicy/LossBefore              0.000202524
GaussianMLPPolicy/dLoss                   4.62955e-07
GaussianMLPValueFunction/LossAfter       -6.52185
GaussianMLPValueFunction/LossBefore      -5.70782
GaussianMLPValueFunction/dLoss            0.814028
TotalEnvSteps                        651348
-----------------------------------  ----------------
2022-08-23 10:42:39 | [trpo_pendulum] epoch #326 | Saving snapshot...
2022-08-23 10:42:40 | [trpo_pendulum] epoch #326 | Saved
2022-08-23 10:42:40 | [trpo_pendulum] epoch #326 | Time 321.31 s
2022-08-23 10:42:40 | [trpo_pendulum] epoch #326 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000337726
Evaluation/AverageReturn                 -0.00320721
Evaluation/Iteration                    326
Evaluation/MaxReturn                     -0.00306382
Evaluation/MinReturn                     -0.0033506
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000143389
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.853
GaussianMLPPolicy/KL                      6.02663e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000204526
GaussianMLPPolicy/LossBefore             -0.000204438
GaussianMLPPolicy/dLoss                   8.73843e-08
GaussianMLPValueFunction/LossAfter       -6.57146
GaussianMLPValueFunction/LossBefore      -5.97965
GaussianMLPValueFunction/dLoss            0.591808
TotalEnvSteps                        653346
-----------------------------------  ----------------
2022-08-23 10:42:40 | [trpo_pendulum] epoch #327 | Saving snapshot...
2022-08-23 10:42:40 | [trpo_pendulum] epoch #327 | Saved
2022-08-23 10:42:40 | [trpo_pendulum] epoch #327 | Time 322.28 s
2022-08-23 10:42:40 | [trpo_pendulum] epoch #327 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000294288
Evaluation/AverageReturn                 -0.00342006
Evaluation/Iteration                    327
Evaluation/MaxReturn                     -0.00335273
Evaluation/MinReturn                     -0.00348739
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.73301e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.85302
GaussianMLPPolicy/KL                      0.000147208
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000233247
GaussianMLPPolicy/LossBefore              0.000233455
GaussianMLPPolicy/dLoss                   2.08616e-07
GaussianMLPValueFunction/LossAfter       -4.20342
GaussianMLPValueFunction/LossBefore      -5.57128
GaussianMLPValueFunction/dLoss           -1.36786
TotalEnvSteps                        655344
-----------------------------------  ----------------
2022-08-23 10:42:41 | [trpo_pendulum] epoch #328 | Saving snapshot...
2022-08-23 10:42:41 | [trpo_pendulum] epoch #328 | Saved
2022-08-23 10:42:41 | [trpo_pendulum] epoch #328 | Time 323.28 s
2022-08-23 10:42:41 | [trpo_pendulum] epoch #328 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000297286
Evaluation/AverageReturn                 -0.00313821
Evaluation/Iteration                    328
Evaluation/MaxReturn                     -0.0030388
Evaluation/MinReturn                     -0.00323761
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      9.94055e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.85919
GaussianMLPPolicy/KL                      0.000454578
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000439698
GaussianMLPPolicy/LossBefore             -0.000439049
GaussianMLPPolicy/dLoss                   6.48899e-07
GaussianMLPValueFunction/LossAfter       -6.72389
GaussianMLPValueFunction/LossBefore      -3.14645
GaussianMLPValueFunction/dLoss            3.57744
TotalEnvSteps                        657342
-----------------------------------  ----------------
2022-08-23 10:42:42 | [trpo_pendulum] epoch #329 | Saving snapshot...
2022-08-23 10:42:42 | [trpo_pendulum] epoch #329 | Saved
2022-08-23 10:42:42 | [trpo_pendulum] epoch #329 | Time 324.23 s
2022-08-23 10:42:42 | [trpo_pendulum] epoch #329 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000312436
Evaluation/AverageReturn                 -0.00337611
Evaluation/Iteration                    329
Evaluation/MaxReturn                     -0.00330026
Evaluation/MinReturn                     -0.00345197
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.58566e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.85919
GaussianMLPPolicy/KL                      2.39767e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               2.04368e-05
GaussianMLPPolicy/LossBefore              2.04705e-05
GaussianMLPPolicy/dLoss                   3.37113e-08
GaussianMLPValueFunction/LossAfter       -6.62965
GaussianMLPValueFunction/LossBefore      -6.68005
GaussianMLPValueFunction/dLoss           -0.0504003
TotalEnvSteps                        659340
-----------------------------------  ----------------
2022-08-23 10:42:43 | [trpo_pendulum] epoch #330 | Saving snapshot...
2022-08-23 10:42:43 | [trpo_pendulum] epoch #330 | Saved
2022-08-23 10:42:43 | [trpo_pendulum] epoch #330 | Time 325.19 s
2022-08-23 10:42:43 | [trpo_pendulum] epoch #330 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000236199
Evaluation/AverageReturn                 -0.00284312
Evaluation/Iteration                    330
Evaluation/MaxReturn                     -0.00279698
Evaluation/MinReturn                     -0.00288927
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.61424e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.86829
GaussianMLPPolicy/KL                      0.000161135
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000133065
GaussianMLPPolicy/LossBefore             -0.000132839
GaussianMLPPolicy/dLoss                   2.25336e-07
GaussianMLPValueFunction/LossAfter       -6.67048
GaussianMLPValueFunction/LossBefore      -6.42649
GaussianMLPValueFunction/dLoss            0.243985
TotalEnvSteps                        661338
-----------------------------------  ----------------
2022-08-23 10:42:44 | [trpo_pendulum] epoch #331 | Saving snapshot...
2022-08-23 10:42:44 | [trpo_pendulum] epoch #331 | Saved
2022-08-23 10:42:44 | [trpo_pendulum] epoch #331 | Time 326.18 s
2022-08-23 10:42:44 | [trpo_pendulum] epoch #331 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000300269
Evaluation/AverageReturn                 -0.00313989
Evaluation/Iteration                    331
Evaluation/MaxReturn                     -0.0030222
Evaluation/MinReturn                     -0.00325758
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000117689
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.86829
GaussianMLPPolicy/KL                      2.16814e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000105527
GaussianMLPPolicy/LossBefore              0.00010553
GaussianMLPPolicy/dLoss                   3.01225e-09
GaussianMLPValueFunction/LossAfter       -6.68294
GaussianMLPValueFunction/LossBefore      -6.52988
GaussianMLPValueFunction/dLoss            0.153062
TotalEnvSteps                        663336
-----------------------------------  ----------------
2022-08-23 10:42:45 | [trpo_pendulum] epoch #332 | Saving snapshot...
2022-08-23 10:42:45 | [trpo_pendulum] epoch #332 | Saved
2022-08-23 10:42:45 | [trpo_pendulum] epoch #332 | Time 327.12 s
2022-08-23 10:42:45 | [trpo_pendulum] epoch #332 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000328955
Evaluation/AverageReturn                 -0.00339793
Evaluation/Iteration                    332
Evaluation/MaxReturn                     -0.00327238
Evaluation/MinReturn                     -0.00352347
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000125545
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.86833
GaussianMLPPolicy/KL                      0.000292099
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000157398
GaussianMLPPolicy/LossBefore              0.000157815
GaussianMLPPolicy/dLoss                   4.17363e-07
GaussianMLPValueFunction/LossAfter       -6.4188
GaussianMLPValueFunction/LossBefore      -6.09283
GaussianMLPValueFunction/dLoss            0.325963
TotalEnvSteps                        665334
-----------------------------------  ----------------
2022-08-23 10:42:46 | [trpo_pendulum] epoch #333 | Saving snapshot...
2022-08-23 10:42:46 | [trpo_pendulum] epoch #333 | Saved
2022-08-23 10:42:46 | [trpo_pendulum] epoch #333 | Time 328.08 s
2022-08-23 10:42:46 | [trpo_pendulum] epoch #333 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000303051
Evaluation/AverageReturn                 -0.00305699
Evaluation/Iteration                    333
Evaluation/MaxReturn                     -0.00301152
Evaluation/MinReturn                     -0.00310246
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.54718e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.86814
GaussianMLPPolicy/KL                      1.1665e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.85917e-06
GaussianMLPPolicy/LossBefore             -3.84236e-06
GaussianMLPPolicy/dLoss                   1.6817e-08
GaussianMLPValueFunction/LossAfter       -6.59164
GaussianMLPValueFunction/LossBefore      -6.70941
GaussianMLPValueFunction/dLoss           -0.117775
TotalEnvSteps                        667332
-----------------------------------  ----------------
2022-08-23 10:42:47 | [trpo_pendulum] epoch #334 | Saving snapshot...
2022-08-23 10:42:47 | [trpo_pendulum] epoch #334 | Saved
2022-08-23 10:42:47 | [trpo_pendulum] epoch #334 | Time 329.18 s
2022-08-23 10:42:47 | [trpo_pendulum] epoch #334 | EpochTime 1.10 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000298708
Evaluation/AverageReturn                 -0.00303162
Evaluation/Iteration                    334
Evaluation/MaxReturn                     -0.0029004
Evaluation/MinReturn                     -0.00316285
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000131225
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.87657
GaussianMLPPolicy/KL                      8.67913e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -9.84821e-05
GaussianMLPPolicy/LossBefore             -9.83615e-05
GaussianMLPPolicy/dLoss                   1.20599e-07
GaussianMLPValueFunction/LossAfter       -6.5417
GaussianMLPValueFunction/LossBefore      -6.56137
GaussianMLPValueFunction/dLoss           -0.0196743
TotalEnvSteps                        669330
-----------------------------------  ----------------
2022-08-23 10:42:48 | [trpo_pendulum] epoch #335 | Saving snapshot...
2022-08-23 10:42:48 | [trpo_pendulum] epoch #335 | Saved
2022-08-23 10:42:48 | [trpo_pendulum] epoch #335 | Time 330.16 s
2022-08-23 10:42:48 | [trpo_pendulum] epoch #335 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000332261
Evaluation/AverageReturn                 -0.00326924
Evaluation/Iteration                    335
Evaluation/MaxReturn                     -0.00317688
Evaluation/MinReturn                     -0.00336159
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      9.23578e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.88479
GaussianMLPPolicy/KL                      8.82774e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               7.05866e-05
GaussianMLPPolicy/LossBefore              7.07119e-05
GaussianMLPPolicy/dLoss                   1.2527e-07
GaussianMLPValueFunction/LossAfter       -6.77488
GaussianMLPValueFunction/LossBefore      -6.67639
GaussianMLPValueFunction/dLoss            0.0984898
TotalEnvSteps                        671328
-----------------------------------  ----------------
2022-08-23 10:42:49 | [trpo_pendulum] epoch #336 | Saving snapshot...
2022-08-23 10:42:49 | [trpo_pendulum] epoch #336 | Saved
2022-08-23 10:42:49 | [trpo_pendulum] epoch #336 | Time 331.11 s
2022-08-23 10:42:49 | [trpo_pendulum] epoch #336 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000275091
Evaluation/AverageReturn                 -0.00295099
Evaluation/Iteration                    336
Evaluation/MaxReturn                     -0.0029417
Evaluation/MinReturn                     -0.00296027
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      9.28586e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.88479
GaussianMLPPolicy/KL                      1.68325e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               4.09475e-05
GaussianMLPPolicy/LossBefore              4.095e-05
GaussianMLPPolicy/dLoss                   2.46291e-09
GaussianMLPValueFunction/LossAfter       -6.57884
GaussianMLPValueFunction/LossBefore      -6.71471
GaussianMLPValueFunction/dLoss           -0.135865
TotalEnvSteps                        673326
-----------------------------------  ----------------
2022-08-23 10:42:50 | [trpo_pendulum] epoch #337 | Saving snapshot...
2022-08-23 10:42:50 | [trpo_pendulum] epoch #337 | Saved
2022-08-23 10:42:50 | [trpo_pendulum] epoch #337 | Time 332.06 s
2022-08-23 10:42:50 | [trpo_pendulum] epoch #337 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000273719
Evaluation/AverageReturn                 -0.00289152
Evaluation/Iteration                    337
Evaluation/MaxReturn                     -0.00281995
Evaluation/MinReturn                     -0.00296308
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.15662e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.88479
GaussianMLPPolicy/KL                      7.18534e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000148449
GaussianMLPPolicy/LossBefore             -0.000148439
GaussianMLPPolicy/dLoss                   1.00263e-08
GaussianMLPValueFunction/LossAfter       -6.68741
GaussianMLPValueFunction/LossBefore      -6.3491
GaussianMLPValueFunction/dLoss            0.338313
TotalEnvSteps                        675324
-----------------------------------  ----------------
2022-08-23 10:42:51 | [trpo_pendulum] epoch #338 | Saving snapshot...
2022-08-23 10:42:51 | [trpo_pendulum] epoch #338 | Saved
2022-08-23 10:42:51 | [trpo_pendulum] epoch #338 | Time 333.07 s
2022-08-23 10:42:51 | [trpo_pendulum] epoch #338 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000331294
Evaluation/AverageReturn                 -0.00296126
Evaluation/Iteration                    338
Evaluation/MaxReturn                     -0.00287299
Evaluation/MinReturn                     -0.00304954
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.82772e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.88479
GaussianMLPPolicy/KL                      2.64086e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -2.83573e-05
GaussianMLPPolicy/LossBefore             -2.83202e-05
GaussianMLPPolicy/dLoss                   3.71674e-08
GaussianMLPValueFunction/LossAfter       -6.69396
GaussianMLPValueFunction/LossBefore      -6.75248
GaussianMLPValueFunction/dLoss           -0.0585213
TotalEnvSteps                        677322
-----------------------------------  ----------------
2022-08-23 10:42:52 | [trpo_pendulum] epoch #339 | Saving snapshot...
2022-08-23 10:42:52 | [trpo_pendulum] epoch #339 | Saved
2022-08-23 10:42:52 | [trpo_pendulum] epoch #339 | Time 334.09 s
2022-08-23 10:42:52 | [trpo_pendulum] epoch #339 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000305537
Evaluation/AverageReturn                 -0.00293578
Evaluation/Iteration                    339
Evaluation/MaxReturn                     -0.00291353
Evaluation/MinReturn                     -0.00295802
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.22438e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.88595
GaussianMLPPolicy/KL                      1.49382e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -7.63838e-05
GaussianMLPPolicy/LossBefore             -7.63628e-05
GaussianMLPPolicy/dLoss                   2.09839e-08
GaussianMLPValueFunction/LossAfter       -6.73497
GaussianMLPValueFunction/LossBefore      -6.66472
GaussianMLPValueFunction/dLoss            0.0702567
TotalEnvSteps                        679320
-----------------------------------  ----------------
2022-08-23 10:42:53 | [trpo_pendulum] epoch #340 | Saving snapshot...
2022-08-23 10:42:53 | [trpo_pendulum] epoch #340 | Saved
2022-08-23 10:42:53 | [trpo_pendulum] epoch #340 | Time 335.07 s
2022-08-23 10:42:53 | [trpo_pendulum] epoch #340 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000273124
Evaluation/AverageReturn                 -0.00288837
Evaluation/Iteration                    340
Evaluation/MaxReturn                     -0.00282202
Evaluation/MinReturn                     -0.00295471
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.63451e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.89344
GaussianMLPPolicy/KL                      0.000105585
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -5.16985e-05
GaussianMLPPolicy/LossBefore             -5.15503e-05
GaussianMLPPolicy/dLoss                   1.48204e-07
GaussianMLPValueFunction/LossAfter       -6.69388
GaussianMLPValueFunction/LossBefore      -6.72963
GaussianMLPValueFunction/dLoss           -0.0357499
TotalEnvSteps                        681318
-----------------------------------  ----------------
2022-08-23 10:42:54 | [trpo_pendulum] epoch #341 | Saving snapshot...
2022-08-23 10:42:54 | [trpo_pendulum] epoch #341 | Saved
2022-08-23 10:42:54 | [trpo_pendulum] epoch #341 | Time 336.08 s
2022-08-23 10:42:54 | [trpo_pendulum] epoch #341 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000282754
Evaluation/AverageReturn                 -0.00297519
Evaluation/Iteration                    341
Evaluation/MaxReturn                     -0.00294787
Evaluation/MinReturn                     -0.0030025
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.73151e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.9008
GaussianMLPPolicy/KL                      8.2614e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               9.59023e-05
GaussianMLPPolicy/LossBefore              9.60175e-05
GaussianMLPPolicy/dLoss                   1.15193e-07
GaussianMLPValueFunction/LossAfter       -6.17579
GaussianMLPValueFunction/LossBefore      -6.5842
GaussianMLPValueFunction/dLoss           -0.408413
TotalEnvSteps                        683316
-----------------------------------  ----------------
2022-08-23 10:42:55 | [trpo_pendulum] epoch #342 | Saving snapshot...
2022-08-23 10:42:55 | [trpo_pendulum] epoch #342 | Saved
2022-08-23 10:42:55 | [trpo_pendulum] epoch #342 | Time 337.09 s
2022-08-23 10:42:55 | [trpo_pendulum] epoch #342 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000294911
Evaluation/AverageReturn                 -0.00286242
Evaluation/Iteration                    342
Evaluation/MaxReturn                     -0.00283444
Evaluation/MinReturn                     -0.0028904
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.79834e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.9008
GaussianMLPPolicy/KL                      5.59095e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000122322
GaussianMLPPolicy/LossBefore              0.000122401
GaussianMLPPolicy/dLoss                   7.87695e-08
GaussianMLPValueFunction/LossAfter       -6.71471
GaussianMLPValueFunction/LossBefore      -6.49994
GaussianMLPValueFunction/dLoss            0.214766
TotalEnvSteps                        685314
-----------------------------------  ----------------
2022-08-23 10:42:56 | [trpo_pendulum] epoch #343 | Saving snapshot...
2022-08-23 10:42:56 | [trpo_pendulum] epoch #343 | Saved
2022-08-23 10:42:56 | [trpo_pendulum] epoch #343 | Time 338.07 s
2022-08-23 10:42:56 | [trpo_pendulum] epoch #343 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000292168
Evaluation/AverageReturn                 -0.002848
Evaluation/Iteration                    343
Evaluation/MaxReturn                     -0.00271027
Evaluation/MinReturn                     -0.00298572
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000137726
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.9008
GaussianMLPPolicy/KL                      1.4868e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               6.43864e-05
GaussianMLPPolicy/LossBefore              6.44072e-05
GaussianMLPPolicy/dLoss                   2.08747e-08
GaussianMLPValueFunction/LossAfter       -5.94616
GaussianMLPValueFunction/LossBefore      -6.71567
GaussianMLPValueFunction/dLoss           -0.769516
TotalEnvSteps                        687312
-----------------------------------  ----------------
2022-08-23 10:42:57 | [trpo_pendulum] epoch #344 | Saving snapshot...
2022-08-23 10:42:57 | [trpo_pendulum] epoch #344 | Saved
2022-08-23 10:42:57 | [trpo_pendulum] epoch #344 | Time 339.09 s
2022-08-23 10:42:57 | [trpo_pendulum] epoch #344 | EpochTime 1.02 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00029522
Evaluation/AverageReturn                 -0.00286779
Evaluation/Iteration                    344
Evaluation/MaxReturn                     -0.00286238
Evaluation/MinReturn                     -0.0028732
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.40677e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90769
GaussianMLPPolicy/KL                      0.000507015
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000167829
GaussianMLPPolicy/LossBefore             -0.000167254
GaussianMLPPolicy/dLoss                   5.74699e-07
GaussianMLPValueFunction/LossAfter       -6.41979
GaussianMLPValueFunction/LossBefore      -6.21891
GaussianMLPValueFunction/dLoss            0.200879
TotalEnvSteps                        689310
-----------------------------------  ----------------
2022-08-23 10:42:58 | [trpo_pendulum] epoch #345 | Saving snapshot...
2022-08-23 10:42:58 | [trpo_pendulum] epoch #345 | Saved
2022-08-23 10:42:58 | [trpo_pendulum] epoch #345 | Time 340.10 s
2022-08-23 10:42:58 | [trpo_pendulum] epoch #345 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000241607
Evaluation/AverageReturn                 -0.00276581
Evaluation/Iteration                    345
Evaluation/MaxReturn                     -0.00271873
Evaluation/MinReturn                     -0.00281289
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.70795e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90769
GaussianMLPPolicy/KL                      2.64137e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000177446
GaussianMLPPolicy/LossBefore             -0.000177442
GaussianMLPPolicy/dLoss                   3.63798e-09
GaussianMLPValueFunction/LossAfter       -6.25391
GaussianMLPValueFunction/LossBefore      -6.166
GaussianMLPValueFunction/dLoss            0.0879107
TotalEnvSteps                        691308
-----------------------------------  ----------------
2022-08-23 10:42:59 | [trpo_pendulum] epoch #346 | Saving snapshot...
2022-08-23 10:42:59 | [trpo_pendulum] epoch #346 | Saved
2022-08-23 10:42:59 | [trpo_pendulum] epoch #346 | Time 341.04 s
2022-08-23 10:42:59 | [trpo_pendulum] epoch #346 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000274893
Evaluation/AverageReturn                 -0.00274328
Evaluation/Iteration                    346
Evaluation/MaxReturn                     -0.00273227
Evaluation/MinReturn                     -0.0027543
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.10144e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90769
GaussianMLPPolicy/KL                      1.58449e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000164128
GaussianMLPPolicy/LossBefore             -0.000164105
GaussianMLPPolicy/dLoss                   2.25118e-08
GaussianMLPValueFunction/LossAfter       -6.48739
GaussianMLPValueFunction/LossBefore      -6.25319
GaussianMLPValueFunction/dLoss            0.234204
TotalEnvSteps                        693306
-----------------------------------  ----------------
2022-08-23 10:43:00 | [trpo_pendulum] epoch #347 | Saving snapshot...
2022-08-23 10:43:00 | [trpo_pendulum] epoch #347 | Saved
2022-08-23 10:43:00 | [trpo_pendulum] epoch #347 | Time 342.02 s
2022-08-23 10:43:00 | [trpo_pendulum] epoch #347 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000283429
Evaluation/AverageReturn                 -0.00275142
Evaluation/Iteration                    347
Evaluation/MaxReturn                     -0.00272301
Evaluation/MinReturn                     -0.00277983
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.84112e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90809
GaussianMLPPolicy/KL                      5.135e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000157061
GaussianMLPPolicy/LossBefore              0.000157133
GaussianMLPPolicy/dLoss                   7.20756e-08
GaussianMLPValueFunction/LossAfter       -6.6379
GaussianMLPValueFunction/LossBefore      -6.29147
GaussianMLPValueFunction/dLoss            0.346432
TotalEnvSteps                        695304
-----------------------------------  ----------------
2022-08-23 10:43:01 | [trpo_pendulum] epoch #348 | Saving snapshot...
2022-08-23 10:43:01 | [trpo_pendulum] epoch #348 | Saved
2022-08-23 10:43:01 | [trpo_pendulum] epoch #348 | Time 342.97 s
2022-08-23 10:43:01 | [trpo_pendulum] epoch #348 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000349062
Evaluation/AverageReturn                 -0.0031332
Evaluation/Iteration                    348
Evaluation/MaxReturn                     -0.00304749
Evaluation/MinReturn                     -0.00321891
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.57104e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90806
GaussianMLPPolicy/KL                      3.57032e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000181672
GaussianMLPPolicy/LossBefore              0.000181677
GaussianMLPPolicy/dLoss                   5.02041e-09
GaussianMLPValueFunction/LossAfter       -6.49759
GaussianMLPValueFunction/LossBefore      -6.00301
GaussianMLPValueFunction/dLoss            0.494582
TotalEnvSteps                        697302
-----------------------------------  ----------------
2022-08-23 10:43:02 | [trpo_pendulum] epoch #349 | Saving snapshot...
2022-08-23 10:43:02 | [trpo_pendulum] epoch #349 | Saved
2022-08-23 10:43:02 | [trpo_pendulum] epoch #349 | Time 343.97 s
2022-08-23 10:43:02 | [trpo_pendulum] epoch #349 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000288772
Evaluation/AverageReturn                 -0.00274994
Evaluation/Iteration                    349
Evaluation/MaxReturn                     -0.00268288
Evaluation/MinReturn                     -0.002817
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.70591e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90806
GaussianMLPPolicy/KL                      1.50802e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000217268
GaussianMLPPolicy/LossBefore             -0.000217267
GaussianMLPPolicy/dLoss                   3.7835e-10
GaussianMLPValueFunction/LossAfter       -6.77327
GaussianMLPValueFunction/LossBefore      -5.84072
GaussianMLPValueFunction/dLoss            0.932551
TotalEnvSteps                        699300
-----------------------------------  ----------------
2022-08-23 10:43:03 | [trpo_pendulum] epoch #350 | Saving snapshot...
2022-08-23 10:43:03 | [trpo_pendulum] epoch #350 | Saved
2022-08-23 10:43:03 | [trpo_pendulum] epoch #350 | Time 344.92 s
2022-08-23 10:43:03 | [trpo_pendulum] epoch #350 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0002849
Evaluation/AverageReturn                 -0.00260729
Evaluation/Iteration                    350
Evaluation/MaxReturn                     -0.00253189
Evaluation/MinReturn                     -0.00268269
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.54e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90806
GaussianMLPPolicy/KL                      2.60202e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               3.66192e-05
GaussianMLPPolicy/LossBefore              3.66228e-05
GaussianMLPPolicy/dLoss                   3.64162e-09
GaussianMLPValueFunction/LossAfter       -6.75652
GaussianMLPValueFunction/LossBefore      -6.78681
GaussianMLPValueFunction/dLoss           -0.0302925
TotalEnvSteps                        701298
-----------------------------------  ----------------
2022-08-23 10:43:04 | [trpo_pendulum] epoch #351 | Saving snapshot...
2022-08-23 10:43:04 | [trpo_pendulum] epoch #351 | Saved
2022-08-23 10:43:04 | [trpo_pendulum] epoch #351 | Time 345.99 s
2022-08-23 10:43:04 | [trpo_pendulum] epoch #351 | EpochTime 1.06 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000276428
Evaluation/AverageReturn                 -0.00271319
Evaluation/Iteration                    351
Evaluation/MaxReturn                     -0.00261442
Evaluation/MinReturn                     -0.00281196
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      9.877e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90806
GaussianMLPPolicy/KL                      7.95964e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -4.09801e-05
GaussianMLPPolicy/LossBefore             -4.09689e-05
GaussianMLPPolicy/dLoss                   1.11977e-08
GaussianMLPValueFunction/LossAfter       -6.71551
GaussianMLPValueFunction/LossBefore      -6.7799
GaussianMLPValueFunction/dLoss           -0.0643935
TotalEnvSteps                        703296
-----------------------------------  ----------------
2022-08-23 10:43:05 | [trpo_pendulum] epoch #352 | Saving snapshot...
2022-08-23 10:43:05 | [trpo_pendulum] epoch #352 | Saved
2022-08-23 10:43:05 | [trpo_pendulum] epoch #352 | Time 346.95 s
2022-08-23 10:43:05 | [trpo_pendulum] epoch #352 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000291985
Evaluation/AverageReturn                 -0.00300111
Evaluation/Iteration                    352
Evaluation/MaxReturn                     -0.00295025
Evaluation/MinReturn                     -0.00305198
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.08657e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90806
GaussianMLPPolicy/KL                      2.54558e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -4.34807e-05
GaussianMLPPolicy/LossBefore             -4.34803e-05
GaussianMLPPolicy/dLoss                   3.74712e-10
GaussianMLPValueFunction/LossAfter       -6.5364
GaussianMLPValueFunction/LossBefore      -6.77459
GaussianMLPValueFunction/dLoss           -0.238191
TotalEnvSteps                        705294
-----------------------------------  ----------------
2022-08-23 10:43:06 | [trpo_pendulum] epoch #353 | Saving snapshot...
2022-08-23 10:43:06 | [trpo_pendulum] epoch #353 | Saved
2022-08-23 10:43:06 | [trpo_pendulum] epoch #353 | Time 347.94 s
2022-08-23 10:43:06 | [trpo_pendulum] epoch #353 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000237734
Evaluation/AverageReturn                 -0.00255389
Evaluation/Iteration                    353
Evaluation/MaxReturn                     -0.00247189
Evaluation/MinReturn                     -0.00263589
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.1999e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90806
GaussianMLPPolicy/KL                      1.13519e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000154645
GaussianMLPPolicy/LossBefore             -0.000154629
GaussianMLPPolicy/dLoss                   1.58761e-08
GaussianMLPValueFunction/LossAfter       -6.79277
GaussianMLPValueFunction/LossBefore      -6.31774
GaussianMLPValueFunction/dLoss            0.475031
TotalEnvSteps                        707292
-----------------------------------  ----------------
2022-08-23 10:43:07 | [trpo_pendulum] epoch #354 | Saving snapshot...
2022-08-23 10:43:07 | [trpo_pendulum] epoch #354 | Saved
2022-08-23 10:43:07 | [trpo_pendulum] epoch #354 | Time 348.89 s
2022-08-23 10:43:07 | [trpo_pendulum] epoch #354 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000309457
Evaluation/AverageReturn                 -0.00313831
Evaluation/Iteration                    354
Evaluation/MaxReturn                     -0.00293468
Evaluation/MinReturn                     -0.00334193
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000203624
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90789
GaussianMLPPolicy/KL                      2.3682e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               9.53387e-05
GaussianMLPPolicy/LossBefore              9.53723e-05
GaussianMLPPolicy/dLoss                   3.35567e-08
GaussianMLPValueFunction/LossAfter       -6.53586
GaussianMLPValueFunction/LossBefore      -6.50367
GaussianMLPValueFunction/dLoss            0.0321851
TotalEnvSteps                        709290
-----------------------------------  ----------------
2022-08-23 10:43:08 | [trpo_pendulum] epoch #355 | Saving snapshot...
2022-08-23 10:43:08 | [trpo_pendulum] epoch #355 | Saved
2022-08-23 10:43:08 | [trpo_pendulum] epoch #355 | Time 349.85 s
2022-08-23 10:43:08 | [trpo_pendulum] epoch #355 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00028151
Evaluation/AverageReturn                 -0.00254918
Evaluation/Iteration                    355
Evaluation/MaxReturn                     -0.00251569
Evaluation/MinReturn                     -0.00258266
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.34827e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90789
GaussianMLPPolicy/KL                      4.47259e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.80728e-05
GaussianMLPPolicy/LossBefore             -3.80665e-05
GaussianMLPPolicy/dLoss                   6.30098e-09
GaussianMLPValueFunction/LossAfter       -6.58093
GaussianMLPValueFunction/LossBefore      -6.77806
GaussianMLPValueFunction/dLoss           -0.197129
TotalEnvSteps                        711288
-----------------------------------  ----------------
2022-08-23 10:43:09 | [trpo_pendulum] epoch #356 | Saving snapshot...
2022-08-23 10:43:09 | [trpo_pendulum] epoch #356 | Saved
2022-08-23 10:43:09 | [trpo_pendulum] epoch #356 | Time 350.85 s
2022-08-23 10:43:09 | [trpo_pendulum] epoch #356 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000286451
Evaluation/AverageReturn                 -0.00315056
Evaluation/Iteration                    356
Evaluation/MaxReturn                     -0.00310487
Evaluation/MinReturn                     -0.00319625
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.56886e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90798
GaussianMLPPolicy/KL                      3.4313e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               7.29123e-06
GaussianMLPPolicy/LossBefore              7.3396e-06
GaussianMLPPolicy/dLoss                   4.83737e-08
GaussianMLPValueFunction/LossAfter       -3.92089
GaussianMLPValueFunction/LossBefore      -6.72353
GaussianMLPValueFunction/dLoss           -2.80264
TotalEnvSteps                        713286
-----------------------------------  ----------------
2022-08-23 10:43:10 | [trpo_pendulum] epoch #357 | Saving snapshot...
2022-08-23 10:43:10 | [trpo_pendulum] epoch #357 | Saved
2022-08-23 10:43:10 | [trpo_pendulum] epoch #357 | Time 351.82 s
2022-08-23 10:43:10 | [trpo_pendulum] epoch #357 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000270026
Evaluation/AverageReturn                 -0.00272378
Evaluation/Iteration                    357
Evaluation/MaxReturn                     -0.00268892
Evaluation/MinReturn                     -0.00275864
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.48626e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90798
GaussianMLPPolicy/KL                      0.000180629
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00026124
GaussianMLPPolicy/LossBefore              0.000261498
GaussianMLPPolicy/dLoss                   2.58005e-07
GaussianMLPValueFunction/LossAfter       -6.7925
GaussianMLPValueFunction/LossBefore      -5.40871
GaussianMLPValueFunction/dLoss            1.38378
TotalEnvSteps                        715284
-----------------------------------  ----------------
2022-08-23 10:43:11 | [trpo_pendulum] epoch #358 | Saving snapshot...
2022-08-23 10:43:11 | [trpo_pendulum] epoch #358 | Saved
2022-08-23 10:43:11 | [trpo_pendulum] epoch #358 | Time 352.78 s
2022-08-23 10:43:11 | [trpo_pendulum] epoch #358 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000280893
Evaluation/AverageReturn                 -0.00317344
Evaluation/Iteration                    358
Evaluation/MaxReturn                     -0.00312561
Evaluation/MinReturn                     -0.00322127
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.78306e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90268
GaussianMLPPolicy/KL                      3.68521e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000104788
GaussianMLPPolicy/LossBefore              0.00010484
GaussianMLPPolicy/dLoss                   5.28962e-08
GaussianMLPValueFunction/LossAfter       -4.83015
GaussianMLPValueFunction/LossBefore      -6.42264
GaussianMLPValueFunction/dLoss           -1.59248
TotalEnvSteps                        717282
-----------------------------------  ----------------
2022-08-23 10:43:12 | [trpo_pendulum] epoch #359 | Saving snapshot...
2022-08-23 10:43:12 | [trpo_pendulum] epoch #359 | Saved
2022-08-23 10:43:12 | [trpo_pendulum] epoch #359 | Time 353.88 s
2022-08-23 10:43:12 | [trpo_pendulum] epoch #359 | EpochTime 1.10 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000290647
Evaluation/AverageReturn                 -0.00315454
Evaluation/Iteration                    359
Evaluation/MaxReturn                     -0.00304169
Evaluation/MinReturn                     -0.00326739
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000112848
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90289
GaussianMLPPolicy/KL                      0.000214057
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000271832
GaussianMLPPolicy/LossBefore              0.000272136
GaussianMLPPolicy/dLoss                   3.04019e-07
GaussianMLPValueFunction/LossAfter       -5.77016
GaussianMLPValueFunction/LossBefore      -5.23171
GaussianMLPValueFunction/dLoss            0.538443
TotalEnvSteps                        719280
-----------------------------------  ----------------
2022-08-23 10:43:13 | [trpo_pendulum] epoch #360 | Saving snapshot...
2022-08-23 10:43:13 | [trpo_pendulum] epoch #360 | Saved
2022-08-23 10:43:13 | [trpo_pendulum] epoch #360 | Time 354.89 s
2022-08-23 10:43:13 | [trpo_pendulum] epoch #360 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000266511
Evaluation/AverageReturn                 -0.00267551
Evaluation/Iteration                    360
Evaluation/MaxReturn                     -0.00263285
Evaluation/MinReturn                     -0.00271817
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.266e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90289
GaussianMLPPolicy/KL                      2.46772e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000121279
GaussianMLPPolicy/LossBefore              0.00012128
GaussianMLPPolicy/dLoss                   2.61934e-10
GaussianMLPValueFunction/LossAfter       -6.34175
GaussianMLPValueFunction/LossBefore      -6.50751
GaussianMLPValueFunction/dLoss           -0.165758
TotalEnvSteps                        721278
-----------------------------------  ----------------
2022-08-23 10:43:14 | [trpo_pendulum] epoch #361 | Saving snapshot...
2022-08-23 10:43:14 | [trpo_pendulum] epoch #361 | Saved
2022-08-23 10:43:14 | [trpo_pendulum] epoch #361 | Time 355.89 s
2022-08-23 10:43:14 | [trpo_pendulum] epoch #361 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000243372
Evaluation/AverageReturn                 -0.0028861
Evaluation/Iteration                    361
Evaluation/MaxReturn                     -0.00283009
Evaluation/MinReturn                     -0.0029421
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.60049e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90328
GaussianMLPPolicy/KL                      0.000349907
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000196795
GaussianMLPPolicy/LossBefore              0.0001973
GaussianMLPPolicy/dLoss                   5.04704e-07
GaussianMLPValueFunction/LossAfter       -6.69607
GaussianMLPValueFunction/LossBefore      -5.99057
GaussianMLPValueFunction/dLoss            0.705501
TotalEnvSteps                        723276
-----------------------------------  ----------------
2022-08-23 10:43:15 | [trpo_pendulum] epoch #362 | Saving snapshot...
2022-08-23 10:43:15 | [trpo_pendulum] epoch #362 | Saved
2022-08-23 10:43:15 | [trpo_pendulum] epoch #362 | Time 356.88 s
2022-08-23 10:43:15 | [trpo_pendulum] epoch #362 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000249682
Evaluation/AverageReturn                 -0.0027115
Evaluation/Iteration                    362
Evaluation/MaxReturn                     -0.00256597
Evaluation/MinReturn                     -0.00285703
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000145528
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.903
GaussianMLPPolicy/KL                      0.000106281
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               8.15031e-05
GaussianMLPPolicy/LossBefore              8.16551e-05
GaussianMLPPolicy/dLoss                   1.51944e-07
GaussianMLPValueFunction/LossAfter       -6.75086
GaussianMLPValueFunction/LossBefore      -6.64107
GaussianMLPValueFunction/dLoss            0.109787
TotalEnvSteps                        725274
-----------------------------------  ----------------
2022-08-23 10:43:16 | [trpo_pendulum] epoch #363 | Saving snapshot...
2022-08-23 10:43:16 | [trpo_pendulum] epoch #363 | Saved
2022-08-23 10:43:16 | [trpo_pendulum] epoch #363 | Time 357.87 s
2022-08-23 10:43:16 | [trpo_pendulum] epoch #363 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000270681
Evaluation/AverageReturn                 -0.0027817
Evaluation/Iteration                    363
Evaluation/MaxReturn                     -0.00276459
Evaluation/MinReturn                     -0.0027988
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.71065e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.903
GaussianMLPPolicy/KL                      4.984e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -1.56515e-05
GaussianMLPPolicy/LossBefore             -1.56445e-05
GaussianMLPPolicy/dLoss                   7.03403e-09
GaussianMLPValueFunction/LossAfter       -6.60058
GaussianMLPValueFunction/LossBefore      -6.80778
GaussianMLPValueFunction/dLoss           -0.207195
TotalEnvSteps                        727272
-----------------------------------  ----------------
2022-08-23 10:43:17 | [trpo_pendulum] epoch #364 | Saving snapshot...
2022-08-23 10:43:17 | [trpo_pendulum] epoch #364 | Saved
2022-08-23 10:43:17 | [trpo_pendulum] epoch #364 | Time 358.85 s
2022-08-23 10:43:17 | [trpo_pendulum] epoch #364 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000281122
Evaluation/AverageReturn                 -0.00282631
Evaluation/Iteration                    364
Evaluation/MaxReturn                     -0.00276279
Evaluation/MinReturn                     -0.00288982
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.3517e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.903
GaussianMLPPolicy/KL                      3.07702e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000112097
GaussianMLPPolicy/LossBefore              0.000112141
GaussianMLPPolicy/dLoss                   4.34011e-08
GaussianMLPValueFunction/LossAfter       -6.25248
GaussianMLPValueFunction/LossBefore      -6.55599
GaussianMLPValueFunction/dLoss           -0.303506
TotalEnvSteps                        729270
-----------------------------------  ----------------
2022-08-23 10:43:18 | [trpo_pendulum] epoch #365 | Saving snapshot...
2022-08-23 10:43:18 | [trpo_pendulum] epoch #365 | Saved
2022-08-23 10:43:18 | [trpo_pendulum] epoch #365 | Time 359.84 s
2022-08-23 10:43:18 | [trpo_pendulum] epoch #365 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000276762
Evaluation/AverageReturn                 -0.0025859
Evaluation/Iteration                    365
Evaluation/MaxReturn                     -0.0024452
Evaluation/MinReturn                     -0.00272659
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000140695
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.903
GaussianMLPPolicy/KL                      1.35761e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000153375
GaussianMLPPolicy/LossBefore              0.000153395
GaussianMLPPolicy/dLoss                   1.9354e-08
GaussianMLPValueFunction/LossAfter       -6.41973
GaussianMLPValueFunction/LossBefore      -6.33063
GaussianMLPValueFunction/dLoss            0.0890994
TotalEnvSteps                        731268
-----------------------------------  ----------------
2022-08-23 10:43:19 | [trpo_pendulum] epoch #366 | Saving snapshot...
2022-08-23 10:43:19 | [trpo_pendulum] epoch #366 | Saved
2022-08-23 10:43:19 | [trpo_pendulum] epoch #366 | Time 360.86 s
2022-08-23 10:43:19 | [trpo_pendulum] epoch #366 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00026352
Evaluation/AverageReturn                 -0.00281962
Evaluation/Iteration                    366
Evaluation/MaxReturn                     -0.00276551
Evaluation/MinReturn                     -0.00287372
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.41068e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90311
GaussianMLPPolicy/KL                      5.62946e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000179243
GaussianMLPPolicy/LossBefore              0.000179323
GaussianMLPPolicy/dLoss                   7.99482e-08
GaussianMLPValueFunction/LossAfter       -6.80523
GaussianMLPValueFunction/LossBefore      -6.12968
GaussianMLPValueFunction/dLoss            0.675549
TotalEnvSteps                        733266
-----------------------------------  ----------------
2022-08-23 10:43:20 | [trpo_pendulum] epoch #367 | Saving snapshot...
2022-08-23 10:43:20 | [trpo_pendulum] epoch #367 | Saved
2022-08-23 10:43:20 | [trpo_pendulum] epoch #367 | Time 361.84 s
2022-08-23 10:43:20 | [trpo_pendulum] epoch #367 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000320854
Evaluation/AverageReturn                 -0.0030099
Evaluation/Iteration                    367
Evaluation/MaxReturn                     -0.00290667
Evaluation/MinReturn                     -0.00311312
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000103226
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90311
GaussianMLPPolicy/KL                      1.87978e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -7.02147e-06
GaussianMLPPolicy/LossBefore             -7.01879e-06
GaussianMLPPolicy/dLoss                   2.67346e-09
GaussianMLPValueFunction/LossAfter       -6.60362
GaussianMLPValueFunction/LossBefore      -6.80555
GaussianMLPValueFunction/dLoss           -0.201929
TotalEnvSteps                        735264
-----------------------------------  ----------------
2022-08-23 10:43:21 | [trpo_pendulum] epoch #368 | Saving snapshot...
2022-08-23 10:43:21 | [trpo_pendulum] epoch #368 | Saved
2022-08-23 10:43:21 | [trpo_pendulum] epoch #368 | Time 362.88 s
2022-08-23 10:43:21 | [trpo_pendulum] epoch #368 | EpochTime 1.03 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000258501
Evaluation/AverageReturn                 -0.00264489
Evaluation/Iteration                    368
Evaluation/MaxReturn                     -0.00253032
Evaluation/MinReturn                     -0.00275945
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000114567
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90311
GaussianMLPPolicy/KL                      3.25525e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               6.00087e-05
GaussianMLPPolicy/LossBefore              6.00133e-05
GaussianMLPPolicy/dLoss                   4.57294e-09
GaussianMLPValueFunction/LossAfter       -6.62653
GaussianMLPValueFunction/LossBefore      -6.74249
GaussianMLPValueFunction/dLoss           -0.115967
TotalEnvSteps                        737262
-----------------------------------  ----------------
2022-08-23 10:43:22 | [trpo_pendulum] epoch #369 | Saving snapshot...
2022-08-23 10:43:22 | [trpo_pendulum] epoch #369 | Saved
2022-08-23 10:43:22 | [trpo_pendulum] epoch #369 | Time 363.89 s
2022-08-23 10:43:22 | [trpo_pendulum] epoch #369 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000259306
Evaluation/AverageReturn                 -0.00263832
Evaluation/Iteration                    369
Evaluation/MaxReturn                     -0.00242214
Evaluation/MinReturn                     -0.0028545
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000216183
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.90311
GaussianMLPPolicy/KL                      8.67937e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               8.64009e-05
GaussianMLPPolicy/LossBefore              8.64019e-05
GaussianMLPPolicy/dLoss                   1.06957e-09
GaussianMLPValueFunction/LossAfter       -5.74364
GaussianMLPValueFunction/LossBefore      -6.66955
GaussianMLPValueFunction/dLoss           -0.925905
TotalEnvSteps                        739260
-----------------------------------  ----------------
2022-08-23 10:43:23 | [trpo_pendulum] epoch #370 | Saving snapshot...
2022-08-23 10:43:23 | [trpo_pendulum] epoch #370 | Saved
2022-08-23 10:43:23 | [trpo_pendulum] epoch #370 | Time 364.84 s
2022-08-23 10:43:23 | [trpo_pendulum] epoch #370 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000264062
Evaluation/AverageReturn                 -0.00274953
Evaluation/Iteration                    370
Evaluation/MaxReturn                     -0.00266226
Evaluation/MinReturn                     -0.0028368
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.727e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.91172
GaussianMLPPolicy/KL                      0.000232871
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.00024495
GaussianMLPPolicy/LossBefore              0.000245272
GaussianMLPPolicy/dLoss                   3.22121e-07
GaussianMLPValueFunction/LossAfter       -6.7353
GaussianMLPValueFunction/LossBefore      -5.53753
GaussianMLPValueFunction/dLoss            1.19778
TotalEnvSteps                        741258
-----------------------------------  ----------------
2022-08-23 10:43:24 | [trpo_pendulum] epoch #371 | Saving snapshot...
2022-08-23 10:43:24 | [trpo_pendulum] epoch #371 | Saved
2022-08-23 10:43:24 | [trpo_pendulum] epoch #371 | Time 365.81 s
2022-08-23 10:43:24 | [trpo_pendulum] epoch #371 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000256374
Evaluation/AverageReturn                 -0.00258804
Evaluation/Iteration                    371
Evaluation/MaxReturn                     -0.00245516
Evaluation/MinReturn                     -0.00272091
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000132878
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.91172
GaussianMLPPolicy/KL                      2.21504e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -6.75457e-05
GaussianMLPPolicy/LossBefore             -6.75455e-05
GaussianMLPPolicy/dLoss                   2.25555e-10
GaussianMLPValueFunction/LossAfter       -6.78013
GaussianMLPValueFunction/LossBefore      -6.72722
GaussianMLPValueFunction/dLoss            0.0529165
TotalEnvSteps                        743256
-----------------------------------  ----------------
2022-08-23 10:43:25 | [trpo_pendulum] epoch #372 | Saving snapshot...
2022-08-23 10:43:25 | [trpo_pendulum] epoch #372 | Saved
2022-08-23 10:43:25 | [trpo_pendulum] epoch #372 | Time 366.78 s
2022-08-23 10:43:25 | [trpo_pendulum] epoch #372 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000293072
Evaluation/AverageReturn                 -0.00261261
Evaluation/Iteration                    372
Evaluation/MaxReturn                     -0.00258421
Evaluation/MinReturn                     -0.00264102
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.84044e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.91172
GaussianMLPPolicy/KL                      9.09329e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               2.30483e-05
GaussianMLPPolicy/LossBefore              2.30611e-05
GaussianMLPPolicy/dLoss                   1.28293e-08
GaussianMLPValueFunction/LossAfter       -6.35312
GaussianMLPValueFunction/LossBefore      -6.82811
GaussianMLPValueFunction/dLoss           -0.474981
TotalEnvSteps                        745254
-----------------------------------  ----------------
2022-08-23 10:43:26 | [trpo_pendulum] epoch #373 | Saving snapshot...
2022-08-23 10:43:26 | [trpo_pendulum] epoch #373 | Saved
2022-08-23 10:43:26 | [trpo_pendulum] epoch #373 | Time 367.72 s
2022-08-23 10:43:26 | [trpo_pendulum] epoch #373 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000225118
Evaluation/AverageReturn                 -0.00240595
Evaluation/Iteration                    373
Evaluation/MaxReturn                     -0.00239365
Evaluation/MinReturn                     -0.00241825
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.22988e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.91172
GaussianMLPPolicy/KL                      8.83679e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000141425
GaussianMLPPolicy/LossBefore              0.000141438
GaussianMLPPolicy/dLoss                   1.23982e-08
GaussianMLPValueFunction/LossAfter       -6.48447
GaussianMLPValueFunction/LossBefore      -6.40669
GaussianMLPValueFunction/dLoss            0.0777769
TotalEnvSteps                        747252
-----------------------------------  ----------------
2022-08-23 10:43:27 | [trpo_pendulum] epoch #374 | Saving snapshot...
2022-08-23 10:43:27 | [trpo_pendulum] epoch #374 | Saved
2022-08-23 10:43:27 | [trpo_pendulum] epoch #374 | Time 368.66 s
2022-08-23 10:43:27 | [trpo_pendulum] epoch #374 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000261426
Evaluation/AverageReturn                 -0.00256853
Evaluation/Iteration                    374
Evaluation/MaxReturn                     -0.00251659
Evaluation/MinReturn                     -0.00262048
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.19431e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.91172
GaussianMLPPolicy/KL                      1.62985e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000133576
GaussianMLPPolicy/LossBefore              0.000133578
GaussianMLPPolicy/dLoss                   2.41562e-09
GaussianMLPValueFunction/LossAfter       -6.73625
GaussianMLPValueFunction/LossBefore      -6.45659
GaussianMLPValueFunction/dLoss            0.279661
TotalEnvSteps                        749250
-----------------------------------  ----------------
2022-08-23 10:43:28 | [trpo_pendulum] epoch #375 | Saving snapshot...
2022-08-23 10:43:28 | [trpo_pendulum] epoch #375 | Saved
2022-08-23 10:43:28 | [trpo_pendulum] epoch #375 | Time 369.61 s
2022-08-23 10:43:28 | [trpo_pendulum] epoch #375 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000290609
Evaluation/AverageReturn                 -0.00285451
Evaluation/Iteration                    375
Evaluation/MaxReturn                     -0.002735
Evaluation/MinReturn                     -0.00297402
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000119508
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.91168
GaussianMLPPolicy/KL                      1.6405e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -2.00696e-05
GaussianMLPPolicy/LossBefore             -2.00462e-05
GaussianMLPPolicy/dLoss                   2.33867e-08
GaussianMLPValueFunction/LossAfter       -6.41984
GaussianMLPValueFunction/LossBefore      -6.81861
GaussianMLPValueFunction/dLoss           -0.398763
TotalEnvSteps                        751248
-----------------------------------  ----------------
2022-08-23 10:43:29 | [trpo_pendulum] epoch #376 | Saving snapshot...
2022-08-23 10:43:29 | [trpo_pendulum] epoch #376 | Saved
2022-08-23 10:43:29 | [trpo_pendulum] epoch #376 | Time 370.58 s
2022-08-23 10:43:29 | [trpo_pendulum] epoch #376 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000258604
Evaluation/AverageReturn                 -0.00276789
Evaluation/Iteration                    376
Evaluation/MaxReturn                     -0.00274345
Evaluation/MinReturn                     -0.00279233
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.44403e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.91194
GaussianMLPPolicy/KL                      7.56925e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000125423
GaussianMLPPolicy/LossBefore              0.00012553
GaussianMLPPolicy/dLoss                   1.07102e-07
GaussianMLPValueFunction/LossAfter       -5.39878
GaussianMLPValueFunction/LossBefore      -6.48598
GaussianMLPValueFunction/dLoss           -1.08719
TotalEnvSteps                        753246
-----------------------------------  ----------------
2022-08-23 10:43:30 | [trpo_pendulum] epoch #377 | Saving snapshot...
2022-08-23 10:43:30 | [trpo_pendulum] epoch #377 | Saved
2022-08-23 10:43:30 | [trpo_pendulum] epoch #377 | Time 371.61 s
2022-08-23 10:43:30 | [trpo_pendulum] epoch #377 | EpochTime 1.03 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000288008
Evaluation/AverageReturn                 -0.00266256
Evaluation/Iteration                    377
Evaluation/MaxReturn                     -0.00259859
Evaluation/MinReturn                     -0.00272653
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.39681e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.91233
GaussianMLPPolicy/KL                      5.56054e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000257618
GaussianMLPPolicy/LossBefore             -0.00025754
GaussianMLPPolicy/dLoss                   7.8202e-08
GaussianMLPValueFunction/LossAfter       -6.31787
GaussianMLPValueFunction/LossBefore      -5.37762
GaussianMLPValueFunction/dLoss            0.940247
TotalEnvSteps                        755244
-----------------------------------  ----------------
2022-08-23 10:43:31 | [trpo_pendulum] epoch #378 | Saving snapshot...
2022-08-23 10:43:31 | [trpo_pendulum] epoch #378 | Saved
2022-08-23 10:43:31 | [trpo_pendulum] epoch #378 | Time 372.63 s
2022-08-23 10:43:31 | [trpo_pendulum] epoch #378 | EpochTime 1.02 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000285625
Evaluation/AverageReturn                 -0.00263564
Evaluation/Iteration                    378
Evaluation/MaxReturn                     -0.00256171
Evaluation/MinReturn                     -0.00270957
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.39318e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.91233
GaussianMLPPolicy/KL                      3.17951e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000183805
GaussianMLPPolicy/LossBefore             -0.000183805
GaussianMLPPolicy/dLoss                   3.34694e-10
GaussianMLPValueFunction/LossAfter       -6.84127
GaussianMLPValueFunction/LossBefore      -6.09524
GaussianMLPValueFunction/dLoss            0.746028
TotalEnvSteps                        757242
-----------------------------------  ----------------
2022-08-23 10:43:32 | [trpo_pendulum] epoch #379 | Saving snapshot...
2022-08-23 10:43:32 | [trpo_pendulum] epoch #379 | Saved
2022-08-23 10:43:32 | [trpo_pendulum] epoch #379 | Time 373.64 s
2022-08-23 10:43:32 | [trpo_pendulum] epoch #379 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00021651
Evaluation/AverageReturn                 -0.00236845
Evaluation/Iteration                    379
Evaluation/MaxReturn                     -0.00229188
Evaluation/MinReturn                     -0.00244501
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.65658e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.91233
GaussianMLPPolicy/KL                      2.04288e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -8.85077e-06
GaussianMLPPolicy/LossBefore             -8.84787e-06
GaussianMLPPolicy/dLoss                   2.90675e-09
GaussianMLPValueFunction/LossAfter       -6.7761
GaussianMLPValueFunction/LossBefore      -6.84285
GaussianMLPValueFunction/dLoss           -0.066752
TotalEnvSteps                        759240
-----------------------------------  ----------------
2022-08-23 10:43:33 | [trpo_pendulum] epoch #380 | Saving snapshot...
2022-08-23 10:43:33 | [trpo_pendulum] epoch #380 | Saved
2022-08-23 10:43:33 | [trpo_pendulum] epoch #380 | Time 374.66 s
2022-08-23 10:43:33 | [trpo_pendulum] epoch #380 | EpochTime 1.02 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000263265
Evaluation/AverageReturn                 -0.00265879
Evaluation/Iteration                    380
Evaluation/MaxReturn                     -0.0025218
Evaluation/MinReturn                     -0.00279579
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000136996
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.91223
GaussianMLPPolicy/KL                      0.000226786
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000121301
GaussianMLPPolicy/LossBefore              0.000121622
GaussianMLPPolicy/dLoss                   3.20702e-07
GaussianMLPValueFunction/LossAfter       -6.29983
GaussianMLPValueFunction/LossBefore      -6.49197
GaussianMLPValueFunction/dLoss           -0.192143
TotalEnvSteps                        761238
-----------------------------------  ----------------
2022-08-23 10:43:34 | [trpo_pendulum] epoch #381 | Saving snapshot...
2022-08-23 10:43:34 | [trpo_pendulum] epoch #381 | Saved
2022-08-23 10:43:34 | [trpo_pendulum] epoch #381 | Time 375.60 s
2022-08-23 10:43:34 | [trpo_pendulum] epoch #381 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000275679
Evaluation/AverageReturn                 -0.00267342
Evaluation/Iteration                    381
Evaluation/MaxReturn                     -0.00263809
Evaluation/MinReturn                     -0.00270875
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.53299e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.91223
GaussianMLPPolicy/KL                      2.77669e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000187906
GaussianMLPPolicy/LossBefore             -0.000187902
GaussianMLPPolicy/dLoss                   3.92902e-09
GaussianMLPValueFunction/LossAfter       -6.76588
GaussianMLPValueFunction/LossBefore      -6.06136
GaussianMLPValueFunction/dLoss            0.704524
TotalEnvSteps                        763236
-----------------------------------  ----------------
2022-08-23 10:43:35 | [trpo_pendulum] epoch #382 | Saving snapshot...
2022-08-23 10:43:35 | [trpo_pendulum] epoch #382 | Saved
2022-08-23 10:43:35 | [trpo_pendulum] epoch #382 | Time 376.54 s
2022-08-23 10:43:35 | [trpo_pendulum] epoch #382 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000254288
Evaluation/AverageReturn                 -0.00250298
Evaluation/Iteration                    382
Evaluation/MaxReturn                     -0.00243577
Evaluation/MinReturn                     -0.00257018
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.7206e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.91223
GaussianMLPPolicy/KL                      5.54818e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               3.94254e-05
GaussianMLPPolicy/LossBefore              3.94261e-05
GaussianMLPPolicy/dLoss                   7.63976e-10
GaussianMLPValueFunction/LossAfter       -6.83457
GaussianMLPValueFunction/LossBefore      -6.81603
GaussianMLPValueFunction/dLoss            0.0185466
TotalEnvSteps                        765234
-----------------------------------  ----------------
2022-08-23 10:43:36 | [trpo_pendulum] epoch #383 | Saving snapshot...
2022-08-23 10:43:36 | [trpo_pendulum] epoch #383 | Saved
2022-08-23 10:43:36 | [trpo_pendulum] epoch #383 | Time 377.56 s
2022-08-23 10:43:36 | [trpo_pendulum] epoch #383 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00024784
Evaluation/AverageReturn                 -0.00259686
Evaluation/Iteration                    383
Evaluation/MaxReturn                     -0.00250513
Evaluation/MinReturn                     -0.0026886
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      9.17372e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.91223
GaussianMLPPolicy/KL                      5.96046e-08
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -2.47698e-05
GaussianMLPPolicy/LossBefore             -2.47698e-05
GaussianMLPPolicy/dLoss                   6.36646e-11
GaussianMLPValueFunction/LossAfter       -6.67404
GaussianMLPValueFunction/LossBefore      -6.83633
GaussianMLPValueFunction/dLoss           -0.162292
TotalEnvSteps                        767232
-----------------------------------  ----------------
2022-08-23 10:43:37 | [trpo_pendulum] epoch #384 | Saving snapshot...
2022-08-23 10:43:37 | [trpo_pendulum] epoch #384 | Saved
2022-08-23 10:43:37 | [trpo_pendulum] epoch #384 | Time 378.51 s
2022-08-23 10:43:37 | [trpo_pendulum] epoch #384 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000251453
Evaluation/AverageReturn                 -0.00274087
Evaluation/Iteration                    384
Evaluation/MaxReturn                     -0.00268289
Evaluation/MinReturn                     -0.00279884
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.79759e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.91223
GaussianMLPPolicy/KL                      4.49893e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -6.81156e-05
GaussianMLPPolicy/LossBefore             -6.81093e-05
GaussianMLPPolicy/dLoss                   6.33736e-09
GaussianMLPValueFunction/LossAfter       -6.02781
GaussianMLPValueFunction/LossBefore      -6.74369
GaussianMLPValueFunction/dLoss           -0.715877
TotalEnvSteps                        769230
-----------------------------------  ----------------
2022-08-23 10:43:38 | [trpo_pendulum] epoch #385 | Saving snapshot...
2022-08-23 10:43:38 | [trpo_pendulum] epoch #385 | Saved
2022-08-23 10:43:38 | [trpo_pendulum] epoch #385 | Time 379.60 s
2022-08-23 10:43:38 | [trpo_pendulum] epoch #385 | EpochTime 1.09 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000268123
Evaluation/AverageReturn                 -0.00271765
Evaluation/Iteration                    385
Evaluation/MaxReturn                     -0.00263434
Evaluation/MinReturn                     -0.00280096
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.33113e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.91223
GaussianMLPPolicy/KL                      5.25356e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000183857
GaussianMLPPolicy/LossBefore             -0.000183783
GaussianMLPPolicy/dLoss                   7.46368e-08
GaussianMLPValueFunction/LossAfter       -6.37336
GaussianMLPValueFunction/LossBefore      -6.08544
GaussianMLPValueFunction/dLoss            0.287928
TotalEnvSteps                        771228
-----------------------------------  ----------------
2022-08-23 10:43:39 | [trpo_pendulum] epoch #386 | Saving snapshot...
2022-08-23 10:43:39 | [trpo_pendulum] epoch #386 | Saved
2022-08-23 10:43:39 | [trpo_pendulum] epoch #386 | Time 380.62 s
2022-08-23 10:43:39 | [trpo_pendulum] epoch #386 | EpochTime 1.02 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000265894
Evaluation/AverageReturn                 -0.00258392
Evaluation/Iteration                    386
Evaluation/MaxReturn                     -0.00253752
Evaluation/MinReturn                     -0.00263033
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.64027e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.91889
GaussianMLPPolicy/KL                      6.65416e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000147307
GaussianMLPPolicy/LossBefore             -0.000147214
GaussianMLPPolicy/dLoss                   9.32341e-08
GaussianMLPValueFunction/LossAfter       -4.90106
GaussianMLPValueFunction/LossBefore      -6.3592
GaussianMLPValueFunction/dLoss           -1.45814
TotalEnvSteps                        773226
-----------------------------------  ----------------
2022-08-23 10:43:40 | [trpo_pendulum] epoch #387 | Saving snapshot...
2022-08-23 10:43:40 | [trpo_pendulum] epoch #387 | Saved
2022-08-23 10:43:40 | [trpo_pendulum] epoch #387 | Time 381.61 s
2022-08-23 10:43:40 | [trpo_pendulum] epoch #387 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000284207
Evaluation/AverageReturn                 -0.00296548
Evaluation/Iteration                    387
Evaluation/MaxReturn                     -0.00280246
Evaluation/MinReturn                     -0.00312849
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000163015
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.91777
GaussianMLPPolicy/KL                      0.000136546
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.0002325
GaussianMLPPolicy/LossBefore             -0.000232309
GaussianMLPPolicy/dLoss                   1.91023e-07
GaussianMLPValueFunction/LossAfter       -6.76812
GaussianMLPValueFunction/LossBefore      -5.58517
GaussianMLPValueFunction/dLoss            1.18294
TotalEnvSteps                        775224
-----------------------------------  ----------------
2022-08-23 10:43:41 | [trpo_pendulum] epoch #388 | Saving snapshot...
2022-08-23 10:43:41 | [trpo_pendulum] epoch #388 | Saved
2022-08-23 10:43:41 | [trpo_pendulum] epoch #388 | Time 382.60 s
2022-08-23 10:43:41 | [trpo_pendulum] epoch #388 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000287091
Evaluation/AverageReturn                 -0.0028326
Evaluation/Iteration                    388
Evaluation/MaxReturn                     -0.00279447
Evaluation/MinReturn                     -0.00287073
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.81304e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.92277
GaussianMLPPolicy/KL                      4.39634e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -6.66293e-05
GaussianMLPPolicy/LossBefore             -6.65688e-05
GaussianMLPPolicy/dLoss                   6.04923e-08
GaussianMLPValueFunction/LossAfter       -6.54653
GaussianMLPValueFunction/LossBefore      -6.72673
GaussianMLPValueFunction/dLoss           -0.180192
TotalEnvSteps                        777222
-----------------------------------  ----------------
2022-08-23 10:43:42 | [trpo_pendulum] epoch #389 | Saving snapshot...
2022-08-23 10:43:42 | [trpo_pendulum] epoch #389 | Saved
2022-08-23 10:43:42 | [trpo_pendulum] epoch #389 | Time 383.59 s
2022-08-23 10:43:42 | [trpo_pendulum] epoch #389 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000252986
Evaluation/AverageReturn                 -0.00251993
Evaluation/Iteration                    389
Evaluation/MaxReturn                     -0.00251863
Evaluation/MinReturn                     -0.00252123
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.30216e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.92277
GaussianMLPPolicy/KL                      7.12839e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               6.10089e-05
GaussianMLPPolicy/LossBefore              6.10098e-05
GaussianMLPPolicy/dLoss                   9.34961e-10
GaussianMLPValueFunction/LossAfter       -4.63067
GaussianMLPValueFunction/LossBefore      -6.76868
GaussianMLPValueFunction/dLoss           -2.13801
TotalEnvSteps                        779220
-----------------------------------  ----------------
2022-08-23 10:43:43 | [trpo_pendulum] epoch #390 | Saving snapshot...
2022-08-23 10:43:43 | [trpo_pendulum] epoch #390 | Saved
2022-08-23 10:43:43 | [trpo_pendulum] epoch #390 | Time 384.52 s
2022-08-23 10:43:43 | [trpo_pendulum] epoch #390 | EpochTime 0.92 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000280827
Evaluation/AverageReturn                 -0.0026155
Evaluation/Iteration                    390
Evaluation/MaxReturn                     -0.00253964
Evaluation/MinReturn                     -0.00269137
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.5865e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.94114
GaussianMLPPolicy/KL                      0.000364784
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000317345
GaussianMLPPolicy/LossBefore              0.000317842
GaussianMLPPolicy/dLoss                   4.96744e-07
GaussianMLPValueFunction/LossAfter       -6.37867
GaussianMLPValueFunction/LossBefore      -4.59295
GaussianMLPValueFunction/dLoss            1.78572
TotalEnvSteps                        781218
-----------------------------------  ----------------
2022-08-23 10:43:44 | [trpo_pendulum] epoch #391 | Saving snapshot...
2022-08-23 10:43:44 | [trpo_pendulum] epoch #391 | Saved
2022-08-23 10:43:44 | [trpo_pendulum] epoch #391 | Time 385.49 s
2022-08-23 10:43:44 | [trpo_pendulum] epoch #391 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000241146
Evaluation/AverageReturn                 -0.00243985
Evaluation/Iteration                    391
Evaluation/MaxReturn                     -0.0023533
Evaluation/MinReturn                     -0.0025264
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.65481e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.94114
GaussianMLPPolicy/KL                      1.89896e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00015008
GaussianMLPPolicy/LossBefore             -0.000150053
GaussianMLPPolicy/dLoss                   2.69647e-08
GaussianMLPValueFunction/LossAfter       -6.53245
GaussianMLPValueFunction/LossBefore      -6.3479
GaussianMLPValueFunction/dLoss            0.184553
TotalEnvSteps                        783216
-----------------------------------  ----------------
2022-08-23 10:43:45 | [trpo_pendulum] epoch #392 | Saving snapshot...
2022-08-23 10:43:45 | [trpo_pendulum] epoch #392 | Saved
2022-08-23 10:43:45 | [trpo_pendulum] epoch #392 | Time 386.42 s
2022-08-23 10:43:45 | [trpo_pendulum] epoch #392 | EpochTime 0.92 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00026364
Evaluation/AverageReturn                 -0.00268181
Evaluation/Iteration                    392
Evaluation/MaxReturn                     -0.00263321
Evaluation/MinReturn                     -0.00273041
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.86021e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.94102
GaussianMLPPolicy/KL                      1.81891e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -7.30586e-05
GaussianMLPPolicy/LossBefore             -7.30328e-05
GaussianMLPPolicy/dLoss                   2.58078e-08
GaussianMLPValueFunction/LossAfter       -5.55435
GaussianMLPValueFunction/LossBefore      -6.71117
GaussianMLPValueFunction/dLoss           -1.15681
TotalEnvSteps                        785214
-----------------------------------  ----------------
2022-08-23 10:43:46 | [trpo_pendulum] epoch #393 | Saving snapshot...
2022-08-23 10:43:46 | [trpo_pendulum] epoch #393 | Saved
2022-08-23 10:43:46 | [trpo_pendulum] epoch #393 | Time 387.42 s
2022-08-23 10:43:46 | [trpo_pendulum] epoch #393 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00023418
Evaluation/AverageReturn                 -0.00254956
Evaluation/Iteration                    393
Evaluation/MaxReturn                     -0.00253546
Evaluation/MinReturn                     -0.00256367
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.41071e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.93687
GaussianMLPPolicy/KL                      5.71172e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000274942
GaussianMLPPolicy/LossBefore             -0.00027486
GaussianMLPPolicy/dLoss                   8.24512e-08
GaussianMLPValueFunction/LossAfter       -5.63796
GaussianMLPValueFunction/LossBefore      -5.15634
GaussianMLPValueFunction/dLoss            0.481614
TotalEnvSteps                        787212
-----------------------------------  ----------------
2022-08-23 10:43:47 | [trpo_pendulum] epoch #394 | Saving snapshot...
2022-08-23 10:43:47 | [trpo_pendulum] epoch #394 | Saved
2022-08-23 10:43:47 | [trpo_pendulum] epoch #394 | Time 388.35 s
2022-08-23 10:43:47 | [trpo_pendulum] epoch #394 | EpochTime 0.92 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000272185
Evaluation/AverageReturn                 -0.00277682
Evaluation/Iteration                    394
Evaluation/MaxReturn                     -0.0026358
Evaluation/MinReturn                     -0.00291784
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000141021
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.93166
GaussianMLPPolicy/KL                      0.000233963
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000295408
GaussianMLPPolicy/LossBefore              0.000295759
GaussianMLPPolicy/dLoss                   3.51254e-07
GaussianMLPValueFunction/LossAfter       -6.81411
GaussianMLPValueFunction/LossBefore      -4.85671
GaussianMLPValueFunction/dLoss            1.9574
TotalEnvSteps                        789210
-----------------------------------  ----------------
2022-08-23 10:43:48 | [trpo_pendulum] epoch #395 | Saving snapshot...
2022-08-23 10:43:48 | [trpo_pendulum] epoch #395 | Saved
2022-08-23 10:43:48 | [trpo_pendulum] epoch #395 | Time 389.40 s
2022-08-23 10:43:48 | [trpo_pendulum] epoch #395 | EpochTime 1.05 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000275057
Evaluation/AverageReturn                 -0.0025245
Evaluation/Iteration                    395
Evaluation/MaxReturn                     -0.00247812
Evaluation/MinReturn                     -0.00257088
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.6379e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.93166
GaussianMLPPolicy/KL                      3.66661e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -5.15783e-05
GaussianMLPPolicy/LossBefore             -5.15732e-05
GaussianMLPPolicy/dLoss                   5.16229e-09
GaussianMLPValueFunction/LossAfter       -6.8499
GaussianMLPValueFunction/LossBefore      -6.7916
GaussianMLPValueFunction/dLoss            0.0582972
TotalEnvSteps                        791208
-----------------------------------  ----------------
2022-08-23 10:43:49 | [trpo_pendulum] epoch #396 | Saving snapshot...
2022-08-23 10:43:49 | [trpo_pendulum] epoch #396 | Saved
2022-08-23 10:43:49 | [trpo_pendulum] epoch #396 | Time 390.34 s
2022-08-23 10:43:49 | [trpo_pendulum] epoch #396 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000231778
Evaluation/AverageReturn                 -0.00237536
Evaluation/Iteration                    396
Evaluation/MaxReturn                     -0.00231738
Evaluation/MinReturn                     -0.00243333
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.79713e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.93166
GaussianMLPPolicy/KL                      3.82693e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               8.65447e-06
GaussianMLPPolicy/LossBefore              8.65984e-06
GaussianMLPPolicy/dLoss                   5.36966e-09
GaussianMLPValueFunction/LossAfter       -6.75589
GaussianMLPValueFunction/LossBefore      -6.85185
GaussianMLPValueFunction/dLoss           -0.0959516
TotalEnvSteps                        793206
-----------------------------------  ----------------
2022-08-23 10:43:50 | [trpo_pendulum] epoch #397 | Saving snapshot...
2022-08-23 10:43:50 | [trpo_pendulum] epoch #397 | Saved
2022-08-23 10:43:50 | [trpo_pendulum] epoch #397 | Time 391.32 s
2022-08-23 10:43:50 | [trpo_pendulum] epoch #397 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000241998
Evaluation/AverageReturn                 -0.00263454
Evaluation/Iteration                    397
Evaluation/MaxReturn                     -0.00254477
Evaluation/MinReturn                     -0.00272431
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.97692e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.93166
GaussianMLPPolicy/KL                      1.62973e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -2.25225e-05
GaussianMLPPolicy/LossBefore             -2.25201e-05
GaussianMLPPolicy/dLoss                   2.35741e-09
GaussianMLPValueFunction/LossAfter       -6.60204
GaussianMLPValueFunction/LossBefore      -6.83082
GaussianMLPValueFunction/dLoss           -0.228776
TotalEnvSteps                        795204
-----------------------------------  ----------------
2022-08-23 10:43:50 | [trpo_pendulum] epoch #398 | Saving snapshot...
2022-08-23 10:43:51 | [trpo_pendulum] epoch #398 | Saved
2022-08-23 10:43:51 | [trpo_pendulum] epoch #398 | Time 392.31 s
2022-08-23 10:43:51 | [trpo_pendulum] epoch #398 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000269313
Evaluation/AverageReturn                 -0.00267341
Evaluation/Iteration                    398
Evaluation/MaxReturn                     -0.00266271
Evaluation/MinReturn                     -0.00268412
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.07029e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.93048
GaussianMLPPolicy/KL                      3.49386e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000132327
GaussianMLPPolicy/LossBefore             -0.000132277
GaussianMLPPolicy/dLoss                   5.05534e-08
GaussianMLPValueFunction/LossAfter       -6.77221
GaussianMLPValueFunction/LossBefore      -6.45561
GaussianMLPValueFunction/dLoss            0.316599
TotalEnvSteps                        797202
-----------------------------------  ----------------
2022-08-23 10:43:51 | [trpo_pendulum] epoch #399 | Saving snapshot...
2022-08-23 10:43:51 | [trpo_pendulum] epoch #399 | Saved
2022-08-23 10:43:51 | [trpo_pendulum] epoch #399 | Time 393.26 s
2022-08-23 10:43:51 | [trpo_pendulum] epoch #399 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000266112
Evaluation/AverageReturn                 -0.00254119
Evaluation/Iteration                    399
Evaluation/MaxReturn                     -0.00253408
Evaluation/MinReturn                     -0.00254831
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.11404e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.93085
GaussianMLPPolicy/KL                      1.52997e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               6.60329e-05
GaussianMLPPolicy/LossBefore              6.60546e-05
GaussianMLPPolicy/dLoss                   2.16605e-08
GaussianMLPValueFunction/LossAfter       -6.7033
GaussianMLPValueFunction/LossBefore      -6.75689
GaussianMLPValueFunction/dLoss           -0.0535913
TotalEnvSteps                        799200
-----------------------------------  ----------------
2022-08-23 10:43:52 | [trpo_pendulum] epoch #400 | Saving snapshot...
2022-08-23 10:43:52 | [trpo_pendulum] epoch #400 | Saved
2022-08-23 10:43:52 | [trpo_pendulum] epoch #400 | Time 394.18 s
2022-08-23 10:43:52 | [trpo_pendulum] epoch #400 | EpochTime 0.92 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000247625
Evaluation/AverageReturn                 -0.00258436
Evaluation/Iteration                    400
Evaluation/MaxReturn                     -0.00253437
Evaluation/MinReturn                     -0.00263435
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.99914e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.93084
GaussianMLPPolicy/KL                      1.12937e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000120864
GaussianMLPPolicy/LossBefore              0.00012088
GaussianMLPPolicy/dLoss                   1.60871e-08
GaussianMLPValueFunction/LossAfter       -6.7848
GaussianMLPValueFunction/LossBefore      -6.49109
GaussianMLPValueFunction/dLoss            0.293713
TotalEnvSteps                        801198
-----------------------------------  ----------------
2022-08-23 10:43:53 | [trpo_pendulum] epoch #401 | Saving snapshot...
2022-08-23 10:43:53 | [trpo_pendulum] epoch #401 | Saved
2022-08-23 10:43:53 | [trpo_pendulum] epoch #401 | Time 395.18 s
2022-08-23 10:43:53 | [trpo_pendulum] epoch #401 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000247608
Evaluation/AverageReturn                 -0.00262199
Evaluation/Iteration                    401
Evaluation/MaxReturn                     -0.00242826
Evaluation/MinReturn                     -0.00281571
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000193728
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.93104
GaussianMLPPolicy/KL                      6.47389e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -5.05157e-05
GaussianMLPPolicy/LossBefore             -5.05065e-05
GaussianMLPPolicy/dLoss                   9.17134e-09
GaussianMLPValueFunction/LossAfter       -6.49442
GaussianMLPValueFunction/LossBefore      -6.77534
GaussianMLPValueFunction/dLoss           -0.280925
TotalEnvSteps                        803196
-----------------------------------  ----------------
2022-08-23 10:43:54 | [trpo_pendulum] epoch #402 | Saving snapshot...
2022-08-23 10:43:54 | [trpo_pendulum] epoch #402 | Saved
2022-08-23 10:43:54 | [trpo_pendulum] epoch #402 | Time 396.12 s
2022-08-23 10:43:54 | [trpo_pendulum] epoch #402 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000261258
Evaluation/AverageReturn                 -0.00295919
Evaluation/Iteration                    402
Evaluation/MaxReturn                     -0.00295632
Evaluation/MinReturn                     -0.00296206
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.86945e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.93646
GaussianMLPPolicy/KL                      7.28486e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -6.54809e-05
GaussianMLPPolicy/LossBefore             -6.53802e-05
GaussianMLPPolicy/dLoss                   1.00743e-07
GaussianMLPValueFunction/LossAfter       -6.5971
GaussianMLPValueFunction/LossBefore      -6.67357
GaussianMLPValueFunction/dLoss           -0.0764618
TotalEnvSteps                        805194
-----------------------------------  ----------------
2022-08-23 10:43:55 | [trpo_pendulum] epoch #403 | Saving snapshot...
2022-08-23 10:43:55 | [trpo_pendulum] epoch #403 | Saved
2022-08-23 10:43:55 | [trpo_pendulum] epoch #403 | Time 397.12 s
2022-08-23 10:43:55 | [trpo_pendulum] epoch #403 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000245395
Evaluation/AverageReturn                 -0.00240822
Evaluation/Iteration                    403
Evaluation/MaxReturn                     -0.00236238
Evaluation/MinReturn                     -0.00245406
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.58359e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.93646
GaussianMLPPolicy/KL                      4.63216e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -1.36676e-05
GaussianMLPPolicy/LossBefore             -1.36611e-05
GaussianMLPPolicy/dLoss                   6.54927e-09
GaussianMLPValueFunction/LossAfter       -6.77489
GaussianMLPValueFunction/LossBefore      -6.83569
GaussianMLPValueFunction/dLoss           -0.0608001
TotalEnvSteps                        807192
-----------------------------------  ----------------
2022-08-23 10:43:56 | [trpo_pendulum] epoch #404 | Saving snapshot...
2022-08-23 10:43:56 | [trpo_pendulum] epoch #404 | Saved
2022-08-23 10:43:56 | [trpo_pendulum] epoch #404 | Time 398.09 s
2022-08-23 10:43:56 | [trpo_pendulum] epoch #404 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000269654
Evaluation/AverageReturn                 -0.00287096
Evaluation/Iteration                    404
Evaluation/MaxReturn                     -0.00276411
Evaluation/MinReturn                     -0.00297782
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000106855
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.93658
GaussianMLPPolicy/KL                      1.02004e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               2.7899e-05
GaussianMLPPolicy/LossBefore              2.79134e-05
GaussianMLPPolicy/dLoss                   1.44337e-08
GaussianMLPValueFunction/LossAfter       -4.80498
GaussianMLPValueFunction/LossBefore      -6.77475
GaussianMLPValueFunction/dLoss           -1.96977
TotalEnvSteps                        809190
-----------------------------------  ----------------
2022-08-23 10:43:57 | [trpo_pendulum] epoch #405 | Saving snapshot...
2022-08-23 10:43:57 | [trpo_pendulum] epoch #405 | Saved
2022-08-23 10:43:57 | [trpo_pendulum] epoch #405 | Time 399.11 s
2022-08-23 10:43:57 | [trpo_pendulum] epoch #405 | EpochTime 1.02 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000239083
Evaluation/AverageReturn                 -0.0028004
Evaluation/Iteration                    405
Evaluation/MaxReturn                     -0.00268147
Evaluation/MinReturn                     -0.00291934
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000118935
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.93977
GaussianMLPPolicy/KL                      7.4655e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000304763
GaussianMLPPolicy/LossBefore             -0.000304656
GaussianMLPPolicy/dLoss                   1.07422e-07
GaussianMLPValueFunction/LossAfter       -4.20415
GaussianMLPValueFunction/LossBefore      -4.78557
GaussianMLPValueFunction/dLoss           -0.581412
TotalEnvSteps                        811188
-----------------------------------  ----------------
2022-08-23 10:43:58 | [trpo_pendulum] epoch #406 | Saving snapshot...
2022-08-23 10:43:58 | [trpo_pendulum] epoch #406 | Saved
2022-08-23 10:43:58 | [trpo_pendulum] epoch #406 | Time 400.13 s
2022-08-23 10:43:58 | [trpo_pendulum] epoch #406 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000235205
Evaluation/AverageReturn                 -0.00236037
Evaluation/Iteration                    406
Evaluation/MaxReturn                     -0.00230212
Evaluation/MinReturn                     -0.00241862
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.8252e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.93977
GaussianMLPPolicy/KL                      4.15432e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000426542
GaussianMLPPolicy/LossBefore             -0.000426483
GaussianMLPPolicy/dLoss                   5.8586e-08
GaussianMLPValueFunction/LossAfter       -6.80238
GaussianMLPValueFunction/LossBefore      -2.82347
GaussianMLPValueFunction/dLoss            3.97891
TotalEnvSteps                        813186
-----------------------------------  ----------------
2022-08-23 10:43:59 | [trpo_pendulum] epoch #407 | Saving snapshot...
2022-08-23 10:43:59 | [trpo_pendulum] epoch #407 | Saved
2022-08-23 10:43:59 | [trpo_pendulum] epoch #407 | Time 401.12 s
2022-08-23 10:43:59 | [trpo_pendulum] epoch #407 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000232045
Evaluation/AverageReturn                 -0.00238503
Evaluation/Iteration                    407
Evaluation/MaxReturn                     -0.0023415
Evaluation/MinReturn                     -0.00242857
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.35334e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.93977
GaussianMLPPolicy/KL                      4.44529e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -4.34339e-05
GaussianMLPPolicy/LossBefore             -4.34334e-05
GaussianMLPPolicy/dLoss                   5.67525e-10
GaussianMLPValueFunction/LossAfter       -6.84582
GaussianMLPValueFunction/LossBefore      -6.80566
GaussianMLPValueFunction/dLoss            0.0401597
TotalEnvSteps                        815184
-----------------------------------  ----------------
2022-08-23 10:44:00 | [trpo_pendulum] epoch #408 | Saving snapshot...
2022-08-23 10:44:00 | [trpo_pendulum] epoch #408 | Saved
2022-08-23 10:44:00 | [trpo_pendulum] epoch #408 | Time 402.15 s
2022-08-23 10:44:00 | [trpo_pendulum] epoch #408 | EpochTime 1.02 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00025385
Evaluation/AverageReturn                 -0.00243279
Evaluation/Iteration                    408
Evaluation/MaxReturn                     -0.00236336
Evaluation/MinReturn                     -0.00250221
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.94296e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.93977
GaussianMLPPolicy/KL                      2.34707e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.4675e-06
GaussianMLPPolicy/LossBefore             -3.4642e-06
GaussianMLPPolicy/dLoss                   3.29533e-09
GaussianMLPValueFunction/LossAfter       -6.82585
GaussianMLPValueFunction/LossBefore      -6.84562
GaussianMLPValueFunction/dLoss           -0.0197697
TotalEnvSteps                        817182
-----------------------------------  ----------------
2022-08-23 10:44:01 | [trpo_pendulum] epoch #409 | Saving snapshot...
2022-08-23 10:44:01 | [trpo_pendulum] epoch #409 | Saved
2022-08-23 10:44:01 | [trpo_pendulum] epoch #409 | Time 403.18 s
2022-08-23 10:44:01 | [trpo_pendulum] epoch #409 | EpochTime 1.02 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000230288
Evaluation/AverageReturn                 -0.00250687
Evaluation/Iteration                    409
Evaluation/MaxReturn                     -0.00248654
Evaluation/MinReturn                     -0.0025272
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.03301e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.93977
GaussianMLPPolicy/KL                      2.07065e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               4.76491e-05
GaussianMLPPolicy/LossBefore              4.76495e-05
GaussianMLPPolicy/dLoss                   3.27418e-10
GaussianMLPValueFunction/LossAfter       -6.68232
GaussianMLPValueFunction/LossBefore      -6.80033
GaussianMLPValueFunction/dLoss           -0.118009
TotalEnvSteps                        819180
-----------------------------------  ----------------
2022-08-23 10:44:02 | [trpo_pendulum] epoch #410 | Saving snapshot...
2022-08-23 10:44:02 | [trpo_pendulum] epoch #410 | Saved
2022-08-23 10:44:02 | [trpo_pendulum] epoch #410 | Time 404.22 s
2022-08-23 10:44:02 | [trpo_pendulum] epoch #410 | EpochTime 1.03 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000227257
Evaluation/AverageReturn                 -0.00224919
Evaluation/Iteration                    410
Evaluation/MaxReturn                     -0.00214234
Evaluation/MinReturn                     -0.00235604
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000106851
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.93977
GaussianMLPPolicy/KL                      7.69282e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               6.8588e-05
GaussianMLPPolicy/LossBefore              6.85891e-05
GaussianMLPPolicy/dLoss                   1.10595e-09
GaussianMLPValueFunction/LossAfter       -6.62356
GaussianMLPValueFunction/LossBefore      -6.75126
GaussianMLPValueFunction/dLoss           -0.127702
TotalEnvSteps                        821178
-----------------------------------  ----------------
2022-08-23 10:44:03 | [trpo_pendulum] epoch #411 | Saving snapshot...
2022-08-23 10:44:03 | [trpo_pendulum] epoch #411 | Saved
2022-08-23 10:44:03 | [trpo_pendulum] epoch #411 | Time 405.22 s
2022-08-23 10:44:03 | [trpo_pendulum] epoch #411 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000261068
Evaluation/AverageReturn                 -0.00236778
Evaluation/Iteration                    411
Evaluation/MaxReturn                     -0.00219568
Evaluation/MinReturn                     -0.00253988
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000172104
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.93977
GaussianMLPPolicy/KL                      6.03836e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -9.88945e-05
GaussianMLPPolicy/LossBefore             -9.88861e-05
GaussianMLPPolicy/dLoss                   8.3819e-09
GaussianMLPValueFunction/LossAfter       -6.43868
GaussianMLPValueFunction/LossBefore      -6.62866
GaussianMLPValueFunction/dLoss           -0.189981
TotalEnvSteps                        823176
-----------------------------------  ----------------
2022-08-23 10:44:04 | [trpo_pendulum] epoch #412 | Saving snapshot...
2022-08-23 10:44:04 | [trpo_pendulum] epoch #412 | Saved
2022-08-23 10:44:04 | [trpo_pendulum] epoch #412 | Time 406.18 s
2022-08-23 10:44:04 | [trpo_pendulum] epoch #412 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000238543
Evaluation/AverageReturn                 -0.00226475
Evaluation/Iteration                    412
Evaluation/MaxReturn                     -0.00223329
Evaluation/MinReturn                     -0.0022962
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.14527e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.94722
GaussianMLPPolicy/KL                      6.59003e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000136823
GaussianMLPPolicy/LossBefore             -0.00013673
GaussianMLPPolicy/dLoss                   9.30304e-08
GaussianMLPValueFunction/LossAfter       -6.85955
GaussianMLPValueFunction/LossBefore      -6.43094
GaussianMLPValueFunction/dLoss            0.428612
TotalEnvSteps                        825174
-----------------------------------  ----------------
2022-08-23 10:44:05 | [trpo_pendulum] epoch #413 | Saving snapshot...
2022-08-23 10:44:05 | [trpo_pendulum] epoch #413 | Saved
2022-08-23 10:44:05 | [trpo_pendulum] epoch #413 | Time 407.11 s
2022-08-23 10:44:05 | [trpo_pendulum] epoch #413 | EpochTime 0.93 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000240592
Evaluation/AverageReturn                 -0.00238649
Evaluation/Iteration                    413
Evaluation/MaxReturn                     -0.00236695
Evaluation/MinReturn                     -0.00240603
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.95389e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.94722
GaussianMLPPolicy/KL                      7.43238e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               6.95282e-06
GaussianMLPPolicy/LossBefore              6.95386e-06
GaussianMLPPolicy/dLoss                   1.03773e-09
GaussianMLPValueFunction/LossAfter       -6.76613
GaussianMLPValueFunction/LossBefore      -6.85742
GaussianMLPValueFunction/dLoss           -0.0912957
TotalEnvSteps                        827172
-----------------------------------  ----------------
2022-08-23 10:44:06 | [trpo_pendulum] epoch #414 | Saving snapshot...
2022-08-23 10:44:06 | [trpo_pendulum] epoch #414 | Saved
2022-08-23 10:44:06 | [trpo_pendulum] epoch #414 | Time 408.06 s
2022-08-23 10:44:06 | [trpo_pendulum] epoch #414 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000257754
Evaluation/AverageReturn                 -0.00249285
Evaluation/Iteration                    414
Evaluation/MaxReturn                     -0.00245891
Evaluation/MinReturn                     -0.0025268
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.39423e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.94722
GaussianMLPPolicy/KL                      5.48703e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -4.64926e-05
GaussianMLPPolicy/LossBefore             -4.64918e-05
GaussianMLPPolicy/dLoss                   7.78527e-10
GaussianMLPValueFunction/LossAfter       -6.8564
GaussianMLPValueFunction/LossBefore      -6.80536
GaussianMLPValueFunction/dLoss            0.0510354
TotalEnvSteps                        829170
-----------------------------------  ----------------
2022-08-23 10:44:07 | [trpo_pendulum] epoch #415 | Saving snapshot...
2022-08-23 10:44:07 | [trpo_pendulum] epoch #415 | Saved
2022-08-23 10:44:07 | [trpo_pendulum] epoch #415 | Time 409.01 s
2022-08-23 10:44:07 | [trpo_pendulum] epoch #415 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000229876
Evaluation/AverageReturn                 -0.00224629
Evaluation/Iteration                    415
Evaluation/MaxReturn                     -0.00218338
Evaluation/MinReturn                     -0.00230919
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.29055e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.94722
GaussianMLPPolicy/KL                      2.47777e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -2.94605e-05
GaussianMLPPolicy/LossBefore             -2.9457e-05
GaussianMLPPolicy/dLoss                   3.487e-09
GaussianMLPValueFunction/LossAfter       -6.85678
GaussianMLPValueFunction/LossBefore      -6.84135
GaussianMLPValueFunction/dLoss            0.0154281
TotalEnvSteps                        831168
-----------------------------------  ----------------
2022-08-23 10:44:08 | [trpo_pendulum] epoch #416 | Saving snapshot...
2022-08-23 10:44:08 | [trpo_pendulum] epoch #416 | Saved
2022-08-23 10:44:08 | [trpo_pendulum] epoch #416 | Time 410.05 s
2022-08-23 10:44:08 | [trpo_pendulum] epoch #416 | EpochTime 1.03 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000257045
Evaluation/AverageReturn                 -0.0025234
Evaluation/Iteration                    416
Evaluation/MaxReturn                     -0.0024175
Evaluation/MinReturn                     -0.0026293
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.0001059
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.94722
GaussianMLPPolicy/KL                      3.7383e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               4.97582e-05
GaussianMLPPolicy/LossBefore              4.97634e-05
GaussianMLPPolicy/dLoss                   5.20959e-09
GaussianMLPValueFunction/LossAfter       -6.48029
GaussianMLPValueFunction/LossBefore      -6.79648
GaussianMLPValueFunction/dLoss           -0.31619
TotalEnvSteps                        833166
-----------------------------------  ----------------
2022-08-23 10:44:09 | [trpo_pendulum] epoch #417 | Saving snapshot...
2022-08-23 10:44:09 | [trpo_pendulum] epoch #417 | Saved
2022-08-23 10:44:09 | [trpo_pendulum] epoch #417 | Time 411.02 s
2022-08-23 10:44:09 | [trpo_pendulum] epoch #417 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000254798
Evaluation/AverageReturn                 -0.00255667
Evaluation/Iteration                    417
Evaluation/MaxReturn                     -0.00234265
Evaluation/MinReturn                     -0.00277069
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000214023
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.94755
GaussianMLPPolicy/KL                      8.49067e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000133264
GaussianMLPPolicy/LossBefore              0.000133384
GaussianMLPPolicy/dLoss                   1.2017e-07
GaussianMLPValueFunction/LossAfter       -6.78657
GaussianMLPValueFunction/LossBefore      -6.45323
GaussianMLPValueFunction/dLoss            0.333334
TotalEnvSteps                        835164
-----------------------------------  ----------------
2022-08-23 10:44:10 | [trpo_pendulum] epoch #418 | Saving snapshot...
2022-08-23 10:44:10 | [trpo_pendulum] epoch #418 | Saved
2022-08-23 10:44:10 | [trpo_pendulum] epoch #418 | Time 412.00 s
2022-08-23 10:44:10 | [trpo_pendulum] epoch #418 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000265074
Evaluation/AverageReturn                 -0.002757
Evaluation/Iteration                    418
Evaluation/MaxReturn                     -0.00269049
Evaluation/MinReturn                     -0.00282351
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.65142e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.94774
GaussianMLPPolicy/KL                      2.62073e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               9.14549e-05
GaussianMLPPolicy/LossBefore              9.14919e-05
GaussianMLPPolicy/dLoss                   3.70201e-08
GaussianMLPValueFunction/LossAfter       -2.90466
GaussianMLPValueFunction/LossBefore      -6.63097
GaussianMLPValueFunction/dLoss           -3.72631
TotalEnvSteps                        837162
-----------------------------------  ----------------
2022-08-23 10:44:11 | [trpo_pendulum] epoch #419 | Saving snapshot...
2022-08-23 10:44:11 | [trpo_pendulum] epoch #419 | Saved
2022-08-23 10:44:11 | [trpo_pendulum] epoch #419 | Time 412.97 s
2022-08-23 10:44:11 | [trpo_pendulum] epoch #419 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000232517
Evaluation/AverageReturn                 -0.00218501
Evaluation/Iteration                    419
Evaluation/MaxReturn                     -0.00207845
Evaluation/MinReturn                     -0.00229157
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000106558
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.96647
GaussianMLPPolicy/KL                      0.000562444
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000496806
GaussianMLPPolicy/LossBefore             -0.000496016
GaussianMLPPolicy/dLoss                   7.90053e-07
GaussianMLPValueFunction/LossAfter       -6.66403
GaussianMLPValueFunction/LossBefore      -1.26598
GaussianMLPValueFunction/dLoss            5.39804
TotalEnvSteps                        839160
-----------------------------------  ----------------
2022-08-23 10:44:12 | [trpo_pendulum] epoch #420 | Saving snapshot...
2022-08-23 10:44:12 | [trpo_pendulum] epoch #420 | Saved
2022-08-23 10:44:12 | [trpo_pendulum] epoch #420 | Time 413.94 s
2022-08-23 10:44:12 | [trpo_pendulum] epoch #420 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000246843
Evaluation/AverageReturn                 -0.00242063
Evaluation/Iteration                    420
Evaluation/MaxReturn                     -0.0024185
Evaluation/MinReturn                     -0.00242277
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.1327e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.96668
GaussianMLPPolicy/KL                      2.82751e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000132798
GaussianMLPPolicy/LossBefore              0.000132838
GaussianMLPPolicy/dLoss                   4.0367e-08
GaussianMLPValueFunction/LossAfter       -6.59067
GaussianMLPValueFunction/LossBefore      -6.45482
GaussianMLPValueFunction/dLoss            0.135849
TotalEnvSteps                        841158
-----------------------------------  ----------------
2022-08-23 10:44:13 | [trpo_pendulum] epoch #421 | Saving snapshot...
2022-08-23 10:44:13 | [trpo_pendulum] epoch #421 | Saved
2022-08-23 10:44:13 | [trpo_pendulum] epoch #421 | Time 414.89 s
2022-08-23 10:44:13 | [trpo_pendulum] epoch #421 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000228541
Evaluation/AverageReturn                 -0.00214972
Evaluation/Iteration                    421
Evaluation/MaxReturn                     -0.0021161
Evaluation/MinReturn                     -0.00218334
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.36216e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.96668
GaussianMLPPolicy/KL                      9.31455e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00014557
GaussianMLPPolicy/LossBefore             -0.000145557
GaussianMLPPolicy/dLoss                   1.32131e-08
GaussianMLPValueFunction/LossAfter       -6.80167
GaussianMLPValueFunction/LossBefore      -6.37695
GaussianMLPValueFunction/dLoss            0.424719
TotalEnvSteps                        843156
-----------------------------------  ----------------
2022-08-23 10:44:14 | [trpo_pendulum] epoch #422 | Saving snapshot...
2022-08-23 10:44:14 | [trpo_pendulum] epoch #422 | Saved
2022-08-23 10:44:14 | [trpo_pendulum] epoch #422 | Time 415.90 s
2022-08-23 10:44:14 | [trpo_pendulum] epoch #422 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000219285
Evaluation/AverageReturn                 -0.00222616
Evaluation/Iteration                    422
Evaluation/MaxReturn                     -0.00221875
Evaluation/MinReturn                     -0.00223358
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.41508e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.96668
GaussianMLPPolicy/KL                      0
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -4.69944e-05
GaussianMLPPolicy/LossBefore             -4.69944e-05
GaussianMLPPolicy/dLoss                   3.63798e-12
GaussianMLPValueFunction/LossAfter       -4.70996
GaussianMLPValueFunction/LossBefore      -6.8074
GaussianMLPValueFunction/dLoss           -2.09744
TotalEnvSteps                        845154
-----------------------------------  ----------------
2022-08-23 10:44:15 | [trpo_pendulum] epoch #423 | Saving snapshot...
2022-08-23 10:44:15 | [trpo_pendulum] epoch #423 | Saved
2022-08-23 10:44:15 | [trpo_pendulum] epoch #423 | Time 416.86 s
2022-08-23 10:44:15 | [trpo_pendulum] epoch #423 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000229075
Evaluation/AverageReturn                 -0.00221446
Evaluation/Iteration                    423
Evaluation/MaxReturn                     -0.00219943
Evaluation/MinReturn                     -0.0022295
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.50368e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.96709
GaussianMLPPolicy/KL                      2.83891e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000299341
GaussianMLPPolicy/LossBefore             -0.000299301
GaussianMLPPolicy/dLoss                   3.99596e-08
GaussianMLPValueFunction/LossAfter       -6.66951
GaussianMLPValueFunction/LossBefore      -4.80705
GaussianMLPValueFunction/dLoss            1.86246
TotalEnvSteps                        847152
-----------------------------------  ----------------
2022-08-23 10:44:16 | [trpo_pendulum] epoch #424 | Saving snapshot...
2022-08-23 10:44:16 | [trpo_pendulum] epoch #424 | Saved
2022-08-23 10:44:16 | [trpo_pendulum] epoch #424 | Time 417.84 s
2022-08-23 10:44:16 | [trpo_pendulum] epoch #424 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000243194
Evaluation/AverageReturn                 -0.00222928
Evaluation/Iteration                    424
Evaluation/MaxReturn                     -0.00216852
Evaluation/MinReturn                     -0.00229005
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.07656e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.96709
GaussianMLPPolicy/KL                      4.51468e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -9.97731e-05
GaussianMLPPolicy/LossBefore             -9.97667e-05
GaussianMLPPolicy/dLoss                   6.38101e-09
GaussianMLPValueFunction/LossAfter       -6.1073
GaussianMLPValueFunction/LossBefore      -6.63471
GaussianMLPValueFunction/dLoss           -0.527412
TotalEnvSteps                        849150
-----------------------------------  ----------------
2022-08-23 10:44:17 | [trpo_pendulum] epoch #425 | Saving snapshot...
2022-08-23 10:44:17 | [trpo_pendulum] epoch #425 | Saved
2022-08-23 10:44:17 | [trpo_pendulum] epoch #425 | Time 418.87 s
2022-08-23 10:44:17 | [trpo_pendulum] epoch #425 | EpochTime 1.02 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000213101
Evaluation/AverageReturn                 -0.00223681
Evaluation/Iteration                    425
Evaluation/MaxReturn                     -0.00203856
Evaluation/MinReturn                     -0.00243505
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000198244
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.97371
GaussianMLPPolicy/KL                      5.62776e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000184866
GaussianMLPPolicy/LossBefore              0.000184944
GaussianMLPPolicy/dLoss                   7.81729e-08
GaussianMLPValueFunction/LossAfter       -6.62043
GaussianMLPValueFunction/LossBefore      -6.0834
GaussianMLPValueFunction/dLoss            0.537035
TotalEnvSteps                        851148
-----------------------------------  ----------------
2022-08-23 10:44:18 | [trpo_pendulum] epoch #426 | Saving snapshot...
2022-08-23 10:44:18 | [trpo_pendulum] epoch #426 | Saved
2022-08-23 10:44:18 | [trpo_pendulum] epoch #426 | Time 419.86 s
2022-08-23 10:44:18 | [trpo_pendulum] epoch #426 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000202031
Evaluation/AverageReturn                 -0.00224248
Evaluation/Iteration                    426
Evaluation/MaxReturn                     -0.0021125
Evaluation/MinReturn                     -0.00237245
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000129979
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.97952
GaussianMLPPolicy/KL                      4.57098e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -6.2344e-05
GaussianMLPPolicy/LossBefore             -6.22796e-05
GaussianMLPPolicy/dLoss                   6.43631e-08
GaussianMLPValueFunction/LossAfter       -6.51233
GaussianMLPValueFunction/LossBefore      -6.75551
GaussianMLPValueFunction/dLoss           -0.243177
TotalEnvSteps                        853146
-----------------------------------  ----------------
2022-08-23 10:44:19 | [trpo_pendulum] epoch #427 | Saving snapshot...
2022-08-23 10:44:19 | [trpo_pendulum] epoch #427 | Saved
2022-08-23 10:44:19 | [trpo_pendulum] epoch #427 | Time 420.85 s
2022-08-23 10:44:19 | [trpo_pendulum] epoch #427 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000223322
Evaluation/AverageReturn                 -0.00222365
Evaluation/Iteration                    427
Evaluation/MaxReturn                     -0.00220065
Evaluation/MinReturn                     -0.00224665
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.29992e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.98175
GaussianMLPPolicy/KL                      0.000322457
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000147668
GaussianMLPPolicy/LossBefore             -0.000147378
GaussianMLPPolicy/dLoss                   2.89758e-07
GaussianMLPValueFunction/LossAfter       -5.71064
GaussianMLPValueFunction/LossBefore      -6.36069
GaussianMLPValueFunction/dLoss           -0.650045
TotalEnvSteps                        855144
-----------------------------------  ----------------
2022-08-23 10:44:20 | [trpo_pendulum] epoch #428 | Saving snapshot...
2022-08-23 10:44:20 | [trpo_pendulum] epoch #428 | Saved
2022-08-23 10:44:20 | [trpo_pendulum] epoch #428 | Time 421.80 s
2022-08-23 10:44:20 | [trpo_pendulum] epoch #428 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000228048
Evaluation/AverageReturn                 -0.00210345
Evaluation/Iteration                    428
Evaluation/MaxReturn                     -0.00209374
Evaluation/MinReturn                     -0.00211315
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      9.70536e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.98175
GaussianMLPPolicy/KL                      6.40825e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000205466
GaussianMLPPolicy/LossBefore              0.000205467
GaussianMLPPolicy/dLoss                   8.73115e-10
GaussianMLPValueFunction/LossAfter       -6.4031
GaussianMLPValueFunction/LossBefore      -5.9081
GaussianMLPValueFunction/dLoss            0.495003
TotalEnvSteps                        857142
-----------------------------------  ----------------
2022-08-23 10:44:21 | [trpo_pendulum] epoch #429 | Saving snapshot...
2022-08-23 10:44:21 | [trpo_pendulum] epoch #429 | Saved
2022-08-23 10:44:21 | [trpo_pendulum] epoch #429 | Time 422.76 s
2022-08-23 10:44:21 | [trpo_pendulum] epoch #429 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000204156
Evaluation/AverageReturn                 -0.0022702
Evaluation/Iteration                    429
Evaluation/MaxReturn                     -0.00217908
Evaluation/MinReturn                     -0.00236133
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      9.11252e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.98299
GaussianMLPPolicy/KL                      5.10475e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000162202
GaussianMLPPolicy/LossBefore              0.000162275
GaussianMLPPolicy/dLoss                   7.32252e-08
GaussianMLPValueFunction/LossAfter       -6.84281
GaussianMLPValueFunction/LossBefore      -6.25825
GaussianMLPValueFunction/dLoss            0.584563
TotalEnvSteps                        859140
-----------------------------------  ----------------
2022-08-23 10:44:22 | [trpo_pendulum] epoch #430 | Saving snapshot...
2022-08-23 10:44:22 | [trpo_pendulum] epoch #430 | Saved
2022-08-23 10:44:22 | [trpo_pendulum] epoch #430 | Time 423.72 s
2022-08-23 10:44:22 | [trpo_pendulum] epoch #430 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000263234
Evaluation/AverageReturn                 -0.00261586
Evaluation/Iteration                    430
Evaluation/MaxReturn                     -0.00256565
Evaluation/MinReturn                     -0.00266607
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.02093e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.97338
GaussianMLPPolicy/KL                      0.000139288
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000105903
GaussianMLPPolicy/LossBefore              0.000106107
GaussianMLPPolicy/dLoss                   2.03996e-07
GaussianMLPValueFunction/LossAfter       -6.70536
GaussianMLPValueFunction/LossBefore      -6.53953
GaussianMLPValueFunction/dLoss            0.165827
TotalEnvSteps                        861138
-----------------------------------  ----------------
2022-08-23 10:44:23 | [trpo_pendulum] epoch #431 | Saving snapshot...
2022-08-23 10:44:23 | [trpo_pendulum] epoch #431 | Saved
2022-08-23 10:44:23 | [trpo_pendulum] epoch #431 | Time 424.71 s
2022-08-23 10:44:23 | [trpo_pendulum] epoch #431 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000214648
Evaluation/AverageReturn                 -0.00215053
Evaluation/Iteration                    431
Evaluation/MaxReturn                     -0.00210067
Evaluation/MinReturn                     -0.00220038
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.98595e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.97338
GaussianMLPPolicy/KL                      2.76954e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.00014865
GaussianMLPPolicy/LossBefore             -0.00014861
GaussianMLPPolicy/dLoss                   3.91447e-08
GaussianMLPValueFunction/LossAfter       -6.83324
GaussianMLPValueFunction/LossBefore      -6.35576
GaussianMLPValueFunction/dLoss            0.477479
TotalEnvSteps                        863136
-----------------------------------  ----------------
2022-08-23 10:44:24 | [trpo_pendulum] epoch #432 | Saving snapshot...
2022-08-23 10:44:24 | [trpo_pendulum] epoch #432 | Saved
2022-08-23 10:44:24 | [trpo_pendulum] epoch #432 | Time 425.66 s
2022-08-23 10:44:24 | [trpo_pendulum] epoch #432 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000221303
Evaluation/AverageReturn                 -0.00218858
Evaluation/Iteration                    432
Evaluation/MaxReturn                     -0.00210521
Evaluation/MinReturn                     -0.00227195
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.33715e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.97338
GaussianMLPPolicy/KL                      1.35229e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.97238e-05
GaussianMLPPolicy/LossBefore             -3.97236e-05
GaussianMLPPolicy/dLoss                   2.14641e-10
GaussianMLPValueFunction/LossAfter       -0.468951
GaussianMLPValueFunction/LossBefore      -6.82783
GaussianMLPValueFunction/dLoss           -6.35888
TotalEnvSteps                        865134
-----------------------------------  ----------------
2022-08-23 10:44:25 | [trpo_pendulum] epoch #433 | Saving snapshot...
2022-08-23 10:44:25 | [trpo_pendulum] epoch #433 | Saved
2022-08-23 10:44:25 | [trpo_pendulum] epoch #433 | Time 426.63 s
2022-08-23 10:44:25 | [trpo_pendulum] epoch #433 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000236479
Evaluation/AverageReturn                 -0.00211332
Evaluation/Iteration                    433
Evaluation/MaxReturn                     -0.00200776
Evaluation/MinReturn                     -0.00221888
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000105562
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.98653
GaussianMLPPolicy/KL                      0.000196142
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000535323
GaussianMLPPolicy/LossBefore             -0.000535046
GaussianMLPPolicy/dLoss                   2.77942e-07
GaussianMLPValueFunction/LossAfter       -6.83907
GaussianMLPValueFunction/LossBefore      -0.23245
GaussianMLPValueFunction/dLoss            6.60662
TotalEnvSteps                        867132
-----------------------------------  ----------------
2022-08-23 10:44:26 | [trpo_pendulum] epoch #434 | Saving snapshot...
2022-08-23 10:44:26 | [trpo_pendulum] epoch #434 | Saved
2022-08-23 10:44:26 | [trpo_pendulum] epoch #434 | Time 427.62 s
2022-08-23 10:44:26 | [trpo_pendulum] epoch #434 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000196827
Evaluation/AverageReturn                 -0.00220219
Evaluation/Iteration                    434
Evaluation/MaxReturn                     -0.00217371
Evaluation/MinReturn                     -0.00223068
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.84858e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.98653
GaussianMLPPolicy/KL                      1.72158e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -1.25766e-05
GaussianMLPPolicy/LossBefore             -1.25742e-05
GaussianMLPPolicy/dLoss                   2.38288e-09
GaussianMLPValueFunction/LossAfter       -3.92081
GaussianMLPValueFunction/LossBefore      -6.85773
GaussianMLPValueFunction/dLoss           -2.93692
TotalEnvSteps                        869130
-----------------------------------  ----------------
2022-08-23 10:44:27 | [trpo_pendulum] epoch #435 | Saving snapshot...
2022-08-23 10:44:27 | [trpo_pendulum] epoch #435 | Saved
2022-08-23 10:44:27 | [trpo_pendulum] epoch #435 | Time 428.73 s
2022-08-23 10:44:27 | [trpo_pendulum] epoch #435 | EpochTime 1.10 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000215928
Evaluation/AverageReturn                 -0.00237601
Evaluation/Iteration                    435
Evaluation/MaxReturn                     -0.00230971
Evaluation/MinReturn                     -0.0024423
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.62955e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.9946
GaussianMLPPolicy/KL                      0.000947709
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000391016
GaussianMLPPolicy/LossBefore              0.00039239
GaussianMLPPolicy/dLoss                   1.37454e-06
GaussianMLPValueFunction/LossAfter       -6.83739
GaussianMLPValueFunction/LossBefore      -3.27974
GaussianMLPValueFunction/dLoss            3.55765
TotalEnvSteps                        871128
-----------------------------------  ----------------
2022-08-23 10:44:28 | [trpo_pendulum] epoch #436 | Saving snapshot...
2022-08-23 10:44:28 | [trpo_pendulum] epoch #436 | Saved
2022-08-23 10:44:28 | [trpo_pendulum] epoch #436 | Time 429.72 s
2022-08-23 10:44:28 | [trpo_pendulum] epoch #436 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000219148
Evaluation/AverageReturn                 -0.00221377
Evaluation/Iteration                    436
Evaluation/MaxReturn                     -0.00221373
Evaluation/MinReturn                     -0.00221381
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.93188e-08
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.9946
GaussianMLPPolicy/KL                      5.8292e-08
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -1.4828e-05
GaussianMLPPolicy/LossBefore             -1.48279e-05
GaussianMLPPolicy/dLoss                   1.00954e-10
GaussianMLPValueFunction/LossAfter       -6.48454
GaussianMLPValueFunction/LossBefore      -6.86181
GaussianMLPValueFunction/dLoss           -0.377267
TotalEnvSteps                        873126
-----------------------------------  ----------------
2022-08-23 10:44:29 | [trpo_pendulum] epoch #437 | Saving snapshot...
2022-08-23 10:44:29 | [trpo_pendulum] epoch #437 | Saved
2022-08-23 10:44:29 | [trpo_pendulum] epoch #437 | Time 430.69 s
2022-08-23 10:44:29 | [trpo_pendulum] epoch #437 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000201273
Evaluation/AverageReturn                 -0.00198426
Evaluation/Iteration                    437
Evaluation/MaxReturn                     -0.00196152
Evaluation/MinReturn                     -0.00200701
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.27424e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.9946
GaussianMLPPolicy/KL                      1.39201e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000106549
GaussianMLPPolicy/LossBefore              0.000106569
GaussianMLPPolicy/dLoss                   1.95578e-08
GaussianMLPValueFunction/LossAfter       -5.31836
GaussianMLPValueFunction/LossBefore      -6.61256
GaussianMLPValueFunction/dLoss           -1.2942
TotalEnvSteps                        875124
-----------------------------------  ----------------
2022-08-23 10:44:30 | [trpo_pendulum] epoch #438 | Saving snapshot...
2022-08-23 10:44:30 | [trpo_pendulum] epoch #438 | Saved
2022-08-23 10:44:30 | [trpo_pendulum] epoch #438 | Time 431.65 s
2022-08-23 10:44:30 | [trpo_pendulum] epoch #438 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000208759
Evaluation/AverageReturn                 -0.00211523
Evaluation/Iteration                    438
Evaluation/MaxReturn                     -0.00207803
Evaluation/MinReturn                     -0.00215243
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.72036e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.9946
GaussianMLPPolicy/KL                      1.94266e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000255185
GaussianMLPPolicy/LossBefore             -0.000255158
GaussianMLPPolicy/dLoss                   2.75031e-08
GaussianMLPValueFunction/LossAfter       -6.80024
GaussianMLPValueFunction/LossBefore      -5.3677
GaussianMLPValueFunction/dLoss            1.43254
TotalEnvSteps                        877122
-----------------------------------  ----------------
2022-08-23 10:44:31 | [trpo_pendulum] epoch #439 | Saving snapshot...
2022-08-23 10:44:31 | [trpo_pendulum] epoch #439 | Saved
2022-08-23 10:44:31 | [trpo_pendulum] epoch #439 | Time 432.62 s
2022-08-23 10:44:31 | [trpo_pendulum] epoch #439 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000209311
Evaluation/AverageReturn                 -0.00207539
Evaluation/Iteration                    439
Evaluation/MaxReturn                     -0.00197346
Evaluation/MinReturn                     -0.00217732
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000101928
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.9946
GaussianMLPPolicy/KL                      5.99925e-08
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               5.56152e-05
GaussianMLPPolicy/LossBefore              5.56153e-05
GaussianMLPPolicy/dLoss                   1.12777e-10
GaussianMLPValueFunction/LossAfter       -5.20857
GaussianMLPValueFunction/LossBefore      -6.80002
GaussianMLPValueFunction/dLoss           -1.59146
TotalEnvSteps                        879120
-----------------------------------  ----------------
2022-08-23 10:44:32 | [trpo_pendulum] epoch #440 | Saving snapshot...
2022-08-23 10:44:32 | [trpo_pendulum] epoch #440 | Saved
2022-08-23 10:44:32 | [trpo_pendulum] epoch #440 | Time 433.59 s
2022-08-23 10:44:32 | [trpo_pendulum] epoch #440 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00024838
Evaluation/AverageReturn                 -0.0021001
Evaluation/Iteration                    440
Evaluation/MaxReturn                     -0.00203931
Evaluation/MinReturn                     -0.00216088
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.07861e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.9946
GaussianMLPPolicy/KL                      4.63962e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000267209
GaussianMLPPolicy/LossBefore             -0.000267202
GaussianMLPPolicy/dLoss                   6.43195e-09
GaussianMLPValueFunction/LossAfter       -6.86834
GaussianMLPValueFunction/LossBefore      -5.2023
GaussianMLPValueFunction/dLoss            1.66603
TotalEnvSteps                        881118
-----------------------------------  ----------------
2022-08-23 10:44:33 | [trpo_pendulum] epoch #441 | Saving snapshot...
2022-08-23 10:44:33 | [trpo_pendulum] epoch #441 | Saved
2022-08-23 10:44:33 | [trpo_pendulum] epoch #441 | Time 434.57 s
2022-08-23 10:44:33 | [trpo_pendulum] epoch #441 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000216968
Evaluation/AverageReturn                 -0.00225076
Evaluation/Iteration                    441
Evaluation/MaxReturn                     -0.00218074
Evaluation/MinReturn                     -0.00232077
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.00135e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.9949
GaussianMLPPolicy/KL                      1.40287e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               3.5928e-05
GaussianMLPPolicy/LossBefore              3.59479e-05
GaussianMLPPolicy/dLoss                   1.9907e-08
GaussianMLPValueFunction/LossAfter       -6.80832
GaussianMLPValueFunction/LossBefore      -6.835
GaussianMLPValueFunction/dLoss           -0.0266757
TotalEnvSteps                        883116
-----------------------------------  ----------------
2022-08-23 10:44:34 | [trpo_pendulum] epoch #442 | Saving snapshot...
2022-08-23 10:44:34 | [trpo_pendulum] epoch #442 | Saved
2022-08-23 10:44:34 | [trpo_pendulum] epoch #442 | Time 435.58 s
2022-08-23 10:44:34 | [trpo_pendulum] epoch #442 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0002244
Evaluation/AverageReturn                 -0.00225387
Evaluation/Iteration                    442
Evaluation/MaxReturn                     -0.00221651
Evaluation/MinReturn                     -0.00229123
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.73605e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.9948
GaussianMLPPolicy/KL                      0.000165099
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               8.8561e-05
GaussianMLPPolicy/LossBefore              8.87981e-05
GaussianMLPPolicy/dLoss                   2.37022e-07
GaussianMLPValueFunction/LossAfter       -5.92266
GaussianMLPValueFunction/LossBefore      -6.63715
GaussianMLPValueFunction/dLoss           -0.714483
TotalEnvSteps                        885114
-----------------------------------  ----------------
2022-08-23 10:44:35 | [trpo_pendulum] epoch #443 | Saving snapshot...
2022-08-23 10:44:35 | [trpo_pendulum] epoch #443 | Saved
2022-08-23 10:44:35 | [trpo_pendulum] epoch #443 | Time 436.58 s
2022-08-23 10:44:35 | [trpo_pendulum] epoch #443 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000242263
Evaluation/AverageReturn                 -0.00237082
Evaluation/Iteration                    443
Evaluation/MaxReturn                     -0.0022835
Evaluation/MinReturn                     -0.00245813
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.73131e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.99693
GaussianMLPPolicy/KL                      5.26643e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000214973
GaussianMLPPolicy/LossBefore             -0.0002149
GaussianMLPPolicy/dLoss                   7.24103e-08
GaussianMLPValueFunction/LossAfter       -6.7865
GaussianMLPValueFunction/LossBefore      -5.7812
GaussianMLPValueFunction/dLoss            1.00529
TotalEnvSteps                        887112
-----------------------------------  ----------------
2022-08-23 10:44:36 | [trpo_pendulum] epoch #444 | Saving snapshot...
2022-08-23 10:44:36 | [trpo_pendulum] epoch #444 | Saved
2022-08-23 10:44:36 | [trpo_pendulum] epoch #444 | Time 437.57 s
2022-08-23 10:44:36 | [trpo_pendulum] epoch #444 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000253286
Evaluation/AverageReturn                 -0.00257332
Evaluation/Iteration                    444
Evaluation/MaxReturn                     -0.00254012
Evaluation/MinReturn                     -0.00260652
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.3198e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -3.9969
GaussianMLPPolicy/KL                      1.97889e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -2.59268e-05
GaussianMLPPolicy/LossBefore             -2.58985e-05
GaussianMLPPolicy/dLoss                   2.83053e-08
GaussianMLPValueFunction/LossAfter       -6.7878
GaussianMLPValueFunction/LossBefore      -6.81875
GaussianMLPValueFunction/dLoss           -0.0309553
TotalEnvSteps                        889110
-----------------------------------  ----------------
2022-08-23 10:44:37 | [trpo_pendulum] epoch #445 | Saving snapshot...
2022-08-23 10:44:37 | [trpo_pendulum] epoch #445 | Saved
2022-08-23 10:44:37 | [trpo_pendulum] epoch #445 | Time 438.57 s
2022-08-23 10:44:37 | [trpo_pendulum] epoch #445 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00021535
Evaluation/AverageReturn                 -0.00215426
Evaluation/Iteration                    445
Evaluation/MaxReturn                     -0.00206539
Evaluation/MinReturn                     -0.00224313
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.88718e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.00449
GaussianMLPPolicy/KL                      5.87235e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -9.38727e-05
GaussianMLPPolicy/LossBefore             -9.37904e-05
GaussianMLPPolicy/dLoss                   8.23566e-08
GaussianMLPValueFunction/LossAfter       -0.426486
GaussianMLPValueFunction/LossBefore      -6.65674
GaussianMLPValueFunction/dLoss           -6.23026
TotalEnvSteps                        891108
-----------------------------------  ----------------
2022-08-23 10:44:38 | [trpo_pendulum] epoch #446 | Saving snapshot...
2022-08-23 10:44:38 | [trpo_pendulum] epoch #446 | Saved
2022-08-23 10:44:38 | [trpo_pendulum] epoch #446 | Time 439.52 s
2022-08-23 10:44:38 | [trpo_pendulum] epoch #446 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000221269
Evaluation/AverageReturn                 -0.00217162
Evaluation/Iteration                    446
Evaluation/MaxReturn                     -0.00207664
Evaluation/MinReturn                     -0.00226661
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      9.49848e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.02905
GaussianMLPPolicy/KL                      0.000640911
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000504995
GaussianMLPPolicy/LossBefore              0.000505878
GaussianMLPPolicy/dLoss                   8.82952e-07
GaussianMLPValueFunction/LossAfter       -6.7536
GaussianMLPValueFunction/LossBefore      -0.952157
GaussianMLPValueFunction/dLoss            5.80145
TotalEnvSteps                        893106
-----------------------------------  ----------------
2022-08-23 10:44:39 | [trpo_pendulum] epoch #447 | Saving snapshot...
2022-08-23 10:44:39 | [trpo_pendulum] epoch #447 | Saved
2022-08-23 10:44:39 | [trpo_pendulum] epoch #447 | Time 440.47 s
2022-08-23 10:44:39 | [trpo_pendulum] epoch #447 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000209606
Evaluation/AverageReturn                 -0.00207464
Evaluation/Iteration                    447
Evaluation/MaxReturn                     -0.00193672
Evaluation/MinReturn                     -0.00221255
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000137914
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.02905
GaussianMLPPolicy/KL                      3.7826e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -7.24343e-05
GaussianMLPPolicy/LossBefore             -7.2429e-05
GaussianMLPPolicy/dLoss                   5.28962e-09
GaussianMLPValueFunction/LossAfter       -6.16148
GaussianMLPValueFunction/LossBefore      -6.74537
GaussianMLPValueFunction/dLoss           -0.583893
TotalEnvSteps                        895104
-----------------------------------  ----------------
2022-08-23 10:44:40 | [trpo_pendulum] epoch #448 | Saving snapshot...
2022-08-23 10:44:40 | [trpo_pendulum] epoch #448 | Saved
2022-08-23 10:44:40 | [trpo_pendulum] epoch #448 | Time 441.51 s
2022-08-23 10:44:40 | [trpo_pendulum] epoch #448 | EpochTime 1.03 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0001964
Evaluation/AverageReturn                 -0.00196001
Evaluation/Iteration                    448
Evaluation/MaxReturn                     -0.00191872
Evaluation/MinReturn                     -0.00200131
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.1298e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.0356
GaussianMLPPolicy/KL                      8.24423e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000177592
GaussianMLPPolicy/LossBefore             -0.000177483
GaussianMLPPolicy/dLoss                   1.09692e-07
GaussianMLPValueFunction/LossAfter       -6.55392
GaussianMLPValueFunction/LossBefore      -6.1412
GaussianMLPValueFunction/dLoss            0.412719
TotalEnvSteps                        897102
-----------------------------------  ----------------
2022-08-23 10:44:41 | [trpo_pendulum] epoch #449 | Saving snapshot...
2022-08-23 10:44:41 | [trpo_pendulum] epoch #449 | Saved
2022-08-23 10:44:41 | [trpo_pendulum] epoch #449 | Time 442.51 s
2022-08-23 10:44:41 | [trpo_pendulum] epoch #449 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000201949
Evaluation/AverageReturn                 -0.00208942
Evaluation/Iteration                    449
Evaluation/MaxReturn                     -0.00207475
Evaluation/MinReturn                     -0.00210408
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.46657e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03577
GaussianMLPPolicy/KL                      8.78319e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -9.9944e-05
GaussianMLPPolicy/LossBefore             -9.99314e-05
GaussianMLPPolicy/dLoss                   1.25947e-08
GaussianMLPValueFunction/LossAfter       -6.21127
GaussianMLPValueFunction/LossBefore      -6.63895
GaussianMLPValueFunction/dLoss           -0.42768
TotalEnvSteps                        899100
-----------------------------------  ----------------
2022-08-23 10:44:42 | [trpo_pendulum] epoch #450 | Saving snapshot...
2022-08-23 10:44:42 | [trpo_pendulum] epoch #450 | Saved
2022-08-23 10:44:42 | [trpo_pendulum] epoch #450 | Time 443.49 s
2022-08-23 10:44:42 | [trpo_pendulum] epoch #450 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000211216
Evaluation/AverageReturn                 -0.00189961
Evaluation/Iteration                    450
Evaluation/MaxReturn                     -0.00187255
Evaluation/MinReturn                     -0.00192667
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.70597e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03577
GaussianMLPPolicy/KL                      4.04222e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000149227
GaussianMLPPolicy/LossBefore              0.000149285
GaussianMLPPolicy/dLoss                   5.74655e-08
GaussianMLPValueFunction/LossAfter       -6.74851
GaussianMLPValueFunction/LossBefore      -6.36371
GaussianMLPValueFunction/dLoss            0.384806
TotalEnvSteps                        901098
-----------------------------------  ----------------
2022-08-23 10:44:43 | [trpo_pendulum] epoch #451 | Saving snapshot...
2022-08-23 10:44:43 | [trpo_pendulum] epoch #451 | Saved
2022-08-23 10:44:43 | [trpo_pendulum] epoch #451 | Time 444.46 s
2022-08-23 10:44:43 | [trpo_pendulum] epoch #451 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000182296
Evaluation/AverageReturn                 -0.00184928
Evaluation/Iteration                    451
Evaluation/MaxReturn                     -0.0018445
Evaluation/MinReturn                     -0.00185407
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.78525e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03577
GaussianMLPPolicy/KL                      1.87337e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               7.23571e-05
GaussianMLPPolicy/LossBefore              7.23597e-05
GaussianMLPPolicy/dLoss                   2.67028e-09
GaussianMLPValueFunction/LossAfter       -6.61076
GaussianMLPValueFunction/LossBefore      -6.75593
GaussianMLPValueFunction/dLoss           -0.145164
TotalEnvSteps                        903096
-----------------------------------  ----------------
2022-08-23 10:44:44 | [trpo_pendulum] epoch #452 | Saving snapshot...
2022-08-23 10:44:44 | [trpo_pendulum] epoch #452 | Saved
2022-08-23 10:44:44 | [trpo_pendulum] epoch #452 | Time 445.42 s
2022-08-23 10:44:44 | [trpo_pendulum] epoch #452 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000213303
Evaluation/AverageReturn                 -0.00223202
Evaluation/Iteration                    452
Evaluation/MaxReturn                     -0.00216646
Evaluation/MinReturn                     -0.00229758
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.55605e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03577
GaussianMLPPolicy/KL                      1.50813e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -5.46583e-05
GaussianMLPPolicy/LossBefore             -5.46561e-05
GaussianMLPPolicy/dLoss                   2.17187e-09
GaussianMLPValueFunction/LossAfter       -6.73819
GaussianMLPValueFunction/LossBefore      -6.78623
GaussianMLPValueFunction/dLoss           -0.0480423
TotalEnvSteps                        905094
-----------------------------------  ----------------
2022-08-23 10:44:45 | [trpo_pendulum] epoch #453 | Saving snapshot...
2022-08-23 10:44:45 | [trpo_pendulum] epoch #453 | Saved
2022-08-23 10:44:45 | [trpo_pendulum] epoch #453 | Time 446.39 s
2022-08-23 10:44:45 | [trpo_pendulum] epoch #453 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000213475
Evaluation/AverageReturn                 -0.00218695
Evaluation/Iteration                    453
Evaluation/MaxReturn                     -0.00211411
Evaluation/MinReturn                     -0.00225979
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      7.2842e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03577
GaussianMLPPolicy/KL                      9.46911e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -8.19454e-05
GaussianMLPPolicy/LossBefore             -8.1932e-05
GaussianMLPPolicy/dLoss                   1.34023e-08
GaussianMLPValueFunction/LossAfter       -6.86315
GaussianMLPValueFunction/LossBefore      -6.70991
GaussianMLPValueFunction/dLoss            0.15324
TotalEnvSteps                        907092
-----------------------------------  ----------------
2022-08-23 10:44:46 | [trpo_pendulum] epoch #454 | Saving snapshot...
2022-08-23 10:44:46 | [trpo_pendulum] epoch #454 | Saved
2022-08-23 10:44:46 | [trpo_pendulum] epoch #454 | Time 447.39 s
2022-08-23 10:44:46 | [trpo_pendulum] epoch #454 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000189823
Evaluation/AverageReturn                 -0.00221261
Evaluation/Iteration                    454
Evaluation/MaxReturn                     -0.00218485
Evaluation/MinReturn                     -0.00224037
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.77587e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03589
GaussianMLPPolicy/KL                      7.89616e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               1.01261e-05
GaussianMLPPolicy/LossBefore              1.01374e-05
GaussianMLPPolicy/dLoss                   1.12477e-08
GaussianMLPValueFunction/LossAfter       -6.67866
GaussianMLPValueFunction/LossBefore      -6.86477
GaussianMLPValueFunction/dLoss           -0.186113
TotalEnvSteps                        909090
-----------------------------------  ----------------
2022-08-23 10:44:47 | [trpo_pendulum] epoch #455 | Saving snapshot...
2022-08-23 10:44:47 | [trpo_pendulum] epoch #455 | Saved
2022-08-23 10:44:47 | [trpo_pendulum] epoch #455 | Time 448.38 s
2022-08-23 10:44:47 | [trpo_pendulum] epoch #455 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000187294
Evaluation/AverageReturn                 -0.00198002
Evaluation/Iteration                    455
Evaluation/MaxReturn                     -0.00188719
Evaluation/MinReturn                     -0.00207284
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      9.28223e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03589
GaussianMLPPolicy/KL                      3.3355e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000125196
GaussianMLPPolicy/LossBefore             -0.000125191
GaussianMLPPolicy/dLoss                   4.75848e-09
GaussianMLPValueFunction/LossAfter       -6.72322
GaussianMLPValueFunction/LossBefore      -6.50744
GaussianMLPValueFunction/dLoss            0.215781
TotalEnvSteps                        911088
-----------------------------------  ----------------
2022-08-23 10:44:48 | [trpo_pendulum] epoch #456 | Saving snapshot...
2022-08-23 10:44:48 | [trpo_pendulum] epoch #456 | Saved
2022-08-23 10:44:48 | [trpo_pendulum] epoch #456 | Time 449.37 s
2022-08-23 10:44:48 | [trpo_pendulum] epoch #456 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000185066
Evaluation/AverageReturn                 -0.00197227
Evaluation/Iteration                    456
Evaluation/MaxReturn                     -0.0018544
Evaluation/MinReturn                     -0.00209015
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000117877
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03589
GaussianMLPPolicy/KL                      9.16981e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -8.13477e-05
GaussianMLPPolicy/LossBefore             -8.13465e-05
GaussianMLPPolicy/dLoss                   1.23691e-09
GaussianMLPValueFunction/LossAfter       -6.87457
GaussianMLPValueFunction/LossBefore      -6.72057
GaussianMLPValueFunction/dLoss            0.154005
TotalEnvSteps                        913086
-----------------------------------  ----------------
2022-08-23 10:44:49 | [trpo_pendulum] epoch #457 | Saving snapshot...
2022-08-23 10:44:49 | [trpo_pendulum] epoch #457 | Saved
2022-08-23 10:44:49 | [trpo_pendulum] epoch #457 | Time 450.37 s
2022-08-23 10:44:49 | [trpo_pendulum] epoch #457 | EpochTime 1.00 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000210731
Evaluation/AverageReturn                 -0.00199189
Evaluation/Iteration                    457
Evaluation/MaxReturn                     -0.00189962
Evaluation/MinReturn                     -0.00208415
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      9.22652e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03589
GaussianMLPPolicy/KL                      1.38824e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               1.69761e-05
GaussianMLPPolicy/LossBefore              1.6978e-05
GaussianMLPPolicy/dLoss                   1.98088e-09
GaussianMLPValueFunction/LossAfter       -6.87679
GaussianMLPValueFunction/LossBefore      -6.87022
GaussianMLPValueFunction/dLoss            0.00656986
TotalEnvSteps                        915084
-----------------------------------  ----------------
2022-08-23 10:44:50 | [trpo_pendulum] epoch #458 | Saving snapshot...
2022-08-23 10:44:50 | [trpo_pendulum] epoch #458 | Saved
2022-08-23 10:44:50 | [trpo_pendulum] epoch #458 | Time 451.33 s
2022-08-23 10:44:50 | [trpo_pendulum] epoch #458 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000230173
Evaluation/AverageReturn                 -0.00219325
Evaluation/Iteration                    458
Evaluation/MaxReturn                     -0.0020471
Evaluation/MinReturn                     -0.0023394
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000146151
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03589
GaussianMLPPolicy/KL                      3.12277e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               1.06635e-05
GaussianMLPPolicy/LossBefore              1.06679e-05
GaussianMLPPolicy/dLoss                   4.40104e-09
GaussianMLPValueFunction/LossAfter       -6.86341
GaussianMLPValueFunction/LossBefore      -6.87313
GaussianMLPValueFunction/dLoss           -0.00971079
TotalEnvSteps                        917082
-----------------------------------  ----------------
2022-08-23 10:44:50 | [trpo_pendulum] epoch #459 | Saving snapshot...
2022-08-23 10:44:51 | [trpo_pendulum] epoch #459 | Saved
2022-08-23 10:44:51 | [trpo_pendulum] epoch #459 | Time 452.30 s
2022-08-23 10:44:51 | [trpo_pendulum] epoch #459 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000193934
Evaluation/AverageReturn                 -0.00193128
Evaluation/Iteration                    459
Evaluation/MaxReturn                     -0.00187663
Evaluation/MinReturn                     -0.00198593
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.4652e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03589
GaussianMLPPolicy/KL                      5.97836e-08
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.63546e-05
GaussianMLPPolicy/LossBefore             -3.63545e-05
GaussianMLPPolicy/dLoss                   1.09139e-10
GaussianMLPValueFunction/LossAfter       -6.82632
GaussianMLPValueFunction/LossBefore      -6.84477
GaussianMLPValueFunction/dLoss           -0.0184522
TotalEnvSteps                        919080
-----------------------------------  ----------------
2022-08-23 10:44:52 | [trpo_pendulum] epoch #460 | Saving snapshot...
2022-08-23 10:44:52 | [trpo_pendulum] epoch #460 | Saved
2022-08-23 10:44:52 | [trpo_pendulum] epoch #460 | Time 453.41 s
2022-08-23 10:44:52 | [trpo_pendulum] epoch #460 | EpochTime 1.11 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000226578
Evaluation/AverageReturn                 -0.00242084
Evaluation/Iteration                    460
Evaluation/MaxReturn                     -0.00239009
Evaluation/MinReturn                     -0.0024516
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.07513e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03597
GaussianMLPPolicy/KL                      3.33819e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               2.98771e-05
GaussianMLPPolicy/LossBefore              2.99241e-05
GaussianMLPPolicy/dLoss                   4.703e-08
GaussianMLPValueFunction/LossAfter       -6.84252
GaussianMLPValueFunction/LossBefore      -6.81818
GaussianMLPValueFunction/dLoss            0.0243387
TotalEnvSteps                        921078
-----------------------------------  ----------------
2022-08-23 10:44:53 | [trpo_pendulum] epoch #461 | Saving snapshot...
2022-08-23 10:44:53 | [trpo_pendulum] epoch #461 | Saved
2022-08-23 10:44:53 | [trpo_pendulum] epoch #461 | Time 454.38 s
2022-08-23 10:44:53 | [trpo_pendulum] epoch #461 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000234821
Evaluation/AverageReturn                 -0.00244304
Evaluation/Iteration                    461
Evaluation/MaxReturn                     -0.00232272
Evaluation/MinReturn                     -0.00256337
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000120324
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03608
GaussianMLPPolicy/KL                      2.90165e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               1.60723e-05
GaussianMLPPolicy/LossBefore              1.61133e-05
GaussianMLPPolicy/dLoss                   4.09909e-08
GaussianMLPValueFunction/LossAfter       -5.26525
GaussianMLPValueFunction/LossBefore      -6.84591
GaussianMLPValueFunction/dLoss           -1.58067
TotalEnvSteps                        923076
-----------------------------------  ----------------
2022-08-23 10:44:54 | [trpo_pendulum] epoch #462 | Saving snapshot...
2022-08-23 10:44:54 | [trpo_pendulum] epoch #462 | Saved
2022-08-23 10:44:54 | [trpo_pendulum] epoch #462 | Time 455.40 s
2022-08-23 10:44:54 | [trpo_pendulum] epoch #462 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000195951
Evaluation/AverageReturn                 -0.00198755
Evaluation/Iteration                    462
Evaluation/MaxReturn                     -0.00190499
Evaluation/MinReturn                     -0.00207011
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.25631e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.04054
GaussianMLPPolicy/KL                      0.00011796
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000197869
GaussianMLPPolicy/LossBefore              0.000198022
GaussianMLPPolicy/dLoss                   1.53013e-07
GaussianMLPValueFunction/LossAfter       -6.78298
GaussianMLPValueFunction/LossBefore      -5.96818
GaussianMLPValueFunction/dLoss            0.814802
TotalEnvSteps                        925074
-----------------------------------  ----------------
2022-08-23 10:44:55 | [trpo_pendulum] epoch #463 | Saving snapshot...
2022-08-23 10:44:55 | [trpo_pendulum] epoch #463 | Saved
2022-08-23 10:44:55 | [trpo_pendulum] epoch #463 | Time 456.41 s
2022-08-23 10:44:55 | [trpo_pendulum] epoch #463 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000205961
Evaluation/AverageReturn                 -0.00202808
Evaluation/Iteration                    463
Evaluation/MaxReturn                     -0.00194774
Evaluation/MinReturn                     -0.00210841
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.03327e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.04046
GaussianMLPPolicy/KL                      2.24939e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               9.04618e-05
GaussianMLPPolicy/LossBefore              9.04935e-05
GaussianMLPPolicy/dLoss                   3.16868e-08
GaussianMLPValueFunction/LossAfter       -5.54532
GaussianMLPValueFunction/LossBefore      -6.67418
GaussianMLPValueFunction/dLoss           -1.12886
TotalEnvSteps                        927072
-----------------------------------  ----------------
2022-08-23 10:44:56 | [trpo_pendulum] epoch #464 | Saving snapshot...
2022-08-23 10:44:56 | [trpo_pendulum] epoch #464 | Saved
2022-08-23 10:44:56 | [trpo_pendulum] epoch #464 | Time 457.37 s
2022-08-23 10:44:56 | [trpo_pendulum] epoch #464 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000185539
Evaluation/AverageReturn                 -0.00205457
Evaluation/Iteration                    464
Evaluation/MaxReturn                     -0.00205313
Evaluation/MinReturn                     -0.00205601
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.44273e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.04046
GaussianMLPPolicy/KL                      2.56667e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000252342
GaussianMLPPolicy/LossBefore             -0.000252306
GaussianMLPPolicy/dLoss                   3.59723e-08
GaussianMLPValueFunction/LossAfter       -6.83135
GaussianMLPValueFunction/LossBefore      -5.38198
GaussianMLPValueFunction/dLoss            1.44937
TotalEnvSteps                        929070
-----------------------------------  ----------------
2022-08-23 10:44:56 | [trpo_pendulum] epoch #465 | Saving snapshot...
2022-08-23 10:44:57 | [trpo_pendulum] epoch #465 | Saved
2022-08-23 10:44:57 | [trpo_pendulum] epoch #465 | Time 458.32 s
2022-08-23 10:44:57 | [trpo_pendulum] epoch #465 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000153357
Evaluation/AverageReturn                 -0.00178764
Evaluation/Iteration                    465
Evaluation/MaxReturn                     -0.00172968
Evaluation/MinReturn                     -0.0018456
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.79631e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.04046
GaussianMLPPolicy/KL                      1.03095e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -6.55356e-05
GaussianMLPPolicy/LossBefore             -6.55212e-05
GaussianMLPPolicy/dLoss                   1.43846e-08
GaussianMLPValueFunction/LossAfter       -6.07699
GaussianMLPValueFunction/LossBefore      -6.77979
GaussianMLPValueFunction/dLoss           -0.702796
TotalEnvSteps                        931068
-----------------------------------  ----------------
2022-08-23 10:44:57 | [trpo_pendulum] epoch #466 | Saving snapshot...
2022-08-23 10:44:58 | [trpo_pendulum] epoch #466 | Saved
2022-08-23 10:44:58 | [trpo_pendulum] epoch #466 | Time 459.32 s
2022-08-23 10:44:58 | [trpo_pendulum] epoch #466 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000196452
Evaluation/AverageReturn                 -0.00187096
Evaluation/Iteration                    466
Evaluation/MaxReturn                     -0.00178915
Evaluation/MinReturn                     -0.00195276
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.18039e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.0389
GaussianMLPPolicy/KL                      7.70664e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000188824
GaussianMLPPolicy/LossBefore              0.000188926
GaussianMLPPolicy/dLoss                   1.02416e-07
GaussianMLPValueFunction/LossAfter       -6.76258
GaussianMLPValueFunction/LossBefore      -6.05431
GaussianMLPValueFunction/dLoss            0.708271
TotalEnvSteps                        933066
-----------------------------------  ----------------
2022-08-23 10:44:59 | [trpo_pendulum] epoch #467 | Saving snapshot...
2022-08-23 10:44:59 | [trpo_pendulum] epoch #467 | Saved
2022-08-23 10:44:59 | [trpo_pendulum] epoch #467 | Time 460.37 s
2022-08-23 10:44:59 | [trpo_pendulum] epoch #467 | EpochTime 1.05 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00021878
Evaluation/AverageReturn                 -0.00210599
Evaluation/Iteration                    467
Evaluation/MaxReturn                     -0.00209975
Evaluation/MinReturn                     -0.00211223
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.23965e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.0389
GaussianMLPPolicy/KL                      1.16345e-08
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -4.9761e-05
GaussianMLPPolicy/LossBefore             -4.9761e-05
GaussianMLPPolicy/dLoss                   7.27596e-12
GaussianMLPValueFunction/LossAfter       -6.81595
GaussianMLPValueFunction/LossBefore      -6.82031
GaussianMLPValueFunction/dLoss           -0.00435543
TotalEnvSteps                        935064
-----------------------------------  ----------------
2022-08-23 10:45:00 | [trpo_pendulum] epoch #468 | Saving snapshot...
2022-08-23 10:45:00 | [trpo_pendulum] epoch #468 | Saved
2022-08-23 10:45:00 | [trpo_pendulum] epoch #468 | Time 461.39 s
2022-08-23 10:45:00 | [trpo_pendulum] epoch #468 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000187485
Evaluation/AverageReturn                 -0.00192554
Evaluation/Iteration                    468
Evaluation/MaxReturn                     -0.00191543
Evaluation/MinReturn                     -0.00193565
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.01101e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.0389
GaussianMLPPolicy/KL                      1.99145e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -6.57786e-05
GaussianMLPPolicy/LossBefore             -6.57505e-05
GaussianMLPPolicy/dLoss                   2.81361e-08
GaussianMLPValueFunction/LossAfter       -6.73711
GaussianMLPValueFunction/LossBefore      -6.77778
GaussianMLPValueFunction/dLoss           -0.0406713
TotalEnvSteps                        937062
-----------------------------------  ----------------
2022-08-23 10:45:01 | [trpo_pendulum] epoch #469 | Saving snapshot...
2022-08-23 10:45:01 | [trpo_pendulum] epoch #469 | Saved
2022-08-23 10:45:01 | [trpo_pendulum] epoch #469 | Time 462.36 s
2022-08-23 10:45:01 | [trpo_pendulum] epoch #469 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000191111
Evaluation/AverageReturn                 -0.00208234
Evaluation/Iteration                    469
Evaluation/MaxReturn                     -0.00199884
Evaluation/MinReturn                     -0.00216584
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      8.35017e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03933
GaussianMLPPolicy/KL                      6.69515e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -5.48441e-05
GaussianMLPPolicy/LossBefore             -5.48348e-05
GaussianMLPPolicy/dLoss                   9.34597e-09
GaussianMLPValueFunction/LossAfter       -6.87435
GaussianMLPValueFunction/LossBefore      -6.80441
GaussianMLPValueFunction/dLoss            0.069943
TotalEnvSteps                        939060
-----------------------------------  ----------------
2022-08-23 10:45:01 | [trpo_pendulum] epoch #470 | Saving snapshot...
2022-08-23 10:45:02 | [trpo_pendulum] epoch #470 | Saved
2022-08-23 10:45:02 | [trpo_pendulum] epoch #470 | Time 463.32 s
2022-08-23 10:45:02 | [trpo_pendulum] epoch #470 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000195962
Evaluation/AverageReturn                 -0.00197277
Evaluation/Iteration                    470
Evaluation/MaxReturn                     -0.00179293
Evaluation/MinReturn                     -0.00215261
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000179837
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03933
GaussianMLPPolicy/KL                      2.4164e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.92333e-05
GaussianMLPPolicy/LossBefore             -3.92329e-05
GaussianMLPPolicy/dLoss                   3.85626e-10
GaussianMLPValueFunction/LossAfter       -6.74643
GaussianMLPValueFunction/LossBefore      -6.84658
GaussianMLPValueFunction/dLoss           -0.100157
TotalEnvSteps                        941058
-----------------------------------  ----------------
2022-08-23 10:45:02 | [trpo_pendulum] epoch #471 | Saving snapshot...
2022-08-23 10:45:02 | [trpo_pendulum] epoch #471 | Saved
2022-08-23 10:45:02 | [trpo_pendulum] epoch #471 | Time 464.27 s
2022-08-23 10:45:02 | [trpo_pendulum] epoch #471 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00019354
Evaluation/AverageReturn                 -0.00200153
Evaluation/Iteration                    471
Evaluation/MaxReturn                     -0.0018699
Evaluation/MinReturn                     -0.00213315
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000131625
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03933
GaussianMLPPolicy/KL                      1.40459e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -7.27825e-05
GaussianMLPPolicy/LossBefore             -7.27806e-05
GaussianMLPPolicy/dLoss                   1.96451e-09
GaussianMLPValueFunction/LossAfter       -6.84981
GaussianMLPValueFunction/LossBefore      -6.75574
GaussianMLPValueFunction/dLoss            0.0940633
TotalEnvSteps                        943056
-----------------------------------  ----------------
2022-08-23 10:45:03 | [trpo_pendulum] epoch #472 | Saving snapshot...
2022-08-23 10:45:03 | [trpo_pendulum] epoch #472 | Saved
2022-08-23 10:45:03 | [trpo_pendulum] epoch #472 | Time 465.25 s
2022-08-23 10:45:03 | [trpo_pendulum] epoch #472 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.0002023
Evaluation/AverageReturn                 -0.00216479
Evaluation/Iteration                    472
Evaluation/MaxReturn                     -0.00212355
Evaluation/MinReturn                     -0.00220602
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.12339e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03944
GaussianMLPPolicy/KL                      2.58458e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               6.9916e-05
GaussianMLPPolicy/LossBefore              6.99525e-05
GaussianMLPPolicy/dLoss                   3.64889e-08
GaussianMLPValueFunction/LossAfter       -6.84276
GaussianMLPValueFunction/LossBefore      -6.7581
GaussianMLPValueFunction/dLoss            0.0846562
TotalEnvSteps                        945054
-----------------------------------  ----------------
2022-08-23 10:45:04 | [trpo_pendulum] epoch #473 | Saving snapshot...
2022-08-23 10:45:04 | [trpo_pendulum] epoch #473 | Saved
2022-08-23 10:45:04 | [trpo_pendulum] epoch #473 | Time 466.24 s
2022-08-23 10:45:04 | [trpo_pendulum] epoch #473 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00018771
Evaluation/AverageReturn                 -0.00197269
Evaluation/Iteration                    473
Evaluation/MaxReturn                     -0.00195689
Evaluation/MinReturn                     -0.00198849
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.58018e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.0401
GaussianMLPPolicy/KL                      1.49099e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -6.38073e-05
GaussianMLPPolicy/LossBefore             -6.37864e-05
GaussianMLPPolicy/dLoss                   2.09111e-08
GaussianMLPValueFunction/LossAfter       -6.8045
GaussianMLPValueFunction/LossBefore      -6.78475
GaussianMLPValueFunction/dLoss            0.0197449
TotalEnvSteps                        947052
-----------------------------------  ----------------
2022-08-23 10:45:05 | [trpo_pendulum] epoch #474 | Saving snapshot...
2022-08-23 10:45:05 | [trpo_pendulum] epoch #474 | Saved
2022-08-23 10:45:05 | [trpo_pendulum] epoch #474 | Time 467.21 s
2022-08-23 10:45:05 | [trpo_pendulum] epoch #474 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000194541
Evaluation/AverageReturn                 -0.00195724
Evaluation/Iteration                    474
Evaluation/MaxReturn                     -0.00194389
Evaluation/MinReturn                     -0.00197059
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.33503e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.0401
GaussianMLPPolicy/KL                      1.78811e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               5.27861e-05
GaussianMLPPolicy/LossBefore              5.27887e-05
GaussianMLPPolicy/dLoss                   2.56841e-09
GaussianMLPValueFunction/LossAfter       -6.86532
GaussianMLPValueFunction/LossBefore      -6.81992
GaussianMLPValueFunction/dLoss            0.0453992
TotalEnvSteps                        949050
-----------------------------------  ----------------
2022-08-23 10:45:06 | [trpo_pendulum] epoch #475 | Saving snapshot...
2022-08-23 10:45:06 | [trpo_pendulum] epoch #475 | Saved
2022-08-23 10:45:06 | [trpo_pendulum] epoch #475 | Time 468.13 s
2022-08-23 10:45:06 | [trpo_pendulum] epoch #475 | EpochTime 0.92 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000198614
Evaluation/AverageReturn                 -0.00221085
Evaluation/Iteration                    475
Evaluation/MaxReturn                     -0.00214918
Evaluation/MinReturn                     -0.00227253
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.16708e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.04435
GaussianMLPPolicy/KL                      3.41383e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               8.85312e-06
GaussianMLPPolicy/LossBefore              8.9015e-06
GaussianMLPPolicy/dLoss                   4.83769e-08
GaussianMLPValueFunction/LossAfter       -6.67045
GaussianMLPValueFunction/LossBefore      -6.8615
GaussianMLPValueFunction/dLoss           -0.191057
TotalEnvSteps                        951048
-----------------------------------  ----------------
2022-08-23 10:45:07 | [trpo_pendulum] epoch #476 | Saving snapshot...
2022-08-23 10:45:07 | [trpo_pendulum] epoch #476 | Saved
2022-08-23 10:45:07 | [trpo_pendulum] epoch #476 | Time 469.07 s
2022-08-23 10:45:07 | [trpo_pendulum] epoch #476 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000207588
Evaluation/AverageReturn                 -0.00204448
Evaluation/Iteration                    476
Evaluation/MaxReturn                     -0.0020262
Evaluation/MinReturn                     -0.00206276
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.82791e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.04442
GaussianMLPPolicy/KL                      2.05558e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000111986
GaussianMLPPolicy/LossBefore             -0.000111957
GaussianMLPPolicy/dLoss                   2.91184e-08
GaussianMLPValueFunction/LossAfter       -5.39729
GaussianMLPValueFunction/LossBefore      -6.58434
GaussianMLPValueFunction/dLoss           -1.18705
TotalEnvSteps                        953046
-----------------------------------  ----------------
2022-08-23 10:45:08 | [trpo_pendulum] epoch #477 | Saving snapshot...
2022-08-23 10:45:08 | [trpo_pendulum] epoch #477 | Saved
2022-08-23 10:45:08 | [trpo_pendulum] epoch #477 | Time 470.05 s
2022-08-23 10:45:08 | [trpo_pendulum] epoch #477 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000197175
Evaluation/AverageReturn                 -0.00224586
Evaluation/Iteration                    477
Evaluation/MaxReturn                     -0.00222992
Evaluation/MinReturn                     -0.00226181
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.59479e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.04141
GaussianMLPPolicy/KL                      0.000317184
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000222989
GaussianMLPPolicy/LossBefore             -0.000222506
GaussianMLPPolicy/dLoss                   4.83458e-07
GaussianMLPValueFunction/LossAfter       -5.74806
GaussianMLPValueFunction/LossBefore      -5.69221
GaussianMLPValueFunction/dLoss            0.0558529
TotalEnvSteps                        955044
-----------------------------------  ----------------
2022-08-23 10:45:09 | [trpo_pendulum] epoch #478 | Saving snapshot...
2022-08-23 10:45:09 | [trpo_pendulum] epoch #478 | Saved
2022-08-23 10:45:09 | [trpo_pendulum] epoch #478 | Time 471.00 s
2022-08-23 10:45:09 | [trpo_pendulum] epoch #478 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000198861
Evaluation/AverageReturn                 -0.00190351
Evaluation/Iteration                    478
Evaluation/MaxReturn                     -0.00183588
Evaluation/MinReturn                     -0.00197115
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      6.76373e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.04141
GaussianMLPPolicy/KL                      3.72037e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000262516
GaussianMLPPolicy/LossBefore             -0.000262511
GaussianMLPPolicy/dLoss                   4.97676e-09
GaussianMLPValueFunction/LossAfter       -3.43531
GaussianMLPValueFunction/LossBefore      -5.24639
GaussianMLPValueFunction/dLoss           -1.81108
TotalEnvSteps                        957042
-----------------------------------  ----------------
2022-08-23 10:45:10 | [trpo_pendulum] epoch #479 | Saving snapshot...
2022-08-23 10:45:10 | [trpo_pendulum] epoch #479 | Saved
2022-08-23 10:45:10 | [trpo_pendulum] epoch #479 | Time 472.04 s
2022-08-23 10:45:10 | [trpo_pendulum] epoch #479 | EpochTime 1.03 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000180726
Evaluation/AverageReturn                 -0.00194081
Evaluation/Iteration                    479
Evaluation/MaxReturn                     -0.0019358
Evaluation/MinReturn                     -0.00194583
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.01283e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03928
GaussianMLPPolicy/KL                      0.000101201
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000379197
GaussianMLPPolicy/LossBefore             -0.000379077
GaussianMLPPolicy/dLoss                   1.20461e-07
GaussianMLPValueFunction/LossAfter       -6.77308
GaussianMLPValueFunction/LossBefore      -3.46443
GaussianMLPValueFunction/dLoss            3.30865
TotalEnvSteps                        959040
-----------------------------------  ----------------
2022-08-23 10:45:11 | [trpo_pendulum] epoch #480 | Saving snapshot...
2022-08-23 10:45:11 | [trpo_pendulum] epoch #480 | Saved
2022-08-23 10:45:11 | [trpo_pendulum] epoch #480 | Time 472.98 s
2022-08-23 10:45:11 | [trpo_pendulum] epoch #480 | EpochTime 0.94 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000194008
Evaluation/AverageReturn                 -0.00188095
Evaluation/Iteration                    480
Evaluation/MaxReturn                     -0.00177591
Evaluation/MinReturn                     -0.00198599
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000105039
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03928
GaussianMLPPolicy/KL                      4.12728e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               6.35694e-05
GaussianMLPPolicy/LossBefore              6.35699e-05
GaussianMLPPolicy/dLoss                   4.94765e-10
GaussianMLPValueFunction/LossAfter       -6.87801
GaussianMLPValueFunction/LossBefore      -6.78508
GaussianMLPValueFunction/dLoss            0.0929317
TotalEnvSteps                        961038
-----------------------------------  ----------------
2022-08-23 10:45:12 | [trpo_pendulum] epoch #481 | Saving snapshot...
2022-08-23 10:45:12 | [trpo_pendulum] epoch #481 | Saved
2022-08-23 10:45:12 | [trpo_pendulum] epoch #481 | Time 474.01 s
2022-08-23 10:45:12 | [trpo_pendulum] epoch #481 | EpochTime 1.03 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000222711
Evaluation/AverageReturn                 -0.00226305
Evaluation/Iteration                    481
Evaluation/MaxReturn                     -0.00223084
Evaluation/MinReturn                     -0.00229527
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.22181e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03939
GaussianMLPPolicy/KL                      4.58259e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               2.61402e-05
GaussianMLPPolicy/LossBefore              2.62053e-05
GaussianMLPPolicy/dLoss                   6.51216e-08
GaussianMLPValueFunction/LossAfter       -6.87039
GaussianMLPValueFunction/LossBefore      -6.84787
GaussianMLPValueFunction/dLoss            0.0225129
TotalEnvSteps                        963036
-----------------------------------  ----------------
2022-08-23 10:45:13 | [trpo_pendulum] epoch #482 | Saving snapshot...
2022-08-23 10:45:13 | [trpo_pendulum] epoch #482 | Saved
2022-08-23 10:45:13 | [trpo_pendulum] epoch #482 | Time 474.94 s
2022-08-23 10:45:13 | [trpo_pendulum] epoch #482 | EpochTime 0.92 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000222897
Evaluation/AverageReturn                 -0.00205861
Evaluation/Iteration                    482
Evaluation/MaxReturn                     -0.00205453
Evaluation/MinReturn                     -0.00206269
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.08096e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03939
GaussianMLPPolicy/KL                      2.48439e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -6.5162e-06
GaussianMLPPolicy/LossBefore             -6.51276e-06
GaussianMLPPolicy/dLoss                   3.43971e-09
GaussianMLPValueFunction/LossAfter       -6.16317
GaussianMLPValueFunction/LossBefore      -6.88152
GaussianMLPValueFunction/dLoss           -0.718351
TotalEnvSteps                        965034
-----------------------------------  ----------------
2022-08-23 10:45:14 | [trpo_pendulum] epoch #483 | Saving snapshot...
2022-08-23 10:45:14 | [trpo_pendulum] epoch #483 | Saved
2022-08-23 10:45:14 | [trpo_pendulum] epoch #483 | Time 475.95 s
2022-08-23 10:45:14 | [trpo_pendulum] epoch #483 | EpochTime 1.01 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000212654
Evaluation/AverageReturn                 -0.00219051
Evaluation/Iteration                    483
Evaluation/MaxReturn                     -0.00217103
Evaluation/MinReturn                     -0.00220999
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.9477e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.03947
GaussianMLPPolicy/KL                      0.000104254
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000189373
GaussianMLPPolicy/LossBefore              0.000189521
GaussianMLPPolicy/dLoss                   1.48211e-07
GaussianMLPValueFunction/LossAfter       -5.39789
GaussianMLPValueFunction/LossBefore      -6.02674
GaussianMLPValueFunction/dLoss           -0.628851
TotalEnvSteps                        967032
-----------------------------------  ----------------
2022-08-23 10:45:15 | [trpo_pendulum] epoch #484 | Saving snapshot...
2022-08-23 10:45:15 | [trpo_pendulum] epoch #484 | Saved
2022-08-23 10:45:15 | [trpo_pendulum] epoch #484 | Time 477.02 s
2022-08-23 10:45:15 | [trpo_pendulum] epoch #484 | EpochTime 1.07 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000219723
Evaluation/AverageReturn                 -0.00210502
Evaluation/Iteration                    484
Evaluation/MaxReturn                     -0.00209053
Evaluation/MinReturn                     -0.00211951
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.4492e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.04608
GaussianMLPPolicy/KL                      6.66767e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000237024
GaussianMLPPolicy/LossBefore              0.000237117
GaussianMLPPolicy/dLoss                   9.25211e-08
GaussianMLPValueFunction/LossAfter       -6.25955
GaussianMLPValueFunction/LossBefore      -5.55522
GaussianMLPValueFunction/dLoss            0.70433
TotalEnvSteps                        969030
-----------------------------------  ----------------
2022-08-23 10:45:16 | [trpo_pendulum] epoch #485 | Saving snapshot...
2022-08-23 10:45:16 | [trpo_pendulum] epoch #485 | Saved
2022-08-23 10:45:16 | [trpo_pendulum] epoch #485 | Time 478.06 s
2022-08-23 10:45:16 | [trpo_pendulum] epoch #485 | EpochTime 1.03 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000203113
Evaluation/AverageReturn                 -0.00199716
Evaluation/Iteration                    485
Evaluation/MaxReturn                     -0.00196984
Evaluation/MinReturn                     -0.00202448
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.73183e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.04608
GaussianMLPPolicy/KL                      3.66228e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000165901
GaussianMLPPolicy/LossBefore             -0.000165849
GaussianMLPPolicy/dLoss                   5.19067e-08
GaussianMLPValueFunction/LossAfter       -5.88084
GaussianMLPValueFunction/LossBefore      -6.2268
GaussianMLPValueFunction/dLoss           -0.345964
TotalEnvSteps                        971028
-----------------------------------  ----------------
2022-08-23 10:45:17 | [trpo_pendulum] epoch #486 | Saving snapshot...
2022-08-23 10:45:17 | [trpo_pendulum] epoch #486 | Saved
2022-08-23 10:45:17 | [trpo_pendulum] epoch #486 | Time 479.16 s
2022-08-23 10:45:17 | [trpo_pendulum] epoch #486 | EpochTime 1.09 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000206804
Evaluation/AverageReturn                 -0.0020863
Evaluation/Iteration                    486
Evaluation/MaxReturn                     -0.00204426
Evaluation/MinReturn                     -0.00212835
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      4.20444e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.04623
GaussianMLPPolicy/KL                      1.16523e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000194937
GaussianMLPPolicy/LossBefore             -0.00019492
GaussianMLPPolicy/dLoss                   1.63564e-08
GaussianMLPValueFunction/LossAfter       -6.8796
GaussianMLPValueFunction/LossBefore      -5.9708
GaussianMLPValueFunction/dLoss            0.908803
TotalEnvSteps                        973026
-----------------------------------  ----------------
2022-08-23 10:45:18 | [trpo_pendulum] epoch #487 | Saving snapshot...
2022-08-23 10:45:18 | [trpo_pendulum] epoch #487 | Saved
2022-08-23 10:45:18 | [trpo_pendulum] epoch #487 | Time 480.11 s
2022-08-23 10:45:18 | [trpo_pendulum] epoch #487 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000208083
Evaluation/AverageReturn                 -0.00193303
Evaluation/Iteration                    487
Evaluation/MaxReturn                     -0.00191253
Evaluation/MinReturn                     -0.00195354
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.05054e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.04623
GaussianMLPPolicy/KL                      5.95927e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -2.85883e-05
GaussianMLPPolicy/LossBefore             -2.85875e-05
GaussianMLPPolicy/dLoss                   8.29459e-10
GaussianMLPValueFunction/LossAfter       -3.67018
GaussianMLPValueFunction/LossBefore      -6.86508
GaussianMLPValueFunction/dLoss           -3.19489
TotalEnvSteps                        975024
-----------------------------------  ----------------
2022-08-23 10:45:19 | [trpo_pendulum] epoch #488 | Saving snapshot...
2022-08-23 10:45:19 | [trpo_pendulum] epoch #488 | Saved
2022-08-23 10:45:19 | [trpo_pendulum] epoch #488 | Time 481.06 s
2022-08-23 10:45:19 | [trpo_pendulum] epoch #488 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000221309
Evaluation/AverageReturn                 -0.00223366
Evaluation/Iteration                    488
Evaluation/MaxReturn                     -0.00212692
Evaluation/MinReturn                     -0.0023404
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000106743
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.04623
GaussianMLPPolicy/KL                      5.71043e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000330513
GaussianMLPPolicy/LossBefore             -0.000330432
GaussianMLPPolicy/dLoss                   8.11124e-08
GaussianMLPValueFunction/LossAfter       -6.55356
GaussianMLPValueFunction/LossBefore      -4.25908
GaussianMLPValueFunction/dLoss            2.29448
TotalEnvSteps                        977022
-----------------------------------  ----------------
2022-08-23 10:45:20 | [trpo_pendulum] epoch #489 | Saving snapshot...
2022-08-23 10:45:20 | [trpo_pendulum] epoch #489 | Saved
2022-08-23 10:45:20 | [trpo_pendulum] epoch #489 | Time 482.09 s
2022-08-23 10:45:20 | [trpo_pendulum] epoch #489 | EpochTime 1.02 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.00021277
Evaluation/AverageReturn                 -0.00219141
Evaluation/Iteration                    489
Evaluation/MaxReturn                     -0.00218156
Evaluation/MinReturn                     -0.00220127
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      9.85066e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.04633
GaussianMLPPolicy/KL                      4.60189e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               0.000109163
GaussianMLPPolicy/LossBefore              0.000109228
GaussianMLPPolicy/dLoss                   6.54836e-08
GaussianMLPValueFunction/LossAfter       -6.86894
GaussianMLPValueFunction/LossBefore      -6.59069
GaussianMLPValueFunction/dLoss            0.278249
TotalEnvSteps                        979020
-----------------------------------  ----------------
2022-08-23 10:45:21 | [trpo_pendulum] epoch #490 | Saving snapshot...
2022-08-23 10:45:21 | [trpo_pendulum] epoch #490 | Saved
2022-08-23 10:45:21 | [trpo_pendulum] epoch #490 | Time 483.07 s
2022-08-23 10:45:21 | [trpo_pendulum] epoch #490 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000229505
Evaluation/AverageReturn                 -0.00228947
Evaluation/Iteration                    490
Evaluation/MaxReturn                     -0.00225362
Evaluation/MinReturn                     -0.00232532
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.58499e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.04637
GaussianMLPPolicy/KL                      1.2055e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -3.25975e-06
GaussianMLPPolicy/LossBefore             -3.24269e-06
GaussianMLPPolicy/dLoss                   1.70667e-08
GaussianMLPValueFunction/LossAfter       -6.65583
GaussianMLPValueFunction/LossBefore      -6.86578
GaussianMLPValueFunction/dLoss           -0.209942
TotalEnvSteps                        981018
-----------------------------------  ----------------
2022-08-23 10:45:22 | [trpo_pendulum] epoch #491 | Saving snapshot...
2022-08-23 10:45:22 | [trpo_pendulum] epoch #491 | Saved
2022-08-23 10:45:22 | [trpo_pendulum] epoch #491 | Time 484.07 s
2022-08-23 10:45:22 | [trpo_pendulum] epoch #491 | EpochTime 0.99 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000240496
Evaluation/AverageReturn                 -0.00228105
Evaluation/Iteration                    491
Evaluation/MaxReturn                     -0.00224988
Evaluation/MinReturn                     -0.00231223
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      3.11795e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.04926
GaussianMLPPolicy/KL                      4.23056e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -9.54014e-05
GaussianMLPPolicy/LossBefore             -9.53426e-05
GaussianMLPPolicy/dLoss                   5.87606e-08
GaussianMLPValueFunction/LossAfter       -6.54675
GaussianMLPValueFunction/LossBefore      -6.65269
GaussianMLPValueFunction/dLoss           -0.105944
TotalEnvSteps                        983016
-----------------------------------  ----------------
2022-08-23 10:45:23 | [trpo_pendulum] epoch #492 | Saving snapshot...
2022-08-23 10:45:23 | [trpo_pendulum] epoch #492 | Saved
2022-08-23 10:45:23 | [trpo_pendulum] epoch #492 | Time 485.05 s
2022-08-23 10:45:23 | [trpo_pendulum] epoch #492 | EpochTime 0.97 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000178523
Evaluation/AverageReturn                 -0.00177861
Evaluation/Iteration                    492
Evaluation/MaxReturn                     -0.00176401
Evaluation/MinReturn                     -0.00179322
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.46046e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.05784
GaussianMLPPolicy/KL                      9.74288e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000170153
GaussianMLPPolicy/LossBefore             -0.000170016
GaussianMLPPolicy/dLoss                   1.37225e-07
GaussianMLPValueFunction/LossAfter       -6.84761
GaussianMLPValueFunction/LossBefore      -6.19797
GaussianMLPValueFunction/dLoss            0.649638
TotalEnvSteps                        985014
-----------------------------------  ----------------
2022-08-23 10:45:24 | [trpo_pendulum] epoch #493 | Saving snapshot...
2022-08-23 10:45:24 | [trpo_pendulum] epoch #493 | Saved
2022-08-23 10:45:24 | [trpo_pendulum] epoch #493 | Time 486.00 s
2022-08-23 10:45:24 | [trpo_pendulum] epoch #493 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000208796
Evaluation/AverageReturn                 -0.00194723
Evaluation/Iteration                    493
Evaluation/MaxReturn                     -0.00184996
Evaluation/MinReturn                     -0.0020445
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      9.72692e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.05784
GaussianMLPPolicy/KL                      4.46498e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               5.28711e-05
GaussianMLPPolicy/LossBefore              5.28716e-05
GaussianMLPPolicy/dLoss                   5.89353e-10
GaussianMLPValueFunction/LossAfter       -6.80277
GaussianMLPValueFunction/LossBefore      -6.81192
GaussianMLPValueFunction/dLoss           -0.00915051
TotalEnvSteps                        987012
-----------------------------------  ----------------
2022-08-23 10:45:25 | [trpo_pendulum] epoch #494 | Saving snapshot...
2022-08-23 10:45:25 | [trpo_pendulum] epoch #494 | Saved
2022-08-23 10:45:25 | [trpo_pendulum] epoch #494 | Time 486.97 s
2022-08-23 10:45:25 | [trpo_pendulum] epoch #494 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000197897
Evaluation/AverageReturn                 -0.00217267
Evaluation/Iteration                    494
Evaluation/MaxReturn                     -0.00214352
Evaluation/MinReturn                     -0.00220181
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.91424e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.05801
GaussianMLPPolicy/KL                      8.37535e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter               8.73012e-05
GaussianMLPPolicy/LossBefore              8.7313e-05
GaussianMLPPolicy/dLoss                   1.17288e-08
GaussianMLPValueFunction/LossAfter       -6.87321
GaussianMLPValueFunction/LossBefore      -6.69183
GaussianMLPValueFunction/dLoss            0.181377
TotalEnvSteps                        989010
-----------------------------------  ----------------
2022-08-23 10:45:26 | [trpo_pendulum] epoch #495 | Line search condition violated. Rejecting the step!
2022-08-23 10:45:26 | [trpo_pendulum] epoch #495 | Violated because loss not improving
2022-08-23 10:45:26 | [trpo_pendulum] epoch #495 | Saving snapshot...
2022-08-23 10:45:26 | [trpo_pendulum] epoch #495 | Saved
2022-08-23 10:45:26 | [trpo_pendulum] epoch #495 | Time 488.01 s
2022-08-23 10:45:26 | [trpo_pendulum] epoch #495 | EpochTime 1.04 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000196577
Evaluation/AverageReturn                 -0.00216771
Evaluation/Iteration                    495
Evaluation/MaxReturn                     -0.00216555
Evaluation/MinReturn                     -0.00216987
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      2.15866e-06
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.05801
GaussianMLPPolicy/KL                      0
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -1.17848e-05
GaussianMLPPolicy/LossBefore             -1.17848e-05
GaussianMLPPolicy/dLoss                   0
GaussianMLPValueFunction/LossAfter       -6.62474
GaussianMLPValueFunction/LossBefore      -6.87497
GaussianMLPValueFunction/dLoss           -0.250224
TotalEnvSteps                        991008
-----------------------------------  ----------------
2022-08-23 10:45:27 | [trpo_pendulum] epoch #496 | Saving snapshot...
2022-08-23 10:45:27 | [trpo_pendulum] epoch #496 | Saved
2022-08-23 10:45:27 | [trpo_pendulum] epoch #496 | Time 488.99 s
2022-08-23 10:45:27 | [trpo_pendulum] epoch #496 | EpochTime 0.98 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000186201
Evaluation/AverageReturn                 -0.00176563
Evaluation/Iteration                    496
Evaluation/MaxReturn                     -0.0016629
Evaluation/MinReturn                     -0.00186837
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      0.000102735
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.05801
GaussianMLPPolicy/KL                      7.62984e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -0.000141665
GaussianMLPPolicy/LossBefore             -0.000141655
GaussianMLPPolicy/dLoss                   1.07539e-08
GaussianMLPValueFunction/LossAfter       -6.79722
GaussianMLPValueFunction/LossBefore      -6.40841
GaussianMLPValueFunction/dLoss            0.388807
TotalEnvSteps                        993006
-----------------------------------  ----------------
2022-08-23 10:45:28 | [trpo_pendulum] epoch #497 | Saving snapshot...
2022-08-23 10:45:28 | [trpo_pendulum] epoch #497 | Saved
2022-08-23 10:45:28 | [trpo_pendulum] epoch #497 | Time 489.95 s
2022-08-23 10:45:28 | [trpo_pendulum] epoch #497 | EpochTime 0.95 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000217653
Evaluation/AverageReturn                 -0.00197782
Evaluation/Iteration                    497
Evaluation/MaxReturn                     -0.00195994
Evaluation/MinReturn                     -0.0019957
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.78822e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.05801
GaussianMLPPolicy/KL                      3.03587e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -4.61937e-05
GaussianMLPPolicy/LossBefore             -4.61894e-05
GaussianMLPPolicy/dLoss                   4.29645e-09
GaussianMLPValueFunction/LossAfter       -6.62441
GaussianMLPValueFunction/LossBefore      -6.83482
GaussianMLPValueFunction/dLoss           -0.210408
TotalEnvSteps                        995004
-----------------------------------  ----------------
2022-08-23 10:45:29 | [trpo_pendulum] epoch #498 | Saving snapshot...
2022-08-23 10:45:29 | [trpo_pendulum] epoch #498 | Saved
2022-08-23 10:45:29 | [trpo_pendulum] epoch #498 | Time 490.91 s
2022-08-23 10:45:29 | [trpo_pendulum] epoch #498 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000207769
Evaluation/AverageReturn                 -0.0021274
Evaluation/Iteration                    498
Evaluation/MaxReturn                     -0.00211509
Evaluation/MinReturn                     -0.00213972
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      1.23155e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.05814
GaussianMLPPolicy/KL                      1.37096e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -7.89089e-05
GaussianMLPPolicy/LossBefore             -7.88896e-05
GaussianMLPPolicy/dLoss                   1.93395e-08
GaussianMLPValueFunction/LossAfter       -6.85963
GaussianMLPValueFunction/LossBefore      -6.73191
GaussianMLPValueFunction/dLoss            0.127725
TotalEnvSteps                        997002
-----------------------------------  ----------------
2022-08-23 10:45:30 | [trpo_pendulum] epoch #499 | Saving snapshot...
2022-08-23 10:45:30 | [trpo_pendulum] epoch #499 | Saved
2022-08-23 10:45:30 | [trpo_pendulum] epoch #499 | Time 491.87 s
2022-08-23 10:45:30 | [trpo_pendulum] epoch #499 | EpochTime 0.96 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn       -0.000205134
Evaluation/AverageReturn                 -0.0018948
Evaluation/Iteration                    499
Evaluation/MaxReturn                     -0.00183976
Evaluation/MinReturn                     -0.00194984
Evaluation/NumEpisodes                    2
Evaluation/StdReturn                      5.50412e-05
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                -4.05814
GaussianMLPPolicy/KL                      1.0301e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter              -6.77576e-06
GaussianMLPPolicy/LossBefore             -6.7756e-06
GaussianMLPPolicy/dLoss                   1.52795e-10
GaussianMLPValueFunction/LossAfter       -6.82513
GaussianMLPValueFunction/LossBefore      -6.88668
GaussianMLPValueFunction/dLoss           -0.0615501
TotalEnvSteps                        999000
-----------------------------------  ----------------
