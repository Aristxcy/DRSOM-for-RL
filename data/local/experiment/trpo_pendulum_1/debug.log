2022-08-17 17:54:39 | [trpo_pendulum] Logging to d:\Github\DRSOM-for-RL\data/local/experiment/trpo_pendulum_1
2022-08-17 17:54:40 | [trpo_pendulum] Obtaining samples...
2022-08-17 17:54:40 | [trpo_pendulum] epoch #0 | Saving snapshot...
2022-08-17 17:54:40 | [trpo_pendulum] epoch #0 | Saved
2022-08-17 17:54:40 | [trpo_pendulum] epoch #0 | Time 0.42 s
2022-08-17 17:54:40 | [trpo_pendulum] epoch #0 | EpochTime 0.42 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -578.086
Evaluation/AverageReturn             -1392.36
Evaluation/Iteration                     0
Evaluation/MaxReturn                 -1305.66
Evaluation/MinReturn                 -1513.83
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    67.1703
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41794
GaussianMLPPolicy/KL                     0.00377344
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -587.307
GaussianMLPPolicy/LossBefore          -584.229
GaussianMLPPolicy/dLoss                  3.078
GaussianMLPValueFunction/LossAfter   97405
GaussianMLPValueFunction/LossBefore  97613
GaussianMLPValueFunction/dLoss         207.961
TotalEnvSteps                         1200
-----------------------------------  --------------
2022-08-17 17:54:40 | [trpo_pendulum] epoch #1 | Saving snapshot...
2022-08-17 17:54:41 | [trpo_pendulum] epoch #1 | Saved
2022-08-17 17:54:41 | [trpo_pendulum] epoch #1 | Time 0.87 s
2022-08-17 17:54:41 | [trpo_pendulum] epoch #1 | EpochTime 0.45 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -732.476
Evaluation/AverageReturn              -1744.47
Evaluation/Iteration                      1
Evaluation/MaxReturn                  -1683.96
Evaluation/MinReturn                  -1805.37
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     39.8297
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41731
GaussianMLPPolicy/KL                      0.000821985
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -723.729
GaussianMLPPolicy/LossBefore           -722.932
GaussianMLPPolicy/dLoss                   0.797607
GaussianMLPValueFunction/LossAfter   150987
GaussianMLPValueFunction/LossBefore  151310
GaussianMLPValueFunction/dLoss          322.984
TotalEnvSteps                          2400
-----------------------------------  ----------------
2022-08-17 17:54:41 | [trpo_pendulum] epoch #2 | Saving snapshot...
2022-08-17 17:54:41 | [trpo_pendulum] epoch #2 | Saved
2022-08-17 17:54:41 | [trpo_pendulum] epoch #2 | Time 1.34 s
2022-08-17 17:54:41 | [trpo_pendulum] epoch #2 | EpochTime 0.46 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -769.133
Evaluation/AverageReturn              -1811.33
Evaluation/Iteration                      2
Evaluation/MaxReturn                  -1767.41
Evaluation/MinReturn                  -1842.9
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     23.7497
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41748
GaussianMLPPolicy/KL                      0.000745071
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -742.887
GaussianMLPPolicy/LossBefore           -741.796
GaussianMLPPolicy/dLoss                   1.09076
GaussianMLPValueFunction/LossAfter   161011
GaussianMLPValueFunction/LossBefore  161360
GaussianMLPValueFunction/dLoss          348.422
TotalEnvSteps                          3600
-----------------------------------  ----------------
2022-08-17 17:54:41 | [trpo_pendulum] epoch #3 | Saving snapshot...
2022-08-17 17:54:41 | [trpo_pendulum] epoch #3 | Saved
2022-08-17 17:54:41 | [trpo_pendulum] epoch #3 | Time 1.80 s
2022-08-17 17:54:41 | [trpo_pendulum] epoch #3 | EpochTime 0.46 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -537.978
Evaluation/AverageReturn             -1359.11
Evaluation/Iteration                     3
Evaluation/MaxReturn                 -1235.32
Evaluation/MinReturn                 -1437.33
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    72.7889
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41808
GaussianMLPPolicy/KL                     0.00126388
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -577.778
GaussianMLPPolicy/LossBefore          -575.878
GaussianMLPPolicy/dLoss                  1.89941
GaussianMLPValueFunction/LossAfter   96386.7
GaussianMLPValueFunction/LossBefore  96583.1
GaussianMLPValueFunction/dLoss         196.367
TotalEnvSteps                         4800
-----------------------------------  --------------
2022-08-17 17:54:42 | [trpo_pendulum] epoch #4 | Saving snapshot...
2022-08-17 17:54:42 | [trpo_pendulum] epoch #4 | Saved
2022-08-17 17:54:42 | [trpo_pendulum] epoch #4 | Time 2.25 s
2022-08-17 17:54:42 | [trpo_pendulum] epoch #4 | EpochTime 0.44 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -781.32
Evaluation/AverageReturn              -1824.53
Evaluation/Iteration                      4
Evaluation/MaxReturn                  -1790.86
Evaluation/MinReturn                  -1881.28
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     30.4838
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41882
GaussianMLPPolicy/KL                      0.000173083
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -734.414
GaussianMLPPolicy/LossBefore           -734.134
GaussianMLPPolicy/dLoss                   0.280029
GaussianMLPValueFunction/LossAfter   160843
GaussianMLPValueFunction/LossBefore  161187
GaussianMLPValueFunction/dLoss          343.969
TotalEnvSteps                          6000
-----------------------------------  ----------------
2022-08-17 17:54:42 | [trpo_pendulum] epoch #5 | Saving snapshot...
2022-08-17 17:54:42 | [trpo_pendulum] epoch #5 | Saved
2022-08-17 17:54:42 | [trpo_pendulum] epoch #5 | Time 2.68 s
2022-08-17 17:54:42 | [trpo_pendulum] epoch #5 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -767.272
Evaluation/AverageReturn              -1813.18
Evaluation/Iteration                      5
Evaluation/MaxReturn                  -1746.03
Evaluation/MinReturn                  -1849.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     32.4446
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41864
GaussianMLPPolicy/KL                      0.000291996
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -778.545
GaussianMLPPolicy/LossBefore           -777.886
GaussianMLPPolicy/dLoss                   0.659363
GaussianMLPValueFunction/LossAfter   160699
GaussianMLPValueFunction/LossBefore  161046
GaussianMLPValueFunction/dLoss          346.891
TotalEnvSteps                          7200
-----------------------------------  ----------------
2022-08-17 17:54:43 | [trpo_pendulum] epoch #6 | Saving snapshot...
2022-08-17 17:54:43 | [trpo_pendulum] epoch #6 | Saved
2022-08-17 17:54:43 | [trpo_pendulum] epoch #6 | Time 3.09 s
2022-08-17 17:54:43 | [trpo_pendulum] epoch #6 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -726.048
Evaluation/AverageReturn              -1754.92
Evaluation/Iteration                      6
Evaluation/MaxReturn                  -1704.63
Evaluation/MinReturn                  -1816.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     42.6711
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41856
GaussianMLPPolicy/KL                      0.000383846
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -731.073
GaussianMLPPolicy/LossBefore           -730.568
GaussianMLPPolicy/dLoss                   0.505432
GaussianMLPValueFunction/LossAfter   154505
GaussianMLPValueFunction/LossBefore  154839
GaussianMLPValueFunction/dLoss          334.266
TotalEnvSteps                          8400
-----------------------------------  ----------------
2022-08-17 17:54:43 | [trpo_pendulum] epoch #7 | Saving snapshot...
2022-08-17 17:54:43 | [trpo_pendulum] epoch #7 | Saved
2022-08-17 17:54:43 | [trpo_pendulum] epoch #7 | Time 3.51 s
2022-08-17 17:54:43 | [trpo_pendulum] epoch #7 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -685.481
Evaluation/AverageReturn              -1693.58
Evaluation/Iteration                      7
Evaluation/MaxReturn                  -1680.88
Evaluation/MinReturn                  -1720.73
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.0142
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41829
GaussianMLPPolicy/KL                      0.000374923
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -734.878
GaussianMLPPolicy/LossBefore           -734.594
GaussianMLPPolicy/dLoss                   0.283997
GaussianMLPValueFunction/LossAfter   146412
GaussianMLPValueFunction/LossBefore  146728
GaussianMLPValueFunction/dLoss          315.5
TotalEnvSteps                          9600
-----------------------------------  ----------------
2022-08-17 17:54:44 | [trpo_pendulum] epoch #8 | Saving snapshot...
2022-08-17 17:54:44 | [trpo_pendulum] epoch #8 | Saved
2022-08-17 17:54:44 | [trpo_pendulum] epoch #8 | Time 3.93 s
2022-08-17 17:54:44 | [trpo_pendulum] epoch #8 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -747.174
Evaluation/AverageReturn              -1787.3
Evaluation/Iteration                      8
Evaluation/MaxReturn                  -1738.16
Evaluation/MinReturn                  -1813.53
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     25.3336
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41795
GaussianMLPPolicy/KL                      0.000290466
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -751.941
GaussianMLPPolicy/LossBefore           -751.58
GaussianMLPPolicy/dLoss                   0.360962
GaussianMLPValueFunction/LossAfter   157707
GaussianMLPValueFunction/LossBefore  158051
GaussianMLPValueFunction/dLoss          344.016
TotalEnvSteps                         10800
-----------------------------------  ----------------
2022-08-17 17:54:44 | [trpo_pendulum] epoch #9 | Saving snapshot...
2022-08-17 17:54:44 | [trpo_pendulum] epoch #9 | Saved
2022-08-17 17:54:44 | [trpo_pendulum] epoch #9 | Time 4.33 s
2022-08-17 17:54:44 | [trpo_pendulum] epoch #9 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -784.291
Evaluation/AverageReturn              -1833.01
Evaluation/Iteration                      9
Evaluation/MaxReturn                  -1789.58
Evaluation/MinReturn                  -1861.86
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     28.5398
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4175
GaussianMLPPolicy/KL                      0.00033904
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -762.839
GaussianMLPPolicy/LossBefore           -762.128
GaussianMLPPolicy/dLoss                   0.711182
GaussianMLPValueFunction/LossAfter   161148
GaussianMLPValueFunction/LossBefore  161501
GaussianMLPValueFunction/dLoss          353.734
TotalEnvSteps                         12000
-----------------------------------  ---------------
2022-08-17 17:54:44 | [trpo_pendulum] epoch #10 | Saving snapshot...
2022-08-17 17:54:44 | [trpo_pendulum] epoch #10 | Saved
2022-08-17 17:54:44 | [trpo_pendulum] epoch #10 | Time 4.74 s
2022-08-17 17:54:44 | [trpo_pendulum] epoch #10 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -622.065
Evaluation/AverageReturn              -1596.21
Evaluation/Iteration                     10
Evaluation/MaxReturn                  -1577.51
Evaluation/MinReturn                  -1611.02
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.0196
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41709
GaussianMLPPolicy/KL                      0.000617428
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -697.073
GaussianMLPPolicy/LossBefore           -695.988
GaussianMLPPolicy/dLoss                   1.08478
GaussianMLPValueFunction/LossAfter   134557
GaussianMLPValueFunction/LossBefore  134845
GaussianMLPValueFunction/dLoss          288.594
TotalEnvSteps                         13200
-----------------------------------  ----------------
2022-08-17 17:54:45 | [trpo_pendulum] epoch #11 | Saving snapshot...
2022-08-17 17:54:45 | [trpo_pendulum] epoch #11 | Saved
2022-08-17 17:54:45 | [trpo_pendulum] epoch #11 | Time 5.16 s
2022-08-17 17:54:45 | [trpo_pendulum] epoch #11 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -771.377
Evaluation/AverageReturn              -1829.14
Evaluation/Iteration                     11
Evaluation/MaxReturn                  -1808.55
Evaluation/MinReturn                  -1867.79
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     20.0223
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41668
GaussianMLPPolicy/KL                      0.000350377
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -757.859
GaussianMLPPolicy/LossBefore           -757.482
GaussianMLPPolicy/dLoss                   0.376221
GaussianMLPValueFunction/LossAfter   162576
GaussianMLPValueFunction/LossBefore  162932
GaussianMLPValueFunction/dLoss          356.25
TotalEnvSteps                         14400
-----------------------------------  ----------------
2022-08-17 17:54:45 | [trpo_pendulum] epoch #12 | Saving snapshot...
2022-08-17 17:54:45 | [trpo_pendulum] epoch #12 | Saved
2022-08-17 17:54:45 | [trpo_pendulum] epoch #12 | Time 5.57 s
2022-08-17 17:54:45 | [trpo_pendulum] epoch #12 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -473.691
Evaluation/AverageReturn              -1394.87
Evaluation/Iteration                     12
Evaluation/MaxReturn                  -1339.37
Evaluation/MinReturn                  -1449.44
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     32.9646
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41647
GaussianMLPPolicy/KL                      0.00044133
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -643.988
GaussianMLPPolicy/LossBefore           -643.595
GaussianMLPPolicy/dLoss                   0.39325
GaussianMLPValueFunction/LossAfter   118008
GaussianMLPValueFunction/LossBefore  118254
GaussianMLPValueFunction/dLoss          246.227
TotalEnvSteps                         15600
-----------------------------------  ---------------
2022-08-17 17:54:46 | [trpo_pendulum] epoch #13 | Saving snapshot...
2022-08-17 17:54:46 | [trpo_pendulum] epoch #13 | Saved
2022-08-17 17:54:46 | [trpo_pendulum] epoch #13 | Time 6.00 s
2022-08-17 17:54:46 | [trpo_pendulum] epoch #13 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -799.703
Evaluation/AverageReturn              -1852.59
Evaluation/Iteration                     13
Evaluation/MaxReturn                  -1797.79
Evaluation/MinReturn                  -1883.71
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     30.6667
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41636
GaussianMLPPolicy/KL                      7.83547e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -743.569
GaussianMLPPolicy/LossBefore           -743.403
GaussianMLPPolicy/dLoss                   0.166443
GaussianMLPValueFunction/LossAfter   160808
GaussianMLPValueFunction/LossBefore  161158
GaussianMLPValueFunction/dLoss          350.203
TotalEnvSteps                         16800
-----------------------------------  ----------------
2022-08-17 17:54:46 | [trpo_pendulum] epoch #14 | Saving snapshot...
2022-08-17 17:54:46 | [trpo_pendulum] epoch #14 | Saved
2022-08-17 17:54:46 | [trpo_pendulum] epoch #14 | Time 6.42 s
2022-08-17 17:54:46 | [trpo_pendulum] epoch #14 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -727.625
Evaluation/AverageReturn              -1764.78
Evaluation/Iteration                     14
Evaluation/MaxReturn                  -1732.31
Evaluation/MinReturn                  -1808.87
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     24.314
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41605
GaussianMLPPolicy/KL                      0.000272393
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -762.542
GaussianMLPPolicy/LossBefore           -761.697
GaussianMLPPolicy/dLoss                   0.845215
GaussianMLPValueFunction/LossAfter   154372
GaussianMLPValueFunction/LossBefore  154707
GaussianMLPValueFunction/dLoss          335.547
TotalEnvSteps                         18000
-----------------------------------  ----------------
2022-08-17 17:54:46 | [trpo_pendulum] epoch #15 | Saving snapshot...
2022-08-17 17:54:46 | [trpo_pendulum] epoch #15 | Saved
2022-08-17 17:54:46 | [trpo_pendulum] epoch #15 | Time 6.84 s
2022-08-17 17:54:46 | [trpo_pendulum] epoch #15 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -560.062
Evaluation/AverageReturn              -1533.27
Evaluation/Iteration                     15
Evaluation/MaxReturn                  -1506.02
Evaluation/MinReturn                  -1563.57
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     18.4802
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41559
GaussianMLPPolicy/KL                      0.000417451
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -713.972
GaussianMLPPolicy/LossBefore           -713.647
GaussianMLPPolicy/dLoss                   0.324585
GaussianMLPValueFunction/LossAfter   132560
GaussianMLPValueFunction/LossBefore  132840
GaussianMLPValueFunction/dLoss          279.781
TotalEnvSteps                         19200
-----------------------------------  ----------------
2022-08-17 17:54:47 | [trpo_pendulum] epoch #16 | Saving snapshot...
2022-08-17 17:54:47 | [trpo_pendulum] epoch #16 | Saved
2022-08-17 17:54:47 | [trpo_pendulum] epoch #16 | Time 7.27 s
2022-08-17 17:54:47 | [trpo_pendulum] epoch #16 | EpochTime 0.42 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -653.698
Evaluation/AverageReturn              -1670.26
Evaluation/Iteration                     16
Evaluation/MaxReturn                  -1652.47
Evaluation/MinReturn                  -1694.01
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.8685
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41522
GaussianMLPPolicy/KL                      4.8438e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -718.905
GaussianMLPPolicy/LossBefore           -719.213
GaussianMLPPolicy/dLoss                  -0.30719
GaussianMLPValueFunction/LossAfter   146249
GaussianMLPValueFunction/LossBefore  146562
GaussianMLPValueFunction/dLoss          312.625
TotalEnvSteps                         20400
-----------------------------------  ---------------
2022-08-17 17:54:47 | [trpo_pendulum] epoch #17 | Saving snapshot...
2022-08-17 17:54:47 | [trpo_pendulum] epoch #17 | Saved
2022-08-17 17:54:47 | [trpo_pendulum] epoch #17 | Time 7.68 s
2022-08-17 17:54:47 | [trpo_pendulum] epoch #17 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -793.973
Evaluation/AverageReturn              -1852.34
Evaluation/Iteration                     17
Evaluation/MaxReturn                  -1842.63
Evaluation/MinReturn                  -1873.17
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.4028
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41471
GaussianMLPPolicy/KL                      7.15909e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -777.837
GaussianMLPPolicy/LossBefore           -777.472
GaussianMLPPolicy/dLoss                   0.364624
GaussianMLPValueFunction/LossAfter   161326
GaussianMLPValueFunction/LossBefore  161678
GaussianMLPValueFunction/dLoss          352.438
TotalEnvSteps                         21600
-----------------------------------  ----------------
2022-08-17 17:54:48 | [trpo_pendulum] epoch #18 | Saving snapshot...
2022-08-17 17:54:48 | [trpo_pendulum] epoch #18 | Saved
2022-08-17 17:54:48 | [trpo_pendulum] epoch #18 | Time 8.10 s
2022-08-17 17:54:48 | [trpo_pendulum] epoch #18 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -792.393
Evaluation/AverageReturn              -1851.33
Evaluation/Iteration                     18
Evaluation/MaxReturn                  -1841.32
Evaluation/MinReturn                  -1866.94
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      7.95334
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41422
GaussianMLPPolicy/KL                      9.20559e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -757.108
GaussianMLPPolicy/LossBefore           -757.091
GaussianMLPPolicy/dLoss                   0.0168457
GaussianMLPValueFunction/LossAfter   160814
GaussianMLPValueFunction/LossBefore  161167
GaussianMLPValueFunction/dLoss          353.469
TotalEnvSteps                         22800
-----------------------------------  ----------------
2022-08-17 17:54:48 | [trpo_pendulum] epoch #19 | Saving snapshot...
2022-08-17 17:54:48 | [trpo_pendulum] epoch #19 | Saved
2022-08-17 17:54:48 | [trpo_pendulum] epoch #19 | Time 8.53 s
2022-08-17 17:54:48 | [trpo_pendulum] epoch #19 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -718.731
Evaluation/AverageReturn              -1767.59
Evaluation/Iteration                     19
Evaluation/MaxReturn                  -1738.83
Evaluation/MinReturn                  -1791.66
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     23.1385
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41377
GaussianMLPPolicy/KL                      3.90685e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -746.502
GaussianMLPPolicy/LossBefore           -746.375
GaussianMLPPolicy/dLoss                   0.126953
GaussianMLPValueFunction/LossAfter   155757
GaussianMLPValueFunction/LossBefore  156098
GaussianMLPValueFunction/dLoss          340.688
TotalEnvSteps                         24000
-----------------------------------  ----------------
2022-08-17 17:54:49 | [trpo_pendulum] epoch #20 | Saving snapshot...
2022-08-17 17:54:49 | [trpo_pendulum] epoch #20 | Saved
2022-08-17 17:54:49 | [trpo_pendulum] epoch #20 | Time 8.97 s
2022-08-17 17:54:49 | [trpo_pendulum] epoch #20 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -699.208
Evaluation/AverageReturn              -1726.99
Evaluation/Iteration                     20
Evaluation/MaxReturn                  -1701.22
Evaluation/MinReturn                  -1759.39
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     19.8782
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41331
GaussianMLPPolicy/KL                      6.45979e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -737.31
GaussianMLPPolicy/LossBefore           -737.045
GaussianMLPPolicy/dLoss                   0.264893
GaussianMLPValueFunction/LossAfter   149312
GaussianMLPValueFunction/LossBefore  149637
GaussianMLPValueFunction/dLoss          325.734
TotalEnvSteps                         25200
-----------------------------------  ----------------
2022-08-17 17:54:49 | [trpo_pendulum] epoch #21 | Saving snapshot...
2022-08-17 17:54:49 | [trpo_pendulum] epoch #21 | Saved
2022-08-17 17:54:49 | [trpo_pendulum] epoch #21 | Time 9.38 s
2022-08-17 17:54:49 | [trpo_pendulum] epoch #21 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -801.136
Evaluation/AverageReturn              -1862.63
Evaluation/Iteration                     21
Evaluation/MaxReturn                  -1853.86
Evaluation/MinReturn                  -1879.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.64593
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41284
GaussianMLPPolicy/KL                      9.0929e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -760.002
GaussianMLPPolicy/LossBefore           -759.71
GaussianMLPPolicy/dLoss                   0.292053
GaussianMLPValueFunction/LossAfter   160712
GaussianMLPValueFunction/LossBefore  161068
GaussianMLPValueFunction/dLoss          356.109
TotalEnvSteps                         26400
-----------------------------------  ---------------
2022-08-17 17:54:49 | [trpo_pendulum] epoch #22 | Saving snapshot...
2022-08-17 17:54:49 | [trpo_pendulum] epoch #22 | Saved
2022-08-17 17:54:49 | [trpo_pendulum] epoch #22 | Time 9.80 s
2022-08-17 17:54:49 | [trpo_pendulum] epoch #22 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -745.882
Evaluation/AverageReturn              -1789.76
Evaluation/Iteration                     22
Evaluation/MaxReturn                  -1767.53
Evaluation/MinReturn                  -1816.31
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     16.983
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41234
GaussianMLPPolicy/KL                      7.82817e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -751.244
GaussianMLPPolicy/LossBefore           -751.078
GaussianMLPPolicy/dLoss                   0.166565
GaussianMLPValueFunction/LossAfter   154287
GaussianMLPValueFunction/LossBefore  154628
GaussianMLPValueFunction/dLoss          341.188
TotalEnvSteps                         27600
-----------------------------------  ----------------
2022-08-17 17:54:50 | [trpo_pendulum] epoch #23 | Saving snapshot...
2022-08-17 17:54:50 | [trpo_pendulum] epoch #23 | Saved
2022-08-17 17:54:50 | [trpo_pendulum] epoch #23 | Time 10.25 s
2022-08-17 17:54:50 | [trpo_pendulum] epoch #23 | EpochTime 0.44 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -629.738
Evaluation/AverageReturn              -1638.15
Evaluation/Iteration                     23
Evaluation/MaxReturn                  -1616.33
Evaluation/MinReturn                  -1666.23
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     16.5386
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41182
GaussianMLPPolicy/KL                      6.78895e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -723.234
GaussianMLPPolicy/LossBefore           -723.232
GaussianMLPPolicy/dLoss                   0.00231934
GaussianMLPValueFunction/LossAfter   141544
GaussianMLPValueFunction/LossBefore  141851
GaussianMLPValueFunction/dLoss          307.391
TotalEnvSteps                         28800
-----------------------------------  ----------------
2022-08-17 17:54:50 | [trpo_pendulum] epoch #24 | Saving snapshot...
2022-08-17 17:54:50 | [trpo_pendulum] epoch #24 | Saved
2022-08-17 17:54:50 | [trpo_pendulum] epoch #24 | Time 10.68 s
2022-08-17 17:54:50 | [trpo_pendulum] epoch #24 | EpochTime 0.42 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -752.416
Evaluation/AverageReturn              -1799.81
Evaluation/Iteration                     24
Evaluation/MaxReturn                  -1777.97
Evaluation/MinReturn                  -1817.9
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.2569
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41139
GaussianMLPPolicy/KL                      3.1525e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -738.587
GaussianMLPPolicy/LossBefore           -738.576
GaussianMLPPolicy/dLoss                   0.0114746
GaussianMLPValueFunction/LossAfter   155125
GaussianMLPValueFunction/LossBefore  155467
GaussianMLPValueFunction/dLoss          342.703
TotalEnvSteps                         30000
-----------------------------------  ---------------
2022-08-17 17:54:51 | [trpo_pendulum] epoch #25 | Saving snapshot...
2022-08-17 17:54:51 | [trpo_pendulum] epoch #25 | Saved
2022-08-17 17:54:51 | [trpo_pendulum] epoch #25 | Time 11.09 s
2022-08-17 17:54:51 | [trpo_pendulum] epoch #25 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -634.083
Evaluation/AverageReturn              -1642.99
Evaluation/Iteration                     25
Evaluation/MaxReturn                  -1628.83
Evaluation/MinReturn                  -1662.41
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     11.1287
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4109
GaussianMLPPolicy/KL                      3.64938e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -726.317
GaussianMLPPolicy/LossBefore           -726.117
GaussianMLPPolicy/dLoss                   0.199158
GaussianMLPValueFunction/LossAfter   140856
GaussianMLPValueFunction/LossBefore  141161
GaussianMLPValueFunction/dLoss          304.812
TotalEnvSteps                         31200
-----------------------------------  ----------------
2022-08-17 17:54:51 | [trpo_pendulum] epoch #26 | Saving snapshot...
2022-08-17 17:54:51 | [trpo_pendulum] epoch #26 | Saved
2022-08-17 17:54:51 | [trpo_pendulum] epoch #26 | Time 11.51 s
2022-08-17 17:54:51 | [trpo_pendulum] epoch #26 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -726.601
Evaluation/AverageReturn              -1776
Evaluation/Iteration                     26
Evaluation/MaxReturn                  -1756.24
Evaluation/MinReturn                  -1795.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     12.7485
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41069
GaussianMLPPolicy/KL                      1.91451e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -720.459
GaussianMLPPolicy/LossBefore           -720.43
GaussianMLPPolicy/dLoss                   0.02948
GaussianMLPValueFunction/LossAfter   153992
GaussianMLPValueFunction/LossBefore  154331
GaussianMLPValueFunction/dLoss          338.406
TotalEnvSteps                         32400
-----------------------------------  ----------------
2022-08-17 17:54:52 | [trpo_pendulum] epoch #27 | Saving snapshot...
2022-08-17 17:54:52 | [trpo_pendulum] epoch #27 | Saved
2022-08-17 17:54:52 | [trpo_pendulum] epoch #27 | Time 11.92 s
2022-08-17 17:54:52 | [trpo_pendulum] epoch #27 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -804.803
Evaluation/AverageReturn              -1863.57
Evaluation/Iteration                     27
Evaluation/MaxReturn                  -1856.43
Evaluation/MinReturn                  -1875.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      6.79301
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41055
GaussianMLPPolicy/KL                      2.23312e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -744.838
GaussianMLPPolicy/LossBefore           -744.827
GaussianMLPPolicy/dLoss                   0.0107422
GaussianMLPValueFunction/LossAfter   157663
GaussianMLPValueFunction/LossBefore  158013
GaussianMLPValueFunction/dLoss          350.578
TotalEnvSteps                         33600
-----------------------------------  ----------------
2022-08-17 17:54:52 | [trpo_pendulum] epoch #28 | Saving snapshot...
2022-08-17 17:54:52 | [trpo_pendulum] epoch #28 | Saved
2022-08-17 17:54:52 | [trpo_pendulum] epoch #28 | Time 12.32 s
2022-08-17 17:54:52 | [trpo_pendulum] epoch #28 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -732.253
Evaluation/AverageReturn              -1776.16
Evaluation/Iteration                     28
Evaluation/MaxReturn                  -1746.07
Evaluation/MinReturn                  -1796.46
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     19.2389
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41053
GaussianMLPPolicy/KL                      5.29353e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -727.8
GaussianMLPPolicy/LossBefore           -727.747
GaussianMLPPolicy/dLoss                   0.0526733
GaussianMLPValueFunction/LossAfter   151923
GaussianMLPValueFunction/LossBefore  152259
GaussianMLPValueFunction/dLoss          335.984
TotalEnvSteps                         34800
-----------------------------------  ----------------
2022-08-17 17:54:52 | [trpo_pendulum] epoch #29 | Saving snapshot...
2022-08-17 17:54:52 | [trpo_pendulum] epoch #29 | Saved
2022-08-17 17:54:52 | [trpo_pendulum] epoch #29 | Time 12.72 s
2022-08-17 17:54:52 | [trpo_pendulum] epoch #29 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -646.491
Evaluation/AverageReturn              -1664.48
Evaluation/Iteration                     29
Evaluation/MaxReturn                  -1622.07
Evaluation/MinReturn                  -1692.8
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     29.8386
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41064
GaussianMLPPolicy/KL                      1.6468e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -704.58
GaussianMLPPolicy/LossBefore           -704.504
GaussianMLPPolicy/dLoss                   0.0760498
GaussianMLPValueFunction/LossAfter   142515
GaussianMLPValueFunction/LossBefore  142825
GaussianMLPValueFunction/dLoss          309.984
TotalEnvSteps                         36000
-----------------------------------  ---------------
2022-08-17 17:54:53 | [trpo_pendulum] epoch #30 | Saving snapshot...
2022-08-17 17:54:53 | [trpo_pendulum] epoch #30 | Saved
2022-08-17 17:54:53 | [trpo_pendulum] epoch #30 | Time 13.14 s
2022-08-17 17:54:53 | [trpo_pendulum] epoch #30 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -712.209
Evaluation/AverageReturn              -1747.4
Evaluation/Iteration                     30
Evaluation/MaxReturn                  -1721.89
Evaluation/MinReturn                  -1766.34
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     15.9679
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41063
GaussianMLPPolicy/KL                      5.82825e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -748.61
GaussianMLPPolicy/LossBefore           -748.195
GaussianMLPPolicy/dLoss                   0.4151
GaussianMLPValueFunction/LossAfter   148454
GaussianMLPValueFunction/LossBefore  148780
GaussianMLPValueFunction/dLoss          326.172
TotalEnvSteps                         37200
-----------------------------------  ----------------
2022-08-17 17:54:53 | [trpo_pendulum] epoch #31 | Saving snapshot...
2022-08-17 17:54:53 | [trpo_pendulum] epoch #31 | Saved
2022-08-17 17:54:53 | [trpo_pendulum] epoch #31 | Time 13.56 s
2022-08-17 17:54:53 | [trpo_pendulum] epoch #31 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -618.644
Evaluation/AverageReturn              -1627.01
Evaluation/Iteration                     31
Evaluation/MaxReturn                  -1612.4
Evaluation/MinReturn                  -1641.42
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.96101
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41061
GaussianMLPPolicy/KL                      4.40179e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -714.008
GaussianMLPPolicy/LossBefore           -714.032
GaussianMLPPolicy/dLoss                  -0.024231
GaussianMLPValueFunction/LossAfter   139193
GaussianMLPValueFunction/LossBefore  139493
GaussianMLPValueFunction/dLoss          300.641
TotalEnvSteps                         38400
-----------------------------------  ----------------
2022-08-17 17:54:54 | [trpo_pendulum] epoch #32 | Saving snapshot...
2022-08-17 17:54:54 | [trpo_pendulum] epoch #32 | Saved
2022-08-17 17:54:54 | [trpo_pendulum] epoch #32 | Time 13.98 s
2022-08-17 17:54:54 | [trpo_pendulum] epoch #32 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -777.417
Evaluation/AverageReturn              -1836.98
Evaluation/Iteration                     32
Evaluation/MaxReturn                  -1811.73
Evaluation/MinReturn                  -1859.12
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.8505
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41061
GaussianMLPPolicy/KL                      1.10851e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -749.217
GaussianMLPPolicy/LossBefore           -749.197
GaussianMLPPolicy/dLoss                   0.020813
GaussianMLPValueFunction/LossAfter   156006
GaussianMLPValueFunction/LossBefore  156351
GaussianMLPValueFunction/dLoss          344.984
TotalEnvSteps                         39600
-----------------------------------  ----------------
2022-08-17 17:54:54 | [trpo_pendulum] epoch #33 | Saving snapshot...
2022-08-17 17:54:54 | [trpo_pendulum] epoch #33 | Saved
2022-08-17 17:54:54 | [trpo_pendulum] epoch #33 | Time 14.40 s
2022-08-17 17:54:54 | [trpo_pendulum] epoch #33 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -629.832
Evaluation/AverageReturn              -1647.68
Evaluation/Iteration                     33
Evaluation/MaxReturn                  -1636.7
Evaluation/MinReturn                  -1667.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.73904
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4107
GaussianMLPPolicy/KL                      1.89833e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -709.644
GaussianMLPPolicy/LossBefore           -709.536
GaussianMLPPolicy/dLoss                   0.108215
GaussianMLPValueFunction/LossAfter   141118
GaussianMLPValueFunction/LossBefore  141423
GaussianMLPValueFunction/dLoss          305.578
TotalEnvSteps                         40800
-----------------------------------  ----------------
2022-08-17 17:54:54 | [trpo_pendulum] epoch #34 | Saving snapshot...
2022-08-17 17:54:54 | [trpo_pendulum] epoch #34 | Saved
2022-08-17 17:54:54 | [trpo_pendulum] epoch #34 | Time 14.84 s
2022-08-17 17:54:54 | [trpo_pendulum] epoch #34 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -516.828
Evaluation/AverageReturn              -1487.2
Evaluation/Iteration                     34
Evaluation/MaxReturn                  -1413.16
Evaluation/MinReturn                  -1553.42
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.711
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41071
GaussianMLPPolicy/KL                      2.66015e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -695.575
GaussianMLPPolicy/LossBefore           -695.49
GaussianMLPPolicy/dLoss                   0.0845947
GaussianMLPValueFunction/LossAfter   126632
GaussianMLPValueFunction/LossBefore  126900
GaussianMLPValueFunction/dLoss          268.32
TotalEnvSteps                         42000
-----------------------------------  ----------------
2022-08-17 17:54:55 | [trpo_pendulum] epoch #35 | Saving snapshot...
2022-08-17 17:54:55 | [trpo_pendulum] epoch #35 | Saved
2022-08-17 17:54:55 | [trpo_pendulum] epoch #35 | Time 15.26 s
2022-08-17 17:54:55 | [trpo_pendulum] epoch #35 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -792.881
Evaluation/AverageReturn              -1853.04
Evaluation/Iteration                     35
Evaluation/MaxReturn                  -1831.65
Evaluation/MinReturn                  -1878.87
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.1511
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41074
GaussianMLPPolicy/KL                      4.17858e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -748.658
GaussianMLPPolicy/LossBefore           -748.446
GaussianMLPPolicy/dLoss                   0.212219
GaussianMLPValueFunction/LossAfter   155311
GaussianMLPValueFunction/LossBefore  155652
GaussianMLPValueFunction/dLoss          341.391
TotalEnvSteps                         43200
-----------------------------------  ----------------
2022-08-17 17:54:55 | [trpo_pendulum] epoch #36 | Saving snapshot...
2022-08-17 17:54:55 | [trpo_pendulum] epoch #36 | Saved
2022-08-17 17:54:55 | [trpo_pendulum] epoch #36 | Time 15.68 s
2022-08-17 17:54:55 | [trpo_pendulum] epoch #36 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -736.761
Evaluation/AverageReturn              -1783.88
Evaluation/Iteration                     36
Evaluation/MaxReturn                  -1769.32
Evaluation/MinReturn                  -1810.03
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.9004
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41072
GaussianMLPPolicy/KL                      5.77046e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -747.206
GaussianMLPPolicy/LossBefore           -747.038
GaussianMLPPolicy/dLoss                   0.168579
GaussianMLPValueFunction/LossAfter   150044
GaussianMLPValueFunction/LossBefore  150374
GaussianMLPValueFunction/dLoss          329.312
TotalEnvSteps                         44400
-----------------------------------  ----------------
2022-08-17 17:54:56 | [trpo_pendulum] epoch #37 | Saving snapshot...
2022-08-17 17:54:56 | [trpo_pendulum] epoch #37 | Saved
2022-08-17 17:54:56 | [trpo_pendulum] epoch #37 | Time 16.21 s
2022-08-17 17:54:56 | [trpo_pendulum] epoch #37 | EpochTime 0.53 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -607.434
Evaluation/AverageReturn              -1621.53
Evaluation/Iteration                     37
Evaluation/MaxReturn                  -1602.61
Evaluation/MinReturn                  -1636.85
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.3809
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41068
GaussianMLPPolicy/KL                      6.70402e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -719.575
GaussianMLPPolicy/LossBefore           -719.485
GaussianMLPPolicy/dLoss                   0.090332
GaussianMLPValueFunction/LossAfter   138732
GaussianMLPValueFunction/LossBefore  139031
GaussianMLPValueFunction/dLoss          298.625
TotalEnvSteps                         45600
-----------------------------------  ----------------
2022-08-17 17:54:56 | [trpo_pendulum] epoch #38 | Saving snapshot...
2022-08-17 17:54:56 | [trpo_pendulum] epoch #38 | Saved
2022-08-17 17:54:56 | [trpo_pendulum] epoch #38 | Time 16.65 s
2022-08-17 17:54:56 | [trpo_pendulum] epoch #38 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -730.671
Evaluation/AverageReturn              -1775.58
Evaluation/Iteration                     38
Evaluation/MaxReturn                  -1768.88
Evaluation/MinReturn                  -1781.34
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      4.07071
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41067
GaussianMLPPolicy/KL                      2.06352e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -737.741
GaussianMLPPolicy/LossBefore           -737.788
GaussianMLPPolicy/dLoss                  -0.046814
GaussianMLPValueFunction/LossAfter   149106
GaussianMLPValueFunction/LossBefore  149433
GaussianMLPValueFunction/dLoss          326.75
TotalEnvSteps                         46800
-----------------------------------  ----------------
2022-08-17 17:54:57 | [trpo_pendulum] epoch #39 | Saving snapshot...
2022-08-17 17:54:57 | [trpo_pendulum] epoch #39 | Saved
2022-08-17 17:54:57 | [trpo_pendulum] epoch #39 | Time 17.06 s
2022-08-17 17:54:57 | [trpo_pendulum] epoch #39 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -716.576
Evaluation/AverageReturn              -1752.32
Evaluation/Iteration                     39
Evaluation/MaxReturn                  -1731
Evaluation/MinReturn                  -1774.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.1691
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41063
GaussianMLPPolicy/KL                      1.48523e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -735.876
GaussianMLPPolicy/LossBefore           -735.61
GaussianMLPPolicy/dLoss                   0.266296
GaussianMLPValueFunction/LossAfter   145890
GaussianMLPValueFunction/LossBefore  146210
GaussianMLPValueFunction/dLoss          319.891
TotalEnvSteps                         48000
-----------------------------------  ----------------
2022-08-17 17:54:57 | [trpo_pendulum] epoch #40 | Saving snapshot...
2022-08-17 17:54:57 | [trpo_pendulum] epoch #40 | Saved
2022-08-17 17:54:57 | [trpo_pendulum] epoch #40 | Time 17.48 s
2022-08-17 17:54:57 | [trpo_pendulum] epoch #40 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -759.296
Evaluation/AverageReturn              -1808.19
Evaluation/Iteration                     40
Evaluation/MaxReturn                  -1791.94
Evaluation/MinReturn                  -1825.38
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.8755
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41071
GaussianMLPPolicy/KL                      4.94572e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -730.067
GaussianMLPPolicy/LossBefore           -729.852
GaussianMLPPolicy/dLoss                   0.215332
GaussianMLPValueFunction/LossAfter   149929
GaussianMLPValueFunction/LossBefore  150261
GaussianMLPValueFunction/dLoss          332.078
TotalEnvSteps                         49200
-----------------------------------  ----------------
2022-08-17 17:54:58 | [trpo_pendulum] epoch #41 | Saving snapshot...
2022-08-17 17:54:58 | [trpo_pendulum] epoch #41 | Saved
2022-08-17 17:54:58 | [trpo_pendulum] epoch #41 | Time 17.90 s
2022-08-17 17:54:58 | [trpo_pendulum] epoch #41 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -804.58
Evaluation/AverageReturn              -1863.9
Evaluation/Iteration                     41
Evaluation/MaxReturn                  -1829.6
Evaluation/MinReturn                  -1885.62
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     17.3403
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41088
GaussianMLPPolicy/KL                      3.94886e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -738.558
GaussianMLPPolicy/LossBefore           -738.544
GaussianMLPPolicy/dLoss                   0.0146484
GaussianMLPValueFunction/LossAfter   153097
GaussianMLPValueFunction/LossBefore  153439
GaussianMLPValueFunction/dLoss          341.984
TotalEnvSteps                         50400
-----------------------------------  ----------------
2022-08-17 17:54:58 | [trpo_pendulum] epoch #42 | Saving snapshot...
2022-08-17 17:54:58 | [trpo_pendulum] epoch #42 | Saved
2022-08-17 17:54:58 | [trpo_pendulum] epoch #42 | Time 18.32 s
2022-08-17 17:54:58 | [trpo_pendulum] epoch #42 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -725.879
Evaluation/AverageReturn              -1767.84
Evaluation/Iteration                     42
Evaluation/MaxReturn                  -1747.67
Evaluation/MinReturn                  -1781.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     12.102
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4109
GaussianMLPPolicy/KL                      9.62497e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -753.445
GaussianMLPPolicy/LossBefore           -752.945
GaussianMLPPolicy/dLoss                   0.499329
GaussianMLPValueFunction/LossAfter   146642
GaussianMLPValueFunction/LossBefore  146968
GaussianMLPValueFunction/dLoss          325.688
TotalEnvSteps                         51600
-----------------------------------  ----------------
2022-08-17 17:54:58 | [trpo_pendulum] epoch #43 | Saving snapshot...
2022-08-17 17:54:58 | [trpo_pendulum] epoch #43 | Saved
2022-08-17 17:54:58 | [trpo_pendulum] epoch #43 | Time 18.74 s
2022-08-17 17:54:58 | [trpo_pendulum] epoch #43 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -729.448
Evaluation/AverageReturn              -1772.24
Evaluation/Iteration                     43
Evaluation/MaxReturn                  -1763.41
Evaluation/MinReturn                  -1791.52
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.92379
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41086
GaussianMLPPolicy/KL                      5.30869e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -744.691
GaussianMLPPolicy/LossBefore           -744.64
GaussianMLPPolicy/dLoss                   0.0507202
GaussianMLPValueFunction/LossAfter   146642
GaussianMLPValueFunction/LossBefore  146968
GaussianMLPValueFunction/dLoss          325.875
TotalEnvSteps                         52800
-----------------------------------  ----------------
2022-08-17 17:54:59 | [trpo_pendulum] epoch #44 | Saving snapshot...
2022-08-17 17:54:59 | [trpo_pendulum] epoch #44 | Saved
2022-08-17 17:54:59 | [trpo_pendulum] epoch #44 | Time 19.17 s
2022-08-17 17:54:59 | [trpo_pendulum] epoch #44 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -813.416
Evaluation/AverageReturn              -1880.83
Evaluation/Iteration                     44
Evaluation/MaxReturn                  -1865.35
Evaluation/MinReturn                  -1894.58
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.3557
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41089
GaussianMLPPolicy/KL                      6.62552e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -747.687
GaussianMLPPolicy/LossBefore           -747.616
GaussianMLPPolicy/dLoss                   0.0708008
GaussianMLPValueFunction/LossAfter   154430
GaussianMLPValueFunction/LossBefore  154778
GaussianMLPValueFunction/dLoss          347.531
TotalEnvSteps                         54000
-----------------------------------  ----------------
2022-08-17 17:54:59 | [trpo_pendulum] epoch #45 | Saving snapshot...
2022-08-17 17:54:59 | [trpo_pendulum] epoch #45 | Saved
2022-08-17 17:54:59 | [trpo_pendulum] epoch #45 | Time 19.59 s
2022-08-17 17:54:59 | [trpo_pendulum] epoch #45 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -801.86
Evaluation/AverageReturn              -1858.25
Evaluation/Iteration                     45
Evaluation/MaxReturn                  -1843.37
Evaluation/MinReturn                  -1880.61
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.1504
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41076
GaussianMLPPolicy/KL                      8.40068e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -766.05
GaussianMLPPolicy/LossBefore           -765.983
GaussianMLPPolicy/dLoss                   0.0667725
GaussianMLPValueFunction/LossAfter   150934
GaussianMLPValueFunction/LossBefore  151276
GaussianMLPValueFunction/dLoss          341.641
TotalEnvSteps                         55200
-----------------------------------  ----------------
2022-08-17 17:55:00 | [trpo_pendulum] epoch #46 | Saving snapshot...
2022-08-17 17:55:00 | [trpo_pendulum] epoch #46 | Saved
2022-08-17 17:55:00 | [trpo_pendulum] epoch #46 | Time 20.02 s
2022-08-17 17:55:00 | [trpo_pendulum] epoch #46 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -706.594
Evaluation/AverageReturn              -1743.78
Evaluation/Iteration                     46
Evaluation/MaxReturn                  -1702.13
Evaluation/MinReturn                  -1764.68
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     21.3528
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41061
GaussianMLPPolicy/KL                      5.08015e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -736.573
GaussianMLPPolicy/LossBefore           -736.215
GaussianMLPPolicy/dLoss                   0.35791
GaussianMLPValueFunction/LossAfter   143647
GaussianMLPValueFunction/LossBefore  143969
GaussianMLPValueFunction/dLoss          321.562
TotalEnvSteps                         56400
-----------------------------------  ----------------
2022-08-17 17:55:00 | [trpo_pendulum] epoch #47 | Saving snapshot...
2022-08-17 17:55:00 | [trpo_pendulum] epoch #47 | Saved
2022-08-17 17:55:00 | [trpo_pendulum] epoch #47 | Time 20.44 s
2022-08-17 17:55:00 | [trpo_pendulum] epoch #47 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -703.145
Evaluation/AverageReturn              -1737.53
Evaluation/Iteration                     47
Evaluation/MaxReturn                  -1688.25
Evaluation/MinReturn                  -1772.5
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     29.7414
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41047
GaussianMLPPolicy/KL                      5.10483e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -731.789
GaussianMLPPolicy/LossBefore           -731.831
GaussianMLPPolicy/dLoss                  -0.041748
GaussianMLPValueFunction/LossAfter   142763
GaussianMLPValueFunction/LossBefore  143082
GaussianMLPValueFunction/dLoss          318.703
TotalEnvSteps                         57600
-----------------------------------  ----------------
2022-08-17 17:55:00 | [trpo_pendulum] epoch #48 | Saving snapshot...
2022-08-17 17:55:01 | [trpo_pendulum] epoch #48 | Saved
2022-08-17 17:55:01 | [trpo_pendulum] epoch #48 | Time 20.86 s
2022-08-17 17:55:01 | [trpo_pendulum] epoch #48 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -608.204
Evaluation/AverageReturn              -1616.55
Evaluation/Iteration                     48
Evaluation/MaxReturn                  -1570.82
Evaluation/MinReturn                  -1657.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     32.9926
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41031
GaussianMLPPolicy/KL                      8.13784e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -717.809
GaussianMLPPolicy/LossBefore           -717.018
GaussianMLPPolicy/dLoss                   0.790649
GaussianMLPValueFunction/LossAfter   133920
GaussianMLPValueFunction/LossBefore  134213
GaussianMLPValueFunction/dLoss          292.891
TotalEnvSteps                         58800
-----------------------------------  ----------------
2022-08-17 17:55:01 | [trpo_pendulum] epoch #49 | Saving snapshot...
2022-08-17 17:55:01 | [trpo_pendulum] epoch #49 | Saved
2022-08-17 17:55:01 | [trpo_pendulum] epoch #49 | Time 21.29 s
2022-08-17 17:55:01 | [trpo_pendulum] epoch #49 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -732.111
Evaluation/AverageReturn              -1777.54
Evaluation/Iteration                     49
Evaluation/MaxReturn                  -1743.64
Evaluation/MinReturn                  -1814.58
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     21.6632
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41016
GaussianMLPPolicy/KL                      4.22783e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -738.593
GaussianMLPPolicy/LossBefore           -738.61
GaussianMLPPolicy/dLoss                  -0.0177612
GaussianMLPValueFunction/LossAfter   145567
GaussianMLPValueFunction/LossBefore  145891
GaussianMLPValueFunction/dLoss          324.672
TotalEnvSteps                         60000
-----------------------------------  ----------------
2022-08-17 17:55:01 | [trpo_pendulum] epoch #50 | Saving snapshot...
2022-08-17 17:55:01 | [trpo_pendulum] epoch #50 | Saved
2022-08-17 17:55:01 | [trpo_pendulum] epoch #50 | Time 21.71 s
2022-08-17 17:55:01 | [trpo_pendulum] epoch #50 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -696.403
Evaluation/AverageReturn              -1731.81
Evaluation/Iteration                     50
Evaluation/MaxReturn                  -1708.72
Evaluation/MinReturn                  -1761.44
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     20.2344
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40992
GaussianMLPPolicy/KL                      8.51092e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -743.834
GaussianMLPPolicy/LossBefore           -743.462
GaussianMLPPolicy/dLoss                   0.372314
GaussianMLPValueFunction/LossAfter   141723
GaussianMLPValueFunction/LossBefore  142037
GaussianMLPValueFunction/dLoss          314.5
TotalEnvSteps                         61200
-----------------------------------  ----------------
2022-08-17 17:55:02 | [trpo_pendulum] epoch #51 | Saving snapshot...
2022-08-17 17:55:02 | [trpo_pendulum] epoch #51 | Saved
2022-08-17 17:55:02 | [trpo_pendulum] epoch #51 | Time 22.13 s
2022-08-17 17:55:02 | [trpo_pendulum] epoch #51 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -761.2
Evaluation/AverageReturn              -1810.68
Evaluation/Iteration                     51
Evaluation/MaxReturn                  -1787.77
Evaluation/MinReturn                  -1836.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     17.0012
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40979
GaussianMLPPolicy/KL                      3.26858e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -732.393
GaussianMLPPolicy/LossBefore           -732.42
GaussianMLPPolicy/dLoss                  -0.0265503
GaussianMLPValueFunction/LossAfter   146548
GaussianMLPValueFunction/LossBefore  146877
GaussianMLPValueFunction/dLoss          329.016
TotalEnvSteps                         62400
-----------------------------------  ----------------
2022-08-17 17:55:02 | [trpo_pendulum] epoch #52 | Saving snapshot...
2022-08-17 17:55:02 | [trpo_pendulum] epoch #52 | Saved
2022-08-17 17:55:02 | [trpo_pendulum] epoch #52 | Time 22.54 s
2022-08-17 17:55:02 | [trpo_pendulum] epoch #52 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -806.149
Evaluation/AverageReturn              -1864.45
Evaluation/Iteration                     52
Evaluation/MaxReturn                  -1851.89
Evaluation/MinReturn                  -1885.04
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.2752
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40962
GaussianMLPPolicy/KL                      0.000224591
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -753.301
GaussianMLPPolicy/LossBefore           -752.084
GaussianMLPPolicy/dLoss                   1.21643
GaussianMLPValueFunction/LossAfter   148795
GaussianMLPValueFunction/LossBefore  149131
GaussianMLPValueFunction/dLoss          336.375
TotalEnvSteps                         63600
-----------------------------------  ----------------
2022-08-17 17:55:03 | [trpo_pendulum] epoch #53 | Saving snapshot...
2022-08-17 17:55:03 | [trpo_pendulum] epoch #53 | Saved
2022-08-17 17:55:03 | [trpo_pendulum] epoch #53 | Time 22.96 s
2022-08-17 17:55:03 | [trpo_pendulum] epoch #53 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -658.551
Evaluation/AverageReturn              -1683.26
Evaluation/Iteration                     53
Evaluation/MaxReturn                  -1644.81
Evaluation/MinReturn                  -1733.45
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     28.6997
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40959
GaussianMLPPolicy/KL                      0.000156903
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -710.216
GaussianMLPPolicy/LossBefore           -710.012
GaussianMLPPolicy/dLoss                   0.204468
GaussianMLPValueFunction/LossAfter   137272
GaussianMLPValueFunction/LossBefore  137576
GaussianMLPValueFunction/dLoss          303.766
TotalEnvSteps                         64800
-----------------------------------  ----------------
2022-08-17 17:55:03 | [trpo_pendulum] epoch #54 | Saving snapshot...
2022-08-17 17:55:03 | [trpo_pendulum] epoch #54 | Saved
2022-08-17 17:55:03 | [trpo_pendulum] epoch #54 | Time 23.37 s
2022-08-17 17:55:03 | [trpo_pendulum] epoch #54 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -711.61
Evaluation/AverageReturn              -1753.19
Evaluation/Iteration                     54
Evaluation/MaxReturn                  -1741.69
Evaluation/MinReturn                  -1773.45
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.7106
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40951
GaussianMLPPolicy/KL                      0.000121005
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -741.73
GaussianMLPPolicy/LossBefore           -741.731
GaussianMLPPolicy/dLoss                  -0.000427246
GaussianMLPValueFunction/LossAfter   142263
GaussianMLPValueFunction/LossBefore  142580
GaussianMLPValueFunction/dLoss          317.109
TotalEnvSteps                         66000
-----------------------------------  ----------------
2022-08-17 17:55:03 | [trpo_pendulum] epoch #55 | Saving snapshot...
2022-08-17 17:55:03 | [trpo_pendulum] epoch #55 | Saved
2022-08-17 17:55:03 | [trpo_pendulum] epoch #55 | Time 23.79 s
2022-08-17 17:55:03 | [trpo_pendulum] epoch #55 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -703.666
Evaluation/AverageReturn              -1746.33
Evaluation/Iteration                     55
Evaluation/MaxReturn                  -1731.48
Evaluation/MinReturn                  -1766.94
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     11.8569
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40941
GaussianMLPPolicy/KL                      7.86753e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -738.445
GaussianMLPPolicy/LossBefore           -738.378
GaussianMLPPolicy/dLoss                   0.0673218
GaussianMLPValueFunction/LossAfter   142094
GaussianMLPValueFunction/LossBefore  142410
GaussianMLPValueFunction/dLoss          316.641
TotalEnvSteps                         67200
-----------------------------------  ----------------
2022-08-17 17:55:04 | [trpo_pendulum] epoch #56 | Saving snapshot...
2022-08-17 17:55:04 | [trpo_pendulum] epoch #56 | Saved
2022-08-17 17:55:04 | [trpo_pendulum] epoch #56 | Time 24.20 s
2022-08-17 17:55:04 | [trpo_pendulum] epoch #56 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -745.33
Evaluation/AverageReturn              -1796.23
Evaluation/Iteration                     56
Evaluation/MaxReturn                  -1774.21
Evaluation/MinReturn                  -1827.85
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     19.5208
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40921
GaussianMLPPolicy/KL                      4.04743e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -752.605
GaussianMLPPolicy/LossBefore           -752.634
GaussianMLPPolicy/dLoss                  -0.0293579
GaussianMLPValueFunction/LossAfter   144965
GaussianMLPValueFunction/LossBefore  145291
GaussianMLPValueFunction/dLoss          325.625
TotalEnvSteps                         68400
-----------------------------------  ----------------
2022-08-17 17:55:04 | [trpo_pendulum] epoch #57 | Saving snapshot...
2022-08-17 17:55:04 | [trpo_pendulum] epoch #57 | Saved
2022-08-17 17:55:04 | [trpo_pendulum] epoch #57 | Time 24.62 s
2022-08-17 17:55:04 | [trpo_pendulum] epoch #57 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -658.613
Evaluation/AverageReturn              -1680.74
Evaluation/Iteration                     57
Evaluation/MaxReturn                  -1665.05
Evaluation/MinReturn                  -1688.78
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      7.91317
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40879
GaussianMLPPolicy/KL                      1.81017e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -749.692
GaussianMLPPolicy/LossBefore           -749.747
GaussianMLPPolicy/dLoss                  -0.0545654
GaussianMLPValueFunction/LossAfter   134895
GaussianMLPValueFunction/LossBefore  135193
GaussianMLPValueFunction/dLoss          298.203
TotalEnvSteps                         69600
-----------------------------------  ----------------
2022-08-17 17:55:05 | [trpo_pendulum] epoch #58 | Saving snapshot...
2022-08-17 17:55:05 | [trpo_pendulum] epoch #58 | Saved
2022-08-17 17:55:05 | [trpo_pendulum] epoch #58 | Time 25.03 s
2022-08-17 17:55:05 | [trpo_pendulum] epoch #58 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -695.539
Evaluation/AverageReturn              -1733.65
Evaluation/Iteration                     58
Evaluation/MaxReturn                  -1723.77
Evaluation/MinReturn                  -1748.83
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.09832
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40839
GaussianMLPPolicy/KL                      4.89945e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -734.982
GaussianMLPPolicy/LossBefore           -734.598
GaussianMLPPolicy/dLoss                   0.383789
GaussianMLPValueFunction/LossAfter   140293
GaussianMLPValueFunction/LossBefore  140604
GaussianMLPValueFunction/dLoss          311.547
TotalEnvSteps                         70800
-----------------------------------  ----------------
2022-08-17 17:55:05 | [trpo_pendulum] epoch #59 | Saving snapshot...
2022-08-17 17:55:05 | [trpo_pendulum] epoch #59 | Saved
2022-08-17 17:55:05 | [trpo_pendulum] epoch #59 | Time 25.46 s
2022-08-17 17:55:05 | [trpo_pendulum] epoch #59 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -597.627
Evaluation/AverageReturn              -1601.48
Evaluation/Iteration                     59
Evaluation/MaxReturn                  -1573.15
Evaluation/MinReturn                  -1629.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     25.9939
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40789
GaussianMLPPolicy/KL                      4.67775e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -723.533
GaussianMLPPolicy/LossBefore           -723.507
GaussianMLPPolicy/dLoss                   0.0264893
GaussianMLPValueFunction/LossAfter   129280
GaussianMLPValueFunction/LossBefore  129561
GaussianMLPValueFunction/dLoss          280.266
TotalEnvSteps                         72000
-----------------------------------  ----------------
2022-08-17 17:55:05 | [trpo_pendulum] epoch #60 | Saving snapshot...
2022-08-17 17:55:06 | [trpo_pendulum] epoch #60 | Saved
2022-08-17 17:55:06 | [trpo_pendulum] epoch #60 | Time 25.87 s
2022-08-17 17:55:06 | [trpo_pendulum] epoch #60 | EpochTime 0.41 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -814.688
Evaluation/AverageReturn              -1887.06
Evaluation/Iteration                     60
Evaluation/MaxReturn                  -1881.92
Evaluation/MinReturn                  -1900.09
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      6.77768
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40742
GaussianMLPPolicy/KL                      3.613e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -756.879
GaussianMLPPolicy/LossBefore           -756.741
GaussianMLPPolicy/dLoss                   0.138428
GaussianMLPValueFunction/LossAfter   150209
GaussianMLPValueFunction/LossBefore  150546
GaussianMLPValueFunction/dLoss          336.453
TotalEnvSteps                         73200
-----------------------------------  --------------
2022-08-17 17:55:06 | [trpo_pendulum] epoch #61 | Saving snapshot...
2022-08-17 17:55:06 | [trpo_pendulum] epoch #61 | Saved
2022-08-17 17:55:06 | [trpo_pendulum] epoch #61 | Time 26.30 s
2022-08-17 17:55:06 | [trpo_pendulum] epoch #61 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -652.519
Evaluation/AverageReturn              -1672.42
Evaluation/Iteration                     61
Evaluation/MaxReturn                  -1631.48
Evaluation/MinReturn                  -1698.63
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     22.149
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40708
GaussianMLPPolicy/KL                      7.06857e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -709.565
GaussianMLPPolicy/LossBefore           -709.369
GaussianMLPPolicy/dLoss                   0.196106
GaussianMLPValueFunction/LossAfter   133313
GaussianMLPValueFunction/LossBefore  133606
GaussianMLPValueFunction/dLoss          293.219
TotalEnvSteps                         74400
-----------------------------------  ----------------
2022-08-17 17:55:06 | [trpo_pendulum] epoch #62 | Saving snapshot...
2022-08-17 17:55:06 | [trpo_pendulum] epoch #62 | Saved
2022-08-17 17:55:06 | [trpo_pendulum] epoch #62 | Time 26.75 s
2022-08-17 17:55:06 | [trpo_pendulum] epoch #62 | EpochTime 0.44 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -588.123
Evaluation/AverageReturn              -1589.85
Evaluation/Iteration                     62
Evaluation/MaxReturn                  -1538.52
Evaluation/MinReturn                  -1642.3
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     39.5692
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40675
GaussianMLPPolicy/KL                      9.83127e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -706.079
GaussianMLPPolicy/LossBefore           -705.823
GaussianMLPPolicy/dLoss                   0.255249
GaussianMLPValueFunction/LossAfter   127808
GaussianMLPValueFunction/LossBefore  128085
GaussianMLPValueFunction/dLoss          276.719
TotalEnvSteps                         75600
-----------------------------------  ----------------
2022-08-17 17:55:07 | [trpo_pendulum] epoch #63 | Saving snapshot...
2022-08-17 17:55:07 | [trpo_pendulum] epoch #63 | Saved
2022-08-17 17:55:07 | [trpo_pendulum] epoch #63 | Time 27.18 s
2022-08-17 17:55:07 | [trpo_pendulum] epoch #63 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -689.133
Evaluation/AverageReturn              -1728.48
Evaluation/Iteration                     63
Evaluation/MaxReturn                  -1675.75
Evaluation/MinReturn                  -1754.39
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     25.8308
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40635
GaussianMLPPolicy/KL                      0.000112431
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -743.707
GaussianMLPPolicy/LossBefore           -743.393
GaussianMLPPolicy/dLoss                   0.314392
GaussianMLPValueFunction/LossAfter   138215
GaussianMLPValueFunction/LossBefore  138518
GaussianMLPValueFunction/dLoss          303.453
TotalEnvSteps                         76800
-----------------------------------  ----------------
2022-08-17 17:55:07 | [trpo_pendulum] epoch #64 | Saving snapshot...
2022-08-17 17:55:07 | [trpo_pendulum] epoch #64 | Saved
2022-08-17 17:55:07 | [trpo_pendulum] epoch #64 | Time 27.59 s
2022-08-17 17:55:07 | [trpo_pendulum] epoch #64 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -702.013
Evaluation/AverageReturn              -1743.24
Evaluation/Iteration                     64
Evaluation/MaxReturn                  -1724.07
Evaluation/MinReturn                  -1763.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     15.0196
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40595
GaussianMLPPolicy/KL                      0.000179954
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -737.546
GaussianMLPPolicy/LossBefore           -736.631
GaussianMLPPolicy/dLoss                   0.915588
GaussianMLPValueFunction/LossAfter   139138
GaussianMLPValueFunction/LossBefore  139444
GaussianMLPValueFunction/dLoss          305.359
TotalEnvSteps                         78000
-----------------------------------  ----------------
2022-08-17 17:55:08 | [trpo_pendulum] epoch #65 | Saving snapshot...
2022-08-17 17:55:08 | [trpo_pendulum] epoch #65 | Saved
2022-08-17 17:55:08 | [trpo_pendulum] epoch #65 | Time 28.03 s
2022-08-17 17:55:08 | [trpo_pendulum] epoch #65 | EpochTime 0.44 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -686.454
Evaluation/AverageReturn              -1713.72
Evaluation/Iteration                     65
Evaluation/MaxReturn                  -1684.29
Evaluation/MinReturn                  -1745.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     18.5228
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40557
GaussianMLPPolicy/KL                      9.60901e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -722.85
GaussianMLPPolicy/LossBefore           -722.957
GaussianMLPPolicy/dLoss                  -0.10675
GaussianMLPValueFunction/LossAfter   134330
GaussianMLPValueFunction/LossBefore  134626
GaussianMLPValueFunction/dLoss          295.5
TotalEnvSteps                         79200
-----------------------------------  ----------------
2022-08-17 17:55:08 | [trpo_pendulum] epoch #66 | Saving snapshot...
2022-08-17 17:55:08 | [trpo_pendulum] epoch #66 | Saved
2022-08-17 17:55:08 | [trpo_pendulum] epoch #66 | Time 28.47 s
2022-08-17 17:55:08 | [trpo_pendulum] epoch #66 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -758.821
Evaluation/AverageReturn              -1809.63
Evaluation/Iteration                     66
Evaluation/MaxReturn                  -1806.53
Evaluation/MinReturn                  -1817.54
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      3.68514
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4053
GaussianMLPPolicy/KL                      1.75281e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -730.932
GaussianMLPPolicy/LossBefore           -731.062
GaussianMLPPolicy/dLoss                  -0.129517
GaussianMLPValueFunction/LossAfter   141882
GaussianMLPValueFunction/LossBefore  142197
GaussianMLPValueFunction/dLoss          315.312
TotalEnvSteps                         80400
-----------------------------------  ----------------
2022-08-17 17:55:09 | [trpo_pendulum] epoch #67 | Saving snapshot...
2022-08-17 17:55:09 | [trpo_pendulum] epoch #67 | Saved
2022-08-17 17:55:09 | [trpo_pendulum] epoch #67 | Time 28.87 s
2022-08-17 17:55:09 | [trpo_pendulum] epoch #67 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -810.428
Evaluation/AverageReturn              -1877.9
Evaluation/Iteration                     67
Evaluation/MaxReturn                  -1864.98
Evaluation/MinReturn                  -1889.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.75194
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40506
GaussianMLPPolicy/KL                      5.13705e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -748.918
GaussianMLPPolicy/LossBefore           -748.877
GaussianMLPPolicy/dLoss                   0.0411987
GaussianMLPValueFunction/LossAfter   146839
GaussianMLPValueFunction/LossBefore  147168
GaussianMLPValueFunction/dLoss          328.375
TotalEnvSteps                         81600
-----------------------------------  ----------------
2022-08-17 17:55:09 | [trpo_pendulum] epoch #68 | Saving snapshot...
2022-08-17 17:55:09 | [trpo_pendulum] epoch #68 | Saved
2022-08-17 17:55:09 | [trpo_pendulum] epoch #68 | Time 29.29 s
2022-08-17 17:55:09 | [trpo_pendulum] epoch #68 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -683.952
Evaluation/AverageReturn              -1715.38
Evaluation/Iteration                     68
Evaluation/MaxReturn                  -1648.67
Evaluation/MinReturn                  -1738.7
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     30.6037
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40508
GaussianMLPPolicy/KL                      1.54079e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -697.516
GaussianMLPPolicy/LossBefore           -697.496
GaussianMLPPolicy/dLoss                   0.0200806
GaussianMLPValueFunction/LossAfter   134163
GaussianMLPValueFunction/LossBefore  134460
GaussianMLPValueFunction/dLoss          297.312
TotalEnvSteps                         82800
-----------------------------------  ----------------
2022-08-17 17:55:09 | [trpo_pendulum] epoch #69 | Saving snapshot...
2022-08-17 17:55:09 | [trpo_pendulum] epoch #69 | Saved
2022-08-17 17:55:09 | [trpo_pendulum] epoch #69 | Time 29.71 s
2022-08-17 17:55:09 | [trpo_pendulum] epoch #69 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -815.431
Evaluation/AverageReturn              -1888.29
Evaluation/Iteration                     69
Evaluation/MaxReturn                  -1874.53
Evaluation/MinReturn                  -1907.29
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     11.7511
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40506
GaussianMLPPolicy/KL                      2.33389e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -757.888
GaussianMLPPolicy/LossBefore           -757.851
GaussianMLPPolicy/dLoss                   0.0370483
GaussianMLPValueFunction/LossAfter   147558
GaussianMLPValueFunction/LossBefore  147890
GaussianMLPValueFunction/dLoss          331.359
TotalEnvSteps                         84000
-----------------------------------  ----------------
2022-08-17 17:55:10 | [trpo_pendulum] epoch #70 | Saving snapshot...
2022-08-17 17:55:10 | [trpo_pendulum] epoch #70 | Saved
2022-08-17 17:55:10 | [trpo_pendulum] epoch #70 | Time 30.12 s
2022-08-17 17:55:10 | [trpo_pendulum] epoch #70 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -732.337
Evaluation/AverageReturn              -1778.23
Evaluation/Iteration                     70
Evaluation/MaxReturn                  -1758.13
Evaluation/MinReturn                  -1810.38
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     15.9649
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40506
GaussianMLPPolicy/KL                      1.66786e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -731.754
GaussianMLPPolicy/LossBefore           -731.685
GaussianMLPPolicy/dLoss                   0.0689087
GaussianMLPValueFunction/LossAfter   138583
GaussianMLPValueFunction/LossBefore  138895
GaussianMLPValueFunction/dLoss          311.625
TotalEnvSteps                         85200
-----------------------------------  ----------------
2022-08-17 17:55:10 | [trpo_pendulum] epoch #71 | Saving snapshot...
2022-08-17 17:55:10 | [trpo_pendulum] epoch #71 | Saved
2022-08-17 17:55:10 | [trpo_pendulum] epoch #71 | Time 30.54 s
2022-08-17 17:55:10 | [trpo_pendulum] epoch #71 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -715.822
Evaluation/AverageReturn              -1752.6
Evaluation/Iteration                     71
Evaluation/MaxReturn                  -1743.61
Evaluation/MinReturn                  -1767.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.00551
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40498
GaussianMLPPolicy/KL                      5.20055e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -736.785
GaussianMLPPolicy/LossBefore           -736.745
GaussianMLPPolicy/dLoss                   0.039856
GaussianMLPValueFunction/LossAfter   135553
GaussianMLPValueFunction/LossBefore  135857
GaussianMLPValueFunction/dLoss          304.078
TotalEnvSteps                         86400
-----------------------------------  ----------------
2022-08-17 17:55:11 | [trpo_pendulum] epoch #72 | Saving snapshot...
2022-08-17 17:55:11 | [trpo_pendulum] epoch #72 | Saved
2022-08-17 17:55:11 | [trpo_pendulum] epoch #72 | Time 30.94 s
2022-08-17 17:55:11 | [trpo_pendulum] epoch #72 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -594.451
Evaluation/AverageReturn              -1580.81
Evaluation/Iteration                     72
Evaluation/MaxReturn                  -1557.01
Evaluation/MinReturn                  -1639.39
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     28.4979
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40487
GaussianMLPPolicy/KL                      5.08969e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -695.453
GaussianMLPPolicy/LossBefore           -695.117
GaussianMLPPolicy/dLoss                   0.336731
GaussianMLPValueFunction/LossAfter   120640
GaussianMLPValueFunction/LossBefore  120902
GaussianMLPValueFunction/dLoss          262.516
TotalEnvSteps                         87600
-----------------------------------  ----------------
2022-08-17 17:55:11 | [trpo_pendulum] epoch #73 | Saving snapshot...
2022-08-17 17:55:11 | [trpo_pendulum] epoch #73 | Saved
2022-08-17 17:55:11 | [trpo_pendulum] epoch #73 | Time 31.35 s
2022-08-17 17:55:11 | [trpo_pendulum] epoch #73 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -688.243
Evaluation/AverageReturn              -1719.1
Evaluation/Iteration                     73
Evaluation/MaxReturn                  -1701.08
Evaluation/MinReturn                  -1759.14
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     19.5323
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40467
GaussianMLPPolicy/KL                      7.27576e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -735.103
GaussianMLPPolicy/LossBefore           -734.822
GaussianMLPPolicy/dLoss                   0.280579
GaussianMLPValueFunction/LossAfter   132926
GaussianMLPValueFunction/LossBefore  133219
GaussianMLPValueFunction/dLoss          292.938
TotalEnvSteps                         88800
-----------------------------------  ----------------
2022-08-17 17:55:11 | [trpo_pendulum] epoch #74 | Saving snapshot...
2022-08-17 17:55:11 | [trpo_pendulum] epoch #74 | Saved
2022-08-17 17:55:11 | [trpo_pendulum] epoch #74 | Time 31.76 s
2022-08-17 17:55:11 | [trpo_pendulum] epoch #74 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -582.283
Evaluation/AverageReturn              -1560.98
Evaluation/Iteration                     74
Evaluation/MaxReturn                  -1445.98
Evaluation/MinReturn                  -1631.31
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     58.1582
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40448
GaussianMLPPolicy/KL                      0.000231639
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -688.383
GaussianMLPPolicy/LossBefore           -687.64
GaussianMLPPolicy/dLoss                   0.742615
GaussianMLPValueFunction/LossAfter   118130
GaussianMLPValueFunction/LossBefore  118384
GaussianMLPValueFunction/dLoss          254.039
TotalEnvSteps                         90000
-----------------------------------  ----------------
2022-08-17 17:55:12 | [trpo_pendulum] epoch #75 | Saving snapshot...
2022-08-17 17:55:12 | [trpo_pendulum] epoch #75 | Saved
2022-08-17 17:55:12 | [trpo_pendulum] epoch #75 | Time 32.17 s
2022-08-17 17:55:12 | [trpo_pendulum] epoch #75 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -783.669
Evaluation/AverageReturn              -1847.38
Evaluation/Iteration                     75
Evaluation/MaxReturn                  -1819.03
Evaluation/MinReturn                  -1866.57
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     16.1723
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40439
GaussianMLPPolicy/KL                      3.23381e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -735.212
GaussianMLPPolicy/LossBefore           -735.276
GaussianMLPPolicy/dLoss                  -0.0645142
GaussianMLPValueFunction/LossAfter   143066
GaussianMLPValueFunction/LossBefore  143380
GaussianMLPValueFunction/dLoss          314.469
TotalEnvSteps                         91200
-----------------------------------  ----------------
2022-08-17 17:55:12 | [trpo_pendulum] epoch #76 | Saving snapshot...
2022-08-17 17:55:12 | [trpo_pendulum] epoch #76 | Saved
2022-08-17 17:55:12 | [trpo_pendulum] epoch #76 | Time 32.59 s
2022-08-17 17:55:12 | [trpo_pendulum] epoch #76 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -815.49
Evaluation/AverageReturn              -1888.08
Evaluation/Iteration                     76
Evaluation/MaxReturn                  -1876.91
Evaluation/MinReturn                  -1898.66
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.2588
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40427
GaussianMLPPolicy/KL                      4.09924e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -756.331
GaussianMLPPolicy/LossBefore           -756.433
GaussianMLPPolicy/dLoss                  -0.102661
GaussianMLPValueFunction/LossAfter   145384
GaussianMLPValueFunction/LossBefore  145706
GaussianMLPValueFunction/dLoss          321.922
TotalEnvSteps                         92400
-----------------------------------  ----------------
2022-08-17 17:55:13 | [trpo_pendulum] epoch #77 | Saving snapshot...
2022-08-17 17:55:13 | [trpo_pendulum] epoch #77 | Saved
2022-08-17 17:55:13 | [trpo_pendulum] epoch #77 | Time 33.01 s
2022-08-17 17:55:13 | [trpo_pendulum] epoch #77 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -820.92
Evaluation/AverageReturn              -1889.37
Evaluation/Iteration                     77
Evaluation/MaxReturn                  -1878.83
Evaluation/MinReturn                  -1899.7
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      6.45768
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40403
GaussianMLPPolicy/KL                      3.00151e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -763.039
GaussianMLPPolicy/LossBefore           -763.066
GaussianMLPPolicy/dLoss                  -0.0270996
GaussianMLPValueFunction/LossAfter   144087
GaussianMLPValueFunction/LossBefore  144408
GaussianMLPValueFunction/dLoss          321.109
TotalEnvSteps                         93600
-----------------------------------  ----------------
2022-08-17 17:55:13 | [trpo_pendulum] epoch #78 | Saving snapshot...
2022-08-17 17:55:13 | [trpo_pendulum] epoch #78 | Saved
2022-08-17 17:55:13 | [trpo_pendulum] epoch #78 | Time 33.41 s
2022-08-17 17:55:13 | [trpo_pendulum] epoch #78 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -776.904
Evaluation/AverageReturn              -1847.72
Evaluation/Iteration                     78
Evaluation/MaxReturn                  -1837.22
Evaluation/MinReturn                  -1870.66
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     11.9257
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40376
GaussianMLPPolicy/KL                      4.05307e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -756.621
GaussianMLPPolicy/LossBefore           -756.354
GaussianMLPPolicy/dLoss                   0.266418
GaussianMLPValueFunction/LossAfter   143686
GaussianMLPValueFunction/LossBefore  144007
GaussianMLPValueFunction/dLoss          321.516
TotalEnvSteps                         94800
-----------------------------------  ----------------
2022-08-17 17:55:13 | [trpo_pendulum] epoch #79 | Saving snapshot...
2022-08-17 17:55:13 | [trpo_pendulum] epoch #79 | Saved
2022-08-17 17:55:13 | [trpo_pendulum] epoch #79 | Time 33.82 s
2022-08-17 17:55:13 | [trpo_pendulum] epoch #79 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -768.383
Evaluation/AverageReturn              -1825.73
Evaluation/Iteration                     79
Evaluation/MaxReturn                  -1793.17
Evaluation/MinReturn                  -1851.51
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     18.1675
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40357
GaussianMLPPolicy/KL                      0.000112784
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -734.578
GaussianMLPPolicy/LossBefore           -734.143
GaussianMLPPolicy/dLoss                   0.435669
GaussianMLPValueFunction/LossAfter   139784
GaussianMLPValueFunction/LossBefore  140098
GaussianMLPValueFunction/dLoss          314.375
TotalEnvSteps                         96000
-----------------------------------  ----------------
2022-08-17 17:55:14 | [trpo_pendulum] epoch #80 | Saving snapshot...
2022-08-17 17:55:14 | [trpo_pendulum] epoch #80 | Saved
2022-08-17 17:55:14 | [trpo_pendulum] epoch #80 | Time 34.23 s
2022-08-17 17:55:14 | [trpo_pendulum] epoch #80 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -801.843
Evaluation/AverageReturn              -1871.38
Evaluation/Iteration                     80
Evaluation/MaxReturn                  -1852.71
Evaluation/MinReturn                  -1886.27
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.6152
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40331
GaussianMLPPolicy/KL                      0.000235592
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -757.958
GaussianMLPPolicy/LossBefore           -757.191
GaussianMLPPolicy/dLoss                   0.766663
GaussianMLPValueFunction/LossAfter   143037
GaussianMLPValueFunction/LossBefore  143359
GaussianMLPValueFunction/dLoss          322.094
TotalEnvSteps                         97200
-----------------------------------  ----------------
2022-08-17 17:55:14 | [trpo_pendulum] epoch #81 | Saving snapshot...
2022-08-17 17:55:14 | [trpo_pendulum] epoch #81 | Saved
2022-08-17 17:55:14 | [trpo_pendulum] epoch #81 | Time 34.64 s
2022-08-17 17:55:14 | [trpo_pendulum] epoch #81 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -698.698
Evaluation/AverageReturn              -1735.9
Evaluation/Iteration                     81
Evaluation/MaxReturn                  -1722.99
Evaluation/MinReturn                  -1744.49
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      6.42631
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40299
GaussianMLPPolicy/KL                      0.000105488
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -734.749
GaussianMLPPolicy/LossBefore           -734.847
GaussianMLPPolicy/dLoss                  -0.0980225
GaussianMLPValueFunction/LossAfter   132482
GaussianMLPValueFunction/LossBefore  132778
GaussianMLPValueFunction/dLoss          296.547
TotalEnvSteps                         98400
-----------------------------------  ----------------
2022-08-17 17:55:15 | [trpo_pendulum] epoch #82 | Saving snapshot...
2022-08-17 17:55:15 | [trpo_pendulum] epoch #82 | Saved
2022-08-17 17:55:15 | [trpo_pendulum] epoch #82 | Time 35.07 s
2022-08-17 17:55:15 | [trpo_pendulum] epoch #82 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -801.906
Evaluation/AverageReturn              -1867.85
Evaluation/Iteration                     82
Evaluation/MaxReturn                  -1839.56
Evaluation/MinReturn                  -1895.69
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     18.6168
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4027
GaussianMLPPolicy/KL                      0.000313529
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -747.473
GaussianMLPPolicy/LossBefore           -746.278
GaussianMLPPolicy/dLoss                   1.19543
GaussianMLPValueFunction/LossAfter   141479
GaussianMLPValueFunction/LossBefore  141798
GaussianMLPValueFunction/dLoss          318.438
TotalEnvSteps                         99600
-----------------------------------  ----------------
2022-08-17 17:55:15 | [trpo_pendulum] epoch #83 | Saving snapshot...
2022-08-17 17:55:15 | [trpo_pendulum] epoch #83 | Saved
2022-08-17 17:55:15 | [trpo_pendulum] epoch #83 | Time 35.48 s
2022-08-17 17:55:15 | [trpo_pendulum] epoch #83 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -772.602
Evaluation/AverageReturn              -1833.1
Evaluation/Iteration                     83
Evaluation/MaxReturn                  -1820.29
Evaluation/MinReturn                  -1844.58
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.46638
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40259
GaussianMLPPolicy/KL                      0.000126564
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -723.162
GaussianMLPPolicy/LossBefore           -723.433
GaussianMLPPolicy/dLoss                  -0.271118
GaussianMLPValueFunction/LossAfter   139277
GaussianMLPValueFunction/LossBefore  139591
GaussianMLPValueFunction/dLoss          313.984
TotalEnvSteps                        100800
-----------------------------------  ----------------
2022-08-17 17:55:16 | [trpo_pendulum] epoch #84 | Saving snapshot...
2022-08-17 17:55:16 | [trpo_pendulum] epoch #84 | Saved
2022-08-17 17:55:16 | [trpo_pendulum] epoch #84 | Time 35.90 s
2022-08-17 17:55:16 | [trpo_pendulum] epoch #84 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -710.022
Evaluation/AverageReturn              -1748.12
Evaluation/Iteration                     84
Evaluation/MaxReturn                  -1713.64
Evaluation/MinReturn                  -1782.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     24.1096
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40246
GaussianMLPPolicy/KL                      0.000112517
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -730.199
GaussianMLPPolicy/LossBefore           -729.96
GaussianMLPPolicy/dLoss                   0.239075
GaussianMLPValueFunction/LossAfter   132194
GaussianMLPValueFunction/LossBefore  132491
GaussianMLPValueFunction/dLoss          297.172
TotalEnvSteps                        102000
-----------------------------------  ----------------
2022-08-17 17:55:16 | [trpo_pendulum] epoch #85 | Saving snapshot...
2022-08-17 17:55:16 | [trpo_pendulum] epoch #85 | Saved
2022-08-17 17:55:16 | [trpo_pendulum] epoch #85 | Time 36.33 s
2022-08-17 17:55:16 | [trpo_pendulum] epoch #85 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -534.634
Evaluation/AverageReturn              -1519.86
Evaluation/Iteration                     85
Evaluation/MaxReturn                  -1441.99
Evaluation/MinReturn                  -1586.05
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.0892
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40236
GaussianMLPPolicy/KL                      9.73546e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -686.033
GaussianMLPPolicy/LossBefore           -685.73
GaussianMLPPolicy/dLoss                   0.303284
GaussianMLPValueFunction/LossAfter   116971
GaussianMLPValueFunction/LossBefore  117223
GaussianMLPValueFunction/dLoss          251.906
TotalEnvSteps                        103200
-----------------------------------  ----------------
2022-08-17 17:55:16 | [trpo_pendulum] epoch #86 | Saving snapshot...
2022-08-17 17:55:16 | [trpo_pendulum] epoch #86 | Saved
2022-08-17 17:55:16 | [trpo_pendulum] epoch #86 | Time 36.75 s
2022-08-17 17:55:16 | [trpo_pendulum] epoch #86 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -771.851
Evaluation/AverageReturn              -1830.12
Evaluation/Iteration                     86
Evaluation/MaxReturn                  -1787.87
Evaluation/MinReturn                  -1853.02
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     21.3267
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40229
GaussianMLPPolicy/KL                      0.000144443
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -736.794
GaussianMLPPolicy/LossBefore           -736.458
GaussianMLPPolicy/dLoss                   0.336365
GaussianMLPValueFunction/LossAfter   138034
GaussianMLPValueFunction/LossBefore  138340
GaussianMLPValueFunction/dLoss          306
TotalEnvSteps                        104400
-----------------------------------  ----------------
2022-08-17 17:55:17 | [trpo_pendulum] epoch #87 | Saving snapshot...
2022-08-17 17:55:17 | [trpo_pendulum] epoch #87 | Saved
2022-08-17 17:55:17 | [trpo_pendulum] epoch #87 | Time 37.18 s
2022-08-17 17:55:17 | [trpo_pendulum] epoch #87 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -618.095
Evaluation/AverageReturn              -1624.22
Evaluation/Iteration                     87
Evaluation/MaxReturn                  -1591.93
Evaluation/MinReturn                  -1642.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     16.0558
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40238
GaussianMLPPolicy/KL                      0.000187261
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -686.352
GaussianMLPPolicy/LossBefore           -685.689
GaussianMLPPolicy/dLoss                   0.663269
GaussianMLPValueFunction/LossAfter   122470
GaussianMLPValueFunction/LossBefore  122736
GaussianMLPValueFunction/dLoss          265.641
TotalEnvSteps                        105600
-----------------------------------  ----------------
2022-08-17 17:55:17 | [trpo_pendulum] epoch #88 | Saving snapshot...
2022-08-17 17:55:17 | [trpo_pendulum] epoch #88 | Saved
2022-08-17 17:55:17 | [trpo_pendulum] epoch #88 | Time 37.60 s
2022-08-17 17:55:17 | [trpo_pendulum] epoch #88 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -805.857
Evaluation/AverageReturn              -1862.18
Evaluation/Iteration                     88
Evaluation/MaxReturn                  -1852.51
Evaluation/MinReturn                  -1867.9
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      4.88174
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40252
GaussianMLPPolicy/KL                      7.61867e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -731.201
GaussianMLPPolicy/LossBefore           -731.27
GaussianMLPPolicy/dLoss                  -0.0689087
GaussianMLPValueFunction/LossAfter   137243
GaussianMLPValueFunction/LossBefore  137544
GaussianMLPValueFunction/dLoss          301.766
TotalEnvSteps                        106800
-----------------------------------  ----------------
2022-08-17 17:55:18 | [trpo_pendulum] epoch #89 | Saving snapshot...
2022-08-17 17:55:18 | [trpo_pendulum] epoch #89 | Saved
2022-08-17 17:55:18 | [trpo_pendulum] epoch #89 | Time 38.01 s
2022-08-17 17:55:18 | [trpo_pendulum] epoch #89 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -674.744
Evaluation/AverageReturn              -1695.49
Evaluation/Iteration                     89
Evaluation/MaxReturn                  -1671.12
Evaluation/MinReturn                  -1721
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     19.5555
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40266
GaussianMLPPolicy/KL                      0.000169063
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -711.845
GaussianMLPPolicy/LossBefore           -711.295
GaussianMLPPolicy/dLoss                   0.55011
GaussianMLPValueFunction/LossAfter   125981
GaussianMLPValueFunction/LossBefore  126256
GaussianMLPValueFunction/dLoss          275.352
TotalEnvSteps                        108000
-----------------------------------  ----------------
2022-08-17 17:55:18 | [trpo_pendulum] epoch #90 | Saving snapshot...
2022-08-17 17:55:18 | [trpo_pendulum] epoch #90 | Saved
2022-08-17 17:55:18 | [trpo_pendulum] epoch #90 | Time 38.43 s
2022-08-17 17:55:18 | [trpo_pendulum] epoch #90 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -742.73
Evaluation/AverageReturn              -1790.54
Evaluation/Iteration                     90
Evaluation/MaxReturn                  -1767.82
Evaluation/MinReturn                  -1815.2
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     17.11
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40296
GaussianMLPPolicy/KL                      0.000112619
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -711.073
GaussianMLPPolicy/LossBefore           -710.892
GaussianMLPPolicy/dLoss                   0.181702
GaussianMLPValueFunction/LossAfter   133463
GaussianMLPValueFunction/LossBefore  133755
GaussianMLPValueFunction/dLoss          292.531
TotalEnvSteps                        109200
-----------------------------------  ----------------
2022-08-17 17:55:18 | [trpo_pendulum] epoch #91 | Saving snapshot...
2022-08-17 17:55:19 | [trpo_pendulum] epoch #91 | Saved
2022-08-17 17:55:19 | [trpo_pendulum] epoch #91 | Time 38.85 s
2022-08-17 17:55:19 | [trpo_pendulum] epoch #91 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -597.444
Evaluation/AverageReturn              -1583.53
Evaluation/Iteration                     91
Evaluation/MaxReturn                  -1537.15
Evaluation/MinReturn                  -1610.04
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     29.4522
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40339
GaussianMLPPolicy/KL                      0.000114825
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -671.521
GaussianMLPPolicy/LossBefore           -671.434
GaussianMLPPolicy/dLoss                   0.0866089
GaussianMLPValueFunction/LossAfter   116059
GaussianMLPValueFunction/LossBefore  116308
GaussianMLPValueFunction/dLoss          248.797
TotalEnvSteps                        110400
-----------------------------------  ----------------
2022-08-17 17:55:19 | [trpo_pendulum] epoch #92 | Saving snapshot...
2022-08-17 17:55:19 | [trpo_pendulum] epoch #92 | Saved
2022-08-17 17:55:19 | [trpo_pendulum] epoch #92 | Time 39.27 s
2022-08-17 17:55:19 | [trpo_pendulum] epoch #92 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -650.008
Evaluation/AverageReturn              -1655.39
Evaluation/Iteration                     92
Evaluation/MaxReturn                  -1629.04
Evaluation/MinReturn                  -1668.63
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.5963
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40378
GaussianMLPPolicy/KL                      5.98282e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -701.458
GaussianMLPPolicy/LossBefore           -701.427
GaussianMLPPolicy/dLoss                   0.0313721
GaussianMLPValueFunction/LossAfter   120851
GaussianMLPValueFunction/LossBefore  121111
GaussianMLPValueFunction/dLoss          260.016
TotalEnvSteps                        111600
-----------------------------------  ----------------
2022-08-17 17:55:19 | [trpo_pendulum] epoch #93 | Saving snapshot...
2022-08-17 17:55:19 | [trpo_pendulum] epoch #93 | Saved
2022-08-17 17:55:19 | [trpo_pendulum] epoch #93 | Time 39.68 s
2022-08-17 17:55:19 | [trpo_pendulum] epoch #93 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -618.967
Evaluation/AverageReturn              -1603.55
Evaluation/Iteration                     93
Evaluation/MaxReturn                  -1547.22
Evaluation/MinReturn                  -1656.94
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     32.2956
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40417
GaussianMLPPolicy/KL                      0.000146081
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -684.658
GaussianMLPPolicy/LossBefore           -683.851
GaussianMLPPolicy/dLoss                   0.807739
GaussianMLPValueFunction/LossAfter   115031
GaussianMLPValueFunction/LossBefore  115274
GaussianMLPValueFunction/dLoss          243.227
TotalEnvSteps                        112800
-----------------------------------  ----------------
2022-08-17 17:55:20 | [trpo_pendulum] epoch #94 | Saving snapshot...
2022-08-17 17:55:20 | [trpo_pendulum] epoch #94 | Saved
2022-08-17 17:55:20 | [trpo_pendulum] epoch #94 | Time 40.10 s
2022-08-17 17:55:20 | [trpo_pendulum] epoch #94 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -603.31
Evaluation/AverageReturn              -1588.81
Evaluation/Iteration                     94
Evaluation/MaxReturn                  -1535.2
Evaluation/MinReturn                  -1640.03
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     32.4165
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40443
GaussianMLPPolicy/KL                      0.00017587
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -697.32
GaussianMLPPolicy/LossBefore           -697.025
GaussianMLPPolicy/dLoss                   0.295593
GaussianMLPValueFunction/LossAfter   115332
GaussianMLPValueFunction/LossBefore  115574
GaussianMLPValueFunction/dLoss          241.992
TotalEnvSteps                        114000
-----------------------------------  ---------------
2022-08-17 17:55:20 | [trpo_pendulum] epoch #95 | Saving snapshot...
2022-08-17 17:55:20 | [trpo_pendulum] epoch #95 | Saved
2022-08-17 17:55:20 | [trpo_pendulum] epoch #95 | Time 40.51 s
2022-08-17 17:55:20 | [trpo_pendulum] epoch #95 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -666.522
Evaluation/AverageReturn              -1681.99
Evaluation/Iteration                     95
Evaluation/MaxReturn                  -1634.8
Evaluation/MinReturn                  -1719.33
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     27.9864
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40473
GaussianMLPPolicy/KL                      0.000137293
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -702.88
GaussianMLPPolicy/LossBefore           -702.483
GaussianMLPPolicy/dLoss                   0.396484
GaussianMLPValueFunction/LossAfter   122983
GaussianMLPValueFunction/LossBefore  123241
GaussianMLPValueFunction/dLoss          258.523
TotalEnvSteps                        115200
-----------------------------------  ----------------
2022-08-17 17:55:21 | [trpo_pendulum] epoch #96 | Saving snapshot...
2022-08-17 17:55:21 | [trpo_pendulum] epoch #96 | Saved
2022-08-17 17:55:21 | [trpo_pendulum] epoch #96 | Time 40.92 s
2022-08-17 17:55:21 | [trpo_pendulum] epoch #96 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -747.091
Evaluation/AverageReturn              -1783.47
Evaluation/Iteration                     96
Evaluation/MaxReturn                  -1762.79
Evaluation/MinReturn                  -1799.28
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     12.5145
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4049
GaussianMLPPolicy/KL                      8.54741e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -734.2
GaussianMLPPolicy/LossBefore           -734.264
GaussianMLPPolicy/dLoss                  -0.0639648
GaussianMLPValueFunction/LossAfter   129225
GaussianMLPValueFunction/LossBefore  129497
GaussianMLPValueFunction/dLoss          271.438
TotalEnvSteps                        116400
-----------------------------------  ----------------
2022-08-17 17:55:21 | [trpo_pendulum] epoch #97 | Saving snapshot...
2022-08-17 17:55:21 | [trpo_pendulum] epoch #97 | Saved
2022-08-17 17:55:21 | [trpo_pendulum] epoch #97 | Time 41.34 s
2022-08-17 17:55:21 | [trpo_pendulum] epoch #97 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -749.342
Evaluation/AverageReturn              -1791.4
Evaluation/Iteration                     97
Evaluation/MaxReturn                  -1776.5
Evaluation/MinReturn                  -1805.26
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.27367
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40509
GaussianMLPPolicy/KL                      5.11028e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -723
GaussianMLPPolicy/LossBefore           -722.889
GaussianMLPPolicy/dLoss                   0.11084
GaussianMLPValueFunction/LossAfter   130254
GaussianMLPValueFunction/LossBefore  130529
GaussianMLPValueFunction/dLoss          274.891
TotalEnvSteps                        117600
-----------------------------------  ----------------
2022-08-17 17:55:21 | [trpo_pendulum] epoch #98 | Saving snapshot...
2022-08-17 17:55:21 | [trpo_pendulum] epoch #98 | Saved
2022-08-17 17:55:21 | [trpo_pendulum] epoch #98 | Time 41.75 s
2022-08-17 17:55:21 | [trpo_pendulum] epoch #98 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -705.985
Evaluation/AverageReturn              -1732.34
Evaluation/Iteration                     98
Evaluation/MaxReturn                  -1721.13
Evaluation/MinReturn                  -1744.54
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.73081
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40528
GaussianMLPPolicy/KL                      4.50432e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -715.597
GaussianMLPPolicy/LossBefore           -715.522
GaussianMLPPolicy/dLoss                   0.0747681
GaussianMLPValueFunction/LossAfter   125409
GaussianMLPValueFunction/LossBefore  125673
GaussianMLPValueFunction/dLoss          263.992
TotalEnvSteps                        118800
-----------------------------------  ----------------
2022-08-17 17:55:22 | [trpo_pendulum] epoch #99 | Saving snapshot...
2022-08-17 17:55:22 | [trpo_pendulum] epoch #99 | Saved
2022-08-17 17:55:22 | [trpo_pendulum] epoch #99 | Time 42.16 s
2022-08-17 17:55:22 | [trpo_pendulum] epoch #99 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -791.439
Evaluation/AverageReturn              -1839.59
Evaluation/Iteration                     99
Evaluation/MaxReturn                  -1814.04
Evaluation/MinReturn                  -1873.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     22.2535
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40552
GaussianMLPPolicy/KL                      4.39184e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -723.483
GaussianMLPPolicy/LossBefore           -723.379
GaussianMLPPolicy/dLoss                   0.104065
GaussianMLPValueFunction/LossAfter   131903
GaussianMLPValueFunction/LossBefore  132180
GaussianMLPValueFunction/dLoss          277.422
TotalEnvSteps                        120000
-----------------------------------  ----------------
2022-08-17 17:55:22 | [trpo_pendulum] epoch #100 | Saving snapshot...
2022-08-17 17:55:22 | [trpo_pendulum] epoch #100 | Saved
2022-08-17 17:55:22 | [trpo_pendulum] epoch #100 | Time 42.56 s
2022-08-17 17:55:22 | [trpo_pendulum] epoch #100 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -797.763
Evaluation/AverageReturn              -1845.07
Evaluation/Iteration                    100
Evaluation/MaxReturn                  -1832.79
Evaluation/MinReturn                  -1867.9
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.3416
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40574
GaussianMLPPolicy/KL                      1.09845e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -730.186
GaussianMLPPolicy/LossBefore           -730.212
GaussianMLPPolicy/dLoss                  -0.0268555
GaussianMLPValueFunction/LossAfter   131191
GaussianMLPValueFunction/LossBefore  131468
GaussianMLPValueFunction/dLoss          276.625
TotalEnvSteps                        121200
-----------------------------------  ----------------
2022-08-17 17:55:23 | [trpo_pendulum] epoch #101 | Saving snapshot...
2022-08-17 17:55:23 | [trpo_pendulum] epoch #101 | Saved
2022-08-17 17:55:23 | [trpo_pendulum] epoch #101 | Time 42.96 s
2022-08-17 17:55:23 | [trpo_pendulum] epoch #101 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -551.675
Evaluation/AverageReturn              -1527.58
Evaluation/Iteration                    101
Evaluation/MaxReturn                  -1461.22
Evaluation/MinReturn                  -1576.11
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     38.1825
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40597
GaussianMLPPolicy/KL                      0.000149555
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -680.006
GaussianMLPPolicy/LossBefore           -679.129
GaussianMLPPolicy/dLoss                   0.876892
GaussianMLPValueFunction/LossAfter   111339
GaussianMLPValueFunction/LossBefore  111569
GaussianMLPValueFunction/dLoss          230.414
TotalEnvSteps                        122400
-----------------------------------  ----------------
2022-08-17 17:55:23 | [trpo_pendulum] epoch #102 | Saving snapshot...
2022-08-17 17:55:23 | [trpo_pendulum] epoch #102 | Saved
2022-08-17 17:55:23 | [trpo_pendulum] epoch #102 | Time 43.37 s
2022-08-17 17:55:23 | [trpo_pendulum] epoch #102 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -788.536
Evaluation/AverageReturn              -1832.64
Evaluation/Iteration                    102
Evaluation/MaxReturn                  -1818.35
Evaluation/MinReturn                  -1865.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     15.8959
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40619
GaussianMLPPolicy/KL                      2.09654e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -726.868
GaussianMLPPolicy/LossBefore           -726.867
GaussianMLPPolicy/dLoss                   0.00146484
GaussianMLPValueFunction/LossAfter   129891
GaussianMLPValueFunction/LossBefore  130162
GaussianMLPValueFunction/dLoss          271.211
TotalEnvSteps                        123600
-----------------------------------  ----------------
2022-08-17 17:55:23 | [trpo_pendulum] epoch #103 | Saving snapshot...
2022-08-17 17:55:23 | [trpo_pendulum] epoch #103 | Saved
2022-08-17 17:55:23 | [trpo_pendulum] epoch #103 | Time 43.78 s
2022-08-17 17:55:23 | [trpo_pendulum] epoch #103 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -786.673
Evaluation/AverageReturn              -1832.77
Evaluation/Iteration                    103
Evaluation/MaxReturn                  -1815.48
Evaluation/MinReturn                  -1853.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.3237
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40623
GaussianMLPPolicy/KL                      6.71756e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -747.535
GaussianMLPPolicy/LossBefore           -747.131
GaussianMLPPolicy/dLoss                   0.404541
GaussianMLPValueFunction/LossAfter   130263
GaussianMLPValueFunction/LossBefore  130535
GaussianMLPValueFunction/dLoss          272.398
TotalEnvSteps                        124800
-----------------------------------  ----------------
2022-08-17 17:55:24 | [trpo_pendulum] epoch #104 | Saving snapshot...
2022-08-17 17:55:24 | [trpo_pendulum] epoch #104 | Saved
2022-08-17 17:55:24 | [trpo_pendulum] epoch #104 | Time 44.20 s
2022-08-17 17:55:24 | [trpo_pendulum] epoch #104 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -799.716
Evaluation/AverageReturn              -1839.58
Evaluation/Iteration                    104
Evaluation/MaxReturn                  -1821.71
Evaluation/MinReturn                  -1848.34
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.25118
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40624
GaussianMLPPolicy/KL                      3.25592e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -729.002
GaussianMLPPolicy/LossBefore           -729.023
GaussianMLPPolicy/dLoss                  -0.0205688
GaussianMLPValueFunction/LossAfter   128293
GaussianMLPValueFunction/LossBefore  128562
GaussianMLPValueFunction/dLoss          268.859
TotalEnvSteps                        126000
-----------------------------------  ----------------
2022-08-17 17:55:24 | [trpo_pendulum] epoch #105 | Saving snapshot...
2022-08-17 17:55:24 | [trpo_pendulum] epoch #105 | Saved
2022-08-17 17:55:24 | [trpo_pendulum] epoch #105 | Time 44.59 s
2022-08-17 17:55:24 | [trpo_pendulum] epoch #105 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -750.145
Evaluation/AverageReturn              -1783.25
Evaluation/Iteration                    105
Evaluation/MaxReturn                  -1757.09
Evaluation/MinReturn                  -1793.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     12.775
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40631
GaussianMLPPolicy/KL                      4.85505e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -713.637
GaussianMLPPolicy/LossBefore           -713.579
GaussianMLPPolicy/dLoss                   0.0584717
GaussianMLPValueFunction/LossAfter   125830
GaussianMLPValueFunction/LossBefore  126094
GaussianMLPValueFunction/dLoss          264.062
TotalEnvSteps                        127200
-----------------------------------  ----------------
2022-08-17 17:55:25 | [trpo_pendulum] epoch #106 | Saving snapshot...
2022-08-17 17:55:25 | [trpo_pendulum] epoch #106 | Saved
2022-08-17 17:55:25 | [trpo_pendulum] epoch #106 | Time 45.00 s
2022-08-17 17:55:25 | [trpo_pendulum] epoch #106 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -602.581
Evaluation/AverageReturn              -1575.71
Evaluation/Iteration                    106
Evaluation/MaxReturn                  -1531.64
Evaluation/MinReturn                  -1609.13
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     30.1461
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40654
GaussianMLPPolicy/KL                      7.99106e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -661.322
GaussianMLPPolicy/LossBefore           -661.315
GaussianMLPPolicy/dLoss                   0.00665283
GaussianMLPValueFunction/LossAfter   109428
GaussianMLPValueFunction/LossBefore  109654
GaussianMLPValueFunction/dLoss          225.906
TotalEnvSteps                        128400
-----------------------------------  ----------------
2022-08-17 17:55:25 | [trpo_pendulum] epoch #107 | Saving snapshot...
2022-08-17 17:55:25 | [trpo_pendulum] epoch #107 | Saved
2022-08-17 17:55:25 | [trpo_pendulum] epoch #107 | Time 45.40 s
2022-08-17 17:55:25 | [trpo_pendulum] epoch #107 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -673.338
Evaluation/AverageReturn              -1668.39
Evaluation/Iteration                    107
Evaluation/MaxReturn                  -1630.39
Evaluation/MinReturn                  -1682.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     17.7103
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40686
GaussianMLPPolicy/KL                      7.96428e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -682.195
GaussianMLPPolicy/LossBefore           -681.982
GaussianMLPPolicy/dLoss                   0.212952
GaussianMLPValueFunction/LossAfter   115672
GaussianMLPValueFunction/LossBefore  115912
GaussianMLPValueFunction/dLoss          239.969
TotalEnvSteps                        129600
-----------------------------------  ----------------
2022-08-17 17:55:25 | [trpo_pendulum] epoch #108 | Saving snapshot...
2022-08-17 17:55:25 | [trpo_pendulum] epoch #108 | Saved
2022-08-17 17:55:25 | [trpo_pendulum] epoch #108 | Time 45.81 s
2022-08-17 17:55:25 | [trpo_pendulum] epoch #108 | EpochTime 0.40 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -738.01
Evaluation/AverageReturn              -1765.71
Evaluation/Iteration                    108
Evaluation/MaxReturn                  -1744.81
Evaluation/MinReturn                  -1783.42
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.8337
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40706
GaussianMLPPolicy/KL                      3.486e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -726.342
GaussianMLPPolicy/LossBefore           -726.308
GaussianMLPPolicy/dLoss                   0.0340576
GaussianMLPValueFunction/LossAfter   123353
GaussianMLPValueFunction/LossBefore  123607
GaussianMLPValueFunction/dLoss          254.461
TotalEnvSteps                        130800
-----------------------------------  --------------
2022-08-17 17:55:26 | [trpo_pendulum] epoch #109 | Saving snapshot...
2022-08-17 17:55:26 | [trpo_pendulum] epoch #109 | Saved
2022-08-17 17:55:26 | [trpo_pendulum] epoch #109 | Time 46.23 s
2022-08-17 17:55:26 | [trpo_pendulum] epoch #109 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -785.277
Evaluation/AverageReturn              -1817.23
Evaluation/Iteration                    109
Evaluation/MaxReturn                  -1782.47
Evaluation/MinReturn                  -1841.58
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     18.9612
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40729
GaussianMLPPolicy/KL                      1.90601e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -714.418
GaussianMLPPolicy/LossBefore           -714.416
GaussianMLPPolicy/dLoss                   0.00177002
GaussianMLPValueFunction/LossAfter   125362
GaussianMLPValueFunction/LossBefore  125619
GaussianMLPValueFunction/dLoss          257.422
TotalEnvSteps                        132000
-----------------------------------  ----------------
2022-08-17 17:55:26 | [trpo_pendulum] epoch #110 | Saving snapshot...
2022-08-17 17:55:26 | [trpo_pendulum] epoch #110 | Saved
2022-08-17 17:55:26 | [trpo_pendulum] epoch #110 | Time 46.64 s
2022-08-17 17:55:26 | [trpo_pendulum] epoch #110 | EpochTime 0.41 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -544.414
Evaluation/AverageReturn              -1499.45
Evaluation/Iteration                    110
Evaluation/MaxReturn                  -1430.49
Evaluation/MinReturn                  -1543.53
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     41.5048
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40755
GaussianMLPPolicy/KL                      0.0002394
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -662.133
GaussianMLPPolicy/LossBefore           -661.038
GaussianMLPPolicy/dLoss                   1.09473
GaussianMLPValueFunction/LossAfter   104312
GaussianMLPValueFunction/LossBefore  104523
GaussianMLPValueFunction/dLoss          210.367
TotalEnvSteps                        133200
-----------------------------------  --------------
2022-08-17 17:55:27 | [trpo_pendulum] epoch #111 | Saving snapshot...
2022-08-17 17:55:27 | [trpo_pendulum] epoch #111 | Saved
2022-08-17 17:55:27 | [trpo_pendulum] epoch #111 | Time 47.06 s
2022-08-17 17:55:27 | [trpo_pendulum] epoch #111 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -638.447
Evaluation/AverageReturn              -1618.14
Evaluation/Iteration                    111
Evaluation/MaxReturn                  -1589.8
Evaluation/MinReturn                  -1652.97
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     22.84
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40772
GaussianMLPPolicy/KL                      0.000270264
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -691.381
GaussianMLPPolicy/LossBefore           -690.899
GaussianMLPPolicy/dLoss                   0.482666
GaussianMLPValueFunction/LossAfter   109939
GaussianMLPValueFunction/LossBefore  110163
GaussianMLPValueFunction/dLoss          223.867
TotalEnvSteps                        134400
-----------------------------------  ----------------
2022-08-17 17:55:27 | [trpo_pendulum] epoch #112 | Saving snapshot...
2022-08-17 17:55:27 | [trpo_pendulum] epoch #112 | Saved
2022-08-17 17:55:27 | [trpo_pendulum] epoch #112 | Time 47.48 s
2022-08-17 17:55:27 | [trpo_pendulum] epoch #112 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -746.384
Evaluation/AverageReturn              -1779.12
Evaluation/Iteration                    112
Evaluation/MaxReturn                  -1760.99
Evaluation/MinReturn                  -1799.19
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     12.7153
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40785
GaussianMLPPolicy/KL                      0.000173797
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -723.068
GaussianMLPPolicy/LossBefore           -722.209
GaussianMLPPolicy/dLoss                   0.859314
GaussianMLPValueFunction/LossAfter   123945
GaussianMLPValueFunction/LossBefore  124195
GaussianMLPValueFunction/dLoss          249.781
TotalEnvSteps                        135600
-----------------------------------  ----------------
2022-08-17 17:55:28 | [trpo_pendulum] epoch #113 | Saving snapshot...
2022-08-17 17:55:28 | [trpo_pendulum] epoch #113 | Saved
2022-08-17 17:55:28 | [trpo_pendulum] epoch #113 | Time 47.90 s
2022-08-17 17:55:28 | [trpo_pendulum] epoch #113 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -538.04
Evaluation/AverageReturn              -1458.34
Evaluation/Iteration                    113
Evaluation/MaxReturn                  -1394.96
Evaluation/MinReturn                  -1513.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     37.3376
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40798
GaussianMLPPolicy/KL                      0.000309233
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -641.613
GaussianMLPPolicy/LossBefore           -641.647
GaussianMLPPolicy/dLoss                  -0.0344849
GaussianMLPValueFunction/LossAfter    95360.2
GaussianMLPValueFunction/LossBefore   95548.5
GaussianMLPValueFunction/dLoss          188.312
TotalEnvSteps                        136800
-----------------------------------  ----------------
2022-08-17 17:55:28 | [trpo_pendulum] epoch #114 | Saving snapshot...
2022-08-17 17:55:28 | [trpo_pendulum] epoch #114 | Saved
2022-08-17 17:55:28 | [trpo_pendulum] epoch #114 | Time 48.33 s
2022-08-17 17:55:28 | [trpo_pendulum] epoch #114 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -605.709
Evaluation/AverageReturn              -1569
Evaluation/Iteration                    114
Evaluation/MaxReturn                  -1490.1
Evaluation/MinReturn                  -1640.78
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.436
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40797
GaussianMLPPolicy/KL                      0.000512316
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -687.497
GaussianMLPPolicy/LossBefore           -686.07
GaussianMLPPolicy/dLoss                   1.42712
GaussianMLPValueFunction/LossAfter   104913
GaussianMLPValueFunction/LossBefore  105120
GaussianMLPValueFunction/dLoss          206.914
TotalEnvSteps                        138000
-----------------------------------  ----------------
2022-08-17 17:55:28 | [trpo_pendulum] epoch #115 | Saving snapshot...
2022-08-17 17:55:28 | [trpo_pendulum] epoch #115 | Saved
2022-08-17 17:55:28 | [trpo_pendulum] epoch #115 | Time 48.74 s
2022-08-17 17:55:28 | [trpo_pendulum] epoch #115 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -522.695
Evaluation/AverageReturn              -1424.34
Evaluation/Iteration                    115
Evaluation/MaxReturn                  -1396.91
Evaluation/MinReturn                  -1460.31
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     19.919
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40784
GaussianMLPPolicy/KL                      0.000681384
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -642.455
GaussianMLPPolicy/LossBefore           -641.685
GaussianMLPPolicy/dLoss                   0.770081
GaussianMLPValueFunction/LossAfter    91063.3
GaussianMLPValueFunction/LossBefore   91240.5
GaussianMLPValueFunction/dLoss          177.219
TotalEnvSteps                        139200
-----------------------------------  ----------------
2022-08-17 17:55:29 | [trpo_pendulum] epoch #116 | Saving snapshot...
2022-08-17 17:55:29 | [trpo_pendulum] epoch #116 | Saved
2022-08-17 17:55:29 | [trpo_pendulum] epoch #116 | Time 49.16 s
2022-08-17 17:55:29 | [trpo_pendulum] epoch #116 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -586.343
Evaluation/AverageReturn              -1504.37
Evaluation/Iteration                    116
Evaluation/MaxReturn                  -1435
Evaluation/MinReturn                  -1609.13
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     53.859
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4079
GaussianMLPPolicy/KL                      0.000488607
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -621.202
GaussianMLPPolicy/LossBefore           -621.008
GaussianMLPPolicy/dLoss                   0.193665
GaussianMLPValueFunction/LossAfter    94588.9
GaussianMLPValueFunction/LossBefore   94772.7
GaussianMLPValueFunction/dLoss          183.773
TotalEnvSteps                        140400
-----------------------------------  ----------------
2022-08-17 17:55:29 | [trpo_pendulum] epoch #117 | Saving snapshot...
2022-08-17 17:55:29 | [trpo_pendulum] epoch #117 | Saved
2022-08-17 17:55:29 | [trpo_pendulum] epoch #117 | Time 49.59 s
2022-08-17 17:55:29 | [trpo_pendulum] epoch #117 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -782.086
Evaluation/AverageReturn              -1820.12
Evaluation/Iteration                    117
Evaluation/MaxReturn                  -1807.95
Evaluation/MinReturn                  -1835.87
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.28817
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40807
GaussianMLPPolicy/KL                      4.18165e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -711.515
GaussianMLPPolicy/LossBefore           -711.624
GaussianMLPPolicy/dLoss                  -0.109131
GaussianMLPValueFunction/LossAfter   124376
GaussianMLPValueFunction/LossBefore  124611
GaussianMLPValueFunction/dLoss          235.172
TotalEnvSteps                        141600
-----------------------------------  ----------------
2022-08-17 17:55:30 | [trpo_pendulum] epoch #118 | Saving snapshot...
2022-08-17 17:55:30 | [trpo_pendulum] epoch #118 | Saved
2022-08-17 17:55:30 | [trpo_pendulum] epoch #118 | Time 50.01 s
2022-08-17 17:55:30 | [trpo_pendulum] epoch #118 | EpochTime 0.42 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -458.54
Evaluation/AverageReturn              -1254.65
Evaluation/Iteration                    118
Evaluation/MaxReturn                  -1167.3
Evaluation/MinReturn                  -1344.98
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     64.9952
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40799
GaussianMLPPolicy/KL                      0.00017938
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -581.432
GaussianMLPPolicy/LossBefore           -581.559
GaussianMLPPolicy/dLoss                  -0.127136
GaussianMLPValueFunction/LossAfter    70914.7
GaussianMLPValueFunction/LossBefore   71049.3
GaussianMLPValueFunction/dLoss          134.57
TotalEnvSteps                        142800
-----------------------------------  ---------------
2022-08-17 17:55:30 | [trpo_pendulum] epoch #119 | Saving snapshot...
2022-08-17 17:55:30 | [trpo_pendulum] epoch #119 | Saved
2022-08-17 17:55:30 | [trpo_pendulum] epoch #119 | Time 50.42 s
2022-08-17 17:55:30 | [trpo_pendulum] epoch #119 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -544.978
Evaluation/AverageReturn              -1424.22
Evaluation/Iteration                    119
Evaluation/MaxReturn                  -1322.87
Evaluation/MinReturn                  -1558.93
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     74.7689
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.408
GaussianMLPPolicy/KL                      0.000336326
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -604.019
GaussianMLPPolicy/LossBefore           -603.29
GaussianMLPPolicy/dLoss                   0.728943
GaussianMLPValueFunction/LossAfter    86061.1
GaussianMLPValueFunction/LossBefore   86222.2
GaussianMLPValueFunction/dLoss          161.07
TotalEnvSteps                        144000
-----------------------------------  ----------------
2022-08-17 17:55:30 | [trpo_pendulum] epoch #120 | Saving snapshot...
2022-08-17 17:55:30 | [trpo_pendulum] epoch #120 | Saved
2022-08-17 17:55:30 | [trpo_pendulum] epoch #120 | Time 50.83 s
2022-08-17 17:55:30 | [trpo_pendulum] epoch #120 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -510.837
Evaluation/AverageReturn              -1318.49
Evaluation/Iteration                    120
Evaluation/MaxReturn                  -1189.6
Evaluation/MinReturn                  -1395.86
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     69.1934
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.408
GaussianMLPPolicy/KL                      0.000262259
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -565.17
GaussianMLPPolicy/LossBefore           -565.084
GaussianMLPPolicy/dLoss                   0.0863647
GaussianMLPValueFunction/LossAfter    72606
GaussianMLPValueFunction/LossBefore   72741.8
GaussianMLPValueFunction/dLoss          135.781
TotalEnvSteps                        145200
-----------------------------------  ----------------
2022-08-17 17:55:31 | [trpo_pendulum] epoch #121 | Saving snapshot...
2022-08-17 17:55:31 | [trpo_pendulum] epoch #121 | Saved
2022-08-17 17:55:31 | [trpo_pendulum] epoch #121 | Time 51.24 s
2022-08-17 17:55:31 | [trpo_pendulum] epoch #121 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -715.305
Evaluation/AverageReturn              -1726.05
Evaluation/Iteration                    121
Evaluation/MaxReturn                  -1690.46
Evaluation/MinReturn                  -1762.45
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     30.212
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40801
GaussianMLPPolicy/KL                      0.000110579
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -703.221
GaussianMLPPolicy/LossBefore           -702.832
GaussianMLPPolicy/dLoss                   0.389343
GaussianMLPValueFunction/LossAfter   116012
GaussianMLPValueFunction/LossBefore  116218
GaussianMLPValueFunction/dLoss          206.648
TotalEnvSteps                        146400
-----------------------------------  ----------------
2022-08-17 17:55:31 | [trpo_pendulum] epoch #122 | Saving snapshot...
2022-08-17 17:55:31 | [trpo_pendulum] epoch #122 | Saved
2022-08-17 17:55:31 | [trpo_pendulum] epoch #122 | Time 51.66 s
2022-08-17 17:55:31 | [trpo_pendulum] epoch #122 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -471.981
Evaluation/AverageReturn              -1230.04
Evaluation/Iteration                    122
Evaluation/MaxReturn                  -1132.5
Evaluation/MinReturn                  -1366.83
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     79.2761
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40793
GaussianMLPPolicy/KL                      0.000264302
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -538.609
GaussianMLPPolicy/LossBefore           -538.517
GaussianMLPPolicy/dLoss                   0.092041
GaussianMLPValueFunction/LossAfter    64085
GaussianMLPValueFunction/LossBefore   64202.2
GaussianMLPValueFunction/dLoss          117.176
TotalEnvSteps                        147600
-----------------------------------  ----------------
2022-08-17 17:55:32 | [trpo_pendulum] epoch #123 | Saving snapshot...
2022-08-17 17:55:32 | [trpo_pendulum] epoch #123 | Saved
2022-08-17 17:55:32 | [trpo_pendulum] epoch #123 | Time 52.07 s
2022-08-17 17:55:32 | [trpo_pendulum] epoch #123 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -705.928
Evaluation/AverageReturn              -1684.98
Evaluation/Iteration                    123
Evaluation/MaxReturn                  -1620.17
Evaluation/MinReturn                  -1778.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.7412
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40788
GaussianMLPPolicy/KL                      8.50766e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -680.086
GaussianMLPPolicy/LossBefore           -679.979
GaussianMLPPolicy/dLoss                   0.106812
GaussianMLPValueFunction/LossAfter   108246
GaussianMLPValueFunction/LossBefore  108434
GaussianMLPValueFunction/dLoss          187.977
TotalEnvSteps                        148800
-----------------------------------  ----------------
2022-08-17 17:55:32 | [trpo_pendulum] epoch #124 | Saving snapshot...
2022-08-17 17:55:32 | [trpo_pendulum] epoch #124 | Saved
2022-08-17 17:55:32 | [trpo_pendulum] epoch #124 | Time 52.49 s
2022-08-17 17:55:32 | [trpo_pendulum] epoch #124 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -441.016
Evaluation/AverageReturn              -1144.06
Evaluation/Iteration                    124
Evaluation/MaxReturn                  -1059.38
Evaluation/MinReturn                  -1187.69
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     43.438
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40784
GaussianMLPPolicy/KL                      5.96794e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -489.654
GaussianMLPPolicy/LossBefore           -489.721
GaussianMLPPolicy/dLoss                  -0.067688
GaussianMLPValueFunction/LossAfter    54959.2
GaussianMLPValueFunction/LossBefore   55055.2
GaussianMLPValueFunction/dLoss           95.9688
TotalEnvSteps                        150000
-----------------------------------  ----------------
2022-08-17 17:55:33 | [trpo_pendulum] epoch #125 | Saving snapshot...
2022-08-17 17:55:33 | [trpo_pendulum] epoch #125 | Saved
2022-08-17 17:55:33 | [trpo_pendulum] epoch #125 | Time 52.90 s
2022-08-17 17:55:33 | [trpo_pendulum] epoch #125 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -748.182
Evaluation/AverageReturn              -1769.61
Evaluation/Iteration                    125
Evaluation/MaxReturn                  -1718.28
Evaluation/MinReturn                  -1803.7
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     31.0481
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40775
GaussianMLPPolicy/KL                      1.58252e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -717.029
GaussianMLPPolicy/LossBefore           -716.932
GaussianMLPPolicy/dLoss                   0.09729
GaussianMLPValueFunction/LossAfter   117980
GaussianMLPValueFunction/LossBefore  118178
GaussianMLPValueFunction/dLoss          197.797
TotalEnvSteps                        151200
-----------------------------------  ----------------
2022-08-17 17:55:33 | [trpo_pendulum] epoch #126 | Saving snapshot...
2022-08-17 17:55:33 | [trpo_pendulum] epoch #126 | Saved
2022-08-17 17:55:33 | [trpo_pendulum] epoch #126 | Time 53.30 s
2022-08-17 17:55:33 | [trpo_pendulum] epoch #126 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -792.121
Evaluation/AverageReturn              -1815.58
Evaluation/Iteration                    126
Evaluation/MaxReturn                  -1726.28
Evaluation/MinReturn                  -1850.81
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     41.2056
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40758
GaussianMLPPolicy/KL                      1.30684e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -722.511
GaussianMLPPolicy/LossBefore           -722.452
GaussianMLPPolicy/dLoss                   0.0592041
GaussianMLPValueFunction/LossAfter   119977
GaussianMLPValueFunction/LossBefore  120181
GaussianMLPValueFunction/dLoss          204.336
TotalEnvSteps                        152400
-----------------------------------  ----------------
2022-08-17 17:55:33 | [trpo_pendulum] epoch #127 | Saving snapshot...
2022-08-17 17:55:33 | [trpo_pendulum] epoch #127 | Saved
2022-08-17 17:55:33 | [trpo_pendulum] epoch #127 | Time 53.71 s
2022-08-17 17:55:33 | [trpo_pendulum] epoch #127 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -674.004
Evaluation/AverageReturn              -1621.07
Evaluation/Iteration                    127
Evaluation/MaxReturn                  -1563.21
Evaluation/MinReturn                  -1723.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     52.41
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40759
GaussianMLPPolicy/KL                      1.51422e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -641.579
GaussianMLPPolicy/LossBefore           -641.56
GaussianMLPPolicy/dLoss                   0.019165
GaussianMLPValueFunction/LossAfter   100258
GaussianMLPValueFunction/LossBefore  100434
GaussianMLPValueFunction/dLoss          175.758
TotalEnvSteps                        153600
-----------------------------------  ----------------
2022-08-17 17:55:34 | [trpo_pendulum] epoch #128 | Saving snapshot...
2022-08-17 17:55:34 | [trpo_pendulum] epoch #128 | Saved
2022-08-17 17:55:34 | [trpo_pendulum] epoch #128 | Time 54.12 s
2022-08-17 17:55:34 | [trpo_pendulum] epoch #128 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -699.447
Evaluation/AverageReturn              -1664.27
Evaluation/Iteration                    128
Evaluation/MaxReturn                  -1549.22
Evaluation/MinReturn                  -1725.91
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     56.0291
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40751
GaussianMLPPolicy/KL                      3.43028e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -679.538
GaussianMLPPolicy/LossBefore           -679.512
GaussianMLPPolicy/dLoss                   0.0257568
GaussianMLPValueFunction/LossAfter   104531
GaussianMLPValueFunction/LossBefore  104714
GaussianMLPValueFunction/dLoss          182.734
TotalEnvSteps                        154800
-----------------------------------  ----------------
2022-08-17 17:55:34 | [trpo_pendulum] epoch #129 | Saving snapshot...
2022-08-17 17:55:34 | [trpo_pendulum] epoch #129 | Saved
2022-08-17 17:55:34 | [trpo_pendulum] epoch #129 | Time 54.53 s
2022-08-17 17:55:34 | [trpo_pendulum] epoch #129 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -726.1
Evaluation/AverageReturn              -1723.36
Evaluation/Iteration                    129
Evaluation/MaxReturn                  -1662.62
Evaluation/MinReturn                  -1810.89
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     51.6262
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40737
GaussianMLPPolicy/KL                      1.98086e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -701.331
GaussianMLPPolicy/LossBefore           -701.248
GaussianMLPPolicy/dLoss                   0.0834351
GaussianMLPValueFunction/LossAfter   111567
GaussianMLPValueFunction/LossBefore  111763
GaussianMLPValueFunction/dLoss          195.562
TotalEnvSteps                        156000
-----------------------------------  ----------------
2022-08-17 17:55:35 | [trpo_pendulum] epoch #130 | Saving snapshot...
2022-08-17 17:55:35 | [trpo_pendulum] epoch #130 | Saved
2022-08-17 17:55:35 | [trpo_pendulum] epoch #130 | Time 54.94 s
2022-08-17 17:55:35 | [trpo_pendulum] epoch #130 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -759.685
Evaluation/AverageReturn              -1779.45
Evaluation/Iteration                    130
Evaluation/MaxReturn                  -1747.69
Evaluation/MinReturn                  -1800.19
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     18.2133
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40715
GaussianMLPPolicy/KL                      3.41052e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -720.331
GaussianMLPPolicy/LossBefore           -720.276
GaussianMLPPolicy/dLoss                   0.0551758
GaussianMLPValueFunction/LossAfter   117243
GaussianMLPValueFunction/LossBefore  117450
GaussianMLPValueFunction/dLoss          206.617
TotalEnvSteps                        157200
-----------------------------------  ----------------
2022-08-17 17:55:35 | [trpo_pendulum] epoch #131 | Saving snapshot...
2022-08-17 17:55:35 | [trpo_pendulum] epoch #131 | Saved
2022-08-17 17:55:35 | [trpo_pendulum] epoch #131 | Time 55.36 s
2022-08-17 17:55:35 | [trpo_pendulum] epoch #131 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -521.644
Evaluation/AverageReturn              -1293.51
Evaluation/Iteration                    131
Evaluation/MaxReturn                  -1209.32
Evaluation/MinReturn                  -1465.3
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     85.2626
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40691
GaussianMLPPolicy/KL                      5.19379e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -539.535
GaussianMLPPolicy/LossBefore           -539.499
GaussianMLPPolicy/dLoss                   0.0361328
GaussianMLPValueFunction/LossAfter    65894.7
GaussianMLPValueFunction/LossBefore   66015.1
GaussianMLPValueFunction/dLoss          120.484
TotalEnvSteps                        158400
-----------------------------------  ----------------
2022-08-17 17:55:35 | [trpo_pendulum] epoch #132 | Saving snapshot...
2022-08-17 17:55:35 | [trpo_pendulum] epoch #132 | Saved
2022-08-17 17:55:35 | [trpo_pendulum] epoch #132 | Time 55.77 s
2022-08-17 17:55:35 | [trpo_pendulum] epoch #132 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -622.423
Evaluation/AverageReturn              -1515.06
Evaluation/Iteration                    132
Evaluation/MaxReturn                  -1395.17
Evaluation/MinReturn                  -1586.05
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     62.3881
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40682
GaussianMLPPolicy/KL                      1.91612e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -607.053
GaussianMLPPolicy/LossBefore           -607.054
GaussianMLPPolicy/dLoss                  -0.000732422
GaussianMLPValueFunction/LossAfter    87735
GaussianMLPValueFunction/LossBefore   87890.5
GaussianMLPValueFunction/dLoss          155.57
TotalEnvSteps                        159600
-----------------------------------  ----------------
2022-08-17 17:55:36 | [trpo_pendulum] epoch #133 | Saving snapshot...
2022-08-17 17:55:36 | [trpo_pendulum] epoch #133 | Saved
2022-08-17 17:55:36 | [trpo_pendulum] epoch #133 | Time 56.18 s
2022-08-17 17:55:36 | [trpo_pendulum] epoch #133 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -466.28
Evaluation/AverageReturn              -1219.85
Evaluation/Iteration                    133
Evaluation/MaxReturn                  -1143.71
Evaluation/MinReturn                  -1296.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     52.6857
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40671
GaussianMLPPolicy/KL                      0.000177662
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -528.797
GaussianMLPPolicy/LossBefore           -528.235
GaussianMLPPolicy/dLoss                   0.561523
GaussianMLPValueFunction/LossAfter    62203.1
GaussianMLPValueFunction/LossBefore   62312.3
GaussianMLPValueFunction/dLoss          109.199
TotalEnvSteps                        160800
-----------------------------------  ----------------
2022-08-17 17:55:36 | [trpo_pendulum] epoch #134 | Saving snapshot...
2022-08-17 17:55:36 | [trpo_pendulum] epoch #134 | Saved
2022-08-17 17:55:36 | [trpo_pendulum] epoch #134 | Time 56.59 s
2022-08-17 17:55:36 | [trpo_pendulum] epoch #134 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -526.529
Evaluation/AverageReturn              -1313.89
Evaluation/Iteration                    134
Evaluation/MaxReturn                  -1205.34
Evaluation/MinReturn                  -1446.31
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     83.4087
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40663
GaussianMLPPolicy/KL                      0.000300436
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -545.089
GaussianMLPPolicy/LossBefore           -544.624
GaussianMLPPolicy/dLoss                   0.465088
GaussianMLPValueFunction/LossAfter    67881.2
GaussianMLPValueFunction/LossBefore   67998.9
GaussianMLPValueFunction/dLoss          117.664
TotalEnvSteps                        162000
-----------------------------------  ----------------
2022-08-17 17:55:37 | [trpo_pendulum] epoch #135 | Saving snapshot...
2022-08-17 17:55:37 | [trpo_pendulum] epoch #135 | Saved
2022-08-17 17:55:37 | [trpo_pendulum] epoch #135 | Time 57.00 s
2022-08-17 17:55:37 | [trpo_pendulum] epoch #135 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -755.396
Evaluation/AverageReturn              -1777.67
Evaluation/Iteration                    135
Evaluation/MaxReturn                  -1726.67
Evaluation/MinReturn                  -1800.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     24.7074
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40643
GaussianMLPPolicy/KL                      0.00010438
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -723.823
GaussianMLPPolicy/LossBefore           -722.827
GaussianMLPPolicy/dLoss                   0.996216
GaussianMLPValueFunction/LossAfter   117023
GaussianMLPValueFunction/LossBefore  117214
GaussianMLPValueFunction/dLoss          190.398
TotalEnvSteps                        163200
-----------------------------------  ---------------
2022-08-17 17:55:37 | [trpo_pendulum] epoch #136 | Saving snapshot...
2022-08-17 17:55:37 | [trpo_pendulum] epoch #136 | Saved
2022-08-17 17:55:37 | [trpo_pendulum] epoch #136 | Time 57.40 s
2022-08-17 17:55:37 | [trpo_pendulum] epoch #136 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -746.36
Evaluation/AverageReturn              -1748.94
Evaluation/Iteration                    136
Evaluation/MaxReturn                  -1712.96
Evaluation/MinReturn                  -1801.31
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     32.3701
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40634
GaussianMLPPolicy/KL                      0.000164972
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -688.632
GaussianMLPPolicy/LossBefore           -688.113
GaussianMLPPolicy/dLoss                   0.519714
GaussianMLPValueFunction/LossAfter   112262
GaussianMLPValueFunction/LossBefore  112448
GaussianMLPValueFunction/dLoss          186.539
TotalEnvSteps                        164400
-----------------------------------  ----------------
2022-08-17 17:55:37 | [trpo_pendulum] epoch #137 | Saving snapshot...
2022-08-17 17:55:37 | [trpo_pendulum] epoch #137 | Saved
2022-08-17 17:55:37 | [trpo_pendulum] epoch #137 | Time 57.81 s
2022-08-17 17:55:37 | [trpo_pendulum] epoch #137 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -529.41
Evaluation/AverageReturn              -1261.13
Evaluation/Iteration                    137
Evaluation/MaxReturn                  -1146.49
Evaluation/MinReturn                  -1446.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     99.2415
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40612
GaussianMLPPolicy/KL                      0.000577498
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -521.592
GaussianMLPPolicy/LossBefore           -521.585
GaussianMLPPolicy/dLoss                   0.00720215
GaussianMLPValueFunction/LossAfter    59422.7
GaussianMLPValueFunction/LossBefore   59528.5
GaussianMLPValueFunction/dLoss          105.762
TotalEnvSteps                        165600
-----------------------------------  ----------------
2022-08-17 17:55:38 | [trpo_pendulum] epoch #138 | Saving snapshot...
2022-08-17 17:55:38 | [trpo_pendulum] epoch #138 | Saved
2022-08-17 17:55:38 | [trpo_pendulum] epoch #138 | Time 58.23 s
2022-08-17 17:55:38 | [trpo_pendulum] epoch #138 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -761.75
Evaluation/AverageReturn              -1757.41
Evaluation/Iteration                    138
Evaluation/MaxReturn                  -1650.18
Evaluation/MinReturn                  -1833.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     69.2602
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40598
GaussianMLPPolicy/KL                      6.16438e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -685.471
GaussianMLPPolicy/LossBefore           -685.6
GaussianMLPPolicy/dLoss                  -0.129517
GaussianMLPValueFunction/LossAfter   110767
GaussianMLPValueFunction/LossBefore  110948
GaussianMLPValueFunction/dLoss          180.984
TotalEnvSteps                        166800
-----------------------------------  ----------------
2022-08-17 17:55:38 | [trpo_pendulum] epoch #139 | Saving snapshot...
2022-08-17 17:55:38 | [trpo_pendulum] epoch #139 | Saved
2022-08-17 17:55:38 | [trpo_pendulum] epoch #139 | Time 58.65 s
2022-08-17 17:55:38 | [trpo_pendulum] epoch #139 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -353.53
Evaluation/AverageReturn               -887.336
Evaluation/Iteration                    139
Evaluation/MaxReturn                   -735.601
Evaluation/MinReturn                  -1053.27
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    100.369
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40583
GaussianMLPPolicy/KL                      0.000502196
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -377.794
GaussianMLPPolicy/LossBefore           -377.331
GaussianMLPPolicy/dLoss                   0.463348
GaussianMLPValueFunction/LossAfter    33155.6
GaussianMLPValueFunction/LossBefore   33211.3
GaussianMLPValueFunction/dLoss           55.6055
TotalEnvSteps                        168000
-----------------------------------  ----------------
2022-08-17 17:55:39 | [trpo_pendulum] epoch #140 | Saving snapshot...
2022-08-17 17:55:39 | [trpo_pendulum] epoch #140 | Saved
2022-08-17 17:55:39 | [trpo_pendulum] epoch #140 | Time 59.05 s
2022-08-17 17:55:39 | [trpo_pendulum] epoch #140 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -769.915
Evaluation/AverageReturn              -1783.34
Evaluation/Iteration                    140
Evaluation/MaxReturn                  -1736.97
Evaluation/MinReturn                  -1832.87
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     38.2723
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4058
GaussianMLPPolicy/KL                      9.83827e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -692.28
GaussianMLPPolicy/LossBefore           -691.679
GaussianMLPPolicy/dLoss                   0.601685
GaussianMLPValueFunction/LossAfter   114554
GaussianMLPValueFunction/LossBefore  114734
GaussianMLPValueFunction/dLoss          179.547
TotalEnvSteps                        169200
-----------------------------------  ----------------
2022-08-17 17:55:39 | [trpo_pendulum] epoch #141 | Saving snapshot...
2022-08-17 17:55:39 | [trpo_pendulum] epoch #141 | Saved
2022-08-17 17:55:39 | [trpo_pendulum] epoch #141 | Time 59.44 s
2022-08-17 17:55:39 | [trpo_pendulum] epoch #141 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -715.576
Evaluation/AverageReturn              -1662.08
Evaluation/Iteration                    141
Evaluation/MaxReturn                  -1540.64
Evaluation/MinReturn                  -1796.99
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     92.3242
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40581
GaussianMLPPolicy/KL                      0.000221269
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -653.2
GaussianMLPPolicy/LossBefore           -653.026
GaussianMLPPolicy/dLoss                   0.174438
GaussianMLPValueFunction/LossAfter    99610.6
GaussianMLPValueFunction/LossBefore   99770.6
GaussianMLPValueFunction/dLoss          159.93
TotalEnvSteps                        170400
-----------------------------------  ----------------
2022-08-17 17:55:39 | [trpo_pendulum] epoch #142 | Saving snapshot...
2022-08-17 17:55:40 | [trpo_pendulum] epoch #142 | Saved
2022-08-17 17:55:40 | [trpo_pendulum] epoch #142 | Time 59.85 s
2022-08-17 17:55:40 | [trpo_pendulum] epoch #142 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -458.416
Evaluation/AverageReturn              -1035.7
Evaluation/Iteration                    142
Evaluation/MaxReturn                   -918.975
Evaluation/MinReturn                  -1197.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     89.8402
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40586
GaussianMLPPolicy/KL                      0.000456995
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -399.294
GaussianMLPPolicy/LossBefore           -399.234
GaussianMLPPolicy/dLoss                   0.0597229
GaussianMLPValueFunction/LossAfter    38012.4
GaussianMLPValueFunction/LossBefore   38077.7
GaussianMLPValueFunction/dLoss           65.3555
TotalEnvSteps                        171600
-----------------------------------  ----------------
2022-08-17 17:55:40 | [trpo_pendulum] epoch #143 | Saving snapshot...
2022-08-17 17:55:40 | [trpo_pendulum] epoch #143 | Saved
2022-08-17 17:55:40 | [trpo_pendulum] epoch #143 | Time 60.27 s
2022-08-17 17:55:40 | [trpo_pendulum] epoch #143 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -709.375
Evaluation/AverageReturn              -1628.01
Evaluation/Iteration                    143
Evaluation/MaxReturn                  -1551.28
Evaluation/MinReturn                  -1766.18
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     77.5712
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40604
GaussianMLPPolicy/KL                      0.000112476
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -622.203
GaussianMLPPolicy/LossBefore           -622.25
GaussianMLPPolicy/dLoss                  -0.0465698
GaussianMLPValueFunction/LossAfter    93932.3
GaussianMLPValueFunction/LossBefore   94076.8
GaussianMLPValueFunction/dLoss          144.484
TotalEnvSteps                        172800
-----------------------------------  ----------------
2022-08-17 17:55:40 | [trpo_pendulum] epoch #144 | Saving snapshot...
2022-08-17 17:55:40 | [trpo_pendulum] epoch #144 | Saved
2022-08-17 17:55:40 | [trpo_pendulum] epoch #144 | Time 60.67 s
2022-08-17 17:55:40 | [trpo_pendulum] epoch #144 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -451.395
Evaluation/AverageReturn              -1009.72
Evaluation/Iteration                    144
Evaluation/MaxReturn                   -862.02
Evaluation/MinReturn                  -1178.91
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     92.8485
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40628
GaussianMLPPolicy/KL                      3.3951e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -382.29
GaussianMLPPolicy/LossBefore           -382.38
GaussianMLPPolicy/dLoss                  -0.0909119
GaussianMLPValueFunction/LossAfter    36050.5
GaussianMLPValueFunction/LossBefore   36108
GaussianMLPValueFunction/dLoss           57.5234
TotalEnvSteps                        174000
-----------------------------------  ---------------
2022-08-17 17:55:41 | [trpo_pendulum] epoch #145 | Saving snapshot...
2022-08-17 17:55:41 | [trpo_pendulum] epoch #145 | Saved
2022-08-17 17:55:41 | [trpo_pendulum] epoch #145 | Time 61.09 s
2022-08-17 17:55:41 | [trpo_pendulum] epoch #145 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -410.651
Evaluation/AverageReturn               -942.089
Evaluation/Iteration                    145
Evaluation/MaxReturn                   -884.562
Evaluation/MinReturn                  -1028.52
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.8254
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40655
GaussianMLPPolicy/KL                      7.98734e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -369.523
GaussianMLPPolicy/LossBefore           -369.387
GaussianMLPPolicy/dLoss                   0.135376
GaussianMLPValueFunction/LossAfter    32638
GaussianMLPValueFunction/LossBefore   32695.8
GaussianMLPValueFunction/dLoss           57.7363
TotalEnvSteps                        175200
-----------------------------------  ----------------
2022-08-17 17:55:41 | [trpo_pendulum] epoch #146 | Saving snapshot...
2022-08-17 17:55:41 | [trpo_pendulum] epoch #146 | Saved
2022-08-17 17:55:41 | [trpo_pendulum] epoch #146 | Time 61.50 s
2022-08-17 17:55:41 | [trpo_pendulum] epoch #146 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -415.881
Evaluation/AverageReturn               -938.903
Evaluation/Iteration                    146
Evaluation/MaxReturn                   -777.394
Evaluation/MinReturn                  -1152.33
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    114.007
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40681
GaussianMLPPolicy/KL                      0.000127697
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -364.686
GaussianMLPPolicy/LossBefore           -364.568
GaussianMLPPolicy/dLoss                   0.117767
GaussianMLPValueFunction/LossAfter    31726
GaussianMLPValueFunction/LossBefore   31771.5
GaussianMLPValueFunction/dLoss           45.5078
TotalEnvSteps                        176400
-----------------------------------  ----------------
2022-08-17 17:55:42 | [trpo_pendulum] epoch #147 | Saving snapshot...
2022-08-17 17:55:42 | [trpo_pendulum] epoch #147 | Saved
2022-08-17 17:55:42 | [trpo_pendulum] epoch #147 | Time 61.90 s
2022-08-17 17:55:42 | [trpo_pendulum] epoch #147 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -414.241
Evaluation/AverageReturn               -955.452
Evaluation/Iteration                    147
Evaluation/MaxReturn                   -864.162
Evaluation/MinReturn                  -1101.92
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     78.0831
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40706
GaussianMLPPolicy/KL                      7.6423e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -379.751
GaussianMLPPolicy/LossBefore           -379.751
GaussianMLPPolicy/dLoss                  -0.000549316
GaussianMLPValueFunction/LossAfter    33099.7
GaussianMLPValueFunction/LossBefore   33147.2
GaussianMLPValueFunction/dLoss           47.5156
TotalEnvSteps                        177600
-----------------------------------  ----------------
2022-08-17 17:55:42 | [trpo_pendulum] epoch #148 | Saving snapshot...
2022-08-17 17:55:42 | [trpo_pendulum] epoch #148 | Saved
2022-08-17 17:55:42 | [trpo_pendulum] epoch #148 | Time 62.31 s
2022-08-17 17:55:42 | [trpo_pendulum] epoch #148 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -432.268
Evaluation/AverageReturn               -954.664
Evaluation/Iteration                    148
Evaluation/MaxReturn                   -856.989
Evaluation/MinReturn                  -1029.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     64.367
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40726
GaussianMLPPolicy/KL                      5.22028e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -368.952
GaussianMLPPolicy/LossBefore           -368.945
GaussianMLPPolicy/dLoss                   0.00692749
GaussianMLPValueFunction/LossAfter    31896.1
GaussianMLPValueFunction/LossBefore   31939.1
GaussianMLPValueFunction/dLoss           43.0098
TotalEnvSteps                        178800
-----------------------------------  ----------------
2022-08-17 17:55:42 | [trpo_pendulum] epoch #149 | Saving snapshot...
2022-08-17 17:55:42 | [trpo_pendulum] epoch #149 | Saved
2022-08-17 17:55:42 | [trpo_pendulum] epoch #149 | Time 62.71 s
2022-08-17 17:55:42 | [trpo_pendulum] epoch #149 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -724.933
Evaluation/AverageReturn              -1645.47
Evaluation/Iteration                    149
Evaluation/MaxReturn                  -1417.34
Evaluation/MinReturn                  -1843.13
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    129.781
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40745
GaussianMLPPolicy/KL                      1.25003e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -637.76
GaussianMLPPolicy/LossBefore           -637.776
GaussianMLPPolicy/dLoss                  -0.0162964
GaussianMLPValueFunction/LossAfter    94937
GaussianMLPValueFunction/LossBefore   95051.4
GaussianMLPValueFunction/dLoss          114.438
TotalEnvSteps                        180000
-----------------------------------  ----------------
2022-08-17 17:55:43 | [trpo_pendulum] epoch #150 | Saving snapshot...
2022-08-17 17:55:43 | [trpo_pendulum] epoch #150 | Saved
2022-08-17 17:55:43 | [trpo_pendulum] epoch #150 | Time 63.12 s
2022-08-17 17:55:43 | [trpo_pendulum] epoch #150 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -749.557
Evaluation/AverageReturn              -1699.97
Evaluation/Iteration                    150
Evaluation/MaxReturn                  -1543.67
Evaluation/MinReturn                  -1817.82
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     90.6224
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40778
GaussianMLPPolicy/KL                      8.14465e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -643.307
GaussianMLPPolicy/LossBefore           -643.27
GaussianMLPPolicy/dLoss                   0.036499
GaussianMLPValueFunction/LossAfter   100096
GaussianMLPValueFunction/LossBefore  100222
GaussianMLPValueFunction/dLoss          126.039
TotalEnvSteps                        181200
-----------------------------------  ----------------
2022-08-17 17:55:43 | [trpo_pendulum] epoch #151 | Saving snapshot...
2022-08-17 17:55:43 | [trpo_pendulum] epoch #151 | Saved
2022-08-17 17:55:43 | [trpo_pendulum] epoch #151 | Time 63.52 s
2022-08-17 17:55:43 | [trpo_pendulum] epoch #151 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -466.512
Evaluation/AverageReturn              -1062.54
Evaluation/Iteration                    151
Evaluation/MaxReturn                   -994.103
Evaluation/MinReturn                  -1215.18
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     79.388
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40807
GaussianMLPPolicy/KL                      0.000673989
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -417.025
GaussianMLPPolicy/LossBefore           -415.479
GaussianMLPPolicy/dLoss                   1.54596
GaussianMLPValueFunction/LossAfter    40396.9
GaussianMLPValueFunction/LossBefore   40452.3
GaussianMLPValueFunction/dLoss           55.3984
TotalEnvSteps                        182400
-----------------------------------  ----------------
2022-08-17 17:55:44 | [trpo_pendulum] epoch #152 | Saving snapshot...
2022-08-17 17:55:44 | [trpo_pendulum] epoch #152 | Saved
2022-08-17 17:55:44 | [trpo_pendulum] epoch #152 | Time 63.93 s
2022-08-17 17:55:44 | [trpo_pendulum] epoch #152 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -736.938
Evaluation/AverageReturn              -1649.8
Evaluation/Iteration                    152
Evaluation/MaxReturn                  -1523.61
Evaluation/MinReturn                  -1802.92
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     92.7948
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40846
GaussianMLPPolicy/KL                      0.00012284
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -621.073
GaussianMLPPolicy/LossBefore           -621.121
GaussianMLPPolicy/dLoss                  -0.0480347
GaussianMLPValueFunction/LossAfter    92682.1
GaussianMLPValueFunction/LossBefore   92799.2
GaussianMLPValueFunction/dLoss          117.078
TotalEnvSteps                        183600
-----------------------------------  ---------------
2022-08-17 17:55:44 | [trpo_pendulum] epoch #153 | Saving snapshot...
2022-08-17 17:55:44 | [trpo_pendulum] epoch #153 | Saved
2022-08-17 17:55:44 | [trpo_pendulum] epoch #153 | Time 64.34 s
2022-08-17 17:55:44 | [trpo_pendulum] epoch #153 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -524.182
Evaluation/AverageReturn              -1163.7
Evaluation/Iteration                    153
Evaluation/MaxReturn                   -989.644
Evaluation/MinReturn                  -1363.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    117.949
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40882
GaussianMLPPolicy/KL                      0.000509098
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -443.714
GaussianMLPPolicy/LossBefore           -443.25
GaussianMLPPolicy/dLoss                   0.463837
GaussianMLPValueFunction/LossAfter    46428.8
GaussianMLPValueFunction/LossBefore   46493.4
GaussianMLPValueFunction/dLoss           64.5703
TotalEnvSteps                        184800
-----------------------------------  ----------------
2022-08-17 17:55:44 | [trpo_pendulum] epoch #154 | Saving snapshot...
2022-08-17 17:55:44 | [trpo_pendulum] epoch #154 | Saved
2022-08-17 17:55:44 | [trpo_pendulum] epoch #154 | Time 64.77 s
2022-08-17 17:55:44 | [trpo_pendulum] epoch #154 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -735.631
Evaluation/AverageReturn              -1658.07
Evaluation/Iteration                    154
Evaluation/MaxReturn                  -1417.83
Evaluation/MinReturn                  -1791.21
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    127.737
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40917
GaussianMLPPolicy/KL                      0.000191602
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -637.792
GaussianMLPPolicy/LossBefore           -637.376
GaussianMLPPolicy/dLoss                   0.416504
GaussianMLPValueFunction/LossAfter    94494.5
GaussianMLPValueFunction/LossBefore   94614.8
GaussianMLPValueFunction/dLoss          120.305
TotalEnvSteps                        186000
-----------------------------------  ----------------
2022-08-17 17:55:45 | [trpo_pendulum] epoch #155 | Saving snapshot...
2022-08-17 17:55:45 | [trpo_pendulum] epoch #155 | Saved
2022-08-17 17:55:45 | [trpo_pendulum] epoch #155 | Time 65.17 s
2022-08-17 17:55:45 | [trpo_pendulum] epoch #155 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -672.615
Evaluation/AverageReturn              -1475.22
Evaluation/Iteration                    155
Evaluation/MaxReturn                  -1213.05
Evaluation/MinReturn                  -1594.01
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    137.15
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4094
GaussianMLPPolicy/KL                      0.000312511
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -566.057
GaussianMLPPolicy/LossBefore           -565.954
GaussianMLPPolicy/dLoss                   0.103455
GaussianMLPValueFunction/LossAfter    73506.4
GaussianMLPValueFunction/LossBefore   73602.8
GaussianMLPValueFunction/dLoss           96.4062
TotalEnvSteps                        187200
-----------------------------------  ----------------
2022-08-17 17:55:45 | [trpo_pendulum] epoch #156 | Saving snapshot...
2022-08-17 17:55:45 | [trpo_pendulum] epoch #156 | Saved
2022-08-17 17:55:45 | [trpo_pendulum] epoch #156 | Time 65.57 s
2022-08-17 17:55:45 | [trpo_pendulum] epoch #156 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -462.243
Evaluation/AverageReturn              -1091.53
Evaluation/Iteration                    156
Evaluation/MaxReturn                   -863.403
Evaluation/MinReturn                  -1165.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    106.188
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40957
GaussianMLPPolicy/KL                      0.00013171
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -446.389
GaussianMLPPolicy/LossBefore           -446.613
GaussianMLPPolicy/dLoss                  -0.22406
GaussianMLPValueFunction/LossAfter    44106.2
GaussianMLPValueFunction/LossBefore   44168.8
GaussianMLPValueFunction/dLoss           62.6055
TotalEnvSteps                        188400
-----------------------------------  ---------------
2022-08-17 17:55:46 | [trpo_pendulum] epoch #157 | Saving snapshot...
2022-08-17 17:55:46 | [trpo_pendulum] epoch #157 | Saved
2022-08-17 17:55:46 | [trpo_pendulum] epoch #157 | Time 65.97 s
2022-08-17 17:55:46 | [trpo_pendulum] epoch #157 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -509.795
Evaluation/AverageReturn              -1141.02
Evaluation/Iteration                    157
Evaluation/MaxReturn                  -1036.69
Evaluation/MinReturn                  -1210.28
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     58.2045
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40967
GaussianMLPPolicy/KL                      0.000213364
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -446.746
GaussianMLPPolicy/LossBefore           -446.508
GaussianMLPPolicy/dLoss                   0.237762
GaussianMLPValueFunction/LossAfter    43456.9
GaussianMLPValueFunction/LossBefore   43515.4
GaussianMLPValueFunction/dLoss           58.543
TotalEnvSteps                        189600
-----------------------------------  ----------------
2022-08-17 17:55:46 | [trpo_pendulum] epoch #158 | Saving snapshot...
2022-08-17 17:55:46 | [trpo_pendulum] epoch #158 | Saved
2022-08-17 17:55:46 | [trpo_pendulum] epoch #158 | Time 66.38 s
2022-08-17 17:55:46 | [trpo_pendulum] epoch #158 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -673.097
Evaluation/AverageReturn              -1457.82
Evaluation/Iteration                    158
Evaluation/MaxReturn                  -1258.16
Evaluation/MinReturn                  -1590.96
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    115.322
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40983
GaussianMLPPolicy/KL                      0.000125509
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -537.5
GaussianMLPPolicy/LossBefore           -537.392
GaussianMLPPolicy/dLoss                   0.108337
GaussianMLPValueFunction/LossAfter    70464
GaussianMLPValueFunction/LossBefore   70551.3
GaussianMLPValueFunction/dLoss           87.2812
TotalEnvSteps                        190800
-----------------------------------  ----------------
2022-08-17 17:55:46 | [trpo_pendulum] epoch #159 | Saving snapshot...
2022-08-17 17:55:46 | [trpo_pendulum] epoch #159 | Saved
2022-08-17 17:55:46 | [trpo_pendulum] epoch #159 | Time 66.79 s
2022-08-17 17:55:46 | [trpo_pendulum] epoch #159 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -447.452
Evaluation/AverageReturn              -1035.82
Evaluation/Iteration                    159
Evaluation/MaxReturn                   -880.994
Evaluation/MinReturn                  -1158.62
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    104.787
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40998
GaussianMLPPolicy/KL                      0.00028113
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -413.161
GaussianMLPPolicy/LossBefore           -412.967
GaussianMLPPolicy/dLoss                   0.193726
GaussianMLPValueFunction/LossAfter    39013
GaussianMLPValueFunction/LossBefore   39067.2
GaussianMLPValueFunction/dLoss           54.2422
TotalEnvSteps                        192000
-----------------------------------  ---------------
2022-08-17 17:55:47 | [trpo_pendulum] epoch #160 | Saving snapshot...
2022-08-17 17:55:47 | [trpo_pendulum] epoch #160 | Saved
2022-08-17 17:55:47 | [trpo_pendulum] epoch #160 | Time 67.20 s
2022-08-17 17:55:47 | [trpo_pendulum] epoch #160 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -493.384
Evaluation/AverageReturn              -1155.49
Evaluation/Iteration                    160
Evaluation/MaxReturn                  -1117.71
Evaluation/MinReturn                  -1204.47
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     26.038
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4102
GaussianMLPPolicy/KL                      2.51652e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -457.389
GaussianMLPPolicy/LossBefore           -457.403
GaussianMLPPolicy/dLoss                  -0.0141602
GaussianMLPValueFunction/LossAfter    47752.7
GaussianMLPValueFunction/LossBefore   47827.9
GaussianMLPValueFunction/dLoss           75.2852
TotalEnvSteps                        193200
-----------------------------------  ----------------
2022-08-17 17:55:47 | [trpo_pendulum] epoch #161 | Saving snapshot...
2022-08-17 17:55:47 | [trpo_pendulum] epoch #161 | Saved
2022-08-17 17:55:47 | [trpo_pendulum] epoch #161 | Time 67.60 s
2022-08-17 17:55:47 | [trpo_pendulum] epoch #161 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -620.849
Evaluation/AverageReturn              -1330.47
Evaluation/Iteration                    161
Evaluation/MaxReturn                  -1211.61
Evaluation/MinReturn                  -1391.9
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     58.6126
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41037
GaussianMLPPolicy/KL                      5.76056e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -495.613
GaussianMLPPolicy/LossBefore           -495.553
GaussianMLPPolicy/dLoss                   0.0605164
GaussianMLPValueFunction/LossAfter    56675.3
GaussianMLPValueFunction/LossBefore   56743
GaussianMLPValueFunction/dLoss           67.6211
TotalEnvSteps                        194400
-----------------------------------  ----------------
2022-08-17 17:55:48 | [trpo_pendulum] epoch #162 | Saving snapshot...
2022-08-17 17:55:48 | [trpo_pendulum] epoch #162 | Saved
2022-08-17 17:55:48 | [trpo_pendulum] epoch #162 | Time 68.00 s
2022-08-17 17:55:48 | [trpo_pendulum] epoch #162 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -592.645
Evaluation/AverageReturn              -1285.76
Evaluation/Iteration                    162
Evaluation/MaxReturn                  -1197.72
Evaluation/MinReturn                  -1421.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     78.8307
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41059
GaussianMLPPolicy/KL                      3.36852e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -474.146
GaussianMLPPolicy/LossBefore           -474.142
GaussianMLPPolicy/dLoss                   0.0038147
GaussianMLPValueFunction/LossAfter    53783.2
GaussianMLPValueFunction/LossBefore   53851.7
GaussianMLPValueFunction/dLoss           68.5156
TotalEnvSteps                        195600
-----------------------------------  ----------------
2022-08-17 17:55:48 | [trpo_pendulum] epoch #163 | Saving snapshot...
2022-08-17 17:55:48 | [trpo_pendulum] epoch #163 | Saved
2022-08-17 17:55:48 | [trpo_pendulum] epoch #163 | Time 68.40 s
2022-08-17 17:55:48 | [trpo_pendulum] epoch #163 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -476.396
Evaluation/AverageReturn              -1159.16
Evaluation/Iteration                    163
Evaluation/MaxReturn                  -1102.61
Evaluation/MinReturn                  -1230.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     40.2201
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41067
GaussianMLPPolicy/KL                      3.00635e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -493.455
GaussianMLPPolicy/LossBefore           -493.42
GaussianMLPPolicy/dLoss                   0.034668
GaussianMLPValueFunction/LossAfter    51016.9
GaussianMLPValueFunction/LossBefore   51100.4
GaussianMLPValueFunction/dLoss           83.5078
TotalEnvSteps                        196800
-----------------------------------  ----------------
2022-08-17 17:55:48 | [trpo_pendulum] epoch #164 | Saving snapshot...
2022-08-17 17:55:48 | [trpo_pendulum] epoch #164 | Saved
2022-08-17 17:55:48 | [trpo_pendulum] epoch #164 | Time 68.81 s
2022-08-17 17:55:48 | [trpo_pendulum] epoch #164 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -444.784
Evaluation/AverageReturn              -1107.49
Evaluation/Iteration                    164
Evaluation/MaxReturn                  -1038.21
Evaluation/MinReturn                  -1186.7
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     57.9274
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4107
GaussianMLPPolicy/KL                      4.59347e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -471.529
GaussianMLPPolicy/LossBefore           -471.402
GaussianMLPPolicy/dLoss                   0.127197
GaussianMLPValueFunction/LossAfter    47977.1
GaussianMLPValueFunction/LossBefore   48027.5
GaussianMLPValueFunction/dLoss           50.3516
TotalEnvSteps                        198000
-----------------------------------  ----------------
2022-08-17 17:55:49 | [trpo_pendulum] epoch #165 | Saving snapshot...
2022-08-17 17:55:49 | [trpo_pendulum] epoch #165 | Saved
2022-08-17 17:55:49 | [trpo_pendulum] epoch #165 | Time 69.20 s
2022-08-17 17:55:49 | [trpo_pendulum] epoch #165 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -463.415
Evaluation/AverageReturn              -1107.93
Evaluation/Iteration                    165
Evaluation/MaxReturn                  -1011.9
Evaluation/MinReturn                  -1171.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     62.4981
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41072
GaussianMLPPolicy/KL                      0.00028487
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -453.509
GaussianMLPPolicy/LossBefore           -453.026
GaussianMLPPolicy/dLoss                   0.483154
GaussianMLPValueFunction/LossAfter    45071
GaussianMLPValueFunction/LossBefore   45132.7
GaussianMLPValueFunction/dLoss           61.7617
TotalEnvSteps                        199200
-----------------------------------  ---------------
2022-08-17 17:55:49 | [trpo_pendulum] epoch #166 | Saving snapshot...
2022-08-17 17:55:49 | [trpo_pendulum] epoch #166 | Saved
2022-08-17 17:55:49 | [trpo_pendulum] epoch #166 | Time 69.62 s
2022-08-17 17:55:49 | [trpo_pendulum] epoch #166 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -589.728
Evaluation/AverageReturn              -1248.07
Evaluation/Iteration                    166
Evaluation/MaxReturn                  -1174.48
Evaluation/MinReturn                  -1363.7
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     61.9967
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41078
GaussianMLPPolicy/KL                      6.83046e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -455.074
GaussianMLPPolicy/LossBefore           -455.072
GaussianMLPPolicy/dLoss                   0.00161743
GaussianMLPValueFunction/LossAfter    48955.7
GaussianMLPValueFunction/LossBefore   49010.2
GaussianMLPValueFunction/dLoss           54.4609
TotalEnvSteps                        200400
-----------------------------------  ----------------
2022-08-17 17:55:50 | [trpo_pendulum] epoch #167 | Saving snapshot...
2022-08-17 17:55:50 | [trpo_pendulum] epoch #167 | Saved
2022-08-17 17:55:50 | [trpo_pendulum] epoch #167 | Time 70.02 s
2022-08-17 17:55:50 | [trpo_pendulum] epoch #167 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -471.5
Evaluation/AverageReturn              -1092.27
Evaluation/Iteration                    167
Evaluation/MaxReturn                   -896.831
Evaluation/MinReturn                  -1201.31
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    104.125
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41076
GaussianMLPPolicy/KL                      2.98527e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -444.548
GaussianMLPPolicy/LossBefore           -444.547
GaussianMLPPolicy/dLoss                   0.000823975
GaussianMLPValueFunction/LossAfter    43487.4
GaussianMLPValueFunction/LossBefore   43539.8
GaussianMLPValueFunction/dLoss           52.4062
TotalEnvSteps                        201600
-----------------------------------  ----------------
2022-08-17 17:55:50 | [trpo_pendulum] epoch #168 | Saving snapshot...
2022-08-17 17:55:50 | [trpo_pendulum] epoch #168 | Saved
2022-08-17 17:55:50 | [trpo_pendulum] epoch #168 | Time 70.44 s
2022-08-17 17:55:50 | [trpo_pendulum] epoch #168 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -462.778
Evaluation/AverageReturn              -1119.25
Evaluation/Iteration                    168
Evaluation/MaxReturn                  -1014.94
Evaluation/MinReturn                  -1260.93
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     90.3912
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41081
GaussianMLPPolicy/KL                      2.16937e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -455.135
GaussianMLPPolicy/LossBefore           -455.093
GaussianMLPPolicy/dLoss                   0.0418701
GaussianMLPValueFunction/LossAfter    47364.3
GaussianMLPValueFunction/LossBefore   47429.5
GaussianMLPValueFunction/dLoss           65.2656
TotalEnvSteps                        202800
-----------------------------------  ----------------
2022-08-17 17:55:50 | [trpo_pendulum] epoch #169 | Saving snapshot...
2022-08-17 17:55:50 | [trpo_pendulum] epoch #169 | Saved
2022-08-17 17:55:50 | [trpo_pendulum] epoch #169 | Time 70.83 s
2022-08-17 17:55:50 | [trpo_pendulum] epoch #169 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -489.821
Evaluation/AverageReturn              -1150.77
Evaluation/Iteration                    169
Evaluation/MaxReturn                  -1044.21
Evaluation/MinReturn                  -1215.21
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     74.3124
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41088
GaussianMLPPolicy/KL                      6.93893e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -464.801
GaussianMLPPolicy/LossBefore           -464.8
GaussianMLPPolicy/dLoss                   0.00109863
GaussianMLPValueFunction/LossAfter    49229
GaussianMLPValueFunction/LossBefore   49334.7
GaussianMLPValueFunction/dLoss          105.754
TotalEnvSteps                        204000
-----------------------------------  ----------------
2022-08-17 17:55:51 | [trpo_pendulum] epoch #170 | Saving snapshot...
2022-08-17 17:55:51 | [trpo_pendulum] epoch #170 | Saved
2022-08-17 17:55:51 | [trpo_pendulum] epoch #170 | Time 71.24 s
2022-08-17 17:55:51 | [trpo_pendulum] epoch #170 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -451.136
Evaluation/AverageReturn              -1063.35
Evaluation/Iteration                    170
Evaluation/MaxReturn                  -1001
Evaluation/MinReturn                  -1133.23
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.6432
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41096
GaussianMLPPolicy/KL                      5.39809e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -428.878
GaussianMLPPolicy/LossBefore           -428.69
GaussianMLPPolicy/dLoss                   0.18808
GaussianMLPValueFunction/LossAfter    40112.2
GaussianMLPValueFunction/LossBefore   40173.3
GaussianMLPValueFunction/dLoss           61.0703
TotalEnvSteps                        205200
-----------------------------------  ----------------
2022-08-17 17:55:51 | [trpo_pendulum] epoch #171 | Saving snapshot...
2022-08-17 17:55:51 | [trpo_pendulum] epoch #171 | Saved
2022-08-17 17:55:51 | [trpo_pendulum] epoch #171 | Time 71.64 s
2022-08-17 17:55:51 | [trpo_pendulum] epoch #171 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -606.331
Evaluation/AverageReturn              -1309.81
Evaluation/Iteration                    171
Evaluation/MaxReturn                  -1234.61
Evaluation/MinReturn                  -1510.52
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     92.6464
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41104
GaussianMLPPolicy/KL                      6.66028e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -487.773
GaussianMLPPolicy/LossBefore           -487.666
GaussianMLPPolicy/dLoss                   0.106995
GaussianMLPValueFunction/LossAfter    55690.4
GaussianMLPValueFunction/LossBefore   55745.8
GaussianMLPValueFunction/dLoss           55.3633
TotalEnvSteps                        206400
-----------------------------------  ----------------
2022-08-17 17:55:52 | [trpo_pendulum] epoch #172 | Saving snapshot...
2022-08-17 17:55:52 | [trpo_pendulum] epoch #172 | Saved
2022-08-17 17:55:52 | [trpo_pendulum] epoch #172 | Time 72.04 s
2022-08-17 17:55:52 | [trpo_pendulum] epoch #172 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -537.58
Evaluation/AverageReturn              -1193.32
Evaluation/Iteration                    172
Evaluation/MaxReturn                  -1077.37
Evaluation/MinReturn                  -1255.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     60.1887
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4112
GaussianMLPPolicy/KL                      8.80097e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -448.865
GaussianMLPPolicy/LossBefore           -448.821
GaussianMLPPolicy/dLoss                   0.04422
GaussianMLPValueFunction/LossAfter    46589.7
GaussianMLPValueFunction/LossBefore   46653.7
GaussianMLPValueFunction/dLoss           63.9961
TotalEnvSteps                        207600
-----------------------------------  ----------------
2022-08-17 17:55:52 | [trpo_pendulum] epoch #173 | Saving snapshot...
2022-08-17 17:55:52 | [trpo_pendulum] epoch #173 | Saved
2022-08-17 17:55:52 | [trpo_pendulum] epoch #173 | Time 72.46 s
2022-08-17 17:55:52 | [trpo_pendulum] epoch #173 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -486.417
Evaluation/AverageReturn              -1132.64
Evaluation/Iteration                    173
Evaluation/MaxReturn                  -1087.93
Evaluation/MinReturn                  -1160.8
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     25.1141
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41146
GaussianMLPPolicy/KL                      0.000101444
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -441.986
GaussianMLPPolicy/LossBefore           -441.916
GaussianMLPPolicy/dLoss                   0.0693359
GaussianMLPValueFunction/LossAfter    45119.4
GaussianMLPValueFunction/LossBefore   45181.9
GaussianMLPValueFunction/dLoss           62.5273
TotalEnvSteps                        208800
-----------------------------------  ----------------
2022-08-17 17:55:52 | [trpo_pendulum] epoch #174 | Saving snapshot...
2022-08-17 17:55:53 | [trpo_pendulum] epoch #174 | Saved
2022-08-17 17:55:53 | [trpo_pendulum] epoch #174 | Time 72.86 s
2022-08-17 17:55:53 | [trpo_pendulum] epoch #174 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -490.315
Evaluation/AverageReturn              -1163.09
Evaluation/Iteration                    174
Evaluation/MaxReturn                  -1092.26
Evaluation/MinReturn                  -1215.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     37.4771
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41165
GaussianMLPPolicy/KL                      0.000169081
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -476.781
GaussianMLPPolicy/LossBefore           -476.627
GaussianMLPPolicy/dLoss                   0.153748
GaussianMLPValueFunction/LossAfter    49251.9
GaussianMLPValueFunction/LossBefore   49321.3
GaussianMLPValueFunction/dLoss           69.418
TotalEnvSteps                        210000
-----------------------------------  ----------------
2022-08-17 17:55:53 | [trpo_pendulum] epoch #175 | Saving snapshot...
2022-08-17 17:55:53 | [trpo_pendulum] epoch #175 | Saved
2022-08-17 17:55:53 | [trpo_pendulum] epoch #175 | Time 73.27 s
2022-08-17 17:55:53 | [trpo_pendulum] epoch #175 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -492.337
Evaluation/AverageReturn              -1178.04
Evaluation/Iteration                    175
Evaluation/MaxReturn                  -1106.05
Evaluation/MinReturn                  -1215.74
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     34.9252
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41176
GaussianMLPPolicy/KL                      3.31398e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -489.877
GaussianMLPPolicy/LossBefore           -489.828
GaussianMLPPolicy/dLoss                   0.0484009
GaussianMLPValueFunction/LossAfter    51864.4
GaussianMLPValueFunction/LossBefore   51917.5
GaussianMLPValueFunction/dLoss           53.0898
TotalEnvSteps                        211200
-----------------------------------  ----------------
2022-08-17 17:55:53 | [trpo_pendulum] epoch #176 | Saving snapshot...
2022-08-17 17:55:53 | [trpo_pendulum] epoch #176 | Saved
2022-08-17 17:55:53 | [trpo_pendulum] epoch #176 | Time 73.69 s
2022-08-17 17:55:53 | [trpo_pendulum] epoch #176 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -447.324
Evaluation/AverageReturn              -1102.32
Evaluation/Iteration                    176
Evaluation/MaxReturn                  -1043.08
Evaluation/MinReturn                  -1171.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     56.7435
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41195
GaussianMLPPolicy/KL                      3.28021e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -453.649
GaussianMLPPolicy/LossBefore           -453.524
GaussianMLPPolicy/dLoss                   0.124268
GaussianMLPValueFunction/LossAfter    47397.5
GaussianMLPValueFunction/LossBefore   47471.2
GaussianMLPValueFunction/dLoss           73.7227
TotalEnvSteps                        212400
-----------------------------------  ----------------
2022-08-17 17:55:54 | [trpo_pendulum] epoch #177 | Saving snapshot...
2022-08-17 17:55:54 | [trpo_pendulum] epoch #177 | Saved
2022-08-17 17:55:54 | [trpo_pendulum] epoch #177 | Time 74.09 s
2022-08-17 17:55:54 | [trpo_pendulum] epoch #177 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -480.915
Evaluation/AverageReturn              -1167.58
Evaluation/Iteration                    177
Evaluation/MaxReturn                  -1107.21
Evaluation/MinReturn                  -1201.13
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     32.5039
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41196
GaussianMLPPolicy/KL                      0.000304421
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -500.238
GaussianMLPPolicy/LossBefore           -499.726
GaussianMLPPolicy/dLoss                   0.511841
GaussianMLPValueFunction/LossAfter    51617.1
GaussianMLPValueFunction/LossBefore   51718.7
GaussianMLPValueFunction/dLoss          101.652
TotalEnvSteps                        213600
-----------------------------------  ----------------
2022-08-17 17:55:54 | [trpo_pendulum] epoch #178 | Saving snapshot...
2022-08-17 17:55:54 | [trpo_pendulum] epoch #178 | Saved
2022-08-17 17:55:54 | [trpo_pendulum] epoch #178 | Time 74.49 s
2022-08-17 17:55:54 | [trpo_pendulum] epoch #178 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -509.182
Evaluation/AverageReturn              -1214.55
Evaluation/Iteration                    178
Evaluation/MaxReturn                  -1182.55
Evaluation/MinReturn                  -1330.33
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     52.0365
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.412
GaussianMLPPolicy/KL                      0.000245718
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -492.781
GaussianMLPPolicy/LossBefore           -492.726
GaussianMLPPolicy/dLoss                   0.0552979
GaussianMLPValueFunction/LossAfter    54667.2
GaussianMLPValueFunction/LossBefore   54726.9
GaussianMLPValueFunction/dLoss           59.6562
TotalEnvSteps                        214800
-----------------------------------  ----------------
2022-08-17 17:55:55 | [trpo_pendulum] epoch #179 | Saving snapshot...
2022-08-17 17:55:55 | [trpo_pendulum] epoch #179 | Saved
2022-08-17 17:55:55 | [trpo_pendulum] epoch #179 | Time 74.90 s
2022-08-17 17:55:55 | [trpo_pendulum] epoch #179 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -523.842
Evaluation/AverageReturn              -1206.97
Evaluation/Iteration                    179
Evaluation/MaxReturn                  -1176.71
Evaluation/MinReturn                  -1306.74
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     45.2072
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41207
GaussianMLPPolicy/KL                      8.81827e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -477.022
GaussianMLPPolicy/LossBefore           -477.053
GaussianMLPPolicy/dLoss                  -0.0310364
GaussianMLPValueFunction/LossAfter    51123.8
GaussianMLPValueFunction/LossBefore   51208.5
GaussianMLPValueFunction/dLoss           84.6797
TotalEnvSteps                        216000
-----------------------------------  ----------------
2022-08-17 17:55:55 | [trpo_pendulum] epoch #180 | Saving snapshot...
2022-08-17 17:55:55 | [trpo_pendulum] epoch #180 | Saved
2022-08-17 17:55:55 | [trpo_pendulum] epoch #180 | Time 75.30 s
2022-08-17 17:55:55 | [trpo_pendulum] epoch #180 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -513.496
Evaluation/AverageReturn              -1200.5
Evaluation/Iteration                    180
Evaluation/MaxReturn                  -1149.36
Evaluation/MinReturn                  -1275.12
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     51.8034
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4124
GaussianMLPPolicy/KL                      2.07266e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -455.009
GaussianMLPPolicy/LossBefore           -455.012
GaussianMLPPolicy/dLoss                  -0.00314331
GaussianMLPValueFunction/LossAfter    49945.4
GaussianMLPValueFunction/LossBefore   50010.5
GaussianMLPValueFunction/dLoss           65.1484
TotalEnvSteps                        217200
-----------------------------------  ----------------
2022-08-17 17:55:55 | [trpo_pendulum] epoch #181 | Saving snapshot...
2022-08-17 17:55:55 | [trpo_pendulum] epoch #181 | Saved
2022-08-17 17:55:55 | [trpo_pendulum] epoch #181 | Time 75.71 s
2022-08-17 17:55:55 | [trpo_pendulum] epoch #181 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -509.26
Evaluation/AverageReturn              -1212.58
Evaluation/Iteration                    181
Evaluation/MaxReturn                  -1162.21
Evaluation/MinReturn                  -1315.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.2957
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41271
GaussianMLPPolicy/KL                      2.79995e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -492.204
GaussianMLPPolicy/LossBefore           -492.119
GaussianMLPPolicy/dLoss                   0.0843201
GaussianMLPValueFunction/LossAfter    53852.6
GaussianMLPValueFunction/LossBefore   53934.4
GaussianMLPValueFunction/dLoss           81.8008
TotalEnvSteps                        218400
-----------------------------------  ----------------
2022-08-17 17:55:56 | [trpo_pendulum] epoch #182 | Saving snapshot...
2022-08-17 17:55:56 | [trpo_pendulum] epoch #182 | Saved
2022-08-17 17:55:56 | [trpo_pendulum] epoch #182 | Time 76.11 s
2022-08-17 17:55:56 | [trpo_pendulum] epoch #182 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -523.696
Evaluation/AverageReturn              -1217.39
Evaluation/Iteration                    182
Evaluation/MaxReturn                  -1113.19
Evaluation/MinReturn                  -1269.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.9497
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41295
GaussianMLPPolicy/KL                      1.68521e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -489.695
GaussianMLPPolicy/LossBefore           -489.676
GaussianMLPPolicy/dLoss                   0.0187988
GaussianMLPValueFunction/LossAfter    50134.8
GaussianMLPValueFunction/LossBefore   50197.5
GaussianMLPValueFunction/dLoss           62.6602
TotalEnvSteps                        219600
-----------------------------------  ----------------
2022-08-17 17:55:56 | [trpo_pendulum] epoch #183 | Saving snapshot...
2022-08-17 17:55:56 | [trpo_pendulum] epoch #183 | Saved
2022-08-17 17:55:56 | [trpo_pendulum] epoch #183 | Time 76.52 s
2022-08-17 17:55:56 | [trpo_pendulum] epoch #183 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -590.882
Evaluation/AverageReturn              -1290.58
Evaluation/Iteration                    183
Evaluation/MaxReturn                  -1238.06
Evaluation/MinReturn                  -1371.19
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     41.0486
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41316
GaussianMLPPolicy/KL                      7.08554e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -488.081
GaussianMLPPolicy/LossBefore           -487.945
GaussianMLPPolicy/dLoss                   0.136078
GaussianMLPValueFunction/LossAfter    52867.7
GaussianMLPValueFunction/LossBefore   52921.6
GaussianMLPValueFunction/dLoss           53.9297
TotalEnvSteps                        220800
-----------------------------------  ----------------
2022-08-17 17:55:57 | [trpo_pendulum] epoch #184 | Saving snapshot...
2022-08-17 17:55:57 | [trpo_pendulum] epoch #184 | Saved
2022-08-17 17:55:57 | [trpo_pendulum] epoch #184 | Time 76.93 s
2022-08-17 17:55:57 | [trpo_pendulum] epoch #184 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -534.908
Evaluation/AverageReturn              -1210.12
Evaluation/Iteration                    184
Evaluation/MaxReturn                  -1096.84
Evaluation/MinReturn                  -1281
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     56.365
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41344
GaussianMLPPolicy/KL                      3.86852e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -463.268
GaussianMLPPolicy/LossBefore           -463.274
GaussianMLPPolicy/dLoss                  -0.00582886
GaussianMLPValueFunction/LossAfter    47836.6
GaussianMLPValueFunction/LossBefore   47892.7
GaussianMLPValueFunction/dLoss           56.0664
TotalEnvSteps                        222000
-----------------------------------  ----------------
2022-08-17 17:55:57 | [trpo_pendulum] epoch #185 | Saving snapshot...
2022-08-17 17:55:57 | [trpo_pendulum] epoch #185 | Saved
2022-08-17 17:55:57 | [trpo_pendulum] epoch #185 | Time 77.34 s
2022-08-17 17:55:57 | [trpo_pendulum] epoch #185 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -652.049
Evaluation/AverageReturn              -1373.73
Evaluation/Iteration                    185
Evaluation/MaxReturn                  -1210.44
Evaluation/MinReturn                  -1612.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    119.292
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41378
GaussianMLPPolicy/KL                      1.07596e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -491.804
GaussianMLPPolicy/LossBefore           -491.624
GaussianMLPPolicy/dLoss                   0.180054
GaussianMLPValueFunction/LossAfter    58839.2
GaussianMLPValueFunction/LossBefore   58899.8
GaussianMLPValueFunction/dLoss           60.6328
TotalEnvSteps                        223200
-----------------------------------  ----------------
2022-08-17 17:55:57 | [trpo_pendulum] epoch #186 | Saving snapshot...
2022-08-17 17:55:57 | [trpo_pendulum] epoch #186 | Saved
2022-08-17 17:55:57 | [trpo_pendulum] epoch #186 | Time 77.74 s
2022-08-17 17:55:57 | [trpo_pendulum] epoch #186 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -498.914
Evaluation/AverageReturn              -1188.46
Evaluation/Iteration                    186
Evaluation/MaxReturn                  -1164.43
Evaluation/MinReturn                  -1205.67
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     16.6354
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41419
GaussianMLPPolicy/KL                      0.000144907
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -476.595
GaussianMLPPolicy/LossBefore           -476.292
GaussianMLPPolicy/dLoss                   0.302246
GaussianMLPValueFunction/LossAfter    51441.6
GaussianMLPValueFunction/LossBefore   51512.4
GaussianMLPValueFunction/dLoss           70.8242
TotalEnvSteps                        224400
-----------------------------------  ----------------
2022-08-17 17:55:58 | [trpo_pendulum] epoch #187 | Saving snapshot...
2022-08-17 17:55:58 | [trpo_pendulum] epoch #187 | Saved
2022-08-17 17:55:58 | [trpo_pendulum] epoch #187 | Time 78.15 s
2022-08-17 17:55:58 | [trpo_pendulum] epoch #187 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -692.588
Evaluation/AverageReturn              -1475.76
Evaluation/Iteration                    187
Evaluation/MaxReturn                  -1240.13
Evaluation/MinReturn                  -1707.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    167.278
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41454
GaussianMLPPolicy/KL                      2.78368e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -545.877
GaussianMLPPolicy/LossBefore           -545.914
GaussianMLPPolicy/dLoss                  -0.0368042
GaussianMLPValueFunction/LossAfter    69218.3
GaussianMLPValueFunction/LossBefore   69291.1
GaussianMLPValueFunction/dLoss           72.8438
TotalEnvSteps                        225600
-----------------------------------  ----------------
2022-08-17 17:55:58 | [trpo_pendulum] epoch #188 | Saving snapshot...
2022-08-17 17:55:58 | [trpo_pendulum] epoch #188 | Saved
2022-08-17 17:55:58 | [trpo_pendulum] epoch #188 | Time 78.56 s
2022-08-17 17:55:58 | [trpo_pendulum] epoch #188 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -512.809
Evaluation/AverageReturn              -1226.07
Evaluation/Iteration                    188
Evaluation/MaxReturn                  -1184.23
Evaluation/MinReturn                  -1276.17
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     28.1105
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41489
GaussianMLPPolicy/KL                      9.10447e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -497.643
GaussianMLPPolicy/LossBefore           -497.628
GaussianMLPPolicy/dLoss                   0.0145874
GaussianMLPValueFunction/LossAfter    54832.8
GaussianMLPValueFunction/LossBefore   54918.6
GaussianMLPValueFunction/dLoss           85.7969
TotalEnvSteps                        226800
-----------------------------------  ----------------
2022-08-17 17:55:59 | [trpo_pendulum] epoch #189 | Saving snapshot...
2022-08-17 17:55:59 | [trpo_pendulum] epoch #189 | Saved
2022-08-17 17:55:59 | [trpo_pendulum] epoch #189 | Time 78.97 s
2022-08-17 17:55:59 | [trpo_pendulum] epoch #189 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -498.216
Evaluation/AverageReturn              -1162.57
Evaluation/Iteration                    189
Evaluation/MaxReturn                  -1069.86
Evaluation/MinReturn                  -1243.34
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     51.2991
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41525
GaussianMLPPolicy/KL                      3.8211e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -461.037
GaussianMLPPolicy/LossBefore           -460.967
GaussianMLPPolicy/dLoss                   0.0704041
GaussianMLPValueFunction/LossAfter    46573.7
GaussianMLPValueFunction/LossBefore   46637.2
GaussianMLPValueFunction/dLoss           63.5234
TotalEnvSteps                        228000
-----------------------------------  ---------------
2022-08-17 17:55:59 | [trpo_pendulum] epoch #190 | Saving snapshot...
2022-08-17 17:55:59 | [trpo_pendulum] epoch #190 | Saved
2022-08-17 17:55:59 | [trpo_pendulum] epoch #190 | Time 79.37 s
2022-08-17 17:55:59 | [trpo_pendulum] epoch #190 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -501.663
Evaluation/AverageReturn              -1197.46
Evaluation/Iteration                    190
Evaluation/MaxReturn                  -1162.9
Evaluation/MinReturn                  -1239.03
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     29.3806
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41552
GaussianMLPPolicy/KL                      5.33777e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -494.127
GaussianMLPPolicy/LossBefore           -493.927
GaussianMLPPolicy/dLoss                   0.199738
GaussianMLPValueFunction/LossAfter    51206.1
GaussianMLPValueFunction/LossBefore   51268.1
GaussianMLPValueFunction/dLoss           62.0039
TotalEnvSteps                        229200
-----------------------------------  ----------------
2022-08-17 17:55:59 | [trpo_pendulum] epoch #191 | Saving snapshot...
2022-08-17 17:55:59 | [trpo_pendulum] epoch #191 | Saved
2022-08-17 17:55:59 | [trpo_pendulum] epoch #191 | Time 79.79 s
2022-08-17 17:55:59 | [trpo_pendulum] epoch #191 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -531.573
Evaluation/AverageReturn              -1250.37
Evaluation/Iteration                    191
Evaluation/MaxReturn                  -1192.05
Evaluation/MinReturn                  -1335.12
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     51.4445
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41582
GaussianMLPPolicy/KL                      0.00036198
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -500.251
GaussianMLPPolicy/LossBefore           -499.665
GaussianMLPPolicy/dLoss                   0.585144
GaussianMLPValueFunction/LossAfter    55412.1
GaussianMLPValueFunction/LossBefore   55489.2
GaussianMLPValueFunction/dLoss           77.0312
TotalEnvSteps                        230400
-----------------------------------  ---------------
2022-08-17 17:56:00 | [trpo_pendulum] epoch #192 | Saving snapshot...
2022-08-17 17:56:00 | [trpo_pendulum] epoch #192 | Saved
2022-08-17 17:56:00 | [trpo_pendulum] epoch #192 | Time 80.20 s
2022-08-17 17:56:00 | [trpo_pendulum] epoch #192 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -576.436
Evaluation/AverageReturn              -1263.84
Evaluation/Iteration                    192
Evaluation/MaxReturn                  -1230.28
Evaluation/MinReturn                  -1299.29
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     26.1703
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41601
GaussianMLPPolicy/KL                      0.000283531
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -488.449
GaussianMLPPolicy/LossBefore           -488.281
GaussianMLPPolicy/dLoss                   0.167755
GaussianMLPValueFunction/LossAfter    50479.4
GaussianMLPValueFunction/LossBefore   50537.3
GaussianMLPValueFunction/dLoss           57.9023
TotalEnvSteps                        231600
-----------------------------------  ----------------
2022-08-17 17:56:00 | [trpo_pendulum] epoch #193 | Saving snapshot...
2022-08-17 17:56:00 | [trpo_pendulum] epoch #193 | Saved
2022-08-17 17:56:00 | [trpo_pendulum] epoch #193 | Time 80.61 s
2022-08-17 17:56:00 | [trpo_pendulum] epoch #193 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -489.882
Evaluation/AverageReturn              -1156.79
Evaluation/Iteration                    193
Evaluation/MaxReturn                  -1123.64
Evaluation/MinReturn                  -1222.62
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     32.9856
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41621
GaussianMLPPolicy/KL                      9.74921e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -464.074
GaussianMLPPolicy/LossBefore           -464.032
GaussianMLPPolicy/dLoss                   0.0421753
GaussianMLPValueFunction/LossAfter    46682.7
GaussianMLPValueFunction/LossBefore   46743.3
GaussianMLPValueFunction/dLoss           60.6445
TotalEnvSteps                        232800
-----------------------------------  ----------------
2022-08-17 17:56:01 | [trpo_pendulum] epoch #194 | Saving snapshot...
2022-08-17 17:56:01 | [trpo_pendulum] epoch #194 | Saved
2022-08-17 17:56:01 | [trpo_pendulum] epoch #194 | Time 81.02 s
2022-08-17 17:56:01 | [trpo_pendulum] epoch #194 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -483.831
Evaluation/AverageReturn              -1130.38
Evaluation/Iteration                    194
Evaluation/MaxReturn                  -1018.62
Evaluation/MinReturn                  -1187.68
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     54.8328
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4165
GaussianMLPPolicy/KL                      5.84715e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -442.555
GaussianMLPPolicy/LossBefore           -442.498
GaussianMLPPolicy/dLoss                   0.057312
GaussianMLPValueFunction/LossAfter    43611
GaussianMLPValueFunction/LossBefore   43669.7
GaussianMLPValueFunction/dLoss           58.6875
TotalEnvSteps                        234000
-----------------------------------  ----------------
2022-08-17 17:56:01 | [trpo_pendulum] epoch #195 | Saving snapshot...
2022-08-17 17:56:01 | [trpo_pendulum] epoch #195 | Saved
2022-08-17 17:56:01 | [trpo_pendulum] epoch #195 | Time 81.44 s
2022-08-17 17:56:01 | [trpo_pendulum] epoch #195 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -665.277
Evaluation/AverageReturn              -1459.56
Evaluation/Iteration                    195
Evaluation/MaxReturn                  -1263.82
Evaluation/MinReturn                  -1785.69
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    199.095
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41674
GaussianMLPPolicy/KL                      3.89058e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -554.689
GaussianMLPPolicy/LossBefore           -554.436
GaussianMLPPolicy/dLoss                   0.253723
GaussianMLPValueFunction/LossAfter    70245.9
GaussianMLPValueFunction/LossBefore   70320.8
GaussianMLPValueFunction/dLoss           74.8438
TotalEnvSteps                        235200
-----------------------------------  ----------------
2022-08-17 17:56:01 | [trpo_pendulum] epoch #196 | Saving snapshot...
2022-08-17 17:56:01 | [trpo_pendulum] epoch #196 | Saved
2022-08-17 17:56:01 | [trpo_pendulum] epoch #196 | Time 81.85 s
2022-08-17 17:56:01 | [trpo_pendulum] epoch #196 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -519.367
Evaluation/AverageReturn              -1176.13
Evaluation/Iteration                    196
Evaluation/MaxReturn                  -1116.3
Evaluation/MinReturn                  -1245.67
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     46.0162
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41699
GaussianMLPPolicy/KL                      2.91941e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -457.083
GaussianMLPPolicy/LossBefore           -457.088
GaussianMLPPolicy/dLoss                  -0.00552368
GaussianMLPValueFunction/LossAfter    44963.1
GaussianMLPValueFunction/LossBefore   45018.8
GaussianMLPValueFunction/dLoss           55.707
TotalEnvSteps                        236400
-----------------------------------  ----------------
2022-08-17 17:56:02 | [trpo_pendulum] epoch #197 | Saving snapshot...
2022-08-17 17:56:02 | [trpo_pendulum] epoch #197 | Saved
2022-08-17 17:56:02 | [trpo_pendulum] epoch #197 | Time 82.25 s
2022-08-17 17:56:02 | [trpo_pendulum] epoch #197 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -467.305
Evaluation/AverageReturn              -1150.28
Evaluation/Iteration                    197
Evaluation/MaxReturn                  -1082.83
Evaluation/MinReturn                  -1201.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.4725
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41716
GaussianMLPPolicy/KL                      0.000225129
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -485.86
GaussianMLPPolicy/LossBefore           -485.493
GaussianMLPPolicy/dLoss                   0.367432
GaussianMLPValueFunction/LossAfter    49978.8
GaussianMLPValueFunction/LossBefore   50071.2
GaussianMLPValueFunction/dLoss           92.3906
TotalEnvSteps                        237600
-----------------------------------  ----------------
2022-08-17 17:56:02 | [trpo_pendulum] epoch #198 | Saving snapshot...
2022-08-17 17:56:02 | [trpo_pendulum] epoch #198 | Saved
2022-08-17 17:56:02 | [trpo_pendulum] epoch #198 | Time 82.66 s
2022-08-17 17:56:02 | [trpo_pendulum] epoch #198 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -490.259
Evaluation/AverageReturn              -1177.24
Evaluation/Iteration                    198
Evaluation/MaxReturn                  -1156.36
Evaluation/MinReturn                  -1197.21
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     17.8299
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41721
GaussianMLPPolicy/KL                      0.000273262
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -492.299
GaussianMLPPolicy/LossBefore           -492.094
GaussianMLPPolicy/dLoss                   0.204895
GaussianMLPValueFunction/LossAfter    49532.5
GaussianMLPValueFunction/LossBefore   49592.6
GaussianMLPValueFunction/dLoss           60.1094
TotalEnvSteps                        238800
-----------------------------------  ----------------
2022-08-17 17:56:03 | [trpo_pendulum] epoch #199 | Saving snapshot...
2022-08-17 17:56:03 | [trpo_pendulum] epoch #199 | Saved
2022-08-17 17:56:03 | [trpo_pendulum] epoch #199 | Time 83.07 s
2022-08-17 17:56:03 | [trpo_pendulum] epoch #199 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -454.563
Evaluation/AverageReturn              -1148.7
Evaluation/Iteration                    199
Evaluation/MaxReturn                  -1073.96
Evaluation/MinReturn                  -1216.85
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     54.6738
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41719
GaussianMLPPolicy/KL                      0.000312939
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -494.367
GaussianMLPPolicy/LossBefore           -494.123
GaussianMLPPolicy/dLoss                   0.243378
GaussianMLPValueFunction/LossAfter    51483
GaussianMLPValueFunction/LossBefore   51571.8
GaussianMLPValueFunction/dLoss           88.8398
TotalEnvSteps                        240000
-----------------------------------  ----------------
2022-08-17 17:56:03 | [trpo_pendulum] epoch #200 | Saving snapshot...
2022-08-17 17:56:03 | [trpo_pendulum] epoch #200 | Saved
2022-08-17 17:56:03 | [trpo_pendulum] epoch #200 | Time 83.48 s
2022-08-17 17:56:03 | [trpo_pendulum] epoch #200 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -511.767
Evaluation/AverageReturn              -1223.49
Evaluation/Iteration                    200
Evaluation/MaxReturn                  -1091.31
Evaluation/MinReturn                  -1318.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     71.6109
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41726
GaussianMLPPolicy/KL                      0.000111485
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -491.841
GaussianMLPPolicy/LossBefore           -491.912
GaussianMLPPolicy/dLoss                  -0.0711975
GaussianMLPValueFunction/LossAfter    53878
GaussianMLPValueFunction/LossBefore   53943.3
GaussianMLPValueFunction/dLoss           65.3516
TotalEnvSteps                        241200
-----------------------------------  ----------------
2022-08-17 17:56:04 | [trpo_pendulum] epoch #201 | Saving snapshot...
2022-08-17 17:56:04 | [trpo_pendulum] epoch #201 | Saved
2022-08-17 17:56:04 | [trpo_pendulum] epoch #201 | Time 83.90 s
2022-08-17 17:56:04 | [trpo_pendulum] epoch #201 | EpochTime 0.42 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -510.009
Evaluation/AverageReturn              -1221.27
Evaluation/Iteration                    201
Evaluation/MaxReturn                  -1178.65
Evaluation/MinReturn                  -1305.11
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     40.8005
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41726
GaussianMLPPolicy/KL                      0.00021577
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -505.812
GaussianMLPPolicy/LossBefore           -505.565
GaussianMLPPolicy/dLoss                   0.247406
GaussianMLPValueFunction/LossAfter    53719.2
GaussianMLPValueFunction/LossBefore   53798
GaussianMLPValueFunction/dLoss           78.8477
TotalEnvSteps                        242400
-----------------------------------  ---------------
2022-08-17 17:56:04 | [trpo_pendulum] epoch #202 | Saving snapshot...
2022-08-17 17:56:04 | [trpo_pendulum] epoch #202 | Saved
2022-08-17 17:56:04 | [trpo_pendulum] epoch #202 | Time 84.30 s
2022-08-17 17:56:04 | [trpo_pendulum] epoch #202 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -495.917
Evaluation/AverageReturn              -1212.86
Evaluation/Iteration                    202
Evaluation/MaxReturn                  -1165.19
Evaluation/MinReturn                  -1318.86
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     61.3641
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41735
GaussianMLPPolicy/KL                      0.000204405
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -494.784
GaussianMLPPolicy/LossBefore           -494.654
GaussianMLPPolicy/dLoss                   0.130127
GaussianMLPValueFunction/LossAfter    53471.9
GaussianMLPValueFunction/LossBefore   53558
GaussianMLPValueFunction/dLoss           86.0273
TotalEnvSteps                        243600
-----------------------------------  ----------------
2022-08-17 17:56:04 | [trpo_pendulum] epoch #203 | Saving snapshot...
2022-08-17 17:56:04 | [trpo_pendulum] epoch #203 | Saved
2022-08-17 17:56:04 | [trpo_pendulum] epoch #203 | Time 84.71 s
2022-08-17 17:56:04 | [trpo_pendulum] epoch #203 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -555.146
Evaluation/AverageReturn              -1243.21
Evaluation/Iteration                    203
Evaluation/MaxReturn                  -1130.48
Evaluation/MinReturn                  -1309.39
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     61.0999
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41739
GaussianMLPPolicy/KL                      0.000269803
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -484.706
GaussianMLPPolicy/LossBefore           -484.42
GaussianMLPPolicy/dLoss                   0.285889
GaussianMLPValueFunction/LossAfter    49069.2
GaussianMLPValueFunction/LossBefore   49130.2
GaussianMLPValueFunction/dLoss           61.0586
TotalEnvSteps                        244800
-----------------------------------  ----------------
2022-08-17 17:56:05 | [trpo_pendulum] epoch #204 | Saving snapshot...
2022-08-17 17:56:05 | [trpo_pendulum] epoch #204 | Saved
2022-08-17 17:56:05 | [trpo_pendulum] epoch #204 | Time 85.12 s
2022-08-17 17:56:05 | [trpo_pendulum] epoch #204 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -563.152
Evaluation/AverageReturn              -1281.59
Evaluation/Iteration                    204
Evaluation/MaxReturn                  -1254.69
Evaluation/MinReturn                  -1316.26
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     24.0914
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41758
GaussianMLPPolicy/KL                      0.000175558
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -486.595
GaussianMLPPolicy/LossBefore           -486.597
GaussianMLPPolicy/dLoss                  -0.00177002
GaussianMLPValueFunction/LossAfter    53209.1
GaussianMLPValueFunction/LossBefore   53288.3
GaussianMLPValueFunction/dLoss           79.1992
TotalEnvSteps                        246000
-----------------------------------  ----------------
2022-08-17 17:56:05 | [trpo_pendulum] epoch #205 | Saving snapshot...
2022-08-17 17:56:05 | [trpo_pendulum] epoch #205 | Saved
2022-08-17 17:56:05 | [trpo_pendulum] epoch #205 | Time 85.52 s
2022-08-17 17:56:05 | [trpo_pendulum] epoch #205 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -555.438
Evaluation/AverageReturn              -1279.93
Evaluation/Iteration                    205
Evaluation/MaxReturn                  -1268.52
Evaluation/MinReturn                  -1296.95
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.1968
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41778
GaussianMLPPolicy/KL                      0.000290567
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -503.186
GaussianMLPPolicy/LossBefore           -502.865
GaussianMLPPolicy/dLoss                   0.320618
GaussianMLPValueFunction/LossAfter    53889.5
GaussianMLPValueFunction/LossBefore   53951
GaussianMLPValueFunction/dLoss           61.4531
TotalEnvSteps                        247200
-----------------------------------  ----------------
2022-08-17 17:56:06 | [trpo_pendulum] epoch #206 | Saving snapshot...
2022-08-17 17:56:06 | [trpo_pendulum] epoch #206 | Saved
2022-08-17 17:56:06 | [trpo_pendulum] epoch #206 | Time 85.93 s
2022-08-17 17:56:06 | [trpo_pendulum] epoch #206 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -561.512
Evaluation/AverageReturn              -1335.34
Evaluation/Iteration                    206
Evaluation/MaxReturn                  -1304.34
Evaluation/MinReturn                  -1359.44
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     17.2851
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41799
GaussianMLPPolicy/KL                      2.84092e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -541.027
GaussianMLPPolicy/LossBefore           -540.792
GaussianMLPPolicy/dLoss                   0.234192
GaussianMLPValueFunction/LossAfter    63059.3
GaussianMLPValueFunction/LossBefore   63186
GaussianMLPValueFunction/dLoss          126.727
TotalEnvSteps                        248400
-----------------------------------  ----------------
2022-08-17 17:56:06 | [trpo_pendulum] epoch #207 | Saving snapshot...
2022-08-17 17:56:06 | [trpo_pendulum] epoch #207 | Saved
2022-08-17 17:56:06 | [trpo_pendulum] epoch #207 | Time 86.35 s
2022-08-17 17:56:06 | [trpo_pendulum] epoch #207 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -529.709
Evaluation/AverageReturn              -1284.38
Evaluation/Iteration                    207
Evaluation/MaxReturn                  -1234.48
Evaluation/MinReturn                  -1332.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     38.941
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41811
GaussianMLPPolicy/KL                      2.88298e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -536.424
GaussianMLPPolicy/LossBefore           -536.402
GaussianMLPPolicy/dLoss                   0.0217896
GaussianMLPValueFunction/LossAfter    58846.9
GaussianMLPValueFunction/LossBefore   58942.7
GaussianMLPValueFunction/dLoss           95.8281
TotalEnvSteps                        249600
-----------------------------------  ----------------
2022-08-17 17:56:06 | [trpo_pendulum] epoch #208 | Saving snapshot...
2022-08-17 17:56:06 | [trpo_pendulum] epoch #208 | Saved
2022-08-17 17:56:06 | [trpo_pendulum] epoch #208 | Time 86.75 s
2022-08-17 17:56:06 | [trpo_pendulum] epoch #208 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -522.706
Evaluation/AverageReturn              -1252.78
Evaluation/Iteration                    208
Evaluation/MaxReturn                  -1160.11
Evaluation/MinReturn                  -1324.06
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     59.3139
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41807
GaussianMLPPolicy/KL                      8.22122e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -527.075
GaussianMLPPolicy/LossBefore           -526.946
GaussianMLPPolicy/dLoss                   0.129028
GaussianMLPValueFunction/LossAfter    55365.8
GaussianMLPValueFunction/LossBefore   55422.6
GaussianMLPValueFunction/dLoss           56.8789
TotalEnvSteps                        250800
-----------------------------------  ----------------
2022-08-17 17:56:07 | [trpo_pendulum] epoch #209 | Saving snapshot...
2022-08-17 17:56:07 | [trpo_pendulum] epoch #209 | Saved
2022-08-17 17:56:07 | [trpo_pendulum] epoch #209 | Time 87.16 s
2022-08-17 17:56:07 | [trpo_pendulum] epoch #209 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -516.001
Evaluation/AverageReturn              -1252.66
Evaluation/Iteration                    209
Evaluation/MaxReturn                  -1183.36
Evaluation/MinReturn                  -1320.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     46.8638
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41808
GaussianMLPPolicy/KL                      4.97e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -511.709
GaussianMLPPolicy/LossBefore           -511.714
GaussianMLPPolicy/dLoss                  -0.00506592
GaussianMLPValueFunction/LossAfter    56017.3
GaussianMLPValueFunction/LossBefore   56089.2
GaussianMLPValueFunction/dLoss           71.8633
TotalEnvSteps                        252000
-----------------------------------  ---------------
2022-08-17 17:56:07 | [trpo_pendulum] epoch #210 | Saving snapshot...
2022-08-17 17:56:07 | [trpo_pendulum] epoch #210 | Saved
2022-08-17 17:56:07 | [trpo_pendulum] epoch #210 | Time 87.57 s
2022-08-17 17:56:07 | [trpo_pendulum] epoch #210 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -491.834
Evaluation/AverageReturn              -1217.67
Evaluation/Iteration                    210
Evaluation/MaxReturn                  -1197.46
Evaluation/MinReturn                  -1239.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     15.0724
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41813
GaussianMLPPolicy/KL                      1.79645e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -504.886
GaussianMLPPolicy/LossBefore           -504.869
GaussianMLPPolicy/dLoss                   0.0168152
GaussianMLPValueFunction/LossAfter    56062.4
GaussianMLPValueFunction/LossBefore   56163.8
GaussianMLPValueFunction/dLoss          101.418
TotalEnvSteps                        253200
-----------------------------------  ----------------
2022-08-17 17:56:08 | [trpo_pendulum] epoch #211 | Saving snapshot...
2022-08-17 17:56:08 | [trpo_pendulum] epoch #211 | Saved
2022-08-17 17:56:08 | [trpo_pendulum] epoch #211 | Time 87.98 s
2022-08-17 17:56:08 | [trpo_pendulum] epoch #211 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -547.608
Evaluation/AverageReturn              -1300.5
Evaluation/Iteration                    211
Evaluation/MaxReturn                  -1219.13
Evaluation/MinReturn                  -1343.18
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     46.5847
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41808
GaussianMLPPolicy/KL                      9.88149e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -536.567
GaussianMLPPolicy/LossBefore           -536.349
GaussianMLPPolicy/dLoss                   0.217957
GaussianMLPValueFunction/LossAfter    59214.7
GaussianMLPValueFunction/LossBefore   59333.6
GaussianMLPValueFunction/dLoss          118.809
TotalEnvSteps                        254400
-----------------------------------  ----------------
2022-08-17 17:56:08 | [trpo_pendulum] epoch #212 | Saving snapshot...
2022-08-17 17:56:08 | [trpo_pendulum] epoch #212 | Saved
2022-08-17 17:56:08 | [trpo_pendulum] epoch #212 | Time 88.40 s
2022-08-17 17:56:08 | [trpo_pendulum] epoch #212 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -665.977
Evaluation/AverageReturn              -1411.75
Evaluation/Iteration                    212
Evaluation/MaxReturn                  -1299.91
Evaluation/MinReturn                  -1629.47
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    109.837
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.418
GaussianMLPPolicy/KL                      4.16434e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -521.243
GaussianMLPPolicy/LossBefore           -521.228
GaussianMLPPolicy/dLoss                   0.0150757
GaussianMLPValueFunction/LossAfter    59847.7
GaussianMLPValueFunction/LossBefore   59918.4
GaussianMLPValueFunction/dLoss           70.7148
TotalEnvSteps                        255600
-----------------------------------  ----------------
2022-08-17 17:56:08 | [trpo_pendulum] epoch #213 | Saving snapshot...
2022-08-17 17:56:08 | [trpo_pendulum] epoch #213 | Saved
2022-08-17 17:56:08 | [trpo_pendulum] epoch #213 | Time 88.80 s
2022-08-17 17:56:08 | [trpo_pendulum] epoch #213 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -685.211
Evaluation/AverageReturn              -1470.31
Evaluation/Iteration                    213
Evaluation/MaxReturn                  -1361.27
Evaluation/MinReturn                  -1664.92
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    121.413
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41782
GaussianMLPPolicy/KL                      1.02716e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -557.509
GaussianMLPPolicy/LossBefore           -557.389
GaussianMLPPolicy/dLoss                   0.119324
GaussianMLPValueFunction/LossAfter    65931.3
GaussianMLPValueFunction/LossBefore   66008.5
GaussianMLPValueFunction/dLoss           77.2031
TotalEnvSteps                        256800
-----------------------------------  ----------------
2022-08-17 17:56:09 | [trpo_pendulum] epoch #214 | Saving snapshot...
2022-08-17 17:56:09 | [trpo_pendulum] epoch #214 | Saved
2022-08-17 17:56:09 | [trpo_pendulum] epoch #214 | Time 89.20 s
2022-08-17 17:56:09 | [trpo_pendulum] epoch #214 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -506.489
Evaluation/AverageReturn              -1207.86
Evaluation/Iteration                    214
Evaluation/MaxReturn                  -1142.23
Evaluation/MinReturn                  -1294.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     53.4411
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41761
GaussianMLPPolicy/KL                      3.40992e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -494.803
GaussianMLPPolicy/LossBefore           -494.721
GaussianMLPPolicy/dLoss                   0.0813599
GaussianMLPValueFunction/LossAfter    50182.9
GaussianMLPValueFunction/LossBefore   50248.5
GaussianMLPValueFunction/dLoss           65.5078
TotalEnvSteps                        258000
-----------------------------------  ----------------
2022-08-17 17:56:09 | [trpo_pendulum] epoch #215 | Saving snapshot...
2022-08-17 17:56:09 | [trpo_pendulum] epoch #215 | Saved
2022-08-17 17:56:09 | [trpo_pendulum] epoch #215 | Time 89.61 s
2022-08-17 17:56:09 | [trpo_pendulum] epoch #215 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -513.874
Evaluation/AverageReturn              -1242.72
Evaluation/Iteration                    215
Evaluation/MaxReturn                  -1146.41
Evaluation/MinReturn                  -1297.86
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.6335
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41725
GaussianMLPPolicy/KL                      8.71747e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -526.301
GaussianMLPPolicy/LossBefore           -526.172
GaussianMLPPolicy/dLoss                   0.1297
GaussianMLPValueFunction/LossAfter    54212.8
GaussianMLPValueFunction/LossBefore   54297
GaussianMLPValueFunction/dLoss           84.2695
TotalEnvSteps                        259200
-----------------------------------  ----------------
2022-08-17 17:56:10 | [trpo_pendulum] epoch #216 | Saving snapshot...
2022-08-17 17:56:10 | [trpo_pendulum] epoch #216 | Saved
2022-08-17 17:56:10 | [trpo_pendulum] epoch #216 | Time 90.02 s
2022-08-17 17:56:10 | [trpo_pendulum] epoch #216 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -529.582
Evaluation/AverageReturn              -1264.56
Evaluation/Iteration                    216
Evaluation/MaxReturn                  -1200.47
Evaluation/MinReturn                  -1347.2
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     52.0899
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41686
GaussianMLPPolicy/KL                      0.000526972
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -524.251
GaussianMLPPolicy/LossBefore           -523.465
GaussianMLPPolicy/dLoss                   0.78656
GaussianMLPValueFunction/LossAfter    56553.7
GaussianMLPValueFunction/LossBefore   56631.5
GaussianMLPValueFunction/dLoss           77.8203
TotalEnvSteps                        260400
-----------------------------------  ----------------
2022-08-17 17:56:10 | [trpo_pendulum] epoch #217 | Saving snapshot...
2022-08-17 17:56:10 | [trpo_pendulum] epoch #217 | Saved
2022-08-17 17:56:10 | [trpo_pendulum] epoch #217 | Time 90.44 s
2022-08-17 17:56:10 | [trpo_pendulum] epoch #217 | EpochTime 0.42 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -525.517
Evaluation/AverageReturn              -1230.46
Evaluation/Iteration                    217
Evaluation/MaxReturn                  -1151.85
Evaluation/MinReturn                  -1305.47
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     61.9735
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41654
GaussianMLPPolicy/KL                      0.00067568
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -489.904
GaussianMLPPolicy/LossBefore           -489.308
GaussianMLPPolicy/dLoss                   0.596405
GaussianMLPValueFunction/LossAfter    50703.6
GaussianMLPValueFunction/LossBefore   50776.2
GaussianMLPValueFunction/dLoss           72.6055
TotalEnvSteps                        261600
-----------------------------------  ---------------
2022-08-17 17:56:10 | [trpo_pendulum] epoch #218 | Saving snapshot...
2022-08-17 17:56:10 | [trpo_pendulum] epoch #218 | Saved
2022-08-17 17:56:10 | [trpo_pendulum] epoch #218 | Time 90.84 s
2022-08-17 17:56:10 | [trpo_pendulum] epoch #218 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -494.365
Evaluation/AverageReturn              -1174.59
Evaluation/Iteration                    218
Evaluation/MaxReturn                  -1148.99
Evaluation/MinReturn                  -1194.79
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.5855
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41623
GaussianMLPPolicy/KL                      0.000554363
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -477.125
GaussianMLPPolicy/LossBefore           -476.883
GaussianMLPPolicy/dLoss                   0.242218
GaussianMLPValueFunction/LossAfter    47284.2
GaussianMLPValueFunction/LossBefore   47351.7
GaussianMLPValueFunction/dLoss           67.5078
TotalEnvSteps                        262800
-----------------------------------  ----------------
2022-08-17 17:56:11 | [trpo_pendulum] epoch #219 | Saving snapshot...
2022-08-17 17:56:11 | [trpo_pendulum] epoch #219 | Saved
2022-08-17 17:56:11 | [trpo_pendulum] epoch #219 | Time 91.25 s
2022-08-17 17:56:11 | [trpo_pendulum] epoch #219 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -666.68
Evaluation/AverageReturn              -1391.9
Evaluation/Iteration                    219
Evaluation/MaxReturn                  -1315.87
Evaluation/MinReturn                  -1534.68
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     74.7269
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4159
GaussianMLPPolicy/KL                      0.000322494
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -506.842
GaussianMLPPolicy/LossBefore           -506.547
GaussianMLPPolicy/dLoss                   0.294647
GaussianMLPValueFunction/LossAfter    58121.4
GaussianMLPValueFunction/LossBefore   58189
GaussianMLPValueFunction/dLoss           67.5625
TotalEnvSteps                        264000
-----------------------------------  ----------------
2022-08-17 17:56:11 | [trpo_pendulum] epoch #220 | Saving snapshot...
2022-08-17 17:56:11 | [trpo_pendulum] epoch #220 | Saved
2022-08-17 17:56:11 | [trpo_pendulum] epoch #220 | Time 91.67 s
2022-08-17 17:56:11 | [trpo_pendulum] epoch #220 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -659.955
Evaluation/AverageReturn              -1401.49
Evaluation/Iteration                    220
Evaluation/MaxReturn                  -1287.27
Evaluation/MinReturn                  -1543.85
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     86.6354
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41564
GaussianMLPPolicy/KL                      0.000182602
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -510.679
GaussianMLPPolicy/LossBefore           -510.791
GaussianMLPPolicy/dLoss                  -0.112061
GaussianMLPValueFunction/LossAfter    59566.4
GaussianMLPValueFunction/LossBefore   59636.4
GaussianMLPValueFunction/dLoss           70.0352
TotalEnvSteps                        265200
-----------------------------------  ----------------
2022-08-17 17:56:12 | [trpo_pendulum] epoch #221 | Saving snapshot...
2022-08-17 17:56:12 | [trpo_pendulum] epoch #221 | Saved
2022-08-17 17:56:12 | [trpo_pendulum] epoch #221 | Time 92.07 s
2022-08-17 17:56:12 | [trpo_pendulum] epoch #221 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -445.796
Evaluation/AverageReturn              -1121.35
Evaluation/Iteration                    221
Evaluation/MaxReturn                  -1051.34
Evaluation/MinReturn                  -1186.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     52.5493
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41538
GaussianMLPPolicy/KL                      0.000478136
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -475.379
GaussianMLPPolicy/LossBefore           -475.008
GaussianMLPPolicy/dLoss                   0.370667
GaussianMLPValueFunction/LossAfter    47900.1
GaussianMLPValueFunction/LossBefore   47988.7
GaussianMLPValueFunction/dLoss           88.6289
TotalEnvSteps                        266400
-----------------------------------  ----------------
2022-08-17 17:56:12 | [trpo_pendulum] epoch #222 | Saving snapshot...
2022-08-17 17:56:12 | [trpo_pendulum] epoch #222 | Saved
2022-08-17 17:56:12 | [trpo_pendulum] epoch #222 | Time 92.47 s
2022-08-17 17:56:12 | [trpo_pendulum] epoch #222 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -478.609
Evaluation/AverageReturn              -1140.68
Evaluation/Iteration                    222
Evaluation/MaxReturn                  -1040.6
Evaluation/MinReturn                  -1190.66
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.3504
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41507
GaussianMLPPolicy/KL                      3.85113e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -468.221
GaussianMLPPolicy/LossBefore           -468.333
GaussianMLPPolicy/dLoss                  -0.111267
GaussianMLPValueFunction/LossAfter    44449.9
GaussianMLPValueFunction/LossBefore   44511.2
GaussianMLPValueFunction/dLoss           61.2734
TotalEnvSteps                        267600
-----------------------------------  ----------------
2022-08-17 17:56:13 | [trpo_pendulum] epoch #223 | Saving snapshot...
2022-08-17 17:56:13 | [trpo_pendulum] epoch #223 | Saved
2022-08-17 17:56:13 | [trpo_pendulum] epoch #223 | Time 92.89 s
2022-08-17 17:56:13 | [trpo_pendulum] epoch #223 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -493.385
Evaluation/AverageReturn              -1144.98
Evaluation/Iteration                    223
Evaluation/MaxReturn                  -1129.92
Evaluation/MinReturn                  -1154.99
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.59494
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4147
GaussianMLPPolicy/KL                      6.60521e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -463.06
GaussianMLPPolicy/LossBefore           -463.002
GaussianMLPPolicy/dLoss                   0.0580139
GaussianMLPValueFunction/LossAfter    42905.9
GaussianMLPValueFunction/LossBefore   42973.6
GaussianMLPValueFunction/dLoss           67.6875
TotalEnvSteps                        268800
-----------------------------------  ----------------
2022-08-17 17:56:13 | [trpo_pendulum] epoch #224 | Saving snapshot...
2022-08-17 17:56:13 | [trpo_pendulum] epoch #224 | Saved
2022-08-17 17:56:13 | [trpo_pendulum] epoch #224 | Time 93.30 s
2022-08-17 17:56:13 | [trpo_pendulum] epoch #224 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -481.372
Evaluation/AverageReturn              -1136.77
Evaluation/Iteration                    224
Evaluation/MaxReturn                  -1060.34
Evaluation/MinReturn                  -1178.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     39.9252
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41432
GaussianMLPPolicy/KL                      0.000159285
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -459.379
GaussianMLPPolicy/LossBefore           -459.12
GaussianMLPPolicy/dLoss                   0.259216
GaussianMLPValueFunction/LossAfter    43388.2
GaussianMLPValueFunction/LossBefore   43447.6
GaussianMLPValueFunction/dLoss           59.4531
TotalEnvSteps                        270000
-----------------------------------  ----------------
2022-08-17 17:56:13 | [trpo_pendulum] epoch #225 | Saving snapshot...
2022-08-17 17:56:13 | [trpo_pendulum] epoch #225 | Saved
2022-08-17 17:56:13 | [trpo_pendulum] epoch #225 | Time 93.70 s
2022-08-17 17:56:13 | [trpo_pendulum] epoch #225 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -478.548
Evaluation/AverageReturn              -1120.71
Evaluation/Iteration                    225
Evaluation/MaxReturn                  -1045.77
Evaluation/MinReturn                  -1165.92
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     36.3739
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41394
GaussianMLPPolicy/KL                      0.000133051
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -450.08
GaussianMLPPolicy/LossBefore           -450.023
GaussianMLPPolicy/dLoss                   0.0578003
GaussianMLPValueFunction/LossAfter    41470.8
GaussianMLPValueFunction/LossBefore   41534.1
GaussianMLPValueFunction/dLoss           63.3555
TotalEnvSteps                        271200
-----------------------------------  ----------------
2022-08-17 17:56:14 | [trpo_pendulum] epoch #226 | Saving snapshot...
2022-08-17 17:56:14 | [trpo_pendulum] epoch #226 | Saved
2022-08-17 17:56:14 | [trpo_pendulum] epoch #226 | Time 94.12 s
2022-08-17 17:56:14 | [trpo_pendulum] epoch #226 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -597.526
Evaluation/AverageReturn              -1295.41
Evaluation/Iteration                    226
Evaluation/MaxReturn                  -1214.19
Evaluation/MinReturn                  -1379.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     59.9424
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41379
GaussianMLPPolicy/KL                      1.1083e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -463.547
GaussianMLPPolicy/LossBefore           -463.528
GaussianMLPPolicy/dLoss                   0.019104
GaussianMLPValueFunction/LossAfter    50967.9
GaussianMLPValueFunction/LossBefore   51025.5
GaussianMLPValueFunction/dLoss           57.6016
TotalEnvSteps                        272400
-----------------------------------  ---------------
2022-08-17 17:56:14 | [trpo_pendulum] epoch #227 | Saving snapshot...
2022-08-17 17:56:14 | [trpo_pendulum] epoch #227 | Saved
2022-08-17 17:56:14 | [trpo_pendulum] epoch #227 | Time 94.54 s
2022-08-17 17:56:14 | [trpo_pendulum] epoch #227 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -680.503
Evaluation/AverageReturn              -1499.67
Evaluation/Iteration                    227
Evaluation/MaxReturn                  -1385.48
Evaluation/MinReturn                  -1580.71
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     75.6588
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41348
GaussianMLPPolicy/KL                      2.64918e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -582.311
GaussianMLPPolicy/LossBefore           -582.131
GaussianMLPPolicy/dLoss                   0.179321
GaussianMLPValueFunction/LossAfter    69658.9
GaussianMLPValueFunction/LossBefore   69736.7
GaussianMLPValueFunction/dLoss           77.8359
TotalEnvSteps                        273600
-----------------------------------  ----------------
2022-08-17 17:56:15 | [trpo_pendulum] epoch #228 | Saving snapshot...
2022-08-17 17:56:15 | [trpo_pendulum] epoch #228 | Saved
2022-08-17 17:56:15 | [trpo_pendulum] epoch #228 | Time 94.95 s
2022-08-17 17:56:15 | [trpo_pendulum] epoch #228 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -511.11
Evaluation/AverageReturn              -1160.3
Evaluation/Iteration                    228
Evaluation/MaxReturn                  -1106.01
Evaluation/MinReturn                  -1230.89
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     41.9595
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41319
GaussianMLPPolicy/KL                      2.41626e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -451.131
GaussianMLPPolicy/LossBefore           -450.953
GaussianMLPPolicy/dLoss                   0.178955
GaussianMLPValueFunction/LossAfter    42248.3
GaussianMLPValueFunction/LossBefore   42300.3
GaussianMLPValueFunction/dLoss           51.9375
TotalEnvSteps                        274800
-----------------------------------  ----------------
2022-08-17 17:56:15 | [trpo_pendulum] epoch #229 | Saving snapshot...
2022-08-17 17:56:15 | [trpo_pendulum] epoch #229 | Saved
2022-08-17 17:56:15 | [trpo_pendulum] epoch #229 | Time 95.35 s
2022-08-17 17:56:15 | [trpo_pendulum] epoch #229 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -480.653
Evaluation/AverageReturn              -1136.92
Evaluation/Iteration                    229
Evaluation/MaxReturn                  -1072.31
Evaluation/MinReturn                  -1174.53
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     33.0357
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41287
GaussianMLPPolicy/KL                      3.95115e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -461.843
GaussianMLPPolicy/LossBefore           -461.81
GaussianMLPPolicy/dLoss                   0.032959
GaussianMLPValueFunction/LossAfter    43088.4
GaussianMLPValueFunction/LossBefore   43151
GaussianMLPValueFunction/dLoss           62.5781
TotalEnvSteps                        276000
-----------------------------------  ----------------
2022-08-17 17:56:15 | [trpo_pendulum] epoch #230 | Saving snapshot...
2022-08-17 17:56:15 | [trpo_pendulum] epoch #230 | Saved
2022-08-17 17:56:15 | [trpo_pendulum] epoch #230 | Time 95.76 s
2022-08-17 17:56:15 | [trpo_pendulum] epoch #230 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -490.064
Evaluation/AverageReturn              -1129.54
Evaluation/Iteration                    230
Evaluation/MaxReturn                  -1102.33
Evaluation/MinReturn                  -1143.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.6255
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41255
GaussianMLPPolicy/KL                      5.55373e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -444.386
GaussianMLPPolicy/LossBefore           -444.383
GaussianMLPPolicy/dLoss                   0.00289917
GaussianMLPValueFunction/LossAfter    40572
GaussianMLPValueFunction/LossBefore   40630.9
GaussianMLPValueFunction/dLoss           58.9062
TotalEnvSteps                        277200
-----------------------------------  ----------------
2022-08-17 17:56:16 | [trpo_pendulum] epoch #231 | Saving snapshot...
2022-08-17 17:56:16 | [trpo_pendulum] epoch #231 | Saved
2022-08-17 17:56:16 | [trpo_pendulum] epoch #231 | Time 96.18 s
2022-08-17 17:56:16 | [trpo_pendulum] epoch #231 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -491.122
Evaluation/AverageReturn              -1109.25
Evaluation/Iteration                    231
Evaluation/MaxReturn                   -979.882
Evaluation/MinReturn                  -1163.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     60.8197
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41228
GaussianMLPPolicy/KL                      5.38292e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -426.262
GaussianMLPPolicy/LossBefore           -426.073
GaussianMLPPolicy/dLoss                   0.188171
GaussianMLPValueFunction/LossAfter    38130.6
GaussianMLPValueFunction/LossBefore   38180.9
GaussianMLPValueFunction/dLoss           50.3672
TotalEnvSteps                        278400
-----------------------------------  ----------------
2022-08-17 17:56:16 | [trpo_pendulum] epoch #232 | Saving snapshot...
2022-08-17 17:56:16 | [trpo_pendulum] epoch #232 | Saved
2022-08-17 17:56:16 | [trpo_pendulum] epoch #232 | Time 96.58 s
2022-08-17 17:56:16 | [trpo_pendulum] epoch #232 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -472.503
Evaluation/AverageReturn              -1110
Evaluation/Iteration                    232
Evaluation/MaxReturn                   -965.281
Evaluation/MinReturn                  -1195.51
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     83.5052
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41193
GaussianMLPPolicy/KL                      2.60818e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -451.038
GaussianMLPPolicy/LossBefore           -451.033
GaussianMLPPolicy/dLoss                   0.0043335
GaussianMLPValueFunction/LossAfter    41422.5
GaussianMLPValueFunction/LossBefore   41472.3
GaussianMLPValueFunction/dLoss           49.7422
TotalEnvSteps                        279600
-----------------------------------  ----------------
2022-08-17 17:56:17 | [trpo_pendulum] epoch #233 | Saving snapshot...
2022-08-17 17:56:17 | [trpo_pendulum] epoch #233 | Saved
2022-08-17 17:56:17 | [trpo_pendulum] epoch #233 | Time 96.99 s
2022-08-17 17:56:17 | [trpo_pendulum] epoch #233 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -474.405
Evaluation/AverageReturn              -1129.27
Evaluation/Iteration                    233
Evaluation/MaxReturn                  -1031.18
Evaluation/MinReturn                  -1195.89
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     66.5871
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41169
GaussianMLPPolicy/KL                      3.15873e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -447.12
GaussianMLPPolicy/LossBefore           -447.106
GaussianMLPPolicy/dLoss                   0.013855
GaussianMLPValueFunction/LossAfter    43276.1
GaussianMLPValueFunction/LossBefore   43332
GaussianMLPValueFunction/dLoss           55.8828
TotalEnvSteps                        280800
-----------------------------------  ----------------
2022-08-17 17:56:17 | [trpo_pendulum] epoch #234 | Saving snapshot...
2022-08-17 17:56:17 | [trpo_pendulum] epoch #234 | Saved
2022-08-17 17:56:17 | [trpo_pendulum] epoch #234 | Time 97.40 s
2022-08-17 17:56:17 | [trpo_pendulum] epoch #234 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -487.26
Evaluation/AverageReturn              -1147.32
Evaluation/Iteration                    234
Evaluation/MaxReturn                  -1075.36
Evaluation/MinReturn                  -1194.43
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     37.705
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41137
GaussianMLPPolicy/KL                      1.66782e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -465.163
GaussianMLPPolicy/LossBefore           -465.131
GaussianMLPPolicy/dLoss                   0.0327148
GaussianMLPValueFunction/LossAfter    43032.5
GaussianMLPValueFunction/LossBefore   43086.9
GaussianMLPValueFunction/dLoss           54.3164
TotalEnvSteps                        282000
-----------------------------------  ----------------
2022-08-17 17:56:17 | [trpo_pendulum] epoch #235 | Saving snapshot...
2022-08-17 17:56:17 | [trpo_pendulum] epoch #235 | Saved
2022-08-17 17:56:17 | [trpo_pendulum] epoch #235 | Time 97.80 s
2022-08-17 17:56:17 | [trpo_pendulum] epoch #235 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -493.69
Evaluation/AverageReturn              -1176.33
Evaluation/Iteration                    235
Evaluation/MaxReturn                  -1052.94
Evaluation/MinReturn                  -1225.8
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     57.3588
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41116
GaussianMLPPolicy/KL                      0.000188073
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -466.917
GaussianMLPPolicy/LossBefore           -466.502
GaussianMLPPolicy/dLoss                   0.414948
GaussianMLPValueFunction/LossAfter    48386.9
GaussianMLPValueFunction/LossBefore   48457.5
GaussianMLPValueFunction/dLoss           70.5117
TotalEnvSteps                        283200
-----------------------------------  ----------------
2022-08-17 17:56:18 | [trpo_pendulum] epoch #236 | Saving snapshot...
2022-08-17 17:56:18 | [trpo_pendulum] epoch #236 | Saved
2022-08-17 17:56:18 | [trpo_pendulum] epoch #236 | Time 98.19 s
2022-08-17 17:56:18 | [trpo_pendulum] epoch #236 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -520.613
Evaluation/AverageReturn              -1162.15
Evaluation/Iteration                    236
Evaluation/MaxReturn                  -1103.72
Evaluation/MinReturn                  -1249.07
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     58.8614
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41093
GaussianMLPPolicy/KL                      0.000321779
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -445.596
GaussianMLPPolicy/LossBefore           -445.166
GaussianMLPPolicy/dLoss                   0.429779
GaussianMLPValueFunction/LossAfter    40554.1
GaussianMLPValueFunction/LossBefore   40601.6
GaussianMLPValueFunction/dLoss           47.4883
TotalEnvSteps                        284400
-----------------------------------  ----------------
2022-08-17 17:56:18 | [trpo_pendulum] epoch #237 | Saving snapshot...
2022-08-17 17:56:18 | [trpo_pendulum] epoch #237 | Saved
2022-08-17 17:56:18 | [trpo_pendulum] epoch #237 | Time 98.71 s
2022-08-17 17:56:18 | [trpo_pendulum] epoch #237 | EpochTime 0.52 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -465.092
Evaluation/AverageReturn              -1088.5
Evaluation/Iteration                    237
Evaluation/MaxReturn                  -1030.56
Evaluation/MinReturn                  -1186.81
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     62.8106
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41085
GaussianMLPPolicy/KL                      0.000103109
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -419.606
GaussianMLPPolicy/LossBefore           -419.72
GaussianMLPPolicy/dLoss                  -0.113403
GaussianMLPValueFunction/LossAfter    39115.4
GaussianMLPValueFunction/LossBefore   39170.9
GaussianMLPValueFunction/dLoss           55.5508
TotalEnvSteps                        285600
-----------------------------------  ----------------
2022-08-17 17:56:19 | [trpo_pendulum] epoch #238 | Saving snapshot...
2022-08-17 17:56:19 | [trpo_pendulum] epoch #238 | Saved
2022-08-17 17:56:19 | [trpo_pendulum] epoch #238 | Time 99.11 s
2022-08-17 17:56:19 | [trpo_pendulum] epoch #238 | EpochTime 0.39 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -624.443
Evaluation/AverageReturn              -1330.59
Evaluation/Iteration                    238
Evaluation/MaxReturn                  -1123.26
Evaluation/MinReturn                  -1449.29
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    119.087
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41078
GaussianMLPPolicy/KL                      0.0001155
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -485.662
GaussianMLPPolicy/LossBefore           -485.495
GaussianMLPPolicy/dLoss                   0.166962
GaussianMLPValueFunction/LossAfter    53314.9
GaussianMLPValueFunction/LossBefore   53370.6
GaussianMLPValueFunction/dLoss           55.6133
TotalEnvSteps                        286800
-----------------------------------  --------------
2022-08-17 17:56:19 | [trpo_pendulum] epoch #239 | Saving snapshot...
2022-08-17 17:56:19 | [trpo_pendulum] epoch #239 | Saved
2022-08-17 17:56:19 | [trpo_pendulum] epoch #239 | Time 99.52 s
2022-08-17 17:56:19 | [trpo_pendulum] epoch #239 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -474.57
Evaluation/AverageReturn              -1129.35
Evaluation/Iteration                    239
Evaluation/MaxReturn                   -924.148
Evaluation/MinReturn                  -1188.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     94.9144
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41063
GaussianMLPPolicy/KL                      0.000462042
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -461.08
GaussianMLPPolicy/LossBefore           -460.552
GaussianMLPPolicy/dLoss                   0.528015
GaussianMLPValueFunction/LossAfter    42941.2
GaussianMLPValueFunction/LossBefore   43001.3
GaussianMLPValueFunction/dLoss           60.1289
TotalEnvSteps                        288000
-----------------------------------  ----------------
2022-08-17 17:56:20 | [trpo_pendulum] epoch #240 | Saving snapshot...
2022-08-17 17:56:20 | [trpo_pendulum] epoch #240 | Saved
2022-08-17 17:56:20 | [trpo_pendulum] epoch #240 | Time 99.92 s
2022-08-17 17:56:20 | [trpo_pendulum] epoch #240 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -456.83
Evaluation/AverageReturn              -1059.23
Evaluation/Iteration                    240
Evaluation/MaxReturn                   -987.577
Evaluation/MinReturn                  -1175.96
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     61.7461
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41042
GaussianMLPPolicy/KL                      0.000519309
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -422.063
GaussianMLPPolicy/LossBefore           -421.62
GaussianMLPPolicy/dLoss                   0.443207
GaussianMLPValueFunction/LossAfter    36680.5
GaussianMLPValueFunction/LossBefore   36726.7
GaussianMLPValueFunction/dLoss           46.1758
TotalEnvSteps                        289200
-----------------------------------  ----------------
2022-08-17 17:56:20 | [trpo_pendulum] epoch #241 | Saving snapshot...
2022-08-17 17:56:20 | [trpo_pendulum] epoch #241 | Saved
2022-08-17 17:56:20 | [trpo_pendulum] epoch #241 | Time 100.33 s
2022-08-17 17:56:20 | [trpo_pendulum] epoch #241 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -486.737
Evaluation/AverageReturn              -1095.29
Evaluation/Iteration                    241
Evaluation/MaxReturn                  -1042.92
Evaluation/MinReturn                  -1123.16
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     27.3664
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41026
GaussianMLPPolicy/KL                      0.000651367
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -416.536
GaussianMLPPolicy/LossBefore           -416.018
GaussianMLPPolicy/dLoss                   0.5177
GaussianMLPValueFunction/LossAfter    36344.5
GaussianMLPValueFunction/LossBefore   36387.8
GaussianMLPValueFunction/dLoss           43.2773
TotalEnvSteps                        290400
-----------------------------------  ----------------
2022-08-17 17:56:20 | [trpo_pendulum] epoch #242 | Saving snapshot...
2022-08-17 17:56:20 | [trpo_pendulum] epoch #242 | Saved
2022-08-17 17:56:20 | [trpo_pendulum] epoch #242 | Time 100.74 s
2022-08-17 17:56:20 | [trpo_pendulum] epoch #242 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -506.222
Evaluation/AverageReturn              -1108.47
Evaluation/Iteration                    242
Evaluation/MaxReturn                   -865.647
Evaluation/MinReturn                  -1300.86
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    131.536
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41009
GaussianMLPPolicy/KL                      0.000369304
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -414.75
GaussianMLPPolicy/LossBefore           -414.753
GaussianMLPPolicy/dLoss                  -0.00323486
GaussianMLPValueFunction/LossAfter    37570.5
GaussianMLPValueFunction/LossBefore   37611.5
GaussianMLPValueFunction/dLoss           40.9961
TotalEnvSteps                        291600
-----------------------------------  ----------------
2022-08-17 17:56:21 | [trpo_pendulum] epoch #243 | Saving snapshot...
2022-08-17 17:56:21 | [trpo_pendulum] epoch #243 | Saved
2022-08-17 17:56:21 | [trpo_pendulum] epoch #243 | Time 101.14 s
2022-08-17 17:56:21 | [trpo_pendulum] epoch #243 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -457.366
Evaluation/AverageReturn              -1008.47
Evaluation/Iteration                    243
Evaluation/MaxReturn                   -967.731
Evaluation/MinReturn                  -1072.97
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     35.2657
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40997
GaussianMLPPolicy/KL                      0.000274986
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -374.549
GaussianMLPPolicy/LossBefore           -374.542
GaussianMLPPolicy/dLoss                   0.00720215
GaussianMLPValueFunction/LossAfter    30959.1
GaussianMLPValueFunction/LossBefore   30995.9
GaussianMLPValueFunction/dLoss           36.8105
TotalEnvSteps                        292800
-----------------------------------  ----------------
2022-08-17 17:56:21 | [trpo_pendulum] epoch #244 | Saving snapshot...
2022-08-17 17:56:21 | [trpo_pendulum] epoch #244 | Saved
2022-08-17 17:56:21 | [trpo_pendulum] epoch #244 | Time 101.56 s
2022-08-17 17:56:21 | [trpo_pendulum] epoch #244 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -555.154
Evaluation/AverageReturn              -1212.68
Evaluation/Iteration                    244
Evaluation/MaxReturn                  -1089.78
Evaluation/MinReturn                  -1312.74
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     91.4727
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40993
GaussianMLPPolicy/KL                      0.000397191
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -445.174
GaussianMLPPolicy/LossBefore           -444.697
GaussianMLPPolicy/dLoss                   0.477417
GaussianMLPValueFunction/LossAfter    44722.8
GaussianMLPValueFunction/LossBefore   44768
GaussianMLPValueFunction/dLoss           45.1992
TotalEnvSteps                        294000
-----------------------------------  ----------------
2022-08-17 17:56:22 | [trpo_pendulum] epoch #245 | Saving snapshot...
2022-08-17 17:56:22 | [trpo_pendulum] epoch #245 | Saved
2022-08-17 17:56:22 | [trpo_pendulum] epoch #245 | Time 101.97 s
2022-08-17 17:56:22 | [trpo_pendulum] epoch #245 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -395.175
Evaluation/AverageReturn               -924.452
Evaluation/Iteration                    245
Evaluation/MaxReturn                   -875.526
Evaluation/MinReturn                  -1018.23
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.8992
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40988
GaussianMLPPolicy/KL                      2.87438e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -363.726
GaussianMLPPolicy/LossBefore           -363.884
GaussianMLPPolicy/dLoss                  -0.157745
GaussianMLPValueFunction/LossAfter    27757.2
GaussianMLPValueFunction/LossBefore   27792.3
GaussianMLPValueFunction/dLoss           35.0527
TotalEnvSteps                        295200
-----------------------------------  ----------------
2022-08-17 17:56:22 | [trpo_pendulum] epoch #246 | Saving snapshot...
2022-08-17 17:56:22 | [trpo_pendulum] epoch #246 | Saved
2022-08-17 17:56:22 | [trpo_pendulum] epoch #246 | Time 102.37 s
2022-08-17 17:56:22 | [trpo_pendulum] epoch #246 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -426.504
Evaluation/AverageReturn              -1029.7
Evaluation/Iteration                    246
Evaluation/MaxReturn                   -989.845
Evaluation/MinReturn                  -1095.71
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     34.666
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40982
GaussianMLPPolicy/KL                      0.000108395
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -416.048
GaussianMLPPolicy/LossBefore           -415.885
GaussianMLPPolicy/dLoss                   0.162994
GaussianMLPValueFunction/LossAfter    35622
GaussianMLPValueFunction/LossBefore   35665
GaussianMLPValueFunction/dLoss           43.0039
TotalEnvSteps                        296400
-----------------------------------  ----------------
2022-08-17 17:56:22 | [trpo_pendulum] epoch #247 | Saving snapshot...
2022-08-17 17:56:22 | [trpo_pendulum] epoch #247 | Saved
2022-08-17 17:56:22 | [trpo_pendulum] epoch #247 | Time 102.78 s
2022-08-17 17:56:22 | [trpo_pendulum] epoch #247 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -596.794
Evaluation/AverageReturn              -1353.72
Evaluation/Iteration                    247
Evaluation/MaxReturn                  -1182.13
Evaluation/MinReturn                  -1535.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    112.456
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4098
GaussianMLPPolicy/KL                      2.92059e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -517.02
GaussianMLPPolicy/LossBefore           -517.017
GaussianMLPPolicy/dLoss                   0.00317383
GaussianMLPValueFunction/LossAfter    57383.3
GaussianMLPValueFunction/LossBefore   57439.1
GaussianMLPValueFunction/dLoss           55.8555
TotalEnvSteps                        297600
-----------------------------------  ----------------
2022-08-17 17:56:23 | [trpo_pendulum] epoch #248 | Saving snapshot...
2022-08-17 17:56:23 | [trpo_pendulum] epoch #248 | Saved
2022-08-17 17:56:23 | [trpo_pendulum] epoch #248 | Time 103.18 s
2022-08-17 17:56:23 | [trpo_pendulum] epoch #248 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -657.922
Evaluation/AverageReturn              -1491.13
Evaluation/Iteration                    248
Evaluation/MaxReturn                  -1304.3
Evaluation/MinReturn                  -1581.16
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     93.1115
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.40998
GaussianMLPPolicy/KL                      3.28208e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -555.04
GaussianMLPPolicy/LossBefore           -554.959
GaussianMLPPolicy/dLoss                   0.0811768
GaussianMLPValueFunction/LossAfter    69532.7
GaussianMLPValueFunction/LossBefore   69603.1
GaussianMLPValueFunction/dLoss           70.3594
TotalEnvSteps                        298800
-----------------------------------  ----------------
2022-08-17 17:56:23 | [trpo_pendulum] epoch #249 | Saving snapshot...
2022-08-17 17:56:23 | [trpo_pendulum] epoch #249 | Saved
2022-08-17 17:56:23 | [trpo_pendulum] epoch #249 | Time 103.59 s
2022-08-17 17:56:23 | [trpo_pendulum] epoch #249 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -497.651
Evaluation/AverageReturn              -1091.96
Evaluation/Iteration                    249
Evaluation/MaxReturn                   -970.982
Evaluation/MinReturn                  -1179.39
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     68.5664
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41005
GaussianMLPPolicy/KL                      0.000219843
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -414.915
GaussianMLPPolicy/LossBefore           -414.503
GaussianMLPPolicy/dLoss                   0.412079
GaussianMLPValueFunction/LossAfter    35679.2
GaussianMLPValueFunction/LossBefore   35719.1
GaussianMLPValueFunction/dLoss           39.8555
TotalEnvSteps                        300000
-----------------------------------  ----------------
2022-08-17 17:56:24 | [trpo_pendulum] epoch #250 | Saving snapshot...
2022-08-17 17:56:24 | [trpo_pendulum] epoch #250 | Saved
2022-08-17 17:56:24 | [trpo_pendulum] epoch #250 | Time 104.00 s
2022-08-17 17:56:24 | [trpo_pendulum] epoch #250 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -713.656
Evaluation/AverageReturn              -1642.2
Evaluation/Iteration                    250
Evaluation/MaxReturn                  -1336.96
Evaluation/MinReturn                  -1796.24
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    151.265
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41038
GaussianMLPPolicy/KL                      6.76553e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -615.497
GaussianMLPPolicy/LossBefore           -615.445
GaussianMLPPolicy/dLoss                   0.0517578
GaussianMLPValueFunction/LossAfter    86325.1
GaussianMLPValueFunction/LossBefore   86417.3
GaussianMLPValueFunction/dLoss           92.1953
TotalEnvSteps                        301200
-----------------------------------  ----------------
2022-08-17 17:56:24 | [trpo_pendulum] epoch #251 | Saving snapshot...
2022-08-17 17:56:24 | [trpo_pendulum] epoch #251 | Saved
2022-08-17 17:56:24 | [trpo_pendulum] epoch #251 | Time 104.41 s
2022-08-17 17:56:24 | [trpo_pendulum] epoch #251 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -690.968
Evaluation/AverageReturn              -1594.58
Evaluation/Iteration                    251
Evaluation/MaxReturn                  -1502.84
Evaluation/MinReturn                  -1672.97
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     55.808
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41074
GaussianMLPPolicy/KL                      3.26251e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -617.733
GaussianMLPPolicy/LossBefore           -617.802
GaussianMLPPolicy/dLoss                  -0.069519
GaussianMLPValueFunction/LossAfter    80652.5
GaussianMLPValueFunction/LossBefore   80744.7
GaussianMLPValueFunction/dLoss           92.2266
TotalEnvSteps                        302400
-----------------------------------  ----------------
2022-08-17 17:56:24 | [trpo_pendulum] epoch #252 | Saving snapshot...
2022-08-17 17:56:24 | [trpo_pendulum] epoch #252 | Saved
2022-08-17 17:56:24 | [trpo_pendulum] epoch #252 | Time 104.81 s
2022-08-17 17:56:24 | [trpo_pendulum] epoch #252 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -748.255
Evaluation/AverageReturn              -1694.11
Evaluation/Iteration                    252
Evaluation/MaxReturn                  -1550.07
Evaluation/MinReturn                  -1822.57
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     96.0292
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41116
GaussianMLPPolicy/KL                      4.72565e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -644.368
GaussianMLPPolicy/LossBefore           -644.1
GaussianMLPPolicy/dLoss                   0.268188
GaussianMLPValueFunction/LossAfter    89722.6
GaussianMLPValueFunction/LossBefore   89831.7
GaussianMLPValueFunction/dLoss          109.039
TotalEnvSteps                        303600
-----------------------------------  ----------------
2022-08-17 17:56:25 | [trpo_pendulum] epoch #253 | Saving snapshot...
2022-08-17 17:56:25 | [trpo_pendulum] epoch #253 | Saved
2022-08-17 17:56:25 | [trpo_pendulum] epoch #253 | Time 105.22 s
2022-08-17 17:56:25 | [trpo_pendulum] epoch #253 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -562.279
Evaluation/AverageReturn              -1270.92
Evaluation/Iteration                    253
Evaluation/MaxReturn                  -1073.9
Evaluation/MinReturn                  -1402.95
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    109.712
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41159
GaussianMLPPolicy/KL                      0.000253182
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -482.304
GaussianMLPPolicy/LossBefore           -481.892
GaussianMLPPolicy/dLoss                   0.411652
GaussianMLPValueFunction/LossAfter    50406.7
GaussianMLPValueFunction/LossBefore   50470.6
GaussianMLPValueFunction/dLoss           63.8672
TotalEnvSteps                        304800
-----------------------------------  ----------------
2022-08-17 17:56:25 | [trpo_pendulum] epoch #254 | Saving snapshot...
2022-08-17 17:56:25 | [trpo_pendulum] epoch #254 | Saved
2022-08-17 17:56:25 | [trpo_pendulum] epoch #254 | Time 105.64 s
2022-08-17 17:56:25 | [trpo_pendulum] epoch #254 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -706.948
Evaluation/AverageReturn              -1651.62
Evaluation/Iteration                    254
Evaluation/MaxReturn                  -1590.64
Evaluation/MinReturn                  -1758.89
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     54.4826
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41198
GaussianMLPPolicy/KL                      2.52914e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -651.379
GaussianMLPPolicy/LossBefore           -651.494
GaussianMLPPolicy/dLoss                  -0.114807
GaussianMLPValueFunction/LossAfter    87598.5
GaussianMLPValueFunction/LossBefore   87710.7
GaussianMLPValueFunction/dLoss          112.234
TotalEnvSteps                        306000
-----------------------------------  ----------------
2022-08-17 17:56:26 | [trpo_pendulum] epoch #255 | Saving snapshot...
2022-08-17 17:56:26 | [trpo_pendulum] epoch #255 | Saved
2022-08-17 17:56:26 | [trpo_pendulum] epoch #255 | Time 106.05 s
2022-08-17 17:56:26 | [trpo_pendulum] epoch #255 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -620.642
Evaluation/AverageReturn              -1455.56
Evaluation/Iteration                    255
Evaluation/MaxReturn                  -1264.91
Evaluation/MinReturn                  -1700.53
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    153.14
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41235
GaussianMLPPolicy/KL                      1.71937e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -573.086
GaussianMLPPolicy/LossBefore           -573.105
GaussianMLPPolicy/dLoss                  -0.0195923
GaussianMLPValueFunction/LossAfter    68731.9
GaussianMLPValueFunction/LossBefore   68823.2
GaussianMLPValueFunction/dLoss           91.2812
TotalEnvSteps                        307200
-----------------------------------  ----------------
2022-08-17 17:56:26 | [trpo_pendulum] epoch #256 | Saving snapshot...
2022-08-17 17:56:26 | [trpo_pendulum] epoch #256 | Saved
2022-08-17 17:56:26 | [trpo_pendulum] epoch #256 | Time 106.45 s
2022-08-17 17:56:26 | [trpo_pendulum] epoch #256 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -625.79
Evaluation/AverageReturn              -1444.45
Evaluation/Iteration                    256
Evaluation/MaxReturn                  -1216.3
Evaluation/MinReturn                  -1714.09
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    162.408
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41264
GaussianMLPPolicy/KL                      8.36177e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -568.338
GaussianMLPPolicy/LossBefore           -568.107
GaussianMLPPolicy/dLoss                   0.230957
GaussianMLPValueFunction/LossAfter    66372.6
GaussianMLPValueFunction/LossBefore   66462.1
GaussianMLPValueFunction/dLoss           89.5156
TotalEnvSteps                        308400
-----------------------------------  ----------------
2022-08-17 17:56:26 | [trpo_pendulum] epoch #257 | Saving snapshot...
2022-08-17 17:56:27 | [trpo_pendulum] epoch #257 | Saved
2022-08-17 17:56:27 | [trpo_pendulum] epoch #257 | Time 106.86 s
2022-08-17 17:56:27 | [trpo_pendulum] epoch #257 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -524.635
Evaluation/AverageReturn              -1200.78
Evaluation/Iteration                    257
Evaluation/MaxReturn                   -975.64
Evaluation/MinReturn                  -1360.23
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    126.111
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41288
GaussianMLPPolicy/KL                      0.000106019
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -466.169
GaussianMLPPolicy/LossBefore           -466.095
GaussianMLPPolicy/dLoss                   0.0739746
GaussianMLPValueFunction/LossAfter    45146.9
GaussianMLPValueFunction/LossBefore   45208.7
GaussianMLPValueFunction/dLoss           61.8594
TotalEnvSteps                        309600
-----------------------------------  ----------------
2022-08-17 17:56:27 | [trpo_pendulum] epoch #258 | Saving snapshot...
2022-08-17 17:56:27 | [trpo_pendulum] epoch #258 | Saved
2022-08-17 17:56:27 | [trpo_pendulum] epoch #258 | Time 107.27 s
2022-08-17 17:56:27 | [trpo_pendulum] epoch #258 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -378.192
Evaluation/AverageReturn               -900.526
Evaluation/Iteration                    258
Evaluation/MaxReturn                   -790.489
Evaluation/MinReturn                  -1021.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     67.8224
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41304
GaussianMLPPolicy/KL                      0.000230424
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -362.37
GaussianMLPPolicy/LossBefore           -362.119
GaussianMLPPolicy/dLoss                   0.251343
GaussianMLPValueFunction/LossAfter    27033.4
GaussianMLPValueFunction/LossBefore   27072.8
GaussianMLPValueFunction/dLoss           39.334
TotalEnvSteps                        310800
-----------------------------------  ----------------
2022-08-17 17:56:27 | [trpo_pendulum] epoch #259 | Saving snapshot...
2022-08-17 17:56:27 | [trpo_pendulum] epoch #259 | Saved
2022-08-17 17:56:27 | [trpo_pendulum] epoch #259 | Time 107.67 s
2022-08-17 17:56:27 | [trpo_pendulum] epoch #259 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -456.493
Evaluation/AverageReturn              -1071.05
Evaluation/Iteration                    259
Evaluation/MaxReturn                   -861.448
Evaluation/MinReturn                  -1279.63
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    134.824
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41328
GaussianMLPPolicy/KL                      6.41686e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -411.572
GaussianMLPPolicy/LossBefore           -411.631
GaussianMLPPolicy/dLoss                  -0.0589294
GaussianMLPValueFunction/LossAfter    36877.6
GaussianMLPValueFunction/LossBefore   36926.2
GaussianMLPValueFunction/dLoss           48.5664
TotalEnvSteps                        312000
-----------------------------------  ----------------
2022-08-17 17:56:28 | [trpo_pendulum] epoch #260 | Saving snapshot...
2022-08-17 17:56:28 | [trpo_pendulum] epoch #260 | Saved
2022-08-17 17:56:28 | [trpo_pendulum] epoch #260 | Time 108.07 s
2022-08-17 17:56:28 | [trpo_pendulum] epoch #260 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -483.794
Evaluation/AverageReturn              -1119.32
Evaluation/Iteration                    260
Evaluation/MaxReturn                   -968.896
Evaluation/MinReturn                  -1234.86
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     86.8356
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41362
GaussianMLPPolicy/KL                      0.000108178
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -423.531
GaussianMLPPolicy/LossBefore           -423.303
GaussianMLPPolicy/dLoss                   0.228363
GaussianMLPValueFunction/LossAfter    38882.4
GaussianMLPValueFunction/LossBefore   38931.9
GaussianMLPValueFunction/dLoss           49.5156
TotalEnvSteps                        313200
-----------------------------------  ----------------
2022-08-17 17:56:28 | [trpo_pendulum] epoch #261 | Saving snapshot...
2022-08-17 17:56:28 | [trpo_pendulum] epoch #261 | Saved
2022-08-17 17:56:28 | [trpo_pendulum] epoch #261 | Time 108.48 s
2022-08-17 17:56:28 | [trpo_pendulum] epoch #261 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -434.831
Evaluation/AverageReturn              -1031.97
Evaluation/Iteration                    261
Evaluation/MaxReturn                   -861.677
Evaluation/MinReturn                  -1264.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    145.94
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41402
GaussianMLPPolicy/KL                      9.24789e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -400.037
GaussianMLPPolicy/LossBefore           -400.054
GaussianMLPPolicy/dLoss                  -0.0160828
GaussianMLPValueFunction/LossAfter    34400.1
GaussianMLPValueFunction/LossBefore   34444.2
GaussianMLPValueFunction/dLoss           44.1094
TotalEnvSteps                        314400
-----------------------------------  ----------------
2022-08-17 17:56:29 | [trpo_pendulum] epoch #262 | Saving snapshot...
2022-08-17 17:56:29 | [trpo_pendulum] epoch #262 | Saved
2022-08-17 17:56:29 | [trpo_pendulum] epoch #262 | Time 108.89 s
2022-08-17 17:56:29 | [trpo_pendulum] epoch #262 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -786.643
Evaluation/AverageReturn              -1813.14
Evaluation/Iteration                    262
Evaluation/MaxReturn                  -1779.77
Evaluation/MinReturn                  -1849.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     22.2812
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4143
GaussianMLPPolicy/KL                      1.99244e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -719.03
GaussianMLPPolicy/LossBefore           -718.912
GaussianMLPPolicy/dLoss                   0.118286
GaussianMLPValueFunction/LossAfter   103006
GaussianMLPValueFunction/LossBefore  103132
GaussianMLPValueFunction/dLoss          126.477
TotalEnvSteps                        315600
-----------------------------------  ----------------
2022-08-17 17:56:29 | [trpo_pendulum] epoch #263 | Saving snapshot...
2022-08-17 17:56:29 | [trpo_pendulum] epoch #263 | Saved
2022-08-17 17:56:29 | [trpo_pendulum] epoch #263 | Time 109.30 s
2022-08-17 17:56:29 | [trpo_pendulum] epoch #263 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -431.632
Evaluation/AverageReturn              -1008.68
Evaluation/Iteration                    263
Evaluation/MaxReturn                   -863.514
Evaluation/MinReturn                  -1103.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     78.0367
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41453
GaussianMLPPolicy/KL                      5.35239e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -396.635
GaussianMLPPolicy/LossBefore           -396.635
GaussianMLPPolicy/dLoss                   0
GaussianMLPValueFunction/LossAfter    31848.6
GaussianMLPValueFunction/LossBefore   31892.2
GaussianMLPValueFunction/dLoss           43.6055
TotalEnvSteps                        316800
-----------------------------------  ----------------
2022-08-17 17:56:29 | [trpo_pendulum] epoch #264 | Saving snapshot...
2022-08-17 17:56:29 | [trpo_pendulum] epoch #264 | Saved
2022-08-17 17:56:29 | [trpo_pendulum] epoch #264 | Time 109.71 s
2022-08-17 17:56:29 | [trpo_pendulum] epoch #264 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -574.874
Evaluation/AverageReturn              -1350.37
Evaluation/Iteration                    264
Evaluation/MaxReturn                  -1187.96
Evaluation/MinReturn                  -1502.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    110.235
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41469
GaussianMLPPolicy/KL                      2.21159e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -538.502
GaussianMLPPolicy/LossBefore           -538.415
GaussianMLPPolicy/dLoss                   0.0873413
GaussianMLPValueFunction/LossAfter    57646.6
GaussianMLPValueFunction/LossBefore   57718.5
GaussianMLPValueFunction/dLoss           71.9414
TotalEnvSteps                        318000
-----------------------------------  ----------------
2022-08-17 17:56:30 | [trpo_pendulum] epoch #265 | Saving snapshot...
2022-08-17 17:56:30 | [trpo_pendulum] epoch #265 | Saved
2022-08-17 17:56:30 | [trpo_pendulum] epoch #265 | Time 110.12 s
2022-08-17 17:56:30 | [trpo_pendulum] epoch #265 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -583.754
Evaluation/AverageReturn              -1373.39
Evaluation/Iteration                    265
Evaluation/MaxReturn                  -1169.68
Evaluation/MinReturn                  -1508.58
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    113.767
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4148
GaussianMLPPolicy/KL                      5.02676e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -546.103
GaussianMLPPolicy/LossBefore           -545.906
GaussianMLPPolicy/dLoss                   0.196411
GaussianMLPValueFunction/LossAfter    59963
GaussianMLPValueFunction/LossBefore   60038.3
GaussianMLPValueFunction/dLoss           75.3398
TotalEnvSteps                        319200
-----------------------------------  ----------------
2022-08-17 17:56:30 | [trpo_pendulum] epoch #266 | Saving snapshot...
2022-08-17 17:56:30 | [trpo_pendulum] epoch #266 | Saved
2022-08-17 17:56:30 | [trpo_pendulum] epoch #266 | Time 110.52 s
2022-08-17 17:56:30 | [trpo_pendulum] epoch #266 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -382.979
Evaluation/AverageReturn               -901.267
Evaluation/Iteration                    266
Evaluation/MaxReturn                   -836.07
Evaluation/MinReturn                   -982.02
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     54.2386
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41493
GaussianMLPPolicy/KL                      3.08973e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -351.784
GaussianMLPPolicy/LossBefore           -351.611
GaussianMLPPolicy/dLoss                   0.173187
GaussianMLPValueFunction/LossAfter    25152.9
GaussianMLPValueFunction/LossBefore   25189.2
GaussianMLPValueFunction/dLoss           36.2715
TotalEnvSteps                        320400
-----------------------------------  ----------------
2022-08-17 17:56:31 | [trpo_pendulum] epoch #267 | Saving snapshot...
2022-08-17 17:56:31 | [trpo_pendulum] epoch #267 | Saved
2022-08-17 17:56:31 | [trpo_pendulum] epoch #267 | Time 110.93 s
2022-08-17 17:56:31 | [trpo_pendulum] epoch #267 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -357.205
Evaluation/AverageReturn               -872.84
Evaluation/Iteration                    267
Evaluation/MaxReturn                   -755.288
Evaluation/MinReturn                   -965.196
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     90.1223
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41508
GaussianMLPPolicy/KL                      3.36322e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -350.001
GaussianMLPPolicy/LossBefore           -349.995
GaussianMLPPolicy/dLoss                   0.00656128
GaussianMLPValueFunction/LossAfter    25428.8
GaussianMLPValueFunction/LossBefore   25463
GaussianMLPValueFunction/dLoss           34.2383
TotalEnvSteps                        321600
-----------------------------------  ----------------
2022-08-17 17:56:31 | [trpo_pendulum] epoch #268 | Saving snapshot...
2022-08-17 17:56:31 | [trpo_pendulum] epoch #268 | Saved
2022-08-17 17:56:31 | [trpo_pendulum] epoch #268 | Time 111.34 s
2022-08-17 17:56:31 | [trpo_pendulum] epoch #268 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -450.194
Evaluation/AverageReturn              -1044.05
Evaluation/Iteration                    268
Evaluation/MaxReturn                   -894.974
Evaluation/MinReturn                  -1165.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     98.3141
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41525
GaussianMLPPolicy/KL                      1.18344e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -402.323
GaussianMLPPolicy/LossBefore           -402.25
GaussianMLPPolicy/dLoss                   0.0724182
GaussianMLPValueFunction/LossAfter    33845.4
GaussianMLPValueFunction/LossBefore   33887.4
GaussianMLPValueFunction/dLoss           42.0039
TotalEnvSteps                        322800
-----------------------------------  ----------------
2022-08-17 17:56:31 | [trpo_pendulum] epoch #269 | Saving snapshot...
2022-08-17 17:56:31 | [trpo_pendulum] epoch #269 | Saved
2022-08-17 17:56:31 | [trpo_pendulum] epoch #269 | Time 111.74 s
2022-08-17 17:56:31 | [trpo_pendulum] epoch #269 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -356.841
Evaluation/AverageReturn               -859.354
Evaluation/Iteration                    269
Evaluation/MaxReturn                   -763.598
Evaluation/MinReturn                   -974.092
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     74.6071
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41542
GaussianMLPPolicy/KL                      1.62389e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -341.594
GaussianMLPPolicy/LossBefore           -341.575
GaussianMLPPolicy/dLoss                   0.0192871
GaussianMLPValueFunction/LossAfter    24551.9
GaussianMLPValueFunction/LossBefore   24584.7
GaussianMLPValueFunction/dLoss           32.7949
TotalEnvSteps                        324000
-----------------------------------  ----------------
2022-08-17 17:56:32 | [trpo_pendulum] epoch #270 | Saving snapshot...
2022-08-17 17:56:32 | [trpo_pendulum] epoch #270 | Saved
2022-08-17 17:56:32 | [trpo_pendulum] epoch #270 | Time 112.17 s
2022-08-17 17:56:32 | [trpo_pendulum] epoch #270 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -375.339
Evaluation/AverageReturn               -910.019
Evaluation/Iteration                    270
Evaluation/MaxReturn                   -760.033
Evaluation/MinReturn                  -1163.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    130.973
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41565
GaussianMLPPolicy/KL                      3.61039e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -357.631
GaussianMLPPolicy/LossBefore           -357.504
GaussianMLPPolicy/dLoss                   0.12619
GaussianMLPValueFunction/LossAfter    27675.1
GaussianMLPValueFunction/LossBefore   27709
GaussianMLPValueFunction/dLoss           33.8945
TotalEnvSteps                        325200
-----------------------------------  ----------------
2022-08-17 17:56:32 | [trpo_pendulum] epoch #271 | Saving snapshot...
2022-08-17 17:56:32 | [trpo_pendulum] epoch #271 | Saved
2022-08-17 17:56:32 | [trpo_pendulum] epoch #271 | Time 112.58 s
2022-08-17 17:56:32 | [trpo_pendulum] epoch #271 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -413.893
Evaluation/AverageReturn               -958.296
Evaluation/Iteration                    271
Evaluation/MaxReturn                   -865.069
Evaluation/MinReturn                  -1058.72
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     84.1851
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41581
GaussianMLPPolicy/KL                      2.36741e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -377.333
GaussianMLPPolicy/LossBefore           -377.34
GaussianMLPPolicy/dLoss                  -0.00695801
GaussianMLPValueFunction/LossAfter    28409.7
GaussianMLPValueFunction/LossBefore   28443.5
GaussianMLPValueFunction/dLoss           33.8047
TotalEnvSteps                        326400
-----------------------------------  ----------------
2022-08-17 17:56:33 | [trpo_pendulum] epoch #272 | Saving snapshot...
2022-08-17 17:56:33 | [trpo_pendulum] epoch #272 | Saved
2022-08-17 17:56:33 | [trpo_pendulum] epoch #272 | Time 112.99 s
2022-08-17 17:56:33 | [trpo_pendulum] epoch #272 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -401.132
Evaluation/AverageReturn               -918.03
Evaluation/Iteration                    272
Evaluation/MaxReturn                   -757.933
Evaluation/MinReturn                  -1082.52
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    132.437
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41594
GaussianMLPPolicy/KL                      3.11237e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -352.384
GaussianMLPPolicy/LossBefore           -352.356
GaussianMLPPolicy/dLoss                   0.0285339
GaussianMLPValueFunction/LossAfter    26072.5
GaussianMLPValueFunction/LossBefore   26102.9
GaussianMLPValueFunction/dLoss           30.3848
TotalEnvSteps                        327600
-----------------------------------  ----------------
2022-08-17 17:56:33 | [trpo_pendulum] epoch #273 | Saving snapshot...
2022-08-17 17:56:33 | [trpo_pendulum] epoch #273 | Saved
2022-08-17 17:56:33 | [trpo_pendulum] epoch #273 | Time 113.39 s
2022-08-17 17:56:33 | [trpo_pendulum] epoch #273 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -500.698
Evaluation/AverageReturn              -1125.72
Evaluation/Iteration                    273
Evaluation/MaxReturn                   -854.105
Evaluation/MinReturn                  -1259.31
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    127.676
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41621
GaussianMLPPolicy/KL                      7.74638e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -414.873
GaussianMLPPolicy/LossBefore           -414.803
GaussianMLPPolicy/dLoss                   0.0706177
GaussianMLPValueFunction/LossAfter    38173.6
GaussianMLPValueFunction/LossBefore   38212.8
GaussianMLPValueFunction/dLoss           39.2305
TotalEnvSteps                        328800
-----------------------------------  ----------------
2022-08-17 17:56:33 | [trpo_pendulum] epoch #274 | Saving snapshot...
2022-08-17 17:56:33 | [trpo_pendulum] epoch #274 | Saved
2022-08-17 17:56:33 | [trpo_pendulum] epoch #274 | Time 113.80 s
2022-08-17 17:56:33 | [trpo_pendulum] epoch #274 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -621.968
Evaluation/AverageReturn              -1477.54
Evaluation/Iteration                    274
Evaluation/MaxReturn                  -1410.21
Evaluation/MinReturn                  -1562.93
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.1095
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41631
GaussianMLPPolicy/KL                      1.68556e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -602.62
GaussianMLPPolicy/LossBefore           -602.498
GaussianMLPPolicy/dLoss                   0.121826
GaussianMLPValueFunction/LossAfter    68962.4
GaussianMLPValueFunction/LossBefore   69031.9
GaussianMLPValueFunction/dLoss           69.4531
TotalEnvSteps                        330000
-----------------------------------  ----------------
2022-08-17 17:56:34 | [trpo_pendulum] epoch #275 | Saving snapshot...
2022-08-17 17:56:34 | [trpo_pendulum] epoch #275 | Saved
2022-08-17 17:56:34 | [trpo_pendulum] epoch #275 | Time 114.20 s
2022-08-17 17:56:34 | [trpo_pendulum] epoch #275 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -376.697
Evaluation/AverageReturn               -907.314
Evaluation/Iteration                    275
Evaluation/MaxReturn                   -806.219
Evaluation/MinReturn                   -976.564
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     58.1728
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41644
GaussianMLPPolicy/KL                      1.98708e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -359.784
GaussianMLPPolicy/LossBefore           -359.658
GaussianMLPPolicy/dLoss                   0.125305
GaussianMLPValueFunction/LossAfter    26579.3
GaussianMLPValueFunction/LossBefore   26611.6
GaussianMLPValueFunction/dLoss           32.3301
TotalEnvSteps                        331200
-----------------------------------  ----------------
2022-08-17 17:56:34 | [trpo_pendulum] epoch #276 | Saving snapshot...
2022-08-17 17:56:34 | [trpo_pendulum] epoch #276 | Saved
2022-08-17 17:56:34 | [trpo_pendulum] epoch #276 | Time 114.62 s
2022-08-17 17:56:34 | [trpo_pendulum] epoch #276 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -762.403
Evaluation/AverageReturn              -1748.09
Evaluation/Iteration                    276
Evaluation/MaxReturn                  -1711.26
Evaluation/MinReturn                  -1813.62
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     35.3139
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41649
GaussianMLPPolicy/KL                      2.20415e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -688.008
GaussianMLPPolicy/LossBefore           -687.956
GaussianMLPPolicy/dLoss                   0.0517578
GaussianMLPValueFunction/LossAfter    93979.4
GaussianMLPValueFunction/LossBefore   94079.2
GaussianMLPValueFunction/dLoss           99.7734
TotalEnvSteps                        332400
-----------------------------------  ----------------
2022-08-17 17:56:35 | [trpo_pendulum] epoch #277 | Saving snapshot...
2022-08-17 17:56:35 | [trpo_pendulum] epoch #277 | Saved
2022-08-17 17:56:35 | [trpo_pendulum] epoch #277 | Time 115.03 s
2022-08-17 17:56:35 | [trpo_pendulum] epoch #277 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -507.263
Evaluation/AverageReturn              -1179.79
Evaluation/Iteration                    277
Evaluation/MaxReturn                  -1076.8
Evaluation/MinReturn                  -1300.68
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     90.1845
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41655
GaussianMLPPolicy/KL                      2.19299e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -460.791
GaussianMLPPolicy/LossBefore           -460.725
GaussianMLPPolicy/dLoss                   0.0665894
GaussianMLPValueFunction/LossAfter    42922.1
GaussianMLPValueFunction/LossBefore   42971.4
GaussianMLPValueFunction/dLoss           49.2852
TotalEnvSteps                        333600
-----------------------------------  ----------------
2022-08-17 17:56:35 | [trpo_pendulum] epoch #278 | Saving snapshot...
2022-08-17 17:56:35 | [trpo_pendulum] epoch #278 | Saved
2022-08-17 17:56:35 | [trpo_pendulum] epoch #278 | Time 115.45 s
2022-08-17 17:56:35 | [trpo_pendulum] epoch #278 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -725.765
Evaluation/AverageReturn              -1681.14
Evaluation/Iteration                    278
Evaluation/MaxReturn                  -1574.14
Evaluation/MinReturn                  -1775.98
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     72.4283
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41661
GaussianMLPPolicy/KL                      3.91902e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -660.259
GaussianMLPPolicy/LossBefore           -660.155
GaussianMLPPolicy/dLoss                   0.10437
GaussianMLPValueFunction/LossAfter    87679
GaussianMLPValueFunction/LossBefore   87780
GaussianMLPValueFunction/dLoss          100.984
TotalEnvSteps                        334800
-----------------------------------  ----------------
2022-08-17 17:56:35 | [trpo_pendulum] epoch #279 | Saving snapshot...
2022-08-17 17:56:36 | [trpo_pendulum] epoch #279 | Saved
2022-08-17 17:56:36 | [trpo_pendulum] epoch #279 | Time 115.87 s
2022-08-17 17:56:36 | [trpo_pendulum] epoch #279 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -636.955
Evaluation/AverageReturn              -1480.38
Evaluation/Iteration                    279
Evaluation/MaxReturn                  -1346.2
Evaluation/MinReturn                  -1624.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     89.2388
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4167
GaussianMLPPolicy/KL                      9.19765e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -578.847
GaussianMLPPolicy/LossBefore           -578.867
GaussianMLPPolicy/dLoss                  -0.0198975
GaussianMLPValueFunction/LossAfter    67880.1
GaussianMLPValueFunction/LossBefore   67962.4
GaussianMLPValueFunction/dLoss           82.3203
TotalEnvSteps                        336000
-----------------------------------  ----------------
2022-08-17 17:56:36 | [trpo_pendulum] epoch #280 | Saving snapshot...
2022-08-17 17:56:36 | [trpo_pendulum] epoch #280 | Saved
2022-08-17 17:56:36 | [trpo_pendulum] epoch #280 | Time 116.29 s
2022-08-17 17:56:36 | [trpo_pendulum] epoch #280 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -652.127
Evaluation/AverageReturn              -1526.05
Evaluation/Iteration                    280
Evaluation/MaxReturn                  -1384.3
Evaluation/MinReturn                  -1717.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    114.096
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41673
GaussianMLPPolicy/KL                      4.32748e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -607.891
GaussianMLPPolicy/LossBefore           -607.57
GaussianMLPPolicy/dLoss                   0.320801
GaussianMLPValueFunction/LossAfter    72711.2
GaussianMLPValueFunction/LossBefore   72802.3
GaussianMLPValueFunction/dLoss           91.1797
TotalEnvSteps                        337200
-----------------------------------  ----------------
2022-08-17 17:56:36 | [trpo_pendulum] epoch #281 | Saving snapshot...
2022-08-17 17:56:36 | [trpo_pendulum] epoch #281 | Saved
2022-08-17 17:56:36 | [trpo_pendulum] epoch #281 | Time 116.69 s
2022-08-17 17:56:36 | [trpo_pendulum] epoch #281 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -378.462
Evaluation/AverageReturn               -865.497
Evaluation/Iteration                    281
Evaluation/MaxReturn                   -750.271
Evaluation/MinReturn                   -937.387
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     61.9014
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41666
GaussianMLPPolicy/KL                      2.0357e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -340.71
GaussianMLPPolicy/LossBefore           -340.714
GaussianMLPPolicy/dLoss                  -0.00402832
GaussianMLPValueFunction/LossAfter    23031.8
GaussianMLPValueFunction/LossBefore   23064.5
GaussianMLPValueFunction/dLoss           32.7031
TotalEnvSteps                        338400
-----------------------------------  ---------------
2022-08-17 17:56:37 | [trpo_pendulum] epoch #282 | Saving snapshot...
2022-08-17 17:56:37 | [trpo_pendulum] epoch #282 | Saved
2022-08-17 17:56:37 | [trpo_pendulum] epoch #282 | Time 117.10 s
2022-08-17 17:56:37 | [trpo_pendulum] epoch #282 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -552.121
Evaluation/AverageReturn              -1264.44
Evaluation/Iteration                    282
Evaluation/MaxReturn                  -1155.43
Evaluation/MinReturn                  -1373.26
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     79.6864
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4167
GaussianMLPPolicy/KL                      3.01536e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -478.914
GaussianMLPPolicy/LossBefore           -478.801
GaussianMLPPolicy/dLoss                   0.112946
GaussianMLPValueFunction/LossAfter    48181.1
GaussianMLPValueFunction/LossBefore   48240.2
GaussianMLPValueFunction/dLoss           59.1172
TotalEnvSteps                        339600
-----------------------------------  ----------------
2022-08-17 17:56:37 | [trpo_pendulum] epoch #283 | Saving snapshot...
2022-08-17 17:56:37 | [trpo_pendulum] epoch #283 | Saved
2022-08-17 17:56:37 | [trpo_pendulum] epoch #283 | Time 117.51 s
2022-08-17 17:56:37 | [trpo_pendulum] epoch #283 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -775.958
Evaluation/AverageReturn              -1776.99
Evaluation/Iteration                    283
Evaluation/MaxReturn                  -1674.28
Evaluation/MinReturn                  -1835.29
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     52.2954
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41672
GaussianMLPPolicy/KL                      2.03753e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -695.756
GaussianMLPPolicy/LossBefore           -695.671
GaussianMLPPolicy/dLoss                   0.0853271
GaussianMLPValueFunction/LossAfter    96473.1
GaussianMLPValueFunction/LossBefore   96594.6
GaussianMLPValueFunction/dLoss          121.492
TotalEnvSteps                        340800
-----------------------------------  ----------------
2022-08-17 17:56:38 | [trpo_pendulum] epoch #284 | Saving snapshot...
2022-08-17 17:56:38 | [trpo_pendulum] epoch #284 | Saved
2022-08-17 17:56:38 | [trpo_pendulum] epoch #284 | Time 117.91 s
2022-08-17 17:56:38 | [trpo_pendulum] epoch #284 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -392.233
Evaluation/AverageReturn               -940.915
Evaluation/Iteration                    284
Evaluation/MaxReturn                   -777.691
Evaluation/MinReturn                  -1236.47
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    143.328
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41673
GaussianMLPPolicy/KL                      2.68637e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -376.24
GaussianMLPPolicy/LossBefore           -376.212
GaussianMLPPolicy/dLoss                   0.0281372
GaussianMLPValueFunction/LossAfter    28019.1
GaussianMLPValueFunction/LossBefore   28058.9
GaussianMLPValueFunction/dLoss           39.7227
TotalEnvSteps                        342000
-----------------------------------  ----------------
2022-08-17 17:56:38 | [trpo_pendulum] epoch #285 | Saving snapshot...
2022-08-17 17:56:38 | [trpo_pendulum] epoch #285 | Saved
2022-08-17 17:56:38 | [trpo_pendulum] epoch #285 | Time 118.33 s
2022-08-17 17:56:38 | [trpo_pendulum] epoch #285 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -724.003
Evaluation/AverageReturn              -1671.13
Evaluation/Iteration                    285
Evaluation/MaxReturn                  -1528.02
Evaluation/MinReturn                  -1819.65
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    114.813
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41695
GaussianMLPPolicy/KL                      2.07536e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -634.802
GaussianMLPPolicy/LossBefore           -634.698
GaussianMLPPolicy/dLoss                   0.104126
GaussianMLPValueFunction/LossAfter    85598
GaussianMLPValueFunction/LossBefore   85707.8
GaussianMLPValueFunction/dLoss          109.789
TotalEnvSteps                        343200
-----------------------------------  ----------------
2022-08-17 17:56:38 | [trpo_pendulum] epoch #286 | Saving snapshot...
2022-08-17 17:56:38 | [trpo_pendulum] epoch #286 | Saved
2022-08-17 17:56:38 | [trpo_pendulum] epoch #286 | Time 118.73 s
2022-08-17 17:56:38 | [trpo_pendulum] epoch #286 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -701.716
Evaluation/AverageReturn              -1652.2
Evaluation/Iteration                    286
Evaluation/MaxReturn                  -1590.47
Evaluation/MinReturn                  -1695.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     44.2306
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41721
GaussianMLPPolicy/KL                      9.00788e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -653.299
GaussianMLPPolicy/LossBefore           -653.311
GaussianMLPPolicy/dLoss                  -0.0114746
GaussianMLPValueFunction/LossAfter    85031.5
GaussianMLPValueFunction/LossBefore   85146.2
GaussianMLPValueFunction/dLoss          114.68
TotalEnvSteps                        344400
-----------------------------------  ----------------
2022-08-17 17:56:39 | [trpo_pendulum] epoch #287 | Saving snapshot...
2022-08-17 17:56:39 | [trpo_pendulum] epoch #287 | Saved
2022-08-17 17:56:39 | [trpo_pendulum] epoch #287 | Time 119.15 s
2022-08-17 17:56:39 | [trpo_pendulum] epoch #287 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -738.235
Evaluation/AverageReturn              -1726.83
Evaluation/Iteration                    287
Evaluation/MaxReturn                  -1680.74
Evaluation/MinReturn                  -1767.13
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     34.2048
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41729
GaussianMLPPolicy/KL                      1.54038e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -698.171
GaussianMLPPolicy/LossBefore           -698.031
GaussianMLPPolicy/dLoss                   0.140137
GaussianMLPValueFunction/LossAfter    92240.1
GaussianMLPValueFunction/LossBefore   92370.6
GaussianMLPValueFunction/dLoss          130.547
TotalEnvSteps                        345600
-----------------------------------  ----------------
2022-08-17 17:56:39 | [trpo_pendulum] epoch #288 | Saving snapshot...
2022-08-17 17:56:39 | [trpo_pendulum] epoch #288 | Saved
2022-08-17 17:56:39 | [trpo_pendulum] epoch #288 | Time 119.55 s
2022-08-17 17:56:39 | [trpo_pendulum] epoch #288 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -635.303
Evaluation/AverageReturn              -1504.57
Evaluation/Iteration                    288
Evaluation/MaxReturn                  -1396.76
Evaluation/MinReturn                  -1569.83
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     64.1162
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41734
GaussianMLPPolicy/KL                      1.67799e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -601.159
GaussianMLPPolicy/LossBefore           -601.083
GaussianMLPPolicy/dLoss                   0.0751953
GaussianMLPValueFunction/LossAfter    70263.5
GaussianMLPValueFunction/LossBefore   70366
GaussianMLPValueFunction/dLoss          102.453
TotalEnvSteps                        346800
-----------------------------------  ----------------
2022-08-17 17:56:40 | [trpo_pendulum] epoch #289 | Saving snapshot...
2022-08-17 17:56:40 | [trpo_pendulum] epoch #289 | Saved
2022-08-17 17:56:40 | [trpo_pendulum] epoch #289 | Time 119.96 s
2022-08-17 17:56:40 | [trpo_pendulum] epoch #289 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -406.564
Evaluation/AverageReturn               -945.215
Evaluation/Iteration                    289
Evaluation/MaxReturn                   -872.674
Evaluation/MinReturn                   -988.578
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     43.0298
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4174
GaussianMLPPolicy/KL                      5.23356e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -366.551
GaussianMLPPolicy/LossBefore           -366.516
GaussianMLPPolicy/dLoss                   0.0344849
GaussianMLPValueFunction/LossAfter    26651
GaussianMLPValueFunction/LossBefore   26692.5
GaussianMLPValueFunction/dLoss           41.4102
TotalEnvSteps                        348000
-----------------------------------  ----------------
2022-08-17 17:56:40 | [trpo_pendulum] epoch #290 | Saving snapshot...
2022-08-17 17:56:40 | [trpo_pendulum] epoch #290 | Saved
2022-08-17 17:56:40 | [trpo_pendulum] epoch #290 | Time 120.38 s
2022-08-17 17:56:40 | [trpo_pendulum] epoch #290 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -694.758
Evaluation/AverageReturn              -1647.97
Evaluation/Iteration                    290
Evaluation/MaxReturn                  -1578.17
Evaluation/MinReturn                  -1725.29
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     55.1136
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41745
GaussianMLPPolicy/KL                      5.68751e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -660.174
GaussianMLPPolicy/LossBefore           -659.703
GaussianMLPPolicy/dLoss                   0.471252
GaussianMLPValueFunction/LossAfter    84800.2
GaussianMLPValueFunction/LossBefore   84920.6
GaussianMLPValueFunction/dLoss          120.453
TotalEnvSteps                        349200
-----------------------------------  ----------------
2022-08-17 17:56:40 | [trpo_pendulum] epoch #291 | Saving snapshot...
2022-08-17 17:56:40 | [trpo_pendulum] epoch #291 | Saved
2022-08-17 17:56:40 | [trpo_pendulum] epoch #291 | Time 120.79 s
2022-08-17 17:56:40 | [trpo_pendulum] epoch #291 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -432.049
Evaluation/AverageReturn               -982.048
Evaluation/Iteration                    291
Evaluation/MaxReturn                   -781.191
Evaluation/MinReturn                  -1070.02
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     98.4218
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41757
GaussianMLPPolicy/KL                      4.04409e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -368.479
GaussianMLPPolicy/LossBefore           -368.508
GaussianMLPPolicy/dLoss                  -0.0285645
GaussianMLPValueFunction/LossAfter    28691.1
GaussianMLPValueFunction/LossBefore   28734
GaussianMLPValueFunction/dLoss           42.916
TotalEnvSteps                        350400
-----------------------------------  ----------------
2022-08-17 17:56:41 | [trpo_pendulum] epoch #292 | Saving snapshot...
2022-08-17 17:56:41 | [trpo_pendulum] epoch #292 | Saved
2022-08-17 17:56:41 | [trpo_pendulum] epoch #292 | Time 121.21 s
2022-08-17 17:56:41 | [trpo_pendulum] epoch #292 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -405.785
Evaluation/AverageReturn               -934.7
Evaluation/Iteration                    292
Evaluation/MaxReturn                   -763.683
Evaluation/MinReturn                  -1067.17
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    121.33
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41759
GaussianMLPPolicy/KL                      5.52608e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -366.836
GaussianMLPPolicy/LossBefore           -366.782
GaussianMLPPolicy/dLoss                   0.0532837
GaussianMLPValueFunction/LossAfter    26290
GaussianMLPValueFunction/LossBefore   26328.2
GaussianMLPValueFunction/dLoss           38.1953
TotalEnvSteps                        351600
-----------------------------------  ----------------
2022-08-17 17:56:41 | [trpo_pendulum] epoch #293 | Saving snapshot...
2022-08-17 17:56:41 | [trpo_pendulum] epoch #293 | Saved
2022-08-17 17:56:41 | [trpo_pendulum] epoch #293 | Time 121.62 s
2022-08-17 17:56:41 | [trpo_pendulum] epoch #293 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -594.728
Evaluation/AverageReturn              -1390.47
Evaluation/Iteration                    293
Evaluation/MaxReturn                  -1312.88
Evaluation/MinReturn                  -1532.2
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     71.6267
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41769
GaussianMLPPolicy/KL                      9.16977e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -540.551
GaussianMLPPolicy/LossBefore           -540.407
GaussianMLPPolicy/dLoss                   0.144531
GaussianMLPValueFunction/LossAfter    59097
GaussianMLPValueFunction/LossBefore   59175.1
GaussianMLPValueFunction/dLoss           78.0469
TotalEnvSteps                        352800
-----------------------------------  ----------------
2022-08-17 17:56:42 | [trpo_pendulum] epoch #294 | Saving snapshot...
2022-08-17 17:56:42 | [trpo_pendulum] epoch #294 | Saved
2022-08-17 17:56:42 | [trpo_pendulum] epoch #294 | Time 122.02 s
2022-08-17 17:56:42 | [trpo_pendulum] epoch #294 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -620.151
Evaluation/AverageReturn              -1433.54
Evaluation/Iteration                    294
Evaluation/MaxReturn                  -1280.76
Evaluation/MinReturn                  -1555.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     92.7674
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41789
GaussianMLPPolicy/KL                      6.84871e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -549.66
GaussianMLPPolicy/LossBefore           -549.585
GaussianMLPPolicy/dLoss                   0.074585
GaussianMLPValueFunction/LossAfter    61629.2
GaussianMLPValueFunction/LossBefore   61711.2
GaussianMLPValueFunction/dLoss           82.0273
TotalEnvSteps                        354000
-----------------------------------  ----------------
2022-08-17 17:56:42 | [trpo_pendulum] epoch #295 | Saving snapshot...
2022-08-17 17:56:42 | [trpo_pendulum] epoch #295 | Saved
2022-08-17 17:56:42 | [trpo_pendulum] epoch #295 | Time 122.45 s
2022-08-17 17:56:42 | [trpo_pendulum] epoch #295 | EpochTime 0.43 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -609.596
Evaluation/AverageReturn              -1430.29
Evaluation/Iteration                    295
Evaluation/MaxReturn                  -1273.26
Evaluation/MinReturn                  -1621.49
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    127.214
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41799
GaussianMLPPolicy/KL                      5.2462e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -572.127
GaussianMLPPolicy/LossBefore           -572.13
GaussianMLPPolicy/dLoss                  -0.00262451
GaussianMLPValueFunction/LossAfter    62854
GaussianMLPValueFunction/LossBefore   62938.6
GaussianMLPValueFunction/dLoss           84.6094
TotalEnvSteps                        355200
-----------------------------------  ---------------
2022-08-17 17:56:42 | [trpo_pendulum] epoch #296 | Saving snapshot...
2022-08-17 17:56:43 | [trpo_pendulum] epoch #296 | Saved
2022-08-17 17:56:43 | [trpo_pendulum] epoch #296 | Time 122.86 s
2022-08-17 17:56:43 | [trpo_pendulum] epoch #296 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -402.427
Evaluation/AverageReturn               -929.801
Evaluation/Iteration                    296
Evaluation/MaxReturn                   -855.392
Evaluation/MinReturn                  -1045.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     74.2722
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41808
GaussianMLPPolicy/KL                      7.10536e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -359.512
GaussianMLPPolicy/LossBefore           -359.329
GaussianMLPPolicy/dLoss                   0.182587
GaussianMLPValueFunction/LossAfter    25394.9
GaussianMLPValueFunction/LossBefore   25431.8
GaussianMLPValueFunction/dLoss           36.8633
TotalEnvSteps                        356400
-----------------------------------  ----------------
2022-08-17 17:56:43 | [trpo_pendulum] epoch #297 | Saving snapshot...
2022-08-17 17:56:43 | [trpo_pendulum] epoch #297 | Saved
2022-08-17 17:56:43 | [trpo_pendulum] epoch #297 | Time 123.27 s
2022-08-17 17:56:43 | [trpo_pendulum] epoch #297 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -450.632
Evaluation/AverageReturn              -1029.35
Evaluation/Iteration                    297
Evaluation/MaxReturn                   -947.226
Evaluation/MinReturn                  -1068.17
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     51.9285
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41808
GaussianMLPPolicy/KL                      0.000173696
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -402.974
GaussianMLPPolicy/LossBefore           -402.672
GaussianMLPPolicy/dLoss                   0.302551
GaussianMLPValueFunction/LossAfter    31142.4
GaussianMLPValueFunction/LossBefore   31184.3
GaussianMLPValueFunction/dLoss           41.8828
TotalEnvSteps                        357600
-----------------------------------  ----------------
2022-08-17 17:56:43 | [trpo_pendulum] epoch #298 | Saving snapshot...
2022-08-17 17:56:43 | [trpo_pendulum] epoch #298 | Saved
2022-08-17 17:56:43 | [trpo_pendulum] epoch #298 | Time 123.68 s
2022-08-17 17:56:43 | [trpo_pendulum] epoch #298 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -390.683
Evaluation/AverageReturn               -881.231
Evaluation/Iteration                    298
Evaluation/MaxReturn                   -743.059
Evaluation/MinReturn                   -994.281
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     79.2248
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41808
GaussianMLPPolicy/KL                      0.000277577
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -332.561
GaussianMLPPolicy/LossBefore           -332.294
GaussianMLPPolicy/dLoss                   0.266907
GaussianMLPValueFunction/LossAfter    22871.9
GaussianMLPValueFunction/LossBefore   22903
GaussianMLPValueFunction/dLoss           31.0723
TotalEnvSteps                        358800
-----------------------------------  ----------------
2022-08-17 17:56:44 | [trpo_pendulum] epoch #299 | Saving snapshot...
2022-08-17 17:56:44 | [trpo_pendulum] epoch #299 | Saved
2022-08-17 17:56:44 | [trpo_pendulum] epoch #299 | Time 124.10 s
2022-08-17 17:56:44 | [trpo_pendulum] epoch #299 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -395.249
Evaluation/AverageReturn               -943.114
Evaluation/Iteration                    299
Evaluation/MaxReturn                   -858.082
Evaluation/MinReturn                  -1034.52
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     78.1112
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41809
GaussianMLPPolicy/KL                      0.000564889
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -373.135
GaussianMLPPolicy/LossBefore           -372.516
GaussianMLPPolicy/dLoss                   0.618683
GaussianMLPValueFunction/LossAfter    27244.2
GaussianMLPValueFunction/LossBefore   27279.9
GaussianMLPValueFunction/dLoss           35.6738
TotalEnvSteps                        360000
-----------------------------------  ----------------
2022-08-17 17:56:44 | [trpo_pendulum] epoch #300 | Saving snapshot...
2022-08-17 17:56:44 | [trpo_pendulum] epoch #300 | Saved
2022-08-17 17:56:44 | [trpo_pendulum] epoch #300 | Time 124.53 s
2022-08-17 17:56:44 | [trpo_pendulum] epoch #300 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -689.418
Evaluation/AverageReturn              -1633.26
Evaluation/Iteration                    300
Evaluation/MaxReturn                  -1529.44
Evaluation/MinReturn                  -1715.28
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     69.4365
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41811
GaussianMLPPolicy/KL                      6.40874e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -650.932
GaussianMLPPolicy/LossBefore           -651.097
GaussianMLPPolicy/dLoss                  -0.165771
GaussianMLPValueFunction/LossAfter    82333
GaussianMLPValueFunction/LossBefore   82429.8
GaussianMLPValueFunction/dLoss           96.8594
TotalEnvSteps                        361200
-----------------------------------  ----------------
2022-08-17 17:56:45 | [trpo_pendulum] epoch #301 | Saving snapshot...
2022-08-17 17:56:45 | [trpo_pendulum] epoch #301 | Saved
2022-08-17 17:56:45 | [trpo_pendulum] epoch #301 | Time 124.94 s
2022-08-17 17:56:45 | [trpo_pendulum] epoch #301 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -451.047
Evaluation/AverageReturn              -1071.4
Evaluation/Iteration                    301
Evaluation/MaxReturn                   -748.876
Evaluation/MinReturn                  -1197.45
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    153.128
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41818
GaussianMLPPolicy/KL                      0.000183402
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -419.474
GaussianMLPPolicy/LossBefore           -419.402
GaussianMLPPolicy/dLoss                   0.0718689
GaussianMLPValueFunction/LossAfter    35615.2
GaussianMLPValueFunction/LossBefore   35660
GaussianMLPValueFunction/dLoss           44.7305
TotalEnvSteps                        362400
-----------------------------------  ----------------
2022-08-17 17:56:45 | [trpo_pendulum] epoch #302 | Saving snapshot...
2022-08-17 17:56:45 | [trpo_pendulum] epoch #302 | Saved
2022-08-17 17:56:45 | [trpo_pendulum] epoch #302 | Time 125.34 s
2022-08-17 17:56:45 | [trpo_pendulum] epoch #302 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -384.392
Evaluation/AverageReturn               -986.962
Evaluation/Iteration                    302
Evaluation/MaxReturn                   -875.271
Evaluation/MinReturn                  -1065.47
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     61.7435
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41836
GaussianMLPPolicy/KL                      6.02434e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -399.962
GaussianMLPPolicy/LossBefore           -400.024
GaussianMLPPolicy/dLoss                  -0.0625
GaussianMLPValueFunction/LossAfter    32509.7
GaussianMLPValueFunction/LossBefore   32551.4
GaussianMLPValueFunction/dLoss           41.7617
TotalEnvSteps                        363600
-----------------------------------  ----------------
2022-08-17 17:56:45 | [trpo_pendulum] epoch #303 | Saving snapshot...
2022-08-17 17:56:45 | [trpo_pendulum] epoch #303 | Saved
2022-08-17 17:56:45 | [trpo_pendulum] epoch #303 | Time 125.75 s
2022-08-17 17:56:45 | [trpo_pendulum] epoch #303 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -784.11
Evaluation/AverageReturn              -1805.7
Evaluation/Iteration                    303
Evaluation/MaxReturn                  -1732.29
Evaluation/MinReturn                  -1842.85
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     39.4485
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41865
GaussianMLPPolicy/KL                      2.04814e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -696.485
GaussianMLPPolicy/LossBefore           -696.338
GaussianMLPPolicy/dLoss                   0.147156
GaussianMLPValueFunction/LossAfter    97439.2
GaussianMLPValueFunction/LossBefore   97557.2
GaussianMLPValueFunction/dLoss          118.016
TotalEnvSteps                        364800
-----------------------------------  ----------------
2022-08-17 17:56:46 | [trpo_pendulum] epoch #304 | Saving snapshot...
2022-08-17 17:56:46 | [trpo_pendulum] epoch #304 | Saved
2022-08-17 17:56:46 | [trpo_pendulum] epoch #304 | Time 126.16 s
2022-08-17 17:56:46 | [trpo_pendulum] epoch #304 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -607.788
Evaluation/AverageReturn              -1449.77
Evaluation/Iteration                    304
Evaluation/MaxReturn                  -1335.45
Evaluation/MinReturn                  -1571.89
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     83.2458
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41872
GaussianMLPPolicy/KL                      6.87968e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -598.221
GaussianMLPPolicy/LossBefore           -597.99
GaussianMLPPolicy/dLoss                   0.231079
GaussianMLPValueFunction/LossAfter    64317.9
GaussianMLPValueFunction/LossBefore   64399.9
GaussianMLPValueFunction/dLoss           81.9648
TotalEnvSteps                        366000
-----------------------------------  ----------------
2022-08-17 17:56:46 | [trpo_pendulum] epoch #305 | Saving snapshot...
2022-08-17 17:56:46 | [trpo_pendulum] epoch #305 | Saved
2022-08-17 17:56:46 | [trpo_pendulum] epoch #305 | Time 126.57 s
2022-08-17 17:56:46 | [trpo_pendulum] epoch #305 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -416.628
Evaluation/AverageReturn              -1008.79
Evaluation/Iteration                    305
Evaluation/MaxReturn                   -849.204
Evaluation/MinReturn                  -1185.97
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    108.344
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41865
GaussianMLPPolicy/KL                      0.000244311
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -415.577
GaussianMLPPolicy/LossBefore           -415.227
GaussianMLPPolicy/dLoss                   0.350342
GaussianMLPValueFunction/LossAfter    31113.7
GaussianMLPValueFunction/LossBefore   31156.2
GaussianMLPValueFunction/dLoss           42.4766
TotalEnvSteps                        367200
-----------------------------------  ----------------
2022-08-17 17:56:47 | [trpo_pendulum] epoch #306 | Saving snapshot...
2022-08-17 17:56:47 | [trpo_pendulum] epoch #306 | Saved
2022-08-17 17:56:47 | [trpo_pendulum] epoch #306 | Time 126.99 s
2022-08-17 17:56:47 | [trpo_pendulum] epoch #306 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -387.246
Evaluation/AverageReturn              -1037.42
Evaluation/Iteration                    306
Evaluation/MaxReturn                   -962.085
Evaluation/MinReturn                  -1196.27
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     83.0236
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41868
GaussianMLPPolicy/KL                      5.28625e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -435.587
GaussianMLPPolicy/LossBefore           -435.692
GaussianMLPPolicy/dLoss                  -0.104797
GaussianMLPValueFunction/LossAfter    37237.2
GaussianMLPValueFunction/LossBefore   37285.8
GaussianMLPValueFunction/dLoss           48.5625
TotalEnvSteps                        368400
-----------------------------------  ----------------
2022-08-17 17:56:47 | [trpo_pendulum] epoch #307 | Saving snapshot...
2022-08-17 17:56:47 | [trpo_pendulum] epoch #307 | Saved
2022-08-17 17:56:47 | [trpo_pendulum] epoch #307 | Time 127.40 s
2022-08-17 17:56:47 | [trpo_pendulum] epoch #307 | EpochTime 0.41 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -697.22
Evaluation/AverageReturn              -1652.73
Evaluation/Iteration                    307
Evaluation/MaxReturn                  -1552.91
Evaluation/MinReturn                  -1740.33
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     63.5807
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4187
GaussianMLPPolicy/KL                      6.872e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -661.631
GaussianMLPPolicy/LossBefore           -661.326
GaussianMLPPolicy/dLoss                   0.304749
GaussianMLPValueFunction/LossAfter    83381.9
GaussianMLPValueFunction/LossBefore   83486.2
GaussianMLPValueFunction/dLoss          104.273
TotalEnvSteps                        369600
-----------------------------------  --------------
2022-08-17 17:56:47 | [trpo_pendulum] epoch #308 | Saving snapshot...
2022-08-17 17:56:47 | [trpo_pendulum] epoch #308 | Saved
2022-08-17 17:56:47 | [trpo_pendulum] epoch #308 | Time 127.81 s
2022-08-17 17:56:47 | [trpo_pendulum] epoch #308 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -558.141
Evaluation/AverageReturn              -1360.55
Evaluation/Iteration                    308
Evaluation/MaxReturn                  -1284.6
Evaluation/MinReturn                  -1454.65
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     58.1893
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4188
GaussianMLPPolicy/KL                      7.84075e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -543.472
GaussianMLPPolicy/LossBefore           -543.457
GaussianMLPPolicy/dLoss                   0.0148926
GaussianMLPValueFunction/LossAfter    57365.5
GaussianMLPValueFunction/LossBefore   57440.1
GaussianMLPValueFunction/dLoss           74.5898
TotalEnvSteps                        370800
-----------------------------------  ----------------
2022-08-17 17:56:48 | [trpo_pendulum] epoch #309 | Saving snapshot...
2022-08-17 17:56:48 | [trpo_pendulum] epoch #309 | Saved
2022-08-17 17:56:48 | [trpo_pendulum] epoch #309 | Time 128.22 s
2022-08-17 17:56:48 | [trpo_pendulum] epoch #309 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -411.363
Evaluation/AverageReturn              -1023.18
Evaluation/Iteration                    309
Evaluation/MaxReturn                   -871.899
Evaluation/MinReturn                  -1178.05
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    109.39
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41894
GaussianMLPPolicy/KL                      0.000237496
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -413.779
GaussianMLPPolicy/LossBefore           -413.412
GaussianMLPPolicy/dLoss                   0.366882
GaussianMLPValueFunction/LossAfter    33058.2
GaussianMLPValueFunction/LossBefore   33103.2
GaussianMLPValueFunction/dLoss           44.9688
TotalEnvSteps                        372000
-----------------------------------  ----------------
2022-08-17 17:56:48 | [trpo_pendulum] epoch #310 | Saving snapshot...
2022-08-17 17:56:48 | [trpo_pendulum] epoch #310 | Saved
2022-08-17 17:56:48 | [trpo_pendulum] epoch #310 | Time 128.63 s
2022-08-17 17:56:48 | [trpo_pendulum] epoch #310 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -786.14
Evaluation/AverageReturn              -1809.69
Evaluation/Iteration                    310
Evaluation/MaxReturn                  -1755.02
Evaluation/MinReturn                  -1845.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     28.6113
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41901
GaussianMLPPolicy/KL                      5.7691e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -714.49
GaussianMLPPolicy/LossBefore           -714.289
GaussianMLPPolicy/dLoss                   0.200867
GaussianMLPValueFunction/LossAfter    97056.4
GaussianMLPValueFunction/LossBefore   97183.3
GaussianMLPValueFunction/dLoss          126.953
TotalEnvSteps                        373200
-----------------------------------  ---------------
2022-08-17 17:56:49 | [trpo_pendulum] epoch #311 | Saving snapshot...
2022-08-17 17:56:49 | [trpo_pendulum] epoch #311 | Saved
2022-08-17 17:56:49 | [trpo_pendulum] epoch #311 | Time 129.05 s
2022-08-17 17:56:49 | [trpo_pendulum] epoch #311 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -761.799
Evaluation/AverageReturn              -1770.16
Evaluation/Iteration                    311
Evaluation/MaxReturn                  -1733.38
Evaluation/MinReturn                  -1811.91
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     24.8888
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41922
GaussianMLPPolicy/KL                      5.4558e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -685.693
GaussianMLPPolicy/LossBefore           -685.532
GaussianMLPPolicy/dLoss                   0.161072
GaussianMLPValueFunction/LossAfter    93188.9
GaussianMLPValueFunction/LossBefore   93318.9
GaussianMLPValueFunction/dLoss          129.93
TotalEnvSteps                        374400
-----------------------------------  ---------------
2022-08-17 17:56:49 | [trpo_pendulum] epoch #312 | Saving snapshot...
2022-08-17 17:56:49 | [trpo_pendulum] epoch #312 | Saved
2022-08-17 17:56:49 | [trpo_pendulum] epoch #312 | Time 129.46 s
2022-08-17 17:56:49 | [trpo_pendulum] epoch #312 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -640.451
Evaluation/AverageReturn              -1570.77
Evaluation/Iteration                    312
Evaluation/MaxReturn                  -1491
Evaluation/MinReturn                  -1676.07
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     69.0357
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41948
GaussianMLPPolicy/KL                      8.69071e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -636.568
GaussianMLPPolicy/LossBefore           -636.42
GaussianMLPPolicy/dLoss                   0.148743
GaussianMLPValueFunction/LossAfter    77572.5
GaussianMLPValueFunction/LossBefore   77685.2
GaussianMLPValueFunction/dLoss          112.625
TotalEnvSteps                        375600
-----------------------------------  ----------------
2022-08-17 17:56:50 | [trpo_pendulum] epoch #313 | Saving snapshot...
2022-08-17 17:56:50 | [trpo_pendulum] epoch #313 | Saved
2022-08-17 17:56:50 | [trpo_pendulum] epoch #313 | Time 129.87 s
2022-08-17 17:56:50 | [trpo_pendulum] epoch #313 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -526.198
Evaluation/AverageReturn              -1339.1
Evaluation/Iteration                    313
Evaluation/MaxReturn                  -1258.84
Evaluation/MinReturn                  -1476.02
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     67.9929
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41991
GaussianMLPPolicy/KL                      4.9621e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -540.742
GaussianMLPPolicy/LossBefore           -540.466
GaussianMLPPolicy/dLoss                   0.276123
GaussianMLPValueFunction/LossAfter    57988.5
GaussianMLPValueFunction/LossBefore   58074.4
GaussianMLPValueFunction/dLoss           85.875
TotalEnvSteps                        376800
-----------------------------------  ---------------
2022-08-17 17:56:50 | [trpo_pendulum] epoch #314 | Saving snapshot...
2022-08-17 17:56:50 | [trpo_pendulum] epoch #314 | Saved
2022-08-17 17:56:50 | [trpo_pendulum] epoch #314 | Time 130.28 s
2022-08-17 17:56:50 | [trpo_pendulum] epoch #314 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -349.259
Evaluation/AverageReturn               -979.799
Evaluation/Iteration                    314
Evaluation/MaxReturn                   -846.042
Evaluation/MinReturn                  -1100.51
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     91.2205
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42033
GaussianMLPPolicy/KL                      1.1953e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -427.677
GaussianMLPPolicy/LossBefore           -427.634
GaussianMLPPolicy/dLoss                   0.0427246
GaussianMLPValueFunction/LossAfter    34299.5
GaussianMLPValueFunction/LossBefore   34351.7
GaussianMLPValueFunction/dLoss           52.1172
TotalEnvSteps                        378000
-----------------------------------  ---------------
2022-08-17 17:56:50 | [trpo_pendulum] epoch #315 | Saving snapshot...
2022-08-17 17:56:50 | [trpo_pendulum] epoch #315 | Saved
2022-08-17 17:56:50 | [trpo_pendulum] epoch #315 | Time 130.70 s
2022-08-17 17:56:50 | [trpo_pendulum] epoch #315 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -482.726
Evaluation/AverageReturn              -1214.15
Evaluation/Iteration                    315
Evaluation/MaxReturn                  -1075.32
Evaluation/MinReturn                  -1387.25
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    100.56
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42074
GaussianMLPPolicy/KL                      1.32779e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -498.477
GaussianMLPPolicy/LossBefore           -498.453
GaussianMLPPolicy/dLoss                   0.0238037
GaussianMLPValueFunction/LossAfter    46849.9
GaussianMLPValueFunction/LossBefore   46916.9
GaussianMLPValueFunction/dLoss           66.9688
TotalEnvSteps                        379200
-----------------------------------  ----------------
2022-08-17 17:56:51 | [trpo_pendulum] epoch #316 | Saving snapshot...
2022-08-17 17:56:51 | [trpo_pendulum] epoch #316 | Saved
2022-08-17 17:56:51 | [trpo_pendulum] epoch #316 | Time 131.10 s
2022-08-17 17:56:51 | [trpo_pendulum] epoch #316 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -541.587
Evaluation/AverageReturn              -1350.22
Evaluation/Iteration                    316
Evaluation/MaxReturn                  -1271.4
Evaluation/MinReturn                  -1485.34
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     80.076
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42109
GaussianMLPPolicy/KL                      3.0975e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -558.355
GaussianMLPPolicy/LossBefore           -558.233
GaussianMLPPolicy/dLoss                   0.122192
GaussianMLPValueFunction/LossAfter    57350.5
GaussianMLPValueFunction/LossBefore   57430.8
GaussianMLPValueFunction/dLoss           80.293
TotalEnvSteps                        380400
-----------------------------------  ---------------
2022-08-17 17:56:51 | [trpo_pendulum] epoch #317 | Saving snapshot...
2022-08-17 17:56:51 | [trpo_pendulum] epoch #317 | Saved
2022-08-17 17:56:51 | [trpo_pendulum] epoch #317 | Time 131.51 s
2022-08-17 17:56:51 | [trpo_pendulum] epoch #317 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -743.105
Evaluation/AverageReturn              -1744.63
Evaluation/Iteration                    317
Evaluation/MaxReturn                  -1708.96
Evaluation/MinReturn                  -1782.83
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     22.7301
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4213
GaussianMLPPolicy/KL                      3.73576e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -704.341
GaussianMLPPolicy/LossBefore           -704.324
GaussianMLPPolicy/dLoss                   0.0167236
GaussianMLPValueFunction/LossAfter    90841.1
GaussianMLPValueFunction/LossBefore   90970.6
GaussianMLPValueFunction/dLoss          129.516
TotalEnvSteps                        381600
-----------------------------------  ----------------
2022-08-17 17:56:52 | [trpo_pendulum] epoch #318 | Saving snapshot...
2022-08-17 17:56:52 | [trpo_pendulum] epoch #318 | Saved
2022-08-17 17:56:52 | [trpo_pendulum] epoch #318 | Time 131.91 s
2022-08-17 17:56:52 | [trpo_pendulum] epoch #318 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -540.816
Evaluation/AverageReturn              -1337.22
Evaluation/Iteration                    318
Evaluation/MaxReturn                  -1206.31
Evaluation/MinReturn                  -1417.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     68.1369
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42141
GaussianMLPPolicy/KL                      1.83382e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -553.688
GaussianMLPPolicy/LossBefore           -553.686
GaussianMLPPolicy/dLoss                   0.00201416
GaussianMLPValueFunction/LossAfter    55294.2
GaussianMLPValueFunction/LossBefore   55375.3
GaussianMLPValueFunction/dLoss           81.125
TotalEnvSteps                        382800
-----------------------------------  ----------------
2022-08-17 17:56:52 | [trpo_pendulum] epoch #319 | Saving snapshot...
2022-08-17 17:56:52 | [trpo_pendulum] epoch #319 | Saved
2022-08-17 17:56:52 | [trpo_pendulum] epoch #319 | Time 132.32 s
2022-08-17 17:56:52 | [trpo_pendulum] epoch #319 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -491.629
Evaluation/AverageReturn              -1236.03
Evaluation/Iteration                    319
Evaluation/MaxReturn                  -1065.11
Evaluation/MinReturn                  -1327.86
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     88.6503
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42165
GaussianMLPPolicy/KL                      2.43582e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -499.588
GaussianMLPPolicy/LossBefore           -499.519
GaussianMLPPolicy/dLoss                   0.0690918
GaussianMLPValueFunction/LossAfter    48419.4
GaussianMLPValueFunction/LossBefore   48490.2
GaussianMLPValueFunction/dLoss           70.8633
TotalEnvSteps                        384000
-----------------------------------  ----------------
2022-08-17 17:56:52 | [trpo_pendulum] epoch #320 | Saving snapshot...
2022-08-17 17:56:52 | [trpo_pendulum] epoch #320 | Saved
2022-08-17 17:56:52 | [trpo_pendulum] epoch #320 | Time 132.73 s
2022-08-17 17:56:52 | [trpo_pendulum] epoch #320 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -527.047
Evaluation/AverageReturn              -1301.61
Evaluation/Iteration                    320
Evaluation/MaxReturn                  -1144.28
Evaluation/MinReturn                  -1446.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     93.9912
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42184
GaussianMLPPolicy/KL                      1.3987e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -533.474
GaussianMLPPolicy/LossBefore           -533.434
GaussianMLPPolicy/dLoss                   0.0403442
GaussianMLPValueFunction/LossAfter    52400.2
GaussianMLPValueFunction/LossBefore   52475.5
GaussianMLPValueFunction/dLoss           75.2188
TotalEnvSteps                        385200
-----------------------------------  ---------------
2022-08-17 17:56:53 | [trpo_pendulum] epoch #321 | Saving snapshot...
2022-08-17 17:56:53 | [trpo_pendulum] epoch #321 | Saved
2022-08-17 17:56:53 | [trpo_pendulum] epoch #321 | Time 133.14 s
2022-08-17 17:56:53 | [trpo_pendulum] epoch #321 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -599.86
Evaluation/AverageReturn              -1456.09
Evaluation/Iteration                    321
Evaluation/MaxReturn                  -1326.32
Evaluation/MinReturn                  -1620.18
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     98.4014
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42209
GaussianMLPPolicy/KL                      1.4101e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -584.161
GaussianMLPPolicy/LossBefore           -584.094
GaussianMLPPolicy/dLoss                   0.0666504
GaussianMLPValueFunction/LossAfter    65114.5
GaussianMLPValueFunction/LossBefore   65207.2
GaussianMLPValueFunction/dLoss           92.6836
TotalEnvSteps                        386400
-----------------------------------  ---------------
2022-08-17 17:56:53 | [trpo_pendulum] epoch #322 | Saving snapshot...
2022-08-17 17:56:53 | [trpo_pendulum] epoch #322 | Saved
2022-08-17 17:56:53 | [trpo_pendulum] epoch #322 | Time 133.55 s
2022-08-17 17:56:53 | [trpo_pendulum] epoch #322 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -575.937
Evaluation/AverageReturn              -1415.15
Evaluation/Iteration                    322
Evaluation/MaxReturn                  -1325.96
Evaluation/MinReturn                  -1515.73
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     67.246
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42235
GaussianMLPPolicy/KL                      6.05299e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -574.379
GaussianMLPPolicy/LossBefore           -574.368
GaussianMLPPolicy/dLoss                   0.0112915
GaussianMLPValueFunction/LossAfter    61575.8
GaussianMLPValueFunction/LossBefore   61664.4
GaussianMLPValueFunction/dLoss           88.5664
TotalEnvSteps                        387600
-----------------------------------  ----------------
2022-08-17 17:56:54 | [trpo_pendulum] epoch #323 | Saving snapshot...
2022-08-17 17:56:54 | [trpo_pendulum] epoch #323 | Saved
2022-08-17 17:56:54 | [trpo_pendulum] epoch #323 | Time 133.96 s
2022-08-17 17:56:54 | [trpo_pendulum] epoch #323 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -499.314
Evaluation/AverageReturn              -1249.67
Evaluation/Iteration                    323
Evaluation/MaxReturn                  -1060.2
Evaluation/MinReturn                  -1351.07
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    104.414
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42258
GaussianMLPPolicy/KL                      3.69109e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -515.846
GaussianMLPPolicy/LossBefore           -515.833
GaussianMLPPolicy/dLoss                   0.0126953
GaussianMLPValueFunction/LossAfter    49028.5
GaussianMLPValueFunction/LossBefore   49099.4
GaussianMLPValueFunction/dLoss           70.918
TotalEnvSteps                        388800
-----------------------------------  ----------------
2022-08-17 17:56:54 | [trpo_pendulum] epoch #324 | Saving snapshot...
2022-08-17 17:56:54 | [trpo_pendulum] epoch #324 | Saved
2022-08-17 17:56:54 | [trpo_pendulum] epoch #324 | Time 134.37 s
2022-08-17 17:56:54 | [trpo_pendulum] epoch #324 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -412.986
Evaluation/AverageReturn              -1057.58
Evaluation/Iteration                    324
Evaluation/MaxReturn                   -881.327
Evaluation/MinReturn                  -1195.69
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    105.859
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42286
GaussianMLPPolicy/KL                      2.13176e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -434.278
GaussianMLPPolicy/LossBefore           -434.184
GaussianMLPPolicy/dLoss                   0.0932007
GaussianMLPValueFunction/LossAfter    36051.2
GaussianMLPValueFunction/LossBefore   36103.4
GaussianMLPValueFunction/dLoss           52.125
TotalEnvSteps                        390000
-----------------------------------  ----------------
2022-08-17 17:56:54 | [trpo_pendulum] epoch #325 | Saving snapshot...
2022-08-17 17:56:54 | [trpo_pendulum] epoch #325 | Saved
2022-08-17 17:56:54 | [trpo_pendulum] epoch #325 | Time 134.78 s
2022-08-17 17:56:54 | [trpo_pendulum] epoch #325 | EpochTime 0.41 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -575.866
Evaluation/AverageReturn              -1415.49
Evaluation/Iteration                    325
Evaluation/MaxReturn                  -1290.49
Evaluation/MinReturn                  -1513.49
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     82.1304
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42309
GaussianMLPPolicy/KL                      4.395e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -580.422
GaussianMLPPolicy/LossBefore           -580.309
GaussianMLPPolicy/dLoss                   0.113403
GaussianMLPValueFunction/LossAfter    61577.3
GaussianMLPValueFunction/LossBefore   61662.3
GaussianMLPValueFunction/dLoss           85.0273
TotalEnvSteps                        391200
-----------------------------------  --------------
2022-08-17 17:56:55 | [trpo_pendulum] epoch #326 | Saving snapshot...
2022-08-17 17:56:55 | [trpo_pendulum] epoch #326 | Saved
2022-08-17 17:56:55 | [trpo_pendulum] epoch #326 | Time 135.19 s
2022-08-17 17:56:55 | [trpo_pendulum] epoch #326 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -618
Evaluation/AverageReturn              -1513.6
Evaluation/Iteration                    326
Evaluation/MaxReturn                  -1448.21
Evaluation/MinReturn                  -1597.06
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.8631
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42336
GaussianMLPPolicy/KL                      1.72404e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -613.306
GaussianMLPPolicy/LossBefore           -613.24
GaussianMLPPolicy/dLoss                   0.0666504
GaussianMLPValueFunction/LossAfter    70088
GaussianMLPValueFunction/LossBefore   70186.1
GaussianMLPValueFunction/dLoss           98.1406
TotalEnvSteps                        392400
-----------------------------------  ----------------
2022-08-17 17:56:55 | [trpo_pendulum] epoch #327 | Saving snapshot...
2022-08-17 17:56:55 | [trpo_pendulum] epoch #327 | Saved
2022-08-17 17:56:55 | [trpo_pendulum] epoch #327 | Time 135.60 s
2022-08-17 17:56:55 | [trpo_pendulum] epoch #327 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -747.712
Evaluation/AverageReturn              -1757.95
Evaluation/Iteration                    327
Evaluation/MaxReturn                  -1699.89
Evaluation/MinReturn                  -1786.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     29.6782
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42362
GaussianMLPPolicy/KL                      3.02214e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -699.333
GaussianMLPPolicy/LossBefore           -699.25
GaussianMLPPolicy/dLoss                   0.0831299
GaussianMLPValueFunction/LossAfter    91315.5
GaussianMLPValueFunction/LossBefore   91448.1
GaussianMLPValueFunction/dLoss          132.594
TotalEnvSteps                        393600
-----------------------------------  ----------------
2022-08-17 17:56:56 | [trpo_pendulum] epoch #328 | Saving snapshot...
2022-08-17 17:56:56 | [trpo_pendulum] epoch #328 | Saved
2022-08-17 17:56:56 | [trpo_pendulum] epoch #328 | Time 136.02 s
2022-08-17 17:56:56 | [trpo_pendulum] epoch #328 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -552.448
Evaluation/AverageReturn              -1380.27
Evaluation/Iteration                    328
Evaluation/MaxReturn                  -1300.44
Evaluation/MinReturn                  -1430.3
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     44.5477
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42393
GaussianMLPPolicy/KL                      3.21003e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -563.847
GaussianMLPPolicy/LossBefore           -563.752
GaussianMLPPolicy/dLoss                   0.0951538
GaussianMLPValueFunction/LossAfter    59120.7
GaussianMLPValueFunction/LossBefore   59208.8
GaussianMLPValueFunction/dLoss           88.1211
TotalEnvSteps                        394800
-----------------------------------  ----------------
2022-08-17 17:56:56 | [trpo_pendulum] epoch #329 | Saving snapshot...
2022-08-17 17:56:56 | [trpo_pendulum] epoch #329 | Saved
2022-08-17 17:56:56 | [trpo_pendulum] epoch #329 | Time 136.43 s
2022-08-17 17:56:56 | [trpo_pendulum] epoch #329 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -737.983
Evaluation/AverageReturn              -1739.83
Evaluation/Iteration                    329
Evaluation/MaxReturn                  -1692.67
Evaluation/MinReturn                  -1770.05
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     30.4527
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42422
GaussianMLPPolicy/KL                      2.86902e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -694.545
GaussianMLPPolicy/LossBefore           -694.299
GaussianMLPPolicy/dLoss                   0.246521
GaussianMLPValueFunction/LossAfter    89620.6
GaussianMLPValueFunction/LossBefore   89756.3
GaussianMLPValueFunction/dLoss          135.719
TotalEnvSteps                        396000
-----------------------------------  ----------------
2022-08-17 17:56:56 | [trpo_pendulum] epoch #330 | Saving snapshot...
2022-08-17 17:56:56 | [trpo_pendulum] epoch #330 | Saved
2022-08-17 17:56:56 | [trpo_pendulum] epoch #330 | Time 136.84 s
2022-08-17 17:56:56 | [trpo_pendulum] epoch #330 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -571.963
Evaluation/AverageReturn              -1400.16
Evaluation/Iteration                    330
Evaluation/MaxReturn                  -1248
Evaluation/MinReturn                  -1526.09
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    104.105
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42434
GaussianMLPPolicy/KL                      8.24207e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -583.376
GaussianMLPPolicy/LossBefore           -583.327
GaussianMLPPolicy/dLoss                   0.0493164
GaussianMLPValueFunction/LossAfter    59439.6
GaussianMLPValueFunction/LossBefore   59531.4
GaussianMLPValueFunction/dLoss           91.8047
TotalEnvSteps                        397200
-----------------------------------  ----------------
2022-08-17 17:56:57 | [trpo_pendulum] epoch #331 | Saving snapshot...
2022-08-17 17:56:57 | [trpo_pendulum] epoch #331 | Saved
2022-08-17 17:56:57 | [trpo_pendulum] epoch #331 | Time 137.25 s
2022-08-17 17:56:57 | [trpo_pendulum] epoch #331 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -722.884
Evaluation/AverageReturn              -1690.36
Evaluation/Iteration                    331
Evaluation/MaxReturn                  -1533.27
Evaluation/MinReturn                  -1750.07
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     73.1448
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42461
GaussianMLPPolicy/KL                      2.14579e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -656.943
GaussianMLPPolicy/LossBefore           -656.914
GaussianMLPPolicy/dLoss                   0.0288086
GaussianMLPValueFunction/LossAfter    83390.2
GaussianMLPValueFunction/LossBefore   83520
GaussianMLPValueFunction/dLoss          129.781
TotalEnvSteps                        398400
-----------------------------------  ----------------
2022-08-17 17:56:57 | [trpo_pendulum] epoch #332 | Saving snapshot...
2022-08-17 17:56:57 | [trpo_pendulum] epoch #332 | Saved
2022-08-17 17:56:57 | [trpo_pendulum] epoch #332 | Time 137.67 s
2022-08-17 17:56:57 | [trpo_pendulum] epoch #332 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -621.526
Evaluation/AverageReturn              -1501.26
Evaluation/Iteration                    332
Evaluation/MaxReturn                  -1347.18
Evaluation/MinReturn                  -1632.05
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     92.5526
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4247
GaussianMLPPolicy/KL                      1.66764e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -621.34
GaussianMLPPolicy/LossBefore           -621.229
GaussianMLPPolicy/dLoss                   0.110779
GaussianMLPValueFunction/LossAfter    67456.5
GaussianMLPValueFunction/LossBefore   67563.1
GaussianMLPValueFunction/dLoss          106.672
TotalEnvSteps                        399600
-----------------------------------  ----------------
2022-08-17 17:56:58 | [trpo_pendulum] epoch #333 | Saving snapshot...
2022-08-17 17:56:58 | [trpo_pendulum] epoch #333 | Saved
2022-08-17 17:56:58 | [trpo_pendulum] epoch #333 | Time 138.08 s
2022-08-17 17:56:58 | [trpo_pendulum] epoch #333 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -639.106
Evaluation/AverageReturn              -1552.42
Evaluation/Iteration                    333
Evaluation/MaxReturn                  -1514.44
Evaluation/MinReturn                  -1634.64
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     44.296
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42483
GaussianMLPPolicy/KL                      2.14446e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -626.765
GaussianMLPPolicy/LossBefore           -626.689
GaussianMLPPolicy/dLoss                   0.0758057
GaussianMLPValueFunction/LossAfter    72566.2
GaussianMLPValueFunction/LossBefore   72681.7
GaussianMLPValueFunction/dLoss          115.484
TotalEnvSteps                        400800
-----------------------------------  ----------------
2022-08-17 17:56:58 | [trpo_pendulum] epoch #334 | Saving snapshot...
2022-08-17 17:56:58 | [trpo_pendulum] epoch #334 | Saved
2022-08-17 17:56:58 | [trpo_pendulum] epoch #334 | Time 138.49 s
2022-08-17 17:56:58 | [trpo_pendulum] epoch #334 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -653.154
Evaluation/AverageReturn              -1576.46
Evaluation/Iteration                    334
Evaluation/MaxReturn                  -1526.09
Evaluation/MinReturn                  -1614.09
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     31.4325
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42485
GaussianMLPPolicy/KL                      2.50436e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -647.841
GaussianMLPPolicy/LossBefore           -647.765
GaussianMLPPolicy/dLoss                   0.0757446
GaussianMLPValueFunction/LossAfter    74324.4
GaussianMLPValueFunction/LossBefore   74443.9
GaussianMLPValueFunction/dLoss          119.5
TotalEnvSteps                        402000
-----------------------------------  ----------------
2022-08-17 17:56:59 | [trpo_pendulum] epoch #335 | Saving snapshot...
2022-08-17 17:56:59 | [trpo_pendulum] epoch #335 | Saved
2022-08-17 17:56:59 | [trpo_pendulum] epoch #335 | Time 138.92 s
2022-08-17 17:56:59 | [trpo_pendulum] epoch #335 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -448.87
Evaluation/AverageReturn              -1150.79
Evaluation/Iteration                    335
Evaluation/MaxReturn                   -746.256
Evaluation/MinReturn                  -1371.37
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    213.97
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42487
GaussianMLPPolicy/KL                      4.50792e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -481.924
GaussianMLPPolicy/LossBefore           -481.893
GaussianMLPPolicy/dLoss                   0.0314636
GaussianMLPValueFunction/LossAfter    42897.1
GaussianMLPValueFunction/LossBefore   42966.2
GaussianMLPValueFunction/dLoss           69.0938
TotalEnvSteps                        403200
-----------------------------------  ----------------
2022-08-17 17:56:59 | [trpo_pendulum] epoch #336 | Saving snapshot...
2022-08-17 17:56:59 | [trpo_pendulum] epoch #336 | Saved
2022-08-17 17:56:59 | [trpo_pendulum] epoch #336 | Time 139.33 s
2022-08-17 17:56:59 | [trpo_pendulum] epoch #336 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -681.184
Evaluation/AverageReturn              -1632.02
Evaluation/Iteration                    336
Evaluation/MaxReturn                  -1554.44
Evaluation/MinReturn                  -1689.81
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.6295
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42491
GaussianMLPPolicy/KL                      4.43427e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -655.827
GaussianMLPPolicy/LossBefore           -655.777
GaussianMLPPolicy/dLoss                   0.0493164
GaussianMLPValueFunction/LossAfter    78980.2
GaussianMLPValueFunction/LossBefore   79105.1
GaussianMLPValueFunction/dLoss          124.914
TotalEnvSteps                        404400
-----------------------------------  ----------------
2022-08-17 17:56:59 | [trpo_pendulum] epoch #337 | Saving snapshot...
2022-08-17 17:56:59 | [trpo_pendulum] epoch #337 | Saved
2022-08-17 17:56:59 | [trpo_pendulum] epoch #337 | Time 139.75 s
2022-08-17 17:56:59 | [trpo_pendulum] epoch #337 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -386.864
Evaluation/AverageReturn               -994.158
Evaluation/Iteration                    337
Evaluation/MaxReturn                   -743.443
Evaluation/MinReturn                  -1193.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    140.301
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42476
GaussianMLPPolicy/KL                      0.000122554
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -431.029
GaussianMLPPolicy/LossBefore           -430.701
GaussianMLPPolicy/dLoss                   0.328217
GaussianMLPValueFunction/LossAfter    31387
GaussianMLPValueFunction/LossBefore   31437.8
GaussianMLPValueFunction/dLoss           50.7695
TotalEnvSteps                        405600
-----------------------------------  ----------------
2022-08-17 17:57:00 | [trpo_pendulum] epoch #338 | Saving snapshot...
2022-08-17 17:57:00 | [trpo_pendulum] epoch #338 | Saved
2022-08-17 17:57:00 | [trpo_pendulum] epoch #338 | Time 140.15 s
2022-08-17 17:57:00 | [trpo_pendulum] epoch #338 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -478.37
Evaluation/AverageReturn              -1218.26
Evaluation/Iteration                    338
Evaluation/MaxReturn                   -982.354
Evaluation/MinReturn                  -1378.86
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    137.883
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42458
GaussianMLPPolicy/KL                      5.27133e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -511.951
GaussianMLPPolicy/LossBefore           -511.94
GaussianMLPPolicy/dLoss                   0.0110474
GaussianMLPValueFunction/LossAfter    46487.5
GaussianMLPValueFunction/LossBefore   46558.5
GaussianMLPValueFunction/dLoss           71.0273
TotalEnvSteps                        406800
-----------------------------------  ----------------
2022-08-17 17:57:00 | [trpo_pendulum] epoch #339 | Saving snapshot...
2022-08-17 17:57:00 | [trpo_pendulum] epoch #339 | Saved
2022-08-17 17:57:00 | [trpo_pendulum] epoch #339 | Time 140.56 s
2022-08-17 17:57:00 | [trpo_pendulum] epoch #339 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -632.927
Evaluation/AverageReturn              -1549.65
Evaluation/Iteration                    339
Evaluation/MaxReturn                  -1479.24
Evaluation/MinReturn                  -1633.52
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     62.3768
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42453
GaussianMLPPolicy/KL                      3.11537e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -623.362
GaussianMLPPolicy/LossBefore           -623.318
GaussianMLPPolicy/dLoss                   0.0438232
GaussianMLPValueFunction/LossAfter    72169.8
GaussianMLPValueFunction/LossBefore   72278.2
GaussianMLPValueFunction/dLoss          108.422
TotalEnvSteps                        408000
-----------------------------------  ----------------
2022-08-17 17:57:01 | [trpo_pendulum] epoch #340 | Saving snapshot...
2022-08-17 17:57:01 | [trpo_pendulum] epoch #340 | Saved
2022-08-17 17:57:01 | [trpo_pendulum] epoch #340 | Time 140.99 s
2022-08-17 17:57:01 | [trpo_pendulum] epoch #340 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -549.961
Evaluation/AverageReturn              -1386.09
Evaluation/Iteration                    340
Evaluation/MaxReturn                  -1276.49
Evaluation/MinReturn                  -1474.64
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     64.2461
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42446
GaussianMLPPolicy/KL                      1.68306e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -578.081
GaussianMLPPolicy/LossBefore           -578.065
GaussianMLPPolicy/dLoss                   0.015625
GaussianMLPValueFunction/LossAfter    58945.4
GaussianMLPValueFunction/LossBefore   59034.9
GaussianMLPValueFunction/dLoss           89.4922
TotalEnvSteps                        409200
-----------------------------------  ----------------
2022-08-17 17:57:01 | [trpo_pendulum] epoch #341 | Saving snapshot...
2022-08-17 17:57:01 | [trpo_pendulum] epoch #341 | Saved
2022-08-17 17:57:01 | [trpo_pendulum] epoch #341 | Time 141.40 s
2022-08-17 17:57:01 | [trpo_pendulum] epoch #341 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -777.33
Evaluation/AverageReturn              -1796.33
Evaluation/Iteration                    341
Evaluation/MaxReturn                  -1743.92
Evaluation/MinReturn                  -1822.36
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     24.8061
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42422
GaussianMLPPolicy/KL                      2.30554e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -723.831
GaussianMLPPolicy/LossBefore           -723.707
GaussianMLPPolicy/dLoss                   0.124023
GaussianMLPValueFunction/LossAfter    91926.7
GaussianMLPValueFunction/LossBefore   92068.6
GaussianMLPValueFunction/dLoss          141.938
TotalEnvSteps                        410400
-----------------------------------  ----------------
2022-08-17 17:57:01 | [trpo_pendulum] epoch #342 | Saving snapshot...
2022-08-17 17:57:01 | [trpo_pendulum] epoch #342 | Saved
2022-08-17 17:57:01 | [trpo_pendulum] epoch #342 | Time 141.81 s
2022-08-17 17:57:01 | [trpo_pendulum] epoch #342 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -663.675
Evaluation/AverageReturn              -1613.26
Evaluation/Iteration                    342
Evaluation/MaxReturn                  -1509.22
Evaluation/MinReturn                  -1666.96
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.9327
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42396
GaussianMLPPolicy/KL                      1.86256e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -661.163
GaussianMLPPolicy/LossBefore           -661.122
GaussianMLPPolicy/dLoss                   0.0412598
GaussianMLPValueFunction/LossAfter    77734.6
GaussianMLPValueFunction/LossBefore   77858
GaussianMLPValueFunction/dLoss          123.453
TotalEnvSteps                        411600
-----------------------------------  ----------------
2022-08-17 17:57:02 | [trpo_pendulum] epoch #343 | Saving snapshot...
2022-08-17 17:57:02 | [trpo_pendulum] epoch #343 | Saved
2022-08-17 17:57:02 | [trpo_pendulum] epoch #343 | Time 142.23 s
2022-08-17 17:57:02 | [trpo_pendulum] epoch #343 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -412.223
Evaluation/AverageReturn              -1088.93
Evaluation/Iteration                    343
Evaluation/MaxReturn                   -943.078
Evaluation/MinReturn                  -1342.54
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    126.926
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42374
GaussianMLPPolicy/KL                      4.10729e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -460.225
GaussianMLPPolicy/LossBefore           -460.191
GaussianMLPPolicy/dLoss                   0.033905
GaussianMLPValueFunction/LossAfter    38305.9
GaussianMLPValueFunction/LossBefore   38367.6
GaussianMLPValueFunction/dLoss           61.6836
TotalEnvSteps                        412800
-----------------------------------  ----------------
2022-08-17 17:57:02 | [trpo_pendulum] epoch #344 | Saving snapshot...
2022-08-17 17:57:02 | [trpo_pendulum] epoch #344 | Saved
2022-08-17 17:57:02 | [trpo_pendulum] epoch #344 | Time 142.64 s
2022-08-17 17:57:02 | [trpo_pendulum] epoch #344 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -407.487
Evaluation/AverageReturn              -1108.55
Evaluation/Iteration                    344
Evaluation/MaxReturn                   -964.481
Evaluation/MinReturn                  -1216.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     81.572
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42358
GaussianMLPPolicy/KL                      2.52253e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -476.229
GaussianMLPPolicy/LossBefore           -476.215
GaussianMLPPolicy/dLoss                   0.0132141
GaussianMLPValueFunction/LossAfter    40759.1
GaussianMLPValueFunction/LossBefore   40822.6
GaussianMLPValueFunction/dLoss           63.4609
TotalEnvSteps                        414000
-----------------------------------  ----------------
2022-08-17 17:57:03 | [trpo_pendulum] epoch #345 | Saving snapshot...
2022-08-17 17:57:03 | [trpo_pendulum] epoch #345 | Saved
2022-08-17 17:57:03 | [trpo_pendulum] epoch #345 | Time 143.05 s
2022-08-17 17:57:03 | [trpo_pendulum] epoch #345 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -647.826
Evaluation/AverageReturn              -1584.33
Evaluation/Iteration                    345
Evaluation/MaxReturn                  -1516.4
Evaluation/MinReturn                  -1720.63
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     70.1817
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42331
GaussianMLPPolicy/KL                      6.68771e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -659.236
GaussianMLPPolicy/LossBefore           -659.179
GaussianMLPPolicy/dLoss                   0.0574341
GaussianMLPValueFunction/LossAfter    75078.7
GaussianMLPValueFunction/LossBefore   75192.1
GaussianMLPValueFunction/dLoss          113.461
TotalEnvSteps                        415200
-----------------------------------  ----------------
2022-08-17 17:57:03 | [trpo_pendulum] epoch #346 | Saving snapshot...
2022-08-17 17:57:03 | [trpo_pendulum] epoch #346 | Saved
2022-08-17 17:57:03 | [trpo_pendulum] epoch #346 | Time 143.47 s
2022-08-17 17:57:03 | [trpo_pendulum] epoch #346 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -438.34
Evaluation/AverageReturn              -1144.62
Evaluation/Iteration                    346
Evaluation/MaxReturn                  -1067.52
Evaluation/MinReturn                  -1341.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     95.2193
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42309
GaussianMLPPolicy/KL                      1.30016e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -479.617
GaussianMLPPolicy/LossBefore           -479.596
GaussianMLPPolicy/dLoss                   0.020813
GaussianMLPValueFunction/LossAfter    41577.4
GaussianMLPValueFunction/LossBefore   41641.4
GaussianMLPValueFunction/dLoss           64.0703
TotalEnvSteps                        416400
-----------------------------------  ----------------
2022-08-17 17:57:04 | [trpo_pendulum] epoch #347 | Saving snapshot...
2022-08-17 17:57:04 | [trpo_pendulum] epoch #347 | Saved
2022-08-17 17:57:04 | [trpo_pendulum] epoch #347 | Time 143.88 s
2022-08-17 17:57:04 | [trpo_pendulum] epoch #347 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -719.645
Evaluation/AverageReturn              -1710.49
Evaluation/Iteration                    347
Evaluation/MaxReturn                  -1679.73
Evaluation/MinReturn                  -1738.34
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     23.3896
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42279
GaussianMLPPolicy/KL                      1.54231e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -695.754
GaussianMLPPolicy/LossBefore           -695.671
GaussianMLPPolicy/dLoss                   0.0829468
GaussianMLPValueFunction/LossAfter    85356.4
GaussianMLPValueFunction/LossBefore   85485.4
GaussianMLPValueFunction/dLoss          128.93
TotalEnvSteps                        417600
-----------------------------------  ----------------
2022-08-17 17:57:04 | [trpo_pendulum] epoch #348 | Saving snapshot...
2022-08-17 17:57:04 | [trpo_pendulum] epoch #348 | Saved
2022-08-17 17:57:04 | [trpo_pendulum] epoch #348 | Time 144.28 s
2022-08-17 17:57:04 | [trpo_pendulum] epoch #348 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -719.452
Evaluation/AverageReturn              -1714.5
Evaluation/Iteration                    348
Evaluation/MaxReturn                  -1665.7
Evaluation/MinReturn                  -1735.86
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     25.2629
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42231
GaussianMLPPolicy/KL                      9.90484e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -708.115
GaussianMLPPolicy/LossBefore           -708.024
GaussianMLPPolicy/dLoss                   0.0909424
GaussianMLPValueFunction/LossAfter    85432.5
GaussianMLPValueFunction/LossBefore   85566
GaussianMLPValueFunction/dLoss          133.5
TotalEnvSteps                        418800
-----------------------------------  ----------------
2022-08-17 17:57:04 | [trpo_pendulum] epoch #349 | Saving snapshot...
2022-08-17 17:57:04 | [trpo_pendulum] epoch #349 | Saved
2022-08-17 17:57:04 | [trpo_pendulum] epoch #349 | Time 144.70 s
2022-08-17 17:57:04 | [trpo_pendulum] epoch #349 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -776.36
Evaluation/AverageReturn              -1802.57
Evaluation/Iteration                    349
Evaluation/MaxReturn                  -1771.92
Evaluation/MinReturn                  -1836.6
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     25.7422
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42171
GaussianMLPPolicy/KL                      1.10779e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -725.434
GaussianMLPPolicy/LossBefore           -725.308
GaussianMLPPolicy/dLoss                   0.12616
GaussianMLPValueFunction/LossAfter    91657.3
GaussianMLPValueFunction/LossBefore   91805.6
GaussianMLPValueFunction/dLoss          148.266
TotalEnvSteps                        420000
-----------------------------------  ----------------
2022-08-17 17:57:05 | [trpo_pendulum] epoch #350 | Saving snapshot...
2022-08-17 17:57:05 | [trpo_pendulum] epoch #350 | Saved
2022-08-17 17:57:05 | [trpo_pendulum] epoch #350 | Time 145.11 s
2022-08-17 17:57:05 | [trpo_pendulum] epoch #350 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -664.86
Evaluation/AverageReturn              -1620.69
Evaluation/Iteration                    350
Evaluation/MaxReturn                  -1483.12
Evaluation/MinReturn                  -1707.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     71.4385
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42112
GaussianMLPPolicy/KL                      4.79478e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -665.345
GaussianMLPPolicy/LossBefore           -665.251
GaussianMLPPolicy/dLoss                   0.0946655
GaussianMLPValueFunction/LossAfter    77742
GaussianMLPValueFunction/LossBefore   77870.6
GaussianMLPValueFunction/dLoss          128.609
TotalEnvSteps                        421200
-----------------------------------  ----------------
2022-08-17 17:57:05 | [trpo_pendulum] epoch #351 | Saving snapshot...
2022-08-17 17:57:05 | [trpo_pendulum] epoch #351 | Saved
2022-08-17 17:57:05 | [trpo_pendulum] epoch #351 | Time 145.52 s
2022-08-17 17:57:05 | [trpo_pendulum] epoch #351 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -602.173
Evaluation/AverageReturn              -1468.92
Evaluation/Iteration                    351
Evaluation/MaxReturn                  -1329.08
Evaluation/MinReturn                  -1591.09
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     78.4063
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42064
GaussianMLPPolicy/KL                      0.000130543
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -590.277
GaussianMLPPolicy/LossBefore           -590.021
GaussianMLPPolicy/dLoss                   0.256165
GaussianMLPValueFunction/LossAfter    63368.1
GaussianMLPValueFunction/LossBefore   63473.4
GaussianMLPValueFunction/dLoss          105.238
TotalEnvSteps                        422400
-----------------------------------  ----------------
2022-08-17 17:57:06 | [trpo_pendulum] epoch #352 | Saving snapshot...
2022-08-17 17:57:06 | [trpo_pendulum] epoch #352 | Saved
2022-08-17 17:57:06 | [trpo_pendulum] epoch #352 | Time 145.92 s
2022-08-17 17:57:06 | [trpo_pendulum] epoch #352 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -706.173
Evaluation/AverageReturn              -1680.21
Evaluation/Iteration                    352
Evaluation/MaxReturn                  -1645.87
Evaluation/MinReturn                  -1741.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     34.3336
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42019
GaussianMLPPolicy/KL                      4.53159e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -675.046
GaussianMLPPolicy/LossBefore           -675.026
GaussianMLPPolicy/dLoss                   0.0201416
GaussianMLPValueFunction/LossAfter    80931.8
GaussianMLPValueFunction/LossBefore   81066.9
GaussianMLPValueFunction/dLoss          135.07
TotalEnvSteps                        423600
-----------------------------------  ----------------
2022-08-17 17:57:06 | [trpo_pendulum] epoch #353 | Saving snapshot...
2022-08-17 17:57:06 | [trpo_pendulum] epoch #353 | Saved
2022-08-17 17:57:06 | [trpo_pendulum] epoch #353 | Time 146.34 s
2022-08-17 17:57:06 | [trpo_pendulum] epoch #353 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -753.515
Evaluation/AverageReturn              -1746.72
Evaluation/Iteration                    353
Evaluation/MaxReturn                  -1679.42
Evaluation/MinReturn                  -1817.73
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     44.0539
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41966
GaussianMLPPolicy/KL                      2.18563e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -697.071
GaussianMLPPolicy/LossBefore           -697.073
GaussianMLPPolicy/dLoss                  -0.00195312
GaussianMLPValueFunction/LossAfter    85102.8
GaussianMLPValueFunction/LossBefore   85247.5
GaussianMLPValueFunction/dLoss          144.688
TotalEnvSteps                        424800
-----------------------------------  ----------------
2022-08-17 17:57:06 | [trpo_pendulum] epoch #354 | Saving snapshot...
2022-08-17 17:57:06 | [trpo_pendulum] epoch #354 | Saved
2022-08-17 17:57:06 | [trpo_pendulum] epoch #354 | Time 146.75 s
2022-08-17 17:57:06 | [trpo_pendulum] epoch #354 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -709.543
Evaluation/AverageReturn              -1674.78
Evaluation/Iteration                    354
Evaluation/MaxReturn                  -1612.53
Evaluation/MinReturn                  -1737.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     37.5979
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41908
GaussianMLPPolicy/KL                      9.23341e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -675.039
GaussianMLPPolicy/LossBefore           -674.597
GaussianMLPPolicy/dLoss                   0.441772
GaussianMLPValueFunction/LossAfter    79878.4
GaussianMLPValueFunction/LossBefore   80016.2
GaussianMLPValueFunction/dLoss          137.852
TotalEnvSteps                        426000
-----------------------------------  ----------------
2022-08-17 17:57:07 | [trpo_pendulum] epoch #355 | Saving snapshot...
2022-08-17 17:57:07 | [trpo_pendulum] epoch #355 | Saved
2022-08-17 17:57:07 | [trpo_pendulum] epoch #355 | Time 147.16 s
2022-08-17 17:57:07 | [trpo_pendulum] epoch #355 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -546.633
Evaluation/AverageReturn              -1326.87
Evaluation/Iteration                    355
Evaluation/MaxReturn                  -1210.34
Evaluation/MinReturn                  -1479.82
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     80.7416
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41858
GaussianMLPPolicy/KL                      0.000154416
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -532.052
GaussianMLPPolicy/LossBefore           -531.841
GaussianMLPPolicy/dLoss                   0.211365
GaussianMLPValueFunction/LossAfter    50833.2
GaussianMLPValueFunction/LossBefore   50920.6
GaussianMLPValueFunction/dLoss           87.4883
TotalEnvSteps                        427200
-----------------------------------  ----------------
2022-08-17 17:57:07 | [trpo_pendulum] epoch #356 | Saving snapshot...
2022-08-17 17:57:07 | [trpo_pendulum] epoch #356 | Saved
2022-08-17 17:57:07 | [trpo_pendulum] epoch #356 | Time 147.57 s
2022-08-17 17:57:07 | [trpo_pendulum] epoch #356 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -697.703
Evaluation/AverageReturn              -1658.77
Evaluation/Iteration                    356
Evaluation/MaxReturn                  -1503.62
Evaluation/MinReturn                  -1750.74
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     81.3942
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41821
GaussianMLPPolicy/KL                      7.86813e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -654.152
GaussianMLPPolicy/LossBefore           -654.094
GaussianMLPPolicy/dLoss                   0.0585938
GaussianMLPValueFunction/LossAfter    78554
GaussianMLPValueFunction/LossBefore   78687.6
GaussianMLPValueFunction/dLoss          133.594
TotalEnvSteps                        428400
-----------------------------------  ----------------
2022-08-17 17:57:08 | [trpo_pendulum] epoch #357 | Saving snapshot...
2022-08-17 17:57:08 | [trpo_pendulum] epoch #357 | Saved
2022-08-17 17:57:08 | [trpo_pendulum] epoch #357 | Time 147.98 s
2022-08-17 17:57:08 | [trpo_pendulum] epoch #357 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -521.576
Evaluation/AverageReturn              -1233.51
Evaluation/Iteration                    357
Evaluation/MaxReturn                  -1095.33
Evaluation/MinReturn                  -1382.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     90.0769
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41784
GaussianMLPPolicy/KL                      3.84295e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -487.758
GaussianMLPPolicy/LossBefore           -487.79
GaussianMLPPolicy/dLoss                  -0.0326538
GaussianMLPValueFunction/LossAfter    42370.9
GaussianMLPValueFunction/LossBefore   42442.8
GaussianMLPValueFunction/dLoss           71.8203
TotalEnvSteps                        429600
-----------------------------------  ----------------
2022-08-17 17:57:08 | [trpo_pendulum] epoch #358 | Saving snapshot...
2022-08-17 17:57:08 | [trpo_pendulum] epoch #358 | Saved
2022-08-17 17:57:08 | [trpo_pendulum] epoch #358 | Time 148.40 s
2022-08-17 17:57:08 | [trpo_pendulum] epoch #358 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -560.878
Evaluation/AverageReturn              -1343.93
Evaluation/Iteration                    358
Evaluation/MaxReturn                  -1289.59
Evaluation/MinReturn                  -1453.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     56.1754
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41745
GaussianMLPPolicy/KL                      2.05968e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -539.46
GaussianMLPPolicy/LossBefore           -539.412
GaussianMLPPolicy/dLoss                   0.0475464
GaussianMLPValueFunction/LossAfter    50972.9
GaussianMLPValueFunction/LossBefore   51056.4
GaussianMLPValueFunction/dLoss           83.4766
TotalEnvSteps                        430800
-----------------------------------  ----------------
2022-08-17 17:57:08 | [trpo_pendulum] epoch #359 | Saving snapshot...
2022-08-17 17:57:08 | [trpo_pendulum] epoch #359 | Saved
2022-08-17 17:57:08 | [trpo_pendulum] epoch #359 | Time 148.82 s
2022-08-17 17:57:08 | [trpo_pendulum] epoch #359 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -488.306
Evaluation/AverageReturn              -1170.76
Evaluation/Iteration                    359
Evaluation/MaxReturn                   -999.81
Evaluation/MinReturn                  -1316.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    105.333
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41735
GaussianMLPPolicy/KL                      5.35296e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -441.738
GaussianMLPPolicy/LossBefore           -441.749
GaussianMLPPolicy/dLoss                  -0.0111389
GaussianMLPValueFunction/LossAfter    38669.4
GaussianMLPValueFunction/LossBefore   38731.4
GaussianMLPValueFunction/dLoss           62.0547
TotalEnvSteps                        432000
-----------------------------------  ----------------
2022-08-17 17:57:09 | [trpo_pendulum] epoch #360 | Saving snapshot...
2022-08-17 17:57:09 | [trpo_pendulum] epoch #360 | Saved
2022-08-17 17:57:09 | [trpo_pendulum] epoch #360 | Time 149.23 s
2022-08-17 17:57:09 | [trpo_pendulum] epoch #360 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -398.553
Evaluation/AverageReturn               -955.66
Evaluation/Iteration                    360
Evaluation/MaxReturn                   -747.214
Evaluation/MinReturn                  -1163.45
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    154.822
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41729
GaussianMLPPolicy/KL                      3.77798e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -370.959
GaussianMLPPolicy/LossBefore           -370.955
GaussianMLPPolicy/dLoss                   0.00335693
GaussianMLPValueFunction/LossAfter    26048.5
GaussianMLPValueFunction/LossBefore   26089.4
GaussianMLPValueFunction/dLoss           40.9258
TotalEnvSteps                        433200
-----------------------------------  ----------------
2022-08-17 17:57:09 | [trpo_pendulum] epoch #361 | Saving snapshot...
2022-08-17 17:57:09 | [trpo_pendulum] epoch #361 | Saved
2022-08-17 17:57:09 | [trpo_pendulum] epoch #361 | Time 149.65 s
2022-08-17 17:57:09 | [trpo_pendulum] epoch #361 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -715.707
Evaluation/AverageReturn              -1661.89
Evaluation/Iteration                    361
Evaluation/MaxReturn                  -1570.2
Evaluation/MinReturn                  -1796.16
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     75.4296
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41719
GaussianMLPPolicy/KL                      3.76244e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -656.01
GaussianMLPPolicy/LossBefore           -655.895
GaussianMLPPolicy/dLoss                   0.114197
GaussianMLPValueFunction/LossAfter    76646.9
GaussianMLPValueFunction/LossBefore   76761.3
GaussianMLPValueFunction/dLoss          114.336
TotalEnvSteps                        434400
-----------------------------------  ----------------
2022-08-17 17:57:10 | [trpo_pendulum] epoch #362 | Saving snapshot...
2022-08-17 17:57:10 | [trpo_pendulum] epoch #362 | Saved
2022-08-17 17:57:10 | [trpo_pendulum] epoch #362 | Time 150.05 s
2022-08-17 17:57:10 | [trpo_pendulum] epoch #362 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -348.204
Evaluation/AverageReturn               -877.71
Evaluation/Iteration                    362
Evaluation/MaxReturn                   -741.365
Evaluation/MinReturn                  -1061.64
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    134.678
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41715
GaussianMLPPolicy/KL                      2.53284e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -350.409
GaussianMLPPolicy/LossBefore           -350.417
GaussianMLPPolicy/dLoss                  -0.00799561
GaussianMLPValueFunction/LossAfter    22946.4
GaussianMLPValueFunction/LossBefore   22982.2
GaussianMLPValueFunction/dLoss           35.7441
TotalEnvSteps                        435600
-----------------------------------  ----------------
2022-08-17 17:57:10 | [trpo_pendulum] epoch #363 | Saving snapshot...
2022-08-17 17:57:10 | [trpo_pendulum] epoch #363 | Saved
2022-08-17 17:57:10 | [trpo_pendulum] epoch #363 | Time 150.45 s
2022-08-17 17:57:10 | [trpo_pendulum] epoch #363 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -640.021
Evaluation/AverageReturn              -1541.34
Evaluation/Iteration                    363
Evaluation/MaxReturn                  -1432.09
Evaluation/MinReturn                  -1650.69
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     77.887
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41703
GaussianMLPPolicy/KL                      5.94074e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -625.656
GaussianMLPPolicy/LossBefore           -625.279
GaussianMLPPolicy/dLoss                   0.376648
GaussianMLPValueFunction/LossAfter    67427.2
GaussianMLPValueFunction/LossBefore   67524.3
GaussianMLPValueFunction/dLoss           97.0078
TotalEnvSteps                        436800
-----------------------------------  ----------------
2022-08-17 17:57:11 | [trpo_pendulum] epoch #364 | Saving snapshot...
2022-08-17 17:57:11 | [trpo_pendulum] epoch #364 | Saved
2022-08-17 17:57:11 | [trpo_pendulum] epoch #364 | Time 150.87 s
2022-08-17 17:57:11 | [trpo_pendulum] epoch #364 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -633.954
Evaluation/AverageReturn              -1510.46
Evaluation/Iteration                    364
Evaluation/MaxReturn                  -1373.94
Evaluation/MinReturn                  -1655.78
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     93.5809
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41676
GaussianMLPPolicy/KL                      5.70814e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -615.98
GaussianMLPPolicy/LossBefore           -615.882
GaussianMLPPolicy/dLoss                   0.0981445
GaussianMLPValueFunction/LossAfter    64142.2
GaussianMLPValueFunction/LossBefore   64235.6
GaussianMLPValueFunction/dLoss           93.3555
TotalEnvSteps                        438000
-----------------------------------  ----------------
2022-08-17 17:57:11 | [trpo_pendulum] epoch #365 | Saving snapshot...
2022-08-17 17:57:11 | [trpo_pendulum] epoch #365 | Saved
2022-08-17 17:57:11 | [trpo_pendulum] epoch #365 | Time 151.28 s
2022-08-17 17:57:11 | [trpo_pendulum] epoch #365 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -405.444
Evaluation/AverageReturn              -1027.82
Evaluation/Iteration                    365
Evaluation/MaxReturn                   -860.094
Evaluation/MinReturn                  -1277.5
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    145.202
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41661
GaussianMLPPolicy/KL                      6.77189e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -411.468
GaussianMLPPolicy/LossBefore           -411.456
GaussianMLPPolicy/dLoss                   0.012146
GaussianMLPValueFunction/LossAfter    32079
GaussianMLPValueFunction/LossBefore   32126.5
GaussianMLPValueFunction/dLoss           47.4883
TotalEnvSteps                        439200
-----------------------------------  ----------------
2022-08-17 17:57:11 | [trpo_pendulum] epoch #366 | Saving snapshot...
2022-08-17 17:57:11 | [trpo_pendulum] epoch #366 | Saved
2022-08-17 17:57:11 | [trpo_pendulum] epoch #366 | Time 151.68 s
2022-08-17 17:57:11 | [trpo_pendulum] epoch #366 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -683.196
Evaluation/AverageReturn              -1610.47
Evaluation/Iteration                    366
Evaluation/MaxReturn                  -1560.42
Evaluation/MinReturn                  -1636.02
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     26.1713
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41649
GaussianMLPPolicy/KL                      8.89653e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -636.396
GaussianMLPPolicy/LossBefore           -636.001
GaussianMLPPolicy/dLoss                   0.395569
GaussianMLPValueFunction/LossAfter    71797.7
GaussianMLPValueFunction/LossBefore   71899.7
GaussianMLPValueFunction/dLoss          102.07
TotalEnvSteps                        440400
-----------------------------------  ----------------
2022-08-17 17:57:12 | [trpo_pendulum] epoch #367 | Saving snapshot...
2022-08-17 17:57:12 | [trpo_pendulum] epoch #367 | Saved
2022-08-17 17:57:12 | [trpo_pendulum] epoch #367 | Time 152.11 s
2022-08-17 17:57:12 | [trpo_pendulum] epoch #367 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -472.312
Evaluation/AverageReturn              -1131.84
Evaluation/Iteration                    367
Evaluation/MaxReturn                   -867.053
Evaluation/MinReturn                  -1246.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    132.818
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4164
GaussianMLPPolicy/KL                      3.24656e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -444.38
GaussianMLPPolicy/LossBefore           -444.379
GaussianMLPPolicy/dLoss                   0.000732422
GaussianMLPValueFunction/LossAfter    36092.2
GaussianMLPValueFunction/LossBefore   36144.3
GaussianMLPValueFunction/dLoss           52.1133
TotalEnvSteps                        441600
-----------------------------------  ----------------
2022-08-17 17:57:12 | [trpo_pendulum] epoch #368 | Saving snapshot...
2022-08-17 17:57:12 | [trpo_pendulum] epoch #368 | Saved
2022-08-17 17:57:12 | [trpo_pendulum] epoch #368 | Time 152.51 s
2022-08-17 17:57:12 | [trpo_pendulum] epoch #368 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -678.994
Evaluation/AverageReturn              -1629.92
Evaluation/Iteration                    368
Evaluation/MaxReturn                  -1455.87
Evaluation/MinReturn                  -1691.46
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     80.7984
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41642
GaussianMLPPolicy/KL                      2.50291e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -643.349
GaussianMLPPolicy/LossBefore           -643.446
GaussianMLPPolicy/dLoss                  -0.0968018
GaussianMLPValueFunction/LossAfter    75085.9
GaussianMLPValueFunction/LossBefore   75192.1
GaussianMLPValueFunction/dLoss          106.266
TotalEnvSteps                        442800
-----------------------------------  ----------------
2022-08-17 17:57:13 | [trpo_pendulum] epoch #369 | Saving snapshot...
2022-08-17 17:57:13 | [trpo_pendulum] epoch #369 | Saved
2022-08-17 17:57:13 | [trpo_pendulum] epoch #369 | Time 152.94 s
2022-08-17 17:57:13 | [trpo_pendulum] epoch #369 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -421.039
Evaluation/AverageReturn              -1023.02
Evaluation/Iteration                    369
Evaluation/MaxReturn                   -759.475
Evaluation/MinReturn                  -1329.62
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    225.562
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41645
GaussianMLPPolicy/KL                      4.32528e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -405.982
GaussianMLPPolicy/LossBefore           -405.97
GaussianMLPPolicy/dLoss                   0.0120544
GaussianMLPValueFunction/LossAfter    30875.1
GaussianMLPValueFunction/LossBefore   30919.9
GaussianMLPValueFunction/dLoss           44.7637
TotalEnvSteps                        444000
-----------------------------------  ----------------
2022-08-17 17:57:13 | [trpo_pendulum] epoch #370 | Saving snapshot...
2022-08-17 17:57:13 | [trpo_pendulum] epoch #370 | Saved
2022-08-17 17:57:13 | [trpo_pendulum] epoch #370 | Time 153.35 s
2022-08-17 17:57:13 | [trpo_pendulum] epoch #370 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -518.59
Evaluation/AverageReturn              -1239.7
Evaluation/Iteration                    370
Evaluation/MaxReturn                   -858.942
Evaluation/MinReturn                  -1363.28
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    171.952
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41654
GaussianMLPPolicy/KL                      6.67416e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -483.023
GaussianMLPPolicy/LossBefore           -482.973
GaussianMLPPolicy/dLoss                   0.0502625
GaussianMLPValueFunction/LossAfter    43168.8
GaussianMLPValueFunction/LossBefore   43228.2
GaussianMLPValueFunction/dLoss           59.3672
TotalEnvSteps                        445200
-----------------------------------  ----------------
2022-08-17 17:57:13 | [trpo_pendulum] epoch #371 | Saving snapshot...
2022-08-17 17:57:13 | [trpo_pendulum] epoch #371 | Saved
2022-08-17 17:57:13 | [trpo_pendulum] epoch #371 | Time 153.75 s
2022-08-17 17:57:13 | [trpo_pendulum] epoch #371 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -758.973
Evaluation/AverageReturn              -1763.35
Evaluation/Iteration                    371
Evaluation/MaxReturn                  -1656.83
Evaluation/MinReturn                  -1808.35
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.6276
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4166
GaussianMLPPolicy/KL                      2.51092e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -693.723
GaussianMLPPolicy/LossBefore           -693.637
GaussianMLPPolicy/dLoss                   0.0852661
GaussianMLPValueFunction/LossAfter    84988.2
GaussianMLPValueFunction/LossBefore   85106.4
GaussianMLPValueFunction/dLoss          118.211
TotalEnvSteps                        446400
-----------------------------------  ----------------
2022-08-17 17:57:14 | [trpo_pendulum] epoch #372 | Saving snapshot...
2022-08-17 17:57:14 | [trpo_pendulum] epoch #372 | Saved
2022-08-17 17:57:14 | [trpo_pendulum] epoch #372 | Time 154.15 s
2022-08-17 17:57:14 | [trpo_pendulum] epoch #372 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -650.38
Evaluation/AverageReturn              -1574.87
Evaluation/Iteration                    372
Evaluation/MaxReturn                  -1453.74
Evaluation/MinReturn                  -1677.97
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     77.4619
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41658
GaussianMLPPolicy/KL                      3.86175e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -641.172
GaussianMLPPolicy/LossBefore           -641.002
GaussianMLPPolicy/dLoss                   0.170166
GaussianMLPValueFunction/LossAfter    70323.8
GaussianMLPValueFunction/LossBefore   70424.9
GaussianMLPValueFunction/dLoss          101.086
TotalEnvSteps                        447600
-----------------------------------  ----------------
2022-08-17 17:57:14 | [trpo_pendulum] epoch #373 | Saving snapshot...
2022-08-17 17:57:14 | [trpo_pendulum] epoch #373 | Saved
2022-08-17 17:57:14 | [trpo_pendulum] epoch #373 | Time 154.55 s
2022-08-17 17:57:14 | [trpo_pendulum] epoch #373 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -729.455
Evaluation/AverageReturn              -1713.72
Evaluation/Iteration                    373
Evaluation/MaxReturn                  -1685.51
Evaluation/MinReturn                  -1766.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     27.8734
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41639
GaussianMLPPolicy/KL                      1.92641e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -691.275
GaussianMLPPolicy/LossBefore           -691.317
GaussianMLPPolicy/dLoss                  -0.0426025
GaussianMLPValueFunction/LossAfter    81206.5
GaussianMLPValueFunction/LossBefore   81326.6
GaussianMLPValueFunction/dLoss          120.18
TotalEnvSteps                        448800
-----------------------------------  ----------------
2022-08-17 17:57:15 | [trpo_pendulum] epoch #374 | Saving snapshot...
2022-08-17 17:57:15 | [trpo_pendulum] epoch #374 | Saved
2022-08-17 17:57:15 | [trpo_pendulum] epoch #374 | Time 154.96 s
2022-08-17 17:57:15 | [trpo_pendulum] epoch #374 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -468.614
Evaluation/AverageReturn              -1141.21
Evaluation/Iteration                    374
Evaluation/MaxReturn                   -766.484
Evaluation/MinReturn                  -1285.87
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    172.947
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41632
GaussianMLPPolicy/KL                      3.38739e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -447.032
GaussianMLPPolicy/LossBefore           -446.982
GaussianMLPPolicy/dLoss                   0.0496216
GaussianMLPValueFunction/LossAfter    37019.6
GaussianMLPValueFunction/LossBefore   37075.1
GaussianMLPValueFunction/dLoss           55.5352
TotalEnvSteps                        450000
-----------------------------------  ----------------
2022-08-17 17:57:15 | [trpo_pendulum] epoch #375 | Saving snapshot...
2022-08-17 17:57:15 | [trpo_pendulum] epoch #375 | Saved
2022-08-17 17:57:15 | [trpo_pendulum] epoch #375 | Time 155.38 s
2022-08-17 17:57:15 | [trpo_pendulum] epoch #375 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -334.477
Evaluation/AverageReturn               -915.472
Evaluation/Iteration                    375
Evaluation/MaxReturn                   -847.174
Evaluation/MinReturn                   -963.11
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     42.2194
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41631
GaussianMLPPolicy/KL                      5.70236e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -385.382
GaussianMLPPolicy/LossBefore           -385.314
GaussianMLPPolicy/dLoss                   0.0681458
GaussianMLPValueFunction/LossAfter    26293.6
GaussianMLPValueFunction/LossBefore   26333.1
GaussianMLPValueFunction/dLoss           39.4922
TotalEnvSteps                        451200
-----------------------------------  ----------------
2022-08-17 17:57:15 | [trpo_pendulum] epoch #376 | Saving snapshot...
2022-08-17 17:57:15 | [trpo_pendulum] epoch #376 | Saved
2022-08-17 17:57:15 | [trpo_pendulum] epoch #376 | Time 155.79 s
2022-08-17 17:57:15 | [trpo_pendulum] epoch #376 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -462.94
Evaluation/AverageReturn              -1093.39
Evaluation/Iteration                    376
Evaluation/MaxReturn                   -864.014
Evaluation/MinReturn                  -1353.69
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    170.056
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41623
GaussianMLPPolicy/KL                      0.000112193
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -432.329
GaussianMLPPolicy/LossBefore           -432.145
GaussianMLPPolicy/dLoss                   0.184723
GaussianMLPValueFunction/LossAfter    32896.2
GaussianMLPValueFunction/LossBefore   32942
GaussianMLPValueFunction/dLoss           45.7734
TotalEnvSteps                        452400
-----------------------------------  ----------------
2022-08-17 17:57:16 | [trpo_pendulum] epoch #377 | Saving snapshot...
2022-08-17 17:57:16 | [trpo_pendulum] epoch #377 | Saved
2022-08-17 17:57:16 | [trpo_pendulum] epoch #377 | Time 156.20 s
2022-08-17 17:57:16 | [trpo_pendulum] epoch #377 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -765.189
Evaluation/AverageReturn              -1777.09
Evaluation/Iteration                    377
Evaluation/MaxReturn                  -1725.25
Evaluation/MinReturn                  -1827.05
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     34.7945
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41602
GaussianMLPPolicy/KL                      7.2031e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -709.026
GaussianMLPPolicy/LossBefore           -708.769
GaussianMLPPolicy/dLoss                   0.256775
GaussianMLPValueFunction/LossAfter    85471.1
GaussianMLPValueFunction/LossBefore   85588.6
GaussianMLPValueFunction/dLoss          117.531
TotalEnvSteps                        453600
-----------------------------------  ---------------
2022-08-17 17:57:16 | [trpo_pendulum] epoch #378 | Saving snapshot...
2022-08-17 17:57:16 | [trpo_pendulum] epoch #378 | Saved
2022-08-17 17:57:16 | [trpo_pendulum] epoch #378 | Time 156.60 s
2022-08-17 17:57:16 | [trpo_pendulum] epoch #378 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -564.287
Evaluation/AverageReturn              -1329.03
Evaluation/Iteration                    378
Evaluation/MaxReturn                  -1295.68
Evaluation/MinReturn                  -1380.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     31.3625
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4159
GaussianMLPPolicy/KL                      0.000102569
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -513.21
GaussianMLPPolicy/LossBefore           -513.184
GaussianMLPPolicy/dLoss                   0.0263062
GaussianMLPValueFunction/LossAfter    47633.2
GaussianMLPValueFunction/LossBefore   47700
GaussianMLPValueFunction/dLoss           66.7617
TotalEnvSteps                        454800
-----------------------------------  ----------------
2022-08-17 17:57:17 | [trpo_pendulum] epoch #379 | Saving snapshot...
2022-08-17 17:57:17 | [trpo_pendulum] epoch #379 | Saved
2022-08-17 17:57:17 | [trpo_pendulum] epoch #379 | Time 157.00 s
2022-08-17 17:57:17 | [trpo_pendulum] epoch #379 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -712.005
Evaluation/AverageReturn              -1682.03
Evaluation/Iteration                    379
Evaluation/MaxReturn                  -1584.93
Evaluation/MinReturn                  -1742.99
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     54.0159
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41579
GaussianMLPPolicy/KL                      8.00114e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -666.206
GaussianMLPPolicy/LossBefore           -665.964
GaussianMLPPolicy/dLoss                   0.241699
GaussianMLPValueFunction/LossAfter    77855.8
GaussianMLPValueFunction/LossBefore   77966.1
GaussianMLPValueFunction/dLoss          110.312
TotalEnvSteps                        456000
-----------------------------------  ----------------
2022-08-17 17:57:17 | [trpo_pendulum] epoch #380 | Saving snapshot...
2022-08-17 17:57:17 | [trpo_pendulum] epoch #380 | Saved
2022-08-17 17:57:17 | [trpo_pendulum] epoch #380 | Time 157.40 s
2022-08-17 17:57:17 | [trpo_pendulum] epoch #380 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -363.842
Evaluation/AverageReturn               -888.641
Evaluation/Iteration                    380
Evaluation/MaxReturn                   -857.539
Evaluation/MinReturn                   -958.972
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     33.0557
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41566
GaussianMLPPolicy/KL                      8.68253e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -353.991
GaussianMLPPolicy/LossBefore           -354.033
GaussianMLPPolicy/dLoss                  -0.0417175
GaussianMLPValueFunction/LossAfter    22168.1
GaussianMLPValueFunction/LossBefore   22201.6
GaussianMLPValueFunction/dLoss           33.4668
TotalEnvSteps                        457200
-----------------------------------  ----------------
2022-08-17 17:57:17 | [trpo_pendulum] epoch #381 | Saving snapshot...
2022-08-17 17:57:17 | [trpo_pendulum] epoch #381 | Saved
2022-08-17 17:57:17 | [trpo_pendulum] epoch #381 | Time 157.81 s
2022-08-17 17:57:17 | [trpo_pendulum] epoch #381 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -335.304
Evaluation/AverageReturn               -829.673
Evaluation/Iteration                    381
Evaluation/MaxReturn                   -663.898
Evaluation/MinReturn                  -1033.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    119.125
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41559
GaussianMLPPolicy/KL                      5.65875e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -325.082
GaussianMLPPolicy/LossBefore           -325.086
GaussianMLPPolicy/dLoss                  -0.00430298
GaussianMLPValueFunction/LossAfter    20106.5
GaussianMLPValueFunction/LossBefore   20135.9
GaussianMLPValueFunction/dLoss           29.3281
TotalEnvSteps                        458400
-----------------------------------  ----------------
2022-08-17 17:57:18 | [trpo_pendulum] epoch #382 | Saving snapshot...
2022-08-17 17:57:18 | [trpo_pendulum] epoch #382 | Saved
2022-08-17 17:57:18 | [trpo_pendulum] epoch #382 | Time 158.22 s
2022-08-17 17:57:18 | [trpo_pendulum] epoch #382 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -777.708
Evaluation/AverageReturn              -1790.98
Evaluation/Iteration                    382
Evaluation/MaxReturn                  -1687.68
Evaluation/MinReturn                  -1839.38
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     48.7626
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41555
GaussianMLPPolicy/KL                      1.10438e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -694.745
GaussianMLPPolicy/LossBefore           -694.653
GaussianMLPPolicy/dLoss                   0.092041
GaussianMLPValueFunction/LossAfter    85415.9
GaussianMLPValueFunction/LossBefore   85529.6
GaussianMLPValueFunction/dLoss          113.672
TotalEnvSteps                        459600
-----------------------------------  ----------------
2022-08-17 17:57:18 | [trpo_pendulum] epoch #383 | Saving snapshot...
2022-08-17 17:57:18 | [trpo_pendulum] epoch #383 | Saved
2022-08-17 17:57:18 | [trpo_pendulum] epoch #383 | Time 158.64 s
2022-08-17 17:57:18 | [trpo_pendulum] epoch #383 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -692.082
Evaluation/AverageReturn              -1586.23
Evaluation/Iteration                    383
Evaluation/MaxReturn                  -1446.53
Evaluation/MinReturn                  -1647.5
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     73.1939
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41548
GaussianMLPPolicy/KL                      2.05947e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -615.854
GaussianMLPPolicy/LossBefore           -615.672
GaussianMLPPolicy/dLoss                   0.181335
GaussianMLPValueFunction/LossAfter    66642.6
GaussianMLPValueFunction/LossBefore   66734.3
GaussianMLPValueFunction/dLoss           91.7188
TotalEnvSteps                        460800
-----------------------------------  ----------------
2022-08-17 17:57:19 | [trpo_pendulum] epoch #384 | Saving snapshot...
2022-08-17 17:57:19 | [trpo_pendulum] epoch #384 | Saved
2022-08-17 17:57:19 | [trpo_pendulum] epoch #384 | Time 159.05 s
2022-08-17 17:57:19 | [trpo_pendulum] epoch #384 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -357.155
Evaluation/AverageReturn               -858.837
Evaluation/Iteration                    384
Evaluation/MaxReturn                   -761.177
Evaluation/MinReturn                   -924.581
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     52.1439
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41543
GaussianMLPPolicy/KL                      3.36993e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -331.883
GaussianMLPPolicy/LossBefore           -331.858
GaussianMLPPolicy/dLoss                   0.0257568
GaussianMLPValueFunction/LossAfter    19917.1
GaussianMLPValueFunction/LossBefore   19946.8
GaussianMLPValueFunction/dLoss           29.6543
TotalEnvSteps                        462000
-----------------------------------  ----------------
2022-08-17 17:57:19 | [trpo_pendulum] epoch #385 | Saving snapshot...
2022-08-17 17:57:19 | [trpo_pendulum] epoch #385 | Saved
2022-08-17 17:57:19 | [trpo_pendulum] epoch #385 | Time 159.46 s
2022-08-17 17:57:19 | [trpo_pendulum] epoch #385 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -751.335
Evaluation/AverageReturn              -1764.53
Evaluation/Iteration                    385
Evaluation/MaxReturn                  -1706.12
Evaluation/MinReturn                  -1806.99
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     36.0121
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41556
GaussianMLPPolicy/KL                      8.29115e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -681.727
GaussianMLPPolicy/LossBefore           -681.62
GaussianMLPPolicy/dLoss                   0.106995
GaussianMLPValueFunction/LossAfter    84359.5
GaussianMLPValueFunction/LossBefore   84474
GaussianMLPValueFunction/dLoss          114.477
TotalEnvSteps                        463200
-----------------------------------  ----------------
2022-08-17 17:57:19 | [trpo_pendulum] epoch #386 | Saving snapshot...
2022-08-17 17:57:20 | [trpo_pendulum] epoch #386 | Saved
2022-08-17 17:57:20 | [trpo_pendulum] epoch #386 | Time 159.87 s
2022-08-17 17:57:20 | [trpo_pendulum] epoch #386 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -746.821
Evaluation/AverageReturn              -1728.11
Evaluation/Iteration                    386
Evaluation/MaxReturn                  -1642.84
Evaluation/MinReturn                  -1813.37
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.7163
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4157
GaussianMLPPolicy/KL                      5.55146e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -671.318
GaussianMLPPolicy/LossBefore           -671.292
GaussianMLPPolicy/dLoss                   0.0263672
GaussianMLPValueFunction/LossAfter    79245.3
GaussianMLPValueFunction/LossBefore   79357.7
GaussianMLPValueFunction/dLoss          112.398
TotalEnvSteps                        464400
-----------------------------------  ----------------
2022-08-17 17:57:20 | [trpo_pendulum] epoch #387 | Saving snapshot...
2022-08-17 17:57:20 | [trpo_pendulum] epoch #387 | Saved
2022-08-17 17:57:20 | [trpo_pendulum] epoch #387 | Time 160.28 s
2022-08-17 17:57:20 | [trpo_pendulum] epoch #387 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -492.295
Evaluation/AverageReturn              -1133.61
Evaluation/Iteration                    387
Evaluation/MaxReturn                   -863.031
Evaluation/MinReturn                  -1277.09
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    163.151
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41582
GaussianMLPPolicy/KL                      4.60013e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -433.482
GaussianMLPPolicy/LossBefore           -433.405
GaussianMLPPolicy/dLoss                   0.0768738
GaussianMLPValueFunction/LossAfter    33752.9
GaussianMLPValueFunction/LossBefore   33801.4
GaussianMLPValueFunction/dLoss           48.5664
TotalEnvSteps                        465600
-----------------------------------  ----------------
2022-08-17 17:57:20 | [trpo_pendulum] epoch #388 | Saving snapshot...
2022-08-17 17:57:20 | [trpo_pendulum] epoch #388 | Saved
2022-08-17 17:57:20 | [trpo_pendulum] epoch #388 | Time 160.68 s
2022-08-17 17:57:20 | [trpo_pendulum] epoch #388 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -493.566
Evaluation/AverageReturn              -1163.55
Evaluation/Iteration                    388
Evaluation/MaxReturn                   -994.504
Evaluation/MinReturn                  -1277.3
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    102.57
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.416
GaussianMLPPolicy/KL                      0.000103588
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -445.705
GaussianMLPPolicy/LossBefore           -445.529
GaussianMLPPolicy/dLoss                   0.1763
GaussianMLPValueFunction/LossAfter    35767.8
GaussianMLPValueFunction/LossBefore   35817.6
GaussianMLPValueFunction/dLoss           49.8203
TotalEnvSteps                        466800
-----------------------------------  ----------------
2022-08-17 17:57:21 | [trpo_pendulum] epoch #389 | Saving snapshot...
2022-08-17 17:57:21 | [trpo_pendulum] epoch #389 | Saved
2022-08-17 17:57:21 | [trpo_pendulum] epoch #389 | Time 161.10 s
2022-08-17 17:57:21 | [trpo_pendulum] epoch #389 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -608.9
Evaluation/AverageReturn              -1415
Evaluation/Iteration                    389
Evaluation/MaxReturn                  -1327.65
Evaluation/MinReturn                  -1532.49
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     70.4125
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41613
GaussianMLPPolicy/KL                      2.08203e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -551.563
GaussianMLPPolicy/LossBefore           -551.473
GaussianMLPPolicy/dLoss                   0.0895996
GaussianMLPValueFunction/LossAfter    52724.5
GaussianMLPValueFunction/LossBefore   52795.6
GaussianMLPValueFunction/dLoss           71.0781
TotalEnvSteps                        468000
-----------------------------------  ----------------
2022-08-17 17:57:21 | [trpo_pendulum] epoch #390 | Saving snapshot...
2022-08-17 17:57:21 | [trpo_pendulum] epoch #390 | Saved
2022-08-17 17:57:21 | [trpo_pendulum] epoch #390 | Time 161.49 s
2022-08-17 17:57:21 | [trpo_pendulum] epoch #390 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -611.625
Evaluation/AverageReturn              -1418.11
Evaluation/Iteration                    390
Evaluation/MaxReturn                  -1229.29
Evaluation/MinReturn                  -1627.73
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    151.966
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41629
GaussianMLPPolicy/KL                      1.24215e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -546.192
GaussianMLPPolicy/LossBefore           -546.195
GaussianMLPPolicy/dLoss                  -0.00268555
GaussianMLPValueFunction/LossAfter    53560.5
GaussianMLPValueFunction/LossBefore   53632.7
GaussianMLPValueFunction/dLoss           72.2188
TotalEnvSteps                        469200
-----------------------------------  ----------------
2022-08-17 17:57:22 | [trpo_pendulum] epoch #391 | Saving snapshot...
2022-08-17 17:57:22 | [trpo_pendulum] epoch #391 | Saved
2022-08-17 17:57:22 | [trpo_pendulum] epoch #391 | Time 161.89 s
2022-08-17 17:57:22 | [trpo_pendulum] epoch #391 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -697.901
Evaluation/AverageReturn              -1621.09
Evaluation/Iteration                    391
Evaluation/MaxReturn                  -1440.36
Evaluation/MinReturn                  -1706.54
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     90.848
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4164
GaussianMLPPolicy/KL                      4.8167e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -634.693
GaussianMLPPolicy/LossBefore           -634.457
GaussianMLPPolicy/dLoss                   0.236328
GaussianMLPValueFunction/LossAfter    69856.5
GaussianMLPValueFunction/LossBefore   69952.2
GaussianMLPValueFunction/dLoss           95.7422
TotalEnvSteps                        470400
-----------------------------------  ---------------
2022-08-17 17:57:22 | [trpo_pendulum] epoch #392 | Saving snapshot...
2022-08-17 17:57:22 | [trpo_pendulum] epoch #392 | Saved
2022-08-17 17:57:22 | [trpo_pendulum] epoch #392 | Time 162.30 s
2022-08-17 17:57:22 | [trpo_pendulum] epoch #392 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -772.772
Evaluation/AverageReturn              -1763.04
Evaluation/Iteration                    392
Evaluation/MaxReturn                  -1624.23
Evaluation/MinReturn                  -1830.04
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     74.1953
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41661
GaussianMLPPolicy/KL                      7.4125e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -671.289
GaussianMLPPolicy/LossBefore           -671.118
GaussianMLPPolicy/dLoss                   0.170288
GaussianMLPValueFunction/LossAfter    81070.1
GaussianMLPValueFunction/LossBefore   81185.5
GaussianMLPValueFunction/dLoss          115.414
TotalEnvSteps                        471600
-----------------------------------  ---------------
2022-08-17 17:57:22 | [trpo_pendulum] epoch #393 | Saving snapshot...
2022-08-17 17:57:22 | [trpo_pendulum] epoch #393 | Saved
2022-08-17 17:57:22 | [trpo_pendulum] epoch #393 | Time 162.70 s
2022-08-17 17:57:22 | [trpo_pendulum] epoch #393 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -356.558
Evaluation/AverageReturn               -867.012
Evaluation/Iteration                    393
Evaluation/MaxReturn                   -762.194
Evaluation/MinReturn                   -939.678
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     53.8368
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41675
GaussianMLPPolicy/KL                      8.75438e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -345.271
GaussianMLPPolicy/LossBefore           -345.257
GaussianMLPPolicy/dLoss                   0.0142212
GaussianMLPValueFunction/LossAfter    20392.9
GaussianMLPValueFunction/LossBefore   20424.3
GaussianMLPValueFunction/dLoss           31.4004
TotalEnvSteps                        472800
-----------------------------------  ----------------
2022-08-17 17:57:23 | [trpo_pendulum] epoch #394 | Saving snapshot...
2022-08-17 17:57:23 | [trpo_pendulum] epoch #394 | Saved
2022-08-17 17:57:23 | [trpo_pendulum] epoch #394 | Time 163.12 s
2022-08-17 17:57:23 | [trpo_pendulum] epoch #394 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -403.397
Evaluation/AverageReturn               -920.338
Evaluation/Iteration                    394
Evaluation/MaxReturn                   -876.48
Evaluation/MinReturn                  -1008.27
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     51.3607
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41683
GaussianMLPPolicy/KL                      3.6285e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -348.415
GaussianMLPPolicy/LossBefore           -348.368
GaussianMLPPolicy/dLoss                   0.0466614
GaussianMLPValueFunction/LossAfter    21469.8
GaussianMLPValueFunction/LossBefore   21500.3
GaussianMLPValueFunction/dLoss           30.5332
TotalEnvSteps                        474000
-----------------------------------  ---------------
2022-08-17 17:57:23 | [trpo_pendulum] epoch #395 | Saving snapshot...
2022-08-17 17:57:23 | [trpo_pendulum] epoch #395 | Saved
2022-08-17 17:57:23 | [trpo_pendulum] epoch #395 | Time 163.53 s
2022-08-17 17:57:23 | [trpo_pendulum] epoch #395 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -506.142
Evaluation/AverageReturn              -1159.06
Evaluation/Iteration                    395
Evaluation/MaxReturn                  -1056.97
Evaluation/MinReturn                  -1319.61
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     90.0682
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41697
GaussianMLPPolicy/KL                      4.87505e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -434.936
GaussianMLPPolicy/LossBefore           -434.986
GaussianMLPPolicy/dLoss                  -0.0496521
GaussianMLPValueFunction/LossAfter    33923.3
GaussianMLPValueFunction/LossBefore   33967.3
GaussianMLPValueFunction/dLoss           43.9492
TotalEnvSteps                        475200
-----------------------------------  ----------------
2022-08-17 17:57:24 | [trpo_pendulum] epoch #396 | Saving snapshot...
2022-08-17 17:57:24 | [trpo_pendulum] epoch #396 | Saved
2022-08-17 17:57:24 | [trpo_pendulum] epoch #396 | Time 163.93 s
2022-08-17 17:57:24 | [trpo_pendulum] epoch #396 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -663.328
Evaluation/AverageReturn              -1555.37
Evaluation/Iteration                    396
Evaluation/MaxReturn                  -1459.93
Evaluation/MinReturn                  -1634.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     58.2184
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41722
GaussianMLPPolicy/KL                      8.94291e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -599.293
GaussianMLPPolicy/LossBefore           -598.897
GaussianMLPPolicy/dLoss                   0.396545
GaussianMLPValueFunction/LossAfter    64167.6
GaussianMLPValueFunction/LossBefore   64249.4
GaussianMLPValueFunction/dLoss           81.793
TotalEnvSteps                        476400
-----------------------------------  ----------------
2022-08-17 17:57:24 | [trpo_pendulum] epoch #397 | Saving snapshot...
2022-08-17 17:57:24 | [trpo_pendulum] epoch #397 | Saved
2022-08-17 17:57:24 | [trpo_pendulum] epoch #397 | Time 164.34 s
2022-08-17 17:57:24 | [trpo_pendulum] epoch #397 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -503.612
Evaluation/AverageReturn              -1133.18
Evaluation/Iteration                    397
Evaluation/MaxReturn                   -960.396
Evaluation/MinReturn                  -1285.35
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    100.151
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4175
GaussianMLPPolicy/KL                      7.26591e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -419.142
GaussianMLPPolicy/LossBefore           -419.129
GaussianMLPPolicy/dLoss                   0.0131226
GaussianMLPValueFunction/LossAfter    32077.3
GaussianMLPValueFunction/LossBefore   32118.7
GaussianMLPValueFunction/dLoss           41.4395
TotalEnvSteps                        477600
-----------------------------------  ----------------
2022-08-17 17:57:24 | [trpo_pendulum] epoch #398 | Saving snapshot...
2022-08-17 17:57:24 | [trpo_pendulum] epoch #398 | Saved
2022-08-17 17:57:24 | [trpo_pendulum] epoch #398 | Time 164.74 s
2022-08-17 17:57:24 | [trpo_pendulum] epoch #398 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -766.836
Evaluation/AverageReturn              -1759.32
Evaluation/Iteration                    398
Evaluation/MaxReturn                  -1686.09
Evaluation/MinReturn                  -1839.49
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     59.9251
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41767
GaussianMLPPolicy/KL                      5.15355e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -689.178
GaussianMLPPolicy/LossBefore           -688.993
GaussianMLPPolicy/dLoss                   0.185242
GaussianMLPValueFunction/LossAfter    80812.3
GaussianMLPValueFunction/LossBefore   80916.9
GaussianMLPValueFunction/dLoss          104.625
TotalEnvSteps                        478800
-----------------------------------  ----------------
2022-08-17 17:57:25 | [trpo_pendulum] epoch #399 | Saving snapshot...
2022-08-17 17:57:25 | [trpo_pendulum] epoch #399 | Saved
2022-08-17 17:57:25 | [trpo_pendulum] epoch #399 | Time 165.16 s
2022-08-17 17:57:25 | [trpo_pendulum] epoch #399 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -709.792
Evaluation/AverageReturn              -1645.3
Evaluation/Iteration                    399
Evaluation/MaxReturn                  -1580
Evaluation/MinReturn                  -1730.56
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     48.8244
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4177
GaussianMLPPolicy/KL                      8.09658e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -652.956
GaussianMLPPolicy/LossBefore           -652.853
GaussianMLPPolicy/dLoss                   0.103699
GaussianMLPValueFunction/LossAfter    70656.8
GaussianMLPValueFunction/LossBefore   70752.2
GaussianMLPValueFunction/dLoss           95.3672
TotalEnvSteps                        480000
-----------------------------------  ----------------
2022-08-17 17:57:25 | [trpo_pendulum] epoch #400 | Saving snapshot...
2022-08-17 17:57:25 | [trpo_pendulum] epoch #400 | Saved
2022-08-17 17:57:25 | [trpo_pendulum] epoch #400 | Time 165.55 s
2022-08-17 17:57:25 | [trpo_pendulum] epoch #400 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -710.205
Evaluation/AverageReturn              -1608.93
Evaluation/Iteration                    400
Evaluation/MaxReturn                  -1506.44
Evaluation/MinReturn                  -1793.05
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     98.603
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41789
GaussianMLPPolicy/KL                      5.52376e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -600.132
GaussianMLPPolicy/LossBefore           -600.124
GaussianMLPPolicy/dLoss                   0.00750732
GaussianMLPValueFunction/LossAfter    66131.6
GaussianMLPValueFunction/LossBefore   66223.1
GaussianMLPValueFunction/dLoss           91.4922
TotalEnvSteps                        481200
-----------------------------------  ----------------
2022-08-17 17:57:26 | [trpo_pendulum] epoch #401 | Saving snapshot...
2022-08-17 17:57:26 | [trpo_pendulum] epoch #401 | Saved
2022-08-17 17:57:26 | [trpo_pendulum] epoch #401 | Time 165.96 s
2022-08-17 17:57:26 | [trpo_pendulum] epoch #401 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -435.07
Evaluation/AverageReturn              -1000.92
Evaluation/Iteration                    401
Evaluation/MaxReturn                   -868.156
Evaluation/MinReturn                  -1143.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     92.8445
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41801
GaussianMLPPolicy/KL                      7.61516e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -385.681
GaussianMLPPolicy/LossBefore           -385.607
GaussianMLPPolicy/dLoss                   0.0741272
GaussianMLPValueFunction/LossAfter    25546.8
GaussianMLPValueFunction/LossBefore   25583.6
GaussianMLPValueFunction/dLoss           36.8281
TotalEnvSteps                        482400
-----------------------------------  ----------------
2022-08-17 17:57:26 | [trpo_pendulum] epoch #402 | Saving snapshot...
2022-08-17 17:57:26 | [trpo_pendulum] epoch #402 | Saved
2022-08-17 17:57:26 | [trpo_pendulum] epoch #402 | Time 166.37 s
2022-08-17 17:57:26 | [trpo_pendulum] epoch #402 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -633.979
Evaluation/AverageReturn              -1434.82
Evaluation/Iteration                    402
Evaluation/MaxReturn                  -1366.63
Evaluation/MinReturn                  -1514.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     52.5426
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41794
GaussianMLPPolicy/KL                      5.37422e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -560.423
GaussianMLPPolicy/LossBefore           -560.249
GaussianMLPPolicy/dLoss                   0.173218
GaussianMLPValueFunction/LossAfter    51773.7
GaussianMLPValueFunction/LossBefore   51842.6
GaussianMLPValueFunction/dLoss           68.9414
TotalEnvSteps                        483600
-----------------------------------  ----------------
2022-08-17 17:57:26 | [trpo_pendulum] epoch #403 | Saving snapshot...
2022-08-17 17:57:26 | [trpo_pendulum] epoch #403 | Saved
2022-08-17 17:57:26 | [trpo_pendulum] epoch #403 | Time 166.78 s
2022-08-17 17:57:26 | [trpo_pendulum] epoch #403 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -408.783
Evaluation/AverageReturn               -939.822
Evaluation/Iteration                    403
Evaluation/MaxReturn                   -901.515
Evaluation/MinReturn                  -1022.71
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     47.3348
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41785
GaussianMLPPolicy/KL                      0.000445448
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -359.676
GaussianMLPPolicy/LossBefore           -358.917
GaussianMLPPolicy/dLoss                   0.759277
GaussianMLPValueFunction/LossAfter    22853.8
GaussianMLPValueFunction/LossBefore   22886.7
GaussianMLPValueFunction/dLoss           32.8906
TotalEnvSteps                        484800
-----------------------------------  ----------------
2022-08-17 17:57:27 | [trpo_pendulum] epoch #404 | Saving snapshot...
2022-08-17 17:57:27 | [trpo_pendulum] epoch #404 | Saved
2022-08-17 17:57:27 | [trpo_pendulum] epoch #404 | Time 167.20 s
2022-08-17 17:57:27 | [trpo_pendulum] epoch #404 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -356.549
Evaluation/AverageReturn               -873.503
Evaluation/Iteration                    404
Evaluation/MaxReturn                   -768.231
Evaluation/MinReturn                   -913.432
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     48.1636
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41774
GaussianMLPPolicy/KL                      0.000445833
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -347.234
GaussianMLPPolicy/LossBefore           -346.952
GaussianMLPPolicy/dLoss                   0.281952
GaussianMLPValueFunction/LossAfter    20631.4
GaussianMLPValueFunction/LossBefore   20660.2
GaussianMLPValueFunction/dLoss           28.8086
TotalEnvSteps                        486000
-----------------------------------  ----------------
2022-08-17 17:57:27 | [trpo_pendulum] epoch #405 | Saving snapshot...
2022-08-17 17:57:27 | [trpo_pendulum] epoch #405 | Saved
2022-08-17 17:57:27 | [trpo_pendulum] epoch #405 | Time 167.61 s
2022-08-17 17:57:27 | [trpo_pendulum] epoch #405 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -698.761
Evaluation/AverageReturn              -1621.31
Evaluation/Iteration                    405
Evaluation/MaxReturn                  -1429.96
Evaluation/MinReturn                  -1778.52
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    127.925
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41752
GaussianMLPPolicy/KL                      8.30264e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -642.386
GaussianMLPPolicy/LossBefore           -642.48
GaussianMLPPolicy/dLoss                  -0.0942993
GaussianMLPValueFunction/LossAfter    68713
GaussianMLPValueFunction/LossBefore   68797.5
GaussianMLPValueFunction/dLoss           84.5312
TotalEnvSteps                        487200
-----------------------------------  ----------------
2022-08-17 17:57:28 | [trpo_pendulum] epoch #406 | Saving snapshot...
2022-08-17 17:57:28 | [trpo_pendulum] epoch #406 | Saved
2022-08-17 17:57:28 | [trpo_pendulum] epoch #406 | Time 168.00 s
2022-08-17 17:57:28 | [trpo_pendulum] epoch #406 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -557.694
Evaluation/AverageReturn              -1299.93
Evaluation/Iteration                    406
Evaluation/MaxReturn                  -1166.5
Evaluation/MinReturn                  -1572.07
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    135.469
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41736
GaussianMLPPolicy/KL                      6.42163e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -499.823
GaussianMLPPolicy/LossBefore           -499.896
GaussianMLPPolicy/dLoss                  -0.072113
GaussianMLPValueFunction/LossAfter    43712
GaussianMLPValueFunction/LossBefore   43766.9
GaussianMLPValueFunction/dLoss           54.8633
TotalEnvSteps                        488400
-----------------------------------  ----------------
2022-08-17 17:57:28 | [trpo_pendulum] epoch #407 | Saving snapshot...
2022-08-17 17:57:28 | [trpo_pendulum] epoch #407 | Saved
2022-08-17 17:57:28 | [trpo_pendulum] epoch #407 | Time 168.41 s
2022-08-17 17:57:28 | [trpo_pendulum] epoch #407 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -515.518
Evaluation/AverageReturn              -1207.12
Evaluation/Iteration                    407
Evaluation/MaxReturn                  -1069.03
Evaluation/MinReturn                  -1327.42
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     82.0809
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41718
GaussianMLPPolicy/KL                      1.27482e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -470.318
GaussianMLPPolicy/LossBefore           -470.222
GaussianMLPPolicy/dLoss                   0.0962219
GaussianMLPValueFunction/LossAfter    37486.7
GaussianMLPValueFunction/LossBefore   37533.4
GaussianMLPValueFunction/dLoss           46.7656
TotalEnvSteps                        489600
-----------------------------------  ----------------
2022-08-17 17:57:28 | [trpo_pendulum] epoch #408 | Saving snapshot...
2022-08-17 17:57:28 | [trpo_pendulum] epoch #408 | Saved
2022-08-17 17:57:28 | [trpo_pendulum] epoch #408 | Time 168.82 s
2022-08-17 17:57:28 | [trpo_pendulum] epoch #408 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -600.805
Evaluation/AverageReturn              -1399.71
Evaluation/Iteration                    408
Evaluation/MaxReturn                  -1309.9
Evaluation/MinReturn                  -1476.16
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     56.7816
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41716
GaussianMLPPolicy/KL                      4.50273e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -531.312
GaussianMLPPolicy/LossBefore           -531.275
GaussianMLPPolicy/dLoss                   0.0369263
GaussianMLPValueFunction/LossAfter    50197.4
GaussianMLPValueFunction/LossBefore   50259
GaussianMLPValueFunction/dLoss           61.6445
TotalEnvSteps                        490800
-----------------------------------  ----------------
2022-08-17 17:57:29 | [trpo_pendulum] epoch #409 | Saving snapshot...
2022-08-17 17:57:29 | [trpo_pendulum] epoch #409 | Saved
2022-08-17 17:57:29 | [trpo_pendulum] epoch #409 | Time 169.24 s
2022-08-17 17:57:29 | [trpo_pendulum] epoch #409 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -487.97
Evaluation/AverageReturn              -1109.57
Evaluation/Iteration                    409
Evaluation/MaxReturn                   -938.257
Evaluation/MinReturn                  -1260.83
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    116.32
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41709
GaussianMLPPolicy/KL                      2.91349e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -421.908
GaussianMLPPolicy/LossBefore           -421.852
GaussianMLPPolicy/dLoss                   0.055481
GaussianMLPValueFunction/LossAfter    30526.3
GaussianMLPValueFunction/LossBefore   30564.1
GaussianMLPValueFunction/dLoss           37.8008
TotalEnvSteps                        492000
-----------------------------------  ----------------
2022-08-17 17:57:29 | [trpo_pendulum] epoch #410 | Saving snapshot...
2022-08-17 17:57:29 | [trpo_pendulum] epoch #410 | Saved
2022-08-17 17:57:29 | [trpo_pendulum] epoch #410 | Time 169.65 s
2022-08-17 17:57:29 | [trpo_pendulum] epoch #410 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -589.725
Evaluation/AverageReturn              -1355.42
Evaluation/Iteration                    410
Evaluation/MaxReturn                  -1297.33
Evaluation/MinReturn                  -1419.14
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.9025
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41701
GaussianMLPPolicy/KL                      2.37383e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -521.127
GaussianMLPPolicy/LossBefore           -520.953
GaussianMLPPolicy/dLoss                   0.174561
GaussianMLPValueFunction/LossAfter    46305.5
GaussianMLPValueFunction/LossBefore   46360.9
GaussianMLPValueFunction/dLoss           55.4062
TotalEnvSteps                        493200
-----------------------------------  ----------------
2022-08-17 17:57:30 | [trpo_pendulum] epoch #411 | Saving snapshot...
2022-08-17 17:57:30 | [trpo_pendulum] epoch #411 | Saved
2022-08-17 17:57:30 | [trpo_pendulum] epoch #411 | Time 170.05 s
2022-08-17 17:57:30 | [trpo_pendulum] epoch #411 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -734.699
Evaluation/AverageReturn              -1705.32
Evaluation/Iteration                    411
Evaluation/MaxReturn                  -1598.63
Evaluation/MinReturn                  -1823.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     79.4854
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41695
GaussianMLPPolicy/KL                      1.1124e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -665.179
GaussianMLPPolicy/LossBefore           -665.118
GaussianMLPPolicy/dLoss                   0.0609131
GaussianMLPValueFunction/LossAfter    75459.8
GaussianMLPValueFunction/LossBefore   75553.2
GaussianMLPValueFunction/dLoss           93.3828
TotalEnvSteps                        494400
-----------------------------------  ---------------
2022-08-17 17:57:30 | [trpo_pendulum] epoch #412 | Saving snapshot...
2022-08-17 17:57:30 | [trpo_pendulum] epoch #412 | Saved
2022-08-17 17:57:30 | [trpo_pendulum] epoch #412 | Time 170.46 s
2022-08-17 17:57:30 | [trpo_pendulum] epoch #412 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -358.658
Evaluation/AverageReturn               -882.496
Evaluation/Iteration                    412
Evaluation/MaxReturn                   -668.429
Evaluation/MinReturn                   -969.664
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    102.988
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41689
GaussianMLPPolicy/KL                      8.21577e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -348.688
GaussianMLPPolicy/LossBefore           -348.675
GaussianMLPPolicy/dLoss                   0.0133057
GaussianMLPValueFunction/LossAfter    21425.6
GaussianMLPValueFunction/LossBefore   21454
GaussianMLPValueFunction/dLoss           28.4805
TotalEnvSteps                        495600
-----------------------------------  ----------------
2022-08-17 17:57:31 | [trpo_pendulum] epoch #413 | Saving snapshot...
2022-08-17 17:57:31 | [trpo_pendulum] epoch #413 | Saved
2022-08-17 17:57:31 | [trpo_pendulum] epoch #413 | Time 170.87 s
2022-08-17 17:57:31 | [trpo_pendulum] epoch #413 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -381.82
Evaluation/AverageReturn               -922.887
Evaluation/Iteration                    413
Evaluation/MaxReturn                   -860.994
Evaluation/MinReturn                  -1008.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     54.0056
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41687
GaussianMLPPolicy/KL                      1.87043e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -358.951
GaussianMLPPolicy/LossBefore           -358.925
GaussianMLPPolicy/dLoss                   0.0260315
GaussianMLPValueFunction/LossAfter    22283.8
GaussianMLPValueFunction/LossBefore   22312.4
GaussianMLPValueFunction/dLoss           28.5859
TotalEnvSteps                        496800
-----------------------------------  ----------------
2022-08-17 17:57:31 | [trpo_pendulum] epoch #414 | Saving snapshot...
2022-08-17 17:57:31 | [trpo_pendulum] epoch #414 | Saved
2022-08-17 17:57:31 | [trpo_pendulum] epoch #414 | Time 171.28 s
2022-08-17 17:57:31 | [trpo_pendulum] epoch #414 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -460.24
Evaluation/AverageReturn              -1058.86
Evaluation/Iteration                    414
Evaluation/MaxReturn                   -975.883
Evaluation/MinReturn                  -1197.41
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     76.6277
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41686
GaussianMLPPolicy/KL                      3.17383e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -400.147
GaussianMLPPolicy/LossBefore           -400.153
GaussianMLPPolicy/dLoss                  -0.00601196
GaussianMLPValueFunction/LossAfter    27678.5
GaussianMLPValueFunction/LossBefore   27711.2
GaussianMLPValueFunction/dLoss           32.6348
TotalEnvSteps                        498000
-----------------------------------  ----------------
2022-08-17 17:57:31 | [trpo_pendulum] epoch #415 | Saving snapshot...
2022-08-17 17:57:31 | [trpo_pendulum] epoch #415 | Saved
2022-08-17 17:57:31 | [trpo_pendulum] epoch #415 | Time 171.69 s
2022-08-17 17:57:31 | [trpo_pendulum] epoch #415 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -609.494
Evaluation/AverageReturn              -1384.57
Evaluation/Iteration                    415
Evaluation/MaxReturn                  -1307.67
Evaluation/MinReturn                  -1535.36
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     72.1513
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41682
GaussianMLPPolicy/KL                      3.88383e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -529.153
GaussianMLPPolicy/LossBefore           -529.001
GaussianMLPPolicy/dLoss                   0.152161
GaussianMLPValueFunction/LossAfter    47726.7
GaussianMLPValueFunction/LossBefore   47780.2
GaussianMLPValueFunction/dLoss           53.4766
TotalEnvSteps                        499200
-----------------------------------  ----------------
2022-08-17 17:57:32 | [trpo_pendulum] epoch #416 | Saving snapshot...
2022-08-17 17:57:32 | [trpo_pendulum] epoch #416 | Saved
2022-08-17 17:57:32 | [trpo_pendulum] epoch #416 | Time 172.10 s
2022-08-17 17:57:32 | [trpo_pendulum] epoch #416 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -448.202
Evaluation/AverageReturn              -1025.14
Evaluation/Iteration                    416
Evaluation/MaxReturn                   -834.719
Evaluation/MinReturn                  -1258.24
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    143.634
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41681
GaussianMLPPolicy/KL                      5.45547e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -383.329
GaussianMLPPolicy/LossBefore           -383.284
GaussianMLPPolicy/dLoss                   0.0449829
GaussianMLPValueFunction/LossAfter    26098.4
GaussianMLPValueFunction/LossBefore   26128.5
GaussianMLPValueFunction/dLoss           30.1875
TotalEnvSteps                        500400
-----------------------------------  ----------------
2022-08-17 17:57:32 | [trpo_pendulum] epoch #417 | Saving snapshot...
2022-08-17 17:57:32 | [trpo_pendulum] epoch #417 | Saved
2022-08-17 17:57:32 | [trpo_pendulum] epoch #417 | Time 172.51 s
2022-08-17 17:57:32 | [trpo_pendulum] epoch #417 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -380.126
Evaluation/AverageReturn               -897.397
Evaluation/Iteration                    417
Evaluation/MaxReturn                   -765.567
Evaluation/MinReturn                  -1151.89
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    120.97
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4168
GaussianMLPPolicy/KL                      2.16645e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -343.585
GaussianMLPPolicy/LossBefore           -343.596
GaussianMLPPolicy/dLoss                  -0.0103455
GaussianMLPValueFunction/LossAfter    20731.1
GaussianMLPValueFunction/LossBefore   20755.2
GaussianMLPValueFunction/dLoss           24.0605
TotalEnvSteps                        501600
-----------------------------------  ----------------
2022-08-17 17:57:33 | [trpo_pendulum] epoch #418 | Saving snapshot...
2022-08-17 17:57:33 | [trpo_pendulum] epoch #418 | Saved
2022-08-17 17:57:33 | [trpo_pendulum] epoch #418 | Time 172.91 s
2022-08-17 17:57:33 | [trpo_pendulum] epoch #418 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -725.555
Evaluation/AverageReturn              -1695.56
Evaluation/Iteration                    418
Evaluation/MaxReturn                  -1627.35
Evaluation/MinReturn                  -1744.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     39.5238
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41678
GaussianMLPPolicy/KL                      3.06793e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -665.889
GaussianMLPPolicy/LossBefore           -665.861
GaussianMLPPolicy/dLoss                   0.0271606
GaussianMLPValueFunction/LossAfter    74405.4
GaussianMLPValueFunction/LossBefore   74486.8
GaussianMLPValueFunction/dLoss           81.3672
TotalEnvSteps                        502800
-----------------------------------  ----------------
2022-08-17 17:57:33 | [trpo_pendulum] epoch #419 | Saving snapshot...
2022-08-17 17:57:33 | [trpo_pendulum] epoch #419 | Saved
2022-08-17 17:57:33 | [trpo_pendulum] epoch #419 | Time 173.33 s
2022-08-17 17:57:33 | [trpo_pendulum] epoch #419 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -573.932
Evaluation/AverageReturn              -1320.15
Evaluation/Iteration                    419
Evaluation/MaxReturn                  -1188.58
Evaluation/MinReturn                  -1447.82
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     81.5664
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41676
GaussianMLPPolicy/KL                      6.42035e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -506.205
GaussianMLPPolicy/LossBefore           -505.991
GaussianMLPPolicy/dLoss                   0.214081
GaussianMLPValueFunction/LossAfter    43551.3
GaussianMLPValueFunction/LossBefore   43600.7
GaussianMLPValueFunction/dLoss           49.3086
TotalEnvSteps                        504000
-----------------------------------  ----------------
2022-08-17 17:57:33 | [trpo_pendulum] epoch #420 | Saving snapshot...
2022-08-17 17:57:33 | [trpo_pendulum] epoch #420 | Saved
2022-08-17 17:57:33 | [trpo_pendulum] epoch #420 | Time 173.75 s
2022-08-17 17:57:33 | [trpo_pendulum] epoch #420 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -555.31
Evaluation/AverageReturn              -1281.4
Evaluation/Iteration                    420
Evaluation/MaxReturn                  -1166.47
Evaluation/MinReturn                  -1374.94
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     65.2884
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41658
GaussianMLPPolicy/KL                      0.000176108
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -505.273
GaussianMLPPolicy/LossBefore           -504.982
GaussianMLPPolicy/dLoss                   0.291199
GaussianMLPValueFunction/LossAfter    40883.3
GaussianMLPValueFunction/LossBefore   40929.8
GaussianMLPValueFunction/dLoss           46.4336
TotalEnvSteps                        505200
-----------------------------------  ----------------
2022-08-17 17:57:34 | [trpo_pendulum] epoch #421 | Saving snapshot...
2022-08-17 17:57:34 | [trpo_pendulum] epoch #421 | Saved
2022-08-17 17:57:34 | [trpo_pendulum] epoch #421 | Time 174.15 s
2022-08-17 17:57:34 | [trpo_pendulum] epoch #421 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -409.186
Evaluation/AverageReturn               -936.643
Evaluation/Iteration                    421
Evaluation/MaxReturn                   -855.512
Evaluation/MinReturn                  -1067.18
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     77.2914
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41633
GaussianMLPPolicy/KL                      0.000227155
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -357.396
GaussianMLPPolicy/LossBefore           -357.185
GaussianMLPPolicy/dLoss                   0.211334
GaussianMLPValueFunction/LossAfter    21273.6
GaussianMLPValueFunction/LossBefore   21298.6
GaussianMLPValueFunction/dLoss           25.0332
TotalEnvSteps                        506400
-----------------------------------  ----------------
2022-08-17 17:57:34 | [trpo_pendulum] epoch #422 | Saving snapshot...
2022-08-17 17:57:34 | [trpo_pendulum] epoch #422 | Saved
2022-08-17 17:57:34 | [trpo_pendulum] epoch #422 | Time 174.56 s
2022-08-17 17:57:34 | [trpo_pendulum] epoch #422 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -668.862
Evaluation/AverageReturn              -1582.42
Evaluation/Iteration                    422
Evaluation/MaxReturn                  -1361.14
Evaluation/MinReturn                  -1752.92
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    140.177
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41625
GaussianMLPPolicy/KL                      5.00705e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -612.326
GaussianMLPPolicy/LossBefore           -612.339
GaussianMLPPolicy/dLoss                  -0.0130615
GaussianMLPValueFunction/LossAfter    65712.9
GaussianMLPValueFunction/LossBefore   65786.1
GaussianMLPValueFunction/dLoss           73.2109
TotalEnvSteps                        507600
-----------------------------------  ----------------
2022-08-17 17:57:35 | [trpo_pendulum] epoch #423 | Saving snapshot...
2022-08-17 17:57:35 | [trpo_pendulum] epoch #423 | Saved
2022-08-17 17:57:35 | [trpo_pendulum] epoch #423 | Time 174.97 s
2022-08-17 17:57:35 | [trpo_pendulum] epoch #423 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -600.562
Evaluation/AverageReturn              -1419.92
Evaluation/Iteration                    423
Evaluation/MaxReturn                  -1290.99
Evaluation/MinReturn                  -1485.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     67.3996
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41601
GaussianMLPPolicy/KL                      0.000124401
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -571.557
GaussianMLPPolicy/LossBefore           -571.366
GaussianMLPPolicy/dLoss                   0.190613
GaussianMLPValueFunction/LossAfter    51752.1
GaussianMLPValueFunction/LossBefore   51811.9
GaussianMLPValueFunction/dLoss           59.7266
TotalEnvSteps                        508800
-----------------------------------  ----------------
2022-08-17 17:57:35 | [trpo_pendulum] epoch #424 | Saving snapshot...
2022-08-17 17:57:35 | [trpo_pendulum] epoch #424 | Saved
2022-08-17 17:57:35 | [trpo_pendulum] epoch #424 | Time 175.38 s
2022-08-17 17:57:35 | [trpo_pendulum] epoch #424 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -530.425
Evaluation/AverageReturn              -1264.19
Evaluation/Iteration                    424
Evaluation/MaxReturn                  -1195.97
Evaluation/MinReturn                  -1378.38
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     70.0629
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41582
GaussianMLPPolicy/KL                      0.000177353
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -492.879
GaussianMLPPolicy/LossBefore           -492.683
GaussianMLPPolicy/dLoss                   0.19574
GaussianMLPValueFunction/LossAfter    41026
GaussianMLPValueFunction/LossBefore   41074
GaussianMLPValueFunction/dLoss           47.9453
TotalEnvSteps                        510000
-----------------------------------  ----------------
2022-08-17 17:57:35 | [trpo_pendulum] epoch #425 | Saving snapshot...
2022-08-17 17:57:35 | [trpo_pendulum] epoch #425 | Saved
2022-08-17 17:57:35 | [trpo_pendulum] epoch #425 | Time 175.79 s
2022-08-17 17:57:35 | [trpo_pendulum] epoch #425 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -656.144
Evaluation/AverageReturn              -1579.72
Evaluation/Iteration                    425
Evaluation/MaxReturn                  -1515.57
Evaluation/MinReturn                  -1684.67
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     60.7744
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41578
GaussianMLPPolicy/KL                      3.71586e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -620.328
GaussianMLPPolicy/LossBefore           -620.385
GaussianMLPPolicy/dLoss                  -0.0563354
GaussianMLPValueFunction/LossAfter    65655
GaussianMLPValueFunction/LossBefore   65733.1
GaussianMLPValueFunction/dLoss           78.1094
TotalEnvSteps                        511200
-----------------------------------  ----------------
2022-08-17 17:57:36 | [trpo_pendulum] epoch #426 | Saving snapshot...
2022-08-17 17:57:36 | [trpo_pendulum] epoch #426 | Saved
2022-08-17 17:57:36 | [trpo_pendulum] epoch #426 | Time 176.20 s
2022-08-17 17:57:36 | [trpo_pendulum] epoch #426 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -783.322
Evaluation/AverageReturn              -1807.73
Evaluation/Iteration                    426
Evaluation/MaxReturn                  -1737.17
Evaluation/MinReturn                  -1850.05
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     35.028
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41594
GaussianMLPPolicy/KL                      6.19161e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -684.993
GaussianMLPPolicy/LossBefore           -684.95
GaussianMLPPolicy/dLoss                   0.0432739
GaussianMLPValueFunction/LossAfter    82590.1
GaussianMLPValueFunction/LossBefore   82694.6
GaussianMLPValueFunction/dLoss          104.555
TotalEnvSteps                        512400
-----------------------------------  ----------------
2022-08-17 17:57:36 | [trpo_pendulum] epoch #427 | Saving snapshot...
2022-08-17 17:57:36 | [trpo_pendulum] epoch #427 | Saved
2022-08-17 17:57:36 | [trpo_pendulum] epoch #427 | Time 176.61 s
2022-08-17 17:57:36 | [trpo_pendulum] epoch #427 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -456.166
Evaluation/AverageReturn              -1105.04
Evaluation/Iteration                    427
Evaluation/MaxReturn                   -851.698
Evaluation/MinReturn                  -1292.53
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    140.061
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4161
GaussianMLPPolicy/KL                      4.28202e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -433.749
GaussianMLPPolicy/LossBefore           -433.69
GaussianMLPPolicy/dLoss                   0.059021
GaussianMLPValueFunction/LossAfter    32307.2
GaussianMLPValueFunction/LossBefore   32349.2
GaussianMLPValueFunction/dLoss           42.0625
TotalEnvSteps                        513600
-----------------------------------  ----------------
2022-08-17 17:57:37 | [trpo_pendulum] epoch #428 | Saving snapshot...
2022-08-17 17:57:37 | [trpo_pendulum] epoch #428 | Saved
2022-08-17 17:57:37 | [trpo_pendulum] epoch #428 | Time 177.03 s
2022-08-17 17:57:37 | [trpo_pendulum] epoch #428 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -683.65
Evaluation/AverageReturn              -1631.44
Evaluation/Iteration                    428
Evaluation/MaxReturn                  -1565.89
Evaluation/MinReturn                  -1701.68
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     53.4637
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41628
GaussianMLPPolicy/KL                      9.49868e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -645.831
GaussianMLPPolicy/LossBefore           -645.745
GaussianMLPPolicy/dLoss                   0.0861816
GaussianMLPValueFunction/LossAfter    69268.4
GaussianMLPValueFunction/LossBefore   69357.8
GaussianMLPValueFunction/dLoss           89.375
TotalEnvSteps                        514800
-----------------------------------  ----------------
2022-08-17 17:57:37 | [trpo_pendulum] epoch #429 | Saving snapshot...
2022-08-17 17:57:37 | [trpo_pendulum] epoch #429 | Saved
2022-08-17 17:57:37 | [trpo_pendulum] epoch #429 | Time 177.43 s
2022-08-17 17:57:37 | [trpo_pendulum] epoch #429 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -498.389
Evaluation/AverageReturn              -1209.48
Evaluation/Iteration                    429
Evaluation/MaxReturn                  -1158.51
Evaluation/MinReturn                  -1270.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     40.6201
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41653
GaussianMLPPolicy/KL                      6.51452e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -471.191
GaussianMLPPolicy/LossBefore           -471.065
GaussianMLPPolicy/dLoss                   0.126312
GaussianMLPValueFunction/LossAfter    37733.9
GaussianMLPValueFunction/LossBefore   37783.4
GaussianMLPValueFunction/dLoss           49.5
TotalEnvSteps                        516000
-----------------------------------  ----------------
2022-08-17 17:57:37 | [trpo_pendulum] epoch #430 | Saving snapshot...
2022-08-17 17:57:37 | [trpo_pendulum] epoch #430 | Saved
2022-08-17 17:57:37 | [trpo_pendulum] epoch #430 | Time 177.83 s
2022-08-17 17:57:37 | [trpo_pendulum] epoch #430 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -737.034
Evaluation/AverageReturn              -1732.4
Evaluation/Iteration                    430
Evaluation/MaxReturn                  -1633.11
Evaluation/MinReturn                  -1782.61
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     51.4998
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41667
GaussianMLPPolicy/KL                      2.94084e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -689.791
GaussianMLPPolicy/LossBefore           -689.614
GaussianMLPPolicy/dLoss                   0.176514
GaussianMLPValueFunction/LossAfter    76853
GaussianMLPValueFunction/LossBefore   76954.9
GaussianMLPValueFunction/dLoss          101.883
TotalEnvSteps                        517200
-----------------------------------  ----------------
2022-08-17 17:57:38 | [trpo_pendulum] epoch #431 | Saving snapshot...
2022-08-17 17:57:38 | [trpo_pendulum] epoch #431 | Saved
2022-08-17 17:57:38 | [trpo_pendulum] epoch #431 | Time 178.26 s
2022-08-17 17:57:38 | [trpo_pendulum] epoch #431 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -726.361
Evaluation/AverageReturn              -1713.71
Evaluation/Iteration                    431
Evaluation/MaxReturn                  -1530.09
Evaluation/MinReturn                  -1818.97
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     90.6251
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41668
GaussianMLPPolicy/KL                      5.54797e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -686.619
GaussianMLPPolicy/LossBefore           -686.454
GaussianMLPPolicy/dLoss                   0.165344
GaussianMLPValueFunction/LossAfter    75679.6
GaussianMLPValueFunction/LossBefore   75784.5
GaussianMLPValueFunction/dLoss          104.93
TotalEnvSteps                        518400
-----------------------------------  ----------------
2022-08-17 17:57:38 | [trpo_pendulum] epoch #432 | Saving snapshot...
2022-08-17 17:57:38 | [trpo_pendulum] epoch #432 | Saved
2022-08-17 17:57:38 | [trpo_pendulum] epoch #432 | Time 178.66 s
2022-08-17 17:57:38 | [trpo_pendulum] epoch #432 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -486.002
Evaluation/AverageReturn              -1130.07
Evaluation/Iteration                    432
Evaluation/MaxReturn                   -780.268
Evaluation/MinReturn                  -1316.41
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    171.511
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41669
GaussianMLPPolicy/KL                      1.22047e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -432.35
GaussianMLPPolicy/LossBefore           -432.409
GaussianMLPPolicy/dLoss                  -0.059021
GaussianMLPValueFunction/LossAfter    32056.2
GaussianMLPValueFunction/LossBefore   32101.1
GaussianMLPValueFunction/dLoss           44.8926
TotalEnvSteps                        519600
-----------------------------------  ----------------
2022-08-17 17:57:39 | [trpo_pendulum] epoch #433 | Saving snapshot...
2022-08-17 17:57:39 | [trpo_pendulum] epoch #433 | Saved
2022-08-17 17:57:39 | [trpo_pendulum] epoch #433 | Time 179.07 s
2022-08-17 17:57:39 | [trpo_pendulum] epoch #433 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -486.543
Evaluation/AverageReturn              -1152.21
Evaluation/Iteration                    433
Evaluation/MaxReturn                  -1091.5
Evaluation/MinReturn                  -1232.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.8481
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41682
GaussianMLPPolicy/KL                      5.08961e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -436.928
GaussianMLPPolicy/LossBefore           -436.799
GaussianMLPPolicy/dLoss                   0.129547
GaussianMLPValueFunction/LossAfter    33464.6
GaussianMLPValueFunction/LossBefore   33509.9
GaussianMLPValueFunction/dLoss           45.332
TotalEnvSteps                        520800
-----------------------------------  ----------------
2022-08-17 17:57:39 | [trpo_pendulum] epoch #434 | Saving snapshot...
2022-08-17 17:57:39 | [trpo_pendulum] epoch #434 | Saved
2022-08-17 17:57:39 | [trpo_pendulum] epoch #434 | Time 179.48 s
2022-08-17 17:57:39 | [trpo_pendulum] epoch #434 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -357.87
Evaluation/AverageReturn               -898.658
Evaluation/Iteration                    434
Evaluation/MaxReturn                   -744.543
Evaluation/MinReturn                  -1059.42
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    119.058
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41689
GaussianMLPPolicy/KL                      0.000183081
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -363.891
GaussianMLPPolicy/LossBefore           -363.593
GaussianMLPPolicy/dLoss                   0.297546
GaussianMLPValueFunction/LossAfter    21889.5
GaussianMLPValueFunction/LossBefore   21919.1
GaussianMLPValueFunction/dLoss           29.5801
TotalEnvSteps                        522000
-----------------------------------  ----------------
2022-08-17 17:57:40 | [trpo_pendulum] epoch #435 | Saving snapshot...
2022-08-17 17:57:40 | [trpo_pendulum] epoch #435 | Saved
2022-08-17 17:57:40 | [trpo_pendulum] epoch #435 | Time 179.89 s
2022-08-17 17:57:40 | [trpo_pendulum] epoch #435 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -776.785
Evaluation/AverageReturn              -1779.89
Evaluation/Iteration                    435
Evaluation/MaxReturn                  -1568.29
Evaluation/MinReturn                  -1842.78
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     96.068
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41701
GaussianMLPPolicy/KL                      1.86718e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -682.166
GaussianMLPPolicy/LossBefore           -682.219
GaussianMLPPolicy/dLoss                  -0.0528564
GaussianMLPValueFunction/LossAfter    79062
GaussianMLPValueFunction/LossBefore   79164.6
GaussianMLPValueFunction/dLoss          102.594
TotalEnvSteps                        523200
-----------------------------------  ----------------
2022-08-17 17:57:40 | [trpo_pendulum] epoch #436 | Saving snapshot...
2022-08-17 17:57:40 | [trpo_pendulum] epoch #436 | Saved
2022-08-17 17:57:40 | [trpo_pendulum] epoch #436 | Time 180.30 s
2022-08-17 17:57:40 | [trpo_pendulum] epoch #436 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -583.952
Evaluation/AverageReturn              -1408.69
Evaluation/Iteration                    436
Evaluation/MaxReturn                  -1212.62
Evaluation/MinReturn                  -1570.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    117.799
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41716
GaussianMLPPolicy/KL                      0.000369323
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -557.492
GaussianMLPPolicy/LossBefore           -556.563
GaussianMLPPolicy/dLoss                   0.929016
GaussianMLPValueFunction/LossAfter    51386.1
GaussianMLPValueFunction/LossBefore   51454.6
GaussianMLPValueFunction/dLoss           68.4258
TotalEnvSteps                        524400
-----------------------------------  ----------------
2022-08-17 17:57:40 | [trpo_pendulum] epoch #437 | Saving snapshot...
2022-08-17 17:57:40 | [trpo_pendulum] epoch #437 | Saved
2022-08-17 17:57:40 | [trpo_pendulum] epoch #437 | Time 180.70 s
2022-08-17 17:57:40 | [trpo_pendulum] epoch #437 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -444.643
Evaluation/AverageReturn               -997.277
Evaluation/Iteration                    437
Evaluation/MaxReturn                   -753.984
Evaluation/MinReturn                  -1251.78
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    161.401
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41724
GaussianMLPPolicy/KL                      0.000393942
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -372.577
GaussianMLPPolicy/LossBefore           -372.481
GaussianMLPPolicy/dLoss                   0.0957031
GaussianMLPValueFunction/LossAfter    24241.8
GaussianMLPValueFunction/LossBefore   24274.1
GaussianMLPValueFunction/dLoss           32.3477
TotalEnvSteps                        525600
-----------------------------------  ----------------
2022-08-17 17:57:41 | [trpo_pendulum] epoch #438 | Saving snapshot...
2022-08-17 17:57:41 | [trpo_pendulum] epoch #438 | Saved
2022-08-17 17:57:41 | [trpo_pendulum] epoch #438 | Time 181.22 s
2022-08-17 17:57:41 | [trpo_pendulum] epoch #438 | EpochTime 0.52 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -646.619
Evaluation/AverageReturn              -1528.94
Evaluation/Iteration                    438
Evaluation/MaxReturn                  -1424.63
Evaluation/MinReturn                  -1685.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     82.8309
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41717
GaussianMLPPolicy/KL                      0.000702082
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -615.986
GaussianMLPPolicy/LossBefore           -614.118
GaussianMLPPolicy/dLoss                   1.86774
GaussianMLPValueFunction/LossAfter    59472
GaussianMLPValueFunction/LossBefore   59548.5
GaussianMLPValueFunction/dLoss           76.4727
TotalEnvSteps                        526800
-----------------------------------  ----------------
2022-08-17 17:57:41 | [trpo_pendulum] epoch #439 | Saving snapshot...
2022-08-17 17:57:41 | [trpo_pendulum] epoch #439 | Saved
2022-08-17 17:57:41 | [trpo_pendulum] epoch #439 | Time 181.64 s
2022-08-17 17:57:41 | [trpo_pendulum] epoch #439 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -587.96
Evaluation/AverageReturn              -1327.09
Evaluation/Iteration                    439
Evaluation/MaxReturn                  -1088.86
Evaluation/MinReturn                  -1483.76
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    133.792
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41705
GaussianMLPPolicy/KL                      0.000743433
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -504.928
GaussianMLPPolicy/LossBefore           -504.75
GaussianMLPPolicy/dLoss                   0.178375
GaussianMLPValueFunction/LossAfter    42859.3
GaussianMLPValueFunction/LossBefore   42914.7
GaussianMLPValueFunction/dLoss           55.3867
TotalEnvSteps                        528000
-----------------------------------  ----------------
2022-08-17 17:57:42 | [trpo_pendulum] epoch #440 | Saving snapshot...
2022-08-17 17:57:42 | [trpo_pendulum] epoch #440 | Saved
2022-08-17 17:57:42 | [trpo_pendulum] epoch #440 | Time 182.04 s
2022-08-17 17:57:42 | [trpo_pendulum] epoch #440 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -412.967
Evaluation/AverageReturn               -957.86
Evaluation/Iteration                    440
Evaluation/MaxReturn                   -753.036
Evaluation/MinReturn                  -1053.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    100.122
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41688
GaussianMLPPolicy/KL                      0.000792169
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -367.468
GaussianMLPPolicy/LossBefore           -367.262
GaussianMLPPolicy/dLoss                   0.206451
GaussianMLPValueFunction/LossAfter    21805.7
GaussianMLPValueFunction/LossBefore   21834.5
GaussianMLPValueFunction/dLoss           28.7129
TotalEnvSteps                        529200
-----------------------------------  ----------------
2022-08-17 17:57:42 | [trpo_pendulum] epoch #441 | Saving snapshot...
2022-08-17 17:57:42 | [trpo_pendulum] epoch #441 | Saved
2022-08-17 17:57:42 | [trpo_pendulum] epoch #441 | Time 182.45 s
2022-08-17 17:57:42 | [trpo_pendulum] epoch #441 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -506.261
Evaluation/AverageReturn              -1094.19
Evaluation/Iteration                    441
Evaluation/MaxReturn                   -975.375
Evaluation/MinReturn                  -1202.21
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     72.0967
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41677
GaussianMLPPolicy/KL                      0.000667178
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -390.122
GaussianMLPPolicy/LossBefore           -389.821
GaussianMLPPolicy/dLoss                   0.301117
GaussianMLPValueFunction/LossAfter    27454.7
GaussianMLPValueFunction/LossBefore   27488.1
GaussianMLPValueFunction/dLoss           33.4375
TotalEnvSteps                        530400
-----------------------------------  ----------------
2022-08-17 17:57:42 | [trpo_pendulum] epoch #442 | Saving snapshot...
2022-08-17 17:57:42 | [trpo_pendulum] epoch #442 | Saved
2022-08-17 17:57:42 | [trpo_pendulum] epoch #442 | Time 182.85 s
2022-08-17 17:57:42 | [trpo_pendulum] epoch #442 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -618.785
Evaluation/AverageReturn              -1389.36
Evaluation/Iteration                    442
Evaluation/MaxReturn                  -1325.78
Evaluation/MinReturn                  -1515.74
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     65.5935
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41649
GaussianMLPPolicy/KL                      0.000605659
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -537.35
GaussianMLPPolicy/LossBefore           -536.758
GaussianMLPPolicy/dLoss                   0.592041
GaussianMLPValueFunction/LossAfter    45933
GaussianMLPValueFunction/LossBefore   45987.4
GaussianMLPValueFunction/dLoss           54.3242
TotalEnvSteps                        531600
-----------------------------------  ----------------
2022-08-17 17:57:43 | [trpo_pendulum] epoch #443 | Saving snapshot...
2022-08-17 17:57:43 | [trpo_pendulum] epoch #443 | Saved
2022-08-17 17:57:43 | [trpo_pendulum] epoch #443 | Time 183.26 s
2022-08-17 17:57:43 | [trpo_pendulum] epoch #443 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -396.1
Evaluation/AverageReturn               -973.953
Evaluation/Iteration                    443
Evaluation/MaxReturn                   -874.462
Evaluation/MinReturn                  -1077.58
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     80.8089
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41621
GaussianMLPPolicy/KL                      0.00134257
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -389.307
GaussianMLPPolicy/LossBefore           -388.181
GaussianMLPPolicy/dLoss                   1.12592
GaussianMLPValueFunction/LossAfter    24827.7
GaussianMLPValueFunction/LossBefore   24859.2
GaussianMLPValueFunction/dLoss           31.5508
TotalEnvSteps                        532800
-----------------------------------  ---------------
2022-08-17 17:57:43 | [trpo_pendulum] epoch #444 | Saving snapshot...
2022-08-17 17:57:43 | [trpo_pendulum] epoch #444 | Saved
2022-08-17 17:57:43 | [trpo_pendulum] epoch #444 | Time 183.66 s
2022-08-17 17:57:43 | [trpo_pendulum] epoch #444 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -745.168
Evaluation/AverageReturn              -1650.49
Evaluation/Iteration                    444
Evaluation/MaxReturn                  -1441.95
Evaluation/MinReturn                  -1804.69
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    113.57
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41586
GaussianMLPPolicy/KL                      0.000383951
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -626.198
GaussianMLPPolicy/LossBefore           -625.804
GaussianMLPPolicy/dLoss                   0.394226
GaussianMLPValueFunction/LossAfter    64941
GaussianMLPValueFunction/LossBefore   65017
GaussianMLPValueFunction/dLoss           75.9961
TotalEnvSteps                        534000
-----------------------------------  ----------------
2022-08-17 17:57:44 | [trpo_pendulum] epoch #445 | Saving snapshot...
2022-08-17 17:57:44 | [trpo_pendulum] epoch #445 | Saved
2022-08-17 17:57:44 | [trpo_pendulum] epoch #445 | Time 184.06 s
2022-08-17 17:57:44 | [trpo_pendulum] epoch #445 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -457.746
Evaluation/AverageReturn              -1114.14
Evaluation/Iteration                    445
Evaluation/MaxReturn                  -1036.24
Evaluation/MinReturn                  -1201.26
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     71.2158
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41562
GaussianMLPPolicy/KL                      0.00141618
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -435.842
GaussianMLPPolicy/LossBefore           -435.128
GaussianMLPPolicy/dLoss                   0.714417
GaussianMLPValueFunction/LossAfter    32491
GaussianMLPValueFunction/LossBefore   32533.1
GaussianMLPValueFunction/dLoss           42.0898
TotalEnvSteps                        535200
-----------------------------------  ---------------
2022-08-17 17:57:44 | [trpo_pendulum] epoch #446 | Saving snapshot...
2022-08-17 17:57:44 | [trpo_pendulum] epoch #446 | Saved
2022-08-17 17:57:44 | [trpo_pendulum] epoch #446 | Time 184.47 s
2022-08-17 17:57:44 | [trpo_pendulum] epoch #446 | EpochTime 0.40 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -527.855
Evaluation/AverageReturn              -1167.17
Evaluation/Iteration                    446
Evaluation/MaxReturn                  -1128.08
Evaluation/MinReturn                  -1200.29
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     28.8192
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41543
GaussianMLPPolicy/KL                      0.0015065
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -428.011
GaussianMLPPolicy/LossBefore           -426.707
GaussianMLPPolicy/dLoss                   1.30362
GaussianMLPValueFunction/LossAfter    31023.4
GaussianMLPValueFunction/LossBefore   31059.7
GaussianMLPValueFunction/dLoss           36.2734
TotalEnvSteps                        536400
-----------------------------------  --------------
2022-08-17 17:57:45 | [trpo_pendulum] epoch #447 | Saving snapshot...
2022-08-17 17:57:45 | [trpo_pendulum] epoch #447 | Saved
2022-08-17 17:57:45 | [trpo_pendulum] epoch #447 | Time 184.88 s
2022-08-17 17:57:45 | [trpo_pendulum] epoch #447 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -518.814
Evaluation/AverageReturn              -1161.34
Evaluation/Iteration                    447
Evaluation/MaxReturn                  -1102.01
Evaluation/MinReturn                  -1255.16
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     61.2486
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41525
GaussianMLPPolicy/KL                      0.00117399
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -431.789
GaussianMLPPolicy/LossBefore           -431.538
GaussianMLPPolicy/dLoss                   0.251465
GaussianMLPValueFunction/LossAfter    30780.7
GaussianMLPValueFunction/LossBefore   30816
GaussianMLPValueFunction/dLoss           35.3789
TotalEnvSteps                        537600
-----------------------------------  ---------------
2022-08-17 17:57:45 | [trpo_pendulum] epoch #448 | Saving snapshot...
2022-08-17 17:57:45 | [trpo_pendulum] epoch #448 | Saved
2022-08-17 17:57:45 | [trpo_pendulum] epoch #448 | Time 185.29 s
2022-08-17 17:57:45 | [trpo_pendulum] epoch #448 | EpochTime 0.40 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -467.45
Evaluation/AverageReturn              -1119.22
Evaluation/Iteration                    448
Evaluation/MaxReturn                  -1083.38
Evaluation/MinReturn                  -1155.61
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     22.719
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41494
GaussianMLPPolicy/KL                      0.0026032
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -453.718
GaussianMLPPolicy/LossBefore           -450.808
GaussianMLPPolicy/dLoss                   2.91003
GaussianMLPValueFunction/LossAfter    30507.6
GaussianMLPValueFunction/LossBefore   30543.2
GaussianMLPValueFunction/dLoss           35.543
TotalEnvSteps                        538800
-----------------------------------  --------------
2022-08-17 17:57:45 | [trpo_pendulum] epoch #449 | Saving snapshot...
2022-08-17 17:57:45 | [trpo_pendulum] epoch #449 | Saved
2022-08-17 17:57:45 | [trpo_pendulum] epoch #449 | Time 185.69 s
2022-08-17 17:57:45 | [trpo_pendulum] epoch #449 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -511.986
Evaluation/AverageReturn              -1222.96
Evaluation/Iteration                    449
Evaluation/MaxReturn                  -1075.98
Evaluation/MinReturn                  -1333.39
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     85.0297
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41479
GaussianMLPPolicy/KL                      0.00280031
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -470.227
GaussianMLPPolicy/LossBefore           -468.884
GaussianMLPPolicy/dLoss                   1.34265
GaussianMLPValueFunction/LossAfter    38084.5
GaussianMLPValueFunction/LossBefore   38130.6
GaussianMLPValueFunction/dLoss           46.1211
TotalEnvSteps                        540000
-----------------------------------  ---------------
2022-08-17 17:57:46 | [trpo_pendulum] epoch #450 | Saving snapshot...
2022-08-17 17:57:46 | [trpo_pendulum] epoch #450 | Saved
2022-08-17 17:57:46 | [trpo_pendulum] epoch #450 | Time 186.11 s
2022-08-17 17:57:46 | [trpo_pendulum] epoch #450 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -614.846
Evaluation/AverageReturn              -1316.62
Evaluation/Iteration                    450
Evaluation/MaxReturn                  -1230.02
Evaluation/MinReturn                  -1398.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     60.7929
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41459
GaussianMLPPolicy/KL                      0.00147202
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -478.017
GaussianMLPPolicy/LossBefore           -477.653
GaussianMLPPolicy/dLoss                   0.363861
GaussianMLPValueFunction/LossAfter    37728.7
GaussianMLPValueFunction/LossBefore   37770.3
GaussianMLPValueFunction/dLoss           41.5586
TotalEnvSteps                        541200
-----------------------------------  ---------------
2022-08-17 17:57:46 | [trpo_pendulum] epoch #451 | Saving snapshot...
2022-08-17 17:57:46 | [trpo_pendulum] epoch #451 | Saved
2022-08-17 17:57:46 | [trpo_pendulum] epoch #451 | Time 186.51 s
2022-08-17 17:57:46 | [trpo_pendulum] epoch #451 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -521.727
Evaluation/AverageReturn              -1280.01
Evaluation/Iteration                    451
Evaluation/MaxReturn                  -1198.78
Evaluation/MinReturn                  -1332.44
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     42.2339
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41463
GaussianMLPPolicy/KL                      0.00132172
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -494.975
GaussianMLPPolicy/LossBefore           -494.88
GaussianMLPPolicy/dLoss                   0.0948181
GaussianMLPValueFunction/LossAfter    42591.3
GaussianMLPValueFunction/LossBefore   42642
GaussianMLPValueFunction/dLoss           50.625
TotalEnvSteps                        542400
-----------------------------------  ---------------
2022-08-17 17:57:47 | [trpo_pendulum] epoch #452 | Saving snapshot...
2022-08-17 17:57:47 | [trpo_pendulum] epoch #452 | Saved
2022-08-17 17:57:47 | [trpo_pendulum] epoch #452 | Time 186.93 s
2022-08-17 17:57:47 | [trpo_pendulum] epoch #452 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -496.818
Evaluation/AverageReturn              -1252.47
Evaluation/Iteration                    452
Evaluation/MaxReturn                  -1182
Evaluation/MinReturn                  -1331.86
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     56.3835
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41482
GaussianMLPPolicy/KL                      0.000976383
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -498.277
GaussianMLPPolicy/LossBefore           -497.941
GaussianMLPPolicy/dLoss                   0.335876
GaussianMLPValueFunction/LossAfter    42680.7
GaussianMLPValueFunction/LossBefore   42731.6
GaussianMLPValueFunction/dLoss           50.918
TotalEnvSteps                        543600
-----------------------------------  ----------------
2022-08-17 17:57:47 | [trpo_pendulum] epoch #453 | Saving snapshot...
2022-08-17 17:57:47 | [trpo_pendulum] epoch #453 | Saved
2022-08-17 17:57:47 | [trpo_pendulum] epoch #453 | Time 187.34 s
2022-08-17 17:57:47 | [trpo_pendulum] epoch #453 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -535.451
Evaluation/AverageReturn              -1290.49
Evaluation/Iteration                    453
Evaluation/MaxReturn                  -1215.68
Evaluation/MinReturn                  -1318.69
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     34.7289
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41497
GaussianMLPPolicy/KL                      0.000379731
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -512.026
GaussianMLPPolicy/LossBefore           -512.234
GaussianMLPPolicy/dLoss                  -0.208801
GaussianMLPValueFunction/LossAfter    42194.5
GaussianMLPValueFunction/LossBefore   42244.2
GaussianMLPValueFunction/dLoss           49.6914
TotalEnvSteps                        544800
-----------------------------------  ----------------
2022-08-17 17:57:47 | [trpo_pendulum] epoch #454 | Saving snapshot...
2022-08-17 17:57:47 | [trpo_pendulum] epoch #454 | Saved
2022-08-17 17:57:47 | [trpo_pendulum] epoch #454 | Time 187.76 s
2022-08-17 17:57:47 | [trpo_pendulum] epoch #454 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -574.306
Evaluation/AverageReturn              -1275.8
Evaluation/Iteration                    454
Evaluation/MaxReturn                  -1163.21
Evaluation/MinReturn                  -1348.57
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     56.8151
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41513
GaussianMLPPolicy/KL                      0.000603366
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -471.863
GaussianMLPPolicy/LossBefore           -471.161
GaussianMLPPolicy/dLoss                   0.701355
GaussianMLPValueFunction/LossAfter    36303
GaussianMLPValueFunction/LossBefore   36344.5
GaussianMLPValueFunction/dLoss           41.5391
TotalEnvSteps                        546000
-----------------------------------  ----------------
2022-08-17 17:57:48 | [trpo_pendulum] epoch #455 | Saving snapshot...
2022-08-17 17:57:48 | [trpo_pendulum] epoch #455 | Saved
2022-08-17 17:57:48 | [trpo_pendulum] epoch #455 | Time 188.16 s
2022-08-17 17:57:48 | [trpo_pendulum] epoch #455 | EpochTime 0.40 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -548.325
Evaluation/AverageReturn              -1330.27
Evaluation/Iteration                    455
Evaluation/MaxReturn                  -1273.42
Evaluation/MinReturn                  -1379.66
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     32.7358
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41515
GaussianMLPPolicy/KL                      0.0010896
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -541.264
GaussianMLPPolicy/LossBefore           -540.358
GaussianMLPPolicy/dLoss                   0.906128
GaussianMLPValueFunction/LossAfter    45371.5
GaussianMLPValueFunction/LossBefore   45430.9
GaussianMLPValueFunction/dLoss           59.3789
TotalEnvSteps                        547200
-----------------------------------  --------------
2022-08-17 17:57:48 | [trpo_pendulum] epoch #456 | Saving snapshot...
2022-08-17 17:57:48 | [trpo_pendulum] epoch #456 | Saved
2022-08-17 17:57:48 | [trpo_pendulum] epoch #456 | Time 188.57 s
2022-08-17 17:57:48 | [trpo_pendulum] epoch #456 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -547.029
Evaluation/AverageReturn              -1330.59
Evaluation/Iteration                    456
Evaluation/MaxReturn                  -1315.84
Evaluation/MinReturn                  -1352.91
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.2857
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41507
GaussianMLPPolicy/KL                      0.00173291
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -542.244
GaussianMLPPolicy/LossBefore           -540.666
GaussianMLPPolicy/dLoss                   1.57751
GaussianMLPValueFunction/LossAfter    45483.5
GaussianMLPValueFunction/LossBefore   45547.7
GaussianMLPValueFunction/dLoss           64.1523
TotalEnvSteps                        548400
-----------------------------------  ---------------
2022-08-17 17:57:49 | [trpo_pendulum] epoch #457 | Saving snapshot...
2022-08-17 17:57:49 | [trpo_pendulum] epoch #457 | Saved
2022-08-17 17:57:49 | [trpo_pendulum] epoch #457 | Time 188.99 s
2022-08-17 17:57:49 | [trpo_pendulum] epoch #457 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -547.856
Evaluation/AverageReturn              -1358.13
Evaluation/Iteration                    457
Evaluation/MaxReturn                  -1338.73
Evaluation/MinReturn                  -1376.43
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     12.3241
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41495
GaussianMLPPolicy/KL                      0.000803297
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -554.578
GaussianMLPPolicy/LossBefore           -554.635
GaussianMLPPolicy/dLoss                  -0.0570679
GaussianMLPValueFunction/LossAfter    49200.5
GaussianMLPValueFunction/LossBefore   49257.6
GaussianMLPValueFunction/dLoss           57.1016
TotalEnvSteps                        549600
-----------------------------------  ----------------
2022-08-17 17:57:49 | [trpo_pendulum] epoch #458 | Saving snapshot...
2022-08-17 17:57:49 | [trpo_pendulum] epoch #458 | Saved
2022-08-17 17:57:49 | [trpo_pendulum] epoch #458 | Time 189.40 s
2022-08-17 17:57:49 | [trpo_pendulum] epoch #458 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -630.566
Evaluation/AverageReturn              -1390.27
Evaluation/Iteration                    458
Evaluation/MaxReturn                  -1361.29
Evaluation/MinReturn                  -1431.62
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     26.9849
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41486
GaussianMLPPolicy/KL                      0.000857443
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -512.201
GaussianMLPPolicy/LossBefore           -511.369
GaussianMLPPolicy/dLoss                   0.832611
GaussianMLPValueFunction/LossAfter    42949.1
GaussianMLPValueFunction/LossBefore   42999.6
GaussianMLPValueFunction/dLoss           50.4805
TotalEnvSteps                        550800
-----------------------------------  ----------------
2022-08-17 17:57:49 | [trpo_pendulum] epoch #459 | Saving snapshot...
2022-08-17 17:57:49 | [trpo_pendulum] epoch #459 | Saved
2022-08-17 17:57:49 | [trpo_pendulum] epoch #459 | Time 189.81 s
2022-08-17 17:57:49 | [trpo_pendulum] epoch #459 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -570.139
Evaluation/AverageReturn              -1327.37
Evaluation/Iteration                    459
Evaluation/MaxReturn                  -1298.78
Evaluation/MinReturn                  -1368.5
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     27.5354
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41483
GaussianMLPPolicy/KL                      0.00070924
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -508.441
GaussianMLPPolicy/LossBefore           -508.378
GaussianMLPPolicy/dLoss                   0.063324
GaussianMLPValueFunction/LossAfter    42500.7
GaussianMLPValueFunction/LossBefore   42553.8
GaussianMLPValueFunction/dLoss           53.125
TotalEnvSteps                        552000
-----------------------------------  ---------------
2022-08-17 17:57:50 | [trpo_pendulum] epoch #460 | Saving snapshot...
2022-08-17 17:57:50 | [trpo_pendulum] epoch #460 | Saved
2022-08-17 17:57:50 | [trpo_pendulum] epoch #460 | Time 190.23 s
2022-08-17 17:57:50 | [trpo_pendulum] epoch #460 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -552.08
Evaluation/AverageReturn              -1342.94
Evaluation/Iteration                    460
Evaluation/MaxReturn                  -1310.19
Evaluation/MinReturn                  -1380.82
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     23.9255
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41473
GaussianMLPPolicy/KL                      0.000686016
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -541.438
GaussianMLPPolicy/LossBefore           -541.053
GaussianMLPPolicy/dLoss                   0.385132
GaussianMLPValueFunction/LossAfter    46076.8
GaussianMLPValueFunction/LossBefore   46132.7
GaussianMLPValueFunction/dLoss           55.9414
TotalEnvSteps                        553200
-----------------------------------  ----------------
2022-08-17 17:57:50 | [trpo_pendulum] epoch #461 | Saving snapshot...
2022-08-17 17:57:50 | [trpo_pendulum] epoch #461 | Saved
2022-08-17 17:57:50 | [trpo_pendulum] epoch #461 | Time 190.64 s
2022-08-17 17:57:50 | [trpo_pendulum] epoch #461 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -569.46
Evaluation/AverageReturn              -1369.28
Evaluation/Iteration                    461
Evaluation/MaxReturn                  -1334.01
Evaluation/MinReturn                  -1436.19
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     35.9483
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41476
GaussianMLPPolicy/KL                      0.000191138
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -533.056
GaussianMLPPolicy/LossBefore           -533.24
GaussianMLPPolicy/dLoss                  -0.184204
GaussianMLPValueFunction/LossAfter    47759.2
GaussianMLPValueFunction/LossBefore   47823.6
GaussianMLPValueFunction/dLoss           64.4453
TotalEnvSteps                        554400
-----------------------------------  ----------------
2022-08-17 17:57:51 | [trpo_pendulum] epoch #462 | Saving snapshot...
2022-08-17 17:57:51 | [trpo_pendulum] epoch #462 | Saved
2022-08-17 17:57:51 | [trpo_pendulum] epoch #462 | Time 191.05 s
2022-08-17 17:57:51 | [trpo_pendulum] epoch #462 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -545.789
Evaluation/AverageReturn              -1328.73
Evaluation/Iteration                    462
Evaluation/MaxReturn                  -1314.39
Evaluation/MinReturn                  -1353.12
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.8677
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4147
GaussianMLPPolicy/KL                      0.000301652
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -536.777
GaussianMLPPolicy/LossBefore           -536.469
GaussianMLPPolicy/dLoss                   0.307678
GaussianMLPValueFunction/LossAfter    44904
GaussianMLPValueFunction/LossBefore   44961.6
GaussianMLPValueFunction/dLoss           57.6328
TotalEnvSteps                        555600
-----------------------------------  ----------------
2022-08-17 17:57:51 | [trpo_pendulum] epoch #463 | Saving snapshot...
2022-08-17 17:57:51 | [trpo_pendulum] epoch #463 | Saved
2022-08-17 17:57:51 | [trpo_pendulum] epoch #463 | Time 191.46 s
2022-08-17 17:57:51 | [trpo_pendulum] epoch #463 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -652.861
Evaluation/AverageReturn              -1429.88
Evaluation/Iteration                    463
Evaluation/MaxReturn                  -1388.66
Evaluation/MinReturn                  -1528.93
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     48.5398
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41472
GaussianMLPPolicy/KL                      0.00022411
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -520.646
GaussianMLPPolicy/LossBefore           -520.395
GaussianMLPPolicy/dLoss                   0.250854
GaussianMLPValueFunction/LossAfter    44986.6
GaussianMLPValueFunction/LossBefore   45041.4
GaussianMLPValueFunction/dLoss           54.7695
TotalEnvSteps                        556800
-----------------------------------  ---------------
2022-08-17 17:57:51 | [trpo_pendulum] epoch #464 | Saving snapshot...
2022-08-17 17:57:52 | [trpo_pendulum] epoch #464 | Saved
2022-08-17 17:57:52 | [trpo_pendulum] epoch #464 | Time 191.87 s
2022-08-17 17:57:52 | [trpo_pendulum] epoch #464 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -497.025
Evaluation/AverageReturn              -1319.95
Evaluation/Iteration                    464
Evaluation/MaxReturn                  -1230.51
Evaluation/MinReturn                  -1358.98
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     45.0464
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41484
GaussianMLPPolicy/KL                      2.43696e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -549.006
GaussianMLPPolicy/LossBefore           -549.043
GaussianMLPPolicy/dLoss                  -0.0375977
GaussianMLPValueFunction/LossAfter    49999.1
GaussianMLPValueFunction/LossBefore   50066
GaussianMLPValueFunction/dLoss           66.8711
TotalEnvSteps                        558000
-----------------------------------  ----------------
2022-08-17 17:57:52 | [trpo_pendulum] epoch #465 | Saving snapshot...
2022-08-17 17:57:52 | [trpo_pendulum] epoch #465 | Saved
2022-08-17 17:57:52 | [trpo_pendulum] epoch #465 | Time 192.28 s
2022-08-17 17:57:52 | [trpo_pendulum] epoch #465 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -573.874
Evaluation/AverageReturn              -1383.7
Evaluation/Iteration                    465
Evaluation/MaxReturn                  -1323.92
Evaluation/MinReturn                  -1433.95
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     33.0767
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41475
GaussianMLPPolicy/KL                      7.23508e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -565.88
GaussianMLPPolicy/LossBefore           -565.601
GaussianMLPPolicy/dLoss                   0.279785
GaussianMLPValueFunction/LossAfter    48092.2
GaussianMLPValueFunction/LossBefore   48154.5
GaussianMLPValueFunction/dLoss           62.3594
TotalEnvSteps                        559200
-----------------------------------  ----------------
2022-08-17 17:57:52 | [trpo_pendulum] epoch #466 | Saving snapshot...
2022-08-17 17:57:52 | [trpo_pendulum] epoch #466 | Saved
2022-08-17 17:57:52 | [trpo_pendulum] epoch #466 | Time 192.69 s
2022-08-17 17:57:52 | [trpo_pendulum] epoch #466 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -564.023
Evaluation/AverageReturn              -1333.73
Evaluation/Iteration                    466
Evaluation/MaxReturn                  -1157.53
Evaluation/MinReturn                  -1420.09
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     85.8011
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41475
GaussianMLPPolicy/KL                      1.39408e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -514.178
GaussianMLPPolicy/LossBefore           -514.147
GaussianMLPPolicy/dLoss                   0.031189
GaussianMLPValueFunction/LossAfter    43027.9
GaussianMLPValueFunction/LossBefore   43084.6
GaussianMLPValueFunction/dLoss           56.7227
TotalEnvSteps                        560400
-----------------------------------  ----------------
2022-08-17 17:57:53 | [trpo_pendulum] epoch #467 | Saving snapshot...
2022-08-17 17:57:53 | [trpo_pendulum] epoch #467 | Saved
2022-08-17 17:57:53 | [trpo_pendulum] epoch #467 | Time 193.11 s
2022-08-17 17:57:53 | [trpo_pendulum] epoch #467 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -570.396
Evaluation/AverageReturn              -1393.73
Evaluation/Iteration                    467
Evaluation/MaxReturn                  -1333.57
Evaluation/MinReturn                  -1450.06
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     37.3446
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41487
GaussianMLPPolicy/KL                      0.000160477
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -548.333
GaussianMLPPolicy/LossBefore           -548.02
GaussianMLPPolicy/dLoss                   0.313477
GaussianMLPValueFunction/LossAfter    49654.9
GaussianMLPValueFunction/LossBefore   49725.3
GaussianMLPValueFunction/dLoss           70.4023
TotalEnvSteps                        561600
-----------------------------------  ----------------
2022-08-17 17:57:53 | [trpo_pendulum] epoch #468 | Saving snapshot...
2022-08-17 17:57:53 | [trpo_pendulum] epoch #468 | Saved
2022-08-17 17:57:53 | [trpo_pendulum] epoch #468 | Time 193.52 s
2022-08-17 17:57:53 | [trpo_pendulum] epoch #468 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -636.274
Evaluation/AverageReturn              -1417.35
Evaluation/Iteration                    468
Evaluation/MaxReturn                  -1377.06
Evaluation/MinReturn                  -1460.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     27.2359
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.415
GaussianMLPPolicy/KL                      0.000109488
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -525.765
GaussianMLPPolicy/LossBefore           -525.723
GaussianMLPPolicy/dLoss                   0.0420532
GaussianMLPValueFunction/LossAfter    44523
GaussianMLPValueFunction/LossBefore   44579.2
GaussianMLPValueFunction/dLoss           56.2109
TotalEnvSteps                        562800
-----------------------------------  ----------------
2022-08-17 17:57:54 | [trpo_pendulum] epoch #469 | Saving snapshot...
2022-08-17 17:57:54 | [trpo_pendulum] epoch #469 | Saved
2022-08-17 17:57:54 | [trpo_pendulum] epoch #469 | Time 193.93 s
2022-08-17 17:57:54 | [trpo_pendulum] epoch #469 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -579.576
Evaluation/AverageReturn              -1397.02
Evaluation/Iteration                    469
Evaluation/MaxReturn                  -1376.43
Evaluation/MinReturn                  -1427.88
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     18.875
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41513
GaussianMLPPolicy/KL                      2.39538e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -554.537
GaussianMLPPolicy/LossBefore           -554.569
GaussianMLPPolicy/dLoss                  -0.0319824
GaussianMLPValueFunction/LossAfter    49692.1
GaussianMLPValueFunction/LossBefore   49765.1
GaussianMLPValueFunction/dLoss           73.0039
TotalEnvSteps                        564000
-----------------------------------  ----------------
2022-08-17 17:57:54 | [trpo_pendulum] epoch #470 | Saving snapshot...
2022-08-17 17:57:54 | [trpo_pendulum] epoch #470 | Saved
2022-08-17 17:57:54 | [trpo_pendulum] epoch #470 | Time 194.34 s
2022-08-17 17:57:54 | [trpo_pendulum] epoch #470 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -610.636
Evaluation/AverageReturn              -1445.01
Evaluation/Iteration                    470
Evaluation/MaxReturn                  -1358.26
Evaluation/MinReturn                  -1489.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     47.6471
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41511
GaussianMLPPolicy/KL                      0.000240089
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -577.809
GaussianMLPPolicy/LossBefore           -577.296
GaussianMLPPolicy/dLoss                   0.512512
GaussianMLPValueFunction/LossAfter    51228.7
GaussianMLPValueFunction/LossBefore   51305.9
GaussianMLPValueFunction/dLoss           77.2422
TotalEnvSteps                        565200
-----------------------------------  ----------------
2022-08-17 17:57:54 | [trpo_pendulum] epoch #471 | Saving snapshot...
2022-08-17 17:57:54 | [trpo_pendulum] epoch #471 | Saved
2022-08-17 17:57:54 | [trpo_pendulum] epoch #471 | Time 194.75 s
2022-08-17 17:57:54 | [trpo_pendulum] epoch #471 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -608.685
Evaluation/AverageReturn              -1453.59
Evaluation/Iteration                    471
Evaluation/MaxReturn                  -1417.78
Evaluation/MinReturn                  -1487.85
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     24.6893
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41507
GaussianMLPPolicy/KL                      0.000928076
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -577.908
GaussianMLPPolicy/LossBefore           -576.616
GaussianMLPPolicy/dLoss                   1.29156
GaussianMLPValueFunction/LossAfter    52354.9
GaussianMLPValueFunction/LossBefore   52419.5
GaussianMLPValueFunction/dLoss           64.6367
TotalEnvSteps                        566400
-----------------------------------  ----------------
2022-08-17 17:57:55 | [trpo_pendulum] epoch #472 | Saving snapshot...
2022-08-17 17:57:55 | [trpo_pendulum] epoch #472 | Saved
2022-08-17 17:57:55 | [trpo_pendulum] epoch #472 | Time 195.16 s
2022-08-17 17:57:55 | [trpo_pendulum] epoch #472 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -592.471
Evaluation/AverageReturn              -1415.41
Evaluation/Iteration                    472
Evaluation/MaxReturn                  -1348.12
Evaluation/MinReturn                  -1476.57
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     44.7299
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41529
GaussianMLPPolicy/KL                      0.00080207
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -537.22
GaussianMLPPolicy/LossBefore           -536.84
GaussianMLPPolicy/dLoss                   0.380127
GaussianMLPValueFunction/LossAfter    49877.2
GaussianMLPValueFunction/LossBefore   49944.5
GaussianMLPValueFunction/dLoss           67.2852
TotalEnvSteps                        567600
-----------------------------------  ---------------
2022-08-17 17:57:55 | [trpo_pendulum] epoch #473 | Saving snapshot...
2022-08-17 17:57:55 | [trpo_pendulum] epoch #473 | Saved
2022-08-17 17:57:55 | [trpo_pendulum] epoch #473 | Time 195.57 s
2022-08-17 17:57:55 | [trpo_pendulum] epoch #473 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -550.82
Evaluation/AverageReturn              -1337.58
Evaluation/Iteration                    473
Evaluation/MaxReturn                  -1315.58
Evaluation/MinReturn                  -1360.65
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.3549
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4155
GaussianMLPPolicy/KL                      0.000915493
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -530.721
GaussianMLPPolicy/LossBefore           -529.992
GaussianMLPPolicy/dLoss                   0.728699
GaussianMLPValueFunction/LossAfter    45200.6
GaussianMLPValueFunction/LossBefore   45262.8
GaussianMLPValueFunction/dLoss           62.2266
TotalEnvSteps                        568800
-----------------------------------  ----------------
2022-08-17 17:57:56 | [trpo_pendulum] epoch #474 | Saving snapshot...
2022-08-17 17:57:56 | [trpo_pendulum] epoch #474 | Saved
2022-08-17 17:57:56 | [trpo_pendulum] epoch #474 | Time 195.99 s
2022-08-17 17:57:56 | [trpo_pendulum] epoch #474 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -589.555
Evaluation/AverageReturn              -1390.74
Evaluation/Iteration                    474
Evaluation/MaxReturn                  -1332.92
Evaluation/MinReturn                  -1460.04
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     52.6641
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41547
GaussianMLPPolicy/KL                      0.000344869
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -562.823
GaussianMLPPolicy/LossBefore           -562.991
GaussianMLPPolicy/dLoss                  -0.16803
GaussianMLPValueFunction/LossAfter    46912.6
GaussianMLPValueFunction/LossBefore   46979.2
GaussianMLPValueFunction/dLoss           66.6016
TotalEnvSteps                        570000
-----------------------------------  ----------------
2022-08-17 17:57:56 | [trpo_pendulum] epoch #475 | Saving snapshot...
2022-08-17 17:57:56 | [trpo_pendulum] epoch #475 | Saved
2022-08-17 17:57:56 | [trpo_pendulum] epoch #475 | Time 196.39 s
2022-08-17 17:57:56 | [trpo_pendulum] epoch #475 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -545.067
Evaluation/AverageReturn              -1312.19
Evaluation/Iteration                    475
Evaluation/MaxReturn                  -1297.7
Evaluation/MinReturn                  -1333.16
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     11.3651
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41543
GaussianMLPPolicy/KL                      0.000127875
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -518.805
GaussianMLPPolicy/LossBefore           -518.896
GaussianMLPPolicy/dLoss                  -0.0905151
GaussianMLPValueFunction/LossAfter    42114.8
GaussianMLPValueFunction/LossBefore   42170.9
GaussianMLPValueFunction/dLoss           56.0977
TotalEnvSteps                        571200
-----------------------------------  ----------------
2022-08-17 17:57:56 | [trpo_pendulum] epoch #476 | Saving snapshot...
2022-08-17 17:57:56 | [trpo_pendulum] epoch #476 | Saved
2022-08-17 17:57:56 | [trpo_pendulum] epoch #476 | Time 196.80 s
2022-08-17 17:57:56 | [trpo_pendulum] epoch #476 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -549.633
Evaluation/AverageReturn              -1344.78
Evaluation/Iteration                    476
Evaluation/MaxReturn                  -1317.11
Evaluation/MinReturn                  -1356.21
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     13.1592
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41508
GaussianMLPPolicy/KL                      8.78354e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -566.284
GaussianMLPPolicy/LossBefore           -566.259
GaussianMLPPolicy/dLoss                   0.0256348
GaussianMLPValueFunction/LossAfter    46340.2
GaussianMLPValueFunction/LossBefore   46405
GaussianMLPValueFunction/dLoss           64.8242
TotalEnvSteps                        572400
-----------------------------------  ----------------
2022-08-17 17:57:57 | [trpo_pendulum] epoch #477 | Saving snapshot...
2022-08-17 17:57:57 | [trpo_pendulum] epoch #477 | Saved
2022-08-17 17:57:57 | [trpo_pendulum] epoch #477 | Time 197.19 s
2022-08-17 17:57:57 | [trpo_pendulum] epoch #477 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -555.738
Evaluation/AverageReturn              -1340.36
Evaluation/Iteration                    477
Evaluation/MaxReturn                  -1326.86
Evaluation/MinReturn                  -1351.88
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.24146
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4148
GaussianMLPPolicy/KL                      3.39897e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -527.414
GaussianMLPPolicy/LossBefore           -527.253
GaussianMLPPolicy/dLoss                   0.160767
GaussianMLPValueFunction/LossAfter    44889.6
GaussianMLPValueFunction/LossBefore   44950.6
GaussianMLPValueFunction/dLoss           61.0742
TotalEnvSteps                        573600
-----------------------------------  ----------------
2022-08-17 17:57:57 | [trpo_pendulum] epoch #478 | Saving snapshot...
2022-08-17 17:57:57 | [trpo_pendulum] epoch #478 | Saved
2022-08-17 17:57:57 | [trpo_pendulum] epoch #478 | Time 197.60 s
2022-08-17 17:57:57 | [trpo_pendulum] epoch #478 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -633.293
Evaluation/AverageReturn              -1394.85
Evaluation/Iteration                    478
Evaluation/MaxReturn                  -1328.59
Evaluation/MinReturn                  -1438.38
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     37.4603
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41447
GaussianMLPPolicy/KL                      0.000106738
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -521.798
GaussianMLPPolicy/LossBefore           -521.531
GaussianMLPPolicy/dLoss                   0.266663
GaussianMLPValueFunction/LossAfter    41888.4
GaussianMLPValueFunction/LossBefore   41942.6
GaussianMLPValueFunction/dLoss           54.2305
TotalEnvSteps                        574800
-----------------------------------  ----------------
2022-08-17 17:57:58 | [trpo_pendulum] epoch #479 | Saving snapshot...
2022-08-17 17:57:58 | [trpo_pendulum] epoch #479 | Saved
2022-08-17 17:57:58 | [trpo_pendulum] epoch #479 | Time 198.01 s
2022-08-17 17:57:58 | [trpo_pendulum] epoch #479 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -538.446
Evaluation/AverageReturn              -1326.14
Evaluation/Iteration                    479
Evaluation/MaxReturn                  -1233.31
Evaluation/MinReturn                  -1393.43
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     48.9953
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41411
GaussianMLPPolicy/KL                      7.46388e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -536.785
GaussianMLPPolicy/LossBefore           -536.761
GaussianMLPPolicy/dLoss                   0.0237427
GaussianMLPValueFunction/LossAfter    44831.1
GaussianMLPValueFunction/LossBefore   44891.3
GaussianMLPValueFunction/dLoss           60.2305
TotalEnvSteps                        576000
-----------------------------------  ----------------
2022-08-17 17:57:58 | [trpo_pendulum] epoch #480 | Saving snapshot...
2022-08-17 17:57:58 | [trpo_pendulum] epoch #480 | Saved
2022-08-17 17:57:58 | [trpo_pendulum] epoch #480 | Time 198.42 s
2022-08-17 17:57:58 | [trpo_pendulum] epoch #480 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -535.227
Evaluation/AverageReturn              -1338.3
Evaluation/Iteration                    480
Evaluation/MaxReturn                  -1314.9
Evaluation/MinReturn                  -1370.54
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     18.3456
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4139
GaussianMLPPolicy/KL                      6.86018e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -533.785
GaussianMLPPolicy/LossBefore           -533.717
GaussianMLPPolicy/dLoss                   0.067627
GaussianMLPValueFunction/LossAfter    46479
GaussianMLPValueFunction/LossBefore   46545.7
GaussianMLPValueFunction/dLoss           66.6758
TotalEnvSteps                        577200
-----------------------------------  ----------------
2022-08-17 17:57:58 | [trpo_pendulum] epoch #481 | Saving snapshot...
2022-08-17 17:57:58 | [trpo_pendulum] epoch #481 | Saved
2022-08-17 17:57:58 | [trpo_pendulum] epoch #481 | Time 198.84 s
2022-08-17 17:57:58 | [trpo_pendulum] epoch #481 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -558.046
Evaluation/AverageReturn              -1357.75
Evaluation/Iteration                    481
Evaluation/MaxReturn                  -1326.7
Evaluation/MinReturn                  -1426.94
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     35.8623
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41366
GaussianMLPPolicy/KL                      0.000500278
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -545.922
GaussianMLPPolicy/LossBefore           -545.14
GaussianMLPPolicy/dLoss                   0.781372
GaussianMLPValueFunction/LossAfter    46287.5
GaussianMLPValueFunction/LossBefore   46348.4
GaussianMLPValueFunction/dLoss           60.8789
TotalEnvSteps                        578400
-----------------------------------  ----------------
2022-08-17 17:57:59 | [trpo_pendulum] epoch #482 | Saving snapshot...
2022-08-17 17:57:59 | [trpo_pendulum] epoch #482 | Saved
2022-08-17 17:57:59 | [trpo_pendulum] epoch #482 | Time 199.25 s
2022-08-17 17:57:59 | [trpo_pendulum] epoch #482 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -559.372
Evaluation/AverageReturn              -1321.31
Evaluation/Iteration                    482
Evaluation/MaxReturn                  -1286.08
Evaluation/MinReturn                  -1359.11
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     21.2601
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41332
GaussianMLPPolicy/KL                      0.000219638
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -524.713
GaussianMLPPolicy/LossBefore           -524.739
GaussianMLPPolicy/dLoss                  -0.0253906
GaussianMLPValueFunction/LossAfter    41181.2
GaussianMLPValueFunction/LossBefore   41235.8
GaussianMLPValueFunction/dLoss           54.6367
TotalEnvSteps                        579600
-----------------------------------  ----------------
2022-08-17 17:57:59 | [trpo_pendulum] epoch #483 | Saving snapshot...
2022-08-17 17:57:59 | [trpo_pendulum] epoch #483 | Saved
2022-08-17 17:57:59 | [trpo_pendulum] epoch #483 | Time 199.67 s
2022-08-17 17:57:59 | [trpo_pendulum] epoch #483 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -584.199
Evaluation/AverageReturn              -1400.71
Evaluation/Iteration                    483
Evaluation/MaxReturn                  -1346.03
Evaluation/MinReturn                  -1449.91
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     36.5309
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41311
GaussianMLPPolicy/KL                      4.60314e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -542.178
GaussianMLPPolicy/LossBefore           -542.269
GaussianMLPPolicy/dLoss                  -0.0911255
GaussianMLPValueFunction/LossAfter    48319.5
GaussianMLPValueFunction/LossBefore   48383.5
GaussianMLPValueFunction/dLoss           64.0547
TotalEnvSteps                        580800
-----------------------------------  ----------------
2022-08-17 17:58:00 | [trpo_pendulum] epoch #484 | Saving snapshot...
2022-08-17 17:58:00 | [trpo_pendulum] epoch #484 | Saved
2022-08-17 17:58:00 | [trpo_pendulum] epoch #484 | Time 200.09 s
2022-08-17 17:58:00 | [trpo_pendulum] epoch #484 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -583.492
Evaluation/AverageReturn              -1353.5
Evaluation/Iteration                    484
Evaluation/MaxReturn                  -1285.82
Evaluation/MinReturn                  -1418.57
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     41.7128
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41298
GaussianMLPPolicy/KL                      0.000207291
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -515.686
GaussianMLPPolicy/LossBefore           -515.285
GaussianMLPPolicy/dLoss                   0.401123
GaussianMLPValueFunction/LossAfter    41743.7
GaussianMLPValueFunction/LossBefore   41798.6
GaussianMLPValueFunction/dLoss           54.8242
TotalEnvSteps                        582000
-----------------------------------  ----------------
2022-08-17 17:58:00 | [trpo_pendulum] epoch #485 | Saving snapshot...
2022-08-17 17:58:00 | [trpo_pendulum] epoch #485 | Saved
2022-08-17 17:58:00 | [trpo_pendulum] epoch #485 | Time 200.51 s
2022-08-17 17:58:00 | [trpo_pendulum] epoch #485 | EpochTime 0.42 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -575.77
Evaluation/AverageReturn              -1367.9
Evaluation/Iteration                    485
Evaluation/MaxReturn                  -1340.26
Evaluation/MinReturn                  -1406.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     27.1238
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4127
GaussianMLPPolicy/KL                      3.799e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -547.695
GaussianMLPPolicy/LossBefore           -547.771
GaussianMLPPolicy/dLoss                  -0.0757446
GaussianMLPValueFunction/LossAfter    45048.4
GaussianMLPValueFunction/LossBefore   45108.4
GaussianMLPValueFunction/dLoss           60.0078
TotalEnvSteps                        583200
-----------------------------------  --------------
2022-08-17 17:58:01 | [trpo_pendulum] epoch #486 | Saving snapshot...
2022-08-17 17:58:01 | [trpo_pendulum] epoch #486 | Saved
2022-08-17 17:58:01 | [trpo_pendulum] epoch #486 | Time 200.93 s
2022-08-17 17:58:01 | [trpo_pendulum] epoch #486 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -574.089
Evaluation/AverageReturn              -1379.8
Evaluation/Iteration                    486
Evaluation/MaxReturn                  -1329.07
Evaluation/MinReturn                  -1439.24
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     43.1884
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41273
GaussianMLPPolicy/KL                      0.000230607
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -520.519
GaussianMLPPolicy/LossBefore           -520.149
GaussianMLPPolicy/dLoss                   0.369629
GaussianMLPValueFunction/LossAfter    46751.9
GaussianMLPValueFunction/LossBefore   46818.2
GaussianMLPValueFunction/dLoss           66.3633
TotalEnvSteps                        584400
-----------------------------------  ----------------
2022-08-17 17:58:01 | [trpo_pendulum] epoch #487 | Saving snapshot...
2022-08-17 17:58:01 | [trpo_pendulum] epoch #487 | Saved
2022-08-17 17:58:01 | [trpo_pendulum] epoch #487 | Time 201.35 s
2022-08-17 17:58:01 | [trpo_pendulum] epoch #487 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -571.611
Evaluation/AverageReturn              -1372.15
Evaluation/Iteration                    487
Evaluation/MaxReturn                  -1333.06
Evaluation/MinReturn                  -1421.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     37.2774
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41282
GaussianMLPPolicy/KL                      7.47669e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -534.24
GaussianMLPPolicy/LossBefore           -534.285
GaussianMLPPolicy/dLoss                  -0.0455933
GaussianMLPValueFunction/LossAfter    45752.4
GaussianMLPValueFunction/LossBefore   45815.9
GaussianMLPValueFunction/dLoss           63.5195
TotalEnvSteps                        585600
-----------------------------------  ----------------
2022-08-17 17:58:01 | [trpo_pendulum] epoch #488 | Saving snapshot...
2022-08-17 17:58:01 | [trpo_pendulum] epoch #488 | Saved
2022-08-17 17:58:01 | [trpo_pendulum] epoch #488 | Time 201.75 s
2022-08-17 17:58:01 | [trpo_pendulum] epoch #488 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -590.97
Evaluation/AverageReturn              -1414.64
Evaluation/Iteration                    488
Evaluation/MaxReturn                  -1370.52
Evaluation/MinReturn                  -1474.62
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     34.338
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41289
GaussianMLPPolicy/KL                      4.80098e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -558.051
GaussianMLPPolicy/LossBefore           -558.033
GaussianMLPPolicy/dLoss                   0.0179443
GaussianMLPValueFunction/LossAfter    49045.5
GaussianMLPValueFunction/LossBefore   49108.3
GaussianMLPValueFunction/dLoss           62.8633
TotalEnvSteps                        586800
-----------------------------------  ----------------
2022-08-17 17:58:02 | [trpo_pendulum] epoch #489 | Saving snapshot...
2022-08-17 17:58:02 | [trpo_pendulum] epoch #489 | Saved
2022-08-17 17:58:02 | [trpo_pendulum] epoch #489 | Time 202.16 s
2022-08-17 17:58:02 | [trpo_pendulum] epoch #489 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -610.886
Evaluation/AverageReturn              -1447.82
Evaluation/Iteration                    489
Evaluation/MaxReturn                  -1418.05
Evaluation/MinReturn                  -1499.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     25.7729
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41273
GaussianMLPPolicy/KL                      2.80287e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -586.659
GaussianMLPPolicy/LossBefore           -586.65
GaussianMLPPolicy/dLoss                   0.00878906
GaussianMLPValueFunction/LossAfter    50316.2
GaussianMLPValueFunction/LossBefore   50389.1
GaussianMLPValueFunction/dLoss           72.957
TotalEnvSteps                        588000
-----------------------------------  ----------------
2022-08-17 17:58:02 | [trpo_pendulum] epoch #490 | Saving snapshot...
2022-08-17 17:58:02 | [trpo_pendulum] epoch #490 | Saved
2022-08-17 17:58:02 | [trpo_pendulum] epoch #490 | Time 202.57 s
2022-08-17 17:58:02 | [trpo_pendulum] epoch #490 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -611.685
Evaluation/AverageReturn              -1459.98
Evaluation/Iteration                    490
Evaluation/MaxReturn                  -1424.15
Evaluation/MinReturn                  -1483.94
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     19.6337
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41259
GaussianMLPPolicy/KL                      3.35741e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -573.828
GaussianMLPPolicy/LossBefore           -573.83
GaussianMLPPolicy/dLoss                  -0.00250244
GaussianMLPValueFunction/LossAfter    51147.2
GaussianMLPValueFunction/LossBefore   51223.6
GaussianMLPValueFunction/dLoss           76.4453
TotalEnvSteps                        589200
-----------------------------------  ----------------
2022-08-17 17:58:03 | [trpo_pendulum] epoch #491 | Saving snapshot...
2022-08-17 17:58:03 | [trpo_pendulum] epoch #491 | Saved
2022-08-17 17:58:03 | [trpo_pendulum] epoch #491 | Time 202.98 s
2022-08-17 17:58:03 | [trpo_pendulum] epoch #491 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -602.545
Evaluation/AverageReturn              -1431.36
Evaluation/Iteration                    491
Evaluation/MaxReturn                  -1394.86
Evaluation/MinReturn                  -1456.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     23.6299
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4126
GaussianMLPPolicy/KL                      0.000167674
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -548.339
GaussianMLPPolicy/LossBefore           -547.976
GaussianMLPPolicy/dLoss                   0.362854
GaussianMLPValueFunction/LossAfter    49125.7
GaussianMLPValueFunction/LossBefore   49200.6
GaussianMLPValueFunction/dLoss           74.8438
TotalEnvSteps                        590400
-----------------------------------  ----------------
2022-08-17 17:58:03 | [trpo_pendulum] epoch #492 | Saving snapshot...
2022-08-17 17:58:03 | [trpo_pendulum] epoch #492 | Saved
2022-08-17 17:58:03 | [trpo_pendulum] epoch #492 | Time 203.40 s
2022-08-17 17:58:03 | [trpo_pendulum] epoch #492 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -590.488
Evaluation/AverageReturn              -1418.73
Evaluation/Iteration                    492
Evaluation/MaxReturn                  -1346.13
Evaluation/MinReturn                  -1482.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     43.9235
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4126
GaussianMLPPolicy/KL                      5.58512e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -560.733
GaussianMLPPolicy/LossBefore           -560.444
GaussianMLPPolicy/dLoss                   0.289368
GaussianMLPValueFunction/LossAfter    49042.2
GaussianMLPValueFunction/LossBefore   49104.9
GaussianMLPValueFunction/dLoss           62.625
TotalEnvSteps                        591600
-----------------------------------  ----------------
2022-08-17 17:58:03 | [trpo_pendulum] epoch #493 | Saving snapshot...
2022-08-17 17:58:03 | [trpo_pendulum] epoch #493 | Saved
2022-08-17 17:58:03 | [trpo_pendulum] epoch #493 | Time 203.80 s
2022-08-17 17:58:03 | [trpo_pendulum] epoch #493 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -591.752
Evaluation/AverageReturn              -1413.16
Evaluation/Iteration                    493
Evaluation/MaxReturn                  -1373.17
Evaluation/MinReturn                  -1462.25
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     31.8408
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41268
GaussianMLPPolicy/KL                      0.000306934
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -548.485
GaussianMLPPolicy/LossBefore           -547.993
GaussianMLPPolicy/dLoss                   0.491455
GaussianMLPValueFunction/LossAfter    48213.9
GaussianMLPValueFunction/LossBefore   48277.4
GaussianMLPValueFunction/dLoss           63.4453
TotalEnvSteps                        592800
-----------------------------------  ----------------
2022-08-17 17:58:04 | [trpo_pendulum] epoch #494 | Saving snapshot...
2022-08-17 17:58:04 | [trpo_pendulum] epoch #494 | Saved
2022-08-17 17:58:04 | [trpo_pendulum] epoch #494 | Time 204.21 s
2022-08-17 17:58:04 | [trpo_pendulum] epoch #494 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -576.807
Evaluation/AverageReturn              -1386.95
Evaluation/Iteration                    494
Evaluation/MaxReturn                  -1347.77
Evaluation/MinReturn                  -1453.37
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     35.0693
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41282
GaussianMLPPolicy/KL                      0.000232971
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -540.399
GaussianMLPPolicy/LossBefore           -540.227
GaussianMLPPolicy/dLoss                   0.172241
GaussianMLPValueFunction/LossAfter    46753.5
GaussianMLPValueFunction/LossBefore   46820.3
GaussianMLPValueFunction/dLoss           66.875
TotalEnvSteps                        594000
-----------------------------------  ----------------
2022-08-17 17:58:04 | [trpo_pendulum] epoch #495 | Saving snapshot...
2022-08-17 17:58:04 | [trpo_pendulum] epoch #495 | Saved
2022-08-17 17:58:04 | [trpo_pendulum] epoch #495 | Time 204.62 s
2022-08-17 17:58:04 | [trpo_pendulum] epoch #495 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -597.318
Evaluation/AverageReturn              -1381.62
Evaluation/Iteration                    495
Evaluation/MaxReturn                  -1334.91
Evaluation/MinReturn                  -1422.49
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     28.6146
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4129
GaussianMLPPolicy/KL                      0.000455357
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -532.99
GaussianMLPPolicy/LossBefore           -532.411
GaussianMLPPolicy/dLoss                   0.57843
GaussianMLPValueFunction/LossAfter    42814.5
GaussianMLPValueFunction/LossBefore   42871.6
GaussianMLPValueFunction/dLoss           57.1445
TotalEnvSteps                        595200
-----------------------------------  ----------------
2022-08-17 17:58:05 | [trpo_pendulum] epoch #496 | Saving snapshot...
2022-08-17 17:58:05 | [trpo_pendulum] epoch #496 | Saved
2022-08-17 17:58:05 | [trpo_pendulum] epoch #496 | Time 205.03 s
2022-08-17 17:58:05 | [trpo_pendulum] epoch #496 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -588.521
Evaluation/AverageReturn              -1350.56
Evaluation/Iteration                    496
Evaluation/MaxReturn                  -1324.33
Evaluation/MinReturn                  -1376.61
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     16.932
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41306
GaussianMLPPolicy/KL                      0.000114205
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -504.865
GaussianMLPPolicy/LossBefore           -504.954
GaussianMLPPolicy/dLoss                  -0.0892029
GaussianMLPValueFunction/LossAfter    40871.7
GaussianMLPValueFunction/LossBefore   40925.8
GaussianMLPValueFunction/dLoss           54.0234
TotalEnvSteps                        596400
-----------------------------------  ----------------
2022-08-17 17:58:05 | [trpo_pendulum] epoch #497 | Saving snapshot...
2022-08-17 17:58:05 | [trpo_pendulum] epoch #497 | Saved
2022-08-17 17:58:05 | [trpo_pendulum] epoch #497 | Time 205.43 s
2022-08-17 17:58:05 | [trpo_pendulum] epoch #497 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -575.348
Evaluation/AverageReturn              -1377.4
Evaluation/Iteration                    497
Evaluation/MaxReturn                  -1346.92
Evaluation/MinReturn                  -1449.81
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     36.1714
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41324
GaussianMLPPolicy/KL                      5.64521e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -537.857
GaussianMLPPolicy/LossBefore           -537.828
GaussianMLPPolicy/dLoss                   0.0280762
GaussianMLPValueFunction/LossAfter    46244.3
GaussianMLPValueFunction/LossBefore   46309.6
GaussianMLPValueFunction/dLoss           65.2734
TotalEnvSteps                        597600
-----------------------------------  ----------------
2022-08-17 17:58:05 | [trpo_pendulum] epoch #498 | Saving snapshot...
2022-08-17 17:58:05 | [trpo_pendulum] epoch #498 | Saved
2022-08-17 17:58:05 | [trpo_pendulum] epoch #498 | Time 205.85 s
2022-08-17 17:58:05 | [trpo_pendulum] epoch #498 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -595.493
Evaluation/AverageReturn              -1412.07
Evaluation/Iteration                    498
Evaluation/MaxReturn                  -1352.22
Evaluation/MinReturn                  -1456.56
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     30.8935
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41337
GaussianMLPPolicy/KL                      0.000120993
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -553.894
GaussianMLPPolicy/LossBefore           -553.763
GaussianMLPPolicy/dLoss                   0.131592
GaussianMLPValueFunction/LossAfter    47425.4
GaussianMLPValueFunction/LossBefore   47493
GaussianMLPValueFunction/dLoss           67.6484
TotalEnvSteps                        598800
-----------------------------------  ----------------
2022-08-17 17:58:06 | [trpo_pendulum] epoch #499 | Saving snapshot...
2022-08-17 17:58:06 | [trpo_pendulum] epoch #499 | Saved
2022-08-17 17:58:06 | [trpo_pendulum] epoch #499 | Time 206.27 s
2022-08-17 17:58:06 | [trpo_pendulum] epoch #499 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -575.474
Evaluation/AverageReturn              -1360.44
Evaluation/Iteration                    499
Evaluation/MaxReturn                  -1350.37
Evaluation/MinReturn                  -1392.63
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.5951
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41344
GaussianMLPPolicy/KL                      1.38937e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -534.035
GaussianMLPPolicy/LossBefore           -533.904
GaussianMLPPolicy/dLoss                   0.130432
GaussianMLPValueFunction/LossAfter    44244.8
GaussianMLPValueFunction/LossBefore   44308.3
GaussianMLPValueFunction/dLoss           63.4492
TotalEnvSteps                        600000
-----------------------------------  ----------------
2022-08-17 17:58:06 | [trpo_pendulum] epoch #500 | Saving snapshot...
2022-08-17 17:58:06 | [trpo_pendulum] epoch #500 | Saved
2022-08-17 17:58:06 | [trpo_pendulum] epoch #500 | Time 206.67 s
2022-08-17 17:58:06 | [trpo_pendulum] epoch #500 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -590.322
Evaluation/AverageReturn              -1364.62
Evaluation/Iteration                    500
Evaluation/MaxReturn                  -1293.02
Evaluation/MinReturn                  -1430.14
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.4145
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41343
GaussianMLPPolicy/KL                      2.23057e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -526.489
GaussianMLPPolicy/LossBefore           -526.509
GaussianMLPPolicy/dLoss                  -0.0197754
GaussianMLPValueFunction/LossAfter    41360.2
GaussianMLPValueFunction/LossBefore   41414.5
GaussianMLPValueFunction/dLoss           54.2422
TotalEnvSteps                        601200
-----------------------------------  ----------------
2022-08-17 17:58:07 | [trpo_pendulum] epoch #501 | Saving snapshot...
2022-08-17 17:58:07 | [trpo_pendulum] epoch #501 | Saved
2022-08-17 17:58:07 | [trpo_pendulum] epoch #501 | Time 207.07 s
2022-08-17 17:58:07 | [trpo_pendulum] epoch #501 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -596.549
Evaluation/AverageReturn              -1430.56
Evaluation/Iteration                    501
Evaluation/MaxReturn                  -1396.37
Evaluation/MinReturn                  -1465.17
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     26.0159
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41321
GaussianMLPPolicy/KL                      0.000489705
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -584.142
GaussianMLPPolicy/LossBefore           -582.917
GaussianMLPPolicy/dLoss                   1.22534
GaussianMLPValueFunction/LossAfter    49105.7
GaussianMLPValueFunction/LossBefore   49175.1
GaussianMLPValueFunction/dLoss           69.4688
TotalEnvSteps                        602400
-----------------------------------  ----------------
2022-08-17 17:58:07 | [trpo_pendulum] epoch #502 | Saving snapshot...
2022-08-17 17:58:07 | [trpo_pendulum] epoch #502 | Saved
2022-08-17 17:58:07 | [trpo_pendulum] epoch #502 | Time 207.48 s
2022-08-17 17:58:07 | [trpo_pendulum] epoch #502 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -567.618
Evaluation/AverageReturn              -1333.63
Evaluation/Iteration                    502
Evaluation/MaxReturn                  -1284.11
Evaluation/MinReturn                  -1374.26
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     34.507
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41311
GaussianMLPPolicy/KL                      0.000845502
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -507.288
GaussianMLPPolicy/LossBefore           -506.341
GaussianMLPPolicy/dLoss                   0.946808
GaussianMLPValueFunction/LossAfter    41093
GaussianMLPValueFunction/LossBefore   41148.7
GaussianMLPValueFunction/dLoss           55.7266
TotalEnvSteps                        603600
-----------------------------------  ----------------
2022-08-17 17:58:08 | [trpo_pendulum] epoch #503 | Saving snapshot...
2022-08-17 17:58:08 | [trpo_pendulum] epoch #503 | Saved
2022-08-17 17:58:08 | [trpo_pendulum] epoch #503 | Time 207.90 s
2022-08-17 17:58:08 | [trpo_pendulum] epoch #503 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -579.931
Evaluation/AverageReturn              -1375.55
Evaluation/Iteration                    503
Evaluation/MaxReturn                  -1336.05
Evaluation/MinReturn                  -1408.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     28.8159
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41297
GaussianMLPPolicy/KL                      0.00206173
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -543.067
GaussianMLPPolicy/LossBefore           -540.615
GaussianMLPPolicy/dLoss                   2.45233
GaussianMLPValueFunction/LossAfter    45053.2
GaussianMLPValueFunction/LossBefore   45109.6
GaussianMLPValueFunction/dLoss           56.4453
TotalEnvSteps                        604800
-----------------------------------  ---------------
2022-08-17 17:58:08 | [trpo_pendulum] epoch #504 | Saving snapshot...
2022-08-17 17:58:08 | [trpo_pendulum] epoch #504 | Saved
2022-08-17 17:58:08 | [trpo_pendulum] epoch #504 | Time 208.30 s
2022-08-17 17:58:08 | [trpo_pendulum] epoch #504 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -631.756
Evaluation/AverageReturn              -1381.12
Evaluation/Iteration                    504
Evaluation/MaxReturn                  -1346.74
Evaluation/MinReturn                  -1403.98
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     23.6269
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41282
GaussianMLPPolicy/KL                      0.00165346
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -506.395
GaussianMLPPolicy/LossBefore           -505.001
GaussianMLPPolicy/dLoss                   1.39423
GaussianMLPValueFunction/LossAfter    39271
GaussianMLPValueFunction/LossBefore   39321.2
GaussianMLPValueFunction/dLoss           50.2188
TotalEnvSteps                        606000
-----------------------------------  ---------------
2022-08-17 17:58:08 | [trpo_pendulum] epoch #505 | Saving snapshot...
2022-08-17 17:58:08 | [trpo_pendulum] epoch #505 | Saved
2022-08-17 17:58:08 | [trpo_pendulum] epoch #505 | Time 208.70 s
2022-08-17 17:58:08 | [trpo_pendulum] epoch #505 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -546.89
Evaluation/AverageReturn              -1327.68
Evaluation/Iteration                    505
Evaluation/MaxReturn                  -1275.05
Evaluation/MinReturn                  -1354.72
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     26.1618
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41279
GaussianMLPPolicy/KL                      0.00266098
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -517.939
GaussianMLPPolicy/LossBefore           -516.03
GaussianMLPPolicy/dLoss                   1.90973
GaussianMLPValueFunction/LossAfter    42661.7
GaussianMLPValueFunction/LossBefore   42718.1
GaussianMLPValueFunction/dLoss           56.4102
TotalEnvSteps                        607200
-----------------------------------  ---------------
2022-08-17 17:58:09 | [trpo_pendulum] epoch #506 | Saving snapshot...
2022-08-17 17:58:09 | [trpo_pendulum] epoch #506 | Saved
2022-08-17 17:58:09 | [trpo_pendulum] epoch #506 | Time 209.13 s
2022-08-17 17:58:09 | [trpo_pendulum] epoch #506 | EpochTime 0.42 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -560.207
Evaluation/AverageReturn              -1327.46
Evaluation/Iteration                    506
Evaluation/MaxReturn                  -1261.78
Evaluation/MinReturn                  -1351.94
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     30.3746
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41273
GaussianMLPPolicy/KL                      0.0018872
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -519.373
GaussianMLPPolicy/LossBefore           -518.977
GaussianMLPPolicy/dLoss                   0.396851
GaussianMLPValueFunction/LossAfter    41153.9
GaussianMLPValueFunction/LossBefore   41208.9
GaussianMLPValueFunction/dLoss           55.0664
TotalEnvSteps                        608400
-----------------------------------  --------------
2022-08-17 17:58:09 | [trpo_pendulum] epoch #507 | Saving snapshot...
2022-08-17 17:58:09 | [trpo_pendulum] epoch #507 | Saved
2022-08-17 17:58:09 | [trpo_pendulum] epoch #507 | Time 209.54 s
2022-08-17 17:58:09 | [trpo_pendulum] epoch #507 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -521.533
Evaluation/AverageReturn              -1248.28
Evaluation/Iteration                    507
Evaluation/MaxReturn                  -1193.43
Evaluation/MinReturn                  -1309.93
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     45.903
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41279
GaussianMLPPolicy/KL                      0.000970831
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -475.599
GaussianMLPPolicy/LossBefore           -475.768
GaussianMLPPolicy/dLoss                  -0.168976
GaussianMLPValueFunction/LossAfter    37222.3
GaussianMLPValueFunction/LossBefore   37268.7
GaussianMLPValueFunction/dLoss           46.4727
TotalEnvSteps                        609600
-----------------------------------  ----------------
2022-08-17 17:58:10 | [trpo_pendulum] epoch #508 | Saving snapshot...
2022-08-17 17:58:10 | [trpo_pendulum] epoch #508 | Saved
2022-08-17 17:58:10 | [trpo_pendulum] epoch #508 | Time 209.93 s
2022-08-17 17:58:10 | [trpo_pendulum] epoch #508 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -631.118
Evaluation/AverageReturn              -1344.53
Evaluation/Iteration                    508
Evaluation/MaxReturn                  -1296.23
Evaluation/MinReturn                  -1422.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     38.3859
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4129
GaussianMLPPolicy/KL                      0.000633083
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -473.224
GaussianMLPPolicy/LossBefore           -472.799
GaussianMLPPolicy/dLoss                   0.424774
GaussianMLPValueFunction/LossAfter    36332.8
GaussianMLPValueFunction/LossBefore   36377.6
GaussianMLPValueFunction/dLoss           44.7891
TotalEnvSteps                        610800
-----------------------------------  ----------------
2022-08-17 17:58:10 | [trpo_pendulum] epoch #509 | Saving snapshot...
2022-08-17 17:58:10 | [trpo_pendulum] epoch #509 | Saved
2022-08-17 17:58:10 | [trpo_pendulum] epoch #509 | Time 210.33 s
2022-08-17 17:58:10 | [trpo_pendulum] epoch #509 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -521.069
Evaluation/AverageReturn              -1258.44
Evaluation/Iteration                    509
Evaluation/MaxReturn                  -1206.72
Evaluation/MinReturn                  -1309.03
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     40.6297
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41305
GaussianMLPPolicy/KL                      0.00087748
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -491.011
GaussianMLPPolicy/LossBefore           -490.643
GaussianMLPPolicy/dLoss                   0.36731
GaussianMLPValueFunction/LossAfter    37520.6
GaussianMLPValueFunction/LossBefore   37567.4
GaussianMLPValueFunction/dLoss           46.8477
TotalEnvSteps                        612000
-----------------------------------  ---------------
2022-08-17 17:58:10 | [trpo_pendulum] epoch #510 | Saving snapshot...
2022-08-17 17:58:10 | [trpo_pendulum] epoch #510 | Saved
2022-08-17 17:58:10 | [trpo_pendulum] epoch #510 | Time 210.75 s
2022-08-17 17:58:10 | [trpo_pendulum] epoch #510 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -492.334
Evaluation/AverageReturn              -1173.94
Evaluation/Iteration                    510
Evaluation/MaxReturn                  -1142.03
Evaluation/MinReturn                  -1205.12
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     24.7495
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41306
GaussianMLPPolicy/KL                      0.000475222
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -464.366
GaussianMLPPolicy/LossBefore           -464.402
GaussianMLPPolicy/dLoss                  -0.0353699
GaussianMLPValueFunction/LossAfter    31873.5
GaussianMLPValueFunction/LossBefore   31912.6
GaussianMLPValueFunction/dLoss           39.166
TotalEnvSteps                        613200
-----------------------------------  ----------------
2022-08-17 17:58:11 | [trpo_pendulum] epoch #511 | Saving snapshot...
2022-08-17 17:58:11 | [trpo_pendulum] epoch #511 | Saved
2022-08-17 17:58:11 | [trpo_pendulum] epoch #511 | Time 211.16 s
2022-08-17 17:58:11 | [trpo_pendulum] epoch #511 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -472.385
Evaluation/AverageReturn              -1149.73
Evaluation/Iteration                    511
Evaluation/MaxReturn                  -1056.54
Evaluation/MinReturn                  -1184.26
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     43.4284
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41309
GaussianMLPPolicy/KL                      0.000442294
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -450.876
GaussianMLPPolicy/LossBefore           -450.674
GaussianMLPPolicy/dLoss                   0.201721
GaussianMLPValueFunction/LossAfter    31244.1
GaussianMLPValueFunction/LossBefore   31282.1
GaussianMLPValueFunction/dLoss           37.9297
TotalEnvSteps                        614400
-----------------------------------  ----------------
2022-08-17 17:58:11 | [trpo_pendulum] epoch #512 | Saving snapshot...
2022-08-17 17:58:11 | [trpo_pendulum] epoch #512 | Saved
2022-08-17 17:58:11 | [trpo_pendulum] epoch #512 | Time 211.58 s
2022-08-17 17:58:11 | [trpo_pendulum] epoch #512 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -476.463
Evaluation/AverageReturn              -1159.58
Evaluation/Iteration                    512
Evaluation/MaxReturn                  -1023.54
Evaluation/MinReturn                  -1277.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     76.7833
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41325
GaussianMLPPolicy/KL                      0.000595535
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -443.567
GaussianMLPPolicy/LossBefore           -443.006
GaussianMLPPolicy/dLoss                   0.560791
GaussianMLPValueFunction/LossAfter    31684.9
GaussianMLPValueFunction/LossBefore   31722.3
GaussianMLPValueFunction/dLoss           37.3984
TotalEnvSteps                        615600
-----------------------------------  ----------------
2022-08-17 17:58:12 | [trpo_pendulum] epoch #513 | Saving snapshot...
2022-08-17 17:58:12 | [trpo_pendulum] epoch #513 | Saved
2022-08-17 17:58:12 | [trpo_pendulum] epoch #513 | Time 211.99 s
2022-08-17 17:58:12 | [trpo_pendulum] epoch #513 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -621.001
Evaluation/AverageReturn              -1316.39
Evaluation/Iteration                    513
Evaluation/MaxReturn                  -1240.02
Evaluation/MinReturn                  -1395.01
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     60.3708
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4134
GaussianMLPPolicy/KL                      0.000254625
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -463.426
GaussianMLPPolicy/LossBefore           -463.456
GaussianMLPPolicy/dLoss                  -0.0294495
GaussianMLPValueFunction/LossAfter    35058.7
GaussianMLPValueFunction/LossBefore   35098.3
GaussianMLPValueFunction/dLoss           39.5938
TotalEnvSteps                        616800
-----------------------------------  ----------------
2022-08-17 17:58:12 | [trpo_pendulum] epoch #514 | Saving snapshot...
2022-08-17 17:58:12 | [trpo_pendulum] epoch #514 | Saved
2022-08-17 17:58:12 | [trpo_pendulum] epoch #514 | Time 212.40 s
2022-08-17 17:58:12 | [trpo_pendulum] epoch #514 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -447.574
Evaluation/AverageReturn              -1123.31
Evaluation/Iteration                    514
Evaluation/MaxReturn                  -1032.65
Evaluation/MinReturn                  -1196.44
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     70.2594
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41348
GaussianMLPPolicy/KL                      0.000262775
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -455.407
GaussianMLPPolicy/LossBefore           -455.329
GaussianMLPPolicy/dLoss                   0.0778198
GaussianMLPValueFunction/LossAfter    31119
GaussianMLPValueFunction/LossBefore   31155
GaussianMLPValueFunction/dLoss           35.9785
TotalEnvSteps                        618000
-----------------------------------  ----------------
2022-08-17 17:58:12 | [trpo_pendulum] epoch #515 | Saving snapshot...
2022-08-17 17:58:12 | [trpo_pendulum] epoch #515 | Saved
2022-08-17 17:58:12 | [trpo_pendulum] epoch #515 | Time 212.81 s
2022-08-17 17:58:12 | [trpo_pendulum] epoch #515 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -541.626
Evaluation/AverageReturn              -1181.57
Evaluation/Iteration                    515
Evaluation/MaxReturn                  -1102.67
Evaluation/MinReturn                  -1250.04
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     65.6721
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41357
GaussianMLPPolicy/KL                      0.000288475
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -423.48
GaussianMLPPolicy/LossBefore           -423.246
GaussianMLPPolicy/dLoss                   0.234802
GaussianMLPValueFunction/LossAfter    28334.8
GaussianMLPValueFunction/LossBefore   28366.2
GaussianMLPValueFunction/dLoss           31.3613
TotalEnvSteps                        619200
-----------------------------------  ----------------
2022-08-17 17:58:13 | [trpo_pendulum] epoch #516 | Saving snapshot...
2022-08-17 17:58:13 | [trpo_pendulum] epoch #516 | Saved
2022-08-17 17:58:13 | [trpo_pendulum] epoch #516 | Time 213.25 s
2022-08-17 17:58:13 | [trpo_pendulum] epoch #516 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -473.454
Evaluation/AverageReturn              -1111.87
Evaluation/Iteration                    516
Evaluation/MaxReturn                   -986.291
Evaluation/MinReturn                  -1187.46
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     65.0309
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41384
GaussianMLPPolicy/KL                      0.000201608
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -406.935
GaussianMLPPolicy/LossBefore           -406.933
GaussianMLPPolicy/dLoss                   0.0020752
GaussianMLPValueFunction/LossAfter    27047.2
GaussianMLPValueFunction/LossBefore   27077
GaussianMLPValueFunction/dLoss           29.7441
TotalEnvSteps                        620400
-----------------------------------  ----------------
2022-08-17 17:58:13 | [trpo_pendulum] epoch #517 | Saving snapshot...
2022-08-17 17:58:13 | [trpo_pendulum] epoch #517 | Saved
2022-08-17 17:58:13 | [trpo_pendulum] epoch #517 | Time 213.66 s
2022-08-17 17:58:13 | [trpo_pendulum] epoch #517 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -559.17
Evaluation/AverageReturn              -1212.08
Evaluation/Iteration                    517
Evaluation/MaxReturn                  -1103.23
Evaluation/MinReturn                  -1259.62
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.6532
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41412
GaussianMLPPolicy/KL                      7.38388e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -429.929
GaussianMLPPolicy/LossBefore           -429.973
GaussianMLPPolicy/dLoss                  -0.0444946
GaussianMLPValueFunction/LossAfter    30251.7
GaussianMLPValueFunction/LossBefore   30283.5
GaussianMLPValueFunction/dLoss           31.8398
TotalEnvSteps                        621600
-----------------------------------  ----------------
2022-08-17 17:58:14 | [trpo_pendulum] epoch #518 | Saving snapshot...
2022-08-17 17:58:14 | [trpo_pendulum] epoch #518 | Saved
2022-08-17 17:58:14 | [trpo_pendulum] epoch #518 | Time 214.08 s
2022-08-17 17:58:14 | [trpo_pendulum] epoch #518 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -746.891
Evaluation/AverageReturn              -1620.37
Evaluation/Iteration                    518
Evaluation/MaxReturn                  -1465.63
Evaluation/MinReturn                  -1840.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    142.808
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41432
GaussianMLPPolicy/KL                      1.43637e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -596.635
GaussianMLPPolicy/LossBefore           -596.648
GaussianMLPPolicy/dLoss                  -0.0133667
GaussianMLPValueFunction/LossAfter    56487.3
GaussianMLPValueFunction/LossBefore   56547.5
GaussianMLPValueFunction/dLoss           60.2383
TotalEnvSteps                        622800
-----------------------------------  ----------------
2022-08-17 17:58:14 | [trpo_pendulum] epoch #519 | Saving snapshot...
2022-08-17 17:58:14 | [trpo_pendulum] epoch #519 | Saved
2022-08-17 17:58:14 | [trpo_pendulum] epoch #519 | Time 214.50 s
2022-08-17 17:58:14 | [trpo_pendulum] epoch #519 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -468.774
Evaluation/AverageReturn              -1092.47
Evaluation/Iteration                    519
Evaluation/MaxReturn                  -1037.26
Evaluation/MinReturn                  -1177.3
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     57.4267
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41448
GaussianMLPPolicy/KL                      1.66443e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -414.976
GaussianMLPPolicy/LossBefore           -414.984
GaussianMLPPolicy/dLoss                  -0.00793457
GaussianMLPValueFunction/LossAfter    26771.6
GaussianMLPValueFunction/LossBefore   26801.3
GaussianMLPValueFunction/dLoss           29.7578
TotalEnvSteps                        624000
-----------------------------------  ----------------
2022-08-17 17:58:15 | [trpo_pendulum] epoch #520 | Saving snapshot...
2022-08-17 17:58:15 | [trpo_pendulum] epoch #520 | Saved
2022-08-17 17:58:15 | [trpo_pendulum] epoch #520 | Time 214.90 s
2022-08-17 17:58:15 | [trpo_pendulum] epoch #520 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -470.242
Evaluation/AverageReturn              -1103.64
Evaluation/Iteration                    520
Evaluation/MaxReturn                  -1040.19
Evaluation/MinReturn                  -1176.83
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     59.784
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41469
GaussianMLPPolicy/KL                      1.84212e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -413.708
GaussianMLPPolicy/LossBefore           -413.71
GaussianMLPPolicy/dLoss                  -0.00134277
GaussianMLPValueFunction/LossAfter    27094.9
GaussianMLPValueFunction/LossBefore   27124.4
GaussianMLPValueFunction/dLoss           29.5469
TotalEnvSteps                        625200
-----------------------------------  ----------------
2022-08-17 17:58:15 | [trpo_pendulum] epoch #521 | Saving snapshot...
2022-08-17 17:58:15 | [trpo_pendulum] epoch #521 | Saved
2022-08-17 17:58:15 | [trpo_pendulum] epoch #521 | Time 215.31 s
2022-08-17 17:58:15 | [trpo_pendulum] epoch #521 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -491.639
Evaluation/AverageReturn              -1129.26
Evaluation/Iteration                    521
Evaluation/MaxReturn                  -1107.78
Evaluation/MinReturn                  -1151
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.2465
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41502
GaussianMLPPolicy/KL                      4.68551e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -411.473
GaussianMLPPolicy/LossBefore           -411.445
GaussianMLPPolicy/dLoss                   0.0276794
GaussianMLPValueFunction/LossAfter    27230.7
GaussianMLPValueFunction/LossBefore   27259.4
GaussianMLPValueFunction/dLoss           28.6738
TotalEnvSteps                        626400
-----------------------------------  ----------------
2022-08-17 17:58:15 | [trpo_pendulum] epoch #522 | Saving snapshot...
2022-08-17 17:58:15 | [trpo_pendulum] epoch #522 | Saved
2022-08-17 17:58:15 | [trpo_pendulum] epoch #522 | Time 215.72 s
2022-08-17 17:58:15 | [trpo_pendulum] epoch #522 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -477.317
Evaluation/AverageReturn              -1089.56
Evaluation/Iteration                    522
Evaluation/MaxReturn                   -987.924
Evaluation/MinReturn                  -1147.53
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     58.8709
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41531
GaussianMLPPolicy/KL                      3.47902e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -405.722
GaussianMLPPolicy/LossBefore           -405.629
GaussianMLPPolicy/dLoss                   0.092926
GaussianMLPValueFunction/LossAfter    25250.7
GaussianMLPValueFunction/LossBefore   25276.8
GaussianMLPValueFunction/dLoss           26.0762
TotalEnvSteps                        627600
-----------------------------------  ----------------
2022-08-17 17:58:16 | [trpo_pendulum] epoch #523 | Saving snapshot...
2022-08-17 17:58:16 | [trpo_pendulum] epoch #523 | Saved
2022-08-17 17:58:16 | [trpo_pendulum] epoch #523 | Time 216.13 s
2022-08-17 17:58:16 | [trpo_pendulum] epoch #523 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -535.477
Evaluation/AverageReturn              -1143.46
Evaluation/Iteration                    523
Evaluation/MaxReturn                  -1097.17
Evaluation/MinReturn                  -1217.95
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     45.2704
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41563
GaussianMLPPolicy/KL                      3.82762e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -397.223
GaussianMLPPolicy/LossBefore           -397.168
GaussianMLPPolicy/dLoss                   0.0552063
GaussianMLPValueFunction/LossAfter    26090.7
GaussianMLPValueFunction/LossBefore   26116.7
GaussianMLPValueFunction/dLoss           26.0098
TotalEnvSteps                        628800
-----------------------------------  ----------------
2022-08-17 17:58:16 | [trpo_pendulum] epoch #524 | Saving snapshot...
2022-08-17 17:58:16 | [trpo_pendulum] epoch #524 | Saved
2022-08-17 17:58:16 | [trpo_pendulum] epoch #524 | Time 216.53 s
2022-08-17 17:58:16 | [trpo_pendulum] epoch #524 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -483.455
Evaluation/AverageReturn              -1082.09
Evaluation/Iteration                    524
Evaluation/MaxReturn                  -1006.93
Evaluation/MinReturn                  -1119.9
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     36.5658
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41589
GaussianMLPPolicy/KL                      7.51661e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -398.503
GaussianMLPPolicy/LossBefore           -398.403
GaussianMLPPolicy/dLoss                   0.0991516
GaussianMLPValueFunction/LossAfter    23796.2
GaussianMLPValueFunction/LossBefore   23819.7
GaussianMLPValueFunction/dLoss           23.5039
TotalEnvSteps                        630000
-----------------------------------  ----------------
2022-08-17 17:58:17 | [trpo_pendulum] epoch #525 | Saving snapshot...
2022-08-17 17:58:17 | [trpo_pendulum] epoch #525 | Saved
2022-08-17 17:58:17 | [trpo_pendulum] epoch #525 | Time 216.95 s
2022-08-17 17:58:17 | [trpo_pendulum] epoch #525 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -453.563
Evaluation/AverageReturn              -1068.44
Evaluation/Iteration                    525
Evaluation/MaxReturn                   -991.209
Evaluation/MinReturn                  -1176.99
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     57.8177
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41615
GaussianMLPPolicy/KL                      1.24904e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -404.368
GaussianMLPPolicy/LossBefore           -404.406
GaussianMLPPolicy/dLoss                  -0.0384216
GaussianMLPValueFunction/LossAfter    25585.4
GaussianMLPValueFunction/LossBefore   25610.3
GaussianMLPValueFunction/dLoss           24.918
TotalEnvSteps                        631200
-----------------------------------  ----------------
2022-08-17 17:58:17 | [trpo_pendulum] epoch #526 | Saving snapshot...
2022-08-17 17:58:17 | [trpo_pendulum] epoch #526 | Saved
2022-08-17 17:58:17 | [trpo_pendulum] epoch #526 | Time 217.36 s
2022-08-17 17:58:17 | [trpo_pendulum] epoch #526 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -447.018
Evaluation/AverageReturn              -1059.46
Evaluation/Iteration                    526
Evaluation/MaxReturn                  -1021.93
Evaluation/MinReturn                  -1181.23
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     55.4323
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41639
GaussianMLPPolicy/KL                      0.000111704
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -405.737
GaussianMLPPolicy/LossBefore           -405.518
GaussianMLPPolicy/dLoss                   0.21933
GaussianMLPValueFunction/LossAfter    25194.4
GaussianMLPValueFunction/LossBefore   25218.6
GaussianMLPValueFunction/dLoss           24.1602
TotalEnvSteps                        632400
-----------------------------------  ----------------
2022-08-17 17:58:17 | [trpo_pendulum] epoch #527 | Saving snapshot...
2022-08-17 17:58:17 | [trpo_pendulum] epoch #527 | Saved
2022-08-17 17:58:17 | [trpo_pendulum] epoch #527 | Time 217.76 s
2022-08-17 17:58:17 | [trpo_pendulum] epoch #527 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -448.321
Evaluation/AverageReturn              -1063.86
Evaluation/Iteration                    527
Evaluation/MaxReturn                  -1028.64
Evaluation/MinReturn                  -1183.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     53.9687
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41665
GaussianMLPPolicy/KL                      6.60067e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -403.611
GaussianMLPPolicy/LossBefore           -403.616
GaussianMLPPolicy/dLoss                  -0.00518799
GaussianMLPValueFunction/LossAfter    25480.3
GaussianMLPValueFunction/LossBefore   25504.6
GaussianMLPValueFunction/dLoss           24.3242
TotalEnvSteps                        633600
-----------------------------------  ----------------
2022-08-17 17:58:18 | [trpo_pendulum] epoch #528 | Saving snapshot...
2022-08-17 17:58:18 | [trpo_pendulum] epoch #528 | Saved
2022-08-17 17:58:18 | [trpo_pendulum] epoch #528 | Time 218.18 s
2022-08-17 17:58:18 | [trpo_pendulum] epoch #528 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -465.767
Evaluation/AverageReturn              -1107.03
Evaluation/Iteration                    528
Evaluation/MaxReturn                  -1040.91
Evaluation/MinReturn                  -1187.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.1502
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41675
GaussianMLPPolicy/KL                      0.000194782
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -438.074
GaussianMLPPolicy/LossBefore           -437.775
GaussianMLPPolicy/dLoss                   0.298492
GaussianMLPValueFunction/LossAfter    27749.5
GaussianMLPValueFunction/LossBefore   27775.3
GaussianMLPValueFunction/dLoss           25.7715
TotalEnvSteps                        634800
-----------------------------------  ----------------
2022-08-17 17:58:18 | [trpo_pendulum] epoch #529 | Saving snapshot...
2022-08-17 17:58:18 | [trpo_pendulum] epoch #529 | Saved
2022-08-17 17:58:18 | [trpo_pendulum] epoch #529 | Time 218.59 s
2022-08-17 17:58:18 | [trpo_pendulum] epoch #529 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -473.225
Evaluation/AverageReturn              -1070.03
Evaluation/Iteration                    529
Evaluation/MaxReturn                   -997.54
Evaluation/MinReturn                  -1104.47
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     39.5592
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4167
GaussianMLPPolicy/KL                      2.45102e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -406.976
GaussianMLPPolicy/LossBefore           -407.034
GaussianMLPPolicy/dLoss                  -0.0579224
GaussianMLPValueFunction/LossAfter    23366.3
GaussianMLPValueFunction/LossBefore   23387.8
GaussianMLPValueFunction/dLoss           21.4551
TotalEnvSteps                        636000
-----------------------------------  ----------------
2022-08-17 17:58:19 | [trpo_pendulum] epoch #530 | Saving snapshot...
2022-08-17 17:58:19 | [trpo_pendulum] epoch #530 | Saved
2022-08-17 17:58:19 | [trpo_pendulum] epoch #530 | Time 219.01 s
2022-08-17 17:58:19 | [trpo_pendulum] epoch #530 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -419.332
Evaluation/AverageReturn              -1010.94
Evaluation/Iteration                    530
Evaluation/MaxReturn                   -905.99
Evaluation/MinReturn                  -1134.52
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     79.1926
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41683
GaussianMLPPolicy/KL                      5.20794e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -375.074
GaussianMLPPolicy/LossBefore           -375.038
GaussianMLPPolicy/dLoss                   0.0357666
GaussianMLPValueFunction/LossAfter    23536.1
GaussianMLPValueFunction/LossBefore   23557.5
GaussianMLPValueFunction/dLoss           21.4043
TotalEnvSteps                        637200
-----------------------------------  ----------------
2022-08-17 17:58:19 | [trpo_pendulum] epoch #531 | Saving snapshot...
2022-08-17 17:58:19 | [trpo_pendulum] epoch #531 | Saved
2022-08-17 17:58:19 | [trpo_pendulum] epoch #531 | Time 219.41 s
2022-08-17 17:58:19 | [trpo_pendulum] epoch #531 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -460.152
Evaluation/AverageReturn              -1086.35
Evaluation/Iteration                    531
Evaluation/MaxReturn                   -948.774
Evaluation/MinReturn                  -1222.64
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     90.508
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41704
GaussianMLPPolicy/KL                      0.000322475
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -408.043
GaussianMLPPolicy/LossBefore           -407.098
GaussianMLPPolicy/dLoss                   0.944794
GaussianMLPValueFunction/LossAfter    26022.9
GaussianMLPValueFunction/LossBefore   26046.3
GaussianMLPValueFunction/dLoss           23.4258
TotalEnvSteps                        638400
-----------------------------------  ----------------
2022-08-17 17:58:19 | [trpo_pendulum] epoch #532 | Saving snapshot...
2022-08-17 17:58:19 | [trpo_pendulum] epoch #532 | Saved
2022-08-17 17:58:19 | [trpo_pendulum] epoch #532 | Time 219.81 s
2022-08-17 17:58:19 | [trpo_pendulum] epoch #532 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -559.234
Evaluation/AverageReturn              -1233.26
Evaluation/Iteration                    532
Evaluation/MaxReturn                  -1189.79
Evaluation/MinReturn                  -1306.97
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     40.6012
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4172
GaussianMLPPolicy/KL                      0.000100581
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -451.881
GaussianMLPPolicy/LossBefore           -451.947
GaussianMLPPolicy/dLoss                  -0.0657654
GaussianMLPValueFunction/LossAfter    31285.2
GaussianMLPValueFunction/LossBefore   31312.5
GaussianMLPValueFunction/dLoss           27.3145
TotalEnvSteps                        639600
-----------------------------------  ----------------
2022-08-17 17:58:20 | [trpo_pendulum] epoch #533 | Saving snapshot...
2022-08-17 17:58:20 | [trpo_pendulum] epoch #533 | Saved
2022-08-17 17:58:20 | [trpo_pendulum] epoch #533 | Time 220.22 s
2022-08-17 17:58:20 | [trpo_pendulum] epoch #533 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -415.951
Evaluation/AverageReturn              -1016.8
Evaluation/Iteration                    533
Evaluation/MaxReturn                   -913.424
Evaluation/MinReturn                  -1125.49
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     77.7384
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41745
GaussianMLPPolicy/KL                      0.000168078
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -388.145
GaussianMLPPolicy/LossBefore           -387.989
GaussianMLPPolicy/dLoss                   0.156677
GaussianMLPValueFunction/LossAfter    24630.8
GaussianMLPValueFunction/LossBefore   24652.8
GaussianMLPValueFunction/dLoss           22.0254
TotalEnvSteps                        640800
-----------------------------------  ----------------
2022-08-17 17:58:20 | [trpo_pendulum] epoch #534 | Saving snapshot...
2022-08-17 17:58:20 | [trpo_pendulum] epoch #534 | Saved
2022-08-17 17:58:20 | [trpo_pendulum] epoch #534 | Time 220.63 s
2022-08-17 17:58:20 | [trpo_pendulum] epoch #534 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -440.223
Evaluation/AverageReturn              -1019.45
Evaluation/Iteration                    534
Evaluation/MaxReturn                   -971.121
Evaluation/MinReturn                  -1065.04
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     31.3354
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41775
GaussianMLPPolicy/KL                      0.000195704
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -374.463
GaussianMLPPolicy/LossBefore           -374.33
GaussianMLPPolicy/dLoss                   0.133575
GaussianMLPValueFunction/LossAfter    21916.8
GaussianMLPValueFunction/LossBefore   21936.3
GaussianMLPValueFunction/dLoss           19.4609
TotalEnvSteps                        642000
-----------------------------------  ----------------
2022-08-17 17:58:21 | [trpo_pendulum] epoch #535 | Saving snapshot...
2022-08-17 17:58:21 | [trpo_pendulum] epoch #535 | Saved
2022-08-17 17:58:21 | [trpo_pendulum] epoch #535 | Time 221.04 s
2022-08-17 17:58:21 | [trpo_pendulum] epoch #535 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -403.854
Evaluation/AverageReturn               -998.729
Evaluation/Iteration                    535
Evaluation/MaxReturn                   -893.613
Evaluation/MinReturn                  -1086.26
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     71.5213
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41802
GaussianMLPPolicy/KL                      0.00031605
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -394.311
GaussianMLPPolicy/LossBefore           -394.003
GaussianMLPPolicy/dLoss                   0.308655
GaussianMLPValueFunction/LossAfter    23429.7
GaussianMLPValueFunction/LossBefore   23450.1
GaussianMLPValueFunction/dLoss           20.4199
TotalEnvSteps                        643200
-----------------------------------  ---------------
2022-08-17 17:58:21 | [trpo_pendulum] epoch #536 | Saving snapshot...
2022-08-17 17:58:21 | [trpo_pendulum] epoch #536 | Saved
2022-08-17 17:58:21 | [trpo_pendulum] epoch #536 | Time 221.44 s
2022-08-17 17:58:21 | [trpo_pendulum] epoch #536 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -421.996
Evaluation/AverageReturn               -956.508
Evaluation/Iteration                    536
Evaluation/MaxReturn                   -921.159
Evaluation/MinReturn                  -1001.52
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     33.0571
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41824
GaussianMLPPolicy/KL                      6.17638e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -351.154
GaussianMLPPolicy/LossBefore           -351.266
GaussianMLPPolicy/dLoss                  -0.112213
GaussianMLPValueFunction/LossAfter    18765.6
GaussianMLPValueFunction/LossBefore   18781.7
GaussianMLPValueFunction/dLoss           16.0684
TotalEnvSteps                        644400
-----------------------------------  ----------------
2022-08-17 17:58:21 | [trpo_pendulum] epoch #537 | Saving snapshot...
2022-08-17 17:58:22 | [trpo_pendulum] epoch #537 | Saved
2022-08-17 17:58:22 | [trpo_pendulum] epoch #537 | Time 221.86 s
2022-08-17 17:58:22 | [trpo_pendulum] epoch #537 | EpochTime 0.41 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -423.344
Evaluation/AverageReturn               -998.746
Evaluation/Iteration                    537
Evaluation/MaxReturn                   -900.194
Evaluation/MinReturn                  -1086.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     70.4516
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41858
GaussianMLPPolicy/KL                      0.0002458
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -367.151
GaussianMLPPolicy/LossBefore           -366.735
GaussianMLPPolicy/dLoss                   0.415985
GaussianMLPValueFunction/LossAfter    22273.1
GaussianMLPValueFunction/LossBefore   22291.8
GaussianMLPValueFunction/dLoss           18.6445
TotalEnvSteps                        645600
-----------------------------------  --------------
2022-08-17 17:58:22 | [trpo_pendulum] epoch #538 | Saving snapshot...
2022-08-17 17:58:22 | [trpo_pendulum] epoch #538 | Saved
2022-08-17 17:58:22 | [trpo_pendulum] epoch #538 | Time 222.26 s
2022-08-17 17:58:22 | [trpo_pendulum] epoch #538 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -411.702
Evaluation/AverageReturn               -957.529
Evaluation/Iteration                    538
Evaluation/MaxReturn                   -893.393
Evaluation/MinReturn                  -1042.03
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     63.9031
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41893
GaussianMLPPolicy/KL                      0.000285718
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -355.227
GaussianMLPPolicy/LossBefore           -355.009
GaussianMLPPolicy/dLoss                   0.21701
GaussianMLPValueFunction/LossAfter    19973.5
GaussianMLPValueFunction/LossBefore   19990
GaussianMLPValueFunction/dLoss           16.5195
TotalEnvSteps                        646800
-----------------------------------  ----------------
2022-08-17 17:58:22 | [trpo_pendulum] epoch #539 | Saving snapshot...
2022-08-17 17:58:22 | [trpo_pendulum] epoch #539 | Saved
2022-08-17 17:58:22 | [trpo_pendulum] epoch #539 | Time 222.68 s
2022-08-17 17:58:22 | [trpo_pendulum] epoch #539 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -442.453
Evaluation/AverageReturn              -1007.85
Evaluation/Iteration                    539
Evaluation/MaxReturn                   -868.594
Evaluation/MinReturn                  -1142.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     82.3899
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41931
GaussianMLPPolicy/KL                      8.30281e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -365.584
GaussianMLPPolicy/LossBefore           -365.708
GaussianMLPPolicy/dLoss                  -0.12384
GaussianMLPValueFunction/LossAfter    21189.5
GaussianMLPValueFunction/LossBefore   21206.5
GaussianMLPValueFunction/dLoss           17.0039
TotalEnvSteps                        648000
-----------------------------------  ----------------
2022-08-17 17:58:23 | [trpo_pendulum] epoch #540 | Saving snapshot...
2022-08-17 17:58:23 | [trpo_pendulum] epoch #540 | Saved
2022-08-17 17:58:23 | [trpo_pendulum] epoch #540 | Time 223.08 s
2022-08-17 17:58:23 | [trpo_pendulum] epoch #540 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -405.789
Evaluation/AverageReturn               -979.268
Evaluation/Iteration                    540
Evaluation/MaxReturn                   -883.782
Evaluation/MinReturn                  -1052.49
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     69.2065
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41972
GaussianMLPPolicy/KL                      0.00012462
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -372.18
GaussianMLPPolicy/LossBefore           -372.036
GaussianMLPPolicy/dLoss                   0.144104
GaussianMLPValueFunction/LossAfter    21581.8
GaussianMLPValueFunction/LossBefore   21599.1
GaussianMLPValueFunction/dLoss           17.2773
TotalEnvSteps                        649200
-----------------------------------  ---------------
2022-08-17 17:58:23 | [trpo_pendulum] epoch #541 | Saving snapshot...
2022-08-17 17:58:23 | [trpo_pendulum] epoch #541 | Saved
2022-08-17 17:58:23 | [trpo_pendulum] epoch #541 | Time 223.49 s
2022-08-17 17:58:23 | [trpo_pendulum] epoch #541 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -425.902
Evaluation/AverageReturn               -969.871
Evaluation/Iteration                    541
Evaluation/MaxReturn                   -871.203
Evaluation/MinReturn                  -1032.35
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     52.5525
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42007
GaussianMLPPolicy/KL                      9.82263e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -358.739
GaussianMLPPolicy/LossBefore           -358.692
GaussianMLPPolicy/dLoss                   0.046814
GaussianMLPValueFunction/LossAfter    19438.8
GaussianMLPValueFunction/LossBefore   19454.2
GaussianMLPValueFunction/dLoss           15.3789
TotalEnvSteps                        650400
-----------------------------------  ----------------
2022-08-17 17:58:24 | [trpo_pendulum] epoch #542 | Saving snapshot...
2022-08-17 17:58:24 | [trpo_pendulum] epoch #542 | Saved
2022-08-17 17:58:24 | [trpo_pendulum] epoch #542 | Time 223.90 s
2022-08-17 17:58:24 | [trpo_pendulum] epoch #542 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -732.151
Evaluation/AverageReturn              -1667.44
Evaluation/Iteration                    542
Evaluation/MaxReturn                  -1515.36
Evaluation/MinReturn                  -1803.34
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    116.846
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42033
GaussianMLPPolicy/KL                      1.29995e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -641.604
GaussianMLPPolicy/LossBefore           -641.583
GaussianMLPPolicy/dLoss                   0.0216675
GaussianMLPValueFunction/LossAfter    60858.7
GaussianMLPValueFunction/LossBefore   60908.3
GaussianMLPValueFunction/dLoss           49.6016
TotalEnvSteps                        651600
-----------------------------------  ----------------
2022-08-17 17:58:24 | [trpo_pendulum] epoch #543 | Saving snapshot...
2022-08-17 17:58:24 | [trpo_pendulum] epoch #543 | Saved
2022-08-17 17:58:24 | [trpo_pendulum] epoch #543 | Time 224.31 s
2022-08-17 17:58:24 | [trpo_pendulum] epoch #543 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -408.623
Evaluation/AverageReturn               -932.65
Evaluation/Iteration                    543
Evaluation/MaxReturn                   -868.485
Evaluation/MinReturn                  -1014.44
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     58.4264
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42055
GaussianMLPPolicy/KL                      2.88166e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -344.449
GaussianMLPPolicy/LossBefore           -344.401
GaussianMLPPolicy/dLoss                   0.0475769
GaussianMLPValueFunction/LossAfter    18060.9
GaussianMLPValueFunction/LossBefore   18076.6
GaussianMLPValueFunction/dLoss           15.7344
TotalEnvSteps                        652800
-----------------------------------  ----------------
2022-08-17 17:58:24 | [trpo_pendulum] epoch #544 | Saving snapshot...
2022-08-17 17:58:24 | [trpo_pendulum] epoch #544 | Saved
2022-08-17 17:58:24 | [trpo_pendulum] epoch #544 | Time 224.73 s
2022-08-17 17:58:24 | [trpo_pendulum] epoch #544 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -422.013
Evaluation/AverageReturn               -955.465
Evaluation/Iteration                    544
Evaluation/MaxReturn                   -846.968
Evaluation/MinReturn                  -1059.43
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     78.3649
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42068
GaussianMLPPolicy/KL                      4.74383e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -355.198
GaussianMLPPolicy/LossBefore           -355.137
GaussianMLPPolicy/dLoss                   0.0613403
GaussianMLPValueFunction/LossAfter    18399.7
GaussianMLPValueFunction/LossBefore   18415.2
GaussianMLPValueFunction/dLoss           15.5547
TotalEnvSteps                        654000
-----------------------------------  ----------------
2022-08-17 17:58:25 | [trpo_pendulum] epoch #545 | Saving snapshot...
2022-08-17 17:58:25 | [trpo_pendulum] epoch #545 | Saved
2022-08-17 17:58:25 | [trpo_pendulum] epoch #545 | Time 225.14 s
2022-08-17 17:58:25 | [trpo_pendulum] epoch #545 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -421.041
Evaluation/AverageReturn               -947.443
Evaluation/Iteration                    545
Evaluation/MaxReturn                   -779.379
Evaluation/MinReturn                  -1116.63
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    119.52
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42072
GaussianMLPPolicy/KL                      2.41707e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -351.367
GaussianMLPPolicy/LossBefore           -351.385
GaussianMLPPolicy/dLoss                  -0.0177307
GaussianMLPValueFunction/LossAfter    18592.7
GaussianMLPValueFunction/LossBefore   18607.9
GaussianMLPValueFunction/dLoss           15.2246
TotalEnvSteps                        655200
-----------------------------------  ----------------
2022-08-17 17:58:25 | [trpo_pendulum] epoch #546 | Saving snapshot...
2022-08-17 17:58:25 | [trpo_pendulum] epoch #546 | Saved
2022-08-17 17:58:25 | [trpo_pendulum] epoch #546 | Time 225.55 s
2022-08-17 17:58:25 | [trpo_pendulum] epoch #546 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -623.018
Evaluation/AverageReturn              -1423.51
Evaluation/Iteration                    546
Evaluation/MaxReturn                  -1319.29
Evaluation/MinReturn                  -1575.39
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     94.2772
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42071
GaussianMLPPolicy/KL                      1.32183e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -544.386
GaussianMLPPolicy/LossBefore           -544.268
GaussianMLPPolicy/dLoss                   0.117737
GaussianMLPValueFunction/LossAfter    44060.6
GaussianMLPValueFunction/LossBefore   44096.4
GaussianMLPValueFunction/dLoss           35.8477
TotalEnvSteps                        656400
-----------------------------------  ----------------
2022-08-17 17:58:26 | [trpo_pendulum] epoch #547 | Saving snapshot...
2022-08-17 17:58:26 | [trpo_pendulum] epoch #547 | Saved
2022-08-17 17:58:26 | [trpo_pendulum] epoch #547 | Time 225.96 s
2022-08-17 17:58:26 | [trpo_pendulum] epoch #547 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -425.755
Evaluation/AverageReturn               -969.165
Evaluation/Iteration                    547
Evaluation/MaxReturn                   -874.064
Evaluation/MinReturn                   -998.093
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     43.2771
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42074
GaussianMLPPolicy/KL                      9.86752e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -353.608
GaussianMLPPolicy/LossBefore           -353.609
GaussianMLPPolicy/dLoss                  -0.00164795
GaussianMLPValueFunction/LossAfter    19137.4
GaussianMLPValueFunction/LossBefore   19153.7
GaussianMLPValueFunction/dLoss           16.3145
TotalEnvSteps                        657600
-----------------------------------  ----------------
2022-08-17 17:58:26 | [trpo_pendulum] epoch #548 | Saving snapshot...
2022-08-17 17:58:26 | [trpo_pendulum] epoch #548 | Saved
2022-08-17 17:58:26 | [trpo_pendulum] epoch #548 | Time 226.39 s
2022-08-17 17:58:26 | [trpo_pendulum] epoch #548 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -417.834
Evaluation/AverageReturn               -942.636
Evaluation/Iteration                    548
Evaluation/MaxReturn                   -867.692
Evaluation/MinReturn                  -1061.53
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     67.1304
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42082
GaussianMLPPolicy/KL                      7.62452e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -338.533
GaussianMLPPolicy/LossBefore           -338.47
GaussianMLPPolicy/dLoss                   0.0627441
GaussianMLPValueFunction/LossAfter    18226
GaussianMLPValueFunction/LossBefore   18241.1
GaussianMLPValueFunction/dLoss           15.1504
TotalEnvSteps                        658800
-----------------------------------  ----------------
2022-08-17 17:58:26 | [trpo_pendulum] epoch #549 | Saving snapshot...
2022-08-17 17:58:26 | [trpo_pendulum] epoch #549 | Saved
2022-08-17 17:58:26 | [trpo_pendulum] epoch #549 | Time 226.80 s
2022-08-17 17:58:26 | [trpo_pendulum] epoch #549 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -448.011
Evaluation/AverageReturn              -1008.21
Evaluation/Iteration                    549
Evaluation/MaxReturn                   -857.919
Evaluation/MinReturn                  -1195.91
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    122.395
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4209
GaussianMLPPolicy/KL                      3.55909e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -367.874
GaussianMLPPolicy/LossBefore           -367.86
GaussianMLPPolicy/dLoss                   0.0143127
GaussianMLPValueFunction/LossAfter    21216.1
GaussianMLPValueFunction/LossBefore   21233.2
GaussianMLPValueFunction/dLoss           17.0859
TotalEnvSteps                        660000
-----------------------------------  ----------------
2022-08-17 17:58:27 | [trpo_pendulum] epoch #550 | Saving snapshot...
2022-08-17 17:58:27 | [trpo_pendulum] epoch #550 | Saved
2022-08-17 17:58:27 | [trpo_pendulum] epoch #550 | Time 227.21 s
2022-08-17 17:58:27 | [trpo_pendulum] epoch #550 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -705.832
Evaluation/AverageReturn              -1585.43
Evaluation/Iteration                    550
Evaluation/MaxReturn                  -1457
Evaluation/MinReturn                  -1785.57
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     98.2395
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42116
GaussianMLPPolicy/KL                      4.72915e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -580.832
GaussianMLPPolicy/LossBefore           -580.774
GaussianMLPPolicy/dLoss                   0.0578613
GaussianMLPValueFunction/LossAfter    53947.7
GaussianMLPValueFunction/LossBefore   53992.5
GaussianMLPValueFunction/dLoss           44.75
TotalEnvSteps                        661200
-----------------------------------  ----------------
2022-08-17 17:58:27 | [trpo_pendulum] epoch #551 | Saving snapshot...
2022-08-17 17:58:27 | [trpo_pendulum] epoch #551 | Saved
2022-08-17 17:58:27 | [trpo_pendulum] epoch #551 | Time 227.62 s
2022-08-17 17:58:27 | [trpo_pendulum] epoch #551 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -508.521
Evaluation/AverageReturn              -1161.53
Evaluation/Iteration                    551
Evaluation/MaxReturn                  -1002.28
Evaluation/MinReturn                  -1307.31
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     96.1511
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42139
GaussianMLPPolicy/KL                      3.12349e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -435.154
GaussianMLPPolicy/LossBefore           -435.047
GaussianMLPPolicy/dLoss                   0.10788
GaussianMLPValueFunction/LossAfter    28552.7
GaussianMLPValueFunction/LossBefore   28577.5
GaussianMLPValueFunction/dLoss           24.7988
TotalEnvSteps                        662400
-----------------------------------  ----------------
2022-08-17 17:58:28 | [trpo_pendulum] epoch #552 | Saving snapshot...
2022-08-17 17:58:28 | [trpo_pendulum] epoch #552 | Saved
2022-08-17 17:58:28 | [trpo_pendulum] epoch #552 | Time 228.03 s
2022-08-17 17:58:28 | [trpo_pendulum] epoch #552 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -389.925
Evaluation/AverageReturn               -895.416
Evaluation/Iteration                    552
Evaluation/MaxReturn                   -752.479
Evaluation/MinReturn                  -1009.07
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     88.8211
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42164
GaussianMLPPolicy/KL                      0.000104637
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -325.805
GaussianMLPPolicy/LossBefore           -325.625
GaussianMLPPolicy/dLoss                   0.180145
GaussianMLPValueFunction/LossAfter    16984.5
GaussianMLPValueFunction/LossBefore   16999.5
GaussianMLPValueFunction/dLoss           14.9707
TotalEnvSteps                        663600
-----------------------------------  ----------------
2022-08-17 17:58:28 | [trpo_pendulum] epoch #553 | Saving snapshot...
2022-08-17 17:58:28 | [trpo_pendulum] epoch #553 | Saved
2022-08-17 17:58:28 | [trpo_pendulum] epoch #553 | Time 228.46 s
2022-08-17 17:58:28 | [trpo_pendulum] epoch #553 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -378.405
Evaluation/AverageReturn               -911.438
Evaluation/Iteration                    553
Evaluation/MaxReturn                   -886.116
Evaluation/MinReturn                   -958.876
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     25.0161
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42184
GaussianMLPPolicy/KL                      0.000124025
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -351.375
GaussianMLPPolicy/LossBefore           -351.291
GaussianMLPPolicy/dLoss                   0.0836487
GaussianMLPValueFunction/LossAfter    18570.3
GaussianMLPValueFunction/LossBefore   18586.2
GaussianMLPValueFunction/dLoss           15.9023
TotalEnvSteps                        664800
-----------------------------------  ----------------
2022-08-17 17:58:29 | [trpo_pendulum] epoch #554 | Saving snapshot...
2022-08-17 17:58:29 | [trpo_pendulum] epoch #554 | Saved
2022-08-17 17:58:29 | [trpo_pendulum] epoch #554 | Time 228.87 s
2022-08-17 17:58:29 | [trpo_pendulum] epoch #554 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -586.417
Evaluation/AverageReturn              -1304.98
Evaluation/Iteration                    554
Evaluation/MaxReturn                  -1179.35
Evaluation/MinReturn                  -1409.65
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     88.6578
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42214
GaussianMLPPolicy/KL                      5.2925e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -471.835
GaussianMLPPolicy/LossBefore           -471.854
GaussianMLPPolicy/dLoss                  -0.0187988
GaussianMLPValueFunction/LossAfter    35361.4
GaussianMLPValueFunction/LossBefore   35390.6
GaussianMLPValueFunction/dLoss           29.2344
TotalEnvSteps                        666000
-----------------------------------  ---------------
2022-08-17 17:58:29 | [trpo_pendulum] epoch #555 | Saving snapshot...
2022-08-17 17:58:29 | [trpo_pendulum] epoch #555 | Saved
2022-08-17 17:58:29 | [trpo_pendulum] epoch #555 | Time 229.27 s
2022-08-17 17:58:29 | [trpo_pendulum] epoch #555 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -525.047
Evaluation/AverageReturn              -1152.57
Evaluation/Iteration                    555
Evaluation/MaxReturn                  -1079.45
Evaluation/MinReturn                  -1293.07
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     74.1022
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42245
GaussianMLPPolicy/KL                      6.38276e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -413.367
GaussianMLPPolicy/LossBefore           -413.307
GaussianMLPPolicy/dLoss                   0.0603638
GaussianMLPValueFunction/LossAfter    26931.6
GaussianMLPValueFunction/LossBefore   26954.4
GaussianMLPValueFunction/dLoss           22.7188
TotalEnvSteps                        667200
-----------------------------------  ----------------
2022-08-17 17:58:29 | [trpo_pendulum] epoch #556 | Saving snapshot...
2022-08-17 17:58:29 | [trpo_pendulum] epoch #556 | Saved
2022-08-17 17:58:29 | [trpo_pendulum] epoch #556 | Time 229.68 s
2022-08-17 17:58:29 | [trpo_pendulum] epoch #556 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -383.479
Evaluation/AverageReturn               -910.942
Evaluation/Iteration                    556
Evaluation/MaxReturn                   -750.35
Evaluation/MinReturn                  -1043.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     96.637
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42282
GaussianMLPPolicy/KL                      0.000103777
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -337.706
GaussianMLPPolicy/LossBefore           -337.591
GaussianMLPPolicy/dLoss                   0.114441
GaussianMLPValueFunction/LossAfter    18222.1
GaussianMLPValueFunction/LossBefore   18237.6
GaussianMLPValueFunction/dLoss           15.5762
TotalEnvSteps                        668400
-----------------------------------  ----------------
2022-08-17 17:58:30 | [trpo_pendulum] epoch #557 | Saving snapshot...
2022-08-17 17:58:30 | [trpo_pendulum] epoch #557 | Saved
2022-08-17 17:58:30 | [trpo_pendulum] epoch #557 | Time 230.09 s
2022-08-17 17:58:30 | [trpo_pendulum] epoch #557 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -419.394
Evaluation/AverageReturn               -977.068
Evaluation/Iteration                    557
Evaluation/MaxReturn                   -865.962
Evaluation/MinReturn                  -1178.94
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    123.119
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42314
GaussianMLPPolicy/KL                      0.000333715
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -368.296
GaussianMLPPolicy/LossBefore           -367.722
GaussianMLPPolicy/dLoss                   0.574371
GaussianMLPValueFunction/LossAfter    20169
GaussianMLPValueFunction/LossBefore   20185.8
GaussianMLPValueFunction/dLoss           16.748
TotalEnvSteps                        669600
-----------------------------------  ----------------
2022-08-17 17:58:30 | [trpo_pendulum] epoch #558 | Saving snapshot...
2022-08-17 17:58:30 | [trpo_pendulum] epoch #558 | Saved
2022-08-17 17:58:30 | [trpo_pendulum] epoch #558 | Time 230.50 s
2022-08-17 17:58:30 | [trpo_pendulum] epoch #558 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -741.431
Evaluation/AverageReturn              -1653.89
Evaluation/Iteration                    558
Evaluation/MaxReturn                  -1456.33
Evaluation/MinReturn                  -1866
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    153.132
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42323
GaussianMLPPolicy/KL                      0.000124357
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -639.682
GaussianMLPPolicy/LossBefore           -639.484
GaussianMLPPolicy/dLoss                   0.197876
GaussianMLPValueFunction/LossAfter    58326.7
GaussianMLPValueFunction/LossBefore   58376.5
GaussianMLPValueFunction/dLoss           49.8594
TotalEnvSteps                        670800
-----------------------------------  ----------------
2022-08-17 17:58:31 | [trpo_pendulum] epoch #559 | Saving snapshot...
2022-08-17 17:58:31 | [trpo_pendulum] epoch #559 | Saved
2022-08-17 17:58:31 | [trpo_pendulum] epoch #559 | Time 230.91 s
2022-08-17 17:58:31 | [trpo_pendulum] epoch #559 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -703.094
Evaluation/AverageReturn              -1551.19
Evaluation/Iteration                    559
Evaluation/MaxReturn                  -1393.2
Evaluation/MinReturn                  -1746.23
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    126.857
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42318
GaussianMLPPolicy/KL                      0.000107384
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -585.563
GaussianMLPPolicy/LossBefore           -585.598
GaussianMLPPolicy/dLoss                  -0.0351562
GaussianMLPValueFunction/LossAfter    50089.8
GaussianMLPValueFunction/LossBefore   50136
GaussianMLPValueFunction/dLoss           46.1836
TotalEnvSteps                        672000
-----------------------------------  ----------------
2022-08-17 17:58:31 | [trpo_pendulum] epoch #560 | Saving snapshot...
2022-08-17 17:58:31 | [trpo_pendulum] epoch #560 | Saved
2022-08-17 17:58:31 | [trpo_pendulum] epoch #560 | Time 231.31 s
2022-08-17 17:58:31 | [trpo_pendulum] epoch #560 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -503.213
Evaluation/AverageReturn              -1095.18
Evaluation/Iteration                    560
Evaluation/MaxReturn                   -980.19
Evaluation/MinReturn                  -1181.91
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     64.6136
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42317
GaussianMLPPolicy/KL                      0.000152924
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -389.326
GaussianMLPPolicy/LossBefore           -389.265
GaussianMLPPolicy/dLoss                   0.0607605
GaussianMLPValueFunction/LossAfter    23666.1
GaussianMLPValueFunction/LossBefore   23688.5
GaussianMLPValueFunction/dLoss           22.4219
TotalEnvSteps                        673200
-----------------------------------  ----------------
2022-08-17 17:58:31 | [trpo_pendulum] epoch #561 | Saving snapshot...
2022-08-17 17:58:31 | [trpo_pendulum] epoch #561 | Saved
2022-08-17 17:58:31 | [trpo_pendulum] epoch #561 | Time 231.73 s
2022-08-17 17:58:31 | [trpo_pendulum] epoch #561 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -687.666
Evaluation/AverageReturn              -1522.98
Evaluation/Iteration                    561
Evaluation/MaxReturn                  -1438.72
Evaluation/MinReturn                  -1580.93
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.6698
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42317
GaussianMLPPolicy/KL                      0.000190632
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -564.971
GaussianMLPPolicy/LossBefore           -564.492
GaussianMLPPolicy/dLoss                   0.479065
GaussianMLPValueFunction/LossAfter    47954.5
GaussianMLPValueFunction/LossBefore   48000.3
GaussianMLPValueFunction/dLoss           45.8555
TotalEnvSteps                        674400
-----------------------------------  ----------------
2022-08-17 17:58:32 | [trpo_pendulum] epoch #562 | Saving snapshot...
2022-08-17 17:58:32 | [trpo_pendulum] epoch #562 | Saved
2022-08-17 17:58:32 | [trpo_pendulum] epoch #562 | Time 232.13 s
2022-08-17 17:58:32 | [trpo_pendulum] epoch #562 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -475.079
Evaluation/AverageReturn              -1072.01
Evaluation/Iteration                    562
Evaluation/MaxReturn                   -955.754
Evaluation/MinReturn                  -1121.14
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     54.6356
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42304
GaussianMLPPolicy/KL                      0.000275923
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -407.589
GaussianMLPPolicy/LossBefore           -407.453
GaussianMLPPolicy/dLoss                   0.135925
GaussianMLPValueFunction/LossAfter    22859.5
GaussianMLPValueFunction/LossBefore   22882
GaussianMLPValueFunction/dLoss           22.457
TotalEnvSteps                        675600
-----------------------------------  ----------------
2022-08-17 17:58:32 | [trpo_pendulum] epoch #563 | Saving snapshot...
2022-08-17 17:58:32 | [trpo_pendulum] epoch #563 | Saved
2022-08-17 17:58:32 | [trpo_pendulum] epoch #563 | Time 232.54 s
2022-08-17 17:58:32 | [trpo_pendulum] epoch #563 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -469.204
Evaluation/AverageReturn              -1062.7
Evaluation/Iteration                    563
Evaluation/MaxReturn                   -911.623
Evaluation/MinReturn                  -1158.01
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     83.057
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42292
GaussianMLPPolicy/KL                      4.82302e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -391.867
GaussianMLPPolicy/LossBefore           -392.012
GaussianMLPPolicy/dLoss                  -0.14505
GaussianMLPValueFunction/LossAfter    23083.4
GaussianMLPValueFunction/LossBefore   23105.7
GaussianMLPValueFunction/dLoss           22.2246
TotalEnvSteps                        676800
-----------------------------------  ----------------
2022-08-17 17:58:33 | [trpo_pendulum] epoch #564 | Saving snapshot...
2022-08-17 17:58:33 | [trpo_pendulum] epoch #564 | Saved
2022-08-17 17:58:33 | [trpo_pendulum] epoch #564 | Time 232.96 s
2022-08-17 17:58:33 | [trpo_pendulum] epoch #564 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -575.558
Evaluation/AverageReturn              -1235.24
Evaluation/Iteration                    564
Evaluation/MaxReturn                  -1115.02
Evaluation/MinReturn                  -1417.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    106.292
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42285
GaussianMLPPolicy/KL                      5.34779e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -437.163
GaussianMLPPolicy/LossBefore           -437.203
GaussianMLPPolicy/dLoss                  -0.0402832
GaussianMLPValueFunction/LossAfter    30241.9
GaussianMLPValueFunction/LossBefore   30270.1
GaussianMLPValueFunction/dLoss           28.25
TotalEnvSteps                        678000
-----------------------------------  ----------------
2022-08-17 17:58:33 | [trpo_pendulum] epoch #565 | Saving snapshot...
2022-08-17 17:58:33 | [trpo_pendulum] epoch #565 | Saved
2022-08-17 17:58:33 | [trpo_pendulum] epoch #565 | Time 233.37 s
2022-08-17 17:58:33 | [trpo_pendulum] epoch #565 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -684.816
Evaluation/AverageReturn              -1513.18
Evaluation/Iteration                    565
Evaluation/MaxReturn                  -1264.98
Evaluation/MinReturn                  -1718.31
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    151.793
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42294
GaussianMLPPolicy/KL                      0.000109729
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -548.464
GaussianMLPPolicy/LossBefore           -547.799
GaussianMLPPolicy/dLoss                   0.665344
GaussianMLPValueFunction/LossAfter    48110.3
GaussianMLPValueFunction/LossBefore   48156.5
GaussianMLPValueFunction/dLoss           46.1914
TotalEnvSteps                        679200
-----------------------------------  ----------------
2022-08-17 17:58:33 | [trpo_pendulum] epoch #566 | Saving snapshot...
2022-08-17 17:58:33 | [trpo_pendulum] epoch #566 | Saved
2022-08-17 17:58:33 | [trpo_pendulum] epoch #566 | Time 233.77 s
2022-08-17 17:58:33 | [trpo_pendulum] epoch #566 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -451.725
Evaluation/AverageReturn              -1051.73
Evaluation/Iteration                    566
Evaluation/MaxReturn                  -1021.01
Evaluation/MinReturn                  -1127.97
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     37.1782
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42302
GaussianMLPPolicy/KL                      0.000193995
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -396.807
GaussianMLPPolicy/LossBefore           -396.616
GaussianMLPPolicy/dLoss                   0.190918
GaussianMLPValueFunction/LossAfter    23169
GaussianMLPValueFunction/LossBefore   23192
GaussianMLPValueFunction/dLoss           22.9863
TotalEnvSteps                        680400
-----------------------------------  ----------------
2022-08-17 17:58:34 | [trpo_pendulum] epoch #567 | Saving snapshot...
2022-08-17 17:58:34 | [trpo_pendulum] epoch #567 | Saved
2022-08-17 17:58:34 | [trpo_pendulum] epoch #567 | Time 234.18 s
2022-08-17 17:58:34 | [trpo_pendulum] epoch #567 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -583.57
Evaluation/AverageReturn              -1245.29
Evaluation/Iteration                    567
Evaluation/MaxReturn                  -1170.92
Evaluation/MinReturn                  -1339.24
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     62.4029
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42315
GaussianMLPPolicy/KL                      0.000106636
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -437.091
GaussianMLPPolicy/LossBefore           -437.086
GaussianMLPPolicy/dLoss                   0.00448608
GaussianMLPValueFunction/LossAfter    30388.3
GaussianMLPValueFunction/LossBefore   30417.5
GaussianMLPValueFunction/dLoss           29.1582
TotalEnvSteps                        681600
-----------------------------------  ----------------
2022-08-17 17:58:34 | [trpo_pendulum] epoch #568 | Saving snapshot...
2022-08-17 17:58:34 | [trpo_pendulum] epoch #568 | Saved
2022-08-17 17:58:34 | [trpo_pendulum] epoch #568 | Time 234.59 s
2022-08-17 17:58:34 | [trpo_pendulum] epoch #568 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -465.265
Evaluation/AverageReturn              -1090.49
Evaluation/Iteration                    568
Evaluation/MaxReturn                  -1012.98
Evaluation/MinReturn                  -1173.79
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     58.0298
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4232
GaussianMLPPolicy/KL                      2.3515e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -420.382
GaussianMLPPolicy/LossBefore           -420.387
GaussianMLPPolicy/dLoss                  -0.00512695
GaussianMLPValueFunction/LossAfter    25581.8
GaussianMLPValueFunction/LossBefore   25606.4
GaussianMLPValueFunction/dLoss           24.6191
TotalEnvSteps                        682800
-----------------------------------  ---------------
2022-08-17 17:58:35 | [trpo_pendulum] epoch #569 | Saving snapshot...
2022-08-17 17:58:35 | [trpo_pendulum] epoch #569 | Saved
2022-08-17 17:58:35 | [trpo_pendulum] epoch #569 | Time 235.00 s
2022-08-17 17:58:35 | [trpo_pendulum] epoch #569 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -453.421
Evaluation/AverageReturn              -1044.19
Evaluation/Iteration                    569
Evaluation/MaxReturn                   -890.465
Evaluation/MinReturn                  -1164.81
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     90.7455
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42325
GaussianMLPPolicy/KL                      0.000147766
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -390.609
GaussianMLPPolicy/LossBefore           -390.313
GaussianMLPPolicy/dLoss                   0.296051
GaussianMLPValueFunction/LossAfter    22506.5
GaussianMLPValueFunction/LossBefore   22527.9
GaussianMLPValueFunction/dLoss           21.4043
TotalEnvSteps                        684000
-----------------------------------  ----------------
2022-08-17 17:58:35 | [trpo_pendulum] epoch #570 | Saving snapshot...
2022-08-17 17:58:35 | [trpo_pendulum] epoch #570 | Saved
2022-08-17 17:58:35 | [trpo_pendulum] epoch #570 | Time 235.41 s
2022-08-17 17:58:35 | [trpo_pendulum] epoch #570 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -466.852
Evaluation/AverageReturn              -1063.08
Evaluation/Iteration                    570
Evaluation/MaxReturn                   -959.9
Evaluation/MinReturn                  -1160.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     75.5441
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42318
GaussianMLPPolicy/KL                      0.000171019
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -404.072
GaussianMLPPolicy/LossBefore           -403.917
GaussianMLPPolicy/dLoss                   0.155457
GaussianMLPValueFunction/LossAfter    22800.8
GaussianMLPValueFunction/LossBefore   22822
GaussianMLPValueFunction/dLoss           21.2793
TotalEnvSteps                        685200
-----------------------------------  ----------------
2022-08-17 17:58:35 | [trpo_pendulum] epoch #571 | Saving snapshot...
2022-08-17 17:58:35 | [trpo_pendulum] epoch #571 | Saved
2022-08-17 17:58:35 | [trpo_pendulum] epoch #571 | Time 235.82 s
2022-08-17 17:58:35 | [trpo_pendulum] epoch #571 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -500.589
Evaluation/AverageReturn              -1116.9
Evaluation/Iteration                    571
Evaluation/MaxReturn                  -1080.21
Evaluation/MinReturn                  -1137.57
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     20.6734
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42317
GaussianMLPPolicy/KL                      0.000198007
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -405.28
GaussianMLPPolicy/LossBefore           -405.073
GaussianMLPPolicy/dLoss                   0.206757
GaussianMLPValueFunction/LossAfter    24672.3
GaussianMLPValueFunction/LossBefore   24694.8
GaussianMLPValueFunction/dLoss           22.459
TotalEnvSteps                        686400
-----------------------------------  ----------------
2022-08-17 17:58:36 | [trpo_pendulum] epoch #572 | Saving snapshot...
2022-08-17 17:58:36 | [trpo_pendulum] epoch #572 | Saved
2022-08-17 17:58:36 | [trpo_pendulum] epoch #572 | Time 236.23 s
2022-08-17 17:58:36 | [trpo_pendulum] epoch #572 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -456.144
Evaluation/AverageReturn              -1108.65
Evaluation/Iteration                    572
Evaluation/MaxReturn                  -1007.05
Evaluation/MinReturn                  -1244.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     80.683
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4231
GaussianMLPPolicy/KL                      0.000140906
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -439.016
GaussianMLPPolicy/LossBefore           -439.019
GaussianMLPPolicy/dLoss                  -0.00311279
GaussianMLPValueFunction/LossAfter    26904.6
GaussianMLPValueFunction/LossBefore   26929.1
GaussianMLPValueFunction/dLoss           24.5078
TotalEnvSteps                        687600
-----------------------------------  ----------------
2022-08-17 17:58:36 | [trpo_pendulum] epoch #573 | Saving snapshot...
2022-08-17 17:58:36 | [trpo_pendulum] epoch #573 | Saved
2022-08-17 17:58:36 | [trpo_pendulum] epoch #573 | Time 236.64 s
2022-08-17 17:58:36 | [trpo_pendulum] epoch #573 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -473.267
Evaluation/AverageReturn              -1103.68
Evaluation/Iteration                    573
Evaluation/MaxReturn                  -1019.04
Evaluation/MinReturn                  -1168.14
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     54.1132
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42299
GaussianMLPPolicy/KL                      1.98839e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -422.423
GaussianMLPPolicy/LossBefore           -422.429
GaussianMLPPolicy/dLoss                  -0.00640869
GaussianMLPValueFunction/LossAfter    25750.3
GaussianMLPValueFunction/LossBefore   25773.6
GaussianMLPValueFunction/dLoss           23.3438
TotalEnvSteps                        688800
-----------------------------------  ----------------
2022-08-17 17:58:37 | [trpo_pendulum] epoch #574 | Saving snapshot...
2022-08-17 17:58:37 | [trpo_pendulum] epoch #574 | Saved
2022-08-17 17:58:37 | [trpo_pendulum] epoch #574 | Time 237.05 s
2022-08-17 17:58:37 | [trpo_pendulum] epoch #574 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -450.891
Evaluation/AverageReturn              -1074.63
Evaluation/Iteration                    574
Evaluation/MaxReturn                  -1035.3
Evaluation/MinReturn                  -1162.37
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     45.4668
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42293
GaussianMLPPolicy/KL                      1.98367e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -411.129
GaussianMLPPolicy/LossBefore           -411.064
GaussianMLPPolicy/dLoss                   0.0653687
GaussianMLPValueFunction/LossAfter    25069.2
GaussianMLPValueFunction/LossBefore   25092.3
GaussianMLPValueFunction/dLoss           23.0898
TotalEnvSteps                        690000
-----------------------------------  ----------------
2022-08-17 17:58:37 | [trpo_pendulum] epoch #575 | Saving snapshot...
2022-08-17 17:58:37 | [trpo_pendulum] epoch #575 | Saved
2022-08-17 17:58:37 | [trpo_pendulum] epoch #575 | Time 237.46 s
2022-08-17 17:58:37 | [trpo_pendulum] epoch #575 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -640.723
Evaluation/AverageReturn              -1356.79
Evaluation/Iteration                    575
Evaluation/MaxReturn                  -1231.74
Evaluation/MinReturn                  -1799.91
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    201.342
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42284
GaussianMLPPolicy/KL                      3.10268e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -483.662
GaussianMLPPolicy/LossBefore           -483.605
GaussianMLPPolicy/dLoss                   0.0570679
GaussianMLPValueFunction/LossAfter    36743.6
GaussianMLPValueFunction/LossBefore   36776.2
GaussianMLPValueFunction/dLoss           32.5898
TotalEnvSteps                        691200
-----------------------------------  ----------------
2022-08-17 17:58:38 | [trpo_pendulum] epoch #576 | Saving snapshot...
2022-08-17 17:58:38 | [trpo_pendulum] epoch #576 | Saved
2022-08-17 17:58:38 | [trpo_pendulum] epoch #576 | Time 237.88 s
2022-08-17 17:58:38 | [trpo_pendulum] epoch #576 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -679.945
Evaluation/AverageReturn              -1459.77
Evaluation/Iteration                    576
Evaluation/MaxReturn                  -1278.61
Evaluation/MinReturn                  -1806.13
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    180.072
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42272
GaussianMLPPolicy/KL                      8.52019e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -529.536
GaussianMLPPolicy/LossBefore           -529.537
GaussianMLPPolicy/dLoss                  -0.00146484
GaussianMLPValueFunction/LossAfter    43214.4
GaussianMLPValueFunction/LossBefore   43254.2
GaussianMLPValueFunction/dLoss           39.7695
TotalEnvSteps                        692400
-----------------------------------  ----------------
2022-08-17 17:58:38 | [trpo_pendulum] epoch #577 | Saving snapshot...
2022-08-17 17:58:38 | [trpo_pendulum] epoch #577 | Saved
2022-08-17 17:58:38 | [trpo_pendulum] epoch #577 | Time 238.29 s
2022-08-17 17:58:38 | [trpo_pendulum] epoch #577 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -465.816
Evaluation/AverageReturn              -1122.54
Evaluation/Iteration                    577
Evaluation/MaxReturn                  -1045.51
Evaluation/MinReturn                  -1168.56
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     46.7136
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42254
GaussianMLPPolicy/KL                      3.63058e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -442.688
GaussianMLPPolicy/LossBefore           -442.685
GaussianMLPPolicy/dLoss                   0.00308228
GaussianMLPValueFunction/LossAfter    27341.1
GaussianMLPValueFunction/LossBefore   27367.1
GaussianMLPValueFunction/dLoss           26.0293
TotalEnvSteps                        693600
-----------------------------------  ----------------
2022-08-17 17:58:38 | [trpo_pendulum] epoch #578 | Saving snapshot...
2022-08-17 17:58:38 | [trpo_pendulum] epoch #578 | Saved
2022-08-17 17:58:38 | [trpo_pendulum] epoch #578 | Time 238.71 s
2022-08-17 17:58:38 | [trpo_pendulum] epoch #578 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -452.841
Evaluation/AverageReturn              -1079.39
Evaluation/Iteration                    578
Evaluation/MaxReturn                  -1032.89
Evaluation/MinReturn                  -1166.63
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     45.2915
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42245
GaussianMLPPolicy/KL                      1.22231e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -409.607
GaussianMLPPolicy/LossBefore           -409.57
GaussianMLPPolicy/dLoss                   0.0368958
GaussianMLPValueFunction/LossAfter    25454
GaussianMLPValueFunction/LossBefore   25478
GaussianMLPValueFunction/dLoss           24.0039
TotalEnvSteps                        694800
-----------------------------------  ----------------
2022-08-17 17:58:39 | [trpo_pendulum] epoch #579 | Saving snapshot...
2022-08-17 17:58:39 | [trpo_pendulum] epoch #579 | Saved
2022-08-17 17:58:39 | [trpo_pendulum] epoch #579 | Time 239.13 s
2022-08-17 17:58:39 | [trpo_pendulum] epoch #579 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -444.491
Evaluation/AverageReturn              -1053.32
Evaluation/Iteration                    579
Evaluation/MaxReturn                  -1022.8
Evaluation/MinReturn                  -1114.21
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     33.1658
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42236
GaussianMLPPolicy/KL                      9.50385e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -402.921
GaussianMLPPolicy/LossBefore           -402.682
GaussianMLPPolicy/dLoss                   0.239105
GaussianMLPValueFunction/LossAfter    23382.4
GaussianMLPValueFunction/LossBefore   23404.5
GaussianMLPValueFunction/dLoss           22.0723
TotalEnvSteps                        696000
-----------------------------------  ----------------
2022-08-17 17:58:39 | [trpo_pendulum] epoch #580 | Saving snapshot...
2022-08-17 17:58:39 | [trpo_pendulum] epoch #580 | Saved
2022-08-17 17:58:39 | [trpo_pendulum] epoch #580 | Time 239.55 s
2022-08-17 17:58:39 | [trpo_pendulum] epoch #580 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -552.759
Evaluation/AverageReturn              -1214.98
Evaluation/Iteration                    580
Evaluation/MaxReturn                  -1185.17
Evaluation/MinReturn                  -1264.85
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     29.5599
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42227
GaussianMLPPolicy/KL                      8.19136e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -443.128
GaussianMLPPolicy/LossBefore           -443.112
GaussianMLPPolicy/dLoss                   0.0160522
GaussianMLPValueFunction/LossAfter    28214.9
GaussianMLPValueFunction/LossBefore   28240.7
GaussianMLPValueFunction/dLoss           25.8027
TotalEnvSteps                        697200
-----------------------------------  ----------------
2022-08-17 17:58:40 | [trpo_pendulum] epoch #581 | Saving snapshot...
2022-08-17 17:58:40 | [trpo_pendulum] epoch #581 | Saved
2022-08-17 17:58:40 | [trpo_pendulum] epoch #581 | Time 239.95 s
2022-08-17 17:58:40 | [trpo_pendulum] epoch #581 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -500.449
Evaluation/AverageReturn              -1107.28
Evaluation/Iteration                    581
Evaluation/MaxReturn                  -1004.42
Evaluation/MinReturn                  -1142.23
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     47.3072
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42212
GaussianMLPPolicy/KL                      6.73165e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -407.232
GaussianMLPPolicy/LossBefore           -407.063
GaussianMLPPolicy/dLoss                   0.168884
GaussianMLPValueFunction/LossAfter    23994.3
GaussianMLPValueFunction/LossBefore   24016.2
GaussianMLPValueFunction/dLoss           21.9102
TotalEnvSteps                        698400
-----------------------------------  ----------------
2022-08-17 17:58:40 | [trpo_pendulum] epoch #582 | Saving snapshot...
2022-08-17 17:58:40 | [trpo_pendulum] epoch #582 | Saved
2022-08-17 17:58:40 | [trpo_pendulum] epoch #582 | Time 240.36 s
2022-08-17 17:58:40 | [trpo_pendulum] epoch #582 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -462.417
Evaluation/AverageReturn              -1119.85
Evaluation/Iteration                    582
Evaluation/MaxReturn                  -1036.96
Evaluation/MinReturn                  -1193.51
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     60.5129
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4219
GaussianMLPPolicy/KL                      1.43578e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -443.614
GaussianMLPPolicy/LossBefore           -443.655
GaussianMLPPolicy/dLoss                  -0.0411072
GaussianMLPValueFunction/LossAfter    27361.8
GaussianMLPValueFunction/LossBefore   27386.5
GaussianMLPValueFunction/dLoss           24.7793
TotalEnvSteps                        699600
-----------------------------------  ----------------
2022-08-17 17:58:40 | [trpo_pendulum] epoch #583 | Saving snapshot...
2022-08-17 17:58:40 | [trpo_pendulum] epoch #583 | Saved
2022-08-17 17:58:40 | [trpo_pendulum] epoch #583 | Time 240.77 s
2022-08-17 17:58:40 | [trpo_pendulum] epoch #583 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -501.8
Evaluation/AverageReturn              -1089.28
Evaluation/Iteration                    583
Evaluation/MaxReturn                  -1000.24
Evaluation/MinReturn                  -1202.54
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     59.7605
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42177
GaussianMLPPolicy/KL                      9.98174e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -382.861
GaussianMLPPolicy/LossBefore           -382.609
GaussianMLPPolicy/dLoss                   0.252441
GaussianMLPValueFunction/LossAfter    22488.5
GaussianMLPValueFunction/LossBefore   22508.7
GaussianMLPValueFunction/dLoss           20.1973
TotalEnvSteps                        700800
-----------------------------------  ----------------
2022-08-17 17:58:41 | [trpo_pendulum] epoch #584 | Saving snapshot...
2022-08-17 17:58:41 | [trpo_pendulum] epoch #584 | Saved
2022-08-17 17:58:41 | [trpo_pendulum] epoch #584 | Time 241.19 s
2022-08-17 17:58:41 | [trpo_pendulum] epoch #584 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -510.788
Evaluation/AverageReturn              -1136.06
Evaluation/Iteration                    584
Evaluation/MaxReturn                  -1099.37
Evaluation/MinReturn                  -1168.05
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     22.7675
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42175
GaussianMLPPolicy/KL                      1.30926e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -405.889
GaussianMLPPolicy/LossBefore           -405.924
GaussianMLPPolicy/dLoss                  -0.0350952
GaussianMLPValueFunction/LossAfter    25365.6
GaussianMLPValueFunction/LossBefore   25388
GaussianMLPValueFunction/dLoss           22.4297
TotalEnvSteps                        702000
-----------------------------------  ----------------
2022-08-17 17:58:41 | [trpo_pendulum] epoch #585 | Saving snapshot...
2022-08-17 17:58:41 | [trpo_pendulum] epoch #585 | Saved
2022-08-17 17:58:41 | [trpo_pendulum] epoch #585 | Time 241.60 s
2022-08-17 17:58:41 | [trpo_pendulum] epoch #585 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -566.178
Evaluation/AverageReturn              -1216.72
Evaluation/Iteration                    585
Evaluation/MaxReturn                  -1126.87
Evaluation/MinReturn                  -1316.45
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     76.6277
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42166
GaussianMLPPolicy/KL                      8.83543e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -438.553
GaussianMLPPolicy/LossBefore           -438.469
GaussianMLPPolicy/dLoss                   0.0843811
GaussianMLPValueFunction/LossAfter    28187.8
GaussianMLPValueFunction/LossBefore   28212.5
GaussianMLPValueFunction/dLoss           24.752
TotalEnvSteps                        703200
-----------------------------------  ----------------
2022-08-17 17:58:42 | [trpo_pendulum] epoch #586 | Saving snapshot...
2022-08-17 17:58:42 | [trpo_pendulum] epoch #586 | Saved
2022-08-17 17:58:42 | [trpo_pendulum] epoch #586 | Time 242.01 s
2022-08-17 17:58:42 | [trpo_pendulum] epoch #586 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -515.818
Evaluation/AverageReturn              -1137.43
Evaluation/Iteration                    586
Evaluation/MaxReturn                  -1102.8
Evaluation/MinReturn                  -1179.24
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     30.1973
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42144
GaussianMLPPolicy/KL                      5.83441e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -423.444
GaussianMLPPolicy/LossBefore           -423.327
GaussianMLPPolicy/dLoss                   0.116913
GaussianMLPValueFunction/LossAfter    24363.8
GaussianMLPValueFunction/LossBefore   24385.3
GaussianMLPValueFunction/dLoss           21.5078
TotalEnvSteps                        704400
-----------------------------------  ----------------
2022-08-17 17:58:42 | [trpo_pendulum] epoch #587 | Saving snapshot...
2022-08-17 17:58:42 | [trpo_pendulum] epoch #587 | Saved
2022-08-17 17:58:42 | [trpo_pendulum] epoch #587 | Time 242.42 s
2022-08-17 17:58:42 | [trpo_pendulum] epoch #587 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -428.119
Evaluation/AverageReturn              -1114.71
Evaluation/Iteration                    587
Evaluation/MaxReturn                  -1052.48
Evaluation/MinReturn                  -1174.23
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     45.7266
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42117
GaussianMLPPolicy/KL                      3.73387e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -464.24
GaussianMLPPolicy/LossBefore           -464.204
GaussianMLPPolicy/dLoss                   0.0367126
GaussianMLPValueFunction/LossAfter    30388.1
GaussianMLPValueFunction/LossBefore   30414.9
GaussianMLPValueFunction/dLoss           26.8613
TotalEnvSteps                        705600
-----------------------------------  ----------------
2022-08-17 17:58:42 | [trpo_pendulum] epoch #588 | Saving snapshot...
2022-08-17 17:58:42 | [trpo_pendulum] epoch #588 | Saved
2022-08-17 17:58:42 | [trpo_pendulum] epoch #588 | Time 242.82 s
2022-08-17 17:58:42 | [trpo_pendulum] epoch #588 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -539.393
Evaluation/AverageReturn              -1198.18
Evaluation/Iteration                    588
Evaluation/MaxReturn                  -1136.18
Evaluation/MinReturn                  -1227.43
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     36.2497
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42103
GaussianMLPPolicy/KL                      2.60819e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -428.682
GaussianMLPPolicy/LossBefore           -428.66
GaussianMLPPolicy/dLoss                   0.0228577
GaussianMLPValueFunction/LossAfter    27828
GaussianMLPValueFunction/LossBefore   27852.6
GaussianMLPValueFunction/dLoss           24.623
TotalEnvSteps                        706800
-----------------------------------  ----------------
2022-08-17 17:58:43 | [trpo_pendulum] epoch #589 | Saving snapshot...
2022-08-17 17:58:43 | [trpo_pendulum] epoch #589 | Saved
2022-08-17 17:58:43 | [trpo_pendulum] epoch #589 | Time 243.24 s
2022-08-17 17:58:43 | [trpo_pendulum] epoch #589 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -465.182
Evaluation/AverageReturn              -1119.58
Evaluation/Iteration                    589
Evaluation/MaxReturn                  -1037.59
Evaluation/MinReturn                  -1173.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     45.0752
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42094
GaussianMLPPolicy/KL                      1.61396e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -431.607
GaussianMLPPolicy/LossBefore           -431.589
GaussianMLPPolicy/dLoss                   0.0185852
GaussianMLPValueFunction/LossAfter    26810.4
GaussianMLPValueFunction/LossBefore   26834.3
GaussianMLPValueFunction/dLoss           23.9316
TotalEnvSteps                        708000
-----------------------------------  ----------------
2022-08-17 17:58:43 | [trpo_pendulum] epoch #590 | Saving snapshot...
2022-08-17 17:58:43 | [trpo_pendulum] epoch #590 | Saved
2022-08-17 17:58:43 | [trpo_pendulum] epoch #590 | Time 243.64 s
2022-08-17 17:58:43 | [trpo_pendulum] epoch #590 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -528.822
Evaluation/AverageReturn              -1144.48
Evaluation/Iteration                    590
Evaluation/MaxReturn                  -1123.26
Evaluation/MinReturn                  -1185.45
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     20.8825
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42086
GaussianMLPPolicy/KL                      2.27086e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -407.112
GaussianMLPPolicy/LossBefore           -407.082
GaussianMLPPolicy/dLoss                   0.0298157
GaussianMLPValueFunction/LossAfter    24415.6
GaussianMLPValueFunction/LossBefore   24437.2
GaussianMLPValueFunction/dLoss           21.5742
TotalEnvSteps                        709200
-----------------------------------  ----------------
2022-08-17 17:58:44 | [trpo_pendulum] epoch #591 | Saving snapshot...
2022-08-17 17:58:44 | [trpo_pendulum] epoch #591 | Saved
2022-08-17 17:58:44 | [trpo_pendulum] epoch #591 | Time 244.06 s
2022-08-17 17:58:44 | [trpo_pendulum] epoch #591 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -631.131
Evaluation/AverageReturn              -1319.07
Evaluation/Iteration                    591
Evaluation/MaxReturn                  -1224.11
Evaluation/MinReturn                  -1423.11
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     58.7018
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42092
GaussianMLPPolicy/KL                      4.09805e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -447.778
GaussianMLPPolicy/LossBefore           -447.691
GaussianMLPPolicy/dLoss                   0.086731
GaussianMLPValueFunction/LossAfter    33031.3
GaussianMLPValueFunction/LossBefore   33060.2
GaussianMLPValueFunction/dLoss           28.9141
TotalEnvSteps                        710400
-----------------------------------  ----------------
2022-08-17 17:58:44 | [trpo_pendulum] epoch #592 | Saving snapshot...
2022-08-17 17:58:44 | [trpo_pendulum] epoch #592 | Saved
2022-08-17 17:58:44 | [trpo_pendulum] epoch #592 | Time 244.46 s
2022-08-17 17:58:44 | [trpo_pendulum] epoch #592 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -497.741
Evaluation/AverageReturn              -1165.25
Evaluation/Iteration                    592
Evaluation/MaxReturn                  -1096.91
Evaluation/MinReturn                  -1259.57
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     48.4515
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42108
GaussianMLPPolicy/KL                      9.09817e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -434.534
GaussianMLPPolicy/LossBefore           -434.561
GaussianMLPPolicy/dLoss                  -0.0269165
GaussianMLPValueFunction/LossAfter    28337.7
GaussianMLPValueFunction/LossBefore   28363.2
GaussianMLPValueFunction/dLoss           25.5273
TotalEnvSteps                        711600
-----------------------------------  ----------------
2022-08-17 17:58:45 | [trpo_pendulum] epoch #593 | Saving snapshot...
2022-08-17 17:58:45 | [trpo_pendulum] epoch #593 | Saved
2022-08-17 17:58:45 | [trpo_pendulum] epoch #593 | Time 244.89 s
2022-08-17 17:58:45 | [trpo_pendulum] epoch #593 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -572.684
Evaluation/AverageReturn              -1224.65
Evaluation/Iteration                    593
Evaluation/MaxReturn                  -1107.09
Evaluation/MinReturn                  -1263.81
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     54.1106
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42118
GaussianMLPPolicy/KL                      6.81745e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -437.672
GaussianMLPPolicy/LossBefore           -437.642
GaussianMLPPolicy/dLoss                   0.0294189
GaussianMLPValueFunction/LossAfter    28515.3
GaussianMLPValueFunction/LossBefore   28540.8
GaussianMLPValueFunction/dLoss           25.4453
TotalEnvSteps                        712800
-----------------------------------  ----------------
2022-08-17 17:58:45 | [trpo_pendulum] epoch #594 | Saving snapshot...
2022-08-17 17:58:45 | [trpo_pendulum] epoch #594 | Saved
2022-08-17 17:58:45 | [trpo_pendulum] epoch #594 | Time 245.31 s
2022-08-17 17:58:45 | [trpo_pendulum] epoch #594 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -559.231
Evaluation/AverageReturn              -1198.72
Evaluation/Iteration                    594
Evaluation/MaxReturn                  -1001.14
Evaluation/MinReturn                  -1281.79
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     98.9757
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42121
GaussianMLPPolicy/KL                      1.93756e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -428.147
GaussianMLPPolicy/LossBefore           -428.12
GaussianMLPPolicy/dLoss                   0.0273132
GaussianMLPValueFunction/LossAfter    26543.1
GaussianMLPValueFunction/LossBefore   26566.9
GaussianMLPValueFunction/dLoss           23.8203
TotalEnvSteps                        714000
-----------------------------------  ----------------
2022-08-17 17:58:45 | [trpo_pendulum] epoch #595 | Saving snapshot...
2022-08-17 17:58:45 | [trpo_pendulum] epoch #595 | Saved
2022-08-17 17:58:45 | [trpo_pendulum] epoch #595 | Time 245.71 s
2022-08-17 17:58:45 | [trpo_pendulum] epoch #595 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -609.588
Evaluation/AverageReturn              -1300.77
Evaluation/Iteration                    595
Evaluation/MaxReturn                  -1206.45
Evaluation/MinReturn                  -1363.82
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.0856
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42127
GaussianMLPPolicy/KL                      3.18671e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -459.11
GaussianMLPPolicy/LossBefore           -458.98
GaussianMLPPolicy/dLoss                   0.130096
GaussianMLPValueFunction/LossAfter    31334.9
GaussianMLPValueFunction/LossBefore   31363
GaussianMLPValueFunction/dLoss           28.0918
TotalEnvSteps                        715200
-----------------------------------  ----------------
2022-08-17 17:58:46 | [trpo_pendulum] epoch #596 | Saving snapshot...
2022-08-17 17:58:46 | [trpo_pendulum] epoch #596 | Saved
2022-08-17 17:58:46 | [trpo_pendulum] epoch #596 | Time 246.12 s
2022-08-17 17:58:46 | [trpo_pendulum] epoch #596 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -488.658
Evaluation/AverageReturn              -1175.5
Evaluation/Iteration                    596
Evaluation/MaxReturn                  -1145.01
Evaluation/MinReturn                  -1197
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     17.3708
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42133
GaussianMLPPolicy/KL                      5.10372e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -457.088
GaussianMLPPolicy/LossBefore           -457.041
GaussianMLPPolicy/dLoss                   0.0471802
GaussianMLPValueFunction/LossAfter    29777.5
GaussianMLPValueFunction/LossBefore   29804.7
GaussianMLPValueFunction/dLoss           27.1895
TotalEnvSteps                        716400
-----------------------------------  ----------------
2022-08-17 17:58:46 | [trpo_pendulum] epoch #597 | Saving snapshot...
2022-08-17 17:58:46 | [trpo_pendulum] epoch #597 | Saved
2022-08-17 17:58:46 | [trpo_pendulum] epoch #597 | Time 246.53 s
2022-08-17 17:58:46 | [trpo_pendulum] epoch #597 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -457.414
Evaluation/AverageReturn              -1106.17
Evaluation/Iteration                    597
Evaluation/MaxReturn                  -1023.17
Evaluation/MinReturn                  -1185.42
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     63.0537
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42145
GaussianMLPPolicy/KL                      9.98721e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -425.61
GaussianMLPPolicy/LossBefore           -425.374
GaussianMLPPolicy/dLoss                   0.236847
GaussianMLPValueFunction/LossAfter    26062.1
GaussianMLPValueFunction/LossBefore   26086
GaussianMLPValueFunction/dLoss           23.918
TotalEnvSteps                        717600
-----------------------------------  ----------------
2022-08-17 17:58:47 | [trpo_pendulum] epoch #598 | Saving snapshot...
2022-08-17 17:58:47 | [trpo_pendulum] epoch #598 | Saved
2022-08-17 17:58:47 | [trpo_pendulum] epoch #598 | Time 246.94 s
2022-08-17 17:58:47 | [trpo_pendulum] epoch #598 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -434.945
Evaluation/AverageReturn              -1131.25
Evaluation/Iteration                    598
Evaluation/MaxReturn                  -1025.45
Evaluation/MinReturn                  -1189.24
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     53.675
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42147
GaussianMLPPolicy/KL                      0.00017302
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -470.291
GaussianMLPPolicy/LossBefore           -470.12
GaussianMLPPolicy/dLoss                   0.170319
GaussianMLPValueFunction/LossAfter    30033.6
GaussianMLPValueFunction/LossBefore   30061.4
GaussianMLPValueFunction/dLoss           27.7617
TotalEnvSteps                        718800
-----------------------------------  ---------------
2022-08-17 17:58:47 | [trpo_pendulum] epoch #599 | Saving snapshot...
2022-08-17 17:58:47 | [trpo_pendulum] epoch #599 | Saved
2022-08-17 17:58:47 | [trpo_pendulum] epoch #599 | Time 247.35 s
2022-08-17 17:58:47 | [trpo_pendulum] epoch #599 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -675.292
Evaluation/AverageReturn              -1408.11
Evaluation/Iteration                    599
Evaluation/MaxReturn                  -1274.32
Evaluation/MinReturn                  -1588.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    105.317
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42142
GaussianMLPPolicy/KL                      0.000101799
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -498.218
GaussianMLPPolicy/LossBefore           -498.054
GaussianMLPPolicy/dLoss                   0.163483
GaussianMLPValueFunction/LossAfter    38104.8
GaussianMLPValueFunction/LossBefore   38139.7
GaussianMLPValueFunction/dLoss           34.9102
TotalEnvSteps                        720000
-----------------------------------  ----------------
2022-08-17 17:58:47 | [trpo_pendulum] epoch #600 | Saving snapshot...
2022-08-17 17:58:47 | [trpo_pendulum] epoch #600 | Saved
2022-08-17 17:58:47 | [trpo_pendulum] epoch #600 | Time 247.75 s
2022-08-17 17:58:47 | [trpo_pendulum] epoch #600 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -491.515
Evaluation/AverageReturn              -1169.61
Evaluation/Iteration                    600
Evaluation/MaxReturn                  -1055.8
Evaluation/MinReturn                  -1268.25
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     80.9551
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42131
GaussianMLPPolicy/KL                      9.42303e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -456.408
GaussianMLPPolicy/LossBefore           -456.433
GaussianMLPPolicy/dLoss                  -0.0254211
GaussianMLPValueFunction/LossAfter    29282.6
GaussianMLPValueFunction/LossBefore   29310.6
GaussianMLPValueFunction/dLoss           27.9297
TotalEnvSteps                        721200
-----------------------------------  ----------------
2022-08-17 17:58:48 | [trpo_pendulum] epoch #601 | Saving snapshot...
2022-08-17 17:58:48 | [trpo_pendulum] epoch #601 | Saved
2022-08-17 17:58:48 | [trpo_pendulum] epoch #601 | Time 248.17 s
2022-08-17 17:58:48 | [trpo_pendulum] epoch #601 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -595.051
Evaluation/AverageReturn              -1261.95
Evaluation/Iteration                    601
Evaluation/MaxReturn                  -1235.05
Evaluation/MinReturn                  -1310.98
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     24.8767
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42131
GaussianMLPPolicy/KL                      8.38189e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -435.051
GaussianMLPPolicy/LossBefore           -435.022
GaussianMLPPolicy/dLoss                   0.0293884
GaussianMLPValueFunction/LossAfter    29620
GaussianMLPValueFunction/LossBefore   29647.8
GaussianMLPValueFunction/dLoss           27.7559
TotalEnvSteps                        722400
-----------------------------------  ----------------
2022-08-17 17:58:48 | [trpo_pendulum] epoch #602 | Saving snapshot...
2022-08-17 17:58:48 | [trpo_pendulum] epoch #602 | Saved
2022-08-17 17:58:48 | [trpo_pendulum] epoch #602 | Time 248.59 s
2022-08-17 17:58:48 | [trpo_pendulum] epoch #602 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -500.643
Evaluation/AverageReturn              -1162.1
Evaluation/Iteration                    602
Evaluation/MaxReturn                  -1057.72
Evaluation/MinReturn                  -1233.17
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     62.6036
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42137
GaussianMLPPolicy/KL                      0.000194893
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -435.152
GaussianMLPPolicy/LossBefore           -434.713
GaussianMLPPolicy/dLoss                   0.438995
GaussianMLPValueFunction/LossAfter    28713.5
GaussianMLPValueFunction/LossBefore   28741.2
GaussianMLPValueFunction/dLoss           27.7285
TotalEnvSteps                        723600
-----------------------------------  ----------------
2022-08-17 17:58:49 | [trpo_pendulum] epoch #603 | Saving snapshot...
2022-08-17 17:58:49 | [trpo_pendulum] epoch #603 | Saved
2022-08-17 17:58:49 | [trpo_pendulum] epoch #603 | Time 249.00 s
2022-08-17 17:58:49 | [trpo_pendulum] epoch #603 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -654.22
Evaluation/AverageReturn              -1357.99
Evaluation/Iteration                    603
Evaluation/MaxReturn                  -1284.01
Evaluation/MinReturn                  -1489.99
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     64.8634
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42166
GaussianMLPPolicy/KL                      3.98303e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -450.191
GaussianMLPPolicy/LossBefore           -450.168
GaussianMLPPolicy/dLoss                   0.0220947
GaussianMLPValueFunction/LossAfter    33835.4
GaussianMLPValueFunction/LossBefore   33867.2
GaussianMLPValueFunction/dLoss           31.8164
TotalEnvSteps                        724800
-----------------------------------  ----------------
2022-08-17 17:58:49 | [trpo_pendulum] epoch #604 | Saving snapshot...
2022-08-17 17:58:49 | [trpo_pendulum] epoch #604 | Saved
2022-08-17 17:58:49 | [trpo_pendulum] epoch #604 | Time 249.41 s
2022-08-17 17:58:49 | [trpo_pendulum] epoch #604 | EpochTime 0.40 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -510.324
Evaluation/AverageReturn              -1221.93
Evaluation/Iteration                    604
Evaluation/MaxReturn                  -1172.39
Evaluation/MinReturn                  -1289.41
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     45.947
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42179
GaussianMLPPolicy/KL                      4.619e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -485.641
GaussianMLPPolicy/LossBefore           -485.599
GaussianMLPPolicy/dLoss                   0.0417786
GaussianMLPValueFunction/LossAfter    31992.4
GaussianMLPValueFunction/LossBefore   32023.1
GaussianMLPValueFunction/dLoss           30.707
TotalEnvSteps                        726000
-----------------------------------  --------------
2022-08-17 17:58:49 | [trpo_pendulum] epoch #605 | Saving snapshot...
2022-08-17 17:58:49 | [trpo_pendulum] epoch #605 | Saved
2022-08-17 17:58:49 | [trpo_pendulum] epoch #605 | Time 249.81 s
2022-08-17 17:58:49 | [trpo_pendulum] epoch #605 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -523.167
Evaluation/AverageReturn              -1227.94
Evaluation/Iteration                    605
Evaluation/MaxReturn                  -1185.38
Evaluation/MinReturn                  -1282.07
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     36.3774
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42184
GaussianMLPPolicy/KL                      2.65207e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -477.02
GaussianMLPPolicy/LossBefore           -476.899
GaussianMLPPolicy/dLoss                   0.120544
GaussianMLPValueFunction/LossAfter    31899.3
GaussianMLPValueFunction/LossBefore   31930.1
GaussianMLPValueFunction/dLoss           30.8301
TotalEnvSteps                        727200
-----------------------------------  ----------------
2022-08-17 17:58:50 | [trpo_pendulum] epoch #606 | Saving snapshot...
2022-08-17 17:58:50 | [trpo_pendulum] epoch #606 | Saved
2022-08-17 17:58:50 | [trpo_pendulum] epoch #606 | Time 250.22 s
2022-08-17 17:58:50 | [trpo_pendulum] epoch #606 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -576.043
Evaluation/AverageReturn              -1253.01
Evaluation/Iteration                    606
Evaluation/MaxReturn                  -1145.41
Evaluation/MinReturn                  -1332.06
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     60.5234
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42175
GaussianMLPPolicy/KL                      1.03434e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -461.551
GaussianMLPPolicy/LossBefore           -461.545
GaussianMLPPolicy/dLoss                   0.00570679
GaussianMLPValueFunction/LossAfter    29094.9
GaussianMLPValueFunction/LossBefore   29123
GaussianMLPValueFunction/dLoss           28.1523
TotalEnvSteps                        728400
-----------------------------------  ----------------
2022-08-17 17:58:50 | [trpo_pendulum] epoch #607 | Saving snapshot...
2022-08-17 17:58:50 | [trpo_pendulum] epoch #607 | Saved
2022-08-17 17:58:50 | [trpo_pendulum] epoch #607 | Time 250.65 s
2022-08-17 17:58:50 | [trpo_pendulum] epoch #607 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -522.135
Evaluation/AverageReturn              -1245.9
Evaluation/Iteration                    607
Evaluation/MaxReturn                  -1182
Evaluation/MinReturn                  -1308.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     48.7263
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42156
GaussianMLPPolicy/KL                      0.000177976
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -493.828
GaussianMLPPolicy/LossBefore           -493.439
GaussianMLPPolicy/dLoss                   0.389526
GaussianMLPValueFunction/LossAfter    32744.7
GaussianMLPValueFunction/LossBefore   32776.6
GaussianMLPValueFunction/dLoss           31.9707
TotalEnvSteps                        729600
-----------------------------------  ----------------
2022-08-17 17:58:51 | [trpo_pendulum] epoch #608 | Saving snapshot...
2022-08-17 17:58:51 | [trpo_pendulum] epoch #608 | Saved
2022-08-17 17:58:51 | [trpo_pendulum] epoch #608 | Time 251.05 s
2022-08-17 17:58:51 | [trpo_pendulum] epoch #608 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -583.195
Evaluation/AverageReturn              -1248.21
Evaluation/Iteration                    608
Evaluation/MaxReturn                  -1130.85
Evaluation/MinReturn                  -1280.82
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     52.9884
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42146
GaussianMLPPolicy/KL                      4.255e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -436.703
GaussianMLPPolicy/LossBefore           -436.703
GaussianMLPPolicy/dLoss                   0.000335693
GaussianMLPValueFunction/LossAfter    28916.6
GaussianMLPValueFunction/LossBefore   28944.7
GaussianMLPValueFunction/dLoss           28.0977
TotalEnvSteps                        730800
-----------------------------------  ----------------
2022-08-17 17:58:51 | [trpo_pendulum] epoch #609 | Saving snapshot...
2022-08-17 17:58:51 | [trpo_pendulum] epoch #609 | Saved
2022-08-17 17:58:51 | [trpo_pendulum] epoch #609 | Time 251.46 s
2022-08-17 17:58:51 | [trpo_pendulum] epoch #609 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -462.284
Evaluation/AverageReturn              -1116.43
Evaluation/Iteration                    609
Evaluation/MaxReturn                  -1041.91
Evaluation/MinReturn                  -1200.33
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     62.7007
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42142
GaussianMLPPolicy/KL                      2.05876e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -428.471
GaussianMLPPolicy/LossBefore           -428.47
GaussianMLPPolicy/dLoss                   0.0010376
GaussianMLPValueFunction/LossAfter    26651.6
GaussianMLPValueFunction/LossBefore   26677.6
GaussianMLPValueFunction/dLoss           26.0098
TotalEnvSteps                        732000
-----------------------------------  ----------------
2022-08-17 17:58:51 | [trpo_pendulum] epoch #610 | Saving snapshot...
2022-08-17 17:58:52 | [trpo_pendulum] epoch #610 | Saved
2022-08-17 17:58:52 | [trpo_pendulum] epoch #610 | Time 251.87 s
2022-08-17 17:58:52 | [trpo_pendulum] epoch #610 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -513.271
Evaluation/AverageReturn              -1201.36
Evaluation/Iteration                    610
Evaluation/MaxReturn                  -1157
Evaluation/MinReturn                  -1307.31
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.8676
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42142
GaussianMLPPolicy/KL                      1.07961e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -455.101
GaussianMLPPolicy/LossBefore           -455.063
GaussianMLPPolicy/dLoss                   0.0376587
GaussianMLPValueFunction/LossAfter    29811.3
GaussianMLPValueFunction/LossBefore   29840.5
GaussianMLPValueFunction/dLoss           29.1758
TotalEnvSteps                        733200
-----------------------------------  ----------------
2022-08-17 17:58:52 | [trpo_pendulum] epoch #611 | Saving snapshot...
2022-08-17 17:58:52 | [trpo_pendulum] epoch #611 | Saved
2022-08-17 17:58:52 | [trpo_pendulum] epoch #611 | Time 252.28 s
2022-08-17 17:58:52 | [trpo_pendulum] epoch #611 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -499.895
Evaluation/AverageReturn              -1183.56
Evaluation/Iteration                    611
Evaluation/MaxReturn                  -1148.48
Evaluation/MinReturn                  -1240.94
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     34.3531
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42136
GaussianMLPPolicy/KL                      8.18433e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -460.385
GaussianMLPPolicy/LossBefore           -460.383
GaussianMLPPolicy/dLoss                   0.0017395
GaussianMLPValueFunction/LossAfter    29164.3
GaussianMLPValueFunction/LossBefore   29192.7
GaussianMLPValueFunction/dLoss           28.3633
TotalEnvSteps                        734400
-----------------------------------  ----------------
2022-08-17 17:58:52 | [trpo_pendulum] epoch #612 | Saving snapshot...
2022-08-17 17:58:52 | [trpo_pendulum] epoch #612 | Saved
2022-08-17 17:58:52 | [trpo_pendulum] epoch #612 | Time 252.70 s
2022-08-17 17:58:52 | [trpo_pendulum] epoch #612 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -564.498
Evaluation/AverageReturn              -1222.92
Evaluation/Iteration                    612
Evaluation/MaxReturn                  -1118.01
Evaluation/MinReturn                  -1280.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.4762
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42116
GaussianMLPPolicy/KL                      7.7344e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -450.217
GaussianMLPPolicy/LossBefore           -450.167
GaussianMLPPolicy/dLoss                   0.0493774
GaussianMLPValueFunction/LossAfter    27443.5
GaussianMLPValueFunction/LossBefore   27469.9
GaussianMLPValueFunction/dLoss           26.418
TotalEnvSteps                        735600
-----------------------------------  ---------------
2022-08-17 17:58:53 | [trpo_pendulum] epoch #613 | Saving snapshot...
2022-08-17 17:58:53 | [trpo_pendulum] epoch #613 | Saved
2022-08-17 17:58:53 | [trpo_pendulum] epoch #613 | Time 253.12 s
2022-08-17 17:58:53 | [trpo_pendulum] epoch #613 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -522.434
Evaluation/AverageReturn              -1215.74
Evaluation/Iteration                    613
Evaluation/MaxReturn                  -1189.38
Evaluation/MinReturn                  -1265.96
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     25.3807
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42101
GaussianMLPPolicy/KL                      0.00016275
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -458.862
GaussianMLPPolicy/LossBefore           -458.543
GaussianMLPPolicy/dLoss                   0.318726
GaussianMLPValueFunction/LossAfter    30714.7
GaussianMLPValueFunction/LossBefore   30744.3
GaussianMLPValueFunction/dLoss           29.543
TotalEnvSteps                        736800
-----------------------------------  ---------------
2022-08-17 17:58:53 | [trpo_pendulum] epoch #614 | Saving snapshot...
2022-08-17 17:58:53 | [trpo_pendulum] epoch #614 | Saved
2022-08-17 17:58:53 | [trpo_pendulum] epoch #614 | Time 253.52 s
2022-08-17 17:58:53 | [trpo_pendulum] epoch #614 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -458.432
Evaluation/AverageReturn              -1149.05
Evaluation/Iteration                    614
Evaluation/MaxReturn                  -1077.42
Evaluation/MinReturn                  -1191.24
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     36.3638
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42097
GaussianMLPPolicy/KL                      0.00019133
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -451.749
GaussianMLPPolicy/LossBefore           -451.556
GaussianMLPPolicy/dLoss                   0.193298
GaussianMLPValueFunction/LossAfter    29537.3
GaussianMLPValueFunction/LossBefore   29566.3
GaussianMLPValueFunction/dLoss           28.9902
TotalEnvSteps                        738000
-----------------------------------  ---------------
2022-08-17 17:58:54 | [trpo_pendulum] epoch #615 | Saving snapshot...
2022-08-17 17:58:54 | [trpo_pendulum] epoch #615 | Saved
2022-08-17 17:58:54 | [trpo_pendulum] epoch #615 | Time 253.93 s
2022-08-17 17:58:54 | [trpo_pendulum] epoch #615 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -479.568
Evaluation/AverageReturn              -1144.23
Evaluation/Iteration                    615
Evaluation/MaxReturn                  -1039.53
Evaluation/MinReturn                  -1175.83
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     47.4965
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42085
GaussianMLPPolicy/KL                      6.47593e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -447.393
GaussianMLPPolicy/LossBefore           -447.472
GaussianMLPPolicy/dLoss                  -0.0795898
GaussianMLPValueFunction/LossAfter    27115.2
GaussianMLPValueFunction/LossBefore   27141.7
GaussianMLPValueFunction/dLoss           26.4395
TotalEnvSteps                        739200
-----------------------------------  ----------------
2022-08-17 17:58:54 | [trpo_pendulum] epoch #616 | Saving snapshot...
2022-08-17 17:58:54 | [trpo_pendulum] epoch #616 | Saved
2022-08-17 17:58:54 | [trpo_pendulum] epoch #616 | Time 254.32 s
2022-08-17 17:58:54 | [trpo_pendulum] epoch #616 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -467.664
Evaluation/AverageReturn              -1132.62
Evaluation/Iteration                    616
Evaluation/MaxReturn                  -1027.35
Evaluation/MinReturn                  -1219.83
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     70.7542
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42072
GaussianMLPPolicy/KL                      8.29156e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -443.413
GaussianMLPPolicy/LossBefore           -443.338
GaussianMLPPolicy/dLoss                   0.0754395
GaussianMLPValueFunction/LossAfter    27554.3
GaussianMLPValueFunction/LossBefore   27580.8
GaussianMLPValueFunction/dLoss           26.541
TotalEnvSteps                        740400
-----------------------------------  ----------------
2022-08-17 17:58:54 | [trpo_pendulum] epoch #617 | Saving snapshot...
2022-08-17 17:58:54 | [trpo_pendulum] epoch #617 | Saved
2022-08-17 17:58:54 | [trpo_pendulum] epoch #617 | Time 254.75 s
2022-08-17 17:58:54 | [trpo_pendulum] epoch #617 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -500.461
Evaluation/AverageReturn              -1132.57
Evaluation/Iteration                    617
Evaluation/MaxReturn                  -1061.98
Evaluation/MinReturn                  -1172.59
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     34.9552
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4206
GaussianMLPPolicy/KL                      4.82904e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -417.937
GaussianMLPPolicy/LossBefore           -417.929
GaussianMLPPolicy/dLoss                   0.0088501
GaussianMLPValueFunction/LossAfter    24842.5
GaussianMLPValueFunction/LossBefore   24866.1
GaussianMLPValueFunction/dLoss           23.6016
TotalEnvSteps                        741600
-----------------------------------  ----------------
2022-08-17 17:58:55 | [trpo_pendulum] epoch #618 | Saving snapshot...
2022-08-17 17:58:55 | [trpo_pendulum] epoch #618 | Saved
2022-08-17 17:58:55 | [trpo_pendulum] epoch #618 | Time 255.16 s
2022-08-17 17:58:55 | [trpo_pendulum] epoch #618 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -492.755
Evaluation/AverageReturn              -1190
Evaluation/Iteration                    618
Evaluation/MaxReturn                  -1179.56
Evaluation/MinReturn                  -1205.52
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      8.64239
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42062
GaussianMLPPolicy/KL                      0.000104073
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -453.248
GaussianMLPPolicy/LossBefore           -453.148
GaussianMLPPolicy/dLoss                   0.100525
GaussianMLPValueFunction/LossAfter    30366.4
GaussianMLPValueFunction/LossBefore   30395.2
GaussianMLPValueFunction/dLoss           28.7871
TotalEnvSteps                        742800
-----------------------------------  ----------------
2022-08-17 17:58:55 | [trpo_pendulum] epoch #619 | Saving snapshot...
2022-08-17 17:58:55 | [trpo_pendulum] epoch #619 | Saved
2022-08-17 17:58:55 | [trpo_pendulum] epoch #619 | Time 255.57 s
2022-08-17 17:58:55 | [trpo_pendulum] epoch #619 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -575.045
Evaluation/AverageReturn              -1246.29
Evaluation/Iteration                    619
Evaluation/MaxReturn                  -1124.46
Evaluation/MinReturn                  -1326.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     68.2629
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42068
GaussianMLPPolicy/KL                      5.36663e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -441.448
GaussianMLPPolicy/LossBefore           -441.414
GaussianMLPPolicy/dLoss                   0.0340271
GaussianMLPValueFunction/LossAfter    28772.3
GaussianMLPValueFunction/LossBefore   28799.4
GaussianMLPValueFunction/dLoss           27.1465
TotalEnvSteps                        744000
-----------------------------------  ----------------
2022-08-17 17:58:56 | [trpo_pendulum] epoch #620 | Saving snapshot...
2022-08-17 17:58:56 | [trpo_pendulum] epoch #620 | Saved
2022-08-17 17:58:56 | [trpo_pendulum] epoch #620 | Time 255.97 s
2022-08-17 17:58:56 | [trpo_pendulum] epoch #620 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -526.538
Evaluation/AverageReturn              -1161.13
Evaluation/Iteration                    620
Evaluation/MaxReturn                  -1109.4
Evaluation/MinReturn                  -1235.39
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     41.7417
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4207
GaussianMLPPolicy/KL                      9.48162e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -423.419
GaussianMLPPolicy/LossBefore           -423.392
GaussianMLPPolicy/dLoss                   0.0270996
GaussianMLPValueFunction/LossAfter    25277.1
GaussianMLPValueFunction/LossBefore   25301
GaussianMLPValueFunction/dLoss           23.8477
TotalEnvSteps                        745200
-----------------------------------  ----------------
2022-08-17 17:58:56 | [trpo_pendulum] epoch #621 | Saving snapshot...
2022-08-17 17:58:56 | [trpo_pendulum] epoch #621 | Saved
2022-08-17 17:58:56 | [trpo_pendulum] epoch #621 | Time 256.37 s
2022-08-17 17:58:56 | [trpo_pendulum] epoch #621 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -647.331
Evaluation/AverageReturn              -1387.5
Evaluation/Iteration                    621
Evaluation/MaxReturn                  -1208.09
Evaluation/MinReturn                  -1561.02
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    126.815
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42079
GaussianMLPPolicy/KL                      1.77132e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -488.62
GaussianMLPPolicy/LossBefore           -488.491
GaussianMLPPolicy/dLoss                   0.129364
GaussianMLPValueFunction/LossAfter    36305.5
GaussianMLPValueFunction/LossBefore   36339.7
GaussianMLPValueFunction/dLoss           34.1484
TotalEnvSteps                        746400
-----------------------------------  ----------------
2022-08-17 17:58:56 | [trpo_pendulum] epoch #622 | Saving snapshot...
2022-08-17 17:58:56 | [trpo_pendulum] epoch #622 | Saved
2022-08-17 17:58:56 | [trpo_pendulum] epoch #622 | Time 256.80 s
2022-08-17 17:58:56 | [trpo_pendulum] epoch #622 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -421.197
Evaluation/AverageReturn              -1085.81
Evaluation/Iteration                    622
Evaluation/MaxReturn                   -991.36
Evaluation/MinReturn                  -1177.05
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     62.9635
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42088
GaussianMLPPolicy/KL                      2.62339e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -438.652
GaussianMLPPolicy/LossBefore           -438.614
GaussianMLPPolicy/dLoss                   0.0374146
GaussianMLPValueFunction/LossAfter    27004
GaussianMLPValueFunction/LossBefore   27030.1
GaussianMLPValueFunction/dLoss           26.0449
TotalEnvSteps                        747600
-----------------------------------  ----------------
2022-08-17 17:58:57 | [trpo_pendulum] epoch #623 | Saving snapshot...
2022-08-17 17:58:57 | [trpo_pendulum] epoch #623 | Saved
2022-08-17 17:58:57 | [trpo_pendulum] epoch #623 | Time 257.21 s
2022-08-17 17:58:57 | [trpo_pendulum] epoch #623 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -556.833
Evaluation/AverageReturn              -1192.93
Evaluation/Iteration                    623
Evaluation/MaxReturn                  -1110.01
Evaluation/MinReturn                  -1264.7
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     52.0682
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42093
GaussianMLPPolicy/KL                      4.53637e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -424.417
GaussianMLPPolicy/LossBefore           -424.383
GaussianMLPPolicy/dLoss                   0.033783
GaussianMLPValueFunction/LossAfter    25508.8
GaussianMLPValueFunction/LossBefore   25533
GaussianMLPValueFunction/dLoss           24.1953
TotalEnvSteps                        748800
-----------------------------------  ----------------
2022-08-17 17:58:57 | [trpo_pendulum] epoch #624 | Saving snapshot...
2022-08-17 17:58:57 | [trpo_pendulum] epoch #624 | Saved
2022-08-17 17:58:57 | [trpo_pendulum] epoch #624 | Time 257.62 s
2022-08-17 17:58:57 | [trpo_pendulum] epoch #624 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -499.995
Evaluation/AverageReturn              -1183.31
Evaluation/Iteration                    624
Evaluation/MaxReturn                  -1171.33
Evaluation/MinReturn                  -1191.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      7.0836
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42088
GaussianMLPPolicy/KL                      2.42326e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -461.766
GaussianMLPPolicy/LossBefore           -461.76
GaussianMLPPolicy/dLoss                   0.00582886
GaussianMLPValueFunction/LossAfter    29213.4
GaussianMLPValueFunction/LossBefore   29241.2
GaussianMLPValueFunction/dLoss           27.8125
TotalEnvSteps                        750000
-----------------------------------  ----------------
2022-08-17 17:58:58 | [trpo_pendulum] epoch #625 | Saving snapshot...
2022-08-17 17:58:58 | [trpo_pendulum] epoch #625 | Saved
2022-08-17 17:58:58 | [trpo_pendulum] epoch #625 | Time 258.03 s
2022-08-17 17:58:58 | [trpo_pendulum] epoch #625 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -475.157
Evaluation/AverageReturn              -1122.06
Evaluation/Iteration                    625
Evaluation/MaxReturn                  -1069.99
Evaluation/MinReturn                  -1186.95
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     45.4887
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4208
GaussianMLPPolicy/KL                      2.87615e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -430.552
GaussianMLPPolicy/LossBefore           -430.491
GaussianMLPPolicy/dLoss                   0.0611267
GaussianMLPValueFunction/LossAfter    26515.6
GaussianMLPValueFunction/LossBefore   26540.9
GaussianMLPValueFunction/dLoss           25.3105
TotalEnvSteps                        751200
-----------------------------------  ----------------
2022-08-17 17:58:58 | [trpo_pendulum] epoch #626 | Saving snapshot...
2022-08-17 17:58:58 | [trpo_pendulum] epoch #626 | Saved
2022-08-17 17:58:58 | [trpo_pendulum] epoch #626 | Time 258.44 s
2022-08-17 17:58:58 | [trpo_pendulum] epoch #626 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -599.869
Evaluation/AverageReturn              -1276.16
Evaluation/Iteration                    626
Evaluation/MaxReturn                  -1222.34
Evaluation/MinReturn                  -1355.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     51.3874
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42081
GaussianMLPPolicy/KL                      2.71324e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -442.618
GaussianMLPPolicy/LossBefore           -442.595
GaussianMLPPolicy/dLoss                   0.0227661
GaussianMLPValueFunction/LossAfter    29379.9
GaussianMLPValueFunction/LossBefore   29407.4
GaussianMLPValueFunction/dLoss           27.5332
TotalEnvSteps                        752400
-----------------------------------  ----------------
2022-08-17 17:58:58 | [trpo_pendulum] epoch #627 | Saving snapshot...
2022-08-17 17:58:58 | [trpo_pendulum] epoch #627 | Saved
2022-08-17 17:58:58 | [trpo_pendulum] epoch #627 | Time 258.85 s
2022-08-17 17:58:58 | [trpo_pendulum] epoch #627 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -490.096
Evaluation/AverageReturn              -1150.88
Evaluation/Iteration                    627
Evaluation/MaxReturn                  -1031.71
Evaluation/MinReturn                  -1184.44
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     54.4234
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42074
GaussianMLPPolicy/KL                      2.01435e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -444.434
GaussianMLPPolicy/LossBefore           -444.375
GaussianMLPPolicy/dLoss                   0.0592041
GaussianMLPValueFunction/LossAfter    26674.5
GaussianMLPValueFunction/LossBefore   26699.9
GaussianMLPValueFunction/dLoss           25.4395
TotalEnvSteps                        753600
-----------------------------------  ----------------
2022-08-17 17:58:59 | [trpo_pendulum] epoch #628 | Saving snapshot...
2022-08-17 17:58:59 | [trpo_pendulum] epoch #628 | Saved
2022-08-17 17:58:59 | [trpo_pendulum] epoch #628 | Time 259.26 s
2022-08-17 17:58:59 | [trpo_pendulum] epoch #628 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -641.676
Evaluation/AverageReturn              -1359.46
Evaluation/Iteration                    628
Evaluation/MaxReturn                  -1220.28
Evaluation/MinReturn                  -1632.37
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    142.061
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42079
GaussianMLPPolicy/KL                      7.71732e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -469.824
GaussianMLPPolicy/LossBefore           -469.546
GaussianMLPPolicy/dLoss                   0.278137
GaussianMLPValueFunction/LossAfter    34636.5
GaussianMLPValueFunction/LossBefore   34669
GaussianMLPValueFunction/dLoss           32.5
TotalEnvSteps                        754800
-----------------------------------  ----------------
2022-08-17 17:58:59 | [trpo_pendulum] epoch #629 | Saving snapshot...
2022-08-17 17:58:59 | [trpo_pendulum] epoch #629 | Saved
2022-08-17 17:58:59 | [trpo_pendulum] epoch #629 | Time 259.68 s
2022-08-17 17:58:59 | [trpo_pendulum] epoch #629 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -454.597
Evaluation/AverageReturn              -1109.26
Evaluation/Iteration                    629
Evaluation/MaxReturn                  -1033.46
Evaluation/MinReturn                  -1168.34
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     51.5231
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42076
GaussianMLPPolicy/KL                      5.0564e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -438.546
GaussianMLPPolicy/LossBefore           -438.557
GaussianMLPPolicy/dLoss                  -0.0107727
GaussianMLPValueFunction/LossAfter    25637.7
GaussianMLPValueFunction/LossBefore   25662.3
GaussianMLPValueFunction/dLoss           24.5566
TotalEnvSteps                        756000
-----------------------------------  ---------------
2022-08-17 17:59:00 | [trpo_pendulum] epoch #630 | Saving snapshot...
2022-08-17 17:59:00 | [trpo_pendulum] epoch #630 | Saved
2022-08-17 17:59:00 | [trpo_pendulum] epoch #630 | Time 260.08 s
2022-08-17 17:59:00 | [trpo_pendulum] epoch #630 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -518.588
Evaluation/AverageReturn              -1192.69
Evaluation/Iteration                    630
Evaluation/MaxReturn                  -1116.91
Evaluation/MinReturn                  -1277.03
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     55.8293
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42072
GaussianMLPPolicy/KL                      3.7497e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -449.432
GaussianMLPPolicy/LossBefore           -449.244
GaussianMLPPolicy/dLoss                   0.188324
GaussianMLPValueFunction/LossAfter    27631.5
GaussianMLPValueFunction/LossBefore   27657.7
GaussianMLPValueFunction/dLoss           26.2148
TotalEnvSteps                        757200
-----------------------------------  ---------------
2022-08-17 17:59:00 | [trpo_pendulum] epoch #631 | Saving snapshot...
2022-08-17 17:59:00 | [trpo_pendulum] epoch #631 | Saved
2022-08-17 17:59:00 | [trpo_pendulum] epoch #631 | Time 260.48 s
2022-08-17 17:59:00 | [trpo_pendulum] epoch #631 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -490.481
Evaluation/AverageReturn              -1142.57
Evaluation/Iteration                    631
Evaluation/MaxReturn                  -1111.16
Evaluation/MinReturn                  -1157.18
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     16.5106
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42074
GaussianMLPPolicy/KL                      8.97458e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -426.649
GaussianMLPPolicy/LossBefore           -426.508
GaussianMLPPolicy/dLoss                   0.1409
GaussianMLPValueFunction/LossAfter    25424.2
GaussianMLPValueFunction/LossBefore   25448.3
GaussianMLPValueFunction/dLoss           24.0957
TotalEnvSteps                        758400
-----------------------------------  ----------------
2022-08-17 17:59:01 | [trpo_pendulum] epoch #632 | Saving snapshot...
2022-08-17 17:59:01 | [trpo_pendulum] epoch #632 | Saved
2022-08-17 17:59:01 | [trpo_pendulum] epoch #632 | Time 260.90 s
2022-08-17 17:59:01 | [trpo_pendulum] epoch #632 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -545.456
Evaluation/AverageReturn              -1188.43
Evaluation/Iteration                    632
Evaluation/MaxReturn                  -1085.18
Evaluation/MinReturn                  -1243.6
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     52.1253
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42079
GaussianMLPPolicy/KL                      3.00031e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -422.193
GaussianMLPPolicy/LossBefore           -421.995
GaussianMLPPolicy/dLoss                   0.197388
GaussianMLPValueFunction/LossAfter    25574
GaussianMLPValueFunction/LossBefore   25597.8
GaussianMLPValueFunction/dLoss           23.8809
TotalEnvSteps                        759600
-----------------------------------  ----------------
2022-08-17 17:59:01 | [trpo_pendulum] epoch #633 | Saving snapshot...
2022-08-17 17:59:01 | [trpo_pendulum] epoch #633 | Saved
2022-08-17 17:59:01 | [trpo_pendulum] epoch #633 | Time 261.31 s
2022-08-17 17:59:01 | [trpo_pendulum] epoch #633 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -490.648
Evaluation/AverageReturn              -1183.51
Evaluation/Iteration                    633
Evaluation/MaxReturn                  -1171.37
Evaluation/MinReturn                  -1204.74
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     10.4606
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42092
GaussianMLPPolicy/KL                      0.000315967
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -453.813
GaussianMLPPolicy/LossBefore           -453.246
GaussianMLPPolicy/dLoss                   0.567078
GaussianMLPValueFunction/LossAfter    29242.2
GaussianMLPValueFunction/LossBefore   29269.7
GaussianMLPValueFunction/dLoss           27.5176
TotalEnvSteps                        760800
-----------------------------------  ----------------
2022-08-17 17:59:01 | [trpo_pendulum] epoch #634 | Saving snapshot...
2022-08-17 17:59:01 | [trpo_pendulum] epoch #634 | Saved
2022-08-17 17:59:01 | [trpo_pendulum] epoch #634 | Time 261.72 s
2022-08-17 17:59:01 | [trpo_pendulum] epoch #634 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -578.048
Evaluation/AverageReturn              -1247.35
Evaluation/Iteration                    634
Evaluation/MaxReturn                  -1207.6
Evaluation/MinReturn                  -1283.71
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     30.7261
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4211
GaussianMLPPolicy/KL                      0.00033424
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -438.628
GaussianMLPPolicy/LossBefore           -438.263
GaussianMLPPolicy/dLoss                   0.364899
GaussianMLPValueFunction/LossAfter    28144
GaussianMLPValueFunction/LossBefore   28170.2
GaussianMLPValueFunction/dLoss           26.2285
TotalEnvSteps                        762000
-----------------------------------  ---------------
2022-08-17 17:59:02 | [trpo_pendulum] epoch #635 | Saving snapshot...
2022-08-17 17:59:02 | [trpo_pendulum] epoch #635 | Saved
2022-08-17 17:59:02 | [trpo_pendulum] epoch #635 | Time 262.13 s
2022-08-17 17:59:02 | [trpo_pendulum] epoch #635 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -501.532
Evaluation/AverageReturn              -1182.51
Evaluation/Iteration                    635
Evaluation/MaxReturn                  -1159.39
Evaluation/MinReturn                  -1214.33
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     17.8032
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42129
GaussianMLPPolicy/KL                      0.000208989
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -449.931
GaussianMLPPolicy/LossBefore           -449.996
GaussianMLPPolicy/dLoss                  -0.0657349
GaussianMLPValueFunction/LossAfter    28624.6
GaussianMLPValueFunction/LossBefore   28651.5
GaussianMLPValueFunction/dLoss           26.877
TotalEnvSteps                        763200
-----------------------------------  ----------------
2022-08-17 17:59:02 | [trpo_pendulum] epoch #636 | Saving snapshot...
2022-08-17 17:59:02 | [trpo_pendulum] epoch #636 | Saved
2022-08-17 17:59:02 | [trpo_pendulum] epoch #636 | Time 262.54 s
2022-08-17 17:59:02 | [trpo_pendulum] epoch #636 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -622.733
Evaluation/AverageReturn              -1305.84
Evaluation/Iteration                    636
Evaluation/MaxReturn                  -1211.41
Evaluation/MinReturn                  -1371.86
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     47.5498
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42146
GaussianMLPPolicy/KL                      0.000141941
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -454.214
GaussianMLPPolicy/LossBefore           -454.134
GaussianMLPPolicy/dLoss                   0.0800476
GaussianMLPValueFunction/LossAfter    29995.7
GaussianMLPValueFunction/LossBefore   30023.7
GaussianMLPValueFunction/dLoss           28.0059
TotalEnvSteps                        764400
-----------------------------------  ----------------
2022-08-17 17:59:03 | [trpo_pendulum] epoch #637 | Saving snapshot...
2022-08-17 17:59:03 | [trpo_pendulum] epoch #637 | Saved
2022-08-17 17:59:03 | [trpo_pendulum] epoch #637 | Time 262.96 s
2022-08-17 17:59:03 | [trpo_pendulum] epoch #637 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -457.012
Evaluation/AverageReturn              -1166.26
Evaluation/Iteration                    637
Evaluation/MaxReturn                  -1062.93
Evaluation/MinReturn                  -1195.54
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     46.5352
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42159
GaussianMLPPolicy/KL                      5.64969e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -473.969
GaussianMLPPolicy/LossBefore           -474.013
GaussianMLPPolicy/dLoss                  -0.044281
GaussianMLPValueFunction/LossAfter    30770.9
GaussianMLPValueFunction/LossBefore   30800.1
GaussianMLPValueFunction/dLoss           29.2578
TotalEnvSteps                        765600
-----------------------------------  ----------------
2022-08-17 17:59:03 | [trpo_pendulum] epoch #638 | Saving snapshot...
2022-08-17 17:59:03 | [trpo_pendulum] epoch #638 | Saved
2022-08-17 17:59:03 | [trpo_pendulum] epoch #638 | Time 263.37 s
2022-08-17 17:59:03 | [trpo_pendulum] epoch #638 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -517.101
Evaluation/AverageReturn              -1215.65
Evaluation/Iteration                    638
Evaluation/MaxReturn                  -1185.83
Evaluation/MinReturn                  -1270.03
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     29.7984
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42167
GaussianMLPPolicy/KL                      2.00266e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -468.21
GaussianMLPPolicy/LossBefore           -468.093
GaussianMLPPolicy/dLoss                   0.117279
GaussianMLPValueFunction/LossAfter    30171.8
GaussianMLPValueFunction/LossBefore   30200.9
GaussianMLPValueFunction/dLoss           29.1035
TotalEnvSteps                        766800
-----------------------------------  ----------------
2022-08-17 17:59:04 | [trpo_pendulum] epoch #639 | Saving snapshot...
2022-08-17 17:59:04 | [trpo_pendulum] epoch #639 | Saved
2022-08-17 17:59:04 | [trpo_pendulum] epoch #639 | Time 263.90 s
2022-08-17 17:59:04 | [trpo_pendulum] epoch #639 | EpochTime 0.52 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -506.015
Evaluation/AverageReturn              -1212.19
Evaluation/Iteration                    639
Evaluation/MaxReturn                  -1151.77
Evaluation/MinReturn                  -1313.98
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.4908
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42169
GaussianMLPPolicy/KL                      4.71864e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -473.919
GaussianMLPPolicy/LossBefore           -473.825
GaussianMLPPolicy/dLoss                   0.0943298
GaussianMLPValueFunction/LossAfter    30775
GaussianMLPValueFunction/LossBefore   30804.6
GaussianMLPValueFunction/dLoss           29.5469
TotalEnvSteps                        768000
-----------------------------------  ----------------
2022-08-17 17:59:04 | [trpo_pendulum] epoch #640 | Saving snapshot...
2022-08-17 17:59:04 | [trpo_pendulum] epoch #640 | Saved
2022-08-17 17:59:04 | [trpo_pendulum] epoch #640 | Time 264.30 s
2022-08-17 17:59:04 | [trpo_pendulum] epoch #640 | EpochTime 0.40 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -505.237
Evaluation/AverageReturn              -1208.94
Evaluation/Iteration                    640
Evaluation/MaxReturn                  -1164.5
Evaluation/MinReturn                  -1274.69
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     43.779
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42164
GaussianMLPPolicy/KL                      0.0003232
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -474.901
GaussianMLPPolicy/LossBefore           -474.351
GaussianMLPPolicy/dLoss                   0.549957
GaussianMLPValueFunction/LossAfter    30166.5
GaussianMLPValueFunction/LossBefore   30195.8
GaussianMLPValueFunction/dLoss           29.2637
TotalEnvSteps                        769200
-----------------------------------  --------------
2022-08-17 17:59:04 | [trpo_pendulum] epoch #641 | Saving snapshot...
2022-08-17 17:59:04 | [trpo_pendulum] epoch #641 | Saved
2022-08-17 17:59:04 | [trpo_pendulum] epoch #641 | Time 264.73 s
2022-08-17 17:59:04 | [trpo_pendulum] epoch #641 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -597.254
Evaluation/AverageReturn              -1291.35
Evaluation/Iteration                    641
Evaluation/MaxReturn                  -1233.22
Evaluation/MinReturn                  -1359.44
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     43.0566
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42141
GaussianMLPPolicy/KL                      0.000583466
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -477.694
GaussianMLPPolicy/LossBefore           -476.747
GaussianMLPPolicy/dLoss                   0.946655
GaussianMLPValueFunction/LossAfter    29714.5
GaussianMLPValueFunction/LossBefore   29743.2
GaussianMLPValueFunction/dLoss           28.7305
TotalEnvSteps                        770400
-----------------------------------  ----------------
2022-08-17 17:59:05 | [trpo_pendulum] epoch #642 | Saving snapshot...
2022-08-17 17:59:05 | [trpo_pendulum] epoch #642 | Saved
2022-08-17 17:59:05 | [trpo_pendulum] epoch #642 | Time 265.15 s
2022-08-17 17:59:05 | [trpo_pendulum] epoch #642 | EpochTime 0.42 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -494.133
Evaluation/AverageReturn              -1183.29
Evaluation/Iteration                    642
Evaluation/MaxReturn                  -1125.72
Evaluation/MinReturn                  -1235.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     35.3918
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42124
GaussianMLPPolicy/KL                      0.00150128
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -456.724
GaussianMLPPolicy/LossBefore           -454.986
GaussianMLPPolicy/dLoss                   1.73871
GaussianMLPValueFunction/LossAfter    28914.3
GaussianMLPValueFunction/LossBefore   28942.5
GaussianMLPValueFunction/dLoss           28.1543
TotalEnvSteps                        771600
-----------------------------------  ---------------
2022-08-17 17:59:05 | [trpo_pendulum] epoch #643 | Saving snapshot...
2022-08-17 17:59:05 | [trpo_pendulum] epoch #643 | Saved
2022-08-17 17:59:05 | [trpo_pendulum] epoch #643 | Time 265.56 s
2022-08-17 17:59:05 | [trpo_pendulum] epoch #643 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -493.812
Evaluation/AverageReturn              -1122.1
Evaluation/Iteration                    643
Evaluation/MaxReturn                  -1022.26
Evaluation/MinReturn                  -1239.34
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     72.0325
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42117
GaussianMLPPolicy/KL                      0.00138083
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -407.374
GaussianMLPPolicy/LossBefore           -406.596
GaussianMLPPolicy/dLoss                   0.778412
GaussianMLPValueFunction/LossAfter    23633.7
GaussianMLPValueFunction/LossBefore   23656.7
GaussianMLPValueFunction/dLoss           22.9023
TotalEnvSteps                        772800
-----------------------------------  ---------------
2022-08-17 17:59:06 | [trpo_pendulum] epoch #644 | Saving snapshot...
2022-08-17 17:59:06 | [trpo_pendulum] epoch #644 | Saved
2022-08-17 17:59:06 | [trpo_pendulum] epoch #644 | Time 265.96 s
2022-08-17 17:59:06 | [trpo_pendulum] epoch #644 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -465.768
Evaluation/AverageReturn              -1106.49
Evaluation/Iteration                    644
Evaluation/MaxReturn                  -1034.32
Evaluation/MinReturn                  -1161.92
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     44.4843
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42102
GaussianMLPPolicy/KL                      0.000899752
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -430.385
GaussianMLPPolicy/LossBefore           -430.4
GaussianMLPPolicy/dLoss                  -0.01474
GaussianMLPValueFunction/LossAfter    24063.9
GaussianMLPValueFunction/LossBefore   24086.9
GaussianMLPValueFunction/dLoss           23
TotalEnvSteps                        774000
-----------------------------------  ----------------
2022-08-17 17:59:06 | [trpo_pendulum] epoch #645 | Saving snapshot...
2022-08-17 17:59:06 | [trpo_pendulum] epoch #645 | Saved
2022-08-17 17:59:06 | [trpo_pendulum] epoch #645 | Time 266.38 s
2022-08-17 17:59:06 | [trpo_pendulum] epoch #645 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -430.885
Evaluation/AverageReturn              -1047.41
Evaluation/Iteration                    645
Evaluation/MaxReturn                   -946.196
Evaluation/MinReturn                  -1105.33
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.5441
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42089
GaussianMLPPolicy/KL                      0.000506254
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -404.657
GaussianMLPPolicy/LossBefore           -404.781
GaussianMLPPolicy/dLoss                  -0.124695
GaussianMLPValueFunction/LossAfter    22723.8
GaussianMLPValueFunction/LossBefore   22745.2
GaussianMLPValueFunction/dLoss           21.4258
TotalEnvSteps                        775200
-----------------------------------  ----------------
2022-08-17 17:59:06 | [trpo_pendulum] epoch #646 | Saving snapshot...
2022-08-17 17:59:06 | [trpo_pendulum] epoch #646 | Saved
2022-08-17 17:59:06 | [trpo_pendulum] epoch #646 | Time 266.79 s
2022-08-17 17:59:06 | [trpo_pendulum] epoch #646 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -473.662
Evaluation/AverageReturn              -1117.33
Evaluation/Iteration                    646
Evaluation/MaxReturn                  -1041.83
Evaluation/MinReturn                  -1168.91
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     40.1349
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42072
GaussianMLPPolicy/KL                      0.00049907
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -429.941
GaussianMLPPolicy/LossBefore           -429.693
GaussianMLPPolicy/dLoss                   0.247345
GaussianMLPValueFunction/LossAfter    24558.3
GaussianMLPValueFunction/LossBefore   24581.1
GaussianMLPValueFunction/dLoss           22.8594
TotalEnvSteps                        776400
-----------------------------------  ---------------
2022-08-17 17:59:07 | [trpo_pendulum] epoch #647 | Saving snapshot...
2022-08-17 17:59:07 | [trpo_pendulum] epoch #647 | Saved
2022-08-17 17:59:07 | [trpo_pendulum] epoch #647 | Time 267.21 s
2022-08-17 17:59:07 | [trpo_pendulum] epoch #647 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -465.661
Evaluation/AverageReturn              -1087.52
Evaluation/Iteration                    647
Evaluation/MaxReturn                  -1021.36
Evaluation/MinReturn                  -1139.56
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     47.6222
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42055
GaussianMLPPolicy/KL                      0.000574874
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -410.303
GaussianMLPPolicy/LossBefore           -409.893
GaussianMLPPolicy/dLoss                   0.410156
GaussianMLPValueFunction/LossAfter    22875.5
GaussianMLPValueFunction/LossBefore   22896.5
GaussianMLPValueFunction/dLoss           21.0469
TotalEnvSteps                        777600
-----------------------------------  ----------------
2022-08-17 17:59:07 | [trpo_pendulum] epoch #648 | Saving snapshot...
2022-08-17 17:59:07 | [trpo_pendulum] epoch #648 | Saved
2022-08-17 17:59:07 | [trpo_pendulum] epoch #648 | Time 267.63 s
2022-08-17 17:59:07 | [trpo_pendulum] epoch #648 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -534.424
Evaluation/AverageReturn              -1135.85
Evaluation/Iteration                    648
Evaluation/MaxReturn                  -1102.31
Evaluation/MinReturn                  -1202.2
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     36.5089
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42033
GaussianMLPPolicy/KL                      0.000411945
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -401.084
GaussianMLPPolicy/LossBefore           -400.872
GaussianMLPPolicy/dLoss                   0.211151
GaussianMLPValueFunction/LossAfter    22765.3
GaussianMLPValueFunction/LossBefore   22785.8
GaussianMLPValueFunction/dLoss           20.4824
TotalEnvSteps                        778800
-----------------------------------  ----------------
2022-08-17 17:59:08 | [trpo_pendulum] epoch #649 | Saving snapshot...
2022-08-17 17:59:08 | [trpo_pendulum] epoch #649 | Saved
2022-08-17 17:59:08 | [trpo_pendulum] epoch #649 | Time 268.05 s
2022-08-17 17:59:08 | [trpo_pendulum] epoch #649 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -514.455
Evaluation/AverageReturn              -1093.33
Evaluation/Iteration                    649
Evaluation/MaxReturn                  -1012.61
Evaluation/MinReturn                  -1188.17
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     52.0212
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4201
GaussianMLPPolicy/KL                      0.000352332
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -381.263
GaussianMLPPolicy/LossBefore           -381.169
GaussianMLPPolicy/dLoss                   0.0939331
GaussianMLPValueFunction/LossAfter    21021
GaussianMLPValueFunction/LossBefore   21039.6
GaussianMLPValueFunction/dLoss           18.6719
TotalEnvSteps                        780000
-----------------------------------  ----------------
2022-08-17 17:59:08 | [trpo_pendulum] epoch #650 | Saving snapshot...
2022-08-17 17:59:08 | [trpo_pendulum] epoch #650 | Saved
2022-08-17 17:59:08 | [trpo_pendulum] epoch #650 | Time 268.48 s
2022-08-17 17:59:08 | [trpo_pendulum] epoch #650 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -542.275
Evaluation/AverageReturn              -1207.49
Evaluation/Iteration                    650
Evaluation/MaxReturn                  -1079.55
Evaluation/MinReturn                  -1294.23
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     85.9554
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4198
GaussianMLPPolicy/KL                      7.01337e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -447.432
GaussianMLPPolicy/LossBefore           -447.588
GaussianMLPPolicy/dLoss                  -0.15625
GaussianMLPValueFunction/LossAfter    27249.7
GaussianMLPValueFunction/LossBefore   27273.6
GaussianMLPValueFunction/dLoss           23.9199
TotalEnvSteps                        781200
-----------------------------------  ----------------
2022-08-17 17:59:09 | [trpo_pendulum] epoch #651 | Saving snapshot...
2022-08-17 17:59:09 | [trpo_pendulum] epoch #651 | Saved
2022-08-17 17:59:09 | [trpo_pendulum] epoch #651 | Time 268.89 s
2022-08-17 17:59:09 | [trpo_pendulum] epoch #651 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -381.783
Evaluation/AverageReturn               -940.229
Evaluation/Iteration                    651
Evaluation/MaxReturn                   -748.757
Evaluation/MinReturn                  -1095.41
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    108.356
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4195
GaussianMLPPolicy/KL                      3.81704e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -366.341
GaussianMLPPolicy/LossBefore           -366.355
GaussianMLPPolicy/dLoss                  -0.01474
GaussianMLPValueFunction/LossAfter    18729.8
GaussianMLPValueFunction/LossBefore   18746.4
GaussianMLPValueFunction/dLoss           16.5879
TotalEnvSteps                        782400
-----------------------------------  ----------------
2022-08-17 17:59:09 | [trpo_pendulum] epoch #652 | Saving snapshot...
2022-08-17 17:59:09 | [trpo_pendulum] epoch #652 | Saved
2022-08-17 17:59:09 | [trpo_pendulum] epoch #652 | Time 269.32 s
2022-08-17 17:59:09 | [trpo_pendulum] epoch #652 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -433.933
Evaluation/AverageReturn              -1033.73
Evaluation/Iteration                    652
Evaluation/MaxReturn                   -900.93
Evaluation/MinReturn                  -1165.42
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     96.5411
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4192
GaussianMLPPolicy/KL                      0.000141475
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -394.398
GaussianMLPPolicy/LossBefore           -394.173
GaussianMLPPolicy/dLoss                   0.225342
GaussianMLPValueFunction/LossAfter    21171.3
GaussianMLPValueFunction/LossBefore   21189.7
GaussianMLPValueFunction/dLoss           18.3535
TotalEnvSteps                        783600
-----------------------------------  ----------------
2022-08-17 17:59:09 | [trpo_pendulum] epoch #653 | Saving snapshot...
2022-08-17 17:59:09 | [trpo_pendulum] epoch #653 | Saved
2022-08-17 17:59:09 | [trpo_pendulum] epoch #653 | Time 269.74 s
2022-08-17 17:59:09 | [trpo_pendulum] epoch #653 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -459.095
Evaluation/AverageReturn              -1020.45
Evaluation/Iteration                    653
Evaluation/MaxReturn                   -961.537
Evaluation/MinReturn                  -1091.56
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     52.4784
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41893
GaussianMLPPolicy/KL                      1.22235e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -365.929
GaussianMLPPolicy/LossBefore           -365.969
GaussianMLPPolicy/dLoss                  -0.0406494
GaussianMLPValueFunction/LossAfter    19005.6
GaussianMLPValueFunction/LossBefore   19021.8
GaussianMLPValueFunction/dLoss           16.1523
TotalEnvSteps                        784800
-----------------------------------  ----------------
2022-08-17 17:59:10 | [trpo_pendulum] epoch #654 | Saving snapshot...
2022-08-17 17:59:10 | [trpo_pendulum] epoch #654 | Saved
2022-08-17 17:59:10 | [trpo_pendulum] epoch #654 | Time 270.16 s
2022-08-17 17:59:10 | [trpo_pendulum] epoch #654 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -407.075
Evaluation/AverageReturn               -993.127
Evaluation/Iteration                    654
Evaluation/MaxReturn                   -879.688
Evaluation/MinReturn                  -1061.79
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     76.4313
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41864
GaussianMLPPolicy/KL                      0.000128129
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -386.736
GaussianMLPPolicy/LossBefore           -386.471
GaussianMLPPolicy/dLoss                   0.265106
GaussianMLPValueFunction/LossAfter    20403.9
GaussianMLPValueFunction/LossBefore   20421
GaussianMLPValueFunction/dLoss           17.0996
TotalEnvSteps                        786000
-----------------------------------  ----------------
2022-08-17 17:59:10 | [trpo_pendulum] epoch #655 | Saving snapshot...
2022-08-17 17:59:10 | [trpo_pendulum] epoch #655 | Saved
2022-08-17 17:59:10 | [trpo_pendulum] epoch #655 | Time 270.58 s
2022-08-17 17:59:10 | [trpo_pendulum] epoch #655 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -405.347
Evaluation/AverageReturn               -974.47
Evaluation/Iteration                    655
Evaluation/MaxReturn                   -836.71
Evaluation/MinReturn                  -1045.47
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     79.2082
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41825
GaussianMLPPolicy/KL                      0.000153235
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -381.481
GaussianMLPPolicy/LossBefore           -381.35
GaussianMLPPolicy/dLoss                   0.130798
GaussianMLPValueFunction/LossAfter    18814.8
GaussianMLPValueFunction/LossBefore   18830.4
GaussianMLPValueFunction/dLoss           15.6133
TotalEnvSteps                        787200
-----------------------------------  ----------------
2022-08-17 17:59:11 | [trpo_pendulum] epoch #656 | Saving snapshot...
2022-08-17 17:59:11 | [trpo_pendulum] epoch #656 | Saved
2022-08-17 17:59:11 | [trpo_pendulum] epoch #656 | Time 270.98 s
2022-08-17 17:59:11 | [trpo_pendulum] epoch #656 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -348.273
Evaluation/AverageReturn               -869.583
Evaluation/Iteration                    656
Evaluation/MaxReturn                   -799.719
Evaluation/MinReturn                   -912.792
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     36.3843
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41791
GaussianMLPPolicy/KL                      0.000124561
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -335.287
GaussianMLPPolicy/LossBefore           -335.234
GaussianMLPPolicy/dLoss                   0.0533142
GaussianMLPValueFunction/LossAfter    16103.9
GaussianMLPValueFunction/LossBefore   16117.1
GaussianMLPValueFunction/dLoss           13.1455
TotalEnvSteps                        788400
-----------------------------------  ----------------
2022-08-17 17:59:11 | [trpo_pendulum] epoch #657 | Saving snapshot...
2022-08-17 17:59:11 | [trpo_pendulum] epoch #657 | Saved
2022-08-17 17:59:11 | [trpo_pendulum] epoch #657 | Time 271.40 s
2022-08-17 17:59:11 | [trpo_pendulum] epoch #657 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -547.582
Evaluation/AverageReturn              -1218.14
Evaluation/Iteration                    657
Evaluation/MaxReturn                  -1082.53
Evaluation/MinReturn                  -1321.68
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     80.968
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41766
GaussianMLPPolicy/KL                      3.95509e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -437.48
GaussianMLPPolicy/LossBefore           -437.506
GaussianMLPPolicy/dLoss                  -0.026001
GaussianMLPValueFunction/LossAfter    27749.9
GaussianMLPValueFunction/LossBefore   27771.8
GaussianMLPValueFunction/dLoss           21.9297
TotalEnvSteps                        789600
-----------------------------------  ----------------
2022-08-17 17:59:11 | [trpo_pendulum] epoch #658 | Saving snapshot...
2022-08-17 17:59:11 | [trpo_pendulum] epoch #658 | Saved
2022-08-17 17:59:11 | [trpo_pendulum] epoch #658 | Time 271.81 s
2022-08-17 17:59:11 | [trpo_pendulum] epoch #658 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -439.784
Evaluation/AverageReturn               -991.851
Evaluation/Iteration                    658
Evaluation/MaxReturn                   -898.378
Evaluation/MinReturn                  -1101.57
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     61.8002
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41749
GaussianMLPPolicy/KL                      6.06822e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -354.548
GaussianMLPPolicy/LossBefore           -354.499
GaussianMLPPolicy/dLoss                   0.0482178
GaussianMLPValueFunction/LossAfter    17798.1
GaussianMLPValueFunction/LossBefore   17812.4
GaussianMLPValueFunction/dLoss           14.3535
TotalEnvSteps                        790800
-----------------------------------  ----------------
2022-08-17 17:59:12 | [trpo_pendulum] epoch #659 | Saving snapshot...
2022-08-17 17:59:12 | [trpo_pendulum] epoch #659 | Saved
2022-08-17 17:59:12 | [trpo_pendulum] epoch #659 | Time 272.23 s
2022-08-17 17:59:12 | [trpo_pendulum] epoch #659 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -416.662
Evaluation/AverageReturn               -952.448
Evaluation/Iteration                    659
Evaluation/MaxReturn                   -863.042
Evaluation/MinReturn                  -1016.89
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     62.9906
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41731
GaussianMLPPolicy/KL                      8.18232e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -347.803
GaussianMLPPolicy/LossBefore           -347.729
GaussianMLPPolicy/dLoss                   0.0743408
GaussianMLPValueFunction/LossAfter    16646.3
GaussianMLPValueFunction/LossBefore   16659.5
GaussianMLPValueFunction/dLoss           13.2148
TotalEnvSteps                        792000
-----------------------------------  ----------------
2022-08-17 17:59:12 | [trpo_pendulum] epoch #660 | Saving snapshot...
2022-08-17 17:59:12 | [trpo_pendulum] epoch #660 | Saved
2022-08-17 17:59:12 | [trpo_pendulum] epoch #660 | Time 272.63 s
2022-08-17 17:59:12 | [trpo_pendulum] epoch #660 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -377.453
Evaluation/AverageReturn               -887.612
Evaluation/Iteration                    660
Evaluation/MaxReturn                   -795.221
Evaluation/MinReturn                  -1015.49
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     65.3089
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41718
GaussianMLPPolicy/KL                      2.07235e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -325.421
GaussianMLPPolicy/LossBefore           -325.448
GaussianMLPPolicy/dLoss                  -0.0262451
GaussianMLPValueFunction/LossAfter    14905.4
GaussianMLPValueFunction/LossBefore   14917
GaussianMLPValueFunction/dLoss           11.6309
TotalEnvSteps                        793200
-----------------------------------  ----------------
2022-08-17 17:59:13 | [trpo_pendulum] epoch #661 | Saving snapshot...
2022-08-17 17:59:13 | [trpo_pendulum] epoch #661 | Saved
2022-08-17 17:59:13 | [trpo_pendulum] epoch #661 | Time 273.05 s
2022-08-17 17:59:13 | [trpo_pendulum] epoch #661 | EpochTime 0.42 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -380.01
Evaluation/AverageReturn               -902.728
Evaluation/Iteration                    661
Evaluation/MaxReturn                   -889.685
Evaluation/MinReturn                   -933.915
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     14.8532
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41718
GaussianMLPPolicy/KL                      9.0182e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -327.652
GaussianMLPPolicy/LossBefore           -327.494
GaussianMLPPolicy/dLoss                   0.158325
GaussianMLPValueFunction/LossAfter    15826.3
GaussianMLPValueFunction/LossBefore   15838.3
GaussianMLPValueFunction/dLoss           12.0146
TotalEnvSteps                        794400
-----------------------------------  ---------------
2022-08-17 17:59:13 | [trpo_pendulum] epoch #662 | Saving snapshot...
2022-08-17 17:59:13 | [trpo_pendulum] epoch #662 | Saved
2022-08-17 17:59:13 | [trpo_pendulum] epoch #662 | Time 273.47 s
2022-08-17 17:59:13 | [trpo_pendulum] epoch #662 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -474.156
Evaluation/AverageReturn              -1058.18
Evaluation/Iteration                    662
Evaluation/MaxReturn                   -897.138
Evaluation/MinReturn                  -1237.68
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    115.846
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41704
GaussianMLPPolicy/KL                      2.32017e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -392.106
GaussianMLPPolicy/LossBefore           -392.138
GaussianMLPPolicy/dLoss                  -0.0315857
GaussianMLPValueFunction/LossAfter    20979.9
GaussianMLPValueFunction/LossBefore   20995.3
GaussianMLPValueFunction/dLoss           15.3867
TotalEnvSteps                        795600
-----------------------------------  ----------------
2022-08-17 17:59:14 | [trpo_pendulum] epoch #663 | Saving snapshot...
2022-08-17 17:59:14 | [trpo_pendulum] epoch #663 | Saved
2022-08-17 17:59:14 | [trpo_pendulum] epoch #663 | Time 273.89 s
2022-08-17 17:59:14 | [trpo_pendulum] epoch #663 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -627.229
Evaluation/AverageReturn              -1400.16
Evaluation/Iteration                    663
Evaluation/MaxReturn                  -1322.43
Evaluation/MinReturn                  -1474.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     51.8795
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41682
GaussianMLPPolicy/KL                      4.02343e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -523.59
GaussianMLPPolicy/LossBefore           -523.473
GaussianMLPPolicy/dLoss                   0.117126
GaussianMLPValueFunction/LossAfter    36976.3
GaussianMLPValueFunction/LossBefore   37004.2
GaussianMLPValueFunction/dLoss           27.8906
TotalEnvSteps                        796800
-----------------------------------  ----------------
2022-08-17 17:59:14 | [trpo_pendulum] epoch #664 | Saving snapshot...
2022-08-17 17:59:14 | [trpo_pendulum] epoch #664 | Saved
2022-08-17 17:59:14 | [trpo_pendulum] epoch #664 | Time 274.30 s
2022-08-17 17:59:14 | [trpo_pendulum] epoch #664 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -684.175
Evaluation/AverageReturn              -1547.18
Evaluation/Iteration                    664
Evaluation/MaxReturn                  -1341.17
Evaluation/MinReturn                  -1789.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    135.125
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41655
GaussianMLPPolicy/KL                      3.59485e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -585.294
GaussianMLPPolicy/LossBefore           -585.301
GaussianMLPPolicy/dLoss                  -0.00726318
GaussianMLPValueFunction/LossAfter    46619.1
GaussianMLPValueFunction/LossBefore   46657.3
GaussianMLPValueFunction/dLoss           38.2031
TotalEnvSteps                        798000
-----------------------------------  ----------------
2022-08-17 17:59:14 | [trpo_pendulum] epoch #665 | Saving snapshot...
2022-08-17 17:59:14 | [trpo_pendulum] epoch #665 | Saved
2022-08-17 17:59:14 | [trpo_pendulum] epoch #665 | Time 274.73 s
2022-08-17 17:59:14 | [trpo_pendulum] epoch #665 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -414.584
Evaluation/AverageReturn               -977.796
Evaluation/Iteration                    665
Evaluation/MaxReturn                   -881.847
Evaluation/MinReturn                  -1031.07
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     46.634
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41634
GaussianMLPPolicy/KL                      5.82251e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -362.988
GaussianMLPPolicy/LossBefore           -362.868
GaussianMLPPolicy/dLoss                   0.120392
GaussianMLPValueFunction/LossAfter    18025.5
GaussianMLPValueFunction/LossBefore   18041
GaussianMLPValueFunction/dLoss           15.4844
TotalEnvSteps                        799200
-----------------------------------  ----------------
2022-08-17 17:59:15 | [trpo_pendulum] epoch #666 | Saving snapshot...
2022-08-17 17:59:15 | [trpo_pendulum] epoch #666 | Saved
2022-08-17 17:59:15 | [trpo_pendulum] epoch #666 | Time 275.14 s
2022-08-17 17:59:15 | [trpo_pendulum] epoch #666 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -358.156
Evaluation/AverageReturn               -852.685
Evaluation/Iteration                    666
Evaluation/MaxReturn                   -799.146
Evaluation/MinReturn                   -898.459
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     36.9581
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41622
GaussianMLPPolicy/KL                      0.000143218
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -310.469
GaussianMLPPolicy/LossBefore           -310.244
GaussianMLPPolicy/dLoss                   0.225403
GaussianMLPValueFunction/LossAfter    14156.8
GaussianMLPValueFunction/LossBefore   14168.8
GaussianMLPValueFunction/dLoss           11.9414
TotalEnvSteps                        800400
-----------------------------------  ----------------
2022-08-17 17:59:15 | [trpo_pendulum] epoch #667 | Saving snapshot...
2022-08-17 17:59:15 | [trpo_pendulum] epoch #667 | Saved
2022-08-17 17:59:15 | [trpo_pendulum] epoch #667 | Time 275.56 s
2022-08-17 17:59:15 | [trpo_pendulum] epoch #667 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -617.063
Evaluation/AverageReturn              -1398.17
Evaluation/Iteration                    667
Evaluation/MaxReturn                  -1265.25
Evaluation/MinReturn                  -1492.32
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     77.0476
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41614
GaussianMLPPolicy/KL                      7.34057e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -518.608
GaussianMLPPolicy/LossBefore           -518.575
GaussianMLPPolicy/dLoss                   0.0327148
GaussianMLPValueFunction/LossAfter    37265
GaussianMLPValueFunction/LossBefore   37295.7
GaussianMLPValueFunction/dLoss           30.6992
TotalEnvSteps                        801600
-----------------------------------  ----------------
2022-08-17 17:59:16 | [trpo_pendulum] epoch #668 | Saving snapshot...
2022-08-17 17:59:16 | [trpo_pendulum] epoch #668 | Saved
2022-08-17 17:59:16 | [trpo_pendulum] epoch #668 | Time 275.99 s
2022-08-17 17:59:16 | [trpo_pendulum] epoch #668 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -416.034
Evaluation/AverageReturn               -959.029
Evaluation/Iteration                    668
Evaluation/MaxReturn                   -857.165
Evaluation/MinReturn                  -1066.7
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     68.2558
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41612
GaussianMLPPolicy/KL                      4.11919e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -346.361
GaussianMLPPolicy/LossBefore           -346.378
GaussianMLPPolicy/dLoss                  -0.0167236
GaussianMLPValueFunction/LossAfter    17165.7
GaussianMLPValueFunction/LossBefore   17180.3
GaussianMLPValueFunction/dLoss           14.5938
TotalEnvSteps                        802800
-----------------------------------  ----------------
2022-08-17 17:59:16 | [trpo_pendulum] epoch #669 | Saving snapshot...
2022-08-17 17:59:16 | [trpo_pendulum] epoch #669 | Saved
2022-08-17 17:59:16 | [trpo_pendulum] epoch #669 | Time 276.41 s
2022-08-17 17:59:16 | [trpo_pendulum] epoch #669 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -478.25
Evaluation/AverageReturn              -1092.14
Evaluation/Iteration                    669
Evaluation/MaxReturn                  -1047.83
Evaluation/MinReturn                  -1173.78
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     46.7186
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4162
GaussianMLPPolicy/KL                      2.44279e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -393.291
GaussianMLPPolicy/LossBefore           -393.297
GaussianMLPPolicy/dLoss                  -0.00598145
GaussianMLPValueFunction/LossAfter    22124.6
GaussianMLPValueFunction/LossBefore   22142.9
GaussianMLPValueFunction/dLoss           18.3047
TotalEnvSteps                        804000
-----------------------------------  ----------------
2022-08-17 17:59:16 | [trpo_pendulum] epoch #670 | Saving snapshot...
2022-08-17 17:59:16 | [trpo_pendulum] epoch #670 | Saved
2022-08-17 17:59:16 | [trpo_pendulum] epoch #670 | Time 276.84 s
2022-08-17 17:59:16 | [trpo_pendulum] epoch #670 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -390.283
Evaluation/AverageReturn               -926.835
Evaluation/Iteration                    670
Evaluation/MaxReturn                   -751.879
Evaluation/MinReturn                  -1035.53
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     98.9319
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41619
GaussianMLPPolicy/KL                      7.26624e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -353.054
GaussianMLPPolicy/LossBefore           -352.943
GaussianMLPPolicy/dLoss                   0.110962
GaussianMLPValueFunction/LossAfter    16666
GaussianMLPValueFunction/LossBefore   16679.8
GaussianMLPValueFunction/dLoss           13.791
TotalEnvSteps                        805200
-----------------------------------  ----------------
2022-08-17 17:59:17 | [trpo_pendulum] epoch #671 | Saving snapshot...
2022-08-17 17:59:17 | [trpo_pendulum] epoch #671 | Saved
2022-08-17 17:59:17 | [trpo_pendulum] epoch #671 | Time 277.27 s
2022-08-17 17:59:17 | [trpo_pendulum] epoch #671 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -482.763
Evaluation/AverageReturn              -1089.18
Evaluation/Iteration                    671
Evaluation/MaxReturn                   -962.248
Evaluation/MinReturn                  -1223.43
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    112.015
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41632
GaussianMLPPolicy/KL                      2.33803e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -383.994
GaussianMLPPolicy/LossBefore           -384.008
GaussianMLPPolicy/dLoss                  -0.013916
GaussianMLPValueFunction/LossAfter    22434.7
GaussianMLPValueFunction/LossBefore   22452.7
GaussianMLPValueFunction/dLoss           17.9609
TotalEnvSteps                        806400
-----------------------------------  ----------------
2022-08-17 17:59:17 | [trpo_pendulum] epoch #672 | Saving snapshot...
2022-08-17 17:59:17 | [trpo_pendulum] epoch #672 | Saved
2022-08-17 17:59:17 | [trpo_pendulum] epoch #672 | Time 277.70 s
2022-08-17 17:59:17 | [trpo_pendulum] epoch #672 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -602.17
Evaluation/AverageReturn              -1378.41
Evaluation/Iteration                    672
Evaluation/MaxReturn                  -1300.12
Evaluation/MinReturn                  -1503.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     80.9896
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41635
GaussianMLPPolicy/KL                      7.09007e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -524.934
GaussianMLPPolicy/LossBefore           -524.835
GaussianMLPPolicy/dLoss                   0.0990601
GaussianMLPValueFunction/LossAfter    36687.9
GaussianMLPValueFunction/LossBefore   36717.9
GaussianMLPValueFunction/dLoss           30.0508
TotalEnvSteps                        807600
-----------------------------------  ----------------
2022-08-17 17:59:18 | [trpo_pendulum] epoch #673 | Saving snapshot...
2022-08-17 17:59:18 | [trpo_pendulum] epoch #673 | Saved
2022-08-17 17:59:18 | [trpo_pendulum] epoch #673 | Time 278.12 s
2022-08-17 17:59:18 | [trpo_pendulum] epoch #673 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -538.943
Evaluation/AverageReturn              -1240.44
Evaluation/Iteration                    673
Evaluation/MaxReturn                  -1176.92
Evaluation/MinReturn                  -1285.51
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     47.2283
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41635
GaussianMLPPolicy/KL                      5.42953e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -466.183
GaussianMLPPolicy/LossBefore           -466.033
GaussianMLPPolicy/dLoss                   0.150421
GaussianMLPValueFunction/LossAfter    29421.6
GaussianMLPValueFunction/LossBefore   29446.6
GaussianMLPValueFunction/dLoss           24.9609
TotalEnvSteps                        808800
-----------------------------------  ----------------
2022-08-17 17:59:18 | [trpo_pendulum] epoch #674 | Saving snapshot...
2022-08-17 17:59:18 | [trpo_pendulum] epoch #674 | Saved
2022-08-17 17:59:18 | [trpo_pendulum] epoch #674 | Time 278.54 s
2022-08-17 17:59:18 | [trpo_pendulum] epoch #674 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -626.802
Evaluation/AverageReturn              -1422.22
Evaluation/Iteration                    674
Evaluation/MaxReturn                  -1354.52
Evaluation/MinReturn                  -1459.06
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     33.447
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41647
GaussianMLPPolicy/KL                      6.57879e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -520.135
GaussianMLPPolicy/LossBefore           -520.02
GaussianMLPPolicy/dLoss                   0.114868
GaussianMLPValueFunction/LossAfter    38560.5
GaussianMLPValueFunction/LossBefore   38594.3
GaussianMLPValueFunction/dLoss           33.832
TotalEnvSteps                        810000
-----------------------------------  ----------------
2022-08-17 17:59:19 | [trpo_pendulum] epoch #675 | Saving snapshot...
2022-08-17 17:59:19 | [trpo_pendulum] epoch #675 | Saved
2022-08-17 17:59:19 | [trpo_pendulum] epoch #675 | Time 278.97 s
2022-08-17 17:59:19 | [trpo_pendulum] epoch #675 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -695.446
Evaluation/AverageReturn              -1538.56
Evaluation/Iteration                    675
Evaluation/MaxReturn                  -1475.94
Evaluation/MinReturn                  -1610.64
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.5418
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41641
GaussianMLPPolicy/KL                      2.08866e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -579.172
GaussianMLPPolicy/LossBefore           -579.193
GaussianMLPPolicy/dLoss                  -0.0211792
GaussianMLPValueFunction/LossAfter    44538.6
GaussianMLPValueFunction/LossBefore   44579.9
GaussianMLPValueFunction/dLoss           41.3086
TotalEnvSteps                        811200
-----------------------------------  ----------------
2022-08-17 17:59:19 | [trpo_pendulum] epoch #676 | Saving snapshot...
2022-08-17 17:59:19 | [trpo_pendulum] epoch #676 | Saved
2022-08-17 17:59:19 | [trpo_pendulum] epoch #676 | Time 279.38 s
2022-08-17 17:59:19 | [trpo_pendulum] epoch #676 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -422.569
Evaluation/AverageReturn               -980.122
Evaluation/Iteration                    676
Evaluation/MaxReturn                   -869.007
Evaluation/MinReturn                  -1080.19
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     91.4755
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41624
GaussianMLPPolicy/KL                      0.000132175
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -371.695
GaussianMLPPolicy/LossBefore           -371.434
GaussianMLPPolicy/dLoss                   0.261444
GaussianMLPValueFunction/LossAfter    18515.4
GaussianMLPValueFunction/LossBefore   18533
GaussianMLPValueFunction/dLoss           17.6074
TotalEnvSteps                        812400
-----------------------------------  ----------------
2022-08-17 17:59:19 | [trpo_pendulum] epoch #677 | Saving snapshot...
2022-08-17 17:59:19 | [trpo_pendulum] epoch #677 | Saved
2022-08-17 17:59:19 | [trpo_pendulum] epoch #677 | Time 279.82 s
2022-08-17 17:59:19 | [trpo_pendulum] epoch #677 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -630.415
Evaluation/AverageReturn              -1403.46
Evaluation/Iteration                    677
Evaluation/MaxReturn                  -1317.83
Evaluation/MinReturn                  -1539.38
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     79.739
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41628
GaussianMLPPolicy/KL                      1.93789e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -497.796
GaussianMLPPolicy/LossBefore           -497.744
GaussianMLPPolicy/dLoss                   0.0514526
GaussianMLPValueFunction/LossAfter    36648
GaussianMLPValueFunction/LossBefore   36682.4
GaussianMLPValueFunction/dLoss           34.4219
TotalEnvSteps                        813600
-----------------------------------  ----------------
2022-08-17 17:59:20 | [trpo_pendulum] epoch #678 | Saving snapshot...
2022-08-17 17:59:20 | [trpo_pendulum] epoch #678 | Saved
2022-08-17 17:59:20 | [trpo_pendulum] epoch #678 | Time 280.26 s
2022-08-17 17:59:20 | [trpo_pendulum] epoch #678 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -344.539
Evaluation/AverageReturn               -831.795
Evaluation/Iteration                    678
Evaluation/MaxReturn                   -750.048
Evaluation/MinReturn                   -962.555
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     77.2126
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41624
GaussianMLPPolicy/KL                      1.86146e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -317.562
GaussianMLPPolicy/LossBefore           -317.495
GaussianMLPPolicy/dLoss                   0.066925
GaussianMLPValueFunction/LossAfter    13354.1
GaussianMLPValueFunction/LossBefore   13367
GaussianMLPValueFunction/dLoss           12.8799
TotalEnvSteps                        814800
-----------------------------------  ----------------
2022-08-17 17:59:20 | [trpo_pendulum] epoch #679 | Saving snapshot...
2022-08-17 17:59:20 | [trpo_pendulum] epoch #679 | Saved
2022-08-17 17:59:20 | [trpo_pendulum] epoch #679 | Time 280.68 s
2022-08-17 17:59:20 | [trpo_pendulum] epoch #679 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -403.673
Evaluation/AverageReturn               -925.147
Evaluation/Iteration                    679
Evaluation/MaxReturn                   -866.987
Evaluation/MinReturn                  -1006.39
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.3249
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41618
GaussianMLPPolicy/KL                      6.75487e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -337.545
GaussianMLPPolicy/LossBefore           -337.409
GaussianMLPPolicy/dLoss                   0.136444
GaussianMLPValueFunction/LossAfter    15707.6
GaussianMLPValueFunction/LossBefore   15721.9
GaussianMLPValueFunction/dLoss           14.3652
TotalEnvSteps                        816000
-----------------------------------  ----------------
2022-08-17 17:59:21 | [trpo_pendulum] epoch #680 | Saving snapshot...
2022-08-17 17:59:21 | [trpo_pendulum] epoch #680 | Saved
2022-08-17 17:59:21 | [trpo_pendulum] epoch #680 | Time 281.10 s
2022-08-17 17:59:21 | [trpo_pendulum] epoch #680 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -644.343
Evaluation/AverageReturn              -1430.37
Evaluation/Iteration                    680
Evaluation/MaxReturn                  -1341.57
Evaluation/MinReturn                  -1565.97
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     76.669
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41603
GaussianMLPPolicy/KL                      8.27552e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -531.026
GaussianMLPPolicy/LossBefore           -531.015
GaussianMLPPolicy/dLoss                   0.0118408
GaussianMLPValueFunction/LossAfter    38153.1
GaussianMLPValueFunction/LossBefore   38187.4
GaussianMLPValueFunction/dLoss           34.25
TotalEnvSteps                        817200
-----------------------------------  ----------------
2022-08-17 17:59:21 | [trpo_pendulum] epoch #681 | Saving snapshot...
2022-08-17 17:59:21 | [trpo_pendulum] epoch #681 | Saved
2022-08-17 17:59:21 | [trpo_pendulum] epoch #681 | Time 281.53 s
2022-08-17 17:59:21 | [trpo_pendulum] epoch #681 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -414.027
Evaluation/AverageReturn               -950.717
Evaluation/Iteration                    681
Evaluation/MaxReturn                   -853.75
Evaluation/MinReturn                  -1037.83
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     68.9003
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41587
GaussianMLPPolicy/KL                      3.41073e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -349.402
GaussianMLPPolicy/LossBefore           -349.269
GaussianMLPPolicy/dLoss                   0.132843
GaussianMLPValueFunction/LossAfter    16811.1
GaussianMLPValueFunction/LossBefore   16826.6
GaussianMLPValueFunction/dLoss           15.4453
TotalEnvSteps                        818400
-----------------------------------  ----------------
2022-08-17 17:59:22 | [trpo_pendulum] epoch #682 | Saving snapshot...
2022-08-17 17:59:22 | [trpo_pendulum] epoch #682 | Saved
2022-08-17 17:59:22 | [trpo_pendulum] epoch #682 | Time 281.94 s
2022-08-17 17:59:22 | [trpo_pendulum] epoch #682 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -537.15
Evaluation/AverageReturn              -1216.69
Evaluation/Iteration                    682
Evaluation/MaxReturn                  -1163.06
Evaluation/MinReturn                  -1276.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     42.78
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41565
GaussianMLPPolicy/KL                      5.12839e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -453.175
GaussianMLPPolicy/LossBefore           -453.154
GaussianMLPPolicy/dLoss                   0.0209351
GaussianMLPValueFunction/LossAfter    27697.5
GaussianMLPValueFunction/LossBefore   27722.2
GaussianMLPValueFunction/dLoss           24.6992
TotalEnvSteps                        819600
-----------------------------------  ----------------
2022-08-17 17:59:22 | [trpo_pendulum] epoch #683 | Saving snapshot...
2022-08-17 17:59:22 | [trpo_pendulum] epoch #683 | Saved
2022-08-17 17:59:22 | [trpo_pendulum] epoch #683 | Time 282.35 s
2022-08-17 17:59:22 | [trpo_pendulum] epoch #683 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -345.307
Evaluation/AverageReturn               -830.244
Evaluation/Iteration                    683
Evaluation/MaxReturn                   -753.978
Evaluation/MinReturn                   -912.571
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     66.5625
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4155
GaussianMLPPolicy/KL                      7.33873e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -305.347
GaussianMLPPolicy/LossBefore           -305.315
GaussianMLPPolicy/dLoss                   0.0315857
GaussianMLPValueFunction/LossAfter    13214.7
GaussianMLPValueFunction/LossBefore   13226.7
GaussianMLPValueFunction/dLoss           11.9727
TotalEnvSteps                        820800
-----------------------------------  ----------------
2022-08-17 17:59:22 | [trpo_pendulum] epoch #684 | Saving snapshot...
2022-08-17 17:59:22 | [trpo_pendulum] epoch #684 | Saved
2022-08-17 17:59:22 | [trpo_pendulum] epoch #684 | Time 282.77 s
2022-08-17 17:59:22 | [trpo_pendulum] epoch #684 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -591.308
Evaluation/AverageReturn              -1365.81
Evaluation/Iteration                    684
Evaluation/MaxReturn                  -1182.09
Evaluation/MinReturn                  -1440.81
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     94.0544
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41536
GaussianMLPPolicy/KL                      0.00040731
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -516.596
GaussianMLPPolicy/LossBefore           -515.17
GaussianMLPPolicy/dLoss                   1.42535
GaussianMLPValueFunction/LossAfter    36072.8
GaussianMLPValueFunction/LossBefore   36104.4
GaussianMLPValueFunction/dLoss           31.5508
TotalEnvSteps                        822000
-----------------------------------  ---------------
2022-08-17 17:59:23 | [trpo_pendulum] epoch #685 | Saving snapshot...
2022-08-17 17:59:23 | [trpo_pendulum] epoch #685 | Saved
2022-08-17 17:59:23 | [trpo_pendulum] epoch #685 | Time 283.18 s
2022-08-17 17:59:23 | [trpo_pendulum] epoch #685 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -678.635
Evaluation/AverageReturn              -1503.26
Evaluation/Iteration                    685
Evaluation/MaxReturn                  -1373.43
Evaluation/MinReturn                  -1653.02
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     81.6311
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4152
GaussianMLPPolicy/KL                      0.000149368
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -553.454
GaussianMLPPolicy/LossBefore           -553.516
GaussianMLPPolicy/dLoss                  -0.0621338
GaussianMLPValueFunction/LossAfter    42034.6
GaussianMLPValueFunction/LossBefore   42073.2
GaussianMLPValueFunction/dLoss           38.5898
TotalEnvSteps                        823200
-----------------------------------  ----------------
2022-08-17 17:59:23 | [trpo_pendulum] epoch #686 | Saving snapshot...
2022-08-17 17:59:23 | [trpo_pendulum] epoch #686 | Saved
2022-08-17 17:59:23 | [trpo_pendulum] epoch #686 | Time 283.59 s
2022-08-17 17:59:23 | [trpo_pendulum] epoch #686 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -442.429
Evaluation/AverageReturn              -1011.82
Evaluation/Iteration                    686
Evaluation/MaxReturn                   -860.629
Evaluation/MinReturn                  -1074.24
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     75.863
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41499
GaussianMLPPolicy/KL                      0.000501039
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -375.276
GaussianMLPPolicy/LossBefore           -374.621
GaussianMLPPolicy/dLoss                   0.655487
GaussianMLPValueFunction/LossAfter    18696.4
GaussianMLPValueFunction/LossBefore   18714
GaussianMLPValueFunction/dLoss           17.5957
TotalEnvSteps                        824400
-----------------------------------  ----------------
2022-08-17 17:59:24 | [trpo_pendulum] epoch #687 | Saving snapshot...
2022-08-17 17:59:24 | [trpo_pendulum] epoch #687 | Saved
2022-08-17 17:59:24 | [trpo_pendulum] epoch #687 | Time 284.00 s
2022-08-17 17:59:24 | [trpo_pendulum] epoch #687 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -381.175
Evaluation/AverageReturn               -924.91
Evaluation/Iteration                    687
Evaluation/MaxReturn                   -881.934
Evaluation/MinReturn                   -992.112
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     39.8919
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41493
GaussianMLPPolicy/KL                      0.000651592
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -340.05
GaussianMLPPolicy/LossBefore           -339.602
GaussianMLPPolicy/dLoss                   0.447845
GaussianMLPValueFunction/LossAfter    16666.5
GaussianMLPValueFunction/LossBefore   16681.9
GaussianMLPValueFunction/dLoss           15.3613
TotalEnvSteps                        825600
-----------------------------------  ----------------
2022-08-17 17:59:24 | [trpo_pendulum] epoch #688 | Saving snapshot...
2022-08-17 17:59:24 | [trpo_pendulum] epoch #688 | Saved
2022-08-17 17:59:24 | [trpo_pendulum] epoch #688 | Time 284.42 s
2022-08-17 17:59:24 | [trpo_pendulum] epoch #688 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -433.04
Evaluation/AverageReturn              -1033.21
Evaluation/Iteration                    688
Evaluation/MaxReturn                   -959.304
Evaluation/MinReturn                  -1116.64
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     51.4283
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41478
GaussianMLPPolicy/KL                      0.000215408
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -398.385
GaussianMLPPolicy/LossBefore           -398.589
GaussianMLPPolicy/dLoss                  -0.203735
GaussianMLPValueFunction/LossAfter    20687.4
GaussianMLPValueFunction/LossBefore   20705.9
GaussianMLPValueFunction/dLoss           18.4688
TotalEnvSteps                        826800
-----------------------------------  ----------------
2022-08-17 17:59:24 | [trpo_pendulum] epoch #689 | Saving snapshot...
2022-08-17 17:59:24 | [trpo_pendulum] epoch #689 | Saved
2022-08-17 17:59:24 | [trpo_pendulum] epoch #689 | Time 284.82 s
2022-08-17 17:59:24 | [trpo_pendulum] epoch #689 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -505.252
Evaluation/AverageReturn              -1095.72
Evaluation/Iteration                    689
Evaluation/MaxReturn                   -863.866
Evaluation/MinReturn                  -1197.84
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    112.298
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41463
GaussianMLPPolicy/KL                      9.15897e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -384.771
GaussianMLPPolicy/LossBefore           -384.78
GaussianMLPPolicy/dLoss                  -0.00881958
GaussianMLPValueFunction/LossAfter    21277.6
GaussianMLPValueFunction/LossBefore   21296.1
GaussianMLPValueFunction/dLoss           18.5098
TotalEnvSteps                        828000
-----------------------------------  ----------------
2022-08-17 17:59:25 | [trpo_pendulum] epoch #690 | Saving snapshot...
2022-08-17 17:59:25 | [trpo_pendulum] epoch #690 | Saved
2022-08-17 17:59:25 | [trpo_pendulum] epoch #690 | Time 285.23 s
2022-08-17 17:59:25 | [trpo_pendulum] epoch #690 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -424.814
Evaluation/AverageReturn               -995.696
Evaluation/Iteration                    690
Evaluation/MaxReturn                   -894.428
Evaluation/MinReturn                  -1156.49
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     93.2017
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4145
GaussianMLPPolicy/KL                      9.38004e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -370.174
GaussianMLPPolicy/LossBefore           -370.178
GaussianMLPPolicy/dLoss                  -0.00460815
GaussianMLPValueFunction/LossAfter    18906.7
GaussianMLPValueFunction/LossBefore   18923
GaussianMLPValueFunction/dLoss           16.3418
TotalEnvSteps                        829200
-----------------------------------  ----------------
2022-08-17 17:59:25 | [trpo_pendulum] epoch #691 | Saving snapshot...
2022-08-17 17:59:25 | [trpo_pendulum] epoch #691 | Saved
2022-08-17 17:59:25 | [trpo_pendulum] epoch #691 | Time 285.64 s
2022-08-17 17:59:25 | [trpo_pendulum] epoch #691 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -423.031
Evaluation/AverageReturn               -978.193
Evaluation/Iteration                    691
Evaluation/MaxReturn                   -801.65
Evaluation/MinReturn                  -1071.21
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     83.6018
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41439
GaussianMLPPolicy/KL                      5.47974e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -357.208
GaussianMLPPolicy/LossBefore           -357.059
GaussianMLPPolicy/dLoss                   0.148987
GaussianMLPValueFunction/LossAfter    17510.4
GaussianMLPValueFunction/LossBefore   17525.2
GaussianMLPValueFunction/dLoss           14.875
TotalEnvSteps                        830400
-----------------------------------  ----------------
2022-08-17 17:59:26 | [trpo_pendulum] epoch #692 | Saving snapshot...
2022-08-17 17:59:26 | [trpo_pendulum] epoch #692 | Saved
2022-08-17 17:59:26 | [trpo_pendulum] epoch #692 | Time 286.05 s
2022-08-17 17:59:26 | [trpo_pendulum] epoch #692 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -559.15
Evaluation/AverageReturn              -1192.66
Evaluation/Iteration                    692
Evaluation/MaxReturn                  -1084.98
Evaluation/MinReturn                  -1302.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     86.6455
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41427
GaussianMLPPolicy/KL                      5.58784e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -416.084
GaussianMLPPolicy/LossBefore           -416.093
GaussianMLPPolicy/dLoss                  -0.00961304
GaussianMLPValueFunction/LossAfter    24648.2
GaussianMLPValueFunction/LossBefore   24668.6
GaussianMLPValueFunction/dLoss           20.3672
TotalEnvSteps                        831600
-----------------------------------  ----------------
2022-08-17 17:59:26 | [trpo_pendulum] epoch #693 | Saving snapshot...
2022-08-17 17:59:26 | [trpo_pendulum] epoch #693 | Saved
2022-08-17 17:59:26 | [trpo_pendulum] epoch #693 | Time 286.45 s
2022-08-17 17:59:26 | [trpo_pendulum] epoch #693 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -390.482
Evaluation/AverageReturn               -909.493
Evaluation/Iteration                    693
Evaluation/MaxReturn                   -780.105
Evaluation/MinReturn                  -1052.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     78.8872
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41421
GaussianMLPPolicy/KL                      8.72801e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -329.392
GaussianMLPPolicy/LossBefore           -329.366
GaussianMLPPolicy/dLoss                   0.0257874
GaussianMLPValueFunction/LossAfter    16145.1
GaussianMLPValueFunction/LossBefore   16158.6
GaussianMLPValueFunction/dLoss           13.4385
TotalEnvSteps                        832800
-----------------------------------  ----------------
2022-08-17 17:59:26 | [trpo_pendulum] epoch #694 | Saving snapshot...
2022-08-17 17:59:27 | [trpo_pendulum] epoch #694 | Saved
2022-08-17 17:59:27 | [trpo_pendulum] epoch #694 | Time 286.86 s
2022-08-17 17:59:27 | [trpo_pendulum] epoch #694 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -438.921
Evaluation/AverageReturn              -1015.84
Evaluation/Iteration                    694
Evaluation/MaxReturn                   -944.553
Evaluation/MinReturn                  -1072.86
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     38.5604
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41399
GaussianMLPPolicy/KL                      7.35847e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -386.791
GaussianMLPPolicy/LossBefore           -386.632
GaussianMLPPolicy/dLoss                   0.158447
GaussianMLPValueFunction/LossAfter    18778.9
GaussianMLPValueFunction/LossBefore   18794.1
GaussianMLPValueFunction/dLoss           15.2832
TotalEnvSteps                        834000
-----------------------------------  ----------------
2022-08-17 17:59:27 | [trpo_pendulum] epoch #695 | Saving snapshot...
2022-08-17 17:59:27 | [trpo_pendulum] epoch #695 | Saved
2022-08-17 17:59:27 | [trpo_pendulum] epoch #695 | Time 287.28 s
2022-08-17 17:59:27 | [trpo_pendulum] epoch #695 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -441.575
Evaluation/AverageReturn              -1047.7
Evaluation/Iteration                    695
Evaluation/MaxReturn                   -888.664
Evaluation/MinReturn                  -1171.76
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     92.0016
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41384
GaussianMLPPolicy/KL                      0.000348817
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -391.448
GaussianMLPPolicy/LossBefore           -390.874
GaussianMLPPolicy/dLoss                   0.573853
GaussianMLPValueFunction/LossAfter    21103.6
GaussianMLPValueFunction/LossBefore   21120.6
GaussianMLPValueFunction/dLoss           16.9648
TotalEnvSteps                        835200
-----------------------------------  ----------------
2022-08-17 17:59:27 | [trpo_pendulum] epoch #696 | Saving snapshot...
2022-08-17 17:59:27 | [trpo_pendulum] epoch #696 | Saved
2022-08-17 17:59:27 | [trpo_pendulum] epoch #696 | Time 287.68 s
2022-08-17 17:59:27 | [trpo_pendulum] epoch #696 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -509.516
Evaluation/AverageReturn              -1128.44
Evaluation/Iteration                    696
Evaluation/MaxReturn                  -1084.13
Evaluation/MinReturn                  -1173.97
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     33.6555
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4137
GaussianMLPPolicy/KL                      0.00034528
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -404.298
GaussianMLPPolicy/LossBefore           -404.045
GaussianMLPPolicy/dLoss                   0.252289
GaussianMLPValueFunction/LossAfter    22567
GaussianMLPValueFunction/LossBefore   22584.9
GaussianMLPValueFunction/dLoss           17.9668
TotalEnvSteps                        836400
-----------------------------------  ---------------
2022-08-17 17:59:28 | [trpo_pendulum] epoch #697 | Saving snapshot...
2022-08-17 17:59:28 | [trpo_pendulum] epoch #697 | Saved
2022-08-17 17:59:28 | [trpo_pendulum] epoch #697 | Time 288.09 s
2022-08-17 17:59:28 | [trpo_pendulum] epoch #697 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -405.248
Evaluation/AverageReturn               -944.282
Evaluation/Iteration                    697
Evaluation/MaxReturn                   -881.635
Evaluation/MinReturn                  -1039.98
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     67.8484
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41348
GaussianMLPPolicy/KL                      0.000689163
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -355.418
GaussianMLPPolicy/LossBefore           -354.649
GaussianMLPPolicy/dLoss                   0.768433
GaussianMLPValueFunction/LossAfter    16969.5
GaussianMLPValueFunction/LossBefore   16983.1
GaussianMLPValueFunction/dLoss           13.5625
TotalEnvSteps                        837600
-----------------------------------  ----------------
2022-08-17 17:59:28 | [trpo_pendulum] epoch #698 | Saving snapshot...
2022-08-17 17:59:28 | [trpo_pendulum] epoch #698 | Saved
2022-08-17 17:59:28 | [trpo_pendulum] epoch #698 | Time 288.50 s
2022-08-17 17:59:28 | [trpo_pendulum] epoch #698 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -429.449
Evaluation/AverageReturn               -978.845
Evaluation/Iteration                    698
Evaluation/MaxReturn                   -888.597
Evaluation/MinReturn                  -1071.03
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     61.0869
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41338
GaussianMLPPolicy/KL                      0.000520198
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -345.086
GaussianMLPPolicy/LossBefore           -344.953
GaussianMLPPolicy/dLoss                   0.132996
GaussianMLPValueFunction/LossAfter    17111
GaussianMLPValueFunction/LossBefore   17124.5
GaussianMLPValueFunction/dLoss           13.4277
TotalEnvSteps                        838800
-----------------------------------  ----------------
2022-08-17 17:59:29 | [trpo_pendulum] epoch #699 | Saving snapshot...
2022-08-17 17:59:29 | [trpo_pendulum] epoch #699 | Saved
2022-08-17 17:59:29 | [trpo_pendulum] epoch #699 | Time 288.91 s
2022-08-17 17:59:29 | [trpo_pendulum] epoch #699 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -480.609
Evaluation/AverageReturn              -1069.91
Evaluation/Iteration                    699
Evaluation/MaxReturn                   -936.309
Evaluation/MinReturn                  -1195.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     94.8308
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41329
GaussianMLPPolicy/KL                      0.000779168
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -383.603
GaussianMLPPolicy/LossBefore           -382.777
GaussianMLPPolicy/dLoss                   0.826538
GaussianMLPValueFunction/LossAfter    20657.7
GaussianMLPValueFunction/LossBefore   20673.5
GaussianMLPValueFunction/dLoss           15.8398
TotalEnvSteps                        840000
-----------------------------------  ----------------
2022-08-17 17:59:29 | [trpo_pendulum] epoch #700 | Saving snapshot...
2022-08-17 17:59:29 | [trpo_pendulum] epoch #700 | Saved
2022-08-17 17:59:29 | [trpo_pendulum] epoch #700 | Time 289.31 s
2022-08-17 17:59:29 | [trpo_pendulum] epoch #700 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -673.251
Evaluation/AverageReturn              -1491.53
Evaluation/Iteration                    700
Evaluation/MaxReturn                  -1364.3
Evaluation/MinReturn                  -1567.94
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     75.7633
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41314
GaussianMLPPolicy/KL                      0.000527698
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -551.73
GaussianMLPPolicy/LossBefore           -551.189
GaussianMLPPolicy/dLoss                   0.541138
GaussianMLPValueFunction/LossAfter    41198.3
GaussianMLPValueFunction/LossBefore   41231
GaussianMLPValueFunction/dLoss           32.75
TotalEnvSteps                        841200
-----------------------------------  ----------------
2022-08-17 17:59:29 | [trpo_pendulum] epoch #701 | Saving snapshot...
2022-08-17 17:59:29 | [trpo_pendulum] epoch #701 | Saved
2022-08-17 17:59:29 | [trpo_pendulum] epoch #701 | Time 289.73 s
2022-08-17 17:59:29 | [trpo_pendulum] epoch #701 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -463.221
Evaluation/AverageReturn              -1036.18
Evaluation/Iteration                    701
Evaluation/MaxReturn                   -896.027
Evaluation/MinReturn                  -1243.78
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    125.795
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41299
GaussianMLPPolicy/KL                      0.000936084
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -372.211
GaussianMLPPolicy/LossBefore           -371.581
GaussianMLPPolicy/dLoss                   0.62973
GaussianMLPValueFunction/LossAfter    19686.8
GaussianMLPValueFunction/LossBefore   19703
GaussianMLPValueFunction/dLoss           16.2051
TotalEnvSteps                        842400
-----------------------------------  ----------------
2022-08-17 17:59:30 | [trpo_pendulum] epoch #702 | Saving snapshot...
2022-08-17 17:59:30 | [trpo_pendulum] epoch #702 | Saved
2022-08-17 17:59:30 | [trpo_pendulum] epoch #702 | Time 290.13 s
2022-08-17 17:59:30 | [trpo_pendulum] epoch #702 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -505.663
Evaluation/AverageReturn              -1178.62
Evaluation/Iteration                    702
Evaluation/MaxReturn                   -989.095
Evaluation/MinReturn                  -1309.78
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     96.5875
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41289
GaussianMLPPolicy/KL                      0.00066277
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -437.978
GaussianMLPPolicy/LossBefore           -437.85
GaussianMLPPolicy/dLoss                   0.128235
GaussianMLPValueFunction/LossAfter    26400.4
GaussianMLPValueFunction/LossBefore   26422.1
GaussianMLPValueFunction/dLoss           21.6602
TotalEnvSteps                        843600
-----------------------------------  ---------------
2022-08-17 17:59:30 | [trpo_pendulum] epoch #703 | Saving snapshot...
2022-08-17 17:59:30 | [trpo_pendulum] epoch #703 | Saved
2022-08-17 17:59:30 | [trpo_pendulum] epoch #703 | Time 290.54 s
2022-08-17 17:59:30 | [trpo_pendulum] epoch #703 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -355.767
Evaluation/AverageReturn               -905.059
Evaluation/Iteration                    703
Evaluation/MaxReturn                   -733.744
Evaluation/MinReturn                  -1020.28
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     93.9744
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41282
GaussianMLPPolicy/KL                      0.000419428
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -351.606
GaussianMLPPolicy/LossBefore           -351.643
GaussianMLPPolicy/dLoss                  -0.0369568
GaussianMLPValueFunction/LossAfter    16597.7
GaussianMLPValueFunction/LossBefore   16611.5
GaussianMLPValueFunction/dLoss           13.8262
TotalEnvSteps                        844800
-----------------------------------  ----------------
2022-08-17 17:59:31 | [trpo_pendulum] epoch #704 | Saving snapshot...
2022-08-17 17:59:31 | [trpo_pendulum] epoch #704 | Saved
2022-08-17 17:59:31 | [trpo_pendulum] epoch #704 | Time 290.94 s
2022-08-17 17:59:31 | [trpo_pendulum] epoch #704 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -410.797
Evaluation/AverageReturn               -986.497
Evaluation/Iteration                    704
Evaluation/MaxReturn                   -625.991
Evaluation/MinReturn                  -1141.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    183.373
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41278
GaussianMLPPolicy/KL                      0.000271946
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -370.275
GaussianMLPPolicy/LossBefore           -370.272
GaussianMLPPolicy/dLoss                   0.0032959
GaussianMLPValueFunction/LossAfter    19313.9
GaussianMLPValueFunction/LossBefore   19329.5
GaussianMLPValueFunction/dLoss           15.5977
TotalEnvSteps                        846000
-----------------------------------  ----------------
2022-08-17 17:59:31 | [trpo_pendulum] epoch #705 | Saving snapshot...
2022-08-17 17:59:31 | [trpo_pendulum] epoch #705 | Saved
2022-08-17 17:59:31 | [trpo_pendulum] epoch #705 | Time 291.37 s
2022-08-17 17:59:31 | [trpo_pendulum] epoch #705 | EpochTime 0.42 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -647.534
Evaluation/AverageReturn              -1503.24
Evaluation/Iteration                    705
Evaluation/MaxReturn                  -1311.02
Evaluation/MinReturn                  -1634.05
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    105.482
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41272
GaussianMLPPolicy/KL                      0.00015546
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -573.012
GaussianMLPPolicy/LossBefore           -572.905
GaussianMLPPolicy/dLoss                   0.106079
GaussianMLPValueFunction/LossAfter    43577.1
GaussianMLPValueFunction/LossBefore   43613.4
GaussianMLPValueFunction/dLoss           36.3203
TotalEnvSteps                        847200
-----------------------------------  ---------------
2022-08-17 17:59:31 | [trpo_pendulum] epoch #706 | Saving snapshot...
2022-08-17 17:59:31 | [trpo_pendulum] epoch #706 | Saved
2022-08-17 17:59:31 | [trpo_pendulum] epoch #706 | Time 291.78 s
2022-08-17 17:59:31 | [trpo_pendulum] epoch #706 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -622.627
Evaluation/AverageReturn              -1453.55
Evaluation/Iteration                    706
Evaluation/MaxReturn                  -1362.38
Evaluation/MinReturn                  -1501.57
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.42
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41272
GaussianMLPPolicy/KL                      0.000137889
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -548.951
GaussianMLPPolicy/LossBefore           -548.882
GaussianMLPPolicy/dLoss                   0.0693359
GaussianMLPValueFunction/LossAfter    40641.4
GaussianMLPValueFunction/LossBefore   40677.6
GaussianMLPValueFunction/dLoss           36.1797
TotalEnvSteps                        848400
-----------------------------------  ----------------
2022-08-17 17:59:32 | [trpo_pendulum] epoch #707 | Saving snapshot...
2022-08-17 17:59:32 | [trpo_pendulum] epoch #707 | Saved
2022-08-17 17:59:32 | [trpo_pendulum] epoch #707 | Time 292.18 s
2022-08-17 17:59:32 | [trpo_pendulum] epoch #707 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -603.826
Evaluation/AverageReturn              -1433.82
Evaluation/Iteration                    707
Evaluation/MaxReturn                  -1266.97
Evaluation/MinReturn                  -1614.37
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    117.849
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41277
GaussianMLPPolicy/KL                      0.000118703
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -548.711
GaussianMLPPolicy/LossBefore           -548.621
GaussianMLPPolicy/dLoss                   0.0895996
GaussianMLPValueFunction/LossAfter    40342
GaussianMLPValueFunction/LossBefore   40379.8
GaussianMLPValueFunction/dLoss           37.8359
TotalEnvSteps                        849600
-----------------------------------  ----------------
2022-08-17 17:59:32 | [trpo_pendulum] epoch #708 | Saving snapshot...
2022-08-17 17:59:32 | [trpo_pendulum] epoch #708 | Saved
2022-08-17 17:59:32 | [trpo_pendulum] epoch #708 | Time 292.58 s
2022-08-17 17:59:32 | [trpo_pendulum] epoch #708 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -532.061
Evaluation/AverageReturn              -1270.8
Evaluation/Iteration                    708
Evaluation/MaxReturn                  -1182.82
Evaluation/MinReturn                  -1378.94
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     63.9222
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41282
GaussianMLPPolicy/KL                      0.000116199
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -487.467
GaussianMLPPolicy/LossBefore           -487.431
GaussianMLPPolicy/dLoss                   0.0355225
GaussianMLPValueFunction/LossAfter    31340.8
GaussianMLPValueFunction/LossBefore   31371
GaussianMLPValueFunction/dLoss           30.2598
TotalEnvSteps                        850800
-----------------------------------  ----------------
2022-08-17 17:59:33 | [trpo_pendulum] epoch #709 | Saving snapshot...
2022-08-17 17:59:33 | [trpo_pendulum] epoch #709 | Saved
2022-08-17 17:59:33 | [trpo_pendulum] epoch #709 | Time 292.99 s
2022-08-17 17:59:33 | [trpo_pendulum] epoch #709 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -656.695
Evaluation/AverageReturn              -1534.32
Evaluation/Iteration                    709
Evaluation/MaxReturn                  -1440.19
Evaluation/MinReturn                  -1642.13
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     63.3183
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41288
GaussianMLPPolicy/KL                      0.000120951
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -584.847
GaussianMLPPolicy/LossBefore           -584.623
GaussianMLPPolicy/dLoss                   0.224182
GaussianMLPValueFunction/LossAfter    45356.2
GaussianMLPValueFunction/LossBefore   45401.7
GaussianMLPValueFunction/dLoss           45.4727
TotalEnvSteps                        852000
-----------------------------------  ----------------
2022-08-17 17:59:33 | [trpo_pendulum] epoch #710 | Saving snapshot...
2022-08-17 17:59:33 | [trpo_pendulum] epoch #710 | Saved
2022-08-17 17:59:33 | [trpo_pendulum] epoch #710 | Time 293.39 s
2022-08-17 17:59:33 | [trpo_pendulum] epoch #710 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -495.679
Evaluation/AverageReturn              -1208.88
Evaluation/Iteration                    710
Evaluation/MaxReturn                  -1082
Evaluation/MinReturn                  -1310.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     71.2088
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41299
GaussianMLPPolicy/KL                      0.000184474
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -465.842
GaussianMLPPolicy/LossBefore           -465.666
GaussianMLPPolicy/dLoss                   0.17627
GaussianMLPValueFunction/LossAfter    28873.7
GaussianMLPValueFunction/LossBefore   28903.4
GaussianMLPValueFunction/dLoss           29.6562
TotalEnvSteps                        853200
-----------------------------------  ----------------
2022-08-17 17:59:33 | [trpo_pendulum] epoch #711 | Saving snapshot...
2022-08-17 17:59:33 | [trpo_pendulum] epoch #711 | Saved
2022-08-17 17:59:33 | [trpo_pendulum] epoch #711 | Time 293.80 s
2022-08-17 17:59:33 | [trpo_pendulum] epoch #711 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -470.903
Evaluation/AverageReturn              -1177.84
Evaluation/Iteration                    711
Evaluation/MaxReturn                  -1126.41
Evaluation/MinReturn                  -1237.04
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     34.3805
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41305
GaussianMLPPolicy/KL                      5.24272e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -467.59
GaussianMLPPolicy/LossBefore           -467.596
GaussianMLPPolicy/dLoss                  -0.00592041
GaussianMLPValueFunction/LossAfter    27898.2
GaussianMLPValueFunction/LossBefore   27926.8
GaussianMLPValueFunction/dLoss           28.6309
TotalEnvSteps                        854400
-----------------------------------  ----------------
2022-08-17 17:59:34 | [trpo_pendulum] epoch #712 | Saving snapshot...
2022-08-17 17:59:34 | [trpo_pendulum] epoch #712 | Saved
2022-08-17 17:59:34 | [trpo_pendulum] epoch #712 | Time 294.22 s
2022-08-17 17:59:34 | [trpo_pendulum] epoch #712 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -763.843
Evaluation/AverageReturn              -1746.37
Evaluation/Iteration                    712
Evaluation/MaxReturn                  -1618.79
Evaluation/MinReturn                  -1822.69
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     83.6363
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41299
GaussianMLPPolicy/KL                      2.48954e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -669.982
GaussianMLPPolicy/LossBefore           -669.849
GaussianMLPPolicy/dLoss                   0.133301
GaussianMLPValueFunction/LossAfter    58037.8
GaussianMLPValueFunction/LossBefore   58100.3
GaussianMLPValueFunction/dLoss           62.4922
TotalEnvSteps                        855600
-----------------------------------  ----------------
2022-08-17 17:59:34 | [trpo_pendulum] epoch #713 | Saving snapshot...
2022-08-17 17:59:34 | [trpo_pendulum] epoch #713 | Saved
2022-08-17 17:59:34 | [trpo_pendulum] epoch #713 | Time 294.63 s
2022-08-17 17:59:34 | [trpo_pendulum] epoch #713 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -528.807
Evaluation/AverageReturn              -1280.4
Evaluation/Iteration                    713
Evaluation/MaxReturn                  -1233
Evaluation/MinReturn                  -1375.21
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     45.5844
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41298
GaussianMLPPolicy/KL                      0.000188886
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -494.192
GaussianMLPPolicy/LossBefore           -493.872
GaussianMLPPolicy/dLoss                   0.320801
GaussianMLPValueFunction/LossAfter    32018.4
GaussianMLPValueFunction/LossBefore   32054
GaussianMLPValueFunction/dLoss           35.5566
TotalEnvSteps                        856800
-----------------------------------  ----------------
2022-08-17 17:59:35 | [trpo_pendulum] epoch #714 | Saving snapshot...
2022-08-17 17:59:35 | [trpo_pendulum] epoch #714 | Saved
2022-08-17 17:59:35 | [trpo_pendulum] epoch #714 | Time 295.03 s
2022-08-17 17:59:35 | [trpo_pendulum] epoch #714 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -416.423
Evaluation/AverageReturn              -1152.28
Evaluation/Iteration                    714
Evaluation/MaxReturn                   -928.937
Evaluation/MinReturn                  -1354.92
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    138.723
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41313
GaussianMLPPolicy/KL                      8.50583e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -471.876
GaussianMLPPolicy/LossBefore           -471.81
GaussianMLPPolicy/dLoss                   0.0652771
GaussianMLPValueFunction/LossAfter    30258.9
GaussianMLPValueFunction/LossBefore   30292.5
GaussianMLPValueFunction/dLoss           33.5703
TotalEnvSteps                        858000
-----------------------------------  ----------------
2022-08-17 17:59:35 | [trpo_pendulum] epoch #715 | Saving snapshot...
2022-08-17 17:59:35 | [trpo_pendulum] epoch #715 | Saved
2022-08-17 17:59:35 | [trpo_pendulum] epoch #715 | Time 295.46 s
2022-08-17 17:59:35 | [trpo_pendulum] epoch #715 | EpochTime 0.42 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -491.049
Evaluation/AverageReturn              -1242.42
Evaluation/Iteration                    715
Evaluation/MaxReturn                  -1123.99
Evaluation/MinReturn                  -1372.06
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     79.1728
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41312
GaussianMLPPolicy/KL                      5.7692e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -508.44
GaussianMLPPolicy/LossBefore           -508.246
GaussianMLPPolicy/dLoss                   0.193817
GaussianMLPValueFunction/LossAfter    31856.2
GaussianMLPValueFunction/LossBefore   31891.5
GaussianMLPValueFunction/dLoss           35.2402
TotalEnvSteps                        859200
-----------------------------------  ---------------
2022-08-17 17:59:35 | [trpo_pendulum] epoch #716 | Saving snapshot...
2022-08-17 17:59:36 | [trpo_pendulum] epoch #716 | Saved
2022-08-17 17:59:36 | [trpo_pendulum] epoch #716 | Time 295.87 s
2022-08-17 17:59:36 | [trpo_pendulum] epoch #716 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -609.349
Evaluation/AverageReturn              -1468.51
Evaluation/Iteration                    716
Evaluation/MaxReturn                  -1308.28
Evaluation/MinReturn                  -1584.52
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     94.9237
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41314
GaussianMLPPolicy/KL                      4.8709e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -569.951
GaussianMLPPolicy/LossBefore           -569.819
GaussianMLPPolicy/dLoss                   0.131409
GaussianMLPValueFunction/LossAfter    42489.5
GaussianMLPValueFunction/LossBefore   42537.3
GaussianMLPValueFunction/dLoss           47.7461
TotalEnvSteps                        860400
-----------------------------------  ---------------
2022-08-17 17:59:36 | [trpo_pendulum] epoch #717 | Saving snapshot...
2022-08-17 17:59:36 | [trpo_pendulum] epoch #717 | Saved
2022-08-17 17:59:36 | [trpo_pendulum] epoch #717 | Time 296.28 s
2022-08-17 17:59:36 | [trpo_pendulum] epoch #717 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -711.251
Evaluation/AverageReturn              -1668.89
Evaluation/Iteration                    717
Evaluation/MaxReturn                  -1569.58
Evaluation/MinReturn                  -1714.29
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.3806
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41329
GaussianMLPPolicy/KL                      3.15612e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -633.014
GaussianMLPPolicy/LossBefore           -632.933
GaussianMLPPolicy/dLoss                   0.0813599
GaussianMLPValueFunction/LossAfter    54233.3
GaussianMLPValueFunction/LossBefore   54297.3
GaussianMLPValueFunction/dLoss           63.9102
TotalEnvSteps                        861600
-----------------------------------  ----------------
2022-08-17 17:59:36 | [trpo_pendulum] epoch #718 | Saving snapshot...
2022-08-17 17:59:36 | [trpo_pendulum] epoch #718 | Saved
2022-08-17 17:59:36 | [trpo_pendulum] epoch #718 | Time 296.68 s
2022-08-17 17:59:36 | [trpo_pendulum] epoch #718 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -608.555
Evaluation/AverageReturn              -1441.52
Evaluation/Iteration                    718
Evaluation/MaxReturn                  -1347.16
Evaluation/MinReturn                  -1604.12
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     85.9823
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41347
GaussianMLPPolicy/KL                      1.57461e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -550.893
GaussianMLPPolicy/LossBefore           -550.931
GaussianMLPPolicy/dLoss                  -0.0385132
GaussianMLPValueFunction/LossAfter    40197.4
GaussianMLPValueFunction/LossBefore   40246.1
GaussianMLPValueFunction/dLoss           48.707
TotalEnvSteps                        862800
-----------------------------------  ----------------
2022-08-17 17:59:37 | [trpo_pendulum] epoch #719 | Saving snapshot...
2022-08-17 17:59:37 | [trpo_pendulum] epoch #719 | Saved
2022-08-17 17:59:37 | [trpo_pendulum] epoch #719 | Time 297.09 s
2022-08-17 17:59:37 | [trpo_pendulum] epoch #719 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -756.565
Evaluation/AverageReturn              -1757
Evaluation/Iteration                    719
Evaluation/MaxReturn                  -1672.29
Evaluation/MinReturn                  -1808.66
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     43.3523
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4135
GaussianMLPPolicy/KL                      1.1733e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -684.534
GaussianMLPPolicy/LossBefore           -684.443
GaussianMLPPolicy/dLoss                   0.0917969
GaussianMLPValueFunction/LossAfter    59681.6
GaussianMLPValueFunction/LossBefore   59757.2
GaussianMLPValueFunction/dLoss           75.625
TotalEnvSteps                        864000
-----------------------------------  ---------------
2022-08-17 17:59:37 | [trpo_pendulum] epoch #720 | Saving snapshot...
2022-08-17 17:59:37 | [trpo_pendulum] epoch #720 | Saved
2022-08-17 17:59:37 | [trpo_pendulum] epoch #720 | Time 297.50 s
2022-08-17 17:59:37 | [trpo_pendulum] epoch #720 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -758.83
Evaluation/AverageReturn              -1743.85
Evaluation/Iteration                    720
Evaluation/MaxReturn                  -1693.51
Evaluation/MinReturn                  -1842.38
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.4282
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41356
GaussianMLPPolicy/KL                      1.78921e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -660.783
GaussianMLPPolicy/LossBefore           -660.707
GaussianMLPPolicy/dLoss                   0.0753784
GaussianMLPValueFunction/LossAfter    57423.8
GaussianMLPValueFunction/LossBefore   57500.3
GaussianMLPValueFunction/dLoss           76.4648
TotalEnvSteps                        865200
-----------------------------------  ----------------
2022-08-17 17:59:38 | [trpo_pendulum] epoch #721 | Saving snapshot...
2022-08-17 17:59:38 | [trpo_pendulum] epoch #721 | Saved
2022-08-17 17:59:38 | [trpo_pendulum] epoch #721 | Time 297.92 s
2022-08-17 17:59:38 | [trpo_pendulum] epoch #721 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -537.074
Evaluation/AverageReturn              -1309.44
Evaluation/Iteration                    721
Evaluation/MaxReturn                  -1220.31
Evaluation/MinReturn                  -1420.7
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     73.3855
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41369
GaussianMLPPolicy/KL                      0.000134156
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -505.379
GaussianMLPPolicy/LossBefore           -505.101
GaussianMLPPolicy/dLoss                   0.278351
GaussianMLPValueFunction/LossAfter    33536.6
GaussianMLPValueFunction/LossBefore   33581.7
GaussianMLPValueFunction/dLoss           45.0977
TotalEnvSteps                        866400
-----------------------------------  ----------------
2022-08-17 17:59:38 | [trpo_pendulum] epoch #722 | Saving snapshot...
2022-08-17 17:59:38 | [trpo_pendulum] epoch #722 | Saved
2022-08-17 17:59:38 | [trpo_pendulum] epoch #722 | Time 298.33 s
2022-08-17 17:59:38 | [trpo_pendulum] epoch #722 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -522.859
Evaluation/AverageReturn              -1279.41
Evaluation/Iteration                    722
Evaluation/MaxReturn                  -1068.94
Evaluation/MinReturn                  -1428.68
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    108.807
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.414
GaussianMLPPolicy/KL                      0.000491657
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -484.537
GaussianMLPPolicy/LossBefore           -483.468
GaussianMLPPolicy/dLoss                   1.06906
GaussianMLPValueFunction/LossAfter    32270.8
GaussianMLPValueFunction/LossBefore   32313.6
GaussianMLPValueFunction/dLoss           42.7539
TotalEnvSteps                        867600
-----------------------------------  ----------------
2022-08-17 17:59:38 | [trpo_pendulum] epoch #723 | Saving snapshot...
2022-08-17 17:59:38 | [trpo_pendulum] epoch #723 | Saved
2022-08-17 17:59:38 | [trpo_pendulum] epoch #723 | Time 298.75 s
2022-08-17 17:59:38 | [trpo_pendulum] epoch #723 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -490.177
Evaluation/AverageReturn              -1155.14
Evaluation/Iteration                    723
Evaluation/MaxReturn                  -1071.73
Evaluation/MinReturn                  -1272.99
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     61.7565
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41431
GaussianMLPPolicy/KL                      0.000154119
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -433.004
GaussianMLPPolicy/LossBefore           -433.269
GaussianMLPPolicy/dLoss                  -0.264679
GaussianMLPValueFunction/LossAfter    24698.3
GaussianMLPValueFunction/LossBefore   24730.3
GaussianMLPValueFunction/dLoss           32.0703
TotalEnvSteps                        868800
-----------------------------------  ----------------
2022-08-17 17:59:39 | [trpo_pendulum] epoch #724 | Saving snapshot...
2022-08-17 17:59:39 | [trpo_pendulum] epoch #724 | Saved
2022-08-17 17:59:39 | [trpo_pendulum] epoch #724 | Time 299.16 s
2022-08-17 17:59:39 | [trpo_pendulum] epoch #724 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -422.347
Evaluation/AverageReturn              -1065.75
Evaluation/Iteration                    724
Evaluation/MaxReturn                   -965.363
Evaluation/MinReturn                  -1163.17
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     65.986
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41451
GaussianMLPPolicy/KL                      0.000232491
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -426.063
GaussianMLPPolicy/LossBefore           -425.787
GaussianMLPPolicy/dLoss                   0.276001
GaussianMLPValueFunction/LossAfter    22707.6
GaussianMLPValueFunction/LossBefore   22736.2
GaussianMLPValueFunction/dLoss           28.582
TotalEnvSteps                        870000
-----------------------------------  ----------------
2022-08-17 17:59:39 | [trpo_pendulum] epoch #725 | Saving snapshot...
2022-08-17 17:59:39 | [trpo_pendulum] epoch #725 | Saved
2022-08-17 17:59:39 | [trpo_pendulum] epoch #725 | Time 299.56 s
2022-08-17 17:59:39 | [trpo_pendulum] epoch #725 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -533.788
Evaluation/AverageReturn              -1273.9
Evaluation/Iteration                    725
Evaluation/MaxReturn                  -1068.16
Evaluation/MinReturn                  -1401.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    105.738
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41457
GaussianMLPPolicy/KL                      0.000398654
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -498.312
GaussianMLPPolicy/LossBefore           -497.716
GaussianMLPPolicy/dLoss                   0.596039
GaussianMLPValueFunction/LossAfter    30945.9
GaussianMLPValueFunction/LossBefore   30983.7
GaussianMLPValueFunction/dLoss           37.7832
TotalEnvSteps                        871200
-----------------------------------  ----------------
2022-08-17 17:59:40 | [trpo_pendulum] epoch #726 | Saving snapshot...
2022-08-17 17:59:40 | [trpo_pendulum] epoch #726 | Saved
2022-08-17 17:59:40 | [trpo_pendulum] epoch #726 | Time 299.96 s
2022-08-17 17:59:40 | [trpo_pendulum] epoch #726 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -701.1
Evaluation/AverageReturn              -1597.1
Evaluation/Iteration                    726
Evaluation/MaxReturn                  -1542.79
Evaluation/MinReturn                  -1668.58
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     41.2264
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41457
GaussianMLPPolicy/KL                      0.000182716
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -605.389
GaussianMLPPolicy/LossBefore           -605.263
GaussianMLPPolicy/dLoss                   0.125671
GaussianMLPValueFunction/LossAfter    46972
GaussianMLPValueFunction/LossBefore   47029.9
GaussianMLPValueFunction/dLoss           57.9297
TotalEnvSteps                        872400
-----------------------------------  ----------------
2022-08-17 17:59:40 | [trpo_pendulum] epoch #727 | Saving snapshot...
2022-08-17 17:59:40 | [trpo_pendulum] epoch #727 | Saved
2022-08-17 17:59:40 | [trpo_pendulum] epoch #727 | Time 300.38 s
2022-08-17 17:59:40 | [trpo_pendulum] epoch #727 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -516.611
Evaluation/AverageReturn              -1189.66
Evaluation/Iteration                    727
Evaluation/MaxReturn                  -1064.95
Evaluation/MinReturn                  -1291.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     76.9514
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41457
GaussianMLPPolicy/KL                      0.0002188
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -440.843
GaussianMLPPolicy/LossBefore           -440.841
GaussianMLPPolicy/dLoss                   0.00219727
GaussianMLPValueFunction/LossAfter    25720.8
GaussianMLPValueFunction/LossBefore   25752.6
GaussianMLPValueFunction/dLoss           31.791
TotalEnvSteps                        873600
-----------------------------------  ---------------
2022-08-17 17:59:40 | [trpo_pendulum] epoch #728 | Saving snapshot...
2022-08-17 17:59:40 | [trpo_pendulum] epoch #728 | Saved
2022-08-17 17:59:40 | [trpo_pendulum] epoch #728 | Time 300.79 s
2022-08-17 17:59:40 | [trpo_pendulum] epoch #728 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -601.88
Evaluation/AverageReturn              -1380.85
Evaluation/Iteration                    728
Evaluation/MaxReturn                  -1287.48
Evaluation/MinReturn                  -1429.62
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     53.5637
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41474
GaussianMLPPolicy/KL                      0.000132958
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -502.137
GaussianMLPPolicy/LossBefore           -502.098
GaussianMLPPolicy/dLoss                   0.0386963
GaussianMLPValueFunction/LossAfter    34787.7
GaussianMLPValueFunction/LossBefore   34830
GaussianMLPValueFunction/dLoss           42.2812
TotalEnvSteps                        874800
-----------------------------------  ----------------
2022-08-17 17:59:41 | [trpo_pendulum] epoch #729 | Saving snapshot...
2022-08-17 17:59:41 | [trpo_pendulum] epoch #729 | Saved
2022-08-17 17:59:41 | [trpo_pendulum] epoch #729 | Time 301.21 s
2022-08-17 17:59:41 | [trpo_pendulum] epoch #729 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -654.649
Evaluation/AverageReturn              -1496.98
Evaluation/Iteration                    729
Evaluation/MaxReturn                  -1455.36
Evaluation/MinReturn                  -1581.41
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     41.7442
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41478
GaussianMLPPolicy/KL                      0.000205809
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -571.724
GaussianMLPPolicy/LossBefore           -571.26
GaussianMLPPolicy/dLoss                   0.463806
GaussianMLPValueFunction/LossAfter    41219.7
GaussianMLPValueFunction/LossBefore   41270.2
GaussianMLPValueFunction/dLoss           50.4844
TotalEnvSteps                        876000
-----------------------------------  ----------------
2022-08-17 17:59:41 | [trpo_pendulum] epoch #730 | Saving snapshot...
2022-08-17 17:59:41 | [trpo_pendulum] epoch #730 | Saved
2022-08-17 17:59:41 | [trpo_pendulum] epoch #730 | Time 301.62 s
2022-08-17 17:59:41 | [trpo_pendulum] epoch #730 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -401.171
Evaluation/AverageReturn               -984.548
Evaluation/Iteration                    730
Evaluation/MaxReturn                   -773.465
Evaluation/MinReturn                  -1106.05
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    105.53
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41487
GaussianMLPPolicy/KL                      0.000665601
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -373.517
GaussianMLPPolicy/LossBefore           -372.546
GaussianMLPPolicy/dLoss                   0.971283
GaussianMLPValueFunction/LossAfter    18863.3
GaussianMLPValueFunction/LossBefore   18886.4
GaussianMLPValueFunction/dLoss           23.0586
TotalEnvSteps                        877200
-----------------------------------  ----------------
2022-08-17 17:59:42 | [trpo_pendulum] epoch #731 | Saving snapshot...
2022-08-17 17:59:42 | [trpo_pendulum] epoch #731 | Saved
2022-08-17 17:59:42 | [trpo_pendulum] epoch #731 | Time 302.03 s
2022-08-17 17:59:42 | [trpo_pendulum] epoch #731 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -676.271
Evaluation/AverageReturn              -1521.76
Evaluation/Iteration                    731
Evaluation/MaxReturn                  -1460.01
Evaluation/MinReturn                  -1593.67
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.4787
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41499
GaussianMLPPolicy/KL                      0.00041947
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -561.016
GaussianMLPPolicy/LossBefore           -560.559
GaussianMLPPolicy/dLoss                   0.457031
GaussianMLPValueFunction/LossAfter    41976.9
GaussianMLPValueFunction/LossBefore   42027
GaussianMLPValueFunction/dLoss           50.1094
TotalEnvSteps                        878400
-----------------------------------  ---------------
2022-08-17 17:59:42 | [trpo_pendulum] epoch #732 | Saving snapshot...
2022-08-17 17:59:42 | [trpo_pendulum] epoch #732 | Saved
2022-08-17 17:59:42 | [trpo_pendulum] epoch #732 | Time 302.44 s
2022-08-17 17:59:42 | [trpo_pendulum] epoch #732 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -569.347
Evaluation/AverageReturn              -1290.38
Evaluation/Iteration                    732
Evaluation/MaxReturn                  -1143.37
Evaluation/MinReturn                  -1423.69
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     81.8118
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.415
GaussianMLPPolicy/KL                      0.000994894
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -484.046
GaussianMLPPolicy/LossBefore           -482.803
GaussianMLPPolicy/dLoss                   1.24213
GaussianMLPValueFunction/LossAfter    29889.2
GaussianMLPValueFunction/LossBefore   29925.1
GaussianMLPValueFunction/dLoss           35.8105
TotalEnvSteps                        879600
-----------------------------------  ----------------
2022-08-17 17:59:42 | [trpo_pendulum] epoch #733 | Saving snapshot...
2022-08-17 17:59:43 | [trpo_pendulum] epoch #733 | Saved
2022-08-17 17:59:43 | [trpo_pendulum] epoch #733 | Time 302.86 s
2022-08-17 17:59:43 | [trpo_pendulum] epoch #733 | EpochTime 0.42 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -503.181
Evaluation/AverageReturn              -1141.09
Evaluation/Iteration                    733
Evaluation/MaxReturn                  -1009.33
Evaluation/MinReturn                  -1338.44
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    105.544
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41506
GaussianMLPPolicy/KL                      0.00119781
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -412.871
GaussianMLPPolicy/LossBefore           -411.99
GaussianMLPPolicy/dLoss                   0.880829
GaussianMLPValueFunction/LossAfter    23273.3
GaussianMLPValueFunction/LossBefore   23300.7
GaussianMLPValueFunction/dLoss           27.4082
TotalEnvSteps                        880800
-----------------------------------  ---------------
2022-08-17 17:59:43 | [trpo_pendulum] epoch #734 | Saving snapshot...
2022-08-17 17:59:43 | [trpo_pendulum] epoch #734 | Saved
2022-08-17 17:59:43 | [trpo_pendulum] epoch #734 | Time 303.29 s
2022-08-17 17:59:43 | [trpo_pendulum] epoch #734 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -456.49
Evaluation/AverageReturn               -996.789
Evaluation/Iteration                    734
Evaluation/MaxReturn                   -956.232
Evaluation/MinReturn                  -1096.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     46.3465
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4152
GaussianMLPPolicy/KL                      0.000918702
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -340.349
GaussianMLPPolicy/LossBefore           -340.267
GaussianMLPPolicy/dLoss                   0.0823059
GaussianMLPValueFunction/LossAfter    16423.5
GaussianMLPValueFunction/LossBefore   16442.3
GaussianMLPValueFunction/dLoss           18.8359
TotalEnvSteps                        882000
-----------------------------------  ----------------
2022-08-17 17:59:43 | [trpo_pendulum] epoch #735 | Saving snapshot...
2022-08-17 17:59:43 | [trpo_pendulum] epoch #735 | Saved
2022-08-17 17:59:43 | [trpo_pendulum] epoch #735 | Time 303.70 s
2022-08-17 17:59:43 | [trpo_pendulum] epoch #735 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -383.694
Evaluation/AverageReturn               -910.096
Evaluation/Iteration                    735
Evaluation/MaxReturn                   -759.047
Evaluation/MinReturn                  -1061.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    110.871
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41528
GaussianMLPPolicy/KL                      0.00086136
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -339.946
GaussianMLPPolicy/LossBefore           -339.632
GaussianMLPPolicy/dLoss                   0.313751
GaussianMLPValueFunction/LossAfter    15399.7
GaussianMLPValueFunction/LossBefore   15416.6
GaussianMLPValueFunction/dLoss           16.9238
TotalEnvSteps                        883200
-----------------------------------  ---------------
2022-08-17 17:59:44 | [trpo_pendulum] epoch #736 | Saving snapshot...
2022-08-17 17:59:44 | [trpo_pendulum] epoch #736 | Saved
2022-08-17 17:59:44 | [trpo_pendulum] epoch #736 | Time 304.11 s
2022-08-17 17:59:44 | [trpo_pendulum] epoch #736 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -635.438
Evaluation/AverageReturn              -1357.7
Evaluation/Iteration                    736
Evaluation/MaxReturn                  -1193.74
Evaluation/MinReturn                  -1493.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     96.3319
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41553
GaussianMLPPolicy/KL                      0.000476077
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -461.869
GaussianMLPPolicy/LossBefore           -461.687
GaussianMLPPolicy/dLoss                   0.181213
GaussianMLPValueFunction/LossAfter    31423.5
GaussianMLPValueFunction/LossBefore   31456.6
GaussianMLPValueFunction/dLoss           33.0566
TotalEnvSteps                        884400
-----------------------------------  ----------------
2022-08-17 17:59:44 | [trpo_pendulum] epoch #737 | Saving snapshot...
2022-08-17 17:59:44 | [trpo_pendulum] epoch #737 | Saved
2022-08-17 17:59:44 | [trpo_pendulum] epoch #737 | Time 304.52 s
2022-08-17 17:59:44 | [trpo_pendulum] epoch #737 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -479.943
Evaluation/AverageReturn              -1062.95
Evaluation/Iteration                    737
Evaluation/MaxReturn                   -992.902
Evaluation/MinReturn                  -1135.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     49.3774
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41578
GaussianMLPPolicy/KL                      0.000487942
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -375.647
GaussianMLPPolicy/LossBefore           -375.578
GaussianMLPPolicy/dLoss                   0.0692444
GaussianMLPValueFunction/LossAfter    19181.2
GaussianMLPValueFunction/LossBefore   19201.3
GaussianMLPValueFunction/dLoss           20.1465
TotalEnvSteps                        885600
-----------------------------------  ----------------
2022-08-17 17:59:45 | [trpo_pendulum] epoch #738 | Saving snapshot...
2022-08-17 17:59:45 | [trpo_pendulum] epoch #738 | Saved
2022-08-17 17:59:45 | [trpo_pendulum] epoch #738 | Time 304.94 s
2022-08-17 17:59:45 | [trpo_pendulum] epoch #738 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -674.056
Evaluation/AverageReturn              -1450.62
Evaluation/Iteration                    738
Evaluation/MaxReturn                  -1310.46
Evaluation/MinReturn                  -1639.65
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    105.964
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41597
GaussianMLPPolicy/KL                      0.000364783
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -518.891
GaussianMLPPolicy/LossBefore           -518.415
GaussianMLPPolicy/dLoss                   0.476013
GaussianMLPValueFunction/LossAfter    35802
GaussianMLPValueFunction/LossBefore   35839
GaussianMLPValueFunction/dLoss           36.9805
TotalEnvSteps                        886800
-----------------------------------  ----------------
2022-08-17 17:59:45 | [trpo_pendulum] epoch #739 | Saving snapshot...
2022-08-17 17:59:45 | [trpo_pendulum] epoch #739 | Saved
2022-08-17 17:59:45 | [trpo_pendulum] epoch #739 | Time 305.34 s
2022-08-17 17:59:45 | [trpo_pendulum] epoch #739 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -514.024
Evaluation/AverageReturn              -1111.02
Evaluation/Iteration                    739
Evaluation/MaxReturn                   -993.275
Evaluation/MinReturn                  -1199.67
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     69.0454
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41612
GaussianMLPPolicy/KL                      0.000454259
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -388.326
GaussianMLPPolicy/LossBefore           -388.175
GaussianMLPPolicy/dLoss                   0.150452
GaussianMLPValueFunction/LossAfter    19904.7
GaussianMLPValueFunction/LossBefore   19925.4
GaussianMLPValueFunction/dLoss           20.6777
TotalEnvSteps                        888000
-----------------------------------  ----------------
2022-08-17 17:59:45 | [trpo_pendulum] epoch #740 | Saving snapshot...
2022-08-17 17:59:45 | [trpo_pendulum] epoch #740 | Saved
2022-08-17 17:59:45 | [trpo_pendulum] epoch #740 | Time 305.75 s
2022-08-17 17:59:45 | [trpo_pendulum] epoch #740 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -466.101
Evaluation/AverageReturn              -1123.78
Evaluation/Iteration                    740
Evaluation/MaxReturn                  -1043.01
Evaluation/MinReturn                  -1175.51
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     55.2249
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41621
GaussianMLPPolicy/KL                      0.000252983
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -433.803
GaussianMLPPolicy/LossBefore           -433.945
GaussianMLPPolicy/dLoss                  -0.142273
GaussianMLPValueFunction/LossAfter    23641
GaussianMLPValueFunction/LossBefore   23665
GaussianMLPValueFunction/dLoss           23.9902
TotalEnvSteps                        889200
-----------------------------------  ----------------
2022-08-17 17:59:46 | [trpo_pendulum] epoch #741 | Saving snapshot...
2022-08-17 17:59:46 | [trpo_pendulum] epoch #741 | Saved
2022-08-17 17:59:46 | [trpo_pendulum] epoch #741 | Time 306.17 s
2022-08-17 17:59:46 | [trpo_pendulum] epoch #741 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -440.65
Evaluation/AverageReturn              -1053.25
Evaluation/Iteration                    741
Evaluation/MaxReturn                   -992.696
Evaluation/MinReturn                  -1171.17
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     59.0254
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41645
GaussianMLPPolicy/KL                      5.81621e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -385.413
GaussianMLPPolicy/LossBefore           -385.489
GaussianMLPPolicy/dLoss                  -0.0763855
GaussianMLPValueFunction/LossAfter    20541.7
GaussianMLPValueFunction/LossBefore   20562.3
GaussianMLPValueFunction/dLoss           20.5742
TotalEnvSteps                        890400
-----------------------------------  ----------------
2022-08-17 17:59:46 | [trpo_pendulum] epoch #742 | Saving snapshot...
2022-08-17 17:59:46 | [trpo_pendulum] epoch #742 | Saved
2022-08-17 17:59:46 | [trpo_pendulum] epoch #742 | Time 306.58 s
2022-08-17 17:59:46 | [trpo_pendulum] epoch #742 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -484.643
Evaluation/AverageReturn              -1122.6
Evaluation/Iteration                    742
Evaluation/MaxReturn                  -1072.2
Evaluation/MinReturn                  -1182.98
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     40.3309
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41649
GaussianMLPPolicy/KL                      6.52975e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -430.045
GaussianMLPPolicy/LossBefore           -430.005
GaussianMLPPolicy/dLoss                   0.0401306
GaussianMLPValueFunction/LossAfter    22177.8
GaussianMLPValueFunction/LossBefore   22199.4
GaussianMLPValueFunction/dLoss           21.6445
TotalEnvSteps                        891600
-----------------------------------  ----------------
2022-08-17 17:59:47 | [trpo_pendulum] epoch #743 | Saving snapshot...
2022-08-17 17:59:47 | [trpo_pendulum] epoch #743 | Saved
2022-08-17 17:59:47 | [trpo_pendulum] epoch #743 | Time 306.99 s
2022-08-17 17:59:47 | [trpo_pendulum] epoch #743 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -481.765
Evaluation/AverageReturn              -1118.09
Evaluation/Iteration                    743
Evaluation/MaxReturn                  -1026.95
Evaluation/MinReturn                  -1142.86
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     41.4052
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41658
GaussianMLPPolicy/KL                      5.83419e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -411.368
GaussianMLPPolicy/LossBefore           -411.329
GaussianMLPPolicy/dLoss                   0.0382385
GaussianMLPValueFunction/LossAfter    21936.6
GaussianMLPValueFunction/LossBefore   21957.7
GaussianMLPValueFunction/dLoss           21.0898
TotalEnvSteps                        892800
-----------------------------------  ----------------
2022-08-17 17:59:47 | [trpo_pendulum] epoch #744 | Saving snapshot...
2022-08-17 17:59:47 | [trpo_pendulum] epoch #744 | Saved
2022-08-17 17:59:47 | [trpo_pendulum] epoch #744 | Time 307.40 s
2022-08-17 17:59:47 | [trpo_pendulum] epoch #744 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -416.9
Evaluation/AverageReturn              -1034.85
Evaluation/Iteration                    744
Evaluation/MaxReturn                   -915.048
Evaluation/MinReturn                  -1187.91
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     84.8834
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41662
GaussianMLPPolicy/KL                      2.06138e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -403.914
GaussianMLPPolicy/LossBefore           -403.912
GaussianMLPPolicy/dLoss                   0.00161743
GaussianMLPValueFunction/LossAfter    21049.4
GaussianMLPValueFunction/LossBefore   21069.4
GaussianMLPValueFunction/dLoss           20.0078
TotalEnvSteps                        894000
-----------------------------------  ----------------
2022-08-17 17:59:47 | [trpo_pendulum] epoch #745 | Saving snapshot...
2022-08-17 17:59:47 | [trpo_pendulum] epoch #745 | Saved
2022-08-17 17:59:47 | [trpo_pendulum] epoch #745 | Time 307.82 s
2022-08-17 17:59:47 | [trpo_pendulum] epoch #745 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -415.142
Evaluation/AverageReturn              -1056.87
Evaluation/Iteration                    745
Evaluation/MaxReturn                  -1031.36
Evaluation/MinReturn                  -1118.04
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     29.1039
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41658
GaussianMLPPolicy/KL                      2.27131e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -425.52
GaussianMLPPolicy/LossBefore           -425.44
GaussianMLPPolicy/dLoss                   0.0805054
GaussianMLPValueFunction/LossAfter    22428.8
GaussianMLPValueFunction/LossBefore   22449.8
GaussianMLPValueFunction/dLoss           21.0723
TotalEnvSteps                        895200
-----------------------------------  ----------------
2022-08-17 17:59:48 | [trpo_pendulum] epoch #746 | Saving snapshot...
2022-08-17 17:59:48 | [trpo_pendulum] epoch #746 | Saved
2022-08-17 17:59:48 | [trpo_pendulum] epoch #746 | Time 308.22 s
2022-08-17 17:59:48 | [trpo_pendulum] epoch #746 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -683.236
Evaluation/AverageReturn              -1439.21
Evaluation/Iteration                    746
Evaluation/MaxReturn                  -1242.7
Evaluation/MinReturn                  -1642.64
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    151.313
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41652
GaussianMLPPolicy/KL                      4.35376e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -502.709
GaussianMLPPolicy/LossBefore           -502.717
GaussianMLPPolicy/dLoss                  -0.00808716
GaussianMLPValueFunction/LossAfter    34905.9
GaussianMLPValueFunction/LossBefore   34938.4
GaussianMLPValueFunction/dLoss           32.4688
TotalEnvSteps                        896400
-----------------------------------  ----------------
2022-08-17 17:59:48 | [trpo_pendulum] epoch #747 | Saving snapshot...
2022-08-17 17:59:48 | [trpo_pendulum] epoch #747 | Saved
2022-08-17 17:59:48 | [trpo_pendulum] epoch #747 | Time 308.64 s
2022-08-17 17:59:48 | [trpo_pendulum] epoch #747 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -464.272
Evaluation/AverageReturn              -1112.35
Evaluation/Iteration                    747
Evaluation/MaxReturn                  -1036.04
Evaluation/MinReturn                  -1178.58
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     58.3434
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41656
GaussianMLPPolicy/KL                      1.06921e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -414.472
GaussianMLPPolicy/LossBefore           -414.458
GaussianMLPPolicy/dLoss                   0.0140381
GaussianMLPValueFunction/LossAfter    22995.7
GaussianMLPValueFunction/LossBefore   23017.5
GaussianMLPValueFunction/dLoss           21.8281
TotalEnvSteps                        897600
-----------------------------------  ----------------
2022-08-17 17:59:49 | [trpo_pendulum] epoch #748 | Saving snapshot...
2022-08-17 17:59:49 | [trpo_pendulum] epoch #748 | Saved
2022-08-17 17:59:49 | [trpo_pendulum] epoch #748 | Time 309.04 s
2022-08-17 17:59:49 | [trpo_pendulum] epoch #748 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -454.437
Evaluation/AverageReturn              -1074.44
Evaluation/Iteration                    748
Evaluation/MaxReturn                  -1010.81
Evaluation/MinReturn                  -1126.02
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     38.7608
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41664
GaussianMLPPolicy/KL                      2.3336e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -400.876
GaussianMLPPolicy/LossBefore           -400.868
GaussianMLPPolicy/dLoss                   0.00799561
GaussianMLPValueFunction/LossAfter    20547.9
GaussianMLPValueFunction/LossBefore   20567.2
GaussianMLPValueFunction/dLoss           19.3594
TotalEnvSteps                        898800
-----------------------------------  ---------------
2022-08-17 17:59:49 | [trpo_pendulum] epoch #749 | Saving snapshot...
2022-08-17 17:59:49 | [trpo_pendulum] epoch #749 | Saved
2022-08-17 17:59:49 | [trpo_pendulum] epoch #749 | Time 309.45 s
2022-08-17 17:59:49 | [trpo_pendulum] epoch #749 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -454.167
Evaluation/AverageReturn              -1089.77
Evaluation/Iteration                    749
Evaluation/MaxReturn                  -1037.96
Evaluation/MinReturn                  -1178.46
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     58.1516
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4167
GaussianMLPPolicy/KL                      2.19089e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -413.991
GaussianMLPPolicy/LossBefore           -413.918
GaussianMLPPolicy/dLoss                   0.0726624
GaussianMLPValueFunction/LossAfter    22215.9
GaussianMLPValueFunction/LossBefore   22236.4
GaussianMLPValueFunction/dLoss           20.5098
TotalEnvSteps                        900000
-----------------------------------  ----------------
2022-08-17 17:59:49 | [trpo_pendulum] epoch #750 | Saving snapshot...
2022-08-17 17:59:49 | [trpo_pendulum] epoch #750 | Saved
2022-08-17 17:59:49 | [trpo_pendulum] epoch #750 | Time 309.85 s
2022-08-17 17:59:49 | [trpo_pendulum] epoch #750 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -446.033
Evaluation/AverageReturn              -1056.63
Evaluation/Iteration                    750
Evaluation/MaxReturn                   -930.047
Evaluation/MinReturn                  -1142.08
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     78.4122
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41673
GaussianMLPPolicy/KL                      3.9296e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -399.492
GaussianMLPPolicy/LossBefore           -399.407
GaussianMLPPolicy/dLoss                   0.084198
GaussianMLPValueFunction/LossAfter    20055.3
GaussianMLPValueFunction/LossBefore   20073.7
GaussianMLPValueFunction/dLoss           18.3555
TotalEnvSteps                        901200
-----------------------------------  ---------------
2022-08-17 17:59:50 | [trpo_pendulum] epoch #751 | Saving snapshot...
2022-08-17 17:59:50 | [trpo_pendulum] epoch #751 | Saved
2022-08-17 17:59:50 | [trpo_pendulum] epoch #751 | Time 310.26 s
2022-08-17 17:59:50 | [trpo_pendulum] epoch #751 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -523.584
Evaluation/AverageReturn              -1134.08
Evaluation/Iteration                    751
Evaluation/MaxReturn                  -1102.54
Evaluation/MinReturn                  -1195.17
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     30.381
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41683
GaussianMLPPolicy/KL                      3.46004e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -389.897
GaussianMLPPolicy/LossBefore           -389.919
GaussianMLPPolicy/dLoss                  -0.0222168
GaussianMLPValueFunction/LossAfter    20552.5
GaussianMLPValueFunction/LossBefore   20570.9
GaussianMLPValueFunction/dLoss           18.4082
TotalEnvSteps                        902400
-----------------------------------  ----------------
2022-08-17 17:59:50 | [trpo_pendulum] epoch #752 | Saving snapshot...
2022-08-17 17:59:50 | [trpo_pendulum] epoch #752 | Saved
2022-08-17 17:59:50 | [trpo_pendulum] epoch #752 | Time 310.67 s
2022-08-17 17:59:50 | [trpo_pendulum] epoch #752 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -443.55
Evaluation/AverageReturn              -1053.28
Evaluation/Iteration                    752
Evaluation/MaxReturn                   -874.495
Evaluation/MinReturn                  -1148.4
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     89.9317
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41706
GaussianMLPPolicy/KL                      2.48303e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -384.635
GaussianMLPPolicy/LossBefore           -384.584
GaussianMLPPolicy/dLoss                   0.0509033
GaussianMLPValueFunction/LossAfter    19798.1
GaussianMLPValueFunction/LossBefore   19815.7
GaussianMLPValueFunction/dLoss           17.584
TotalEnvSteps                        903600
-----------------------------------  ----------------
2022-08-17 17:59:51 | [trpo_pendulum] epoch #753 | Saving snapshot...
2022-08-17 17:59:51 | [trpo_pendulum] epoch #753 | Saved
2022-08-17 17:59:51 | [trpo_pendulum] epoch #753 | Time 311.09 s
2022-08-17 17:59:51 | [trpo_pendulum] epoch #753 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -537.345
Evaluation/AverageReturn              -1152.34
Evaluation/Iteration                    753
Evaluation/MaxReturn                  -1114.94
Evaluation/MinReturn                  -1229.89
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     36.5724
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41732
GaussianMLPPolicy/KL                      7.08378e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -395.312
GaussianMLPPolicy/LossBefore           -395.309
GaussianMLPPolicy/dLoss                   0.0027771
GaussianMLPValueFunction/LossAfter    21077.2
GaussianMLPValueFunction/LossBefore   21095.5
GaussianMLPValueFunction/dLoss           18.3262
TotalEnvSteps                        904800
-----------------------------------  ----------------
2022-08-17 17:59:51 | [trpo_pendulum] epoch #754 | Saving snapshot...
2022-08-17 17:59:51 | [trpo_pendulum] epoch #754 | Saved
2022-08-17 17:59:51 | [trpo_pendulum] epoch #754 | Time 311.49 s
2022-08-17 17:59:51 | [trpo_pendulum] epoch #754 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -556.114
Evaluation/AverageReturn              -1189.49
Evaluation/Iteration                    754
Evaluation/MaxReturn                  -1083.7
Evaluation/MinReturn                  -1325.74
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     82.4514
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4176
GaussianMLPPolicy/KL                      9.17765e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -409.811
GaussianMLPPolicy/LossBefore           -409.548
GaussianMLPPolicy/dLoss                   0.262878
GaussianMLPValueFunction/LossAfter    22683.1
GaussianMLPValueFunction/LossBefore   22702.7
GaussianMLPValueFunction/dLoss           19.5352
TotalEnvSteps                        906000
-----------------------------------  ----------------
2022-08-17 17:59:52 | [trpo_pendulum] epoch #755 | Saving snapshot...
2022-08-17 17:59:52 | [trpo_pendulum] epoch #755 | Saved
2022-08-17 17:59:52 | [trpo_pendulum] epoch #755 | Time 311.89 s
2022-08-17 17:59:52 | [trpo_pendulum] epoch #755 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -447.802
Evaluation/AverageReturn              -1057.92
Evaluation/Iteration                    755
Evaluation/MaxReturn                   -990.479
Evaluation/MinReturn                  -1121.63
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     44.0255
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41782
GaussianMLPPolicy/KL                      0.000189884
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -399.514
GaussianMLPPolicy/LossBefore           -399.289
GaussianMLPPolicy/dLoss                   0.224823
GaussianMLPValueFunction/LossAfter    19813.9
GaussianMLPValueFunction/LossBefore   19831
GaussianMLPValueFunction/dLoss           17.1289
TotalEnvSteps                        907200
-----------------------------------  ----------------
2022-08-17 17:59:52 | [trpo_pendulum] epoch #756 | Saving snapshot...
2022-08-17 17:59:52 | [trpo_pendulum] epoch #756 | Saved
2022-08-17 17:59:52 | [trpo_pendulum] epoch #756 | Time 312.29 s
2022-08-17 17:59:52 | [trpo_pendulum] epoch #756 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -566.025
Evaluation/AverageReturn              -1201.44
Evaluation/Iteration                    756
Evaluation/MaxReturn                  -1121.48
Evaluation/MinReturn                  -1247.07
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     42.8257
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41807
GaussianMLPPolicy/KL                      0.000128144
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -410.243
GaussianMLPPolicy/LossBefore           -410.206
GaussianMLPPolicy/dLoss                   0.0370483
GaussianMLPValueFunction/LossAfter    22671.7
GaussianMLPValueFunction/LossBefore   22690.9
GaussianMLPValueFunction/dLoss           19.2422
TotalEnvSteps                        908400
-----------------------------------  ----------------
2022-08-17 17:59:52 | [trpo_pendulum] epoch #757 | Saving snapshot...
2022-08-17 17:59:52 | [trpo_pendulum] epoch #757 | Saved
2022-08-17 17:59:52 | [trpo_pendulum] epoch #757 | Time 312.71 s
2022-08-17 17:59:52 | [trpo_pendulum] epoch #757 | EpochTime 0.42 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -506.793
Evaluation/AverageReturn              -1143.84
Evaluation/Iteration                    757
Evaluation/MaxReturn                   -998.148
Evaluation/MinReturn                  -1242.71
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     82.0522
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41831
GaussianMLPPolicy/KL                      3.8051e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -413.993
GaussianMLPPolicy/LossBefore           -414.054
GaussianMLPPolicy/dLoss                  -0.0612793
GaussianMLPValueFunction/LossAfter    22034
GaussianMLPValueFunction/LossBefore   22052.8
GaussianMLPValueFunction/dLoss           18.752
TotalEnvSteps                        909600
-----------------------------------  ---------------
2022-08-17 17:59:53 | [trpo_pendulum] epoch #758 | Saving snapshot...
2022-08-17 17:59:53 | [trpo_pendulum] epoch #758 | Saved
2022-08-17 17:59:53 | [trpo_pendulum] epoch #758 | Time 313.13 s
2022-08-17 17:59:53 | [trpo_pendulum] epoch #758 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -523.743
Evaluation/AverageReturn              -1179.18
Evaluation/Iteration                    758
Evaluation/MaxReturn                  -1121.69
Evaluation/MinReturn                  -1255.26
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.3538
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41843
GaussianMLPPolicy/KL                      1.52102e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -436.663
GaussianMLPPolicy/LossBefore           -436.677
GaussianMLPPolicy/dLoss                  -0.0146484
GaussianMLPValueFunction/LossAfter    23128.3
GaussianMLPValueFunction/LossBefore   23147.9
GaussianMLPValueFunction/dLoss           19.6582
TotalEnvSteps                        910800
-----------------------------------  ----------------
2022-08-17 17:59:53 | [trpo_pendulum] epoch #759 | Saving snapshot...
2022-08-17 17:59:53 | [trpo_pendulum] epoch #759 | Saved
2022-08-17 17:59:53 | [trpo_pendulum] epoch #759 | Time 313.54 s
2022-08-17 17:59:53 | [trpo_pendulum] epoch #759 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -617.653
Evaluation/AverageReturn              -1298.83
Evaluation/Iteration                    759
Evaluation/MaxReturn                  -1129.93
Evaluation/MinReturn                  -1484.9
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    111.57
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4185
GaussianMLPPolicy/KL                      2.17003e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -451.749
GaussianMLPPolicy/LossBefore           -451.701
GaussianMLPPolicy/dLoss                   0.0482178
GaussianMLPValueFunction/LossAfter    26999.8
GaussianMLPValueFunction/LossBefore   27022.8
GaussianMLPValueFunction/dLoss           22.9336
TotalEnvSteps                        912000
-----------------------------------  ----------------
2022-08-17 17:59:54 | [trpo_pendulum] epoch #760 | Saving snapshot...
2022-08-17 17:59:54 | [trpo_pendulum] epoch #760 | Saved
2022-08-17 17:59:54 | [trpo_pendulum] epoch #760 | Time 313.96 s
2022-08-17 17:59:54 | [trpo_pendulum] epoch #760 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -489.345
Evaluation/AverageReturn              -1140.06
Evaluation/Iteration                    760
Evaluation/MaxReturn                  -1086.6
Evaluation/MinReturn                  -1229.82
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     46.6775
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41865
GaussianMLPPolicy/KL                      8.39674e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -417.446
GaussianMLPPolicy/LossBefore           -417.402
GaussianMLPPolicy/dLoss                   0.044281
GaussianMLPValueFunction/LossAfter    22418.5
GaussianMLPValueFunction/LossBefore   22437.9
GaussianMLPValueFunction/dLoss           19.3887
TotalEnvSteps                        913200
-----------------------------------  ----------------
2022-08-17 17:59:54 | [trpo_pendulum] epoch #761 | Saving snapshot...
2022-08-17 17:59:54 | [trpo_pendulum] epoch #761 | Saved
2022-08-17 17:59:54 | [trpo_pendulum] epoch #761 | Time 314.36 s
2022-08-17 17:59:54 | [trpo_pendulum] epoch #761 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -510.434
Evaluation/AverageReturn              -1173.27
Evaluation/Iteration                    761
Evaluation/MaxReturn                  -1121.34
Evaluation/MinReturn                  -1231.37
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     42.2675
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41885
GaussianMLPPolicy/KL                      6.34656e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -428.581
GaussianMLPPolicy/LossBefore           -428.556
GaussianMLPPolicy/dLoss                   0.0243225
GaussianMLPValueFunction/LossAfter    23632.5
GaussianMLPValueFunction/LossBefore   23652.9
GaussianMLPValueFunction/dLoss           20.3672
TotalEnvSteps                        914400
-----------------------------------  ----------------
2022-08-17 17:59:54 | [trpo_pendulum] epoch #762 | Saving snapshot...
2022-08-17 17:59:54 | [trpo_pendulum] epoch #762 | Saved
2022-08-17 17:59:54 | [trpo_pendulum] epoch #762 | Time 314.78 s
2022-08-17 17:59:54 | [trpo_pendulum] epoch #762 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -466.209
Evaluation/AverageReturn              -1142.14
Evaluation/Iteration                    762
Evaluation/MaxReturn                  -1050.02
Evaluation/MinReturn                  -1214.69
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.9131
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41898
GaussianMLPPolicy/KL                      7.88902e-07
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -447.571
GaussianMLPPolicy/LossBefore           -447.553
GaussianMLPPolicy/dLoss                   0.0173035
GaussianMLPValueFunction/LossAfter    24522.3
GaussianMLPValueFunction/LossBefore   24543.5
GaussianMLPValueFunction/dLoss           21.2383
TotalEnvSteps                        915600
-----------------------------------  ----------------
2022-08-17 17:59:55 | [trpo_pendulum] epoch #763 | Saving snapshot...
2022-08-17 17:59:55 | [trpo_pendulum] epoch #763 | Saved
2022-08-17 17:59:55 | [trpo_pendulum] epoch #763 | Time 315.19 s
2022-08-17 17:59:55 | [trpo_pendulum] epoch #763 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -481.702
Evaluation/AverageReturn              -1132.28
Evaluation/Iteration                    763
Evaluation/MaxReturn                  -1046.4
Evaluation/MinReturn                  -1184.06
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     52.8394
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41896
GaussianMLPPolicy/KL                      2.52057e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -435.385
GaussianMLPPolicy/LossBefore           -435.288
GaussianMLPPolicy/dLoss                   0.097168
GaussianMLPValueFunction/LossAfter    23296.9
GaussianMLPValueFunction/LossBefore   23317.1
GaussianMLPValueFunction/dLoss           20.2031
TotalEnvSteps                        916800
-----------------------------------  ----------------
2022-08-17 17:59:55 | [trpo_pendulum] epoch #764 | Saving snapshot...
2022-08-17 17:59:55 | [trpo_pendulum] epoch #764 | Saved
2022-08-17 17:59:55 | [trpo_pendulum] epoch #764 | Time 315.60 s
2022-08-17 17:59:55 | [trpo_pendulum] epoch #764 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -499.389
Evaluation/AverageReturn              -1185.43
Evaluation/Iteration                    764
Evaluation/MaxReturn                  -1167.27
Evaluation/MinReturn                  -1198.89
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.84407
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4188
GaussianMLPPolicy/KL                      7.06718e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -463.32
GaussianMLPPolicy/LossBefore           -463.271
GaussianMLPPolicy/dLoss                   0.0489807
GaussianMLPValueFunction/LossAfter    25727
GaussianMLPValueFunction/LossBefore   25749.5
GaussianMLPValueFunction/dLoss           22.4512
TotalEnvSteps                        918000
-----------------------------------  ----------------
2022-08-17 17:59:56 | [trpo_pendulum] epoch #765 | Saving snapshot...
2022-08-17 17:59:56 | [trpo_pendulum] epoch #765 | Saved
2022-08-17 17:59:56 | [trpo_pendulum] epoch #765 | Time 316.00 s
2022-08-17 17:59:56 | [trpo_pendulum] epoch #765 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -503.143
Evaluation/AverageReturn              -1153.13
Evaluation/Iteration                    765
Evaluation/MaxReturn                  -1099.83
Evaluation/MinReturn                  -1188.24
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     33.6285
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41874
GaussianMLPPolicy/KL                      8.05575e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -416.997
GaussianMLPPolicy/LossBefore           -416.82
GaussianMLPPolicy/dLoss                   0.176727
GaussianMLPValueFunction/LossAfter    22355.6
GaussianMLPValueFunction/LossBefore   22375.2
GaussianMLPValueFunction/dLoss           19.5801
TotalEnvSteps                        919200
-----------------------------------  ----------------
2022-08-17 17:59:56 | [trpo_pendulum] epoch #766 | Saving snapshot...
2022-08-17 17:59:56 | [trpo_pendulum] epoch #766 | Saved
2022-08-17 17:59:56 | [trpo_pendulum] epoch #766 | Time 316.43 s
2022-08-17 17:59:56 | [trpo_pendulum] epoch #766 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -514.621
Evaluation/AverageReturn              -1178.69
Evaluation/Iteration                    766
Evaluation/MaxReturn                  -1131.44
Evaluation/MinReturn                  -1246.22
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     40.2962
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41869
GaussianMLPPolicy/KL                      1.17301e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -435.632
GaussianMLPPolicy/LossBefore           -435.637
GaussianMLPPolicy/dLoss                  -0.00512695
GaussianMLPValueFunction/LossAfter    23561.1
GaussianMLPValueFunction/LossBefore   23581.7
GaussianMLPValueFunction/dLoss           20.5742
TotalEnvSteps                        920400
-----------------------------------  ----------------
2022-08-17 17:59:56 | [trpo_pendulum] epoch #767 | Saving snapshot...
2022-08-17 17:59:57 | [trpo_pendulum] epoch #767 | Saved
2022-08-17 17:59:57 | [trpo_pendulum] epoch #767 | Time 316.87 s
2022-08-17 17:59:57 | [trpo_pendulum] epoch #767 | EpochTime 0.44 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -480.663
Evaluation/AverageReturn              -1118.55
Evaluation/Iteration                    767
Evaluation/MaxReturn                  -1006.16
Evaluation/MinReturn                  -1198.95
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     61.6865
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41861
GaussianMLPPolicy/KL                      3.72696e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -417.551
GaussianMLPPolicy/LossBefore           -417.392
GaussianMLPPolicy/dLoss                   0.158752
GaussianMLPValueFunction/LossAfter    21718.5
GaussianMLPValueFunction/LossBefore   21737.4
GaussianMLPValueFunction/dLoss           18.9609
TotalEnvSteps                        921600
-----------------------------------  ----------------
2022-08-17 17:59:57 | [trpo_pendulum] epoch #768 | Saving snapshot...
2022-08-17 17:59:57 | [trpo_pendulum] epoch #768 | Saved
2022-08-17 17:59:57 | [trpo_pendulum] epoch #768 | Time 317.30 s
2022-08-17 17:59:57 | [trpo_pendulum] epoch #768 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -486.744
Evaluation/AverageReturn              -1163.93
Evaluation/Iteration                    768
Evaluation/MaxReturn                  -1103.97
Evaluation/MinReturn                  -1203.57
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     38.0771
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41839
GaussianMLPPolicy/KL                      0.000342134
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -457.513
GaussianMLPPolicy/LossBefore           -456.833
GaussianMLPPolicy/dLoss                   0.679718
GaussianMLPValueFunction/LossAfter    24680.6
GaussianMLPValueFunction/LossBefore   24702.1
GaussianMLPValueFunction/dLoss           21.5078
TotalEnvSteps                        922800
-----------------------------------  ----------------
2022-08-17 17:59:57 | [trpo_pendulum] epoch #769 | Saving snapshot...
2022-08-17 17:59:57 | [trpo_pendulum] epoch #769 | Saved
2022-08-17 17:59:57 | [trpo_pendulum] epoch #769 | Time 317.72 s
2022-08-17 17:59:57 | [trpo_pendulum] epoch #769 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -604.87
Evaluation/AverageReturn              -1270.16
Evaluation/Iteration                    769
Evaluation/MaxReturn                  -1201.48
Evaluation/MinReturn                  -1346.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     60.1241
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41825
GaussianMLPPolicy/KL                      0.000293554
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -431.759
GaussianMLPPolicy/LossBefore           -431.488
GaussianMLPPolicy/dLoss                   0.270721
GaussianMLPValueFunction/LossAfter    25084.4
GaussianMLPValueFunction/LossBefore   25106.2
GaussianMLPValueFunction/dLoss           21.8223
TotalEnvSteps                        924000
-----------------------------------  ----------------
2022-08-17 17:59:58 | [trpo_pendulum] epoch #770 | Saving snapshot...
2022-08-17 17:59:58 | [trpo_pendulum] epoch #770 | Saved
2022-08-17 17:59:58 | [trpo_pendulum] epoch #770 | Time 318.12 s
2022-08-17 17:59:58 | [trpo_pendulum] epoch #770 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -653.822
Evaluation/AverageReturn              -1366.33
Evaluation/Iteration                    770
Evaluation/MaxReturn                  -1266.75
Evaluation/MinReturn                  -1525.12
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     86.8901
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41806
GaussianMLPPolicy/KL                      0.000190276
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -474.172
GaussianMLPPolicy/LossBefore           -474.095
GaussianMLPPolicy/dLoss                   0.077301
GaussianMLPValueFunction/LossAfter    29989.9
GaussianMLPValueFunction/LossBefore   30016.2
GaussianMLPValueFunction/dLoss           26.377
TotalEnvSteps                        925200
-----------------------------------  ----------------
2022-08-17 17:59:58 | [trpo_pendulum] epoch #771 | Saving snapshot...
2022-08-17 17:59:58 | [trpo_pendulum] epoch #771 | Saved
2022-08-17 17:59:58 | [trpo_pendulum] epoch #771 | Time 318.54 s
2022-08-17 17:59:58 | [trpo_pendulum] epoch #771 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -455.687
Evaluation/AverageReturn              -1087.58
Evaluation/Iteration                    771
Evaluation/MaxReturn                  -1017.51
Evaluation/MinReturn                  -1166.89
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     65.5293
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41798
GaussianMLPPolicy/KL                      0.000376583
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -403.946
GaussianMLPPolicy/LossBefore           -403.642
GaussianMLPPolicy/dLoss                   0.304291
GaussianMLPValueFunction/LossAfter    21028.5
GaussianMLPValueFunction/LossBefore   21047.4
GaussianMLPValueFunction/dLoss           18.8867
TotalEnvSteps                        926400
-----------------------------------  ----------------
2022-08-17 17:59:59 | [trpo_pendulum] epoch #772 | Saving snapshot...
2022-08-17 17:59:59 | [trpo_pendulum] epoch #772 | Saved
2022-08-17 17:59:59 | [trpo_pendulum] epoch #772 | Time 318.95 s
2022-08-17 17:59:59 | [trpo_pendulum] epoch #772 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -477.403
Evaluation/AverageReturn              -1122.49
Evaluation/Iteration                    772
Evaluation/MaxReturn                  -1061.28
Evaluation/MinReturn                  -1156.42
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     36.3279
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41797
GaussianMLPPolicy/KL                      0.000504317
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -416.956
GaussianMLPPolicy/LossBefore           -416.519
GaussianMLPPolicy/dLoss                   0.43631
GaussianMLPValueFunction/LossAfter    22056.7
GaussianMLPValueFunction/LossBefore   22076.3
GaussianMLPValueFunction/dLoss           19.6387
TotalEnvSteps                        927600
-----------------------------------  ----------------
2022-08-17 17:59:59 | [trpo_pendulum] epoch #773 | Saving snapshot...
2022-08-17 17:59:59 | [trpo_pendulum] epoch #773 | Saved
2022-08-17 17:59:59 | [trpo_pendulum] epoch #773 | Time 319.35 s
2022-08-17 17:59:59 | [trpo_pendulum] epoch #773 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -416.597
Evaluation/AverageReturn              -1044.25
Evaluation/Iteration                    773
Evaluation/MaxReturn                   -922.212
Evaluation/MinReturn                  -1119.57
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     59.955
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41792
GaussianMLPPolicy/KL                      0.000322441
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -410.956
GaussianMLPPolicy/LossBefore           -410.948
GaussianMLPPolicy/dLoss                   0.00769043
GaussianMLPValueFunction/LossAfter    21084.7
GaussianMLPValueFunction/LossBefore   21103.3
GaussianMLPValueFunction/dLoss           18.6133
TotalEnvSteps                        928800
-----------------------------------  ----------------
2022-08-17 17:59:59 | [trpo_pendulum] epoch #774 | Saving snapshot...
2022-08-17 17:59:59 | [trpo_pendulum] epoch #774 | Saved
2022-08-17 17:59:59 | [trpo_pendulum] epoch #774 | Time 319.76 s
2022-08-17 17:59:59 | [trpo_pendulum] epoch #774 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -620.28
Evaluation/AverageReturn              -1300.64
Evaluation/Iteration                    774
Evaluation/MaxReturn                  -1234.8
Evaluation/MinReturn                  -1357.24
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     40.0583
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41791
GaussianMLPPolicy/KL                      0.000168568
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -443.104
GaussianMLPPolicy/LossBefore           -443.074
GaussianMLPPolicy/dLoss                   0.0293579
GaussianMLPValueFunction/LossAfter    26785.9
GaussianMLPValueFunction/LossBefore   26809.3
GaussianMLPValueFunction/dLoss           23.377
TotalEnvSteps                        930000
-----------------------------------  ----------------
2022-08-17 18:00:00 | [trpo_pendulum] epoch #775 | Saving snapshot...
2022-08-17 18:00:00 | [trpo_pendulum] epoch #775 | Saved
2022-08-17 18:00:00 | [trpo_pendulum] epoch #775 | Time 320.18 s
2022-08-17 18:00:00 | [trpo_pendulum] epoch #775 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -445.046
Evaluation/AverageReturn              -1042.69
Evaluation/Iteration                    775
Evaluation/MaxReturn                   -889.719
Evaluation/MinReturn                  -1159.85
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    116.384
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41798
GaussianMLPPolicy/KL                      0.000319464
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -381.334
GaussianMLPPolicy/LossBefore           -381.063
GaussianMLPPolicy/dLoss                   0.270966
GaussianMLPValueFunction/LossAfter    18974.1
GaussianMLPValueFunction/LossBefore   18990.9
GaussianMLPValueFunction/dLoss           16.8164
TotalEnvSteps                        931200
-----------------------------------  ----------------
2022-08-17 18:00:00 | [trpo_pendulum] epoch #776 | Saving snapshot...
2022-08-17 18:00:00 | [trpo_pendulum] epoch #776 | Saved
2022-08-17 18:00:00 | [trpo_pendulum] epoch #776 | Time 320.60 s
2022-08-17 18:00:00 | [trpo_pendulum] epoch #776 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -456.238
Evaluation/AverageReturn              -1060.1
Evaluation/Iteration                    776
Evaluation/MaxReturn                   -992.316
Evaluation/MinReturn                  -1119.62
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.3122
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41819
GaussianMLPPolicy/KL                      0.000356946
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -379.06
GaussianMLPPolicy/LossBefore           -378.8
GaussianMLPPolicy/dLoss                   0.259216
GaussianMLPValueFunction/LossAfter    18785.6
GaussianMLPValueFunction/LossBefore   18801.9
GaussianMLPValueFunction/dLoss           16.3672
TotalEnvSteps                        932400
-----------------------------------  ----------------
2022-08-17 18:00:01 | [trpo_pendulum] epoch #777 | Saving snapshot...
2022-08-17 18:00:01 | [trpo_pendulum] epoch #777 | Saved
2022-08-17 18:00:01 | [trpo_pendulum] epoch #777 | Time 321.03 s
2022-08-17 18:00:01 | [trpo_pendulum] epoch #777 | EpochTime 0.43 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -432.963
Evaluation/AverageReturn              -1004.6
Evaluation/Iteration                    777
Evaluation/MaxReturn                   -768.906
Evaluation/MinReturn                  -1096.52
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    109.147
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41832
GaussianMLPPolicy/KL                      0.00040866
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -372.754
GaussianMLPPolicy/LossBefore           -372.488
GaussianMLPPolicy/dLoss                   0.265381
GaussianMLPValueFunction/LossAfter    18088
GaussianMLPValueFunction/LossBefore   18103.4
GaussianMLPValueFunction/dLoss           15.4238
TotalEnvSteps                        933600
-----------------------------------  ---------------
2022-08-17 18:00:01 | [trpo_pendulum] epoch #778 | Saving snapshot...
2022-08-17 18:00:01 | [trpo_pendulum] epoch #778 | Saved
2022-08-17 18:00:01 | [trpo_pendulum] epoch #778 | Time 321.45 s
2022-08-17 18:00:01 | [trpo_pendulum] epoch #778 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -359.435
Evaluation/AverageReturn               -902.394
Evaluation/Iteration                    778
Evaluation/MaxReturn                   -773.764
Evaluation/MinReturn                  -1051.04
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    108.087
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41846
GaussianMLPPolicy/KL                      0.000389528
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -346.487
GaussianMLPPolicy/LossBefore           -346.257
GaussianMLPPolicy/dLoss                   0.229462
GaussianMLPValueFunction/LossAfter    15452.1
GaussianMLPValueFunction/LossBefore   15465.1
GaussianMLPValueFunction/dLoss           13.0332
TotalEnvSteps                        934800
-----------------------------------  ----------------
2022-08-17 18:00:02 | [trpo_pendulum] epoch #779 | Saving snapshot...
2022-08-17 18:00:02 | [trpo_pendulum] epoch #779 | Saved
2022-08-17 18:00:02 | [trpo_pendulum] epoch #779 | Time 321.87 s
2022-08-17 18:00:02 | [trpo_pendulum] epoch #779 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -654.234
Evaluation/AverageReturn              -1413.86
Evaluation/Iteration                    779
Evaluation/MaxReturn                  -1284.11
Evaluation/MinReturn                  -1713.92
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    139.828
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41855
GaussianMLPPolicy/KL                      0.000264743
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -505.871
GaussianMLPPolicy/LossBefore           -505.607
GaussianMLPPolicy/dLoss                   0.263916
GaussianMLPValueFunction/LossAfter    33437.5
GaussianMLPValueFunction/LossBefore   33465.3
GaussianMLPValueFunction/dLoss           27.8086
TotalEnvSteps                        936000
-----------------------------------  ----------------
2022-08-17 18:00:02 | [trpo_pendulum] epoch #780 | Saving snapshot...
2022-08-17 18:00:02 | [trpo_pendulum] epoch #780 | Saved
2022-08-17 18:00:02 | [trpo_pendulum] epoch #780 | Time 322.30 s
2022-08-17 18:00:02 | [trpo_pendulum] epoch #780 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -528.199
Evaluation/AverageReturn              -1140.56
Evaluation/Iteration                    780
Evaluation/MaxReturn                  -1080.64
Evaluation/MinReturn                  -1223.93
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     55.3206
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41865
GaussianMLPPolicy/KL                      0.000613422
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -396.535
GaussianMLPPolicy/LossBefore           -395.789
GaussianMLPPolicy/dLoss                   0.74646
GaussianMLPValueFunction/LossAfter    20540.6
GaussianMLPValueFunction/LossBefore   20558.1
GaussianMLPValueFunction/dLoss           17.5098
TotalEnvSteps                        937200
-----------------------------------  ----------------
2022-08-17 18:00:02 | [trpo_pendulum] epoch #781 | Saving snapshot...
2022-08-17 18:00:02 | [trpo_pendulum] epoch #781 | Saved
2022-08-17 18:00:02 | [trpo_pendulum] epoch #781 | Time 322.72 s
2022-08-17 18:00:02 | [trpo_pendulum] epoch #781 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -667.274
Evaluation/AverageReturn              -1457.41
Evaluation/Iteration                    781
Evaluation/MaxReturn                  -1421.17
Evaluation/MinReturn                  -1525.1
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     39.6302
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41888
GaussianMLPPolicy/KL                      0.000322607
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -512.761
GaussianMLPPolicy/LossBefore           -512.712
GaussianMLPPolicy/dLoss                   0.0496216
GaussianMLPValueFunction/LossAfter    35362.6
GaussianMLPValueFunction/LossBefore   35393.2
GaussianMLPValueFunction/dLoss           30.6562
TotalEnvSteps                        938400
-----------------------------------  ----------------
2022-08-17 18:00:03 | [trpo_pendulum] epoch #782 | Saving snapshot...
2022-08-17 18:00:03 | [trpo_pendulum] epoch #782 | Saved
2022-08-17 18:00:03 | [trpo_pendulum] epoch #782 | Time 323.12 s
2022-08-17 18:00:03 | [trpo_pendulum] epoch #782 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -402.85
Evaluation/AverageReturn               -916.875
Evaluation/Iteration                    782
Evaluation/MaxReturn                   -846.116
Evaluation/MinReturn                   -986.935
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     45.4105
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41911
GaussianMLPPolicy/KL                      0.000333338
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -325.898
GaussianMLPPolicy/LossBefore           -325.91
GaussianMLPPolicy/dLoss                  -0.0123596
GaussianMLPValueFunction/LossAfter    13636.6
GaussianMLPValueFunction/LossBefore   13648.7
GaussianMLPValueFunction/dLoss           12.1953
TotalEnvSteps                        939600
-----------------------------------  ----------------
2022-08-17 18:00:03 | [trpo_pendulum] epoch #783 | Saving snapshot...
2022-08-17 18:00:03 | [trpo_pendulum] epoch #783 | Saved
2022-08-17 18:00:03 | [trpo_pendulum] epoch #783 | Time 323.55 s
2022-08-17 18:00:03 | [trpo_pendulum] epoch #783 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -365.504
Evaluation/AverageReturn               -856.316
Evaluation/Iteration                    783
Evaluation/MaxReturn                   -786.322
Evaluation/MinReturn                  -1003.55
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     74.3589
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41925
GaussianMLPPolicy/KL                      0.000239095
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -316.392
GaussianMLPPolicy/LossBefore           -316.346
GaussianMLPPolicy/dLoss                   0.0465393
GaussianMLPValueFunction/LossAfter    12203.1
GaussianMLPValueFunction/LossBefore   12213.6
GaussianMLPValueFunction/dLoss           10.5576
TotalEnvSteps                        940800
-----------------------------------  ----------------
2022-08-17 18:00:04 | [trpo_pendulum] epoch #784 | Saving snapshot...
2022-08-17 18:00:04 | [trpo_pendulum] epoch #784 | Saved
2022-08-17 18:00:04 | [trpo_pendulum] epoch #784 | Time 323.97 s
2022-08-17 18:00:04 | [trpo_pendulum] epoch #784 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -375.597
Evaluation/AverageReturn               -899.385
Evaluation/Iteration                    784
Evaluation/MaxReturn                   -867.971
Evaluation/MinReturn                   -929.918
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     20.9887
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41923
GaussianMLPPolicy/KL                      0.000223148
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -344.893
GaussianMLPPolicy/LossBefore           -344.788
GaussianMLPPolicy/dLoss                   0.104492
GaussianMLPValueFunction/LossAfter    14385.1
GaussianMLPValueFunction/LossBefore   14396.9
GaussianMLPValueFunction/dLoss           11.8672
TotalEnvSteps                        942000
-----------------------------------  ----------------
2022-08-17 18:00:04 | [trpo_pendulum] epoch #785 | Saving snapshot...
2022-08-17 18:00:04 | [trpo_pendulum] epoch #785 | Saved
2022-08-17 18:00:04 | [trpo_pendulum] epoch #785 | Time 324.40 s
2022-08-17 18:00:04 | [trpo_pendulum] epoch #785 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -454.112
Evaluation/AverageReturn              -1002.82
Evaluation/Iteration                    785
Evaluation/MaxReturn                   -879.023
Evaluation/MinReturn                  -1160.94
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     89.6812
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41927
GaussianMLPPolicy/KL                      0.000118596
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -347.468
GaussianMLPPolicy/LossBefore           -347.523
GaussianMLPPolicy/dLoss                  -0.0552063
GaussianMLPValueFunction/LossAfter    16403.1
GaussianMLPValueFunction/LossBefore   16416.1
GaussianMLPValueFunction/dLoss           13.0527
TotalEnvSteps                        943200
-----------------------------------  ----------------
2022-08-17 18:00:04 | [trpo_pendulum] epoch #786 | Saving snapshot...
2022-08-17 18:00:04 | [trpo_pendulum] epoch #786 | Saved
2022-08-17 18:00:04 | [trpo_pendulum] epoch #786 | Time 324.82 s
2022-08-17 18:00:04 | [trpo_pendulum] epoch #786 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -379.557
Evaluation/AverageReturn               -887.055
Evaluation/Iteration                    786
Evaluation/MaxReturn                   -794.374
Evaluation/MinReturn                   -971.049
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     53.7348
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41933
GaussianMLPPolicy/KL                      0.000157857
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -320.396
GaussianMLPPolicy/LossBefore           -320.259
GaussianMLPPolicy/dLoss                   0.137482
GaussianMLPValueFunction/LossAfter    13234.9
GaussianMLPValueFunction/LossBefore   13245.3
GaussianMLPValueFunction/dLoss           10.4629
TotalEnvSteps                        944400
-----------------------------------  ----------------
2022-08-17 18:00:05 | [trpo_pendulum] epoch #787 | Saving snapshot...
2022-08-17 18:00:05 | [trpo_pendulum] epoch #787 | Saved
2022-08-17 18:00:05 | [trpo_pendulum] epoch #787 | Time 325.24 s
2022-08-17 18:00:05 | [trpo_pendulum] epoch #787 | EpochTime 0.42 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -501.341
Evaluation/AverageReturn              -1132.23
Evaluation/Iteration                    787
Evaluation/MaxReturn                   -958.301
Evaluation/MinReturn                  -1242.63
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     94.1648
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41944
GaussianMLPPolicy/KL                      5.8319e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -406.39
GaussianMLPPolicy/LossBefore           -406.287
GaussianMLPPolicy/dLoss                   0.103058
GaussianMLPValueFunction/LossAfter    21992
GaussianMLPValueFunction/LossBefore   22008.7
GaussianMLPValueFunction/dLoss           16.7324
TotalEnvSteps                        945600
-----------------------------------  ---------------
2022-08-17 18:00:05 | [trpo_pendulum] epoch #788 | Saving snapshot...
2022-08-17 18:00:05 | [trpo_pendulum] epoch #788 | Saved
2022-08-17 18:00:05 | [trpo_pendulum] epoch #788 | Time 325.65 s
2022-08-17 18:00:05 | [trpo_pendulum] epoch #788 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -579.789
Evaluation/AverageReturn              -1295.33
Evaluation/Iteration                    788
Evaluation/MaxReturn                  -1100.78
Evaluation/MinReturn                  -1413.21
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     95.4107
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41955
GaussianMLPPolicy/KL                      1.48967e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -470.356
GaussianMLPPolicy/LossBefore           -470.355
GaussianMLPPolicy/dLoss                   0.00112915
GaussianMLPValueFunction/LossAfter    28388.2
GaussianMLPValueFunction/LossBefore   28410.3
GaussianMLPValueFunction/dLoss           22.0645
TotalEnvSteps                        946800
-----------------------------------  ----------------
2022-08-17 18:00:06 | [trpo_pendulum] epoch #789 | Saving snapshot...
2022-08-17 18:00:06 | [trpo_pendulum] epoch #789 | Saved
2022-08-17 18:00:06 | [trpo_pendulum] epoch #789 | Time 326.07 s
2022-08-17 18:00:06 | [trpo_pendulum] epoch #789 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -375.036
Evaluation/AverageReturn               -877.526
Evaluation/Iteration                    789
Evaluation/MaxReturn                   -770.301
Evaluation/MinReturn                   -969.004
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     65.6382
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41963
GaussianMLPPolicy/KL                      1.23668e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -319.883
GaussianMLPPolicy/LossBefore           -319.825
GaussianMLPPolicy/dLoss                   0.0584717
GaussianMLPValueFunction/LossAfter    12923.9
GaussianMLPValueFunction/LossBefore   12934.3
GaussianMLPValueFunction/dLoss           10.3369
TotalEnvSteps                        948000
-----------------------------------  ----------------
2022-08-17 18:00:06 | [trpo_pendulum] epoch #790 | Saving snapshot...
2022-08-17 18:00:06 | [trpo_pendulum] epoch #790 | Saved
2022-08-17 18:00:06 | [trpo_pendulum] epoch #790 | Time 326.48 s
2022-08-17 18:00:06 | [trpo_pendulum] epoch #790 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -437.851
Evaluation/AverageReturn               -976.866
Evaluation/Iteration                    790
Evaluation/MaxReturn                   -861.687
Evaluation/MinReturn                  -1204.72
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    123.671
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41974
GaussianMLPPolicy/KL                      3.71483e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -341.969
GaussianMLPPolicy/LossBefore           -341.974
GaussianMLPPolicy/dLoss                  -0.00482178
GaussianMLPValueFunction/LossAfter    15711.6
GaussianMLPValueFunction/LossBefore   15723.6
GaussianMLPValueFunction/dLoss           12.0625
TotalEnvSteps                        949200
-----------------------------------  ----------------
2022-08-17 18:00:07 | [trpo_pendulum] epoch #791 | Saving snapshot...
2022-08-17 18:00:07 | [trpo_pendulum] epoch #791 | Saved
2022-08-17 18:00:07 | [trpo_pendulum] epoch #791 | Time 326.90 s
2022-08-17 18:00:07 | [trpo_pendulum] epoch #791 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -686.424
Evaluation/AverageReturn              -1540.93
Evaluation/Iteration                    791
Evaluation/MaxReturn                  -1447.09
Evaluation/MinReturn                  -1635.15
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     55.2835
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41973
GaussianMLPPolicy/KL                      6.81354e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -578.992
GaussianMLPPolicy/LossBefore           -578.904
GaussianMLPPolicy/dLoss                   0.0880737
GaussianMLPValueFunction/LossAfter    40556.5
GaussianMLPValueFunction/LossBefore   40588.6
GaussianMLPValueFunction/dLoss           32.1211
TotalEnvSteps                        950400
-----------------------------------  ----------------
2022-08-17 18:00:07 | [trpo_pendulum] epoch #792 | Saving snapshot...
2022-08-17 18:00:07 | [trpo_pendulum] epoch #792 | Saved
2022-08-17 18:00:07 | [trpo_pendulum] epoch #792 | Time 327.32 s
2022-08-17 18:00:07 | [trpo_pendulum] epoch #792 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -689.474
Evaluation/AverageReturn              -1527.71
Evaluation/Iteration                    792
Evaluation/MaxReturn                  -1338.52
Evaluation/MinReturn                  -1684.65
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    114.622
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41955
GaussianMLPPolicy/KL                      9.39178e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -573.256
GaussianMLPPolicy/LossBefore           -573.226
GaussianMLPPolicy/dLoss                   0.0303345
GaussianMLPValueFunction/LossAfter    39916.6
GaussianMLPValueFunction/LossBefore   39950.7
GaussianMLPValueFunction/dLoss           34.0977
TotalEnvSteps                        951600
-----------------------------------  ----------------
2022-08-17 18:00:07 | [trpo_pendulum] epoch #793 | Saving snapshot...
2022-08-17 18:00:07 | [trpo_pendulum] epoch #793 | Saved
2022-08-17 18:00:07 | [trpo_pendulum] epoch #793 | Time 327.74 s
2022-08-17 18:00:07 | [trpo_pendulum] epoch #793 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -542.438
Evaluation/AverageReturn              -1214.67
Evaluation/Iteration                    793
Evaluation/MaxReturn                  -1069.5
Evaluation/MinReturn                  -1369.04
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     95.2016
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41942
GaussianMLPPolicy/KL                      3.90306e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -437.545
GaussianMLPPolicy/LossBefore           -437.476
GaussianMLPPolicy/dLoss                   0.0695801
GaussianMLPValueFunction/LossAfter    24700.4
GaussianMLPValueFunction/LossBefore   24722.3
GaussianMLPValueFunction/dLoss           21.8164
TotalEnvSteps                        952800
-----------------------------------  ----------------
2022-08-17 18:00:08 | [trpo_pendulum] epoch #794 | Saving snapshot...
2022-08-17 18:00:08 | [trpo_pendulum] epoch #794 | Saved
2022-08-17 18:00:08 | [trpo_pendulum] epoch #794 | Time 328.15 s
2022-08-17 18:00:08 | [trpo_pendulum] epoch #794 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -392.66
Evaluation/AverageReturn               -899.654
Evaluation/Iteration                    794
Evaluation/MaxReturn                   -789.144
Evaluation/MinReturn                  -1057.33
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     79.6427
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41927
GaussianMLPPolicy/KL                      1.25666e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -324.041
GaussianMLPPolicy/LossBefore           -324.05
GaussianMLPPolicy/dLoss                  -0.00842285
GaussianMLPValueFunction/LossAfter    13353.7
GaussianMLPValueFunction/LossBefore   13365.5
GaussianMLPValueFunction/dLoss           11.8574
TotalEnvSteps                        954000
-----------------------------------  ----------------
2022-08-17 18:00:08 | [trpo_pendulum] epoch #795 | Saving snapshot...
2022-08-17 18:00:08 | [trpo_pendulum] epoch #795 | Saved
2022-08-17 18:00:08 | [trpo_pendulum] epoch #795 | Time 328.58 s
2022-08-17 18:00:08 | [trpo_pendulum] epoch #795 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -744.263
Evaluation/AverageReturn              -1667.94
Evaluation/Iteration                    795
Evaluation/MaxReturn                  -1584.73
Evaluation/MinReturn                  -1752.82
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     61.8327
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41904
GaussianMLPPolicy/KL                      3.84904e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -627.167
GaussianMLPPolicy/LossBefore           -626.945
GaussianMLPPolicy/dLoss                   0.222778
GaussianMLPValueFunction/LossAfter    47930.1
GaussianMLPValueFunction/LossBefore   47973.4
GaussianMLPValueFunction/dLoss           43.3086
TotalEnvSteps                        955200
-----------------------------------  ----------------
2022-08-17 18:00:09 | [trpo_pendulum] epoch #796 | Saving snapshot...
2022-08-17 18:00:09 | [trpo_pendulum] epoch #796 | Saved
2022-08-17 18:00:09 | [trpo_pendulum] epoch #796 | Time 328.99 s
2022-08-17 18:00:09 | [trpo_pendulum] epoch #796 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -365.721
Evaluation/AverageReturn               -852.434
Evaluation/Iteration                    796
Evaluation/MaxReturn                   -769.695
Evaluation/MinReturn                   -911.456
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     54.4447
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41882
GaussianMLPPolicy/KL                      0.000100097
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -308.486
GaussianMLPPolicy/LossBefore           -308.422
GaussianMLPPolicy/dLoss                   0.0640564
GaussianMLPValueFunction/LossAfter    12072.6
GaussianMLPValueFunction/LossBefore   12083.9
GaussianMLPValueFunction/dLoss           11.3477
TotalEnvSteps                        956400
-----------------------------------  ----------------
2022-08-17 18:00:09 | [trpo_pendulum] epoch #797 | Saving snapshot...
2022-08-17 18:00:09 | [trpo_pendulum] epoch #797 | Saved
2022-08-17 18:00:09 | [trpo_pendulum] epoch #797 | Time 329.41 s
2022-08-17 18:00:09 | [trpo_pendulum] epoch #797 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -560.399
Evaluation/AverageReturn              -1254.91
Evaluation/Iteration                    797
Evaluation/MaxReturn                  -1169.48
Evaluation/MinReturn                  -1285.23
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     38.9701
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41861
GaussianMLPPolicy/KL                      3.65131e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -456.513
GaussianMLPPolicy/LossBefore           -456.497
GaussianMLPPolicy/dLoss                   0.0166931
GaussianMLPValueFunction/LossAfter    25789.2
GaussianMLPValueFunction/LossBefore   25812.3
GaussianMLPValueFunction/dLoss           23.127
TotalEnvSteps                        957600
-----------------------------------  ----------------
2022-08-17 18:00:09 | [trpo_pendulum] epoch #798 | Saving snapshot...
2022-08-17 18:00:09 | [trpo_pendulum] epoch #798 | Saved
2022-08-17 18:00:09 | [trpo_pendulum] epoch #798 | Time 329.82 s
2022-08-17 18:00:09 | [trpo_pendulum] epoch #798 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -585.359
Evaluation/AverageReturn              -1288.43
Evaluation/Iteration                    798
Evaluation/MaxReturn                  -1081.81
Evaluation/MinReturn                  -1387.74
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    100.133
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41836
GaussianMLPPolicy/KL                      3.44567e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -467.452
GaussianMLPPolicy/LossBefore           -467.413
GaussianMLPPolicy/dLoss                   0.0387573
GaussianMLPValueFunction/LossAfter    27405.2
GaussianMLPValueFunction/LossBefore   27430
GaussianMLPValueFunction/dLoss           24.7656
TotalEnvSteps                        958800
-----------------------------------  ----------------
2022-08-17 18:00:10 | [trpo_pendulum] epoch #799 | Saving snapshot...
2022-08-17 18:00:10 | [trpo_pendulum] epoch #799 | Saved
2022-08-17 18:00:10 | [trpo_pendulum] epoch #799 | Time 330.24 s
2022-08-17 18:00:10 | [trpo_pendulum] epoch #799 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -540.874
Evaluation/AverageReturn              -1189.15
Evaluation/Iteration                    799
Evaluation/MaxReturn                  -1076.73
Evaluation/MinReturn                  -1300.47
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     98.7723
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41801
GaussianMLPPolicy/KL                      9.62204e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -431.354
GaussianMLPPolicy/LossBefore           -431.344
GaussianMLPPolicy/dLoss                   0.0108643
GaussianMLPValueFunction/LossAfter    23110.5
GaussianMLPValueFunction/LossBefore   23131.5
GaussianMLPValueFunction/dLoss           21.0137
TotalEnvSteps                        960000
-----------------------------------  ----------------
2022-08-17 18:00:10 | [trpo_pendulum] epoch #800 | Saving snapshot...
2022-08-17 18:00:10 | [trpo_pendulum] epoch #800 | Saved
2022-08-17 18:00:10 | [trpo_pendulum] epoch #800 | Time 330.66 s
2022-08-17 18:00:10 | [trpo_pendulum] epoch #800 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -424.062
Evaluation/AverageReturn               -963.532
Evaluation/Iteration                    800
Evaluation/MaxReturn                   -856.636
Evaluation/MinReturn                  -1036.13
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     56.1576
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4178
GaussianMLPPolicy/KL                      2.86048e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -336.588
GaussianMLPPolicy/LossBefore           -336.57
GaussianMLPPolicy/dLoss                   0.0177917
GaussianMLPValueFunction/LossAfter    15062.6
GaussianMLPValueFunction/LossBefore   15076.3
GaussianMLPValueFunction/dLoss           13.668
TotalEnvSteps                        961200
-----------------------------------  ----------------
2022-08-17 18:00:11 | [trpo_pendulum] epoch #801 | Saving snapshot...
2022-08-17 18:00:11 | [trpo_pendulum] epoch #801 | Saved
2022-08-17 18:00:11 | [trpo_pendulum] epoch #801 | Time 331.07 s
2022-08-17 18:00:11 | [trpo_pendulum] epoch #801 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -591.56
Evaluation/AverageReturn              -1309.22
Evaluation/Iteration                    801
Evaluation/MaxReturn                   -973.688
Evaluation/MinReturn                  -1406.79
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    153.878
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41766
GaussianMLPPolicy/KL                      2.76879e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -468.123
GaussianMLPPolicy/LossBefore           -468.132
GaussianMLPPolicy/dLoss                  -0.0090332
GaussianMLPValueFunction/LossAfter    28725.5
GaussianMLPValueFunction/LossBefore   28751
GaussianMLPValueFunction/dLoss           25.4277
TotalEnvSteps                        962400
-----------------------------------  ----------------
2022-08-17 18:00:11 | [trpo_pendulum] epoch #802 | Saving snapshot...
2022-08-17 18:00:11 | [trpo_pendulum] epoch #802 | Saved
2022-08-17 18:00:11 | [trpo_pendulum] epoch #802 | Time 331.50 s
2022-08-17 18:00:11 | [trpo_pendulum] epoch #802 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -414.477
Evaluation/AverageReturn               -936.066
Evaluation/Iteration                    802
Evaluation/MaxReturn                   -822.789
Evaluation/MinReturn                  -1042.19
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     86.5854
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41753
GaussianMLPPolicy/KL                      5.69301e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -331.576
GaussianMLPPolicy/LossBefore           -331.536
GaussianMLPPolicy/dLoss                   0.0393677
GaussianMLPValueFunction/LossAfter    14321.8
GaussianMLPValueFunction/LossBefore   14334.6
GaussianMLPValueFunction/dLoss           12.8271
TotalEnvSteps                        963600
-----------------------------------  ----------------
2022-08-17 18:00:12 | [trpo_pendulum] epoch #803 | Saving snapshot...
2022-08-17 18:00:12 | [trpo_pendulum] epoch #803 | Saved
2022-08-17 18:00:12 | [trpo_pendulum] epoch #803 | Time 331.90 s
2022-08-17 18:00:12 | [trpo_pendulum] epoch #803 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -671.755
Evaluation/AverageReturn              -1461.63
Evaluation/Iteration                    803
Evaluation/MaxReturn                  -1358.32
Evaluation/MinReturn                  -1611.54
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     88.9011
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41753
GaussianMLPPolicy/KL                      7.82355e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -513.712
GaussianMLPPolicy/LossBefore           -513.669
GaussianMLPPolicy/dLoss                   0.0437012
GaussianMLPValueFunction/LossAfter    34890.2
GaussianMLPValueFunction/LossBefore   34921.1
GaussianMLPValueFunction/dLoss           30.8828
TotalEnvSteps                        964800
-----------------------------------  ----------------
2022-08-17 18:00:12 | [trpo_pendulum] epoch #804 | Saving snapshot...
2022-08-17 18:00:12 | [trpo_pendulum] epoch #804 | Saved
2022-08-17 18:00:12 | [trpo_pendulum] epoch #804 | Time 332.31 s
2022-08-17 18:00:12 | [trpo_pendulum] epoch #804 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -669.081
Evaluation/AverageReturn              -1464.65
Evaluation/Iteration                    804
Evaluation/MaxReturn                  -1305.57
Evaluation/MinReturn                  -1596.68
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     91.3791
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41746
GaussianMLPPolicy/KL                      1.51964e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -532.907
GaussianMLPPolicy/LossBefore           -532.875
GaussianMLPPolicy/dLoss                   0.0326538
GaussianMLPValueFunction/LossAfter    35353.1
GaussianMLPValueFunction/LossBefore   35385.8
GaussianMLPValueFunction/dLoss           32.6758
TotalEnvSteps                        966000
-----------------------------------  ----------------
2022-08-17 18:00:12 | [trpo_pendulum] epoch #805 | Saving snapshot...
2022-08-17 18:00:12 | [trpo_pendulum] epoch #805 | Saved
2022-08-17 18:00:12 | [trpo_pendulum] epoch #805 | Time 332.73 s
2022-08-17 18:00:12 | [trpo_pendulum] epoch #805 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -487.79
Evaluation/AverageReturn              -1083.51
Evaluation/Iteration                    805
Evaluation/MaxReturn                   -978.247
Evaluation/MinReturn                  -1169.42
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     58.7095
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41745
GaussianMLPPolicy/KL                      0.000141228
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -381.431
GaussianMLPPolicy/LossBefore           -381.111
GaussianMLPPolicy/dLoss                   0.319641
GaussianMLPValueFunction/LossAfter    18938.7
GaussianMLPValueFunction/LossBefore   18956.4
GaussianMLPValueFunction/dLoss           17.7598
TotalEnvSteps                        967200
-----------------------------------  ----------------
2022-08-17 18:00:13 | [trpo_pendulum] epoch #806 | Saving snapshot...
2022-08-17 18:00:13 | [trpo_pendulum] epoch #806 | Saved
2022-08-17 18:00:13 | [trpo_pendulum] epoch #806 | Time 333.15 s
2022-08-17 18:00:13 | [trpo_pendulum] epoch #806 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -344.902
Evaluation/AverageReturn               -834.822
Evaluation/Iteration                    806
Evaluation/MaxReturn                   -649.809
Evaluation/MinReturn                  -1001.65
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    115.063
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41728
GaussianMLPPolicy/KL                      0.000312424
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -321.051
GaussianMLPPolicy/LossBefore           -320.602
GaussianMLPPolicy/dLoss                   0.449188
GaussianMLPValueFunction/LossAfter    12792.2
GaussianMLPValueFunction/LossBefore   12804
GaussianMLPValueFunction/dLoss           11.7861
TotalEnvSteps                        968400
-----------------------------------  ----------------
2022-08-17 18:00:13 | [trpo_pendulum] epoch #807 | Saving snapshot...
2022-08-17 18:00:13 | [trpo_pendulum] epoch #807 | Saved
2022-08-17 18:00:13 | [trpo_pendulum] epoch #807 | Time 333.58 s
2022-08-17 18:00:13 | [trpo_pendulum] epoch #807 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -657.063
Evaluation/AverageReturn              -1463.73
Evaluation/Iteration                    807
Evaluation/MaxReturn                  -1343.6
Evaluation/MinReturn                  -1591.43
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     81.1575
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41732
GaussianMLPPolicy/KL                      0.000208693
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -519.861
GaussianMLPPolicy/LossBefore           -519.708
GaussianMLPPolicy/dLoss                   0.152405
GaussianMLPValueFunction/LossAfter    35745.8
GaussianMLPValueFunction/LossBefore   35778.2
GaussianMLPValueFunction/dLoss           32.3672
TotalEnvSteps                        969600
-----------------------------------  ----------------
2022-08-17 18:00:14 | [trpo_pendulum] epoch #808 | Saving snapshot...
2022-08-17 18:00:14 | [trpo_pendulum] epoch #808 | Saved
2022-08-17 18:00:14 | [trpo_pendulum] epoch #808 | Time 334.01 s
2022-08-17 18:00:14 | [trpo_pendulum] epoch #808 | EpochTime 0.43 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -579.122
Evaluation/AverageReturn              -1288.96
Evaluation/Iteration                    808
Evaluation/MaxReturn                  -1276.44
Evaluation/MinReturn                  -1308.05
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                      9.8021
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41733
GaussianMLPPolicy/KL                      0.000425169
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -468.366
GaussianMLPPolicy/LossBefore           -467.785
GaussianMLPPolicy/dLoss                   0.580566
GaussianMLPValueFunction/LossAfter    27163.8
GaussianMLPValueFunction/LossBefore   27189
GaussianMLPValueFunction/dLoss           25.2441
TotalEnvSteps                        970800
-----------------------------------  ----------------
2022-08-17 18:00:14 | [trpo_pendulum] epoch #809 | Saving snapshot...
2022-08-17 18:00:14 | [trpo_pendulum] epoch #809 | Saved
2022-08-17 18:00:14 | [trpo_pendulum] epoch #809 | Time 334.42 s
2022-08-17 18:00:14 | [trpo_pendulum] epoch #809 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -395.179
Evaluation/AverageReturn               -908.433
Evaluation/Iteration                    809
Evaluation/MaxReturn                   -852.827
Evaluation/MinReturn                   -995.87
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     54.965
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41739
GaussianMLPPolicy/KL                      0.000362427
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -321.338
GaussianMLPPolicy/LossBefore           -321.239
GaussianMLPPolicy/dLoss                   0.0990601
GaussianMLPValueFunction/LossAfter    13362.9
GaussianMLPValueFunction/LossBefore   13375.4
GaussianMLPValueFunction/dLoss           12.499
TotalEnvSteps                        972000
-----------------------------------  ----------------
2022-08-17 18:00:14 | [trpo_pendulum] epoch #810 | Saving snapshot...
2022-08-17 18:00:14 | [trpo_pendulum] epoch #810 | Saved
2022-08-17 18:00:14 | [trpo_pendulum] epoch #810 | Time 334.82 s
2022-08-17 18:00:14 | [trpo_pendulum] epoch #810 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -426.416
Evaluation/AverageReturn               -980.638
Evaluation/Iteration                    810
Evaluation/MaxReturn                   -749.831
Evaluation/MinReturn                  -1127.36
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    126.302
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41733
GaussianMLPPolicy/KL                      0.000247132
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -363.628
GaussianMLPPolicy/LossBefore           -363.628
GaussianMLPPolicy/dLoss                  -0.000183105
GaussianMLPValueFunction/LossAfter    15870.1
GaussianMLPValueFunction/LossBefore   15884.3
GaussianMLPValueFunction/dLoss           14.1982
TotalEnvSteps                        973200
-----------------------------------  ----------------
2022-08-17 18:00:15 | [trpo_pendulum] epoch #811 | Saving snapshot...
2022-08-17 18:00:15 | [trpo_pendulum] epoch #811 | Saved
2022-08-17 18:00:15 | [trpo_pendulum] epoch #811 | Time 335.23 s
2022-08-17 18:00:15 | [trpo_pendulum] epoch #811 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -368.368
Evaluation/AverageReturn               -891.176
Evaluation/Iteration                    811
Evaluation/MaxReturn                   -779.408
Evaluation/MinReturn                   -958.864
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     60.0547
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41726
GaussianMLPPolicy/KL                      0.000306822
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -332.824
GaussianMLPPolicy/LossBefore           -332.554
GaussianMLPPolicy/dLoss                   0.269806
GaussianMLPValueFunction/LossAfter    13708
GaussianMLPValueFunction/LossBefore   13720
GaussianMLPValueFunction/dLoss           11.9766
TotalEnvSteps                        974400
-----------------------------------  ----------------
2022-08-17 18:00:15 | [trpo_pendulum] epoch #812 | Saving snapshot...
2022-08-17 18:00:15 | [trpo_pendulum] epoch #812 | Saved
2022-08-17 18:00:15 | [trpo_pendulum] epoch #812 | Time 335.64 s
2022-08-17 18:00:15 | [trpo_pendulum] epoch #812 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -582.617
Evaluation/AverageReturn              -1311.54
Evaluation/Iteration                    812
Evaluation/MaxReturn                  -1200.03
Evaluation/MinReturn                  -1416.21
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     74.7831
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4172
GaussianMLPPolicy/KL                      0.000588947
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -480.336
GaussianMLPPolicy/LossBefore           -479.399
GaussianMLPPolicy/dLoss                   0.936981
GaussianMLPValueFunction/LossAfter    28622.5
GaussianMLPValueFunction/LossBefore   28646.8
GaussianMLPValueFunction/dLoss           24.3594
TotalEnvSteps                        975600
-----------------------------------  ----------------
2022-08-17 18:00:16 | [trpo_pendulum] epoch #813 | Saving snapshot...
2022-08-17 18:00:16 | [trpo_pendulum] epoch #813 | Saved
2022-08-17 18:00:16 | [trpo_pendulum] epoch #813 | Time 336.06 s
2022-08-17 18:00:16 | [trpo_pendulum] epoch #813 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -514.648
Evaluation/AverageReturn              -1223.94
Evaluation/Iteration                    813
Evaluation/MaxReturn                  -1166.49
Evaluation/MinReturn                  -1293.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     44.8447
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41718
GaussianMLPPolicy/KL                      0.000368019
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -461.827
GaussianMLPPolicy/LossBefore           -461.914
GaussianMLPPolicy/dLoss                  -0.0869446
GaussianMLPValueFunction/LossAfter    25808.1
GaussianMLPValueFunction/LossBefore   25830.6
GaussianMLPValueFunction/dLoss           22.4863
TotalEnvSteps                        976800
-----------------------------------  ----------------
2022-08-17 18:00:16 | [trpo_pendulum] epoch #814 | Saving snapshot...
2022-08-17 18:00:16 | [trpo_pendulum] epoch #814 | Saved
2022-08-17 18:00:16 | [trpo_pendulum] epoch #814 | Time 336.48 s
2022-08-17 18:00:16 | [trpo_pendulum] epoch #814 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -570.46
Evaluation/AverageReturn              -1353.67
Evaluation/Iteration                    814
Evaluation/MaxReturn                  -1271.7
Evaluation/MinReturn                  -1411.48
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     50.1465
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41724
GaussianMLPPolicy/KL                      0.000109383
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -511.471
GaussianMLPPolicy/LossBefore           -511.639
GaussianMLPPolicy/dLoss                  -0.16748
GaussianMLPValueFunction/LossAfter    32008.4
GaussianMLPValueFunction/LossBefore   32036.9
GaussianMLPValueFunction/dLoss           28.5566
TotalEnvSteps                        978000
-----------------------------------  ----------------
2022-08-17 18:00:17 | [trpo_pendulum] epoch #815 | Saving snapshot...
2022-08-17 18:00:17 | [trpo_pendulum] epoch #815 | Saved
2022-08-17 18:00:17 | [trpo_pendulum] epoch #815 | Time 336.89 s
2022-08-17 18:00:17 | [trpo_pendulum] epoch #815 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -756.247
Evaluation/AverageReturn              -1735.62
Evaluation/Iteration                    815
Evaluation/MaxReturn                  -1566.92
Evaluation/MinReturn                  -1828.96
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     89.2565
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41737
GaussianMLPPolicy/KL                      1.84812e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -650.445
GaussianMLPPolicy/LossBefore           -650.468
GaussianMLPPolicy/dLoss                  -0.022522
GaussianMLPValueFunction/LossAfter    52278.6
GaussianMLPValueFunction/LossBefore   52329.1
GaussianMLPValueFunction/dLoss           50.5625
TotalEnvSteps                        979200
-----------------------------------  ----------------
2022-08-17 18:00:17 | [trpo_pendulum] epoch #816 | Saving snapshot...
2022-08-17 18:00:17 | [trpo_pendulum] epoch #816 | Saved
2022-08-17 18:00:17 | [trpo_pendulum] epoch #816 | Time 337.29 s
2022-08-17 18:00:17 | [trpo_pendulum] epoch #816 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -458.446
Evaluation/AverageReturn              -1133.17
Evaluation/Iteration                    816
Evaluation/MaxReturn                  -1052.15
Evaluation/MinReturn                  -1179.03
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     46.9632
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41749
GaussianMLPPolicy/KL                      1.13211e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -440.406
GaussianMLPPolicy/LossBefore           -440.429
GaussianMLPPolicy/dLoss                  -0.0229492
GaussianMLPValueFunction/LossAfter    22958.8
GaussianMLPValueFunction/LossBefore   22981.7
GaussianMLPValueFunction/dLoss           22.9414
TotalEnvSteps                        980400
-----------------------------------  ----------------
2022-08-17 18:00:17 | [trpo_pendulum] epoch #817 | Saving snapshot...
2022-08-17 18:00:17 | [trpo_pendulum] epoch #817 | Saved
2022-08-17 18:00:17 | [trpo_pendulum] epoch #817 | Time 337.71 s
2022-08-17 18:00:17 | [trpo_pendulum] epoch #817 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -719.302
Evaluation/AverageReturn              -1666.33
Evaluation/Iteration                    817
Evaluation/MaxReturn                  -1471.99
Evaluation/MinReturn                  -1791.77
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    109.623
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41774
GaussianMLPPolicy/KL                      1.11139e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -622.876
GaussianMLPPolicy/LossBefore           -622.718
GaussianMLPPolicy/dLoss                   0.158142
GaussianMLPValueFunction/LossAfter    48696.9
GaussianMLPValueFunction/LossBefore   48747.3
GaussianMLPValueFunction/dLoss           50.4336
TotalEnvSteps                        981600
-----------------------------------  ----------------
2022-08-17 18:00:18 | [trpo_pendulum] epoch #818 | Saving snapshot...
2022-08-17 18:00:18 | [trpo_pendulum] epoch #818 | Saved
2022-08-17 18:00:18 | [trpo_pendulum] epoch #818 | Time 338.14 s
2022-08-17 18:00:18 | [trpo_pendulum] epoch #818 | EpochTime 0.42 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -652.017
Evaluation/AverageReturn              -1507.29
Evaluation/Iteration                    818
Evaluation/MaxReturn                  -1408.81
Evaluation/MinReturn                  -1625.47
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     77.4117
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41799
GaussianMLPPolicy/KL                      2.52054e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -567.838
GaussianMLPPolicy/LossBefore           -567.717
GaussianMLPPolicy/dLoss                   0.120911
GaussianMLPValueFunction/LossAfter    38917
GaussianMLPValueFunction/LossBefore   38959.2
GaussianMLPValueFunction/dLoss           42.1562
TotalEnvSteps                        982800
-----------------------------------  ----------------
2022-08-17 18:00:18 | [trpo_pendulum] epoch #819 | Saving snapshot...
2022-08-17 18:00:18 | [trpo_pendulum] epoch #819 | Saved
2022-08-17 18:00:18 | [trpo_pendulum] epoch #819 | Time 338.56 s
2022-08-17 18:00:18 | [trpo_pendulum] epoch #819 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -435.38
Evaluation/AverageReturn              -1048.57
Evaluation/Iteration                    819
Evaluation/MaxReturn                   -955.394
Evaluation/MinReturn                  -1162.79
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     66.642
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41827
GaussianMLPPolicy/KL                      3.86613e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -391.635
GaussianMLPPolicy/LossBefore           -391.606
GaussianMLPPolicy/dLoss                   0.0289307
GaussianMLPValueFunction/LossAfter    18827
GaussianMLPValueFunction/LossBefore   18847.6
GaussianMLPValueFunction/dLoss           20.541
TotalEnvSteps                        984000
-----------------------------------  ----------------
2022-08-17 18:00:19 | [trpo_pendulum] epoch #820 | Saving snapshot...
2022-08-17 18:00:19 | [trpo_pendulum] epoch #820 | Saved
2022-08-17 18:00:19 | [trpo_pendulum] epoch #820 | Time 338.95 s
2022-08-17 18:00:19 | [trpo_pendulum] epoch #820 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -455.804
Evaluation/AverageReturn              -1139.61
Evaluation/Iteration                    820
Evaluation/MaxReturn                  -1021.8
Evaluation/MinReturn                  -1274.61
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     78.6703
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41862
GaussianMLPPolicy/KL                      1.37474e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -438.383
GaussianMLPPolicy/LossBefore           -438.349
GaussianMLPPolicy/dLoss                   0.0335388
GaussianMLPValueFunction/LossAfter    23573.5
GaussianMLPValueFunction/LossBefore   23598.5
GaussianMLPValueFunction/dLoss           24.9844
TotalEnvSteps                        985200
-----------------------------------  ----------------
2022-08-17 18:00:19 | [trpo_pendulum] epoch #821 | Saving snapshot...
2022-08-17 18:00:19 | [trpo_pendulum] epoch #821 | Saved
2022-08-17 18:00:19 | [trpo_pendulum] epoch #821 | Time 339.36 s
2022-08-17 18:00:19 | [trpo_pendulum] epoch #821 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -639.116
Evaluation/AverageReturn              -1503.14
Evaluation/Iteration                    821
Evaluation/MaxReturn                  -1396.87
Evaluation/MinReturn                  -1609.16
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     63.2791
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41896
GaussianMLPPolicy/KL                      2.02957e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -573.225
GaussianMLPPolicy/LossBefore           -573.135
GaussianMLPPolicy/dLoss                   0.090271
GaussianMLPValueFunction/LossAfter    39373.7
GaussianMLPValueFunction/LossBefore   39415.9
GaussianMLPValueFunction/dLoss           42.1289
TotalEnvSteps                        986400
-----------------------------------  ----------------
2022-08-17 18:00:19 | [trpo_pendulum] epoch #822 | Saving snapshot...
2022-08-17 18:00:19 | [trpo_pendulum] epoch #822 | Saved
2022-08-17 18:00:19 | [trpo_pendulum] epoch #822 | Time 339.78 s
2022-08-17 18:00:19 | [trpo_pendulum] epoch #822 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -365.811
Evaluation/AverageReturn               -972.667
Evaluation/Iteration                    822
Evaluation/MaxReturn                   -939.373
Evaluation/MinReturn                  -1043.68
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     33.8648
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41928
GaussianMLPPolicy/KL                      1.7986e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -390.916
GaussianMLPPolicy/LossBefore           -390.901
GaussianMLPPolicy/dLoss                   0.0148926
GaussianMLPValueFunction/LossAfter    18081.6
GaussianMLPValueFunction/LossBefore   18101.1
GaussianMLPValueFunction/dLoss           19.5391
TotalEnvSteps                        987600
-----------------------------------  ---------------
2022-08-17 18:00:20 | [trpo_pendulum] epoch #823 | Saving snapshot...
2022-08-17 18:00:20 | [trpo_pendulum] epoch #823 | Saved
2022-08-17 18:00:20 | [trpo_pendulum] epoch #823 | Time 340.19 s
2022-08-17 18:00:20 | [trpo_pendulum] epoch #823 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -441.374
Evaluation/AverageReturn              -1085.39
Evaluation/Iteration                    823
Evaluation/MaxReturn                   -968.84
Evaluation/MinReturn                  -1172.69
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     80.039
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41953
GaussianMLPPolicy/KL                      4.65139e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -420.952
GaussianMLPPolicy/LossBefore           -420.846
GaussianMLPPolicy/dLoss                   0.106049
GaussianMLPValueFunction/LossAfter    20739.6
GaussianMLPValueFunction/LossBefore   20761.2
GaussianMLPValueFunction/dLoss           21.6699
TotalEnvSteps                        988800
-----------------------------------  ----------------
2022-08-17 18:00:20 | [trpo_pendulum] epoch #824 | Saving snapshot...
2022-08-17 18:00:20 | [trpo_pendulum] epoch #824 | Saved
2022-08-17 18:00:20 | [trpo_pendulum] epoch #824 | Time 340.60 s
2022-08-17 18:00:20 | [trpo_pendulum] epoch #824 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -733.519
Evaluation/AverageReturn              -1674.34
Evaluation/Iteration                    824
Evaluation/MaxReturn                  -1645.3
Evaluation/MinReturn                  -1713.64
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     22.5975
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.41986
GaussianMLPPolicy/KL                      1.41606e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -623.188
GaussianMLPPolicy/LossBefore           -623.148
GaussianMLPPolicy/dLoss                   0.0397339
GaussianMLPValueFunction/LossAfter    47738.2
GaussianMLPValueFunction/LossBefore   47789.2
GaussianMLPValueFunction/dLoss           51.0117
TotalEnvSteps                        990000
-----------------------------------  ----------------
2022-08-17 18:00:21 | [trpo_pendulum] epoch #825 | Saving snapshot...
2022-08-17 18:00:21 | [trpo_pendulum] epoch #825 | Saved
2022-08-17 18:00:21 | [trpo_pendulum] epoch #825 | Time 341.00 s
2022-08-17 18:00:21 | [trpo_pendulum] epoch #825 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -556.278
Evaluation/AverageReturn              -1306.1
Evaluation/Iteration                    825
Evaluation/MaxReturn                  -1266.17
Evaluation/MinReturn                  -1375.36
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     39.5392
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42008
GaussianMLPPolicy/KL                      2.11277e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -499.778
GaussianMLPPolicy/LossBefore           -499.786
GaussianMLPPolicy/dLoss                  -0.00775146
GaussianMLPValueFunction/LossAfter    28873.1
GaussianMLPValueFunction/LossBefore   28904.7
GaussianMLPValueFunction/dLoss           31.6172
TotalEnvSteps                        991200
-----------------------------------  ----------------
2022-08-17 18:00:21 | [trpo_pendulum] epoch #826 | Saving snapshot...
2022-08-17 18:00:21 | [trpo_pendulum] epoch #826 | Saved
2022-08-17 18:00:21 | [trpo_pendulum] epoch #826 | Time 341.42 s
2022-08-17 18:00:21 | [trpo_pendulum] epoch #826 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -580.944
Evaluation/AverageReturn              -1356.75
Evaluation/Iteration                    826
Evaluation/MaxReturn                  -1214.49
Evaluation/MinReturn                  -1459.9
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     84.8865
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42052
GaussianMLPPolicy/KL                      2.52606e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -493.661
GaussianMLPPolicy/LossBefore           -493.629
GaussianMLPPolicy/dLoss                   0.0324097
GaussianMLPValueFunction/LossAfter    31319.9
GaussianMLPValueFunction/LossBefore   31354.2
GaussianMLPValueFunction/dLoss           34.3691
TotalEnvSteps                        992400
-----------------------------------  ----------------
2022-08-17 18:00:21 | [trpo_pendulum] epoch #827 | Saving snapshot...
2022-08-17 18:00:21 | [trpo_pendulum] epoch #827 | Saved
2022-08-17 18:00:21 | [trpo_pendulum] epoch #827 | Time 341.83 s
2022-08-17 18:00:21 | [trpo_pendulum] epoch #827 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -522.096
Evaluation/AverageReturn              -1224.07
Evaluation/Iteration                    827
Evaluation/MaxReturn                  -1053.95
Evaluation/MinReturn                  -1302.03
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     82.0367
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42083
GaussianMLPPolicy/KL                      1.08102e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -466.995
GaussianMLPPolicy/LossBefore           -466.957
GaussianMLPPolicy/dLoss                   0.0378723
GaussianMLPValueFunction/LossAfter    25314.2
GaussianMLPValueFunction/LossBefore   25341.9
GaussianMLPValueFunction/dLoss           27.748
TotalEnvSteps                        993600
-----------------------------------  ----------------
2022-08-17 18:00:22 | [trpo_pendulum] epoch #828 | Saving snapshot...
2022-08-17 18:00:22 | [trpo_pendulum] epoch #828 | Saved
2022-08-17 18:00:22 | [trpo_pendulum] epoch #828 | Time 342.23 s
2022-08-17 18:00:22 | [trpo_pendulum] epoch #828 | EpochTime 0.40 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -418.393
Evaluation/AverageReturn              -1037.05
Evaluation/Iteration                    828
Evaluation/MaxReturn                   -858.96
Evaluation/MinReturn                  -1160.75
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     92.9558
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42105
GaussianMLPPolicy/KL                      1.46283e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -405.39
GaussianMLPPolicy/LossBefore           -405.365
GaussianMLPPolicy/dLoss                   0.0259399
GaussianMLPValueFunction/LossAfter    19073.8
GaussianMLPValueFunction/LossBefore   19094.4
GaussianMLPValueFunction/dLoss           20.6074
TotalEnvSteps                        994800
-----------------------------------  ----------------
2022-08-17 18:00:22 | [trpo_pendulum] epoch #829 | Saving snapshot...
2022-08-17 18:00:22 | [trpo_pendulum] epoch #829 | Saved
2022-08-17 18:00:22 | [trpo_pendulum] epoch #829 | Time 342.64 s
2022-08-17 18:00:22 | [trpo_pendulum] epoch #829 | EpochTime 0.40 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn     -568.282
Evaluation/AverageReturn              -1335.99
Evaluation/Iteration                    829
Evaluation/MaxReturn                  -1244.22
Evaluation/MinReturn                  -1420.61
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     77.9721
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42133
GaussianMLPPolicy/KL                      3.846e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -500.951
GaussianMLPPolicy/LossBefore           -500.846
GaussianMLPPolicy/dLoss                   0.104492
GaussianMLPValueFunction/LossAfter    30418.4
GaussianMLPValueFunction/LossBefore   30450.6
GaussianMLPValueFunction/dLoss           32.2324
TotalEnvSteps                        996000
-----------------------------------  --------------
2022-08-17 18:00:23 | [trpo_pendulum] epoch #830 | Saving snapshot...
2022-08-17 18:00:23 | [trpo_pendulum] epoch #830 | Saved
2022-08-17 18:00:23 | [trpo_pendulum] epoch #830 | Time 343.05 s
2022-08-17 18:00:23 | [trpo_pendulum] epoch #830 | EpochTime 0.41 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -471.225
Evaluation/AverageReturn              -1171.66
Evaluation/Iteration                    830
Evaluation/MaxReturn                  -1068.23
Evaluation/MinReturn                  -1301.11
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     81.0581
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42166
GaussianMLPPolicy/KL                      3.28052e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -452.692
GaussianMLPPolicy/LossBefore           -452.444
GaussianMLPPolicy/dLoss                   0.248077
GaussianMLPValueFunction/LossAfter    24698.5
GaussianMLPValueFunction/LossBefore   24724.7
GaussianMLPValueFunction/dLoss           26.1934
TotalEnvSteps                        997200
-----------------------------------  ----------------
2022-08-17 18:00:23 | [trpo_pendulum] epoch #831 | Saving snapshot...
2022-08-17 18:00:23 | [trpo_pendulum] epoch #831 | Saved
2022-08-17 18:00:23 | [trpo_pendulum] epoch #831 | Time 343.45 s
2022-08-17 18:00:23 | [trpo_pendulum] epoch #831 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn     -452.482
Evaluation/AverageReturn              -1064.14
Evaluation/Iteration                    831
Evaluation/MaxReturn                   -766.855
Evaluation/MinReturn                  -1212.64
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                    144.031
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.4219
GaussianMLPPolicy/KL                      2.5252e-06
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -400.073
GaussianMLPPolicy/LossBefore           -400.094
GaussianMLPPolicy/dLoss                  -0.0211182
GaussianMLPValueFunction/LossAfter    19191.4
GaussianMLPValueFunction/LossBefore   19211.5
GaussianMLPValueFunction/dLoss           20.0273
TotalEnvSteps                        998400
-----------------------------------  ---------------
2022-08-17 18:00:23 | [trpo_pendulum] epoch #832 | Saving snapshot...
2022-08-17 18:00:23 | [trpo_pendulum] epoch #832 | Saved
2022-08-17 18:00:23 | [trpo_pendulum] epoch #832 | Time 343.84 s
2022-08-17 18:00:23 | [trpo_pendulum] epoch #832 | EpochTime 0.39 s
-----------------------------------  ----------------
Evaluation/AverageDiscountedReturn     -787.732
Evaluation/AverageReturn              -1790.64
Evaluation/Iteration                    832
Evaluation/MaxReturn                  -1742.64
Evaluation/MinReturn                  -1836.61
Evaluation/NumEpisodes                    6
Evaluation/StdReturn                     34.7727
Evaluation/TerminationRate                0
GaussianMLPPolicy/Entropy                 1.42192
GaussianMLPPolicy/KL                      1.96793e-05
GaussianMLPPolicy/KLBefore                0
GaussianMLPPolicy/LossAfter            -691.752
GaussianMLPPolicy/LossBefore           -691.567
GaussianMLPPolicy/dLoss                   0.184875
GaussianMLPValueFunction/LossAfter    54520.8
GaussianMLPValueFunction/LossBefore   54579.9
GaussianMLPValueFunction/dLoss           59.0625
TotalEnvSteps                        999600
-----------------------------------  ----------------
2022-08-17 18:00:24 | [trpo_pendulum] epoch #833 | Saving snapshot...
2022-08-17 18:00:24 | [trpo_pendulum] epoch #833 | Saved
2022-08-17 18:00:24 | [trpo_pendulum] epoch #833 | Time 344.25 s
2022-08-17 18:00:24 | [trpo_pendulum] epoch #833 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -587.629
Evaluation/AverageReturn             -1352.49
Evaluation/Iteration                   833
Evaluation/MaxReturn                 -1286.43
Evaluation/MinReturn                 -1434.23
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    53.4791
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42193
GaussianMLPPolicy/KL                     3.02232e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -507.007
GaussianMLPPolicy/LossBefore          -506.841
GaussianMLPPolicy/dLoss                  0.166138
GaussianMLPValueFunction/LossAfter   30359.2
GaussianMLPValueFunction/LossBefore  30393.1
GaussianMLPValueFunction/dLoss          33.8672
TotalEnvSteps                            1.0008e+06
-----------------------------------  ---------------
2022-08-17 18:00:24 | [trpo_pendulum] epoch #834 | Saving snapshot...
2022-08-17 18:00:24 | [trpo_pendulum] epoch #834 | Saved
2022-08-17 18:00:24 | [trpo_pendulum] epoch #834 | Time 344.65 s
2022-08-17 18:00:24 | [trpo_pendulum] epoch #834 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -520.36
Evaluation/AverageReturn             -1237.97
Evaluation/Iteration                   834
Evaluation/MaxReturn                 -1175.06
Evaluation/MinReturn                 -1310.1
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    52.8577
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42186
GaussianMLPPolicy/KL                     1.90735e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -478.083
GaussianMLPPolicy/LossBefore          -478.084
GaussianMLPPolicy/dLoss                 -0.00100708
GaussianMLPValueFunction/LossAfter   26050.4
GaussianMLPValueFunction/LossBefore  26079.4
GaussianMLPValueFunction/dLoss          28.9941
TotalEnvSteps                            1.002e+06
-----------------------------------  ---------------
2022-08-17 18:00:25 | [trpo_pendulum] epoch #835 | Saving snapshot...
2022-08-17 18:00:25 | [trpo_pendulum] epoch #835 | Saved
2022-08-17 18:00:25 | [trpo_pendulum] epoch #835 | Time 345.06 s
2022-08-17 18:00:25 | [trpo_pendulum] epoch #835 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -549.745
Evaluation/AverageReturn             -1282.91
Evaluation/Iteration                   835
Evaluation/MaxReturn                 -1185.7
Evaluation/MinReturn                 -1396.37
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    66.1849
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42187
GaussianMLPPolicy/KL                     7.94363e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -476.235
GaussianMLPPolicy/LossBefore          -476.179
GaussianMLPPolicy/dLoss                  0.0563049
GaussianMLPValueFunction/LossAfter   27570.6
GaussianMLPValueFunction/LossBefore  27601
GaussianMLPValueFunction/dLoss          30.3965
TotalEnvSteps                            1.0032e+06
-----------------------------------  ---------------
2022-08-17 18:00:25 | [trpo_pendulum] epoch #836 | Saving snapshot...
2022-08-17 18:00:25 | [trpo_pendulum] epoch #836 | Saved
2022-08-17 18:00:25 | [trpo_pendulum] epoch #836 | Time 345.46 s
2022-08-17 18:00:25 | [trpo_pendulum] epoch #836 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -688.361
Evaluation/AverageReturn             -1596.26
Evaluation/Iteration                   836
Evaluation/MaxReturn                 -1478.28
Evaluation/MinReturn                 -1740.56
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    85.0429
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42187
GaussianMLPPolicy/KL                     2.41454e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -609.002
GaussianMLPPolicy/LossBefore          -608.959
GaussianMLPPolicy/dLoss                  0.043335
GaussianMLPValueFunction/LossAfter   43513.6
GaussianMLPValueFunction/LossBefore  43562.7
GaussianMLPValueFunction/dLoss          49.0898
TotalEnvSteps                            1.0044e+06
-----------------------------------  ---------------
2022-08-17 18:00:25 | [trpo_pendulum] epoch #837 | Saving snapshot...
2022-08-17 18:00:26 | [trpo_pendulum] epoch #837 | Saved
2022-08-17 18:00:26 | [trpo_pendulum] epoch #837 | Time 345.86 s
2022-08-17 18:00:26 | [trpo_pendulum] epoch #837 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -717.06
Evaluation/AverageReturn             -1670.48
Evaluation/Iteration                   837
Evaluation/MaxReturn                 -1545.67
Evaluation/MinReturn                 -1774.98
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    80.5299
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42195
GaussianMLPPolicy/KL                     1.27191e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -633.562
GaussianMLPPolicy/LossBefore          -633.449
GaussianMLPPolicy/dLoss                  0.113159
GaussianMLPValueFunction/LossAfter   47977.7
GaussianMLPValueFunction/LossBefore  48034.5
GaussianMLPValueFunction/dLoss          56.8203
TotalEnvSteps                            1.0056e+06
-----------------------------------  ---------------
2022-08-17 18:00:26 | [trpo_pendulum] epoch #838 | Saving snapshot...
2022-08-17 18:00:26 | [trpo_pendulum] epoch #838 | Saved
2022-08-17 18:00:26 | [trpo_pendulum] epoch #838 | Time 346.27 s
2022-08-17 18:00:26 | [trpo_pendulum] epoch #838 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -413.645
Evaluation/AverageReturn             -1029.19
Evaluation/Iteration                   838
Evaluation/MaxReturn                  -925.206
Evaluation/MinReturn                 -1100.68
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    64.5536
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42205
GaussianMLPPolicy/KL                     3.10138e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -395.939
GaussianMLPPolicy/LossBefore          -395.916
GaussianMLPPolicy/dLoss                  0.0227356
GaussianMLPValueFunction/LossAfter   18263
GaussianMLPValueFunction/LossBefore  18284.9
GaussianMLPValueFunction/dLoss          21.8359
TotalEnvSteps                            1.0068e+06
-----------------------------------  ---------------
2022-08-17 18:00:26 | [trpo_pendulum] epoch #839 | Saving snapshot...
2022-08-17 18:00:26 | [trpo_pendulum] epoch #839 | Saved
2022-08-17 18:00:26 | [trpo_pendulum] epoch #839 | Time 346.79 s
2022-08-17 18:00:26 | [trpo_pendulum] epoch #839 | EpochTime 0.52 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -410.113
Evaluation/AverageReturn              -994.275
Evaluation/Iteration                   839
Evaluation/MaxReturn                  -895.914
Evaluation/MinReturn                 -1095.56
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    64.2957
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42212
GaussianMLPPolicy/KL                     7.3028e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -377.591
GaussianMLPPolicy/LossBefore          -377.599
GaussianMLPPolicy/dLoss                 -0.00891113
GaussianMLPValueFunction/LossAfter   16637.3
GaussianMLPValueFunction/LossBefore  16656.4
GaussianMLPValueFunction/dLoss          19.1289
TotalEnvSteps                            1.008e+06
-----------------------------------  --------------
2022-08-17 18:00:27 | [trpo_pendulum] epoch #840 | Saving snapshot...
2022-08-17 18:00:27 | [trpo_pendulum] epoch #840 | Saved
2022-08-17 18:00:27 | [trpo_pendulum] epoch #840 | Time 347.19 s
2022-08-17 18:00:27 | [trpo_pendulum] epoch #840 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -763.99
Evaluation/AverageReturn             -1735.82
Evaluation/Iteration                   840
Evaluation/MaxReturn                 -1634.75
Evaluation/MinReturn                 -1800.84
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    56.9943
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42211
GaussianMLPPolicy/KL                     1.40703e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -660.223
GaussianMLPPolicy/LossBefore          -660.11
GaussianMLPPolicy/dLoss                  0.113159
GaussianMLPValueFunction/LossAfter   50514.4
GaussianMLPValueFunction/LossBefore  50572.8
GaussianMLPValueFunction/dLoss          58.3789
TotalEnvSteps                            1.0092e+06
-----------------------------------  ---------------
2022-08-17 18:00:27 | [trpo_pendulum] epoch #841 | Saving snapshot...
2022-08-17 18:00:27 | [trpo_pendulum] epoch #841 | Saved
2022-08-17 18:00:27 | [trpo_pendulum] epoch #841 | Time 347.58 s
2022-08-17 18:00:27 | [trpo_pendulum] epoch #841 | EpochTime 0.39 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -765.24
Evaluation/AverageReturn             -1721.86
Evaluation/Iteration                   841
Evaluation/MaxReturn                 -1651.29
Evaluation/MinReturn                 -1816.65
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    64.5604
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42183
GaussianMLPPolicy/KL                     1.7617e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -663.986
GaussianMLPPolicy/LossBefore          -663.94
GaussianMLPPolicy/dLoss                  0.0461426
GaussianMLPValueFunction/LossAfter   49075.5
GaussianMLPValueFunction/LossBefore  49135.3
GaussianMLPValueFunction/dLoss          59.7773
TotalEnvSteps                            1.0104e+06
-----------------------------------  --------------
2022-08-17 18:00:28 | [trpo_pendulum] epoch #842 | Saving snapshot...
2022-08-17 18:00:28 | [trpo_pendulum] epoch #842 | Saved
2022-08-17 18:00:28 | [trpo_pendulum] epoch #842 | Time 347.98 s
2022-08-17 18:00:28 | [trpo_pendulum] epoch #842 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -449.003
Evaluation/AverageReturn             -1071.98
Evaluation/Iteration                   842
Evaluation/MaxReturn                  -968.945
Evaluation/MinReturn                 -1172.44
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    80.0607
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42167
GaussianMLPPolicy/KL                     1.11212e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -396.147
GaussianMLPPolicy/LossBefore          -396.165
GaussianMLPPolicy/dLoss                 -0.0178528
GaussianMLPValueFunction/LossAfter   19042.3
GaussianMLPValueFunction/LossBefore  19065.7
GaussianMLPValueFunction/dLoss          23.3477
TotalEnvSteps                            1.0116e+06
-----------------------------------  ---------------
2022-08-17 18:00:28 | [trpo_pendulum] epoch #843 | Saving snapshot...
2022-08-17 18:00:28 | [trpo_pendulum] epoch #843 | Saved
2022-08-17 18:00:28 | [trpo_pendulum] epoch #843 | Time 348.39 s
2022-08-17 18:00:28 | [trpo_pendulum] epoch #843 | EpochTime 0.41 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -447.657
Evaluation/AverageReturn             -1075.22
Evaluation/Iteration                   843
Evaluation/MaxReturn                  -884.869
Evaluation/MinReturn                 -1255.59
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   126.725
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42131
GaussianMLPPolicy/KL                     6.5684e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -424.427
GaussianMLPPolicy/LossBefore          -424.41
GaussianMLPPolicy/dLoss                  0.0166321
GaussianMLPValueFunction/LossAfter   19607.2
GaussianMLPValueFunction/LossBefore  19630.3
GaussianMLPValueFunction/dLoss          23.1172
TotalEnvSteps                            1.0128e+06
-----------------------------------  --------------
2022-08-17 18:00:28 | [trpo_pendulum] epoch #844 | Saving snapshot...
2022-08-17 18:00:28 | [trpo_pendulum] epoch #844 | Saved
2022-08-17 18:00:28 | [trpo_pendulum] epoch #844 | Time 348.79 s
2022-08-17 18:00:28 | [trpo_pendulum] epoch #844 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -682.576
Evaluation/AverageReturn             -1554.81
Evaluation/Iteration                   844
Evaluation/MaxReturn                 -1464.81
Evaluation/MinReturn                 -1661.59
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    67.4655
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42101
GaussianMLPPolicy/KL                     2.74353e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -579.163
GaussianMLPPolicy/LossBefore          -579.124
GaussianMLPPolicy/dLoss                  0.0386963
GaussianMLPValueFunction/LossAfter   39890.2
GaussianMLPValueFunction/LossBefore  39936.8
GaussianMLPValueFunction/dLoss          46.6133
TotalEnvSteps                            1.014e+06
-----------------------------------  ---------------
2022-08-17 18:00:29 | [trpo_pendulum] epoch #845 | Saving snapshot...
2022-08-17 18:00:29 | [trpo_pendulum] epoch #845 | Saved
2022-08-17 18:00:29 | [trpo_pendulum] epoch #845 | Time 349.20 s
2022-08-17 18:00:29 | [trpo_pendulum] epoch #845 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -423.493
Evaluation/AverageReturn             -1011.95
Evaluation/Iteration                   845
Evaluation/MaxReturn                  -884.217
Evaluation/MinReturn                 -1190.44
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   101.388
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42085
GaussianMLPPolicy/KL                     1.36831e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -370.657
GaussianMLPPolicy/LossBefore          -370.61
GaussianMLPPolicy/dLoss                  0.0474243
GaussianMLPValueFunction/LossAfter   16979.5
GaussianMLPValueFunction/LossBefore  16999.3
GaussianMLPValueFunction/dLoss          19.8789
TotalEnvSteps                            1.0152e+06
-----------------------------------  ---------------
2022-08-17 18:00:29 | [trpo_pendulum] epoch #846 | Saving snapshot...
2022-08-17 18:00:29 | [trpo_pendulum] epoch #846 | Saved
2022-08-17 18:00:29 | [trpo_pendulum] epoch #846 | Time 349.59 s
2022-08-17 18:00:29 | [trpo_pendulum] epoch #846 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -707.163
Evaluation/AverageReturn             -1597.2
Evaluation/Iteration                   846
Evaluation/MaxReturn                 -1491.24
Evaluation/MinReturn                 -1760.82
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    84.7388
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42066
GaussianMLPPolicy/KL                     3.73066e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -597.878
GaussianMLPPolicy/LossBefore          -597.708
GaussianMLPPolicy/dLoss                  0.169922
GaussianMLPValueFunction/LossAfter   41733.7
GaussianMLPValueFunction/LossBefore  41782
GaussianMLPValueFunction/dLoss          48.2422
TotalEnvSteps                            1.0164e+06
-----------------------------------  ---------------
2022-08-17 18:00:30 | [trpo_pendulum] epoch #847 | Saving snapshot...
2022-08-17 18:00:30 | [trpo_pendulum] epoch #847 | Saved
2022-08-17 18:00:30 | [trpo_pendulum] epoch #847 | Time 349.99 s
2022-08-17 18:00:30 | [trpo_pendulum] epoch #847 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -429.124
Evaluation/AverageReturn             -1048.16
Evaluation/Iteration                   847
Evaluation/MaxReturn                  -963.741
Evaluation/MinReturn                 -1157.41
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    66.7926
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42046
GaussianMLPPolicy/KL                     3.20212e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -401.997
GaussianMLPPolicy/LossBefore          -401.964
GaussianMLPPolicy/dLoss                  0.0331726
GaussianMLPValueFunction/LossAfter   18605.8
GaussianMLPValueFunction/LossBefore  18627.5
GaussianMLPValueFunction/dLoss          21.6172
TotalEnvSteps                            1.0176e+06
-----------------------------------  ---------------
2022-08-17 18:00:30 | [trpo_pendulum] epoch #848 | Saving snapshot...
2022-08-17 18:00:30 | [trpo_pendulum] epoch #848 | Saved
2022-08-17 18:00:30 | [trpo_pendulum] epoch #848 | Time 350.39 s
2022-08-17 18:00:30 | [trpo_pendulum] epoch #848 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -530.486
Evaluation/AverageReturn             -1244.4
Evaluation/Iteration                   848
Evaluation/MaxReturn                 -1154.47
Evaluation/MinReturn                 -1361.14
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    73.0481
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42032
GaussianMLPPolicy/KL                     8.34745e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -465.053
GaussianMLPPolicy/LossBefore          -464.981
GaussianMLPPolicy/dLoss                  0.0714722
GaussianMLPValueFunction/LossAfter   25650.4
GaussianMLPValueFunction/LossBefore  25679.3
GaussianMLPValueFunction/dLoss          28.8359
TotalEnvSteps                            1.0188e+06
-----------------------------------  ---------------
2022-08-17 18:00:30 | [trpo_pendulum] epoch #849 | Saving snapshot...
2022-08-17 18:00:30 | [trpo_pendulum] epoch #849 | Saved
2022-08-17 18:00:30 | [trpo_pendulum] epoch #849 | Time 350.79 s
2022-08-17 18:00:30 | [trpo_pendulum] epoch #849 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -363.756
Evaluation/AverageReturn              -931.389
Evaluation/Iteration                   849
Evaluation/MaxReturn                  -863.248
Evaluation/MinReturn                 -1062.79
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    69.1725
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42013
GaussianMLPPolicy/KL                     2.85675e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -367.859
GaussianMLPPolicy/LossBefore          -367.861
GaussianMLPPolicy/dLoss                 -0.00195312
GaussianMLPValueFunction/LossAfter   15307.7
GaussianMLPValueFunction/LossBefore  15324.7
GaussianMLPValueFunction/dLoss          16.9951
TotalEnvSteps                            1.02e+06
-----------------------------------  ---------------
2022-08-17 18:00:31 | [trpo_pendulum] epoch #850 | Saving snapshot...
2022-08-17 18:00:31 | [trpo_pendulum] epoch #850 | Saved
2022-08-17 18:00:31 | [trpo_pendulum] epoch #850 | Time 351.19 s
2022-08-17 18:00:31 | [trpo_pendulum] epoch #850 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -453.69
Evaluation/AverageReturn             -1104.99
Evaluation/Iteration                   850
Evaluation/MaxReturn                  -854.626
Evaluation/MinReturn                 -1298.77
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   137.298
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42008
GaussianMLPPolicy/KL                     3.54372e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -413.887
GaussianMLPPolicy/LossBefore          -413.696
GaussianMLPPolicy/dLoss                  0.190765
GaussianMLPValueFunction/LossAfter   20890.5
GaussianMLPValueFunction/LossBefore  20912.6
GaussianMLPValueFunction/dLoss          22.166
TotalEnvSteps                            1.0212e+06
-----------------------------------  ---------------
2022-08-17 18:00:31 | [trpo_pendulum] epoch #851 | Saving snapshot...
2022-08-17 18:00:31 | [trpo_pendulum] epoch #851 | Saved
2022-08-17 18:00:31 | [trpo_pendulum] epoch #851 | Time 351.59 s
2022-08-17 18:00:31 | [trpo_pendulum] epoch #851 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -519.738
Evaluation/AverageReturn             -1223.35
Evaluation/Iteration                   851
Evaluation/MaxReturn                 -1091.07
Evaluation/MinReturn                 -1339.52
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    86.5385
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42004
GaussianMLPPolicy/KL                     5.67239e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -459.695
GaussianMLPPolicy/LossBefore          -459.577
GaussianMLPPolicy/dLoss                  0.118286
GaussianMLPValueFunction/LossAfter   24925.8
GaussianMLPValueFunction/LossBefore  24951.8
GaussianMLPValueFunction/dLoss          25.9453
TotalEnvSteps                            1.0224e+06
-----------------------------------  ---------------
2022-08-17 18:00:32 | [trpo_pendulum] epoch #852 | Saving snapshot...
2022-08-17 18:00:32 | [trpo_pendulum] epoch #852 | Saved
2022-08-17 18:00:32 | [trpo_pendulum] epoch #852 | Time 351.99 s
2022-08-17 18:00:32 | [trpo_pendulum] epoch #852 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -692.731
Evaluation/AverageReturn             -1575.85
Evaluation/Iteration                   852
Evaluation/MaxReturn                 -1341.55
Evaluation/MinReturn                 -1724.11
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   119.263
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42014
GaussianMLPPolicy/KL                     1.16275e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -577.81
GaussianMLPPolicy/LossBefore          -577.859
GaussianMLPPolicy/dLoss                 -0.0495605
GaussianMLPValueFunction/LossAfter   40889.4
GaussianMLPValueFunction/LossBefore  40932.8
GaussianMLPValueFunction/dLoss          43.4648
TotalEnvSteps                            1.0236e+06
-----------------------------------  ---------------
2022-08-17 18:00:32 | [trpo_pendulum] epoch #853 | Saving snapshot...
2022-08-17 18:00:32 | [trpo_pendulum] epoch #853 | Saved
2022-08-17 18:00:32 | [trpo_pendulum] epoch #853 | Time 352.40 s
2022-08-17 18:00:32 | [trpo_pendulum] epoch #853 | EpochTime 0.41 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -424.213
Evaluation/AverageReturn             -1037.49
Evaluation/Iteration                   853
Evaluation/MaxReturn                  -887.157
Evaluation/MinReturn                 -1077.54
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    67.4253
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42014
GaussianMLPPolicy/KL                     4.4706e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -403.281
GaussianMLPPolicy/LossBefore          -403.211
GaussianMLPPolicy/dLoss                  0.0699158
GaussianMLPValueFunction/LossAfter   18127.6
GaussianMLPValueFunction/LossBefore  18147.1
GaussianMLPValueFunction/dLoss          19.5
TotalEnvSteps                            1.0248e+06
-----------------------------------  --------------
2022-08-17 18:00:32 | [trpo_pendulum] epoch #854 | Saving snapshot...
2022-08-17 18:00:32 | [trpo_pendulum] epoch #854 | Saved
2022-08-17 18:00:32 | [trpo_pendulum] epoch #854 | Time 352.81 s
2022-08-17 18:00:32 | [trpo_pendulum] epoch #854 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -460.643
Evaluation/AverageReturn             -1082.21
Evaluation/Iteration                   854
Evaluation/MaxReturn                  -916.83
Evaluation/MinReturn                 -1169.57
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    82.2969
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42009
GaussianMLPPolicy/KL                     7.79841e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -405.19
GaussianMLPPolicy/LossBefore          -405.214
GaussianMLPPolicy/dLoss                 -0.0235291
GaussianMLPValueFunction/LossAfter   18863.5
GaussianMLPValueFunction/LossBefore  18883.2
GaussianMLPValueFunction/dLoss          19.6387
TotalEnvSteps                            1.026e+06
-----------------------------------  ---------------
2022-08-17 18:00:33 | [trpo_pendulum] epoch #855 | Saving snapshot...
2022-08-17 18:00:33 | [trpo_pendulum] epoch #855 | Saved
2022-08-17 18:00:33 | [trpo_pendulum] epoch #855 | Time 353.21 s
2022-08-17 18:00:33 | [trpo_pendulum] epoch #855 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -762.908
Evaluation/AverageReturn             -1715.86
Evaluation/Iteration                   855
Evaluation/MaxReturn                 -1667.11
Evaluation/MinReturn                 -1778.57
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    46.0278
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42006
GaussianMLPPolicy/KL                     1.78794e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -637.65
GaussianMLPPolicy/LossBefore          -637.569
GaussianMLPPolicy/dLoss                  0.081604
GaussianMLPValueFunction/LossAfter   47756.4
GaussianMLPValueFunction/LossBefore  47807.3
GaussianMLPValueFunction/dLoss          50.8281
TotalEnvSteps                            1.0272e+06
-----------------------------------  ---------------
2022-08-17 18:00:33 | [trpo_pendulum] epoch #856 | Saving snapshot...
2022-08-17 18:00:33 | [trpo_pendulum] epoch #856 | Saved
2022-08-17 18:00:33 | [trpo_pendulum] epoch #856 | Time 353.60 s
2022-08-17 18:00:33 | [trpo_pendulum] epoch #856 | EpochTime 0.39 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -581.846
Evaluation/AverageReturn             -1328.67
Evaluation/Iteration                   856
Evaluation/MaxReturn                 -1245.99
Evaluation/MinReturn                 -1413.62
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    53.0883
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42008
GaussianMLPPolicy/KL                     3.9734e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -487.64
GaussianMLPPolicy/LossBefore          -487.451
GaussianMLPPolicy/dLoss                  0.18924
GaussianMLPValueFunction/LossAfter   28286.7
GaussianMLPValueFunction/LossBefore  28317.5
GaussianMLPValueFunction/dLoss          30.8359
TotalEnvSteps                            1.0284e+06
-----------------------------------  --------------
2022-08-17 18:00:34 | [trpo_pendulum] epoch #857 | Saving snapshot...
2022-08-17 18:00:34 | [trpo_pendulum] epoch #857 | Saved
2022-08-17 18:00:34 | [trpo_pendulum] epoch #857 | Time 354.00 s
2022-08-17 18:00:34 | [trpo_pendulum] epoch #857 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -600.783
Evaluation/AverageReturn             -1393.75
Evaluation/Iteration                   857
Evaluation/MaxReturn                 -1309.59
Evaluation/MinReturn                 -1495.77
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    70.9528
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41998
GaussianMLPPolicy/KL                     3.82417e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -533.679
GaussianMLPPolicy/LossBefore          -533.59
GaussianMLPPolicy/dLoss                  0.0882568
GaussianMLPValueFunction/LossAfter   31805.5
GaussianMLPValueFunction/LossBefore  31840.4
GaussianMLPValueFunction/dLoss          34.8574
TotalEnvSteps                            1.0296e+06
-----------------------------------  ---------------
2022-08-17 18:00:34 | [trpo_pendulum] epoch #858 | Saving snapshot...
2022-08-17 18:00:34 | [trpo_pendulum] epoch #858 | Saved
2022-08-17 18:00:34 | [trpo_pendulum] epoch #858 | Time 354.40 s
2022-08-17 18:00:34 | [trpo_pendulum] epoch #858 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -585.678
Evaluation/AverageReturn             -1378.02
Evaluation/Iteration                   858
Evaluation/MaxReturn                 -1289.98
Evaluation/MinReturn                 -1475.14
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    68.1981
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42004
GaussianMLPPolicy/KL                     5.27902e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -512.03
GaussianMLPPolicy/LossBefore          -512.017
GaussianMLPPolicy/dLoss                  0.0135498
GaussianMLPValueFunction/LossAfter   31711.6
GaussianMLPValueFunction/LossBefore  31746.7
GaussianMLPValueFunction/dLoss          35.0879
TotalEnvSteps                            1.0308e+06
-----------------------------------  ---------------
2022-08-17 18:00:34 | [trpo_pendulum] epoch #859 | Saving snapshot...
2022-08-17 18:00:34 | [trpo_pendulum] epoch #859 | Saved
2022-08-17 18:00:34 | [trpo_pendulum] epoch #859 | Time 354.80 s
2022-08-17 18:00:34 | [trpo_pendulum] epoch #859 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -771.089
Evaluation/AverageReturn             -1736.62
Evaluation/Iteration                   859
Evaluation/MaxReturn                 -1609.75
Evaluation/MinReturn                 -1824.87
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    70.0537
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42015
GaussianMLPPolicy/KL                     5.28416e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -642.567
GaussianMLPPolicy/LossBefore          -642.51
GaussianMLPPolicy/dLoss                  0.0562744
GaussianMLPValueFunction/LossAfter   48902.6
GaussianMLPValueFunction/LossBefore  48959.1
GaussianMLPValueFunction/dLoss          56.418
TotalEnvSteps                            1.032e+06
-----------------------------------  ---------------
2022-08-17 18:00:35 | [trpo_pendulum] epoch #860 | Saving snapshot...
2022-08-17 18:00:35 | [trpo_pendulum] epoch #860 | Saved
2022-08-17 18:00:35 | [trpo_pendulum] epoch #860 | Time 355.21 s
2022-08-17 18:00:35 | [trpo_pendulum] epoch #860 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -487.203
Evaluation/AverageReturn             -1120.81
Evaluation/Iteration                   860
Evaluation/MaxReturn                 -1027.89
Evaluation/MinReturn                 -1187.69
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    62.0104
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42014
GaussianMLPPolicy/KL                     2.64005e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -419.581
GaussianMLPPolicy/LossBefore          -419.487
GaussianMLPPolicy/dLoss                  0.0941162
GaussianMLPValueFunction/LossAfter   19899.3
GaussianMLPValueFunction/LossBefore  19922.5
GaussianMLPValueFunction/dLoss          23.168
TotalEnvSteps                            1.0332e+06
-----------------------------------  ---------------
2022-08-17 18:00:35 | [trpo_pendulum] epoch #861 | Saving snapshot...
2022-08-17 18:00:35 | [trpo_pendulum] epoch #861 | Saved
2022-08-17 18:00:35 | [trpo_pendulum] epoch #861 | Time 355.62 s
2022-08-17 18:00:35 | [trpo_pendulum] epoch #861 | EpochTime 0.40 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -621.617
Evaluation/AverageReturn             -1432.83
Evaluation/Iteration                   861
Evaluation/MaxReturn                 -1377.45
Evaluation/MinReturn                 -1587.77
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    70.3631
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42002
GaussianMLPPolicy/KL                     5.3366e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -545.747
GaussianMLPPolicy/LossBefore          -545.639
GaussianMLPPolicy/dLoss                  0.108337
GaussianMLPValueFunction/LossAfter   33380.2
GaussianMLPValueFunction/LossBefore  33418.4
GaussianMLPValueFunction/dLoss          38.2461
TotalEnvSteps                            1.0344e+06
-----------------------------------  --------------
2022-08-17 18:00:36 | [trpo_pendulum] epoch #862 | Saving snapshot...
2022-08-17 18:00:36 | [trpo_pendulum] epoch #862 | Saved
2022-08-17 18:00:36 | [trpo_pendulum] epoch #862 | Time 356.02 s
2022-08-17 18:00:36 | [trpo_pendulum] epoch #862 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -331.978
Evaluation/AverageReturn              -913.608
Evaluation/Iteration                   862
Evaluation/MaxReturn                  -747.969
Evaluation/MinReturn                 -1042.18
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   103.643
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41995
GaussianMLPPolicy/KL                     5.8591e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -369.139
GaussianMLPPolicy/LossBefore          -369.138
GaussianMLPPolicy/dLoss                  0.000793457
GaussianMLPValueFunction/LossAfter   15842.3
GaussianMLPValueFunction/LossBefore  15860.4
GaussianMLPValueFunction/dLoss          18.1162
TotalEnvSteps                            1.0356e+06
-----------------------------------  ---------------
2022-08-17 18:00:36 | [trpo_pendulum] epoch #863 | Saving snapshot...
2022-08-17 18:00:36 | [trpo_pendulum] epoch #863 | Saved
2022-08-17 18:00:36 | [trpo_pendulum] epoch #863 | Time 356.45 s
2022-08-17 18:00:36 | [trpo_pendulum] epoch #863 | EpochTime 0.42 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -726.222
Evaluation/AverageReturn             -1680.56
Evaluation/Iteration                   863
Evaluation/MaxReturn                 -1579.3
Evaluation/MinReturn                 -1843.32
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    87.3263
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41984
GaussianMLPPolicy/KL                     1.14134e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -642.965
GaussianMLPPolicy/LossBefore          -642.869
GaussianMLPPolicy/dLoss                  0.0957642
GaussianMLPValueFunction/LossAfter   46882.4
GaussianMLPValueFunction/LossBefore  46935.9
GaussianMLPValueFunction/dLoss          53.5078
TotalEnvSteps                            1.0368e+06
-----------------------------------  ---------------
2022-08-17 18:00:36 | [trpo_pendulum] epoch #864 | Saving snapshot...
2022-08-17 18:00:37 | [trpo_pendulum] epoch #864 | Saved
2022-08-17 18:00:37 | [trpo_pendulum] epoch #864 | Time 356.87 s
2022-08-17 18:00:37 | [trpo_pendulum] epoch #864 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -638.67
Evaluation/AverageReturn             -1494.36
Evaluation/Iteration                   864
Evaluation/MaxReturn                 -1420.38
Evaluation/MinReturn                 -1576.38
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    53.352
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41988
GaussianMLPPolicy/KL                     7.08783e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -557.913
GaussianMLPPolicy/LossBefore          -557.696
GaussianMLPPolicy/dLoss                  0.217834
GaussianMLPValueFunction/LossAfter   36941.6
GaussianMLPValueFunction/LossBefore  36985
GaussianMLPValueFunction/dLoss          43.4453
TotalEnvSteps                            1.038e+06
-----------------------------------  ---------------
2022-08-17 18:00:37 | [trpo_pendulum] epoch #865 | Saving snapshot...
2022-08-17 18:00:37 | [trpo_pendulum] epoch #865 | Saved
2022-08-17 18:00:37 | [trpo_pendulum] epoch #865 | Time 357.30 s
2022-08-17 18:00:37 | [trpo_pendulum] epoch #865 | EpochTime 0.42 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -660.617
Evaluation/AverageReturn             -1529.85
Evaluation/Iteration                   865
Evaluation/MaxReturn                 -1460.16
Evaluation/MinReturn                 -1583.93
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    53.9195
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41997
GaussianMLPPolicy/KL                     0.000214018
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -574.379
GaussianMLPPolicy/LossBefore          -573.733
GaussianMLPPolicy/dLoss                  0.645813
GaussianMLPValueFunction/LossAfter   38420.6
GaussianMLPValueFunction/LossBefore  38466.7
GaussianMLPValueFunction/dLoss          46.0781
TotalEnvSteps                            1.0392e+06
-----------------------------------  ---------------
2022-08-17 18:00:37 | [trpo_pendulum] epoch #866 | Saving snapshot...
2022-08-17 18:00:37 | [trpo_pendulum] epoch #866 | Saved
2022-08-17 18:00:37 | [trpo_pendulum] epoch #866 | Time 357.69 s
2022-08-17 18:00:37 | [trpo_pendulum] epoch #866 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -638.403
Evaluation/AverageReturn             -1463.14
Evaluation/Iteration                   866
Evaluation/MaxReturn                 -1414.94
Evaluation/MinReturn                 -1500.15
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    25.4793
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42015
GaussianMLPPolicy/KL                     0.000163447
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -538.735
GaussianMLPPolicy/LossBefore          -538.691
GaussianMLPPolicy/dLoss                  0.0444336
GaussianMLPValueFunction/LossAfter   34417.9
GaussianMLPValueFunction/LossBefore  34459.7
GaussianMLPValueFunction/dLoss          41.793
TotalEnvSteps                            1.0404e+06
-----------------------------------  ---------------
2022-08-17 18:00:38 | [trpo_pendulum] epoch #867 | Saving snapshot...
2022-08-17 18:00:38 | [trpo_pendulum] epoch #867 | Saved
2022-08-17 18:00:38 | [trpo_pendulum] epoch #867 | Time 358.10 s
2022-08-17 18:00:38 | [trpo_pendulum] epoch #867 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -385.65
Evaluation/AverageReturn              -870.915
Evaluation/Iteration                   867
Evaluation/MaxReturn                  -661.04
Evaluation/MinReturn                 -1018.43
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   127.247
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42035
GaussianMLPPolicy/KL                     8.27859e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -301.052
GaussianMLPPolicy/LossBefore          -301.151
GaussianMLPPolicy/dLoss                 -0.0984497
GaussianMLPValueFunction/LossAfter   11547.2
GaussianMLPValueFunction/LossBefore  11561.1
GaussianMLPValueFunction/dLoss          13.9717
TotalEnvSteps                            1.0416e+06
-----------------------------------  ---------------
2022-08-17 18:00:38 | [trpo_pendulum] epoch #868 | Saving snapshot...
2022-08-17 18:00:38 | [trpo_pendulum] epoch #868 | Saved
2022-08-17 18:00:38 | [trpo_pendulum] epoch #868 | Time 358.51 s
2022-08-17 18:00:38 | [trpo_pendulum] epoch #868 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -632.107
Evaluation/AverageReturn             -1449.46
Evaluation/Iteration                   868
Evaluation/MaxReturn                 -1385.65
Evaluation/MinReturn                 -1505.05
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    34.6285
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42061
GaussianMLPPolicy/KL                     0.000103158
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -534.733
GaussianMLPPolicy/LossBefore          -534.578
GaussianMLPPolicy/dLoss                  0.154907
GaussianMLPValueFunction/LossAfter   33647.8
GaussianMLPValueFunction/LossBefore  33686.6
GaussianMLPValueFunction/dLoss          38.8281
TotalEnvSteps                            1.0428e+06
-----------------------------------  ---------------
2022-08-17 18:00:39 | [trpo_pendulum] epoch #869 | Saving snapshot...
2022-08-17 18:00:39 | [trpo_pendulum] epoch #869 | Saved
2022-08-17 18:00:39 | [trpo_pendulum] epoch #869 | Time 358.92 s
2022-08-17 18:00:39 | [trpo_pendulum] epoch #869 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -556.418
Evaluation/AverageReturn             -1275.75
Evaluation/Iteration                   869
Evaluation/MaxReturn                 -1182.28
Evaluation/MinReturn                 -1420.78
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    75.234
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42083
GaussianMLPPolicy/KL                     4.96519e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -472.438
GaussianMLPPolicy/LossBefore          -472.454
GaussianMLPPolicy/dLoss                 -0.0159302
GaussianMLPValueFunction/LossAfter   25533.4
GaussianMLPValueFunction/LossBefore  25562.8
GaussianMLPValueFunction/dLoss          29.418
TotalEnvSteps                            1.044e+06
-----------------------------------  ---------------
2022-08-17 18:00:39 | [trpo_pendulum] epoch #870 | Saving snapshot...
2022-08-17 18:00:39 | [trpo_pendulum] epoch #870 | Saved
2022-08-17 18:00:39 | [trpo_pendulum] epoch #870 | Time 359.32 s
2022-08-17 18:00:39 | [trpo_pendulum] epoch #870 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -448.138
Evaluation/AverageReturn             -1045.3
Evaluation/Iteration                   870
Evaluation/MaxReturn                  -876.15
Evaluation/MinReturn                 -1206.36
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   140.767
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42105
GaussianMLPPolicy/KL                     0.000276614
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -382.428
GaussianMLPPolicy/LossBefore          -381.82
GaussianMLPPolicy/dLoss                  0.607208
GaussianMLPValueFunction/LossAfter   17540
GaussianMLPValueFunction/LossBefore  17559.8
GaussianMLPValueFunction/dLoss          19.8145
TotalEnvSteps                            1.0452e+06
-----------------------------------  ---------------
2022-08-17 18:00:39 | [trpo_pendulum] epoch #871 | Saving snapshot...
2022-08-17 18:00:39 | [trpo_pendulum] epoch #871 | Saved
2022-08-17 18:00:39 | [trpo_pendulum] epoch #871 | Time 359.72 s
2022-08-17 18:00:39 | [trpo_pendulum] epoch #871 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -458.13
Evaluation/AverageReturn             -1035.4
Evaluation/Iteration                   871
Evaluation/MaxReturn                  -887.034
Evaluation/MinReturn                 -1200.59
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   118.305
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42124
GaussianMLPPolicy/KL                     0.000308878
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -370.961
GaussianMLPPolicy/LossBefore          -370.719
GaussianMLPPolicy/dLoss                  0.241577
GaussianMLPValueFunction/LossAfter   16381.4
GaussianMLPValueFunction/LossBefore  16399.2
GaussianMLPValueFunction/dLoss          17.832
TotalEnvSteps                            1.0464e+06
-----------------------------------  ---------------
2022-08-17 18:00:40 | [trpo_pendulum] epoch #872 | Saving snapshot...
2022-08-17 18:00:40 | [trpo_pendulum] epoch #872 | Saved
2022-08-17 18:00:40 | [trpo_pendulum] epoch #872 | Time 360.14 s
2022-08-17 18:00:40 | [trpo_pendulum] epoch #872 | EpochTime 0.42 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -724.919
Evaluation/AverageReturn             -1633.19
Evaluation/Iteration                   872
Evaluation/MaxReturn                 -1451.35
Evaluation/MinReturn                 -1828.54
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   110.938
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42146
GaussianMLPPolicy/KL                     0.00018724
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -603.829
GaussianMLPPolicy/LossBefore          -603.461
GaussianMLPPolicy/dLoss                  0.368652
GaussianMLPValueFunction/LossAfter   42614.3
GaussianMLPValueFunction/LossBefore  42660.7
GaussianMLPValueFunction/dLoss          46.418
TotalEnvSteps                            1.0476e+06
-----------------------------------  --------------
2022-08-17 18:00:40 | [trpo_pendulum] epoch #873 | Saving snapshot...
2022-08-17 18:00:40 | [trpo_pendulum] epoch #873 | Saved
2022-08-17 18:00:40 | [trpo_pendulum] epoch #873 | Time 360.54 s
2022-08-17 18:00:40 | [trpo_pendulum] epoch #873 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -583.041
Evaluation/AverageReturn             -1322.99
Evaluation/Iteration                   873
Evaluation/MaxReturn                 -1239.2
Evaluation/MinReturn                 -1449.32
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    66.118
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42155
GaussianMLPPolicy/KL                     0.000544125
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -494.736
GaussianMLPPolicy/LossBefore          -494.023
GaussianMLPPolicy/dLoss                  0.712128
GaussianMLPValueFunction/LossAfter   27363.5
GaussianMLPValueFunction/LossBefore  27393.8
GaussianMLPValueFunction/dLoss          30.2832
TotalEnvSteps                            1.0488e+06
-----------------------------------  ---------------
2022-08-17 18:00:41 | [trpo_pendulum] epoch #874 | Saving snapshot...
2022-08-17 18:00:41 | [trpo_pendulum] epoch #874 | Saved
2022-08-17 18:00:41 | [trpo_pendulum] epoch #874 | Time 360.93 s
2022-08-17 18:00:41 | [trpo_pendulum] epoch #874 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -577.318
Evaluation/AverageReturn             -1257.31
Evaluation/Iteration                   874
Evaluation/MaxReturn                 -1070.61
Evaluation/MinReturn                 -1440.94
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   130.094
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42135
GaussianMLPPolicy/KL                     0.000402119
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -466.537
GaussianMLPPolicy/LossBefore          -466.465
GaussianMLPPolicy/dLoss                  0.0712891
GaussianMLPValueFunction/LossAfter   24075.1
GaussianMLPValueFunction/LossBefore  24101.4
GaussianMLPValueFunction/dLoss          26.332
TotalEnvSteps                            1.05e+06
-----------------------------------  ---------------
2022-08-17 18:00:41 | [trpo_pendulum] epoch #875 | Saving snapshot...
2022-08-17 18:00:41 | [trpo_pendulum] epoch #875 | Saved
2022-08-17 18:00:41 | [trpo_pendulum] epoch #875 | Time 361.35 s
2022-08-17 18:00:41 | [trpo_pendulum] epoch #875 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -524.366
Evaluation/AverageReturn             -1136.72
Evaluation/Iteration                   875
Evaluation/MaxReturn                 -1036.52
Evaluation/MinReturn                 -1261.94
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    81.6482
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42126
GaussianMLPPolicy/KL                     0.000363317
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -387.989
GaussianMLPPolicy/LossBefore          -387.806
GaussianMLPPolicy/dLoss                  0.182983
GaussianMLPValueFunction/LossAfter   19020.6
GaussianMLPValueFunction/LossBefore  19041
GaussianMLPValueFunction/dLoss          20.4473
TotalEnvSteps                            1.0512e+06
-----------------------------------  ---------------
2022-08-17 18:00:41 | [trpo_pendulum] epoch #876 | Saving snapshot...
2022-08-17 18:00:41 | [trpo_pendulum] epoch #876 | Saved
2022-08-17 18:00:41 | [trpo_pendulum] epoch #876 | Time 361.75 s
2022-08-17 18:00:41 | [trpo_pendulum] epoch #876 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -424.99
Evaluation/AverageReturn              -980.565
Evaluation/Iteration                   876
Evaluation/MaxReturn                  -868.585
Evaluation/MinReturn                 -1124.1
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    87.8856
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42113
GaussianMLPPolicy/KL                     0.000253789
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -358.249
GaussianMLPPolicy/LossBefore          -358.25
GaussianMLPPolicy/dLoss                 -0.00161743
GaussianMLPValueFunction/LossAfter   14487.1
GaussianMLPValueFunction/LossBefore  14502.3
GaussianMLPValueFunction/dLoss          15.2197
TotalEnvSteps                            1.0524e+06
-----------------------------------  ---------------
2022-08-17 18:00:42 | [trpo_pendulum] epoch #877 | Saving snapshot...
2022-08-17 18:00:42 | [trpo_pendulum] epoch #877 | Saved
2022-08-17 18:00:42 | [trpo_pendulum] epoch #877 | Time 362.14 s
2022-08-17 18:00:42 | [trpo_pendulum] epoch #877 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -436.184
Evaluation/AverageReturn             -1008.97
Evaluation/Iteration                   877
Evaluation/MaxReturn                  -919.402
Evaluation/MinReturn                 -1078.74
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    50.152
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42101
GaussianMLPPolicy/KL                     9.50148e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -366.506
GaussianMLPPolicy/LossBefore          -366.583
GaussianMLPPolicy/dLoss                 -0.0769348
GaussianMLPValueFunction/LossAfter   15701.6
GaussianMLPValueFunction/LossBefore  15717.4
GaussianMLPValueFunction/dLoss          15.79
TotalEnvSteps                            1.0536e+06
-----------------------------------  ---------------
2022-08-17 18:00:42 | [trpo_pendulum] epoch #878 | Saving snapshot...
2022-08-17 18:00:42 | [trpo_pendulum] epoch #878 | Saved
2022-08-17 18:00:42 | [trpo_pendulum] epoch #878 | Time 362.54 s
2022-08-17 18:00:42 | [trpo_pendulum] epoch #878 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -480.236
Evaluation/AverageReturn             -1023.25
Evaluation/Iteration                   878
Evaluation/MaxReturn                  -844.512
Evaluation/MinReturn                 -1121.83
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    92.4348
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42082
GaussianMLPPolicy/KL                     4.60751e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -351.966
GaussianMLPPolicy/LossBefore          -351.981
GaussianMLPPolicy/dLoss                 -0.0149841
GaussianMLPValueFunction/LossAfter   14675
GaussianMLPValueFunction/LossBefore  14689.2
GaussianMLPValueFunction/dLoss          14.1963
TotalEnvSteps                            1.0548e+06
-----------------------------------  ---------------
2022-08-17 18:00:43 | [trpo_pendulum] epoch #879 | Saving snapshot...
2022-08-17 18:00:43 | [trpo_pendulum] epoch #879 | Saved
2022-08-17 18:00:43 | [trpo_pendulum] epoch #879 | Time 362.94 s
2022-08-17 18:00:43 | [trpo_pendulum] epoch #879 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -501.106
Evaluation/AverageReturn             -1116.69
Evaluation/Iteration                   879
Evaluation/MaxReturn                 -1064.67
Evaluation/MinReturn                 -1220.86
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    52.8413
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42064
GaussianMLPPolicy/KL                     1.62362e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -397.057
GaussianMLPPolicy/LossBefore          -397.018
GaussianMLPPolicy/dLoss                  0.0394897
GaussianMLPValueFunction/LossAfter   18332.8
GaussianMLPValueFunction/LossBefore  18349.9
GaussianMLPValueFunction/dLoss          17.1562
TotalEnvSteps                            1.056e+06
-----------------------------------  ---------------
2022-08-17 18:00:43 | [trpo_pendulum] epoch #880 | Saving snapshot...
2022-08-17 18:00:43 | [trpo_pendulum] epoch #880 | Saved
2022-08-17 18:00:43 | [trpo_pendulum] epoch #880 | Time 363.35 s
2022-08-17 18:00:43 | [trpo_pendulum] epoch #880 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -635.653
Evaluation/AverageReturn             -1360.69
Evaluation/Iteration                   880
Evaluation/MaxReturn                 -1202.79
Evaluation/MinReturn                 -1639.91
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   137.514
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42044
GaussianMLPPolicy/KL                     4.18173e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -479.323
GaussianMLPPolicy/LossBefore          -479.215
GaussianMLPPolicy/dLoss                  0.108063
GaussianMLPValueFunction/LossAfter   27592.1
GaussianMLPValueFunction/LossBefore  27617.6
GaussianMLPValueFunction/dLoss          25.5195
TotalEnvSteps                            1.0572e+06
-----------------------------------  ---------------
2022-08-17 18:00:43 | [trpo_pendulum] epoch #881 | Saving snapshot...
2022-08-17 18:00:43 | [trpo_pendulum] epoch #881 | Saved
2022-08-17 18:00:43 | [trpo_pendulum] epoch #881 | Time 363.77 s
2022-08-17 18:00:43 | [trpo_pendulum] epoch #881 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -517.043
Evaluation/AverageReturn             -1114.72
Evaluation/Iteration                   881
Evaluation/MaxReturn                 -1070.7
Evaluation/MinReturn                 -1191.27
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    41.6212
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42029
GaussianMLPPolicy/KL                     0.000146049
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -381.669
GaussianMLPPolicy/LossBefore          -381.409
GaussianMLPPolicy/dLoss                  0.259735
GaussianMLPValueFunction/LossAfter   17978.5
GaussianMLPValueFunction/LossBefore  17995.2
GaussianMLPValueFunction/dLoss          16.6777
TotalEnvSteps                            1.0584e+06
-----------------------------------  ---------------
2022-08-17 18:00:44 | [trpo_pendulum] epoch #882 | Saving snapshot...
2022-08-17 18:00:44 | [trpo_pendulum] epoch #882 | Saved
2022-08-17 18:00:44 | [trpo_pendulum] epoch #882 | Time 364.20 s
2022-08-17 18:00:44 | [trpo_pendulum] epoch #882 | EpochTime 0.42 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -445.875
Evaluation/AverageReturn              -983.514
Evaluation/Iteration                   882
Evaluation/MaxReturn                  -938.115
Evaluation/MinReturn                 -1016.97
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    30.6052
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42017
GaussianMLPPolicy/KL                     0.000139437
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -340.656
GaussianMLPPolicy/LossBefore          -340.611
GaussianMLPPolicy/dLoss                  0.045105
GaussianMLPValueFunction/LossAfter   13885.7
GaussianMLPValueFunction/LossBefore  13898.4
GaussianMLPValueFunction/dLoss          12.6553
TotalEnvSteps                            1.0596e+06
-----------------------------------  ---------------
2022-08-17 18:00:44 | [trpo_pendulum] epoch #883 | Saving snapshot...
2022-08-17 18:00:44 | [trpo_pendulum] epoch #883 | Saved
2022-08-17 18:00:44 | [trpo_pendulum] epoch #883 | Time 364.61 s
2022-08-17 18:00:44 | [trpo_pendulum] epoch #883 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -411.127
Evaluation/AverageReturn              -921.874
Evaluation/Iteration                   883
Evaluation/MaxReturn                  -865.298
Evaluation/MinReturn                  -981.425
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    43.2125
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42009
GaussianMLPPolicy/KL                     3.54818e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -318.992
GaussianMLPPolicy/LossBefore          -319.038
GaussianMLPPolicy/dLoss                 -0.0459595
GaussianMLPValueFunction/LossAfter   11845.5
GaussianMLPValueFunction/LossBefore  11856
GaussianMLPValueFunction/dLoss          10.5029
TotalEnvSteps                            1.0608e+06
-----------------------------------  ---------------
2022-08-17 18:00:45 | [trpo_pendulum] epoch #884 | Saving snapshot...
2022-08-17 18:00:45 | [trpo_pendulum] epoch #884 | Saved
2022-08-17 18:00:45 | [trpo_pendulum] epoch #884 | Time 365.04 s
2022-08-17 18:00:45 | [trpo_pendulum] epoch #884 | EpochTime 0.42 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -639.71
Evaluation/AverageReturn             -1423.84
Evaluation/Iteration                   884
Evaluation/MaxReturn                 -1321.76
Evaluation/MinReturn                 -1525.3
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    76.6598
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41988
GaussianMLPPolicy/KL                     1.44632e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -528.315
GaussianMLPPolicy/LossBefore          -528.286
GaussianMLPPolicy/dLoss                  0.0289917
GaussianMLPValueFunction/LossAfter   31032.8
GaussianMLPValueFunction/LossBefore  31059.7
GaussianMLPValueFunction/dLoss          26.8145
TotalEnvSteps                            1.062e+06
-----------------------------------  ---------------
2022-08-17 18:00:45 | [trpo_pendulum] epoch #885 | Saving snapshot...
2022-08-17 18:00:45 | [trpo_pendulum] epoch #885 | Saved
2022-08-17 18:00:45 | [trpo_pendulum] epoch #885 | Time 365.44 s
2022-08-17 18:00:45 | [trpo_pendulum] epoch #885 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -728.912
Evaluation/AverageReturn             -1621.53
Evaluation/Iteration                   885
Evaluation/MaxReturn                 -1528.03
Evaluation/MinReturn                 -1809.01
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    94.5493
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41983
GaussianMLPPolicy/KL                     1.90375e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -583.359
GaussianMLPPolicy/LossBefore          -583.25
GaussianMLPPolicy/dLoss                  0.108948
GaussianMLPValueFunction/LossAfter   40679
GaussianMLPValueFunction/LossBefore  40716.4
GaussianMLPValueFunction/dLoss          37.4023
TotalEnvSteps                            1.0632e+06
-----------------------------------  ---------------
2022-08-17 18:00:45 | [trpo_pendulum] epoch #886 | Saving snapshot...
2022-08-17 18:00:45 | [trpo_pendulum] epoch #886 | Saved
2022-08-17 18:00:45 | [trpo_pendulum] epoch #886 | Time 365.84 s
2022-08-17 18:00:45 | [trpo_pendulum] epoch #886 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -434.764
Evaluation/AverageReturn              -998.17
Evaluation/Iteration                   886
Evaluation/MaxReturn                  -887.675
Evaluation/MinReturn                 -1044.3
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    52.0702
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.4197
GaussianMLPPolicy/KL                     2.53516e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -366.146
GaussianMLPPolicy/LossBefore          -366.156
GaussianMLPPolicy/dLoss                 -0.00976562
GaussianMLPValueFunction/LossAfter   14932.6
GaussianMLPValueFunction/LossBefore  14946.7
GaussianMLPValueFunction/dLoss          14.0635
TotalEnvSteps                            1.0644e+06
-----------------------------------  ---------------
2022-08-17 18:00:46 | [trpo_pendulum] epoch #887 | Saving snapshot...
2022-08-17 18:00:46 | [trpo_pendulum] epoch #887 | Saved
2022-08-17 18:00:46 | [trpo_pendulum] epoch #887 | Time 366.24 s
2022-08-17 18:00:46 | [trpo_pendulum] epoch #887 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -397.23
Evaluation/AverageReturn              -998.099
Evaluation/Iteration                   887
Evaluation/MaxReturn                  -872.744
Evaluation/MinReturn                 -1052.35
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    60.1297
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41957
GaussianMLPPolicy/KL                     8.39134e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -386.386
GaussianMLPPolicy/LossBefore          -386.115
GaussianMLPPolicy/dLoss                  0.270874
GaussianMLPValueFunction/LossAfter   16792.1
GaussianMLPValueFunction/LossBefore  16807.4
GaussianMLPValueFunction/dLoss          15.3359
TotalEnvSteps                            1.0656e+06
-----------------------------------  ---------------
2022-08-17 18:00:46 | [trpo_pendulum] epoch #888 | Saving snapshot...
2022-08-17 18:00:46 | [trpo_pendulum] epoch #888 | Saved
2022-08-17 18:00:46 | [trpo_pendulum] epoch #888 | Time 366.64 s
2022-08-17 18:00:46 | [trpo_pendulum] epoch #888 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -402.584
Evaluation/AverageReturn              -927.687
Evaluation/Iteration                   888
Evaluation/MaxReturn                  -831.374
Evaluation/MinReturn                 -1033.15
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    73.911
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41945
GaussianMLPPolicy/KL                     0.000132934
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -332.388
GaussianMLPPolicy/LossBefore          -332.216
GaussianMLPPolicy/dLoss                  0.17215
GaussianMLPValueFunction/LossAfter   12760.9
GaussianMLPValueFunction/LossBefore  12772.3
GaussianMLPValueFunction/dLoss          11.4014
TotalEnvSteps                            1.0668e+06
-----------------------------------  ---------------
2022-08-17 18:00:47 | [trpo_pendulum] epoch #889 | Saving snapshot...
2022-08-17 18:00:47 | [trpo_pendulum] epoch #889 | Saved
2022-08-17 18:00:47 | [trpo_pendulum] epoch #889 | Time 367.05 s
2022-08-17 18:00:47 | [trpo_pendulum] epoch #889 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -434.467
Evaluation/AverageReturn              -972.89
Evaluation/Iteration                   889
Evaluation/MaxReturn                  -865.414
Evaluation/MinReturn                 -1014.77
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    50.7495
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41939
GaussianMLPPolicy/KL                     3.89843e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -337.204
GaussianMLPPolicy/LossBefore          -337.253
GaussianMLPPolicy/dLoss                 -0.0498352
GaussianMLPValueFunction/LossAfter   13658.2
GaussianMLPValueFunction/LossBefore  13669.9
GaussianMLPValueFunction/dLoss          11.7129
TotalEnvSteps                            1.068e+06
-----------------------------------  ---------------
2022-08-17 18:00:47 | [trpo_pendulum] epoch #890 | Saving snapshot...
2022-08-17 18:00:47 | [trpo_pendulum] epoch #890 | Saved
2022-08-17 18:00:47 | [trpo_pendulum] epoch #890 | Time 367.45 s
2022-08-17 18:00:47 | [trpo_pendulum] epoch #890 | EpochTime 0.39 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -683.915
Evaluation/AverageReturn             -1474.89
Evaluation/Iteration                   890
Evaluation/MaxReturn                 -1283
Evaluation/MinReturn                 -1614.7
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   100.886
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41956
GaussianMLPPolicy/KL                     0.00014195
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -504.464
GaussianMLPPolicy/LossBefore          -503.934
GaussianMLPPolicy/dLoss                  0.530518
GaussianMLPValueFunction/LossAfter   32340.5
GaussianMLPValueFunction/LossBefore  32368
GaussianMLPValueFunction/dLoss          27.5156
TotalEnvSteps                            1.0692e+06
-----------------------------------  --------------
2022-08-17 18:00:47 | [trpo_pendulum] epoch #891 | Saving snapshot...
2022-08-17 18:00:48 | [trpo_pendulum] epoch #891 | Saved
2022-08-17 18:00:48 | [trpo_pendulum] epoch #891 | Time 367.86 s
2022-08-17 18:00:48 | [trpo_pendulum] epoch #891 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -615.591
Evaluation/AverageReturn             -1377.34
Evaluation/Iteration                   891
Evaluation/MaxReturn                 -1185.61
Evaluation/MinReturn                 -1469.03
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   101.057
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41953
GaussianMLPPolicy/KL                     2.29805e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -515.092
GaussianMLPPolicy/LossBefore          -515.144
GaussianMLPPolicy/dLoss                 -0.0523071
GaussianMLPValueFunction/LossAfter   28952.8
GaussianMLPValueFunction/LossBefore  28978.4
GaussianMLPValueFunction/dLoss          25.5879
TotalEnvSteps                            1.0704e+06
-----------------------------------  ---------------
2022-08-17 18:00:48 | [trpo_pendulum] epoch #892 | Saving snapshot...
2022-08-17 18:00:48 | [trpo_pendulum] epoch #892 | Saved
2022-08-17 18:00:48 | [trpo_pendulum] epoch #892 | Time 368.26 s
2022-08-17 18:00:48 | [trpo_pendulum] epoch #892 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -419.437
Evaluation/AverageReturn              -976.279
Evaluation/Iteration                   892
Evaluation/MaxReturn                  -881.286
Evaluation/MinReturn                 -1040.63
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    61.2688
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41952
GaussianMLPPolicy/KL                     0.000139086
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -353.469
GaussianMLPPolicy/LossBefore          -353.19
GaussianMLPPolicy/dLoss                  0.279053
GaussianMLPValueFunction/LossAfter   14375.4
GaussianMLPValueFunction/LossBefore  14388.2
GaussianMLPValueFunction/dLoss          12.8779
TotalEnvSteps                            1.0716e+06
-----------------------------------  ---------------
2022-08-17 18:00:48 | [trpo_pendulum] epoch #893 | Saving snapshot...
2022-08-17 18:00:48 | [trpo_pendulum] epoch #893 | Saved
2022-08-17 18:00:48 | [trpo_pendulum] epoch #893 | Time 368.65 s
2022-08-17 18:00:48 | [trpo_pendulum] epoch #893 | EpochTime 0.39 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -736.182
Evaluation/AverageReturn             -1641.3
Evaluation/Iteration                   893
Evaluation/MaxReturn                 -1543
Evaluation/MinReturn                 -1766.29
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    71.4569
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41957
GaussianMLPPolicy/KL                     1.2998e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -598.184
GaussianMLPPolicy/LossBefore          -598.235
GaussianMLPPolicy/dLoss                 -0.0505981
GaussianMLPValueFunction/LossAfter   41632
GaussianMLPValueFunction/LossBefore  41669.9
GaussianMLPValueFunction/dLoss          37.9102
TotalEnvSteps                            1.0728e+06
-----------------------------------  --------------
2022-08-17 18:00:49 | [trpo_pendulum] epoch #894 | Saving snapshot...
2022-08-17 18:00:49 | [trpo_pendulum] epoch #894 | Saved
2022-08-17 18:00:49 | [trpo_pendulum] epoch #894 | Time 369.07 s
2022-08-17 18:00:49 | [trpo_pendulum] epoch #894 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -525.9
Evaluation/AverageReturn             -1169.45
Evaluation/Iteration                   894
Evaluation/MaxReturn                  -968.029
Evaluation/MinReturn                 -1279.82
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   100.913
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41957
GaussianMLPPolicy/KL                     4.21381e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -419.835
GaussianMLPPolicy/LossBefore          -419.753
GaussianMLPPolicy/dLoss                  0.0826416
GaussianMLPValueFunction/LossAfter   20281.1
GaussianMLPValueFunction/LossBefore  20300
GaussianMLPValueFunction/dLoss          18.9238
TotalEnvSteps                            1.074e+06
-----------------------------------  ---------------
2022-08-17 18:00:49 | [trpo_pendulum] epoch #895 | Saving snapshot...
2022-08-17 18:00:49 | [trpo_pendulum] epoch #895 | Saved
2022-08-17 18:00:49 | [trpo_pendulum] epoch #895 | Time 369.48 s
2022-08-17 18:00:49 | [trpo_pendulum] epoch #895 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -373.771
Evaluation/AverageReturn              -860.449
Evaluation/Iteration                   895
Evaluation/MaxReturn                  -755.079
Evaluation/MinReturn                  -903.72
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    49.3397
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41955
GaussianMLPPolicy/KL                     2.52958e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -305.628
GaussianMLPPolicy/LossBefore          -305.607
GaussianMLPPolicy/dLoss                  0.0203552
GaussianMLPValueFunction/LossAfter   10775.7
GaussianMLPValueFunction/LossBefore  10785.7
GaussianMLPValueFunction/dLoss          10.0234
TotalEnvSteps                            1.0752e+06
-----------------------------------  ---------------
2022-08-17 18:00:50 | [trpo_pendulum] epoch #896 | Saving snapshot...
2022-08-17 18:00:50 | [trpo_pendulum] epoch #896 | Saved
2022-08-17 18:00:50 | [trpo_pendulum] epoch #896 | Time 369.88 s
2022-08-17 18:00:50 | [trpo_pendulum] epoch #896 | EpochTime 0.39 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -541.406
Evaluation/AverageReturn             -1243.09
Evaluation/Iteration                   896
Evaluation/MaxReturn                 -1165.49
Evaluation/MinReturn                 -1332.81
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    52.4644
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41953
GaussianMLPPolicy/KL                     6.432e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -458.071
GaussianMLPPolicy/LossBefore          -458.016
GaussianMLPPolicy/dLoss                  0.0544434
GaussianMLPValueFunction/LossAfter   23697.9
GaussianMLPValueFunction/LossBefore  23718.9
GaussianMLPValueFunction/dLoss          20.9844
TotalEnvSteps                            1.0764e+06
-----------------------------------  --------------
2022-08-17 18:00:50 | [trpo_pendulum] epoch #897 | Saving snapshot...
2022-08-17 18:00:50 | [trpo_pendulum] epoch #897 | Saved
2022-08-17 18:00:50 | [trpo_pendulum] epoch #897 | Time 370.28 s
2022-08-17 18:00:50 | [trpo_pendulum] epoch #897 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -713.848
Evaluation/AverageReturn             -1572.02
Evaluation/Iteration                   897
Evaluation/MaxReturn                 -1431
Evaluation/MinReturn                 -1741.33
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    95.2776
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41971
GaussianMLPPolicy/KL                     2.98164e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -552.873
GaussianMLPPolicy/LossBefore          -552.876
GaussianMLPPolicy/dLoss                 -0.00250244
GaussianMLPValueFunction/LossAfter   37522.2
GaussianMLPValueFunction/LossBefore  37556.6
GaussianMLPValueFunction/dLoss          34.457
TotalEnvSteps                            1.0776e+06
-----------------------------------  ---------------
2022-08-17 18:00:50 | [trpo_pendulum] epoch #898 | Saving snapshot...
2022-08-17 18:00:50 | [trpo_pendulum] epoch #898 | Saved
2022-08-17 18:00:50 | [trpo_pendulum] epoch #898 | Time 370.69 s
2022-08-17 18:00:50 | [trpo_pendulum] epoch #898 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -644.508
Evaluation/AverageReturn             -1446.57
Evaluation/Iteration                   898
Evaluation/MaxReturn                 -1351.48
Evaluation/MinReturn                 -1526.36
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    62.2384
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41996
GaussianMLPPolicy/KL                     8.08873e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -523.81
GaussianMLPPolicy/LossBefore          -523.48
GaussianMLPPolicy/dLoss                  0.32959
GaussianMLPValueFunction/LossAfter   31998.9
GaussianMLPValueFunction/LossBefore  32029.5
GaussianMLPValueFunction/dLoss          30.623
TotalEnvSteps                            1.0788e+06
-----------------------------------  ---------------
2022-08-17 18:00:51 | [trpo_pendulum] epoch #899 | Saving snapshot...
2022-08-17 18:00:51 | [trpo_pendulum] epoch #899 | Saved
2022-08-17 18:00:51 | [trpo_pendulum] epoch #899 | Time 371.11 s
2022-08-17 18:00:51 | [trpo_pendulum] epoch #899 | EpochTime 0.42 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -705.93
Evaluation/AverageReturn             -1563.08
Evaluation/Iteration                   899
Evaluation/MaxReturn                 -1317.53
Evaluation/MinReturn                 -1789.43
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   146.68
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42
GaussianMLPPolicy/KL                     8.04108e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -582.644
GaussianMLPPolicy/LossBefore          -582.491
GaussianMLPPolicy/dLoss                  0.153015
GaussianMLPValueFunction/LossAfter   37563
GaussianMLPValueFunction/LossBefore  37600.4
GaussianMLPValueFunction/dLoss          37.418
TotalEnvSteps                            1.08e+06
-----------------------------------  ---------------
2022-08-17 18:00:51 | [trpo_pendulum] epoch #900 | Saving snapshot...
2022-08-17 18:00:51 | [trpo_pendulum] epoch #900 | Saved
2022-08-17 18:00:51 | [trpo_pendulum] epoch #900 | Time 371.51 s
2022-08-17 18:00:51 | [trpo_pendulum] epoch #900 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -601.022
Evaluation/AverageReturn             -1350.97
Evaluation/Iteration                   900
Evaluation/MaxReturn                 -1192.45
Evaluation/MinReturn                 -1473.56
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    94.344
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41993
GaussianMLPPolicy/KL                     0.000198258
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -501.73
GaussianMLPPolicy/LossBefore          -501.435
GaussianMLPPolicy/dLoss                  0.294952
GaussianMLPValueFunction/LossAfter   27914
GaussianMLPValueFunction/LossBefore  27942.5
GaussianMLPValueFunction/dLoss          28.4492
TotalEnvSteps                            1.0812e+06
-----------------------------------  ---------------
2022-08-17 18:00:52 | [trpo_pendulum] epoch #901 | Saving snapshot...
2022-08-17 18:00:52 | [trpo_pendulum] epoch #901 | Saved
2022-08-17 18:00:52 | [trpo_pendulum] epoch #901 | Time 371.91 s
2022-08-17 18:00:52 | [trpo_pendulum] epoch #901 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -541.332
Evaluation/AverageReturn             -1182.91
Evaluation/Iteration                   901
Evaluation/MaxReturn                 -1122.36
Evaluation/MinReturn                 -1232.15
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    36.178
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41979
GaussianMLPPolicy/KL                     9.40844e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -420.852
GaussianMLPPolicy/LossBefore          -420.918
GaussianMLPPolicy/dLoss                 -0.0655823
GaussianMLPValueFunction/LossAfter   20240.5
GaussianMLPValueFunction/LossBefore  20261
GaussianMLPValueFunction/dLoss          20.543
TotalEnvSteps                            1.0824e+06
-----------------------------------  ---------------
2022-08-17 18:00:52 | [trpo_pendulum] epoch #902 | Saving snapshot...
2022-08-17 18:00:52 | [trpo_pendulum] epoch #902 | Saved
2022-08-17 18:00:52 | [trpo_pendulum] epoch #902 | Time 372.32 s
2022-08-17 18:00:52 | [trpo_pendulum] epoch #902 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -473.325
Evaluation/AverageReturn             -1053.43
Evaluation/Iteration                   902
Evaluation/MaxReturn                  -960.784
Evaluation/MinReturn                 -1163.96
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    68.6051
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41947
GaussianMLPPolicy/KL                     0.000129396
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -385.914
GaussianMLPPolicy/LossBefore          -385.793
GaussianMLPPolicy/dLoss                  0.121307
GaussianMLPValueFunction/LossAfter   15928.3
GaussianMLPValueFunction/LossBefore  15944.2
GaussianMLPValueFunction/dLoss          15.8623
TotalEnvSteps                            1.0836e+06
-----------------------------------  ---------------
2022-08-17 18:00:52 | [trpo_pendulum] epoch #903 | Saving snapshot...
2022-08-17 18:00:52 | [trpo_pendulum] epoch #903 | Saved
2022-08-17 18:00:52 | [trpo_pendulum] epoch #903 | Time 372.72 s
2022-08-17 18:00:52 | [trpo_pendulum] epoch #903 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -620.746
Evaluation/AverageReturn             -1372.07
Evaluation/Iteration                   903
Evaluation/MaxReturn                 -1313.12
Evaluation/MinReturn                 -1428.44
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    46.1909
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41925
GaussianMLPPolicy/KL                     0.000136174
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -488.052
GaussianMLPPolicy/LossBefore          -487.898
GaussianMLPPolicy/dLoss                  0.15448
GaussianMLPValueFunction/LossAfter   27869.1
GaussianMLPValueFunction/LossBefore  27896.3
GaussianMLPValueFunction/dLoss          27.1934
TotalEnvSteps                            1.0848e+06
-----------------------------------  ---------------
2022-08-17 18:00:53 | [trpo_pendulum] epoch #904 | Saving snapshot...
2022-08-17 18:00:53 | [trpo_pendulum] epoch #904 | Saved
2022-08-17 18:00:53 | [trpo_pendulum] epoch #904 | Time 373.12 s
2022-08-17 18:00:53 | [trpo_pendulum] epoch #904 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -506.528
Evaluation/AverageReturn             -1113.48
Evaluation/Iteration                   904
Evaluation/MaxReturn                 -1071.74
Evaluation/MinReturn                 -1169.96
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    39.5412
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41902
GaussianMLPPolicy/KL                     0.000173016
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -392.213
GaussianMLPPolicy/LossBefore          -392.085
GaussianMLPPolicy/dLoss                  0.128052
GaussianMLPValueFunction/LossAfter   17628.5
GaussianMLPValueFunction/LossBefore  17645.7
GaussianMLPValueFunction/dLoss          17.1914
TotalEnvSteps                            1.086e+06
-----------------------------------  ---------------
2022-08-17 18:00:53 | [trpo_pendulum] epoch #905 | Saving snapshot...
2022-08-17 18:00:53 | [trpo_pendulum] epoch #905 | Saved
2022-08-17 18:00:53 | [trpo_pendulum] epoch #905 | Time 373.52 s
2022-08-17 18:00:53 | [trpo_pendulum] epoch #905 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -675.947
Evaluation/AverageReturn             -1476.12
Evaluation/Iteration                   905
Evaluation/MaxReturn                 -1369.2
Evaluation/MinReturn                 -1578.95
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    74.6982
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41889
GaussianMLPPolicy/KL                     0.000219112
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -521.655
GaussianMLPPolicy/LossBefore          -521.214
GaussianMLPPolicy/dLoss                  0.440613
GaussianMLPValueFunction/LossAfter   32461.2
GaussianMLPValueFunction/LossBefore  32492.8
GaussianMLPValueFunction/dLoss          31.5566
TotalEnvSteps                            1.0872e+06
-----------------------------------  ---------------
2022-08-17 18:00:54 | [trpo_pendulum] epoch #906 | Saving snapshot...
2022-08-17 18:00:54 | [trpo_pendulum] epoch #906 | Saved
2022-08-17 18:00:54 | [trpo_pendulum] epoch #906 | Time 373.93 s
2022-08-17 18:00:54 | [trpo_pendulum] epoch #906 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -514.161
Evaluation/AverageReturn             -1127.53
Evaluation/Iteration                   906
Evaluation/MaxReturn                 -1075.15
Evaluation/MinReturn                 -1213.83
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    51.5465
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41883
GaussianMLPPolicy/KL                     0.000106397
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -389.835
GaussianMLPPolicy/LossBefore          -389.968
GaussianMLPPolicy/dLoss                 -0.132568
GaussianMLPValueFunction/LossAfter   17955.7
GaussianMLPValueFunction/LossBefore  17973.3
GaussianMLPValueFunction/dLoss          17.5898
TotalEnvSteps                            1.0884e+06
-----------------------------------  ---------------
2022-08-17 18:00:54 | [trpo_pendulum] epoch #907 | Saving snapshot...
2022-08-17 18:00:54 | [trpo_pendulum] epoch #907 | Saved
2022-08-17 18:00:54 | [trpo_pendulum] epoch #907 | Time 374.32 s
2022-08-17 18:00:54 | [trpo_pendulum] epoch #907 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -558.476
Evaluation/AverageReturn             -1191.61
Evaluation/Iteration                   907
Evaluation/MaxReturn                 -1085.99
Evaluation/MinReturn                 -1306.89
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    76.7289
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41868
GaussianMLPPolicy/KL                     3.23356e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -416.539
GaussianMLPPolicy/LossBefore          -416.542
GaussianMLPPolicy/dLoss                 -0.00262451
GaussianMLPValueFunction/LossAfter   20021.5
GaussianMLPValueFunction/LossBefore  20040.6
GaussianMLPValueFunction/dLoss          19.1191
TotalEnvSteps                            1.0896e+06
-----------------------------------  ---------------
2022-08-17 18:00:54 | [trpo_pendulum] epoch #908 | Saving snapshot...
2022-08-17 18:00:54 | [trpo_pendulum] epoch #908 | Saved
2022-08-17 18:00:54 | [trpo_pendulum] epoch #908 | Time 374.73 s
2022-08-17 18:00:54 | [trpo_pendulum] epoch #908 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -521.195
Evaluation/AverageReturn             -1140.23
Evaluation/Iteration                   908
Evaluation/MaxReturn                 -1056.87
Evaluation/MinReturn                 -1288.97
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    82.5736
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41852
GaussianMLPPolicy/KL                     2.52148e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -399.129
GaussianMLPPolicy/LossBefore          -399.144
GaussianMLPPolicy/dLoss                 -0.015564
GaussianMLPValueFunction/LossAfter   18234.3
GaussianMLPValueFunction/LossBefore  18251.5
GaussianMLPValueFunction/dLoss          17.1875
TotalEnvSteps                            1.0908e+06
-----------------------------------  ---------------
2022-08-17 18:00:55 | [trpo_pendulum] epoch #909 | Saving snapshot...
2022-08-17 18:00:55 | [trpo_pendulum] epoch #909 | Saved
2022-08-17 18:00:55 | [trpo_pendulum] epoch #909 | Time 375.12 s
2022-08-17 18:00:55 | [trpo_pendulum] epoch #909 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -432.461
Evaluation/AverageReturn              -973.473
Evaluation/Iteration                   909
Evaluation/MaxReturn                  -875.997
Evaluation/MinReturn                 -1094.4
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    89.5166
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41835
GaussianMLPPolicy/KL                     3.88451e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -345.098
GaussianMLPPolicy/LossBefore          -344.996
GaussianMLPPolicy/dLoss                  0.10202
GaussianMLPValueFunction/LossAfter   13327.9
GaussianMLPValueFunction/LossBefore  13340.3
GaussianMLPValueFunction/dLoss          12.3555
TotalEnvSteps                            1.092e+06
-----------------------------------  ---------------
2022-08-17 18:00:55 | [trpo_pendulum] epoch #910 | Saving snapshot...
2022-08-17 18:00:55 | [trpo_pendulum] epoch #910 | Saved
2022-08-17 18:00:55 | [trpo_pendulum] epoch #910 | Time 375.54 s
2022-08-17 18:00:55 | [trpo_pendulum] epoch #910 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -494.883
Evaluation/AverageReturn             -1088.57
Evaluation/Iteration                   910
Evaluation/MaxReturn                 -1050.71
Evaluation/MinReturn                 -1175.19
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    40.2121
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41822
GaussianMLPPolicy/KL                     8.55077e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -377.52
GaussianMLPPolicy/LossBefore          -377.383
GaussianMLPPolicy/dLoss                  0.136566
GaussianMLPValueFunction/LossAfter   16468.7
GaussianMLPValueFunction/LossBefore  16483.4
GaussianMLPValueFunction/dLoss          14.668
TotalEnvSteps                            1.0932e+06
-----------------------------------  ---------------
2022-08-17 18:00:56 | [trpo_pendulum] epoch #911 | Saving snapshot...
2022-08-17 18:00:56 | [trpo_pendulum] epoch #911 | Saved
2022-08-17 18:00:56 | [trpo_pendulum] epoch #911 | Time 375.93 s
2022-08-17 18:00:56 | [trpo_pendulum] epoch #911 | EpochTime 0.38 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -424.313
Evaluation/AverageReturn              -967.206
Evaluation/Iteration                   911
Evaluation/MaxReturn                  -892.456
Evaluation/MinReturn                 -1042.77
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    55.0108
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41812
GaussianMLPPolicy/KL                     9.02427e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -342.646
GaussianMLPPolicy/LossBefore          -342.684
GaussianMLPPolicy/dLoss                 -0.0373535
GaussianMLPValueFunction/LossAfter   13786.9
GaussianMLPValueFunction/LossBefore  13798.9
GaussianMLPValueFunction/dLoss          12.0186
TotalEnvSteps                            1.0944e+06
-----------------------------------  ---------------
2022-08-17 18:00:56 | [trpo_pendulum] epoch #912 | Saving snapshot...
2022-08-17 18:00:56 | [trpo_pendulum] epoch #912 | Saved
2022-08-17 18:00:56 | [trpo_pendulum] epoch #912 | Time 376.32 s
2022-08-17 18:00:56 | [trpo_pendulum] epoch #912 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -409.731
Evaluation/AverageReturn              -965.05
Evaluation/Iteration                   912
Evaluation/MaxReturn                  -801.617
Evaluation/MinReturn                 -1111.1
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   100.613
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.418
GaussianMLPPolicy/KL                     1.63735e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -353.249
GaussianMLPPolicy/LossBefore          -353.203
GaussianMLPPolicy/dLoss                  0.0461426
GaussianMLPValueFunction/LossAfter   14030.7
GaussianMLPValueFunction/LossBefore  14042.5
GaussianMLPValueFunction/dLoss          11.874
TotalEnvSteps                            1.0956e+06
-----------------------------------  ---------------
2022-08-17 18:00:56 | [trpo_pendulum] epoch #913 | Saving snapshot...
2022-08-17 18:00:56 | [trpo_pendulum] epoch #913 | Saved
2022-08-17 18:00:56 | [trpo_pendulum] epoch #913 | Time 376.74 s
2022-08-17 18:00:56 | [trpo_pendulum] epoch #913 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -671.287
Evaluation/AverageReturn             -1433.4
Evaluation/Iteration                   913
Evaluation/MaxReturn                 -1360.41
Evaluation/MinReturn                 -1550.91
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    75.089
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.418
GaussianMLPPolicy/KL                     1.77632e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -492.405
GaussianMLPPolicy/LossBefore          -492.357
GaussianMLPPolicy/dLoss                  0.0482788
GaussianMLPValueFunction/LossAfter   29404.5
GaussianMLPValueFunction/LossBefore  29429.1
GaussianMLPValueFunction/dLoss          24.6094
TotalEnvSteps                            1.0968e+06
-----------------------------------  ---------------
2022-08-17 18:00:57 | [trpo_pendulum] epoch #914 | Saving snapshot...
2022-08-17 18:00:57 | [trpo_pendulum] epoch #914 | Saved
2022-08-17 18:00:57 | [trpo_pendulum] epoch #914 | Time 377.15 s
2022-08-17 18:00:57 | [trpo_pendulum] epoch #914 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -692.49
Evaluation/AverageReturn             -1485.4
Evaluation/Iteration                   914
Evaluation/MaxReturn                 -1290.56
Evaluation/MinReturn                 -1662.56
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   135.155
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41795
GaussianMLPPolicy/KL                     4.63582e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -526.156
GaussianMLPPolicy/LossBefore          -526.019
GaussianMLPPolicy/dLoss                  0.137573
GaussianMLPValueFunction/LossAfter   32412.1
GaussianMLPValueFunction/LossBefore  32440.4
GaussianMLPValueFunction/dLoss          28.334
TotalEnvSteps                            1.098e+06
-----------------------------------  ---------------
2022-08-17 18:00:57 | [trpo_pendulum] epoch #915 | Saving snapshot...
2022-08-17 18:00:57 | [trpo_pendulum] epoch #915 | Saved
2022-08-17 18:00:57 | [trpo_pendulum] epoch #915 | Time 377.54 s
2022-08-17 18:00:57 | [trpo_pendulum] epoch #915 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -408.132
Evaluation/AverageReturn              -978.527
Evaluation/Iteration                   915
Evaluation/MaxReturn                  -882.442
Evaluation/MinReturn                 -1047.86
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    61.4007
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.4179
GaussianMLPPolicy/KL                     3.57268e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -362.428
GaussianMLPPolicy/LossBefore          -362.45
GaussianMLPPolicy/dLoss                 -0.0216675
GaussianMLPValueFunction/LossAfter   14686.1
GaussianMLPValueFunction/LossBefore  14699.2
GaussianMLPValueFunction/dLoss          13.1426
TotalEnvSteps                            1.0992e+06
-----------------------------------  ---------------
2022-08-17 18:00:58 | [trpo_pendulum] epoch #916 | Saving snapshot...
2022-08-17 18:00:58 | [trpo_pendulum] epoch #916 | Saved
2022-08-17 18:00:58 | [trpo_pendulum] epoch #916 | Time 377.93 s
2022-08-17 18:00:58 | [trpo_pendulum] epoch #916 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -401.748
Evaluation/AverageReturn              -967.115
Evaluation/Iteration                   916
Evaluation/MaxReturn                  -904.644
Evaluation/MinReturn                 -1042.35
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    52.4682
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41784
GaussianMLPPolicy/KL                     4.38842e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -360.495
GaussianMLPPolicy/LossBefore          -360.502
GaussianMLPPolicy/dLoss                 -0.00701904
GaussianMLPValueFunction/LossAfter   14986.3
GaussianMLPValueFunction/LossBefore  14999.3
GaussianMLPValueFunction/dLoss          12.9766
TotalEnvSteps                            1.1004e+06
-----------------------------------  ---------------
2022-08-17 18:00:58 | [trpo_pendulum] epoch #917 | Saving snapshot...
2022-08-17 18:00:58 | [trpo_pendulum] epoch #917 | Saved
2022-08-17 18:00:58 | [trpo_pendulum] epoch #917 | Time 378.34 s
2022-08-17 18:00:58 | [trpo_pendulum] epoch #917 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -500.133
Evaluation/AverageReturn             -1076.75
Evaluation/Iteration                   917
Evaluation/MaxReturn                  -991.128
Evaluation/MinReturn                 -1115.68
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    40.0063
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41786
GaussianMLPPolicy/KL                     1.62676e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -362.119
GaussianMLPPolicy/LossBefore          -362.084
GaussianMLPPolicy/dLoss                  0.0343933
GaussianMLPValueFunction/LossAfter   16056.5
GaussianMLPValueFunction/LossBefore  16070
GaussianMLPValueFunction/dLoss          13.5068
TotalEnvSteps                            1.1016e+06
-----------------------------------  ---------------
2022-08-17 18:00:58 | [trpo_pendulum] epoch #918 | Saving snapshot...
2022-08-17 18:00:58 | [trpo_pendulum] epoch #918 | Saved
2022-08-17 18:00:58 | [trpo_pendulum] epoch #918 | Time 378.75 s
2022-08-17 18:00:58 | [trpo_pendulum] epoch #918 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -426.493
Evaluation/AverageReturn             -1017.31
Evaluation/Iteration                   918
Evaluation/MaxReturn                  -912.757
Evaluation/MinReturn                 -1082.03
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    51.9364
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41787
GaussianMLPPolicy/KL                     5.43982e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -377.157
GaussianMLPPolicy/LossBefore          -377.071
GaussianMLPPolicy/dLoss                  0.085907
GaussianMLPValueFunction/LossAfter   15913.6
GaussianMLPValueFunction/LossBefore  15926.8
GaussianMLPValueFunction/dLoss          13.2471
TotalEnvSteps                            1.1028e+06
-----------------------------------  ---------------
2022-08-17 18:00:59 | [trpo_pendulum] epoch #919 | Saving snapshot...
2022-08-17 18:00:59 | [trpo_pendulum] epoch #919 | Saved
2022-08-17 18:00:59 | [trpo_pendulum] epoch #919 | Time 379.14 s
2022-08-17 18:00:59 | [trpo_pendulum] epoch #919 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -484.78
Evaluation/AverageReturn             -1061.68
Evaluation/Iteration                   919
Evaluation/MaxReturn                  -982.015
Evaluation/MinReturn                 -1113.14
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    45.473
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41794
GaussianMLPPolicy/KL                     7.49074e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -362.537
GaussianMLPPolicy/LossBefore          -362.455
GaussianMLPPolicy/dLoss                  0.0826721
GaussianMLPValueFunction/LossAfter   15398.1
GaussianMLPValueFunction/LossBefore  15410.6
GaussianMLPValueFunction/dLoss          12.5254
TotalEnvSteps                            1.104e+06
-----------------------------------  ---------------
2022-08-17 18:00:59 | [trpo_pendulum] epoch #920 | Saving snapshot...
2022-08-17 18:00:59 | [trpo_pendulum] epoch #920 | Saved
2022-08-17 18:00:59 | [trpo_pendulum] epoch #920 | Time 379.55 s
2022-08-17 18:00:59 | [trpo_pendulum] epoch #920 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -528.905
Evaluation/AverageReturn             -1129.71
Evaluation/Iteration                   920
Evaluation/MaxReturn                 -1105.7
Evaluation/MinReturn                 -1208.73
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    35.5578
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41806
GaussianMLPPolicy/KL                     6.00674e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -380.589
GaussianMLPPolicy/LossBefore          -380.559
GaussianMLPPolicy/dLoss                  0.0297546
GaussianMLPValueFunction/LossAfter   17365.4
GaussianMLPValueFunction/LossBefore  17379.3
GaussianMLPValueFunction/dLoss          13.8281
TotalEnvSteps                            1.1052e+06
-----------------------------------  ---------------
2022-08-17 18:01:00 | [trpo_pendulum] epoch #921 | Saving snapshot...
2022-08-17 18:01:00 | [trpo_pendulum] epoch #921 | Saved
2022-08-17 18:01:00 | [trpo_pendulum] epoch #921 | Time 379.96 s
2022-08-17 18:01:00 | [trpo_pendulum] epoch #921 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -467.544
Evaluation/AverageReturn             -1096.65
Evaluation/Iteration                   921
Evaluation/MaxReturn                 -1036.94
Evaluation/MinReturn                 -1179.87
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    58.093
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41827
GaussianMLPPolicy/KL                     1.99874e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -396.019
GaussianMLPPolicy/LossBefore          -395.89
GaussianMLPPolicy/dLoss                  0.129517
GaussianMLPValueFunction/LossAfter   18434.5
GaussianMLPValueFunction/LossBefore  18449.2
GaussianMLPValueFunction/dLoss          14.6367
TotalEnvSteps                            1.1064e+06
-----------------------------------  ---------------
2022-08-17 18:01:00 | [trpo_pendulum] epoch #922 | Saving snapshot...
2022-08-17 18:01:00 | [trpo_pendulum] epoch #922 | Saved
2022-08-17 18:01:00 | [trpo_pendulum] epoch #922 | Time 380.35 s
2022-08-17 18:01:00 | [trpo_pendulum] epoch #922 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -445.589
Evaluation/AverageReturn             -1038.85
Evaluation/Iteration                   922
Evaluation/MaxReturn                  -900.144
Evaluation/MinReturn                 -1124.31
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    69.7158
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41846
GaussianMLPPolicy/KL                     0.000146914
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -378.896
GaussianMLPPolicy/LossBefore          -378.603
GaussianMLPPolicy/dLoss                  0.293091
GaussianMLPValueFunction/LossAfter   16301.5
GaussianMLPValueFunction/LossBefore  16314.4
GaussianMLPValueFunction/dLoss          12.8945
TotalEnvSteps                            1.1076e+06
-----------------------------------  ---------------
2022-08-17 18:01:00 | [trpo_pendulum] epoch #923 | Saving snapshot...
2022-08-17 18:01:00 | [trpo_pendulum] epoch #923 | Saved
2022-08-17 18:01:00 | [trpo_pendulum] epoch #923 | Time 380.76 s
2022-08-17 18:01:00 | [trpo_pendulum] epoch #923 | EpochTime 0.40 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -426.27
Evaluation/AverageReturn             -1016.45
Evaluation/Iteration                   923
Evaluation/MaxReturn                  -959.688
Evaluation/MinReturn                 -1051.47
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    31.7591
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41859
GaussianMLPPolicy/KL                     0.00010004
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -380.206
GaussianMLPPolicy/LossBefore          -380.125
GaussianMLPPolicy/dLoss                  0.0817871
GaussianMLPValueFunction/LossAfter   15776.5
GaussianMLPValueFunction/LossBefore  15788.9
GaussianMLPValueFunction/dLoss          12.3486
TotalEnvSteps                            1.1088e+06
-----------------------------------  --------------
2022-08-17 18:01:01 | [trpo_pendulum] epoch #924 | Saving snapshot...
2022-08-17 18:01:01 | [trpo_pendulum] epoch #924 | Saved
2022-08-17 18:01:01 | [trpo_pendulum] epoch #924 | Time 381.17 s
2022-08-17 18:01:01 | [trpo_pendulum] epoch #924 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -384.117
Evaluation/AverageReturn              -938.647
Evaluation/Iteration                   924
Evaluation/MaxReturn                  -896.439
Evaluation/MinReturn                 -1017.95
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    45.3671
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.4187
GaussianMLPPolicy/KL                     2.46311e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -352.125
GaussianMLPPolicy/LossBefore          -352.134
GaussianMLPPolicy/dLoss                 -0.00976562
GaussianMLPValueFunction/LossAfter   13784.7
GaussianMLPValueFunction/LossBefore  13795.3
GaussianMLPValueFunction/dLoss          10.6611
TotalEnvSteps                            1.11e+06
-----------------------------------  ---------------
2022-08-17 18:01:01 | [trpo_pendulum] epoch #925 | Saving snapshot...
2022-08-17 18:01:01 | [trpo_pendulum] epoch #925 | Saved
2022-08-17 18:01:01 | [trpo_pendulum] epoch #925 | Time 381.58 s
2022-08-17 18:01:01 | [trpo_pendulum] epoch #925 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -478.157
Evaluation/AverageReturn             -1073.09
Evaluation/Iteration                   925
Evaluation/MaxReturn                  -956.517
Evaluation/MinReturn                 -1156.77
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    64.1127
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41874
GaussianMLPPolicy/KL                     8.46745e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -384.513
GaussianMLPPolicy/LossBefore          -384.335
GaussianMLPPolicy/dLoss                  0.177368
GaussianMLPValueFunction/LossAfter   16467.7
GaussianMLPValueFunction/LossBefore  16480.1
GaussianMLPValueFunction/dLoss          12.4121
TotalEnvSteps                            1.1112e+06
-----------------------------------  ---------------
2022-08-17 18:01:02 | [trpo_pendulum] epoch #926 | Saving snapshot...
2022-08-17 18:01:02 | [trpo_pendulum] epoch #926 | Saved
2022-08-17 18:01:02 | [trpo_pendulum] epoch #926 | Time 381.98 s
2022-08-17 18:01:02 | [trpo_pendulum] epoch #926 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -607.037
Evaluation/AverageReturn             -1284.15
Evaluation/Iteration                   926
Evaluation/MaxReturn                 -1217.7
Evaluation/MinReturn                 -1395.53
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    69.5958
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41874
GaussianMLPPolicy/KL                     3.69807e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -442.439
GaussianMLPPolicy/LossBefore          -442.405
GaussianMLPPolicy/dLoss                  0.0344543
GaussianMLPValueFunction/LossAfter   22982
GaussianMLPValueFunction/LossBefore  22999.3
GaussianMLPValueFunction/dLoss          17.2852
TotalEnvSteps                            1.1124e+06
-----------------------------------  ---------------
2022-08-17 18:01:02 | [trpo_pendulum] epoch #927 | Saving snapshot...
2022-08-17 18:01:02 | [trpo_pendulum] epoch #927 | Saved
2022-08-17 18:01:02 | [trpo_pendulum] epoch #927 | Time 382.37 s
2022-08-17 18:01:02 | [trpo_pendulum] epoch #927 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -538.696
Evaluation/AverageReturn             -1156.88
Evaluation/Iteration                   927
Evaluation/MaxReturn                 -1078.71
Evaluation/MinReturn                 -1194.42
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    40.1678
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41881
GaussianMLPPolicy/KL                     1.98136e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -391.118
GaussianMLPPolicy/LossBefore          -391.127
GaussianMLPPolicy/dLoss                 -0.00939941
GaussianMLPValueFunction/LossAfter   18513.6
GaussianMLPValueFunction/LossBefore  18527.8
GaussianMLPValueFunction/dLoss          14.1523
TotalEnvSteps                            1.1136e+06
-----------------------------------  ---------------
2022-08-17 18:01:02 | [trpo_pendulum] epoch #928 | Saving snapshot...
2022-08-17 18:01:02 | [trpo_pendulum] epoch #928 | Saved
2022-08-17 18:01:02 | [trpo_pendulum] epoch #928 | Time 382.78 s
2022-08-17 18:01:02 | [trpo_pendulum] epoch #928 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -423.913
Evaluation/AverageReturn              -981.704
Evaluation/Iteration                   928
Evaluation/MaxReturn                  -882.185
Evaluation/MinReturn                 -1054.83
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    71.8031
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41878
GaussianMLPPolicy/KL                     1.58978e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -361.792
GaussianMLPPolicy/LossBefore          -361.706
GaussianMLPPolicy/dLoss                  0.0860596
GaussianMLPValueFunction/LossAfter   14214.3
GaussianMLPValueFunction/LossBefore  14225.2
GaussianMLPValueFunction/dLoss          10.918
TotalEnvSteps                            1.1148e+06
-----------------------------------  ---------------
2022-08-17 18:01:03 | [trpo_pendulum] epoch #929 | Saving snapshot...
2022-08-17 18:01:03 | [trpo_pendulum] epoch #929 | Saved
2022-08-17 18:01:03 | [trpo_pendulum] epoch #929 | Time 383.17 s
2022-08-17 18:01:03 | [trpo_pendulum] epoch #929 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -590.961
Evaluation/AverageReturn             -1271.35
Evaluation/Iteration                   929
Evaluation/MaxReturn                 -1094.49
Evaluation/MinReturn                 -1363.78
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    87.3123
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41888
GaussianMLPPolicy/KL                     2.74758e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -430.885
GaussianMLPPolicy/LossBefore          -430.703
GaussianMLPPolicy/dLoss                  0.181824
GaussianMLPValueFunction/LossAfter   22746.5
GaussianMLPValueFunction/LossBefore  22763.7
GaussianMLPValueFunction/dLoss          17.209
TotalEnvSteps                            1.116e+06
-----------------------------------  ---------------
2022-08-17 18:01:03 | [trpo_pendulum] epoch #930 | Saving snapshot...
2022-08-17 18:01:03 | [trpo_pendulum] epoch #930 | Saved
2022-08-17 18:01:03 | [trpo_pendulum] epoch #930 | Time 383.56 s
2022-08-17 18:01:03 | [trpo_pendulum] epoch #930 | EpochTime 0.38 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -501.945
Evaluation/AverageReturn             -1086.96
Evaluation/Iteration                   930
Evaluation/MaxReturn                 -1069.46
Evaluation/MinReturn                 -1104.33
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    12.5726
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41906
GaussianMLPPolicy/KL                     7.13891e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -366.505
GaussianMLPPolicy/LossBefore          -366.48
GaussianMLPPolicy/dLoss                  0.0256958
GaussianMLPValueFunction/LossAfter   15948.5
GaussianMLPValueFunction/LossBefore  15960.7
GaussianMLPValueFunction/dLoss          12.2451
TotalEnvSteps                            1.1172e+06
-----------------------------------  ---------------
2022-08-17 18:01:04 | [trpo_pendulum] epoch #931 | Saving snapshot...
2022-08-17 18:01:04 | [trpo_pendulum] epoch #931 | Saved
2022-08-17 18:01:04 | [trpo_pendulum] epoch #931 | Time 383.96 s
2022-08-17 18:01:04 | [trpo_pendulum] epoch #931 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -429.505
Evaluation/AverageReturn             -1000.88
Evaluation/Iteration                   931
Evaluation/MaxReturn                  -758.362
Evaluation/MinReturn                 -1086.98
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   109.986
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41929
GaussianMLPPolicy/KL                     7.38505e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -358.038
GaussianMLPPolicy/LossBefore          -357.773
GaussianMLPPolicy/dLoss                  0.26532
GaussianMLPValueFunction/LossAfter   15206.4
GaussianMLPValueFunction/LossBefore  15218
GaussianMLPValueFunction/dLoss          11.5967
TotalEnvSteps                            1.1184e+06
-----------------------------------  ---------------
2022-08-17 18:01:04 | [trpo_pendulum] epoch #932 | Saving snapshot...
2022-08-17 18:01:04 | [trpo_pendulum] epoch #932 | Saved
2022-08-17 18:01:04 | [trpo_pendulum] epoch #932 | Time 384.36 s
2022-08-17 18:01:04 | [trpo_pendulum] epoch #932 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -629.926
Evaluation/AverageReturn             -1345.94
Evaluation/Iteration                   932
Evaluation/MaxReturn                 -1248.15
Evaluation/MinReturn                 -1451.9
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    61.5295
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41954
GaussianMLPPolicy/KL                     5.69843e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -463.654
GaussianMLPPolicy/LossBefore          -463.586
GaussianMLPPolicy/dLoss                  0.0682068
GaussianMLPValueFunction/LossAfter   25206.8
GaussianMLPValueFunction/LossBefore  25225.9
GaussianMLPValueFunction/dLoss          19.1504
TotalEnvSteps                            1.1196e+06
-----------------------------------  ---------------
2022-08-17 18:01:04 | [trpo_pendulum] epoch #933 | Saving snapshot...
2022-08-17 18:01:04 | [trpo_pendulum] epoch #933 | Saved
2022-08-17 18:01:04 | [trpo_pendulum] epoch #933 | Time 384.76 s
2022-08-17 18:01:04 | [trpo_pendulum] epoch #933 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -396.2
Evaluation/AverageReturn              -936.677
Evaluation/Iteration                   933
Evaluation/MaxReturn                  -856.991
Evaluation/MinReturn                 -1038.54
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    62.5491
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.41979
GaussianMLPPolicy/KL                     0.000125752
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -339.309
GaussianMLPPolicy/LossBefore          -339.187
GaussianMLPPolicy/dLoss                  0.121979
GaussianMLPValueFunction/LossAfter   13037.8
GaussianMLPValueFunction/LossBefore  13047.9
GaussianMLPValueFunction/dLoss          10.1475
TotalEnvSteps                            1.1208e+06
-----------------------------------  ---------------
2022-08-17 18:01:05 | [trpo_pendulum] epoch #934 | Saving snapshot...
2022-08-17 18:01:05 | [trpo_pendulum] epoch #934 | Saved
2022-08-17 18:01:05 | [trpo_pendulum] epoch #934 | Time 385.17 s
2022-08-17 18:01:05 | [trpo_pendulum] epoch #934 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -463.785
Evaluation/AverageReturn             -1044.08
Evaluation/Iteration                   934
Evaluation/MaxReturn                  -973.605
Evaluation/MinReturn                 -1118.01
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    57.1388
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42012
GaussianMLPPolicy/KL                     4.86851e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -361.492
GaussianMLPPolicy/LossBefore          -361.499
GaussianMLPPolicy/dLoss                 -0.00671387
GaussianMLPValueFunction/LossAfter   15274.7
GaussianMLPValueFunction/LossBefore  15286.2
GaussianMLPValueFunction/dLoss          11.5713
TotalEnvSteps                            1.122e+06
-----------------------------------  ---------------
2022-08-17 18:01:05 | [trpo_pendulum] epoch #935 | Saving snapshot...
2022-08-17 18:01:05 | [trpo_pendulum] epoch #935 | Saved
2022-08-17 18:01:05 | [trpo_pendulum] epoch #935 | Time 385.56 s
2022-08-17 18:01:05 | [trpo_pendulum] epoch #935 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -457.446
Evaluation/AverageReturn             -1026.56
Evaluation/Iteration                   935
Evaluation/MaxReturn                  -958.969
Evaluation/MinReturn                 -1071.81
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    46.3913
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42049
GaussianMLPPolicy/KL                     5.06646e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -356.348
GaussianMLPPolicy/LossBefore          -356.375
GaussianMLPPolicy/dLoss                 -0.0267029
GaussianMLPValueFunction/LossAfter   14556.9
GaussianMLPValueFunction/LossBefore  14567.8
GaussianMLPValueFunction/dLoss          10.8965
TotalEnvSteps                            1.1232e+06
-----------------------------------  ---------------
2022-08-17 18:01:06 | [trpo_pendulum] epoch #936 | Saving snapshot...
2022-08-17 18:01:06 | [trpo_pendulum] epoch #936 | Saved
2022-08-17 18:01:06 | [trpo_pendulum] epoch #936 | Time 385.96 s
2022-08-17 18:01:06 | [trpo_pendulum] epoch #936 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -333.247
Evaluation/AverageReturn              -845.642
Evaluation/Iteration                   936
Evaluation/MaxReturn                  -754.842
Evaluation/MinReturn                  -931.502
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    73.3894
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42076
GaussianMLPPolicy/KL                     4.41517e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -326.054
GaussianMLPPolicy/LossBefore          -326.048
GaussianMLPPolicy/dLoss                  0.00585938
GaussianMLPValueFunction/LossAfter   11824.3
GaussianMLPValueFunction/LossBefore  11833
GaussianMLPValueFunction/dLoss           8.73633
TotalEnvSteps                            1.1244e+06
-----------------------------------  ---------------
2022-08-17 18:01:06 | [trpo_pendulum] epoch #937 | Saving snapshot...
2022-08-17 18:01:06 | [trpo_pendulum] epoch #937 | Saved
2022-08-17 18:01:06 | [trpo_pendulum] epoch #937 | Time 386.36 s
2022-08-17 18:01:06 | [trpo_pendulum] epoch #937 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -587.982
Evaluation/AverageReturn             -1255.55
Evaluation/Iteration                   937
Evaluation/MaxReturn                 -1120.71
Evaluation/MinReturn                 -1333.87
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    91.2742
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42104
GaussianMLPPolicy/KL                     3.14239e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -429.459
GaussianMLPPolicy/LossBefore          -429.452
GaussianMLPPolicy/dLoss                  0.00726318
GaussianMLPValueFunction/LossAfter   21995.7
GaussianMLPValueFunction/LossBefore  22011.5
GaussianMLPValueFunction/dLoss          15.8457
TotalEnvSteps                            1.1256e+06
-----------------------------------  ---------------
2022-08-17 18:01:06 | [trpo_pendulum] epoch #938 | Saving snapshot...
2022-08-17 18:01:06 | [trpo_pendulum] epoch #938 | Saved
2022-08-17 18:01:06 | [trpo_pendulum] epoch #938 | Time 386.76 s
2022-08-17 18:01:06 | [trpo_pendulum] epoch #938 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -422.941
Evaluation/AverageReturn              -975.785
Evaluation/Iteration                   938
Evaluation/MaxReturn                  -881.96
Evaluation/MinReturn                 -1092.96
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    71.7209
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42127
GaussianMLPPolicy/KL                     6.23233e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -352.315
GaussianMLPPolicy/LossBefore          -352.279
GaussianMLPPolicy/dLoss                  0.0362854
GaussianMLPValueFunction/LossAfter   13827.6
GaussianMLPValueFunction/LossBefore  13837.8
GaussianMLPValueFunction/dLoss          10.1953
TotalEnvSteps                            1.1268e+06
-----------------------------------  ---------------
2022-08-17 18:01:07 | [trpo_pendulum] epoch #939 | Saving snapshot...
2022-08-17 18:01:07 | [trpo_pendulum] epoch #939 | Saved
2022-08-17 18:01:07 | [trpo_pendulum] epoch #939 | Time 387.16 s
2022-08-17 18:01:07 | [trpo_pendulum] epoch #939 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -596.245
Evaluation/AverageReturn             -1296.27
Evaluation/Iteration                   939
Evaluation/MaxReturn                 -1213.72
Evaluation/MinReturn                 -1331.6
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    38.4573
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.4216
GaussianMLPPolicy/KL                     2.65258e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -446.126
GaussianMLPPolicy/LossBefore          -446.014
GaussianMLPPolicy/dLoss                  0.111969
GaussianMLPValueFunction/LossAfter   23581.5
GaussianMLPValueFunction/LossBefore  23598.8
GaussianMLPValueFunction/dLoss          17.2266
TotalEnvSteps                            1.128e+06
-----------------------------------  ---------------
2022-08-17 18:01:07 | [trpo_pendulum] epoch #940 | Saving snapshot...
2022-08-17 18:01:07 | [trpo_pendulum] epoch #940 | Saved
2022-08-17 18:01:07 | [trpo_pendulum] epoch #940 | Time 387.55 s
2022-08-17 18:01:07 | [trpo_pendulum] epoch #940 | EpochTime 0.38 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -414.474
Evaluation/AverageReturn              -959.554
Evaluation/Iteration                   940
Evaluation/MaxReturn                  -877.711
Evaluation/MinReturn                 -1111.74
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    81.7365
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42199
GaussianMLPPolicy/KL                     2.95686e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -337.603
GaussianMLPPolicy/LossBefore          -337.534
GaussianMLPPolicy/dLoss                  0.0691833
GaussianMLPValueFunction/LossAfter   13250.9
GaussianMLPValueFunction/LossBefore  13260.9
GaussianMLPValueFunction/dLoss           9.93066
TotalEnvSteps                            1.1292e+06
-----------------------------------  ---------------
2022-08-17 18:01:08 | [trpo_pendulum] epoch #941 | Saving snapshot...
2022-08-17 18:01:08 | [trpo_pendulum] epoch #941 | Saved
2022-08-17 18:01:08 | [trpo_pendulum] epoch #941 | Time 387.95 s
2022-08-17 18:01:08 | [trpo_pendulum] epoch #941 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -471.804
Evaluation/AverageReturn             -1001.68
Evaluation/Iteration                   941
Evaluation/MaxReturn                  -850.533
Evaluation/MinReturn                 -1096.74
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    96.338
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42236
GaussianMLPPolicy/KL                     5.08064e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -333.449
GaussianMLPPolicy/LossBefore          -333.455
GaussianMLPPolicy/dLoss                 -0.0062561
GaussianMLPValueFunction/LossAfter   13291.2
GaussianMLPValueFunction/LossBefore  13300.9
GaussianMLPValueFunction/dLoss           9.66406
TotalEnvSteps                            1.1304e+06
-----------------------------------  ---------------
2022-08-17 18:01:08 | [trpo_pendulum] epoch #942 | Saving snapshot...
2022-08-17 18:01:08 | [trpo_pendulum] epoch #942 | Saved
2022-08-17 18:01:08 | [trpo_pendulum] epoch #942 | Time 388.35 s
2022-08-17 18:01:08 | [trpo_pendulum] epoch #942 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -446.242
Evaluation/AverageReturn             -1012.87
Evaluation/Iteration                   942
Evaluation/MaxReturn                  -972.018
Evaluation/MinReturn                 -1060.25
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    29.751
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42266
GaussianMLPPolicy/KL                     7.29014e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -362.451
GaussianMLPPolicy/LossBefore          -362.228
GaussianMLPPolicy/dLoss                  0.222504
GaussianMLPValueFunction/LossAfter   14256.2
GaussianMLPValueFunction/LossBefore  14266.4
GaussianMLPValueFunction/dLoss          10.2412
TotalEnvSteps                            1.1316e+06
-----------------------------------  ---------------
2022-08-17 18:01:08 | [trpo_pendulum] epoch #943 | Saving snapshot...
2022-08-17 18:01:08 | [trpo_pendulum] epoch #943 | Saved
2022-08-17 18:01:08 | [trpo_pendulum] epoch #943 | Time 388.74 s
2022-08-17 18:01:08 | [trpo_pendulum] epoch #943 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -410.723
Evaluation/AverageReturn              -989.209
Evaluation/Iteration                   943
Evaluation/MaxReturn                  -897.086
Evaluation/MinReturn                 -1024.17
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    44.8813
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42297
GaussianMLPPolicy/KL                     7.16532e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -366.072
GaussianMLPPolicy/LossBefore          -366.045
GaussianMLPPolicy/dLoss                  0.026947
GaussianMLPValueFunction/LossAfter   14467.2
GaussianMLPValueFunction/LossBefore  14477.5
GaussianMLPValueFunction/dLoss          10.3105
TotalEnvSteps                            1.1328e+06
-----------------------------------  ---------------
2022-08-17 18:01:09 | [trpo_pendulum] epoch #944 | Saving snapshot...
2022-08-17 18:01:09 | [trpo_pendulum] epoch #944 | Saved
2022-08-17 18:01:09 | [trpo_pendulum] epoch #944 | Time 389.13 s
2022-08-17 18:01:09 | [trpo_pendulum] epoch #944 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -427.554
Evaluation/AverageReturn             -1024.72
Evaluation/Iteration                   944
Evaluation/MaxReturn                  -934.868
Evaluation/MinReturn                 -1157.19
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    73.456
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42329
GaussianMLPPolicy/KL                     1.45282e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -379.303
GaussianMLPPolicy/LossBefore          -379.204
GaussianMLPPolicy/dLoss                  0.0993958
GaussianMLPValueFunction/LossAfter   16168.8
GaussianMLPValueFunction/LossBefore  16180.2
GaussianMLPValueFunction/dLoss          11.4219
TotalEnvSteps                            1.134e+06
-----------------------------------  ---------------
2022-08-17 18:01:09 | [trpo_pendulum] epoch #945 | Saving snapshot...
2022-08-17 18:01:09 | [trpo_pendulum] epoch #945 | Saved
2022-08-17 18:01:09 | [trpo_pendulum] epoch #945 | Time 389.54 s
2022-08-17 18:01:09 | [trpo_pendulum] epoch #945 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -622.284
Evaluation/AverageReturn             -1327.77
Evaluation/Iteration                   945
Evaluation/MaxReturn                 -1302.54
Evaluation/MinReturn                 -1382.88
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    27.0554
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42357
GaussianMLPPolicy/KL                     3.03375e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -460.831
GaussianMLPPolicy/LossBefore          -460.815
GaussianMLPPolicy/dLoss                  0.0160828
GaussianMLPValueFunction/LossAfter   24048
GaussianMLPValueFunction/LossBefore  24065.1
GaussianMLPValueFunction/dLoss          17.0742
TotalEnvSteps                            1.1352e+06
-----------------------------------  ---------------
2022-08-17 18:01:10 | [trpo_pendulum] epoch #946 | Saving snapshot...
2022-08-17 18:01:10 | [trpo_pendulum] epoch #946 | Saved
2022-08-17 18:01:10 | [trpo_pendulum] epoch #946 | Time 389.94 s
2022-08-17 18:01:10 | [trpo_pendulum] epoch #946 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -593.345
Evaluation/AverageReturn             -1268.33
Evaluation/Iteration                   946
Evaluation/MaxReturn                 -1154.07
Evaluation/MinReturn                 -1412.62
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    83.9883
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42384
GaussianMLPPolicy/KL                     4.58459e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -436.944
GaussianMLPPolicy/LossBefore          -436.936
GaussianMLPPolicy/dLoss                  0.00817871
GaussianMLPValueFunction/LossAfter   22052
GaussianMLPValueFunction/LossBefore  22068.2
GaussianMLPValueFunction/dLoss          16.1621
TotalEnvSteps                            1.1364e+06
-----------------------------------  ---------------
2022-08-17 18:01:10 | [trpo_pendulum] epoch #947 | Saving snapshot...
2022-08-17 18:01:10 | [trpo_pendulum] epoch #947 | Saved
2022-08-17 18:01:10 | [trpo_pendulum] epoch #947 | Time 390.35 s
2022-08-17 18:01:10 | [trpo_pendulum] epoch #947 | EpochTime 0.40 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -462.537
Evaluation/AverageReturn             -1031.94
Evaluation/Iteration                   947
Evaluation/MaxReturn                  -992.854
Evaluation/MinReturn                 -1096.95
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    44.3657
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42392
GaussianMLPPolicy/KL                     2.3785e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -375.767
GaussianMLPPolicy/LossBefore          -375.717
GaussianMLPPolicy/dLoss                  0.0493469
GaussianMLPValueFunction/LossAfter   14631.9
GaussianMLPValueFunction/LossBefore  14642.9
GaussianMLPValueFunction/dLoss          10.9219
TotalEnvSteps                            1.1376e+06
-----------------------------------  --------------
2022-08-17 18:01:10 | [trpo_pendulum] epoch #948 | Saving snapshot...
2022-08-17 18:01:10 | [trpo_pendulum] epoch #948 | Saved
2022-08-17 18:01:10 | [trpo_pendulum] epoch #948 | Time 390.75 s
2022-08-17 18:01:10 | [trpo_pendulum] epoch #948 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -594.848
Evaluation/AverageReturn             -1268.27
Evaluation/Iteration                   948
Evaluation/MaxReturn                 -1191.73
Evaluation/MinReturn                 -1348.02
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    62.1166
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42386
GaussianMLPPolicy/KL                     1.29623e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -448.354
GaussianMLPPolicy/LossBefore          -448.32
GaussianMLPPolicy/dLoss                  0.0341797
GaussianMLPValueFunction/LossAfter   22086.7
GaussianMLPValueFunction/LossBefore  22103.1
GaussianMLPValueFunction/dLoss          16.3438
TotalEnvSteps                            1.1388e+06
-----------------------------------  ---------------
2022-08-17 18:01:11 | [trpo_pendulum] epoch #949 | Saving snapshot...
2022-08-17 18:01:11 | [trpo_pendulum] epoch #949 | Saved
2022-08-17 18:01:11 | [trpo_pendulum] epoch #949 | Time 391.15 s
2022-08-17 18:01:11 | [trpo_pendulum] epoch #949 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -506.995
Evaluation/AverageReturn             -1120.43
Evaluation/Iteration                   949
Evaluation/MaxReturn                 -1073.35
Evaluation/MinReturn                 -1200.52
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    44.6113
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42369
GaussianMLPPolicy/KL                     8.45391e-07
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -403.017
GaussianMLPPolicy/LossBefore          -403.018
GaussianMLPPolicy/dLoss                 -0.000701904
GaussianMLPValueFunction/LossAfter   17142.9
GaussianMLPValueFunction/LossBefore  17155.9
GaussianMLPValueFunction/dLoss          12.9238
TotalEnvSteps                            1.14e+06
-----------------------------------  ---------------
2022-08-17 18:01:11 | [trpo_pendulum] epoch #950 | Saving snapshot...
2022-08-17 18:01:11 | [trpo_pendulum] epoch #950 | Saved
2022-08-17 18:01:11 | [trpo_pendulum] epoch #950 | Time 391.55 s
2022-08-17 18:01:11 | [trpo_pendulum] epoch #950 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -452.35
Evaluation/AverageReturn             -1031.92
Evaluation/Iteration                   950
Evaluation/MaxReturn                  -897.333
Evaluation/MinReturn                 -1129.1
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    87.2045
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42359
GaussianMLPPolicy/KL                     6.22591e-06
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -366.143
GaussianMLPPolicy/LossBefore          -366.122
GaussianMLPPolicy/dLoss                  0.0210571
GaussianMLPValueFunction/LossAfter   14856.8
GaussianMLPValueFunction/LossBefore  14868
GaussianMLPValueFunction/dLoss          11.1982
TotalEnvSteps                            1.1412e+06
-----------------------------------  ---------------
2022-08-17 18:01:12 | [trpo_pendulum] epoch #951 | Saving snapshot...
2022-08-17 18:01:12 | [trpo_pendulum] epoch #951 | Saved
2022-08-17 18:01:12 | [trpo_pendulum] epoch #951 | Time 391.96 s
2022-08-17 18:01:12 | [trpo_pendulum] epoch #951 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -424.745
Evaluation/AverageReturn              -990.745
Evaluation/Iteration                   951
Evaluation/MaxReturn                  -891.19
Evaluation/MinReturn                 -1082.6
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    64.9506
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42343
GaussianMLPPolicy/KL                     5.40615e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -365.011
GaussianMLPPolicy/LossBefore          -364.894
GaussianMLPPolicy/dLoss                  0.116821
GaussianMLPValueFunction/LossAfter   14166.3
GaussianMLPValueFunction/LossBefore  14176.9
GaussianMLPValueFunction/dLoss          10.5498
TotalEnvSteps                            1.1424e+06
-----------------------------------  ---------------
2022-08-17 18:01:12 | [trpo_pendulum] epoch #952 | Saving snapshot...
2022-08-17 18:01:12 | [trpo_pendulum] epoch #952 | Saved
2022-08-17 18:01:12 | [trpo_pendulum] epoch #952 | Time 392.38 s
2022-08-17 18:01:12 | [trpo_pendulum] epoch #952 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -529.247
Evaluation/AverageReturn             -1165.04
Evaluation/Iteration                   952
Evaluation/MaxReturn                 -1078.49
Evaluation/MinReturn                 -1273.53
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    78.6554
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42331
GaussianMLPPolicy/KL                     3.64218e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -408.651
GaussianMLPPolicy/LossBefore          -408.63
GaussianMLPPolicy/dLoss                  0.0207825
GaussianMLPValueFunction/LossAfter   18763.7
GaussianMLPValueFunction/LossBefore  18777.4
GaussianMLPValueFunction/dLoss          13.7422
TotalEnvSteps                            1.1436e+06
-----------------------------------  ---------------
2022-08-17 18:01:12 | [trpo_pendulum] epoch #953 | Saving snapshot...
2022-08-17 18:01:12 | [trpo_pendulum] epoch #953 | Saved
2022-08-17 18:01:12 | [trpo_pendulum] epoch #953 | Time 392.79 s
2022-08-17 18:01:12 | [trpo_pendulum] epoch #953 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -693.573
Evaluation/AverageReturn             -1481.46
Evaluation/Iteration                   953
Evaluation/MaxReturn                 -1391.67
Evaluation/MinReturn                 -1638.27
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    89.4247
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42335
GaussianMLPPolicy/KL                     2.89887e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -508.371
GaussianMLPPolicy/LossBefore          -508.298
GaussianMLPPolicy/dLoss                  0.0733032
GaussianMLPValueFunction/LossAfter   30929.4
GaussianMLPValueFunction/LossBefore  30952.9
GaussianMLPValueFunction/dLoss          23.5059
TotalEnvSteps                            1.1448e+06
-----------------------------------  ---------------
2022-08-17 18:01:13 | [trpo_pendulum] epoch #954 | Saving snapshot...
2022-08-17 18:01:13 | [trpo_pendulum] epoch #954 | Saved
2022-08-17 18:01:13 | [trpo_pendulum] epoch #954 | Time 393.20 s
2022-08-17 18:01:13 | [trpo_pendulum] epoch #954 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -454.914
Evaluation/AverageReturn             -1005.7
Evaluation/Iteration                   954
Evaluation/MaxReturn                  -989.478
Evaluation/MinReturn                 -1060.04
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    25.0523
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42341
GaussianMLPPolicy/KL                     7.50231e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -346.154
GaussianMLPPolicy/LossBefore          -346.077
GaussianMLPPolicy/dLoss                  0.0772705
GaussianMLPValueFunction/LossAfter   13790.7
GaussianMLPValueFunction/LossBefore  13801.5
GaussianMLPValueFunction/dLoss          10.8145
TotalEnvSteps                            1.146e+06
-----------------------------------  ---------------
2022-08-17 18:01:13 | [trpo_pendulum] epoch #955 | Saving snapshot...
2022-08-17 18:01:13 | [trpo_pendulum] epoch #955 | Saved
2022-08-17 18:01:13 | [trpo_pendulum] epoch #955 | Time 393.60 s
2022-08-17 18:01:13 | [trpo_pendulum] epoch #955 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -408.749
Evaluation/AverageReturn              -947.175
Evaluation/Iteration                   955
Evaluation/MaxReturn                  -884.528
Evaluation/MinReturn                 -1025.17
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    55.5394
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42352
GaussianMLPPolicy/KL                     7.94063e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -336.41
GaussianMLPPolicy/LossBefore          -336.356
GaussianMLPPolicy/dLoss                  0.0539856
GaussianMLPValueFunction/LossAfter   12687.2
GaussianMLPValueFunction/LossBefore  12697
GaussianMLPValueFunction/dLoss           9.7793
TotalEnvSteps                            1.1472e+06
-----------------------------------  ---------------
2022-08-17 18:01:14 | [trpo_pendulum] epoch #956 | Saving snapshot...
2022-08-17 18:01:14 | [trpo_pendulum] epoch #956 | Saved
2022-08-17 18:01:14 | [trpo_pendulum] epoch #956 | Time 394.01 s
2022-08-17 18:01:14 | [trpo_pendulum] epoch #956 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -432.714
Evaluation/AverageReturn             -1020.48
Evaluation/Iteration                   956
Evaluation/MaxReturn                  -991.228
Evaluation/MinReturn                 -1037.7
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    18.13
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42365
GaussianMLPPolicy/KL                     0.000339584
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -373.738
GaussianMLPPolicy/LossBefore          -373.179
GaussianMLPPolicy/dLoss                  0.558624
GaussianMLPValueFunction/LossAfter   15261.1
GaussianMLPValueFunction/LossBefore  15272.6
GaussianMLPValueFunction/dLoss          11.4805
TotalEnvSteps                            1.1484e+06
-----------------------------------  ---------------
2022-08-17 18:01:14 | [trpo_pendulum] epoch #957 | Saving snapshot...
2022-08-17 18:01:14 | [trpo_pendulum] epoch #957 | Saved
2022-08-17 18:01:14 | [trpo_pendulum] epoch #957 | Time 394.42 s
2022-08-17 18:01:14 | [trpo_pendulum] epoch #957 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -349.609
Evaluation/AverageReturn              -847.023
Evaluation/Iteration                   957
Evaluation/MaxReturn                  -760.321
Evaluation/MinReturn                  -894.596
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    58.473
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42372
GaussianMLPPolicy/KL                     0.000274388
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -313.635
GaussianMLPPolicy/LossBefore          -313.516
GaussianMLPPolicy/dLoss                  0.119141
GaussianMLPValueFunction/LossAfter   10501.5
GaussianMLPValueFunction/LossBefore  10509.4
GaussianMLPValueFunction/dLoss           7.87598
TotalEnvSteps                            1.1496e+06
-----------------------------------  ---------------
2022-08-17 18:01:14 | [trpo_pendulum] epoch #958 | Saving snapshot...
2022-08-17 18:01:14 | [trpo_pendulum] epoch #958 | Saved
2022-08-17 18:01:14 | [trpo_pendulum] epoch #958 | Time 394.81 s
2022-08-17 18:01:14 | [trpo_pendulum] epoch #958 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -582.416
Evaluation/AverageReturn             -1262.97
Evaluation/Iteration                   958
Evaluation/MaxReturn                 -1109.48
Evaluation/MinReturn                 -1341.19
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    78.4936
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42398
GaussianMLPPolicy/KL                     0.000245502
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -427.232
GaussianMLPPolicy/LossBefore          -427.051
GaussianMLPPolicy/dLoss                  0.180389
GaussianMLPValueFunction/LossAfter   22289.9
GaussianMLPValueFunction/LossBefore  22306
GaussianMLPValueFunction/dLoss          16.1055
TotalEnvSteps                            1.1508e+06
-----------------------------------  ---------------
2022-08-17 18:01:15 | [trpo_pendulum] epoch #959 | Saving snapshot...
2022-08-17 18:01:15 | [trpo_pendulum] epoch #959 | Saved
2022-08-17 18:01:15 | [trpo_pendulum] epoch #959 | Time 395.22 s
2022-08-17 18:01:15 | [trpo_pendulum] epoch #959 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -530.203
Evaluation/AverageReturn             -1156.27
Evaluation/Iteration                   959
Evaluation/MaxReturn                 -1068.34
Evaluation/MinReturn                 -1301.85
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    86.3639
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42428
GaussianMLPPolicy/KL                     0.000231975
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -397.966
GaussianMLPPolicy/LossBefore          -397.823
GaussianMLPPolicy/dLoss                  0.143219
GaussianMLPValueFunction/LossAfter   18744.6
GaussianMLPValueFunction/LossBefore  18758.4
GaussianMLPValueFunction/dLoss          13.8125
TotalEnvSteps                            1.152e+06
-----------------------------------  ---------------
2022-08-17 18:01:15 | [trpo_pendulum] epoch #960 | Saving snapshot...
2022-08-17 18:01:15 | [trpo_pendulum] epoch #960 | Saved
2022-08-17 18:01:15 | [trpo_pendulum] epoch #960 | Time 395.62 s
2022-08-17 18:01:15 | [trpo_pendulum] epoch #960 | EpochTime 0.39 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -680.647
Evaluation/AverageReturn             -1466.26
Evaluation/Iteration                   960
Evaluation/MaxReturn                 -1355
Evaluation/MinReturn                 -1655.72
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    93.4752
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42462
GaussianMLPPolicy/KL                     0.00029881
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -513.467
GaussianMLPPolicy/LossBefore          -512.872
GaussianMLPPolicy/dLoss                  0.594788
GaussianMLPValueFunction/LossAfter   30084.9
GaussianMLPValueFunction/LossBefore  30108
GaussianMLPValueFunction/dLoss          23.0273
TotalEnvSteps                            1.1532e+06
-----------------------------------  --------------
2022-08-17 18:01:16 | [trpo_pendulum] epoch #961 | Saving snapshot...
2022-08-17 18:01:16 | [trpo_pendulum] epoch #961 | Saved
2022-08-17 18:01:16 | [trpo_pendulum] epoch #961 | Time 396.02 s
2022-08-17 18:01:16 | [trpo_pendulum] epoch #961 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -414.735
Evaluation/AverageReturn              -951.044
Evaluation/Iteration                   961
Evaluation/MaxReturn                  -839.378
Evaluation/MinReturn                 -1081.51
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    95.8503
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42484
GaussianMLPPolicy/KL                     0.000415416
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -345.486
GaussianMLPPolicy/LossBefore          -345.329
GaussianMLPPolicy/dLoss                  0.156952
GaussianMLPValueFunction/LossAfter   12714.1
GaussianMLPValueFunction/LossBefore  12724.1
GaussianMLPValueFunction/dLoss          10.0381
TotalEnvSteps                            1.1544e+06
-----------------------------------  ---------------
2022-08-17 18:01:16 | [trpo_pendulum] epoch #962 | Saving snapshot...
2022-08-17 18:01:16 | [trpo_pendulum] epoch #962 | Saved
2022-08-17 18:01:16 | [trpo_pendulum] epoch #962 | Time 396.41 s
2022-08-17 18:01:16 | [trpo_pendulum] epoch #962 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -568.086
Evaluation/AverageReturn             -1263.86
Evaluation/Iteration                   962
Evaluation/MaxReturn                 -1078.47
Evaluation/MinReturn                 -1307.93
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    83.3672
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42504
GaussianMLPPolicy/KL                     0.000383744
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -452.787
GaussianMLPPolicy/LossBefore          -452.552
GaussianMLPPolicy/dLoss                  0.235168
GaussianMLPValueFunction/LossAfter   22805.3
GaussianMLPValueFunction/LossBefore  22822.9
GaussianMLPValueFunction/dLoss          17.6641
TotalEnvSteps                            1.1556e+06
-----------------------------------  ---------------
2022-08-17 18:01:16 | [trpo_pendulum] epoch #963 | Saving snapshot...
2022-08-17 18:01:16 | [trpo_pendulum] epoch #963 | Saved
2022-08-17 18:01:16 | [trpo_pendulum] epoch #963 | Time 396.82 s
2022-08-17 18:01:16 | [trpo_pendulum] epoch #963 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -448.246
Evaluation/AverageReturn             -1014.39
Evaluation/Iteration                   963
Evaluation/MaxReturn                  -851.167
Evaluation/MinReturn                 -1156.65
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    96.9757
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42522
GaussianMLPPolicy/KL                     0.000365922
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -360.881
GaussianMLPPolicy/LossBefore          -360.727
GaussianMLPPolicy/dLoss                  0.154144
GaussianMLPValueFunction/LossAfter   14327.1
GaussianMLPValueFunction/LossBefore  14338.3
GaussianMLPValueFunction/dLoss          11.2412
TotalEnvSteps                            1.1568e+06
-----------------------------------  ---------------
2022-08-17 18:01:17 | [trpo_pendulum] epoch #964 | Saving snapshot...
2022-08-17 18:01:17 | [trpo_pendulum] epoch #964 | Saved
2022-08-17 18:01:17 | [trpo_pendulum] epoch #964 | Time 397.21 s
2022-08-17 18:01:17 | [trpo_pendulum] epoch #964 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -481.62
Evaluation/AverageReturn             -1095
Evaluation/Iteration                   964
Evaluation/MaxReturn                  -870.655
Evaluation/MinReturn                 -1233.9
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   131.118
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42539
GaussianMLPPolicy/KL                     0.000282547
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -393.732
GaussianMLPPolicy/LossBefore          -393.676
GaussianMLPPolicy/dLoss                  0.0562439
GaussianMLPValueFunction/LossAfter   17156.8
GaussianMLPValueFunction/LossBefore  17170
GaussianMLPValueFunction/dLoss          13.2207
TotalEnvSteps                            1.158e+06
-----------------------------------  ---------------
2022-08-17 18:01:17 | [trpo_pendulum] epoch #965 | Saving snapshot...
2022-08-17 18:01:17 | [trpo_pendulum] epoch #965 | Saved
2022-08-17 18:01:17 | [trpo_pendulum] epoch #965 | Time 397.62 s
2022-08-17 18:01:17 | [trpo_pendulum] epoch #965 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -528.744
Evaluation/AverageReturn             -1215.81
Evaluation/Iteration                   965
Evaluation/MaxReturn                 -1061.45
Evaluation/MinReturn                 -1278.62
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    78.2417
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42566
GaussianMLPPolicy/KL                     0.000257879
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -436.818
GaussianMLPPolicy/LossBefore          -436.67
GaussianMLPPolicy/dLoss                  0.147156
GaussianMLPValueFunction/LossAfter   21359.7
GaussianMLPValueFunction/LossBefore  21376.3
GaussianMLPValueFunction/dLoss          16.543
TotalEnvSteps                            1.1592e+06
-----------------------------------  ---------------
2022-08-17 18:01:18 | [trpo_pendulum] epoch #966 | Saving snapshot...
2022-08-17 18:01:18 | [trpo_pendulum] epoch #966 | Saved
2022-08-17 18:01:18 | [trpo_pendulum] epoch #966 | Time 398.02 s
2022-08-17 18:01:18 | [trpo_pendulum] epoch #966 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -710.173
Evaluation/AverageReturn             -1580.91
Evaluation/Iteration                   966
Evaluation/MaxReturn                 -1449.25
Evaluation/MinReturn                 -1661.33
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    74.6615
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42606
GaussianMLPPolicy/KL                     0.000132501
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -567.443
GaussianMLPPolicy/LossBefore          -567.313
GaussianMLPPolicy/dLoss                  0.130066
GaussianMLPValueFunction/LossAfter   36457
GaussianMLPValueFunction/LossBefore  36486.9
GaussianMLPValueFunction/dLoss          29.8672
TotalEnvSteps                            1.1604e+06
-----------------------------------  ---------------
2022-08-17 18:01:18 | [trpo_pendulum] epoch #967 | Saving snapshot...
2022-08-17 18:01:18 | [trpo_pendulum] epoch #967 | Saved
2022-08-17 18:01:18 | [trpo_pendulum] epoch #967 | Time 398.42 s
2022-08-17 18:01:18 | [trpo_pendulum] epoch #967 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -557.781
Evaluation/AverageReturn             -1282.97
Evaluation/Iteration                   967
Evaluation/MaxReturn                 -1214.9
Evaluation/MinReturn                 -1350.5
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    42.0147
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42638
GaussianMLPPolicy/KL                     0.000250693
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -477.752
GaussianMLPPolicy/LossBefore          -477.586
GaussianMLPPolicy/dLoss                  0.166504
GaussianMLPValueFunction/LossAfter   23933.3
GaussianMLPValueFunction/LossBefore  23953.8
GaussianMLPValueFunction/dLoss          20.4609
TotalEnvSteps                            1.1616e+06
-----------------------------------  ---------------
2022-08-17 18:01:18 | [trpo_pendulum] epoch #968 | Saving snapshot...
2022-08-17 18:01:18 | [trpo_pendulum] epoch #968 | Saved
2022-08-17 18:01:18 | [trpo_pendulum] epoch #968 | Time 398.81 s
2022-08-17 18:01:18 | [trpo_pendulum] epoch #968 | EpochTime 0.38 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -520.618
Evaluation/AverageReturn             -1228.54
Evaluation/Iteration                   968
Evaluation/MaxReturn                 -1171.72
Evaluation/MinReturn                 -1270.14
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    34.0674
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.4267
GaussianMLPPolicy/KL                     0.000242197
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -460.044
GaussianMLPPolicy/LossBefore          -459.87
GaussianMLPPolicy/dLoss                  0.174469
GaussianMLPValueFunction/LossAfter   22384.3
GaussianMLPValueFunction/LossBefore  22403.7
GaussianMLPValueFunction/dLoss          19.4141
TotalEnvSteps                            1.1628e+06
-----------------------------------  ---------------
2022-08-17 18:01:19 | [trpo_pendulum] epoch #969 | Saving snapshot...
2022-08-17 18:01:19 | [trpo_pendulum] epoch #969 | Saved
2022-08-17 18:01:19 | [trpo_pendulum] epoch #969 | Time 399.21 s
2022-08-17 18:01:19 | [trpo_pendulum] epoch #969 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -493.588
Evaluation/AverageReturn             -1171.76
Evaluation/Iteration                   969
Evaluation/MaxReturn                  -947.375
Evaluation/MinReturn                 -1273.74
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   108.606
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42688
GaussianMLPPolicy/KL                     0.000222465
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -448.204
GaussianMLPPolicy/LossBefore          -448.088
GaussianMLPPolicy/dLoss                  0.116455
GaussianMLPValueFunction/LossAfter   20544.5
GaussianMLPValueFunction/LossBefore  20562.4
GaussianMLPValueFunction/dLoss          17.9023
TotalEnvSteps                            1.164e+06
-----------------------------------  ---------------
2022-08-17 18:01:19 | [trpo_pendulum] epoch #970 | Saving snapshot...
2022-08-17 18:01:19 | [trpo_pendulum] epoch #970 | Saved
2022-08-17 18:01:19 | [trpo_pendulum] epoch #970 | Time 399.61 s
2022-08-17 18:01:19 | [trpo_pendulum] epoch #970 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -590.414
Evaluation/AverageReturn             -1386.47
Evaluation/Iteration                   970
Evaluation/MaxReturn                 -1323.61
Evaluation/MinReturn                 -1475.43
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    57.4705
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42699
GaussianMLPPolicy/KL                     9.78093e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -529.788
GaussianMLPPolicy/LossBefore          -529.783
GaussianMLPPolicy/dLoss                  0.00476074
GaussianMLPValueFunction/LossAfter   28915.6
GaussianMLPValueFunction/LossBefore  28941.2
GaussianMLPValueFunction/dLoss          25.6387
TotalEnvSteps                            1.1652e+06
-----------------------------------  ---------------
2022-08-17 18:01:20 | [trpo_pendulum] epoch #971 | Saving snapshot...
2022-08-17 18:01:20 | [trpo_pendulum] epoch #971 | Saved
2022-08-17 18:01:20 | [trpo_pendulum] epoch #971 | Time 400.00 s
2022-08-17 18:01:20 | [trpo_pendulum] epoch #971 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -727.699
Evaluation/AverageReturn             -1653.99
Evaluation/Iteration                   971
Evaluation/MaxReturn                 -1462.48
Evaluation/MinReturn                 -1816.4
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   124.766
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42697
GaussianMLPPolicy/KL                     1.47791e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -628.951
GaussianMLPPolicy/LossBefore          -628.998
GaussianMLPPolicy/dLoss                 -0.0464478
GaussianMLPValueFunction/LossAfter   40969.6
GaussianMLPValueFunction/LossBefore  41008.3
GaussianMLPValueFunction/dLoss          38.7383
TotalEnvSteps                            1.1664e+06
-----------------------------------  ---------------
2022-08-17 18:01:20 | [trpo_pendulum] epoch #972 | Saving snapshot...
2022-08-17 18:01:20 | [trpo_pendulum] epoch #972 | Saved
2022-08-17 18:01:20 | [trpo_pendulum] epoch #972 | Time 400.40 s
2022-08-17 18:01:20 | [trpo_pendulum] epoch #972 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -438.576
Evaluation/AverageReturn             -1151.64
Evaluation/Iteration                   972
Evaluation/MaxReturn                 -1062.56
Evaluation/MinReturn                 -1264.64
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    61.1607
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42691
GaussianMLPPolicy/KL                     5.58914e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -468.298
GaussianMLPPolicy/LossBefore          -467.956
GaussianMLPPolicy/dLoss                  0.34198
GaussianMLPValueFunction/LossAfter   22191.9
GaussianMLPValueFunction/LossBefore  22213.5
GaussianMLPValueFunction/dLoss          21.6113
TotalEnvSteps                            1.1676e+06
-----------------------------------  ---------------
2022-08-17 18:01:20 | [trpo_pendulum] epoch #973 | Saving snapshot...
2022-08-17 18:01:20 | [trpo_pendulum] epoch #973 | Saved
2022-08-17 18:01:20 | [trpo_pendulum] epoch #973 | Time 400.81 s
2022-08-17 18:01:20 | [trpo_pendulum] epoch #973 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -432.271
Evaluation/AverageReturn             -1087.74
Evaluation/Iteration                   973
Evaluation/MaxReturn                  -898.274
Evaluation/MinReturn                 -1313.97
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   134.487
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42696
GaussianMLPPolicy/KL                     0.000208008
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -415.736
GaussianMLPPolicy/LossBefore          -415.332
GaussianMLPPolicy/dLoss                  0.404053
GaussianMLPValueFunction/LossAfter   18601.3
GaussianMLPValueFunction/LossBefore  18619.2
GaussianMLPValueFunction/dLoss          17.9727
TotalEnvSteps                            1.1688e+06
-----------------------------------  ---------------
2022-08-17 18:01:21 | [trpo_pendulum] epoch #974 | Saving snapshot...
2022-08-17 18:01:21 | [trpo_pendulum] epoch #974 | Saved
2022-08-17 18:01:21 | [trpo_pendulum] epoch #974 | Time 401.22 s
2022-08-17 18:01:21 | [trpo_pendulum] epoch #974 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -717.171
Evaluation/AverageReturn             -1611.17
Evaluation/Iteration                   974
Evaluation/MaxReturn                 -1538.02
Evaluation/MinReturn                 -1756.47
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    76.6309
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42696
GaussianMLPPolicy/KL                     7.23478e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -600.312
GaussianMLPPolicy/LossBefore          -600.182
GaussianMLPPolicy/dLoss                  0.130371
GaussianMLPValueFunction/LossAfter   37841
GaussianMLPValueFunction/LossBefore  37878.3
GaussianMLPValueFunction/dLoss          37.2812
TotalEnvSteps                            1.17e+06
-----------------------------------  ---------------
2022-08-17 18:01:21 | [trpo_pendulum] epoch #975 | Saving snapshot...
2022-08-17 18:01:21 | [trpo_pendulum] epoch #975 | Saved
2022-08-17 18:01:21 | [trpo_pendulum] epoch #975 | Time 401.61 s
2022-08-17 18:01:21 | [trpo_pendulum] epoch #975 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -572.323
Evaluation/AverageReturn             -1349.75
Evaluation/Iteration                   975
Evaluation/MaxReturn                 -1293.37
Evaluation/MinReturn                 -1401.74
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    35.6672
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42709
GaussianMLPPolicy/KL                     0.000301901
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -502.084
GaussianMLPPolicy/LossBefore          -501.466
GaussianMLPPolicy/dLoss                  0.617249
GaussianMLPValueFunction/LossAfter   27427
GaussianMLPValueFunction/LossBefore  27454.8
GaussianMLPValueFunction/dLoss          27.8164
TotalEnvSteps                            1.1712e+06
-----------------------------------  ---------------
2022-08-17 18:01:22 | [trpo_pendulum] epoch #976 | Saving snapshot...
2022-08-17 18:01:22 | [trpo_pendulum] epoch #976 | Saved
2022-08-17 18:01:22 | [trpo_pendulum] epoch #976 | Time 402.02 s
2022-08-17 18:01:22 | [trpo_pendulum] epoch #976 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -415.88
Evaluation/AverageReturn             -1068.87
Evaluation/Iteration                   976
Evaluation/MaxReturn                  -939.002
Evaluation/MinReturn                 -1191.95
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    74.5099
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42725
GaussianMLPPolicy/KL                     0.000646414
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -419.344
GaussianMLPPolicy/LossBefore          -418.471
GaussianMLPPolicy/dLoss                  0.873352
GaussianMLPValueFunction/LossAfter   18368.2
GaussianMLPValueFunction/LossBefore  18386.8
GaussianMLPValueFunction/dLoss          18.6387
TotalEnvSteps                            1.1724e+06
-----------------------------------  ---------------
2022-08-17 18:01:22 | [trpo_pendulum] epoch #977 | Saving snapshot...
2022-08-17 18:01:22 | [trpo_pendulum] epoch #977 | Saved
2022-08-17 18:01:22 | [trpo_pendulum] epoch #977 | Time 402.42 s
2022-08-17 18:01:22 | [trpo_pendulum] epoch #977 | EpochTime 0.39 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -606.209
Evaluation/AverageReturn             -1382.76
Evaluation/Iteration                   977
Evaluation/MaxReturn                 -1365.17
Evaluation/MinReturn                 -1388.58
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                     8.24762
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42716
GaussianMLPPolicy/KL                     0.00029899
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -529.62
GaussianMLPPolicy/LossBefore          -529.746
GaussianMLPPolicy/dLoss                 -0.125488
GaussianMLPValueFunction/LossAfter   27412
GaussianMLPValueFunction/LossBefore  27439.5
GaussianMLPValueFunction/dLoss          27.5254
TotalEnvSteps                            1.1736e+06
-----------------------------------  --------------
2022-08-17 18:01:22 | [trpo_pendulum] epoch #978 | Saving snapshot...
2022-08-17 18:01:22 | [trpo_pendulum] epoch #978 | Saved
2022-08-17 18:01:22 | [trpo_pendulum] epoch #978 | Time 402.81 s
2022-08-17 18:01:22 | [trpo_pendulum] epoch #978 | EpochTime 0.39 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -440.855
Evaluation/AverageReturn             -1017.98
Evaluation/Iteration                   978
Evaluation/MaxReturn                  -771.765
Evaluation/MinReturn                 -1168.29
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   144.338
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42711
GaussianMLPPolicy/KL                     0.00020988
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -366.09
GaussianMLPPolicy/LossBefore          -366.131
GaussianMLPPolicy/dLoss                 -0.0404053
GaussianMLPValueFunction/LossAfter   15047.5
GaussianMLPValueFunction/LossBefore  15062.5
GaussianMLPValueFunction/dLoss          15.0518
TotalEnvSteps                            1.1748e+06
-----------------------------------  --------------
2022-08-17 18:01:23 | [trpo_pendulum] epoch #979 | Saving snapshot...
2022-08-17 18:01:23 | [trpo_pendulum] epoch #979 | Saved
2022-08-17 18:01:23 | [trpo_pendulum] epoch #979 | Time 403.23 s
2022-08-17 18:01:23 | [trpo_pendulum] epoch #979 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -454.998
Evaluation/AverageReturn             -1062.68
Evaluation/Iteration                   979
Evaluation/MaxReturn                  -857.413
Evaluation/MinReturn                 -1143.21
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   102.771
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.4271
GaussianMLPPolicy/KL                     0.000228023
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -386.195
GaussianMLPPolicy/LossBefore          -386.025
GaussianMLPPolicy/dLoss                  0.170532
GaussianMLPValueFunction/LossAfter   16009.8
GaussianMLPValueFunction/LossBefore  16025.3
GaussianMLPValueFunction/dLoss          15.5391
TotalEnvSteps                            1.176e+06
-----------------------------------  ---------------
2022-08-17 18:01:23 | [trpo_pendulum] epoch #980 | Saving snapshot...
2022-08-17 18:01:23 | [trpo_pendulum] epoch #980 | Saved
2022-08-17 18:01:23 | [trpo_pendulum] epoch #980 | Time 403.64 s
2022-08-17 18:01:23 | [trpo_pendulum] epoch #980 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -544.329
Evaluation/AverageReturn             -1230.01
Evaluation/Iteration                   980
Evaluation/MaxReturn                 -1168.71
Evaluation/MinReturn                 -1303.79
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    55.2379
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42707
GaussianMLPPolicy/KL                     0.000101747
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -448.798
GaussianMLPPolicy/LossBefore          -448.859
GaussianMLPPolicy/dLoss                 -0.0603027
GaussianMLPValueFunction/LossAfter   21389.8
GaussianMLPValueFunction/LossBefore  21410
GaussianMLPValueFunction/dLoss          20.248
TotalEnvSteps                            1.1772e+06
-----------------------------------  ---------------
2022-08-17 18:01:24 | [trpo_pendulum] epoch #981 | Saving snapshot...
2022-08-17 18:01:24 | [trpo_pendulum] epoch #981 | Saved
2022-08-17 18:01:24 | [trpo_pendulum] epoch #981 | Time 404.04 s
2022-08-17 18:01:24 | [trpo_pendulum] epoch #981 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -513.982
Evaluation/AverageReturn             -1181.91
Evaluation/Iteration                   981
Evaluation/MaxReturn                 -1073.68
Evaluation/MinReturn                 -1247.67
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    57.8309
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42715
GaussianMLPPolicy/KL                     6.26887e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -424.343
GaussianMLPPolicy/LossBefore          -424.348
GaussianMLPPolicy/dLoss                 -0.00488281
GaussianMLPValueFunction/LossAfter   19856.7
GaussianMLPValueFunction/LossBefore  19875.4
GaussianMLPValueFunction/dLoss          18.6992
TotalEnvSteps                            1.1784e+06
-----------------------------------  ---------------
2022-08-17 18:01:24 | [trpo_pendulum] epoch #982 | Saving snapshot...
2022-08-17 18:01:24 | [trpo_pendulum] epoch #982 | Saved
2022-08-17 18:01:24 | [trpo_pendulum] epoch #982 | Time 404.44 s
2022-08-17 18:01:24 | [trpo_pendulum] epoch #982 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -590.818
Evaluation/AverageReturn             -1338.57
Evaluation/Iteration                   982
Evaluation/MaxReturn                 -1276.25
Evaluation/MinReturn                 -1425.28
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    53.5537
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42715
GaussianMLPPolicy/KL                     8.50177e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -495.924
GaussianMLPPolicy/LossBefore          -495.757
GaussianMLPPolicy/dLoss                  0.167572
GaussianMLPValueFunction/LossAfter   25538.5
GaussianMLPValueFunction/LossBefore  25562.5
GaussianMLPValueFunction/dLoss          24.0273
TotalEnvSteps                            1.1796e+06
-----------------------------------  ---------------
2022-08-17 18:01:24 | [trpo_pendulum] epoch #983 | Saving snapshot...
2022-08-17 18:01:25 | [trpo_pendulum] epoch #983 | Saved
2022-08-17 18:01:25 | [trpo_pendulum] epoch #983 | Time 404.86 s
2022-08-17 18:01:25 | [trpo_pendulum] epoch #983 | EpochTime 0.42 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -584.346
Evaluation/AverageReturn             -1342.1
Evaluation/Iteration                   983
Evaluation/MaxReturn                 -1267.3
Evaluation/MinReturn                 -1416.45
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    51.0278
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42702
GaussianMLPPolicy/KL                     0.000468403
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -509.301
GaussianMLPPolicy/LossBefore          -508.155
GaussianMLPPolicy/dLoss                  1.14536
GaussianMLPValueFunction/LossAfter   25995
GaussianMLPValueFunction/LossBefore  26019.8
GaussianMLPValueFunction/dLoss          24.8086
TotalEnvSteps                            1.1808e+06
-----------------------------------  ---------------
2022-08-17 18:01:25 | [trpo_pendulum] epoch #984 | Saving snapshot...
2022-08-17 18:01:25 | [trpo_pendulum] epoch #984 | Saved
2022-08-17 18:01:25 | [trpo_pendulum] epoch #984 | Time 405.28 s
2022-08-17 18:01:25 | [trpo_pendulum] epoch #984 | EpochTime 0.41 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -387.788
Evaluation/AverageReturn              -905.926
Evaluation/Iteration                   984
Evaluation/MaxReturn                  -629.928
Evaluation/MinReturn                 -1066.52
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                   134.609
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42685
GaussianMLPPolicy/KL                     0.00056547
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -329.763
GaussianMLPPolicy/LossBefore          -329.353
GaussianMLPPolicy/dLoss                  0.40976
GaussianMLPValueFunction/LossAfter   11535.3
GaussianMLPValueFunction/LossBefore  11546.4
GaussianMLPValueFunction/dLoss          11.0508
TotalEnvSteps                            1.182e+06
-----------------------------------  --------------
2022-08-17 18:01:25 | [trpo_pendulum] epoch #985 | Saving snapshot...
2022-08-17 18:01:25 | [trpo_pendulum] epoch #985 | Saved
2022-08-17 18:01:25 | [trpo_pendulum] epoch #985 | Time 405.69 s
2022-08-17 18:01:25 | [trpo_pendulum] epoch #985 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -383.463
Evaluation/AverageReturn              -915.471
Evaluation/Iteration                   985
Evaluation/MaxReturn                  -754.69
Evaluation/MinReturn                 -1009.07
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    87.9358
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42668
GaussianMLPPolicy/KL                     0.000274346
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -336.573
GaussianMLPPolicy/LossBefore          -336.74
GaussianMLPPolicy/dLoss                 -0.167267
GaussianMLPValueFunction/LossAfter   11766.9
GaussianMLPValueFunction/LossBefore  11777.7
GaussianMLPValueFunction/dLoss          10.8193
TotalEnvSteps                            1.1832e+06
-----------------------------------  ---------------
2022-08-17 18:01:26 | [trpo_pendulum] epoch #986 | Saving snapshot...
2022-08-17 18:01:26 | [trpo_pendulum] epoch #986 | Saved
2022-08-17 18:01:26 | [trpo_pendulum] epoch #986 | Time 406.12 s
2022-08-17 18:01:26 | [trpo_pendulum] epoch #986 | EpochTime 0.43 s
-----------------------------------  --------------
Evaluation/AverageDiscountedReturn    -399.735
Evaluation/AverageReturn              -904.001
Evaluation/Iteration                   986
Evaluation/MaxReturn                  -816.46
Evaluation/MinReturn                  -981.072
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    57.6649
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42643
GaussianMLPPolicy/KL                     0.00026404
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -322.874
GaussianMLPPolicy/LossBefore          -322.728
GaussianMLPPolicy/dLoss                  0.146545
GaussianMLPValueFunction/LossAfter   10993.3
GaussianMLPValueFunction/LossBefore  11002.9
GaussianMLPValueFunction/dLoss           9.6748
TotalEnvSteps                            1.1844e+06
-----------------------------------  --------------
2022-08-17 18:01:26 | [trpo_pendulum] epoch #987 | Saving snapshot...
2022-08-17 18:01:26 | [trpo_pendulum] epoch #987 | Saved
2022-08-17 18:01:26 | [trpo_pendulum] epoch #987 | Time 406.52 s
2022-08-17 18:01:26 | [trpo_pendulum] epoch #987 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -394.754
Evaluation/AverageReturn              -901.524
Evaluation/Iteration                   987
Evaluation/MaxReturn                  -762.449
Evaluation/MinReturn                 -1014.3
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    75.3931
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42625
GaussianMLPPolicy/KL                     0.000277308
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -314.257
GaussianMLPPolicy/LossBefore          -314.118
GaussianMLPPolicy/dLoss                  0.13858
GaussianMLPValueFunction/LossAfter   11195.7
GaussianMLPValueFunction/LossBefore  11205.1
GaussianMLPValueFunction/dLoss           9.45312
TotalEnvSteps                            1.1856e+06
-----------------------------------  ---------------
2022-08-17 18:01:27 | [trpo_pendulum] epoch #988 | Saving snapshot...
2022-08-17 18:01:27 | [trpo_pendulum] epoch #988 | Saved
2022-08-17 18:01:27 | [trpo_pendulum] epoch #988 | Time 406.91 s
2022-08-17 18:01:27 | [trpo_pendulum] epoch #988 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -423.538
Evaluation/AverageReturn              -963.863
Evaluation/Iteration                   988
Evaluation/MaxReturn                  -874.88
Evaluation/MinReturn                 -1092.89
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    86.0619
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42591
GaussianMLPPolicy/KL                     7.22685e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -354.904
GaussianMLPPolicy/LossBefore          -354.998
GaussianMLPPolicy/dLoss                 -0.0938416
GaussianMLPValueFunction/LossAfter   12489
GaussianMLPValueFunction/LossBefore  12499.1
GaussianMLPValueFunction/dLoss          10.1475
TotalEnvSteps                            1.1868e+06
-----------------------------------  ---------------
2022-08-17 18:01:27 | [trpo_pendulum] epoch #989 | Saving snapshot...
2022-08-17 18:01:27 | [trpo_pendulum] epoch #989 | Saved
2022-08-17 18:01:27 | [trpo_pendulum] epoch #989 | Time 407.32 s
2022-08-17 18:01:27 | [trpo_pendulum] epoch #989 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -587.64
Evaluation/AverageReturn             -1297.5
Evaluation/Iteration                   989
Evaluation/MaxReturn                 -1208.51
Evaluation/MinReturn                 -1350.74
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    43.0825
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42556
GaussianMLPPolicy/KL                     0.000166836
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -466.376
GaussianMLPPolicy/LossBefore          -466.089
GaussianMLPPolicy/dLoss                  0.287354
GaussianMLPValueFunction/LossAfter   23066.9
GaussianMLPValueFunction/LossBefore  23085.3
GaussianMLPValueFunction/dLoss          18.3652
TotalEnvSteps                            1.188e+06
-----------------------------------  ---------------
2022-08-17 18:01:27 | [trpo_pendulum] epoch #990 | Saving snapshot...
2022-08-17 18:01:27 | [trpo_pendulum] epoch #990 | Saved
2022-08-17 18:01:27 | [trpo_pendulum] epoch #990 | Time 407.72 s
2022-08-17 18:01:27 | [trpo_pendulum] epoch #990 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -577.771
Evaluation/AverageReturn             -1268.06
Evaluation/Iteration                   990
Evaluation/MaxReturn                 -1196.94
Evaluation/MinReturn                 -1366.48
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    57.9475
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42516
GaussianMLPPolicy/KL                     0.000217298
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -455.835
GaussianMLPPolicy/LossBefore          -455.621
GaussianMLPPolicy/dLoss                  0.214264
GaussianMLPValueFunction/LossAfter   21903.5
GaussianMLPValueFunction/LossBefore  21921.3
GaussianMLPValueFunction/dLoss          17.7617
TotalEnvSteps                            1.1892e+06
-----------------------------------  ---------------
2022-08-17 18:01:28 | [trpo_pendulum] epoch #991 | Saving snapshot...
2022-08-17 18:01:28 | [trpo_pendulum] epoch #991 | Saved
2022-08-17 18:01:28 | [trpo_pendulum] epoch #991 | Time 408.14 s
2022-08-17 18:01:28 | [trpo_pendulum] epoch #991 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -559.879
Evaluation/AverageReturn             -1224.87
Evaluation/Iteration                   991
Evaluation/MaxReturn                 -1095.47
Evaluation/MinReturn                 -1320.89
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    76.5122
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.4248
GaussianMLPPolicy/KL                     0.000518449
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -430.977
GaussianMLPPolicy/LossBefore          -430.125
GaussianMLPPolicy/dLoss                  0.85257
GaussianMLPValueFunction/LossAfter   20251
GaussianMLPValueFunction/LossBefore  20267.6
GaussianMLPValueFunction/dLoss          16.6074
TotalEnvSteps                            1.1904e+06
-----------------------------------  ---------------
2022-08-17 18:01:28 | [trpo_pendulum] epoch #992 | Saving snapshot...
2022-08-17 18:01:28 | [trpo_pendulum] epoch #992 | Saved
2022-08-17 18:01:28 | [trpo_pendulum] epoch #992 | Time 408.53 s
2022-08-17 18:01:28 | [trpo_pendulum] epoch #992 | EpochTime 0.39 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -580.149
Evaluation/AverageReturn             -1229.42
Evaluation/Iteration                   992
Evaluation/MaxReturn                 -1105.26
Evaluation/MinReturn                 -1386.32
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    82.7235
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42442
GaussianMLPPolicy/KL                     0.000379891
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -424.468
GaussianMLPPolicy/LossBefore          -424.387
GaussianMLPPolicy/dLoss                  0.0805664
GaussianMLPValueFunction/LossAfter   19981.6
GaussianMLPValueFunction/LossBefore  19998.1
GaussianMLPValueFunction/dLoss          16.4219
TotalEnvSteps                            1.1916e+06
-----------------------------------  ---------------
2022-08-17 18:01:29 | [trpo_pendulum] epoch #993 | Saving snapshot...
2022-08-17 18:01:29 | [trpo_pendulum] epoch #993 | Saved
2022-08-17 18:01:29 | [trpo_pendulum] epoch #993 | Time 408.91 s
2022-08-17 18:01:29 | [trpo_pendulum] epoch #993 | EpochTime 0.38 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -424.027
Evaluation/AverageReturn             -1007.46
Evaluation/Iteration                   993
Evaluation/MaxReturn                  -878.91
Evaluation/MinReturn                 -1161.59
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    99.109
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42416
GaussianMLPPolicy/KL                     0.000243917
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -363.681
GaussianMLPPolicy/LossBefore          -363.8
GaussianMLPPolicy/dLoss                 -0.118225
GaussianMLPValueFunction/LossAfter   14740.3
GaussianMLPValueFunction/LossBefore  14752.5
GaussianMLPValueFunction/dLoss          12.1904
TotalEnvSteps                            1.1928e+06
-----------------------------------  ---------------
2022-08-17 18:01:29 | [trpo_pendulum] epoch #994 | Saving snapshot...
2022-08-17 18:01:29 | [trpo_pendulum] epoch #994 | Saved
2022-08-17 18:01:29 | [trpo_pendulum] epoch #994 | Time 409.33 s
2022-08-17 18:01:29 | [trpo_pendulum] epoch #994 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -531.019
Evaluation/AverageReturn             -1157.14
Evaluation/Iteration                   994
Evaluation/MaxReturn                 -1105.55
Evaluation/MinReturn                 -1218.45
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    48.0691
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42403
GaussianMLPPolicy/KL                     6.25775e-05
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -394.855
GaussianMLPPolicy/LossBefore          -394.949
GaussianMLPPolicy/dLoss                 -0.0947876
GaussianMLPValueFunction/LossAfter   17396.2
GaussianMLPValueFunction/LossBefore  17410.2
GaussianMLPValueFunction/dLoss          14.0859
TotalEnvSteps                            1.194e+06
-----------------------------------  ---------------
2022-08-17 18:01:29 | [trpo_pendulum] epoch #995 | Saving snapshot...
2022-08-17 18:01:29 | [trpo_pendulum] epoch #995 | Saved
2022-08-17 18:01:29 | [trpo_pendulum] epoch #995 | Time 409.73 s
2022-08-17 18:01:29 | [trpo_pendulum] epoch #995 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -469.059
Evaluation/AverageReturn             -1047.41
Evaluation/Iteration                   995
Evaluation/MaxReturn                  -974.449
Evaluation/MinReturn                 -1123.12
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    59.7485
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42389
GaussianMLPPolicy/KL                     0.000194543
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -369.851
GaussianMLPPolicy/LossBefore          -369.508
GaussianMLPPolicy/dLoss                  0.342529
GaussianMLPValueFunction/LossAfter   14420.6
GaussianMLPValueFunction/LossBefore  14432.3
GaussianMLPValueFunction/dLoss          11.6113
TotalEnvSteps                            1.1952e+06
-----------------------------------  ---------------
2022-08-17 18:01:30 | [trpo_pendulum] epoch #996 | Saving snapshot...
2022-08-17 18:01:30 | [trpo_pendulum] epoch #996 | Saved
2022-08-17 18:01:30 | [trpo_pendulum] epoch #996 | Time 410.14 s
2022-08-17 18:01:30 | [trpo_pendulum] epoch #996 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -396.781
Evaluation/AverageReturn              -943.56
Evaluation/Iteration                   996
Evaluation/MaxReturn                  -895.019
Evaluation/MinReturn                 -1038.17
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    62.3896
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42367
GaussianMLPPolicy/KL                     0.000293598
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -352.593
GaussianMLPPolicy/LossBefore          -352.323
GaussianMLPPolicy/dLoss                  0.27005
GaussianMLPValueFunction/LossAfter   12797.1
GaussianMLPValueFunction/LossBefore  12807.2
GaussianMLPValueFunction/dLoss          10.1094
TotalEnvSteps                            1.1964e+06
-----------------------------------  ---------------
2022-08-17 18:01:30 | [trpo_pendulum] epoch #997 | Saving snapshot...
2022-08-17 18:01:30 | [trpo_pendulum] epoch #997 | Saved
2022-08-17 18:01:30 | [trpo_pendulum] epoch #997 | Time 410.56 s
2022-08-17 18:01:30 | [trpo_pendulum] epoch #997 | EpochTime 0.41 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -464.469
Evaluation/AverageReturn             -1071.75
Evaluation/Iteration                   997
Evaluation/MaxReturn                  -974.071
Evaluation/MinReturn                 -1159.18
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    59.7515
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42336
GaussianMLPPolicy/KL                     0.000216671
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -396.8
GaussianMLPPolicy/LossBefore          -396.725
GaussianMLPPolicy/dLoss                  0.0756226
GaussianMLPValueFunction/LossAfter   16309.6
GaussianMLPValueFunction/LossBefore  16322.2
GaussianMLPValueFunction/dLoss          12.6104
TotalEnvSteps                            1.1976e+06
-----------------------------------  ---------------
2022-08-17 18:01:31 | [trpo_pendulum] epoch #998 | Saving snapshot...
2022-08-17 18:01:31 | [trpo_pendulum] epoch #998 | Saved
2022-08-17 18:01:31 | [trpo_pendulum] epoch #998 | Time 410.98 s
2022-08-17 18:01:31 | [trpo_pendulum] epoch #998 | EpochTime 0.42 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -462.315
Evaluation/AverageReturn             -1061.02
Evaluation/Iteration                   998
Evaluation/MaxReturn                  -988.516
Evaluation/MinReturn                 -1124.53
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    44.2911
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42292
GaussianMLPPolicy/KL                     0.000303947
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -394.855
GaussianMLPPolicy/LossBefore          -394.566
GaussianMLPPolicy/dLoss                  0.289703
GaussianMLPValueFunction/LossAfter   15302.5
GaussianMLPValueFunction/LossBefore  15314.3
GaussianMLPValueFunction/dLoss          11.7334
TotalEnvSteps                            1.1988e+06
-----------------------------------  ---------------
2022-08-17 18:01:31 | [trpo_pendulum] epoch #999 | Saving snapshot...
2022-08-17 18:01:31 | [trpo_pendulum] epoch #999 | Saved
2022-08-17 18:01:31 | [trpo_pendulum] epoch #999 | Time 411.38 s
2022-08-17 18:01:31 | [trpo_pendulum] epoch #999 | EpochTime 0.40 s
-----------------------------------  ---------------
Evaluation/AverageDiscountedReturn    -463.465
Evaluation/AverageReturn             -1035.28
Evaluation/Iteration                   999
Evaluation/MaxReturn                  -997.048
Evaluation/MinReturn                 -1097.75
Evaluation/NumEpisodes                   6
Evaluation/StdReturn                    39.7374
Evaluation/TerminationRate               0
GaussianMLPPolicy/Entropy                1.42251
GaussianMLPPolicy/KL                     0.000481779
GaussianMLPPolicy/KLBefore               0
GaussianMLPPolicy/LossAfter           -365.015
GaussianMLPPolicy/LossBefore          -364.531
GaussianMLPPolicy/dLoss                  0.484009
GaussianMLPValueFunction/LossAfter   14088.4
GaussianMLPValueFunction/LossBefore  14099.1
GaussianMLPValueFunction/dLoss          10.6719
TotalEnvSteps                            1.2e+06
-----------------------------------  ---------------
